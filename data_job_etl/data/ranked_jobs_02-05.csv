,id,url,title,company,stack,remote,location,industry,type,created_at,text,summary,education,size,experience,remote_num,exp_num,rank
350,56587,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-engineer_london,Junior Data Engineer,Artefact,"{GCP,Azure,AWS,BigQuery,Git,SQL,Python,Postgres}",Télétravail total possible,London,"Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that’s why we identify as “marketing engineers”. In order to improve the performance and impact of brands, and consumers’ experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). Junior Data Engineer About us: Artefact is a new generation of a data service provider, specialising in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we’re enjoying skyrocketing growth. Our broad range of data-driven solutions in data consulting and digital marketing are designed to meet our clients’ specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we’ve acquired with our 1000+ client base around the globe. We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client. Role Profile: As a Data Engineer at Artefact, you will be given opportunities to innovate, build, train and communicate with a team made up of consultants, data scientists, creatives and engineers to identify business needs and define innovative solutions. You will work in a collaborative team which champions knowledge sharing. You will work in an environment that encourages coaching & collaboration at all levels. Allowing you to work closely with other departments & keep abreast of industry news/updates and share your discoveries with others. Your technical skills: Programming skills in Python including building, testing and releasing code into production SQL skills with exposure working with relational/columnar databases (e.g. BigQuery, SQL Server, Postgres) Experience using Git and version controlling A willingness to learn and find solutions to complex problems Exposure with one of the main cloud providers (GCP, Azure, AWS) is desirable Experience with agile software delivery and CI/CD processes is a bonus Your mindset: Curious, you are always seeking innovative solutions for your clients Sharing of knowledge is essential for you and you actively participate in the diffusion of information within Artefact (seminaries, formations, certifications) Entrepreneurial, you bring solutions, new ideas, within your team at Artefact You are able to act on the whole value chain of projects (infrastructures and platforms creation, data collection, application of machine learning models, APIs REST creations, of front-ends, of tests, continuous deployments) You have strong communication skills and can popularize technical terms or solutions to more business oriented profiles, you can work in a team with very diversified profiles You are independent in managing your tasks and timelines Why you should join us Artefact is revolutionizing marketing: join us to build the future of marketing Progress: every day offers new challenges and new opportunities to learn Culture: Check out our website (Artefact.com) or Instagram (Artefact UK) to find out more about our diverse, vibrant culture here Entrepreneurship: you will be joining a team of driven entrepreneurs. We won’t give up until we make a huge dent in this industry! Hit apply, and see whether what we offer is what you’ve been looking for!","Artefact, a consulting firm specialized in AI and Data, is seeking a Junior Data Engineer to work with a team of consultants, data scientists, creatives and engineers to identify business needs and define innovative solutions. The ideal candidate must have programming skills in Python, SQL skills, experience using Git and version control, ability to learn and solve complex problems, and familiarity with cloud providers. Artefact offers a vibrant culture, opportunities to learn and grow, and a chance to revolutionize marketing.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,3,0.08309324832467525
30,56722,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-gdo-data-software-engineer-h-f_paris,ALIT GDO - DATA SOFTWARE ENGINEER,Air Liquide,"{DynamoDB,DBT,Glue,Lambda,Docker,EC2,Postgresql,Athena,Gitlab,Prometheus,Git,grafana,AWS,SQL,EMR,Airflow,Redshift,S3,Python}",Télétravail total possible,"Paris, 74000","Environnement / Développement durable, Santé, Energie, Digital",CDI,2023-03-26,"Air Liquide est un leader mondial des gaz, technologies et services pour l’industrie et la santé . Oxygène, azote et hydrogène sont des petites molécules essentielles à la vie, la matière et l’énergie. Grâce à l’engagement et l’inventivité de ses collaborateurs pour répondre aux enjeux de la transition énergétique et environnementale, de la santé et de la transformation numérique , Air Liquide crée encore plus de valeur pour l’ensemble de ses parties prenantes. La diversité et l’inclusion du handicap au sein de notre organisation nous permet de répondre au mieux aux défis complexes des marchés que nous servons, de stimuler l’innovation et de contribuer à créer de la valeur pour nos clients, nos partenaires et la société en général. Notre méthode de gestion des talents – de l’embauche au développement de leur carrière – sont le reflet de notre engagement en faveur de la diversité et de l’inclusion du handicap . La conjugaison de ces éléments et de la grande part d’intrapreneuriat au sein d’équipes à taille humaine nous permet de relever des challenges ambitieux. Au sein de la division Innovation et Développement, le département Global Data Operations (GDO) accompagne nos ambitions de stratégie et de gouvernance, en apportant l'expertise et les plateformes technologiques Data & IA nécessaires au développement de solutions différenciantes pour les métiers d'Air Liquide. Au sein de GDO, la Product Line Data Lake & AI à pour mission d'accompagner la stratégie de déploiement à l'échelle d'Air Liquide : il s'agit de construire, opérer et faire évoluer la data platform du groupe. L'équipe est composée de profils pluridisciplinaires et à en charge spécifiquement les produits et stratégies data lake et data science dans des contextes géographiques étendus sur différents Hub ( Amérique, Asie, Europe et Afrique) ainsi que des contraintes fortes liées aux législations imposées par nos activités business. Vous ferez partie de l'équipe Core Data Platform , et rapporterez au Data Platform Product Manager. Vos responsabilités incluent la conception et l'opération des produits que compose la data platform Air Liquide telle que les services d'Ingestion, de transformation, de data quality et tooling divers pour supporter toutes les activités projets : Contribuer au développement et à la maintenance des nouvelles fonctionnalités des produits lake Contribuer à l'amélioration de l'architecture technique de la plateforme Contribuer à la revue de code Contribuer à la correction des bugs fonctionnels et techniques Contribuer à l'amélioration de la qualité du code et du produit en participant à l'écriture des tests unitaires, fonctionnels, d'intégrations, de charges et End-to-End Contribuer à la documentation fonctionnelle et technique de l'application Contribuer à l'amélioration de l'observabilité de la plateforme Bonne application des règles de sécurité et de confidentialité du Groupe liées au traitement de la donnée Education et Expérience Bac + 5 de formation Ingénieur ou formation supérieure en sciences Informatiques, idéalement avec une orientation Data 3+ années d'expériences en relation avec le poste Expérience de travail en environnement agile Compétences techniques Langage : Python CI/CD : Git, Gitlab-CI,Docker Observability: Prometheus, grafana Cloud : Très bonnes connaissances des technologies AWS Data analytics: EMR, Lambda, DynamoDB, Athena, Glue Catalog, AWS Batch, EC2, S3 Orchestration: Airflow , AWS StepFunction Database : Redshift ,Postgresql API: FastApi, Falcon Compétences fortement appréciées : SQL, PySpark , DBT, Apigee, Cloudformation, Terraform Compétences non techniques Proactivité et orientation utilisateurs Ouverture d'esprit et esprit d'équipe Curiosité et prise d'initiative. Capacité à travailler dans un environnement matriciel international Capacité d'analyse et de synthèse L'anglais et le français courants à l'écrit comme à l'oral sont indispensables. Horaires et lieux de travail Le poste est basé à Paris XIe sur le Campus de La Factory. Des déplacements occasionnels pourront être nécessaires en France ou à l'étranger. Manager : Data Platform Product Manager Ce que nous offrons L'utilisation des dernières technologies et la possibilité de travailler avec des experts techniques très reconnus dans leur domaine La possibilité d' apprendre et de monter en compétences en continu dans une équipe récente, agile et en croissance Des perspectives d'évolution au sein du groupe grâce à notre politique de mobilité interne Un cadre de travail stimulant et multiculturel au cœur de Paris, avec un accord télétravail en place (3 jours par semaine de télétravail) De nombreux avantages : Participation/Intéressement, prime vacances, carte tickets restaurants, CE, 152€/mois de CESU pour les personnes ayant à charge un ou plusieurs enfant(s) de 3 ans ou moins …","Air Liquide is seeking a Data Platform Engineer with at least 3 years of relevant experience in a similar role, strong Python skills, and expertise in AWS cloud, data analytics, and CI/CD tools. The successful candidate will be responsible for designing and operating the data platform at Air Liquide, contributing to the development of new features, improving the platform's technical architecture, reviewing and correcting code, and ensuring data security and confidentiality. A degree in Computer Science or a related field is required, and the candidate should be proactive, a team player, and able to work in an international, matrixed environment. The position is based in Paris but may require occasional travel within France or internationally.",Bac +5 / Master,> 2000 salariés,< 6 mois,3,3,0.08309324832467525
391,34673,https://www.welcometothejungle.com/fr/companies/axionable/jobs/data-engineer-junior_paris,Data Engineer Junior,Axionable,"{GCP,durable,python,Django,Shell,HDFS,AWS,Azure,NoSQL,SQL}",Télétravail total possible,Paris,"Intelligence artificielle / Machine Learning, Environnement / Développement durable, Big Data",CDI,2022-08-08,"Axionable est le leader de l’intelligence artificielle durable en France et au Canada. Certifié B Corp et labellisé GreenTech Innovation, membre du Conseil d’Administration du collectif de référence Impact AI, Axionable s’engage dans la résolution de problématiques métiers à impact positif grâce à une IA éthique et durable. Son équipe d’experts du conseil en Data/IA et en développement durable développe une nouvelle approche business de la Data et l’IA, capable de combiner résultat économique avec impact social, sociétal et environnemental. Axionable agit notamment dans les secteurs de la banque/assurance, de l’énergie et des utilities, des transports, industrie, des médias, du luxe, du BTP, de l’immobilier, des médias et de la santé. Il accompagne ses clients de bout en bout, depuis l’audit stratégique, l’analyse et la classification des données, jusqu’au déploiement de solutions d’IA responsables. Fondé en 2016, et depuis toujours indépendant, autofinancé et rentable, il connaît depuis une forte croissance. Axionable compte 50 collaborateurs répartis entre Paris et Montréal. En tant que Data Engineer Junior (F/H), vous contribuerez à la réalisation de plateformes (Big) Data et Intelligence Artificielle (IA) permettant de répondre aux besoins métiers de nos clients. Vos missions consisteront à : Définir et mettre en œuvre des pipelines (Datalake, Datawarehouse, …) d’ingestion et de traitement de données (On-premise & Cloud) , Mettre en place et Industrialiser des solutions grâce aux outils DevOps / CloudOps (Terraform, Ansible, CI/CD, …), Contribuer à la mise en place de tableaux de bord (Power BI, Data Studio, …) Participer à la construction d’interfaces transactionnelles d’un point de vue API back-end (Django), Interagir avec nos experts data science et métiers, Participer à la veille technologique dans votre domaine d’expertise et êtes force de proposition. Le poste est à pourvoir à partir de septembre 2022 Axionable s’engage en faveur de l’égalité des chances, de la diversité et de l’équité. Nous encourageons tout·e candidat·e ayant l’expérience requise à postuler à nos offres. Bac +5, Master en Informatique ou école d’ingénieur spécialisé en système d’information et Big Data Doté·e d’ une première expérience significative sur un poste similaire (stage/alternance) Avoir une expérience mettant en jeux un middleware de stockage de la donnée tels que DatawareHouse, HDFS ou NoSQL Connaissances dans le développement avec les langages python, Shell, SQL Les connaissances sur l’un des trois principaux fournisseurs de cloud public (Azure, GCP,AWS) sont très appréciés Positif·ve et adoptant une posture en faveur de la Responsabilité Sociétale de l’Entreprise (RSE) Autonome, curieux·se et passionné·e des sujets IA et data Mobile ponctuellement pour intervenir sur les sites de nos clients Français courant, l’anglais courant est un plus 1 Entretien RH + 2 Entretiens","Axionable, the leader in sustainable Artificial Intelligence in France and Canada, seeks a Junior Data Engineer with a Master's in Computer Science or Engineering and Big Data, and a first significant experience in a similar role. The candidate should have knowledge of middleware storage such as DatawareHouse, HDFS or NoSQL, and development with Python, Shell, SQL. Experience with Cloud providers such as Azure, GCP, or AWS and proficiency in French and English are pluses. The Data Engineer will work on building pipelines, tableboards, and interfaces alongside Axionable's Data Science experts and should be responsible, independent, and passionate about data and AI topics.",N,N,N,3,3,0.08309324832467525
227,58076,https://www.welcometothejungle.com/fr/companies/sicara/jobs/data-engineer_paris,Data Engineer Junior,Sicara,"{Microsoft,Scala,AWS,Spark,Azure,Hadoop,Python}",Télétravail partiel possible,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"Sicara est une startup experte en data, basée à Paris : nous révolutionnons les projets data en combinant notre méthodologie agile de delivery de projet et notre savoir-faire en data science et data engineering afin d’aider nos clients à capitaliser sur le potentiel de la donnée. Filiale du groupe Theodo, un écosystème de 9 filiales et +400 personnes situées à Paris, Londres, New York et Casablanca, créée en novembre 2016 , Sicara est passée de 2 à 35 personnes en quatre ans. Pour soutenir notre croissance de 50%, nous cherchons à faire grandir notre portefeuille client. Régulièrement en contact avec les équipes techniques et les consultants Sicara seniors, nos AI Project Managers utilisent leurs compétences pour déployer la méthodologie projet de développement de solution en data science. Sur nos projets, tu seras amené(e) à : Analyser les données sources et échanger avec les experts métier afin d’identifier et évaluer des cas d’usage métier Travailler en équipe de 2 à 4 data engineers épaulés par un coach agile et un coach technique Mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels) sur le cloud Déployer les pipelines de données (ETL et ELT) Assurer la migration des données vers les nouveaux environnements Mettre en place des outils de contrôle de la qualité de la donnée Accompagner et former les équipes clients Au sein de Sicara, tu seras amené·e à : Contribuer à notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog. Contribuer à améliorer nos savoir-faire en expérimentant continuellement de nouvelles méthodes et de nouveaux outils afin d’améliorer l’efficacité des équipes. Diplômé(e) d’une école d’ingénieur Tu as une forte appétence pour le secteur de la data et tu as idéalement une première expérience dans le conseil ou dans la tech Tu as une expérience passée en tant que Data Engineer Tu as envie de progresser et d’évoluer dans un environnement challengeant et bienveillant au quotidien Tu as une bonne connaissance de Python et tu as déjà utilisé des technologies Big Data (Spark, Scala, Hadoop) Tu connais ou as envie d’apprendre à utiliser l’un des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure) 1 entretien RH + 2 entretiens techniques + 2 entretiens dirigeants","Sicara, a data startup based in Paris, is seeking an AI Project Manager to support its growth and work with technical teams and senior consultants to deploy the project methodology for data science solutions. The role involves analyzing data sources, working in a team of 2-4 data engineers, and implementing resilient and secure data systems on the cloud. The ideal candidate should have a strong interest in data, previous experience in consulting or tech, and be familiar with Python, Big Data technologies, and Cloud Providers. The hiring process includes an HR interview, two technical interviews, and two interviews with executives.",Bac +5 / Master,Entre 15 et 50 salariés,> 6 mois,2,3,0.06924437360389604
423,43178,https://www.welcometothejungle.com/fr/companies/axians/jobs/data-engineer-h-f-f-h_nice,DATA ENGINEER,Axians France,{NoSQL},Télétravail partiel possible,Nice,"Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Cybersécurité",CDI,2023-01-30,"Rejoignez Axians Database une société du Pôle Axians Communication & Cloud, marque de VINCI Energies dédiée aux solutions ICT. Le positionnement d'Axians offre à ses clients une large gamme d'expertises, une compétence depuis la conception de l'infrastructure avec intégration des meilleures solutions technologiques, jusqu'au support garantissant une haute disponibilité. Axians Database est une société spécialisée dans la gestion de la donnée. Implantée sur le territoire national, nos quatre métiers historiques sont le Conseil, les Services Managés, la Formation et la Gestion des Actifs. En une quinzaine d'années, Axians Database a su s'imposer comme l'un des leaders de la gestion des systèmes de bases de données en France. Nous disposons aujourd'hui d'un haut niveau de certifications et d'expertises sur les SGBD majeurs du marché. Nous sommes aujourd'hui à la veille d'une importante phase de croissance en partie liée à des sujets innovants : DevOps, Clouds publics, NoSQL et automatisation. Dans le cadre de notre développement, nous recrutons à Sophia-Antipolis ou Aix-en-Provence en CDI, un.e : DATA ENGINEER (H/F) Pour accompagner notre forte croissance nous recherchons un(e) Data Engineer. Vous serez en charge au quotidien : * D'analyser les besoins clients * D'animer des ateliers afin d'étudier et cadrer les besoins clients * De préconiser les solutions et architectures cibles * De définir les méthodologies de déploiement et les plans de migration * De rédiger les dossiers d'architecture et les spécifications techniques * De construire les architectures de données * De concevoir et mettre en place des systèmes de données résilients et sécurisés (datawarehouse, datalake, systèmes temps-réels) * De construire et déployer les pipelines de données * D'assurer la migration des données vers les nouveaux environnements * D'assurer une veille technologique continue sur les solutions cloud * D'accompagner et former les équipes clients aux méthodes et concepts du cloud Autonome sur votre poste, vous appréciez communiquer et échanger techniquement avec l'ensemble des collaborateurs. Vous travaillerez dans un souci constant d'amélioration et de modernisation de nos outils. Vous serez donc encouragé à être force de propositions. Vous êtes la personne idéale pour rejoindre notre équipe si … De formation Bac+5 en informatique, vous avez entre 0 et 2 ans d'expérience (stage ou alternance inclus) sur un poste similaire. Rigoureux et proactif, vous serez force de proposition et vous impliquerez pleinement dans les missions qui vous seront confiées. Votre envie et votre capacité à grandir techniquement, votre goût pour le partage et le travail en équipe vous poussent à aller plus loin et voir autrement. Votre futur écosystème : Une équipe dynamique composée de collaborateurs aux profils variés comprenant des jeunes professionnels et des experts confirmés. Cet environnement vous permettra de développer vos compétences au quotidien. Une entreprise vivante qui veille à l'épanouissement de ses salariés (télétravail, organisation de challenges, animations...). Envie d'un nouveau challenge, il est désormais temps de nous rejoindre !","Axians Database seeks a Data Engineer to analyze customer needs, suggest solutions and architectural designs, and create resilient and secure data systems. The ideal candidate will have a degree in computer science, 0-2 years of experience in a similar position, be proactive and rigorous, and possess a desire to learn and grow technically. Axians offers a dynamic work environment with opportunities for telecommuting and employee engagement initiatives.",Bac +5 / Master,Entre 250 et 2000 salariés,< 6 mois,2,3,0.06924437360389604
449,50017,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-analytics-all-genders_paris,Junior Data Engineer - Analytics (All Genders),Dailymotion,"{Aerospike,Docker,Beam,Kafka,Linux,Dataflow,Git,NoSQL,Bash,Kubernetes,Java,SQL,Airflow,Druid,Spark,BigQuery,GCP,GO,Python}",Télétravail partiel possible,"140, Boulevard Malesherbes, Paris, 75017","Big Data, Média, Publicité",CDI,2023-02-07,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Dailymotion is seeking a Data (Analytics) Engineer for the Analytics Engineering team. You will join the Data Engineering & Machine Learning craft. A craft consists of multiple teams of engineers and machine learning experts who collaborate daily to create and run Data products in Dailymotion. Inside this craft, the Analytics Engineering team’s mission is to provide trustworthy and available data to enable analysis & insights throughout the company (B2C, B2B products, and business teams). Analytics Engineering team builds and maintains products like our multi-petabyte data warehouse, event processors (at tens of thousands of messages per second), highly scalable client-facing analytics, data ingestion & distribution, synchronizing data across databases & systems, etc. The team is responsible for making costs-performance tradeoffs around data modeling & architecture. The team is also involved with training users of our data on SQL and analytics best practices and spearheading a significant effort around data governance. Analytics Engineering is a new and emerging space within the Data sphere. As an Analytics Engineer, you bring a software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. It requires a mix of programming skills and data skills on a day-to-day basis. If you are interested in solving challenging business problems with your skills, consider applying to this role. Your impact will be broad and across all of Dailymotion’s businesses. What you will do: Collect vast amounts of raw data from internal sources and external sources in batch and streaming modes. Expose the data through APIs, flat files, data marts, etc., for internal and external users. Design Druid datasets for external facing consumers for speed, consistency, cost, and efficiency. Write complex and optimal SQL queries to transform data in our data lake into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations through Airflow. Investigate data discrepancy, data quality issues. Debug performance issues using query plan. Design BigQuery table data model to efficiently answer business use cases considering cost and performance. Ensure data is clean, consistent, and available. Perform data quality checks, create monitors. Catalog and document the business entities, data marts, dimensions, metrics, business rules, etc. Be a knowledge guide on the various business entities, data marts. Train users of our data on SQL and analytics best practices. Come up with new tools, processes, documents and explore new tech during the cool-down periods. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Remote in France / Sophia Antipolis / Paris Type of contract: Permanent Start Date: ASAP For the France offices 🇫🇷 🏡 Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) 💰International Group Savings Plan offered through the Vivendi Group 🍼 8 weeks paid Paternity leave or Co-parental leave 🕶️ Excellent Employee Culture (Company Events / Training / Parties / All hands …) 🚀 Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review …) 🏥 Company-paid Health Insurance and Personal Services Vouchers (CESU) 🚆Commuter benefit coverage - Public Transport and Bike refund ⛱️ Paid Time off – RTT and Saving time plan (CET) ✅ Meal Vouchers 🎡Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles BS/MS in Computer Science, Engineering or related field 2+ years experience around Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. 1+ years of experience developing and debugging software in Python. Good business modeling skills: going from a stakeholder’s expressed requirements to an actual data model. Ability to work with multiple stakeholders - Product, Engineers, Analysts, Product managers, DevOps, etc. Comfortable working with Linux and the GCP stack Experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies is a plus. Experience in real-time analytics databases like Apache Druid is a plus. Familiarity with NoSQL technologies such as Aerospike is a plus. Writing and speaking proficiency in English Technologies used by the team: Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine, etc), Python, GO, Airflow, SQL, Git, Java, JSON, Bash, Docker, Druid, Kubernetes, etc","Dailymotion is looking for a Data (Analytics) Engineer to join their Analytics Engineering team. The team's mission is to provide trustworthy and available data to enable analysis and insights throughout the company. The role requires skills in Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. It also requires software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. The ideal candidate will have experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies. The role is permanent and can be remote or office-based in France.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,3,0.06924437360389604
246,37378,https://www.welcometothejungle.com/fr/companies/qotid/jobs/product-owner-data-h-f-cdi_paris,Product Owner / Data engineering  (CDI),QOTID,"{dataset,via,SQL}",Télétravail total possible,N,SaaS / Cloud Services,CDI,2022-10-18,"Bonjour à toi et bienvenue chez Qotid ! 👋 Tu souhaites embarquer dans une aventure humaine pleine de challenge ? Alors, tu es au bon endroit ! Qotid est une Fintech qui propose une solution de pilotage de la performance à destination des dirigeants de PME et directions financières (DAF, RAF, Experts comptables) qui leur permet de consolider des données de diverses sources (logiciel de ventes, logiciel comptable, etc) et de les visualiser à travers une interface de data visualisation no code pour créer des tableaux de bords sur mesure, suivre leur rentabilité et prévoir facilement leur trésorerie via la réalisation de budgets. Nous avons développé notre propre solution de business intelligence et mobilisons l’expertise de notre équipe pour perfectionner notre solution et répondre aux besoins du marché. Pour accélérer notre croissance, nous avons besoin d’un(e) vrai(e) champion(ne) comme Product Owner / Data Engineering! Tes missions principales : • Analyse des besoins du client • Modélisation de la base de donnée • Rédaction et priorisation des users stories • Gestion du backlog, suivi et animation des équipes techniques en méthode Agile • Challenger les équipes sur les fonctionnalités et le design • Phase de tests et recettes • Contrôle qualité sur la plateforme, gestion des bugs et correction en base de donnée • Preparation de dataset en vu des tests unitaires • Gestion et mise à jour des supports internes. De formation ingénieurs, commerce ou universitaire bac +5 vous justifiez d’une expérience minimum de 2 ans sur des enjeux autour de la data (collecte, modélisation, visualisation) en stage ou en CDI dans le domaine du contrôle de gestion, finance d’entreprise, gestion de projet finance. Compétences : • Tu as l’esprit startup : dynamisme, adaptabilité et bonne humeur. • Tu fais preuve d’une grande autonomie et d’une implication à toute épreuve • Tu es force de proposition et tu aimes te fixer des objectifs ambitieux. • Tu as une forte appétence pour les chiffres. Une connaissance sur les enjeux finance et comptabilité est un plus. • Vous avez de l’expérience en pilotage de projet et maitriser la méthode Agile. • Vous êtes à l’aise avec la Data et vous avez quelques connaissances en langage SQL, en gestion de base de données et sur les environnements ETL • Vous maîtrisez l’anglais oral et écrit. Une deuxième langue est un plus Le lieu de travail est à Station F mais peut également être total ou partiel Remote.","Qotid, a Fintech company, is seeking a Product Owner/Data Engineering with at least 2 years of experience in data collection, modeling, and visualization. The ideal candidate should have a startup mindset, strong analytical skills, be highly autonomous, and fluent in English. The position is located at Station F but can be partially or fully remote. Experience in Agile project management and SQL is required.",Bac +5 / Master,Entre 15 et 50 salariés,> 6 mois,3,2,0.06924437360389604
159,57149,https://www.welcometothejungle.com/fr/companies/cartelis/jobs/consultant-data-engineer-h-f-cdi_paris,Consultant Data / Analytics Engineer (junior) - Paris,Cartelis,"{Dataiku,Metabase,Airbyte,PostgreSQL,Octolis,DBT,Airflow,dbt,BigQuery,SQL,Python,Tableau}",Télétravail partiel possible,"33, Rue Stephenson, Paris, 75018","Digital Marketing / Data Marketing, IT / Digital, Big Data",CDI,2023-03-26,"Cartelis est un cabinet de conseil qui intervient sur des projets où les données clients sont au cœur des enjeux : Ingénierie data / Marketing relationnel / Analytics & BI. Sur ces projets, Cartelis intervient sur l’ensemble de la chaine de valeur, de la conception avec les équipes dirigeantes jusqu’à à leur adoption par les équipes métiers, et opère sur la transformation digitale de startups matures (Openclassrooms, Blablacar, SendinBlue, etc.) et de grands groupes (Renault, Randstad, Valeo, etc.). Fondée par une équipe d’entrepreneurs, Cartelis a vite rencontré un vrai succès du fait de la qualité de ses interventions et ses méthodologies efficaces. Cartelis fait partie des rares cabinets qui travaille aussi bien pour les meilleurs startups (BlaBlaCar, OpenClassroom, Sendinblue…) que pour des ETI et grands comptes (Randstad, Renault…). Le cabinet a pour ambition de consolider sa position de référence du conseil en data marketing. Pour porter ce projet, le cabinet s’appuie sur l’expertise d’une dizaine de consultants et vise de doubler de taille d’ici à fin 2022. Concrètement, être consultant chez Cartelis c’est : Faire du conseil dans un cabinet qui refuse d’envoyer ses consultants en régie, et qui travaille vraiment en multi-missions. Développer rapidement ses compétences business et techniques en travaillant sur des missions variées. Participer à des aventures entrepreneuriales : l’équipe Cartelis est amenée à épauler les structures historiquement lancées par le cabinet ( Salesdorado , la Fabrique du Net, Octolis…). Descriptif du poste Rôle dans l’équipe Tu prendras une place importante dans la réalisation de nos missions data ainsi qu’à la vie interne du cabinet en pleine croissance. Exemples de missions clients Ingénierie Data : création de flux de données (API, ETL…), modélisation (dbt) et création de bases de données Cloud (Snowlake, PostgreSQL, BigQuery) Data Analytics : encadrement d’une équipe d’analystes en charge de l’exploitation de données avancées (SQL, Python, Dataiku…) et de reportings automatisés (Tableau, Metabase…) Process automation : automatisation des process et des flux de données. Missions internes : selon ta charge de travail et tes envies, tu participeras à la vie du cabinet et pourras également intervenir sur nos autres activités ( Octolis , Salesdorado) sur les aspects suivants notamment : Amélioration des process internes Accompagnement aux évolutions produits Les avantages Notre ambition pour toi ? Te former pour que tu puisses devenir Head of Data d’une belle boîte tech ou devenir consultant data de haut niveau. À l’intersection du conseil digital et de l’ingénierie data, tu bénéficieras d’une double-expérience très prisée sur le marché du travail au sein d’un secteur en pleine expansion. Tu travailleras sur plusieurs clients en parallèle pour monter en compétence plus rapidement. Tu évolueras dans un environnement à la fois exigeant et bienveillant, au sein d’une équipe jeune et sympathique. Cadre de travail sur mesure : chaque membre de l’équipe adapte sa présence au bureau selon ses besoins et envies, allant du 100% présentiel dans des bureaux lumineux dédiés à l’équipe, au 100% télétravail. Cette flexibilité est permise grâce à une optimisation en continu de l’organisation interne, qui permet de faciliter les échanges, en distanciel ou non. “Le groupe vit bien” : rencontres autour de pause-déjeuner pour découvrir les restaurants alentours, bières partagées lors de l’apéro bi-mensuel, week-end de team building en dehors de Paris. Tu es issu d’une formation d’ingénieur / informatique Tu as de fortes capacités d’organisation, un sens de l’analyse aiguisé et un esprit d’initiative Tu es un excellent communicant à l’oral comme à l’écrit Tu as un bon niveau d’anglais à l’écrit et à l’oral Les univers de la data et du marketing t’intéressent Tu sais coder dans 2 de ces 3 langages JS/SQL/Python Les petits plus : tu as déjà utilisé des outils data à la mode (DBT, Airflow, Airbyte…) Les petits plus : tu maîtrises certains outils martech (CRM, marketing automation, GTM, Google Analytics…) Le precessus de recrutement se fait en 4 étapes : Remplir ce formulaire de candidature Une étude de cas data à préparer chez toi Une étude de cas d’1h type “Market sizing” sans préparation avec un consultant Un dernier entretien avec un directeur associé","Cartelis, a consulting firm specializing in data-driven projects such as data engineering, relational marketing, analytics, and BI, is seeking a consultant with coding skills in either JavaScript, SQL, or Python. The ideal candidate should have strong organizational skills, excellent communication skills, and an initiative-driven mindset. Successful applicants will have the opportunity to work on multiple client projects simultaneously and participate in the development of internal projects. The company offers a flexible working environment, with a mix of remote and in-person work options. The recruitment process includes four stages, including an at-home data case study and a one-hour exercise with a consultant.",Bac +5 / Master,< 15 salariés,> 6 mois,2,3,0.06924437360389604
254,56309,https://www.welcometothejungle.com/fr/companies/lydia/jobs/analytics-engineer_paris_LYDIA_wwlgKoV,Analytics Engineer,Lydia,"{dbt,SQL,python}",Télétravail partiel possible,"Paris, 75004","Application mobile, Banque",CDI,2023-03-26,"With over 7 million active users and an impressive 5,000 new customers joining every day, Lydia aims to become one of Europe’s leading financial services organisations. Founded in 2013, Lydia has been recognised as one of France’s most promising start-ups through its recent inclusion into the ""Next 40"" ranking. After raising €112 million from investors in 2020, we have plans to accelerate our European deployment while continuing to offer additional innovative solutions. From top-security contactless mobile payment to a wide array of app-based services, Lydia puts people at the centre of the digital banking experience. We are looking for an Analytics Engineer to join the Customer Care squad. This squad is in charge of humanizing banking digital experience and support users efficiently. You will be the data referent of this specific company vertical, responsible for everything from data ingestion to data analysis, all while improving and maintaining the Data Warehouse. To help the squad reach its goals, you will be in close contact with a diverse team of talents: mobile developpers, backend, frontend, product owner, etc… You will also have the opportunity to contribute to the Data Engineering story : A transverse team of 3 data engineers dedicated to improve our tooling, improve processes, etc. All to enable you to meet your goals. What you will do : - Proactively design and maintain a robust and product friendly data model for our Data Warehouse for each business unit with an eye towards performance and scalability. - Example Projects: Design a data model to let the marketing team and data analysts follow-up conversions in a maintainable and scalable way. - Collaborate with data engineers to design and implement state-of-the-art pipeline frameworks and apply coding guidelines and principles to ETL and ELT code. - Example Projects: Build an efficient reverse ETL task to give customer care agents access to enriched data for a personalized customer experience. - Collaborate with Product and Tech teams to ensure the data sent by apps is able to fulfill the analytical needs of each business unit. - Example Projects: Check that the data collection specifications will fit the analytical needs of the marketing team when a new product is launched. You are in the right place if : - You have a MSc in computer science or related fields from an engineering school - You have had an experience (internship or full-time) in an analytical position (data engineer, data analyst, software engineer) - You are willing to help end-users in their analytical journey - You are willing to code in python and SQL with high quality coding standards - You have between 0 and 5 years experience - You are curious and autonomous - You are fluent in English, both orally and in writing Nice to have : - knowledge of dbt - a previous experience in a customer care related field Recruitment Process : - Initial interview by phone with the Recruitment Team ; - First round of interviews at Lydia with the Vertical Lead Manager ; - Technical Case Study; - Second round of interviews with a member of our Data team. At Lydia, we believe that diversity is a strength. Diversity is part of our culture and identity. We want to create an inclusive culture where all forms of diversity are seen as a real value to the company. Lydia is therefore proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, colour, national origin, sex, sexual orientation, gender identity, gender expression, physical characteristics, age, status as an individual with a disability, or other applicable legally protected characteristics.","Lydia, a digital banking start-up in France, is seeking an Analytics Engineer to join their Customer Care squad, responsible for humanising the banking digital experience and supporting users efficiently. The successful candidate will be responsible for data ingestion, analysis, and maintaining the Data Warehouse, working closely with a diverse team of talents. Required skills include a MSc in computer science, experience in an analytical field, coding proficiency in Python and SQL, and fluency in English. Diversity is valued, and Lydia is an equal employment opportunity employer.",Non spécifié,Entre 50 et 250 salariés,< 6 mois,2,3,0.06924437360389604
416,39703,https://www.welcometothejungle.com/fr/companies/pwc/jobs/data-engineer-junior-cdi-f-h_neuilly-sur-seine,Data Engineer Junior | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",Télétravail partiel possible,"63, rue de villiers , Neuilly-Sur-Seine, 92200","Stratégie, Audit",CDI,2022-11-29,"Chez PwC, nous croisons les approches et multiplions les possibles pour inventer un monde de solutions durables. Nous associons les meilleurs talents aux dernières technologies pour aider nos clients à décupler la confiance. C'est la stratégie mondiale du réseau PwC, The New Equation. Parce que votre terrain de jeu est sans limites, nous vous offrons des missions ambitieuses, une organisation flexible, un environnement de travail unique et des opportunités de développement illimitées. En France, PwC est certifié Top Employer. Nous sommes également partenaire officiel des Jeux Olympiques et Paralympiques de Paris 2024, en accompagnant son comité d'organisation dans la tenue du plus grand événement mondial : l'opportunité de contribuer à des projets complexes et porteurs de sens. Faites partie des 8 000 nouveaux talents qui rejoindront nos équipes France et Maghreb d'ici 2025. Rejoignez vous aussi La Nouvelle Équation. PwC poursuit sa stratégie mondiale The New Equation, portée par l'humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes. Notre communauté Data et IA réunit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la chaîne de valeur, de la stratégie à l'exécution, afin d'accompagner nos clients sur l'ensemble de leurs métiers et de leurs entités, dans leur ""data transformation "". Ce que vous pouvez attendre de nous En tant que Data engineer dans les équipes Data & IA de PwC votre mission sera de: Contribuer à la définition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en étroite collaboration avec les data architects Mettre en œuvre ces solutions en mode Agile en optimisant : La performance et le passage à l'échelle La qualité des données et des modèles au fil du temps La cohérence avec les outils et les frameworks existants La qualité et conformité (revue cyber, Cloud, auditabilité des traitements, RGPD) Mise en place de CI/CD pour le déploiement des solutions chez les clients Notre boite à outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes - Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous êtes diplômé(e) ou futur(e) diplômé(e) d'une école d'ingénieur ou d'une université (type Master2..) avec une majeure en système d'information, en Data ou en Datascience. Vous êtes particulièrement intéressé par la mise en oeuvre de solutions data complète et par la gestion des flux et leur orchestration (notamment événementielle) tout cela dans des environnements cloud Vous avez pu exercer cet intérêt et vos talents dans vos expériences passées sur une ou plusieurs composantes de la chaîne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD… Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte écologique","PwC is seeking a Data Engineer to contribute to the definition and design of innovative Data Analytics and Big Data solutions in collaboration with their Data Architect team. The role involves implementing solutions in an Agile manner with a focus on scalability, data quality, and compliance while utilizing technologies such as Microsoft Azure, Google Cloud Platform, Amazon Web Services, and Python. Candidates should have experience with data pipelines, data lakes, machine learning algorithms, and APIs, and possess a global mindset to design sustainable solutions.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
451,56938,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-adtech-all-genders_paris,Junior Data Engineer - AdTech (All Genders),Dailymotion,"{Flink,Beam,Jenkins,Go,Airflow,Kubernetes,Datadog,Dataflow,Docker,Java,SQL,K8S,Python,BigQuery}",Télétravail partiel possible,"140, Boulevard Malesherbes, Paris, 75017","Big Data, Média, Publicité",CDI,2023-03-26,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Our team context: Dailymotion is seeking a Junior Data Engineer to join the Data tribe. Our tribe is responsible for all the Data products at Dailymotion; your work will have an impact throughout Dailymotion’s business and help make data-driven decisions on products and strategy. You will join a team of Data and Machine Learning engineers who have built Software that processes hundreds of terabytes of data, billions of real-time events, hundreds of tasks automated by Airflow and millions of API calls every day. Multiple machine learning projects including recommender systems, semantic annotations, spam detection, and fraud detection. What we will do together: Our stack runs almost exclusively on Google Cloud Platform. You will work in an environment made up of Data Lakes (BigQuery, etc.), data streaming platforms (Beam / Dataflow, Flink, etc.), orchestration and scheduling platforms (Airflow), container-oriented deployment, and management platforms (Docker, K8S, Jenkins), SQL. You will also participate in data modeling activities and design of data flows until their implementation and support in production. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Paris Type of contract: Permanent Start Date: ASAP For the France offices 🇫🇷 🏡 Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) 💰International Group Savings Plan offered through the Vivendi Group 🍼 8 weeks paid Paternity leave or Co-parental leave 🕶️ Excellent Employee Culture (Company Events / Training / Parties / All hands …) 🚀 Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review …) 🏥 Company-paid Health Insurance and Personal Services Vouchers (CESU) 🚆Commuter benefit coverage - Public Transport and Bike refund ⛱️ Paid Time off – RTT and Saving time plan (CET) ✅ Meal Vouchers 🎡Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles Why you are a perfect candidate for us: • You have at least 1 year accumulated experience as a Data Engineer • You are fluent in English and French • You are a team player, continually suggesting improvements and effective collaboration. • You like to implement new technologies and innovative solutions as well as the associated prototyping. • You know how to write technical specifications. • You have hands-on experience or interest in building/managing Big Data pipelines. • You will be motivated in working on building batch and streaming data streams to process a large number of events. • You have hands-on experience with different languages e.g.: Python, Go lang, Java, monitoring of development standards to ensure delivery of reusable and good quality code. • You have hands-on experience with different types of databases and SQL knowledge. • You have experience establishing and maintaining integration tests. • Experience on how to automate your deployments (Docker, Kubernetes, CI, Datadog…) • You have an entry-level knowledge on how to analyze, design, or improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes. What we offer you: • Additional opportunities as we grow and learn together. • Join our open, collaborative culture. • Exciting, dynamic projects to work on. • Flexibility to work remotely.","Dailymotion is seeking a Junior Data Engineer for their Data tribe. Candidates should have at least one year of experience as a Data Engineer, hands-on experience or interest in building and managing Big Data pipelines, and experience with different types of databases and SQL knowledge. Candidates should also be a team player and have an entry-level knowledge of analyzing, designing, or improving the efficiency, scalability, and stability of data collection, storage, and retrieval processes. The position offers opportunities for growth, dynamic projects, and flexibility to work remotely.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,3,0.06924437360389604
383,34317,https://www.welcometothejungle.com/fr/companies/bforbank/jobs/data-engineering-manager-h-f_la-defense,Data Engineering Manager,BforBank,"{Oracle,Python,GitLab,Looker,Informatica,Kafka,via,Neo4j}",Télétravail partiel possible,La Défense,Banque,CDI,2022-08-08,"Sur le modèle d'une ""Tech company"", BforBank place l'innovation et le digital au coeur de sa transformation. Notre mission, offrir à nos clients une expérience bancaire incomparable pour répondre leurs besoins et usages mobile. Rejoindre BforBank c'est rejoindre une équipe engagée dans un grand projet de développement stratégique en France et en Europe. Nous sommes aujourd'hui 280 passionné(e)s et recherchons nos talents de demain. Vous avez l'esprit d'initiative ? Vous partagez les valeurs d'engagement et de performance ? Vous êtes animé par le travail en équipe ? Ces qualités nous rassemblent, n'hésitez plus et rejoignez-nous ! Présentation du service Au sein de la direction Tech, la Data Factory a pour objectifs de piloter, définir, déployer et opérer les meilleures solutions technologiques répondant aux cas d'usage data et d'automatisations de processus de la banque au travers de plateformes. Également, la Data Factory contribue au développement des produits, à la cristallisation et à la diffusion des pratiques au sein des Squads BforBank sur les usages data. Vos missions principales sont les suivantes : En tant que Manager du pole Data Engineering, tu es le point d'entrée des directeurs métiers Produits, Expérience Client, Performance, Conformité afin de les accompagner dans leurs projets technologiques liés à la data. En tant que Manager, tu auras la charge de construire ton équipe, de l'animer et de la faire grandir. Ton équipe sera constituée d'experts Tech, de Data Engineers, d'Agile Delivery Leads, de Business Analysts IT, de testeurs Les projets sont menés soit en mode agile au sein de squads pluridisciplinaires, soit en cycle en V. Plus concrètement: Management opérationnel et hiérarchique Responsable du staffing et du capacity planning de l'équipe, Management humain des ressources de son domaine: développement des compétences, des parcours professionnels, satisfaction collaborateurs Recrutement internes, Sourcing des ressources tech intégrant des squads / projets du périmètre (en lien avec les leads chapter), Responsabilité d'un budget externe, Optimisation du dispositif pour remplir tes objectifs Delivery des projets Suivi d'un portefeuille de projets, Appui auprès des squads et projets de votre périmètre pour que le delivery soit le plus efficace possible, que la squad travaille en autonomie, et que les objectifs soient remplis, Appui à l'on boarding des nouveaux collaborateurs: poste de travail, habilitations, logistique, Facilite la planification des releases et permet l'identification des adhérences en transversalité des squads, Aide les directions Métiers à atteindre leurs objectifs de qualité Favoriser la diffusion des bonnes pratiques de delivery et de développement logiciel dans votre périmètre, S'assurer de la bonne coordination des différents intervenants des services Tech, y compris Architectes et DevOps. Transformation Tech Ambassadeur de la Tech auprès des directions Métiers et des Product Managers, vous aurez un rôle de conseil Tech sur votre périmètre, Participation active à la veille Technologique et l'acculturation DATA de l'entreprise, Contribution à la diffusion de la culture Tech dans l'entreprise, Point d'entrée du ou des directeurs Métiers pour la direction Tech pour votre périmètre, Favorise le travail en transversal au sein de la direction Tech et au-delà, Contribue aux chantiers de transformation tech, et accompagne les équipes, S'approprie les OKR et contribue via vos actions à l'atteintes de KR, Relai de la transformation des modes de travail Compétences recherchées : Ce que vous maîtrisez : Le pilotage de projets en cycle en V et en agile Le management opérationnel de profils technologiques L'architecture d'un SI Les thématiques Comptabilité Bancaire et/ou Conformité Bancaire, ou RH L'intégration de progiciels ou de solutions en mode Saas. Ce poste est fait pour vous si : Vous avez une première expérience réussie en tant que Manager IT Vous faites preuve de leadership Vous avez une bonne capacité à fédérer et à communiquer au-delà de votre équipe Vous savez travailler dans des environnements en forte transformation et aimer la conduite du changement Vous êtes autonome et rigoureux Outils informatiques : Environnement Technique : Database : Big Query, Oracle, Neo4j Pipeline/processing : Kafka, Informatica, Python Reporting : Looker, Business Objects, Linkurious Infra : Google Cloud Platform et On Premise Ops : Terraform, GitLab Ce que vous maîtrisez : Le pilotage de projets en cycle en V et en agile Le management opérationnel de profils technologiques L'architecture d'un SI Les thématiques Comptabilité Bancaire et/ou Conformité Bancaire, ou RH L'intégration de progiciels ou de solutions en mode Saas. Ce poste est fait pour vous si : Vous avez une première expérience réussie en tant que Manager IT Vous faites preuve de leadership Vous avez une bonne capacité à fédérer et à communiquer au-delà de votre équipe Vous savez travailler dans des environnements en forte transformation et aimer la conduite du changement Vous êtes autonome et rigoureux Formation: Tu es diplômé(e) d'un master en école d'ingénieur ou équivalent. Chez BforBank nous recherchons avant tout des compétences. Vous ne disposez pas du diplôme requis mais avez des expériences équivalentes ? N'hésitez pas à postuler ! Expérience : Expérience de 5 ans minimum en tant que manager d'une équipe IT data.","BforBank is seeking a Manager of Data Engineering to lead a team of experts in technology and data engineering, responsible for deploying and operating the best technological solutions to meet the bank's data usage and process automation needs. Key skills required include project management, operational management, leadership, good communication skills, and the ability to work in a rapidly changing environment. The successful candidate will have at least 5 years of experience as an IT data team manager and a master's degree in engineering or equivalent.",Bac +5 / Master,Entre 250 et 2000 salariés,< 6 mois,2,3,0.06924437360389604
193,54871,https://www.welcometothejungle.com/fr/companies/pwc/jobs/data-engineer-junior-cdi-f-h_neuilly-sur-seine_PF_ewYAaAm,Data Engineer Junior | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",Télétravail partiel possible,"63, rue de villiers , Neuilly-Sur-Seine, 92200","Stratégie, Audit",CDI,2023-03-24,"Chez PwC, nous croisons les approches et multiplions les possibles pour inventer un monde de solutions durables. Nous associons les meilleurs talents aux dernières technologies pour aider nos clients à décupler la confiance. C'est la stratégie mondiale du réseau PwC, The New Equation. Parce que votre terrain de jeu est sans limites, nous vous offrons des missions ambitieuses, une organisation flexible, un environnement de travail unique et des opportunités de développement illimitées. En France, PwC est certifié Top Employer. Nous sommes également partenaire officiel des Jeux Olympiques et Paralympiques de Paris 2024, en accompagnant son comité d'organisation dans la tenue du plus grand événement mondial : l'opportunité de contribuer à des projets complexes et porteurs de sens. Faites partie des 8 000 nouveaux talents qui rejoindront nos équipes France et Maghreb d'ici 2025. Rejoignez vous aussi La Nouvelle Équation. PwC poursuit sa stratégie mondiale The New Equation, portée par l'humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes. Notre communauté Data et IA réunit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la chaîne de valeur, de la stratégie à l'exécution, afin d'accompagner nos clients sur l'ensemble de leurs métiers et de leurs entités, dans leur ""data transformation "". Ce que vous pouvez attendre de nous En tant que Data engineer dans les équipes Data & IA de PwC votre mission sera de: Contribuer à la définition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en étroite collaboration avec les data architects Mettre en œuvre ces solutions en mode Agile en optimisant : La performance et le passage à l'échelle La qualité des données et des modèles au fil du temps La cohérence avec les outils et les frameworks existants La qualité et conformité (revue cyber, Cloud, auditabilité des traitements, RGPD) Mise en place de CI/CD pour le déploiement des solutions chez les clients Notre boite à outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes - Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous êtes diplômé(e) ou futur(e) diplômé(e) d'une école d'ingénieur ou d'une université (type Master2..) avec une majeure en système d'information, en Data ou en Datascience. Vous êtes particulièrement intéressé par la mise en oeuvre de solutions data complète et par la gestion des flux et leur orchestration (notamment événementielle) tout cela dans des environnements cloud Vous avez pu exercer cet intérêt et vos talents dans vos expériences passées sur une ou plusieurs composantes de la chaîne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD… Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte écologique","PwC is seeking a Data Engineer to join its Data & AI teams. The successful candidate will be responsible for designing and implementing innovative data analytics and big data solutions in a cloud environment, collaborating closely with data architects. The ideal candidate should have experience in various data-related components, including cloud infrastructure, data pipelines, data lakes, machine learning algorithms, and APIs, among others. Proficiency in Python, Docker, Kubernetes, Git, and cloud platforms such as Azure, AWS, or GCP is required. A degree in Computer Science or a related field is also required.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
191,49832,https://www.welcometothejungle.com/fr/companies/canopee/jobs/data-engineer-coperneec_paris,Data Engineer - COPERNEEC,Canopee Group,"{MapReduce,Tensorflow,Scala,Kafka,R,Spark,Azure,Hadoop,Python}",Télétravail total possible,"77 Boulevard Berthier, Paris, 75017","Intelligence artificielle / Machine Learning, Transformation, Finance",CDI,2023-02-07,"Coperneec est un cabinet de conseil spécialiste de la valorisation de la Data. Les expertises de nos consultants couvrent toute la chaîne des savoir-faire : Data Science, Data Analysis, Data Engineering et Data Business Analysis. Nos méthodes et techniques scientifiques éprouvées permettent de résoudre les problématiques Data dans tous les secteurs de l’industrie. Le but : extraire la connaissance à partir des données et pérenniser les avancées technologiques qui en découlent. La R&D est au cœur de notre ADN ! « From revolution to performance » avec Coperneec ! Vous êtes Data Engineer et avez un goût prononcé pour les problématiques data, l’implémentation technique de solutions innovantes et l’administration de plateformes Big Data à fortes valeurs ajoutées ? Coperneec recrute ! En nous rejoignant, vous aurez l’occasion d’intégrer des pôles de Data Engineering au sein de Directions Métier, Data Labs, ou DSI, dans un écosystème allant du secteur bancaire et financier à l’ensemble de l’industrie. Vous serez amené(e) à : Comprendre précisément les problématiques métier, ainsi que la compléxité des environnements IT associés Participer à des projets d’architecture, proposer et développer des outils “in house” offrant un accès et un traitement de la donnée optimisé Etre garant de l’implémentation des algorithmes et de leur performance Vous communiquerez vos résultats et vos solutions en les confrontant avec les équipes métier et techniques Vous évoluerez également au sein de la Practice Data Engineering, et pourrez y développer des études et travaux de recherches innovants. Vous êtes diplomé(e) d’une Ecole d’Ingénieur et/ou d’un 3ème cycle universitaire spécialisé en Data Science ou Data Engineering Vous justifiez d’une première expérience réussie en tant que Data Engineer tous secteurs Python, Hadoop, Scala, Spark, MapReduce, Kafka, Tensorflow, infrastructures Cloud Azure… Autant de termes qui n’ont plus de secret pour vous ;) Vous êtes bon(ne) communiquant(e) et n’avez pas peur d’alterner entre conseil et expertise technique Rigoureux(se) et curieux(se), vous faites preuve d’autonomie et aimez relever de nouveaux challenges scientifiques et techniques","Coperneec, a consultancy firm specializing in Data, is hiring a Data Engineer who has expertise in Python, Hadoop, Scala, Spark, MapReduce, Kafka, and infrastructures Cloud Azure. The candidate must have a degree from an engineering school or a specialized university and a successful experience as a data engineer in various sectors. The role involves understanding business issues, participating in architecture projects, proposing and developing tool solutions, ensuring algorithm implementation and performance, and communicating results and solutions to both technical and business teams. The candidate must be a good communicator, rigorous and curious, and able to switch between technical expertise and consulting.",Bac +5 / Master,Entre 50 et 250 salariés,> 6 mois,3,2,0.06924437360389604
60,63386,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-retail-bordeaux_bordeaux,Ingénieur Big Data - Retail - Bordeaux,Sopra Steria,"{Oracle,Python,omni,Nifi,Scala,Shell,Kibana,Kafka,Hive,Spark,SQL,Java,NoSQL,Hadoop,Jupyter}",Télétravail partiel possible,"20 avenue Pythagore, Bordeaux, 33700","IT / Digital, Organisation / Management",CDI,2023-03-31,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Retail » accompagne les grands acteurs de la distribution en Europe : améliorer les parcours clients omni-canaux, la performance des canaux de vente digitaux et physiques, maîtriser les opérations pour adapter les processus logistiques, proposer une offre mixant produits / services en étant innovant, tels sont nos challenges quotidiens. Notre connaissance du métier (logistique, distribution, point de vente) et notre expertise technologique nous permettent d'être un partenaire privilégié du secteur pour répondre aux nouveaux modes et usages des consommateurs. Votre futur environnement de travail : La Business Unit Retail de Bordeaux est une équipe à taille humaine qui compte plus de 80 collaborateurs passionnés intervenant sur des projets complexes, agiles, et à forte technicité. Leur objectif : accompagner les plus gros retailers et acteurs Télécom de la région dans leur projet de transformation et le déploiement de leurs outils pour leur permettre de garder une longueur d'avance et de répondre à leurs enjeux de time tomarket ! Votre rôle et vos missions : - Concevoir et développer des solutions Data/IA à des fins analytics & dashboarding - Accompagner des Métiers dans la compréhension des Analytics et la mise en oeuvre de solution ""data driven"" - Mettre en oeuvre des solutions industrielles exploitables, mesurables et opérables - Communiquer et traduire les résultats complexes et leurs implications aux parties prenantes - Capitaliser sur les solutions pour créer de nouveaux produits, de nouveaux services et de nouvelles opportunités de digitalisation, de valorisation de la donnée - Assurer un rôle de veille technologique sur tous les outils autours de la data, IA et BI. Ce que nous vous proposons : - Progresser et développer vos compétences : Avec le dispositif de Management RH, vous êtes acteur(trice) de votre carrière, vous êtes au centre du dispositif avec votre manager opérationnel et votre mentor. Avec un objectif de plus de 5j de formation/an/collaborateur, vous êtes accompagné(e) pour acquérir toutes les compétences nécessaires au bon déroulement de votre mission et votre carrière. L'Academy Sopra Steria dispense aussi bien des formations techniques, que méthodologiques ou encore de développement personnel. - Construire un avenir positif en mettant le digital au service de l'humain - Evoluer dans une entreprise qui encourage l'audace, la curiosité et l'envie d'entreprendre Les avantages à nous rejoindre : - Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. - Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement et des primes vacances. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». Votre profil : De formation Bac+ 5, vous justifiez d'une expérience en tant que Data Engineer, dans le domaine du Big Data, et vous êtes passionné(e) par les nouvelles technologies. Dynamique, curieux(se), adaptable et force de proposition, vous êtes capable et avez envie de travailler aussi bien avec des équipes techniques que des équipes métiers. Vous avez de bonnes connaissances particulièrement : - Dans l'écosystème Data et IA - Sur les technologies informatiques pour manipuler des bases de données (Oracle, posgres, NoSQL,..) et sur les framework Hadoop, Spark , Hive , Oozie , Nifi, Jupyter, Kafka - Sur les langages informatiques (SQL, Scala, Python, Java , Shell) vous permettant d'être autonome sur la manipulation des données - Sur les outils BI et data visualisation (Kibana, Qliksense, power BI ..) - En agilité et sur les outils associés (scrum, confluence, Jira, ..) Au-delà de votre expertise technique, vous avez une bonne communication orale et écrite en français et en anglais et êtes capable de vulgariser votre discours. Chez Sopra Steria, nous sommes engagés pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les différences. Tous nos postes sont ouverts aux personnes en situation de handicap. https://www.soprasteria.fr/carrieres/decouvrez-sopra-steria/nos-engagements-rse","Sopra Steria, an European Tech leader, is seeking a passionate Data Engineer with experience in Big Data and knowledge of data ecosystem, AI, Hadoop, Spark, Hive, Oozie, Nifi, Jupyter, Kafka, and SQL/Scala/Python/Java/Shell programming. The successful candidate will work collaboratively with technical and business teams to develop, communicate and implement data-driven solutions for clients in the Retail sector. Sopra Steria encourages personal and professional development, promotes an inclusive and respectful work environment, and offers a comprehensive benefits package.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
183,56774,https://www.welcometothejungle.com/fr/companies/groupe-bpce/jobs/data-engineer-h-f-nantes_nantes,Data Engineer [] - Nantes,Groupe BPCE,"{durable,DataIku,Anaconda,GIT,Jenkins,Scala,R,Hive,Spark,GCP,SQL,Hadoop,Python}",Télétravail partiel possible,"Nantes, 44200","Banque, FinTech / InsurTech, Finance",CDI,2023-03-26,"BPCE SI est une entreprise informatique du Groupe BPCE. Avec ses 19 implantations en régions, BPCE SI intervient au plus près des établissements bancaires. Chaque jour, plus de 2600 collaborateurs imaginent, inventent, testent des solutions innovantes pour faciliter la vie des utilisateurs des Caisses d'Epargne, des Banques Populaires et de plusieurs filiales et établissements bancaires comme le Crédit Coopératif et la SocFim. A travers l'utilisation de nos solutions bancaires, nous sommes présents dans le quotidien de près de 1 Français sur 2 ! Plus de 80 métiers sont présents au sein de BPCE SI et plus de 50 technologies et langages de développement sont utilisés dans nos solutions bancaires ! Entreprise humaine et engagée, notre politique de Responsabilité sociale de l'entreprise porte des sujets clés comme la mixité, la diversité, le handicap, la qualité de vie au travail et le développement durable. Nous attachons une attention particulière à la réussite de chacun(e). Nos équipes sont accompagnées tout au long de leur parcours et évoluent dans un environnement de travail stimulant pour exprimer leurs talents. Alors, pour booster votre carrière et profiter de la diversité des terrains de jeux que proposent BPCE Solutions informatiques et le Groupe BPCE, rejoignez-nous ! Poste et missions Auprès du Manager du Produit Data Services, vous intervenez dans l'équipe Lab & Services - Socle Data en tant que support dans le traitement des sujets Data, en accompagnant les Banques et les acteurs du Groupe BPCE. Sur la base des expressions de besoins auxquelles vous contribuez : Vous définissez les spécifications, concevez, développez et mettez à disposition des solutions logicielles et/ou des corrections sur un périmètre applicatif Data principalement orienté nouveaux usages (Big data Hadoop/Cloud, Power BI, Stambia, …) Vous participez à la résolution des incidents et effectuez le support utilisateurs Vous exécutez des activités de Data Analyse : Obtenir des données adéquates, trouver les sources de données pertinentes, faire des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, concevoir des datamarts, voire des entrepôts de données (data warehouses). Analyser les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement. Vous exécutez des activités de Data Ingenierie sur l'écosystème Big Data / Google Cloud Platform (GCP) servant aux cas d'usages avancés de Data Science des établissements ou Organe Central. Expert en données Big Data, le Data ingénieur réalise les composants logiciels, les teste, les assemble et les met à disposition pour mise en Production, en assure la maintenance corrective ou évolutive, s'assure de leur comportement, leur pertinence dans le temps. Il rédige et met à jour les documentations associées, Il construit les flux d'alimentation de données de la plateforme : création de Datalab, alimentation du Datalake…, Il maîtrise les processus d'ingénierie logicielle : qualité de code, disciplines de test, gestion de configuration, automatisation packaging/déploiement, Il adopte une démarche d'amélioration continue en proposant des améliorations de l'usine de développement, Il industrialise les modèles de Data Science en garantissant la pérennité, robustesse et performance des traitements en production ; en utilisant les patterns de déploiement standards, utilisé sur les plateformes concernées, Il peut assister les Data Scientist en contribution à l'analyse, la préparation des données l'exploration des solutions, Il est en support technique des établissements sur les briques applicatives de la plateforme, Il effectue les veilles techniques et technologiques qui lui permettent d'analyser, concevoir et développer les composants, et participer à la mise en place de nouvelles briques techniques, Il réalise les tests, la mise en production, la maintenance et la documentation de votre solution. Vous avez développé vos compétences sur : Développements Big Data sur écosystème GCP/Big Query, Spark/SparkML, Hive, Scala, Python, R, Anaconda/Miniconda, DataIku, ... Outils CI/CD : GIT, Bitbucket, Jenkins, XLR, XLD… Data analyse et connaissance de systèmes décisionnels : SQL, HQL, BI Au-delà de vos compétences techniques, vous êtes reconnu(e) pour votre esprit d'équipe, curiosité et autonomie. Vous avez démontré vos capacités d'analyse et de recherche sur incidents ainsi que sur la compréhension et prise en charge de problème en autonomie.","BPCE SI is seeking a Big Data Engineer who will work within the Data Services team to provide support in the handling of data issues, assist banks and other BPCE Group actors, and participate in the analysis, design, development, and deployment of software solutions relating to new uses of data. The ideal candidate will have experience with Big Data developments on the GCP ecosystem, Spark/SparkML, Hive, Scala, Python, R, Anaconda/Miniconda, DataIku, and SQL/HQL in addition to strong teamwork, curiosity, and analytical skills. The role will involve a wide range of activities, including data analysis, data engineering, and technical support.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
189,37435,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-all-genders_paris_DAILY_5PD8wr,Junior Data Engineer (All Genders),Dailymotion,"{Aerospike,Docker,Beam,Kafka,Linux,Dataflow,Git,NoSQL,Bash,Kubernetes,Java,SQL,Airflow,Druid,Spark,BigQuery,GCP,GO,Python}",Télétravail partiel possible,N,"Big Data, Média, Publicité",CDI,2022-10-18,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Dailymotion is seeking a Data (Analytics) Engineer for the Analytics Engineering team. You will join the Data Engineering & Machine Learning craft. A craft consists of multiple teams of engineers and machine learning experts who collaborate daily to create and run Data products in Dailymotion. Inside this craft, the Analytics Engineering team’s mission is to provide trustworthy and available data to enable analysis & insights throughout the company (B2C, B2B products, and business teams). Analytics Engineering team builds and maintains products like our multi-petabyte data warehouse, event processors (at tens of thousands of messages per second), highly scalable client-facing analytics, data ingestion & distribution, synchronizing data across databases & systems, etc. The team is responsible for making costs-performance tradeoffs around data modeling & architecture. The team is also involved with training users of our data on SQL and analytics best practices and spearheading a significant effort around data governance. Analytics Engineering is a new and emerging space within the Data sphere. As an Analytics Engineer, you bring a software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. It requires a mix of programming skills and data skills on a day-to-day basis. If you are interested in solving challenging business problems with your skills, consider applying to this role. Your impact will be broad and across all of Dailymotion’s businesses. What you will do: Collect vast amounts of raw data from internal sources and external sources in batch and streaming modes. Expose the data through APIs, flat files, data marts, etc., for internal and external users. Design Druid datasets for external facing consumers for speed, consistency, cost, and efficiency. Write complex and optimal SQL queries to transform data in our data lake into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations through Airflow. Investigate data discrepancy, data quality issues. Debug performance issues using query plan. Design BigQuery table data model to efficiently answer business use cases considering cost and performance. Ensure data is clean, consistent, and available. Perform data quality checks, create monitors. Catalog and document the business entities, data marts, dimensions, metrics, business rules, etc. Be a knowledge guide on the various business entities, data marts. Train users of our data on SQL and analytics best practices. Come up with new tools, processes, documents and explore new tech during the cool-down periods. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Remote in France / Sophia Antipolis / Paris Type of contract: Permanent Start Date: ASAP For the France offices 🇫🇷 🏡 Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) 💰International Group Savings Plan offered through the Vivendi Group 🍼 8 weeks paid Paternity leave or Co-parental leave 🕶️ Excellent Employee Culture (Company Events / Training / Parties / All hands …) 🚀 Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review …) 🏥 Company-paid Health Insurance and Personal Services Vouchers (CESU) 🚆Commuter benefit coverage - Public Transport and Bike refund ⛱️ Paid Time off – RTT and Saving time plan (CET) ✅ Meal Vouchers 🎡Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles BS/MS in Computer Science, Engineering or related field 2+ years experience around Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. 1+ years of experience developing and debugging software in Python. Good business modeling skills: going from a stakeholder’s expressed requirements to an actual data model. Ability to work with multiple stakeholders - Product, Engineers, Analysts, Product managers, DevOps, etc. Comfortable working with Linux and the GCP stack Experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies is a plus. Experience in real-time analytics databases like Apache Druid is a plus. Familiarity with NoSQL technologies such as Aerospike is a plus. Writing and speaking proficiency in English Technologies used by the team: Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine, etc), Python, GO, Airflow, SQL, Git, Java, JSON, Bash, Docker, Druid, Kubernetes, etc","Dailymotion is hiring a Data (Analytics) Engineer to join the Analytics Engineering team. The role involves collecting and transforming large amounts of raw data, designing Druid datasets for external consumers, writing complex SQL queries, and identifying dependencies for transformations. The ideal candidate will have experience in big data, data warehousing, complex SQL, and Python, as well as good business modeling skills and the ability to work with multiple stakeholders. Knowledge of cloud-based technologies and real-time analytics databases is a plus. The position is permanent and can be done remotely in France, Sophia Antipolis, or Paris.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,3,0.06924437360389604
20,49877,https://www.welcometothejungle.com/fr/companies/free/jobs/junior-data-engineer-h-f_paris,Junior Data Engineer  -,Free,"{git,IAM}",Télétravail partiel possible,"16 Rue de la Ville-l'Évêque, Paris, 75008",Electronique / Télécommunications,CDI,2023-02-07,"Chez Iliad-Free, nous sommes persuadés que la Diversité est une richesse ! Créé en 1999, le Groupe ILIAD est un acteur majeur des télécommunications en Europe. Opérateur innovant, inventeur de la 1ère box triple-play au monde, ILIAD est aujourd’hui présent en France, en Italie et en Pologne et compte 14 700 collaborateurs au service de 42,7 millions d’abonnés. Maison-mère de FREE, le groupe est aujourd’hui un opérateur intégré Fixe et Mobile Très Haut Débit qui se distingue par ses offres simples et accessible. Rattaché(e) au Responsable Data Engineering, vous œuvrez à la construction et à la maintenance de la plateforme data d’Iliad. En cours de construction, cette plateforme assemblera des composants open-source et des développements internes avec une haute exigence sur la solidité, la performance, l’ergonomie et la sécurité. Accompagné(e) par le management du pôle, vous participerez au développement et au support de cette plateforme ainsi que sa connexion avec le reste du SI des entités d’Iliad. Vous participerez également avec les data scientists à la réalisation de cas d’usage. Vous serez amené à travailler, selon les priorités internes, vos goût et compétences sur plusieurs de ces éléments. La plateforme comporte plusieurs éléments : Base de données Plateforme d’ETL Gestion des droits (IAM) Système de Self-service de Data Infrastructure de déploiement de Dashboard Infrastructure de déploiement de modèle (training et inférence) Analytique sur l’utilisation de la plateforme Hard-skills : Connaissance théorique et pratique du développement Un ou plusieurs langages de programmation Familier avec 3 domaines parmi 4 : ops/database/backend/frontend Pratique du développement collaboratif (git) Soft-skills : Esprit d’équipe et communication efficace avec ses pairs et ses managers Axé sur les résultats, pragmatique et agile Intéressé par l’informatique et ouvert sur les méthodes (XP, Agile, Craft…) Capable de challenger les autres et de recevoir du feedback Niveau de formation Bac+5 ou équivalent dans le domaine de l’informatique Evolution possible Data Engineer Senior Data Engineer Lead Data Engineer Principal Data Engineer","Iliad-Free seeks a Data Engineer to build and maintain their data platform using open-source components and internal developments. The platform includes a database, ETL platform, IAM, self-service data system, dashboard deployment infrastructure, model deployment infrastructure, and analytics. The ideal candidate should have theoretical and practical knowledge of development, familiarity with multiple programming languages and domains (ops/database/backend/frontend), practice of collaborative development (git), effective communication and teamwork skills, and an interest in IT and Agile methodologies. A Bac+5 degree in computer science or equivalent is preferred, and the position offers growth opportunities up to Principal Data Engineer.",> Bac +5 / Doctorat,Entre 50 et 250 salariés,Non spécifié,2,3,0.06924437360389604
187,37291,https://www.welcometothejungle.com/fr/companies/ekimetrics/jobs/data-engineer-junior-h-f-n-paris_paris,Junior Consultant Data Engineer  /N),Ekimetrics,{R},Télétravail partiel possible,N,"IT / Digital, Stratégie, Audit, Big Data",CDI,2022-10-18,"Ekimetrics est leader européen en data science avec +320 data scientists et +1000 projets depuis 2006. Présents à Paris, Londres, NY et HK, ils menent des projets dans +50 pays et pour tous les secteurs d’activité : services financiers, Retail, Telecom, Santé, etc. Leur mission est d’aider les entreprises à auditer leurs opportunités data, enrichir leur capital analytique, et déployer des solutions actionnables permettant de maximiser leur performance marketing et opérationnelle, et ré-énergiser les business models. Leur focus absolu est de délivrer des gains à court terme, tout en garantissant le développement du capital data de nos clients à long terme. Ils s’engagent à proposer les approches data science les plus avancées, et à construire des pratiques AI éthiques et durables. Quelques chiffres clés : 16 années d’expérience en Data Science +320 data scientists 4 bureaux à Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit généré pour nos clients depuis 2006 +1000 projets Data Science Ekimetrics est leader européen en data science avec + 320 data scientists et +1000 projets depuis 2006. Présents à Paris, Londres, NY et HK, nous menons des projets dans +50 pays et pour tous les secteurs d’activité : services financiers, Retail, Telecom, Santé, etc. Notre mission est d’aider les entreprises à auditer leurs opportunités data , enrichir leur capital analytique , et déployer des solutions actionnables permettant de maximiser leur performance marketing et opérationnelle , et ré-énergiser les business models . Notre focus absolu est de délivrer des gains à court terme, tout en garantissant le développement du capital data de nos clients à long terme. Nous nous engageons à proposer les approches data science les plus avancées, et à construire des pratiques AI éthiques et durables. Quelques chiffres clés : 16 années d’expérience en Data Science +320 data scientists, tous consultants 4 bureaux à Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit généré pour nos clients depuis 2006 +1000 projets Data Science Forts de notre expertise en Data Engineering, nous accompagnons nos clients dans leur Transformation Data afin qu'ils puissent mener à bien des initiatives ambitieuses orientées vers la donnée. Nous conseillons nos clients dans le choix de la technologie la plus appropriée ainsi qu'à la mise en place d' Architectures Data robustes et évolutives. Notre mission est aussi d'accompagner des projets en Business Intelligence & en industrialisation d'algorithmes. Découvrez nos derniers projets en Data Engineering : * Pour un opticien, accompagnement dans le design et le déploiement d’une architecture data lake et dans la construction d’un modèle de données business constituant le référentiel d’entreprise (MDM). * Pour un acteur du tourisme, identification des uses cases pertinents et construction d’une road map data stratégique sur 3 ans pour le comité de direction. * Enfin pour un acteur de l’agroalimentaire, mise en place le master data management : architecture, structuration de la plateforme, et intégration cloud. Vos missions : * Concevoir et développer des chaînes complexes * Implémenter et industrialiser des algorithmes dans un environnement Big Data * Développer des outils destinés à faciliter l’accès aux pipelines de données * Approfondir vos connaissances en Machine Learning * Participer aux activités de R&D (Veille, formations, animation de Meetups, Hackathons, etc.) Profil recherché : * Bac+ 5 Ecole d'ingénieur ou Équivalent * Première expérience sur des sujets Big Data (Projet ou expérience professionnelle) * Expérience dans l’industrialisation d’algorithmes * Expérience dans un environnement Cloud * Connaissances avancées en acquisition de données * Appétence pour la Data Science. Ce que nous offrons : Ekimetrics est pour la première année certifié Great Place to Work *Un package attractif fixe + variable individuel + intéressement + prise en charge de votre pass Navigo à 50% ou indemnité vélo + une carte ticket restaurant Edenred + une excellente couverture mutuelle Alan et une politique de télétravail flexible *Un environnement de travail inspirant : des bureaux en plein cœur de Paris sur les Champs-Elysées avec des expositions d’œuvres d’art régulières sur nos murs * Des formations variées adaptées à tous les niveaux pour rester à la pointe de votre expertise * Des parcours de carrières adaptés à chacun avec des possibilités de mobilités à l’international * La possibilité de participer à des conférences sur des sujets data * Des équipes de sport & des cours de gym (Crossfit, Yoga, Boxing, Football, Basketball) En tant qu’employeur, Ekimetrics offre à tous les mêmes opportunités d’accès à l’emploi sans distinction de genre, ethnicité, religion, orientation sexuelle, statut social, handicap et d’âge. Ekimetrics veille à développer un environnement de travail inclusif qui reflète la diversité dans ses équipes.","Ekimetrics, the European leader in data science, is seeking a Data Engineer to design and develop complex chains, implement and industrialize algorithms in a big data environment, develop tools to facilitate access to data pipelines and participate in R&D activities. The ideal candidate will have a degree in engineering, experience in big data projects, knowledge of data acquisition, and a strong interest in data science. Ekimetrics offers an attractive package including an excellent fixed salary, flexible remote work, and career development opportunities, among others. The company is committed to diversity and inclusivity in the workplace.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,3,0.06924437360389604
215,65923,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-gdo-bi-data-engineer-h-f_paris,ALIT GDO - BI Data Engineer,Air Liquide,"{Azure,durable,Dax,SQL}",Télétravail partiel possible,"Paris, 74000","Environnement / Développement durable, Santé, Energie, Digital",CDI,2023-04-05,"Air Liquide est un leader mondial des gaz, technologies et services pour l'industrie et la santé. Présent dans 75 pays avec 66 400 collaborateurs, le Groupe sert plus de 3,8 millions de clients et de patients. Oxygène, azote et hydrogène sont des petites molécules essentielles à la vie, la matière et l'énergie. Elles incarnent le territoire scientifique d'Air Liquide et sont au cœur du métier du Groupe depuis sa création en 1902. Air Liquide a pour ambition d'être un leader de son industrie, d'être performant sur le long terme et de contribuer à un monde plus durable - avec au cœur de sa stratégie, un engagement marqué en faveur du climat et de la transition énergétique. Air Liquide est de longue date sensibilisée à la diversité et à l'égalité professionnelle, et poursuit son engagement pour l'emploi des personnes en situation de handicap. Air Liquide a entamé avec succès sa transformation Digitale et IT , centrée sur l'expérience client et l'amélioration de de la profitabilité des opérations, deux piliers majeurs de notre programme NEOS. Cette transformation impacte notre façon de réaliser, gérer et monitorer nos opérations. Elle implique aussi la définition de nouveaux modes de collaborations, la création de nouvelles compétences et de nouveaux postes. Aujourd'hui, le département Digital & IT poursuit cette transformation tant au niveau de l'infrastructure (GIO), des plateformes data (GDO), que des applications métiers (DSI ou BIS) et des dispositifs créés autour de l'innovation, des méthodes d'innovation et de la data (Fabs et Factory). Le département Global Data Operations (GDO) a été créé dans l'entité Air Liquide IT pour supporter les ambitions du Groupe en matière de gestion des données, apporter l'expertise technologique pour le développement de nouvelles solutions différenciantes pour le business Air Liquide, avec un focus particulier sur les sujets autour de la data dans un premier temps. GDO dans sa phase initiale opère trois plateformes : Business Intelligence, Data Lake et API. Au sein de GDO, et rapportant au Technical Lead BI Group le ou la BI Data Engineer défini la roadmap technique pour la Product Line en cohérence avec la stratégie et les besoins exprimés par le Solution Owner et le Product Line manager. Il ou elle est intégré.e sur les projets structurants et travaille en coordination avec les product managers et le métier afin de s'assurer de la bonne réponse technologique face aux besoins exprimés. En tant que BI Data Engineer vous aurez les responsabilités suivantes : Concevoir, développer, tester et mettre en production des traitements de données dans différents contextes métier et applicatifs Concevoir, mettre en oeuvre et optimiser, avec les data architects et devops, les pipelines de traitement de la donnée permettant l'alimentation des applications data depuis les sources de données du Groupe Assurer le support des traitements de données mis en oeuvre Contribuer à la définition des processus, standards et méthodes techniques permettant d'assurer un haut niveau de qualité de service et de livrables Réaliser et participer avec l'équipe à la veille technologique/l'état de l'art des technologies utilisées et être force de proposition Respecter les règles de sécurité et de confidentialité du Groupe au sein de la plateforme, et des traitements de données (security by design, privacy by design) Compétences techniques Expérience minimum de 3-5 ans dans le design et l'implémentation de solution Azure BI de grande envergure Certification sur les produits Data Azure nécessaires AZ-900, DP-203 ) Excellente maîtrise SQL & Dax / Azure Data Factory / Azure Analysis services Connaissance des méthodologies de développement Compétences non techniques Faire preuve d'autonomie, d'esprit d'initiative et de motivation Expérience passée de larges projets de BI en connexion directe avec le métier Capacité à travailler dans un environnement matriciel international (BIS, GIO, Fabs Digitales, IT industriel, entités business) Esprit critique, analyse et résolution des problèmes Capacités de communication écrites et orales, en particulier pour vulgariser les sujets techniques L'anglais et le français lus, écrits et parlés sont indispensables. Localisation géographique : France / Ile de France / Paris - Le poste est basé à Paris XIe sur le Campus de La Digital Factory. Catégorie professionnelle : Ingénieurs et Cadres Des déplacements occasionnels pourront être nécessaires en France ou à l'étranger. Astreintes à prévoir Télétravail 3jrs/semaine","Air Liquide seeks a BI Data Engineer with at least 3-5 years of experience in Azure BI solution design and implementation. The role involves designing, developing, testing, and implementing data processing in various business contexts and applications. The successful candidate must have excellent SQL and Dax / Azure Data Factory / Azure Analysis services skills, be able to work independently, and communicate effectively in English and French, among other qualifications. The job is based in Paris, France, and may require occasional travel.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
453,56847,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/gdo-data-engineer-h-f-self-service-data-initiatives_paris,GDO - DATA ENGINEER  - SELF SERVICE DATA INITIATIVES,Air Liquide,"{durable,git,Tensorflow,Athena,pandas,GitLab,bash,IAM,Glue,AWS,S3,linux,via,moderne,Sagemaker,SQL,Python,numpy}",Télétravail partiel possible,"Paris, 74000","Environnement / Développement durable, Santé, Energie, Digital",CDI,2023-03-26,"Air Liquide est un leader mondial des gaz, technologies et services pour l’industrie et la santé . Oxygène, azote et hydrogène sont des petites molécules essentielles à la vie, la matière et l’énergie. Grâce à l’engagement et l’inventivité de ses collaborateurs pour répondre aux enjeux de la transition énergétique et environnementale, de la santé et de la transformation numérique , Air Liquide crée encore plus de valeur pour l’ensemble de ses parties prenantes. La diversité et l’inclusion du handicap au sein de notre organisation nous permet de répondre au mieux aux défis complexes des marchés que nous servons, de stimuler l’innovation et de contribuer à créer de la valeur pour nos clients, nos partenaires et la société en général. Notre méthode de gestion des talents – de l’embauche au développement de leur carrière – sont le reflet de notre engagement en faveur de la diversité et de l’inclusion du handicap . La conjugaison de ces éléments et de la grande part d’intrapreneuriat au sein d’équipes à taille humaine nous permet de relever des challenges ambitieux. Au sein de la division Innovation et Développement, le département Global Data Operations (GDO) accompagne nos ambitions de stratégie et de gouvernance, en apportant l'expertise et les plateformes technologiques Data & IA nécessaires au développement de solutions différenciantes pour les métiers d'Air Liquide. Au sein de GDO, la Product Line Data Lake & AI a pour mission d'accompagner la stratégie de déploiement à l'échelle d'Air Liquide : i) disponibilité des données pour les géographies du groupe, ii) diversification des cas d'usages pour les domaines métiers (BI, Data Science, Digital), iii) passage à l'échelle de l'IA Data du groupe. L'équipe travaille en méthodologie agile et s'appuie sur une plateforme moderne pour alimenter les cas d'usage métier dans différents hubs géographiques ( Amérique, Asie, Europe et Afrique). Le programme AI Readiness a pour objectif de faire monter les utilisateurs data du groupe Air Liquide en compétences Data & IA d'ici à 2025. Ce programme inclut des initiatives permettant de rendre nos données plus accessibles et fiables à un nombre grandissant de Data Users au sein du Groupe afin de permettre aux Opérations de prendre les meilleures décisions, de créer des produits porteurs d'avantage compétitif, tout en tenant compte des enjeux de développement durable (optimisation, performance énergétique, stockage de l'énergie via le développement de la filière hydrogène, …). Dans ce cadre, la GDO Data Suite est la solution Air Liquide d'exposition et mise à disposition des données des différents Data Lakes, permettant aux consommateurs de découvrir et d'utiliser cette donnée aux travers de notebooks en Python ou SQL worksheets. Missions Au sein de GDO, l'équipe User Service GDO Data Suite a pour mission d'assurer l'adoption et le bon accompagnement des utilisateurs des offres self service Data proposées par GDO : Data Studio, Data Portal entre autres. La personne spécifiquement en charge du support utilisateur sera amenée à collaborer avec des Data Analysts, Data Scientists, Data Engineers et Machine Learning Engineers dans le cadre du programme AI Readiness qui vise à déployer les compétences et les outils d'IA au sein du groupe Air Liquide. Ambassadeur Data Suite, le/la Data Engineer fera partie intégrante de la User Service team , point d'entrée des utilisateurs pour la prise en main et accompagnement sur les produits Data Studio et Data Portal . Pour promouvoir l'adoption et la rétention des utilisateurs, il/elle devra notamment: Collaborer avec les Data users du groupe, de la création de leur projet data sur Data Portal au développement de celle-ci sur Data Studio. Accompagner les utilisateurs finaux dans la prise en main de ces outils et services, au travers de coaching, partage de connaissances, voire de formation pour leur permettre de développer en continu leurs compétences de programmation. Capitaliser sur ces collaborations pour faire évoluer les produits en collaboration avec les équipes Data Studio et Data Portal, en anticipant et remontant les besoins utilisateurs. Définir et promouvoir les bonnes pratiques d'usage et de développement auprès des Data users, en mettant en place ou en consolidant des méthodes et des bonnes pratiques. Animer la communauté des data users à travers des communications, compagnes de feedback pour mesurer la satisfaction etc. Définir et mettre en place des KPI pour suivre l'adoption et l'usage des produits. Education et Expérience A partir de Bac+5, Formation Ingénieur(e) en Sciences Informatiques, avec une forte orientation data. Compétences techniques De bonnes connaissances en développement Python avec une maîtrise de librairies de Machine Learning (numpy, pandas, scikit-learn, Tensorflow, etc.) Technologies cloud: AWS (Sagemaker, CloudWatch, S3, IAM, Athena, Glue, Lake Formation, Fargate, RDS, CLoudFormation ) Système : OS linux, bash. Maîtrise de git, GitLab Maîtrise de l'apprentissage statistique et en Machine/Deep Learning (apprentissage supervisé, non supervisé, etc.) Seraient un plus: Des notions en gestion de données : collecte, analyse, distribution, etc. Des notions d'Intégration Continue / Déploiement Continue (CI/CD) Maîtrise des best practices en matière de code Quelques connaissances en Infrastructure as Code (IaC): Cloudformation, Terraform Compétences non techniques Un esprit curieux et d'initiative. Un sens utilisateur pour délivrer un service efficace Capacité à travailler dans un environnement international Excellentes capacités de communication écrites et orales, en particulier pour vulgariser les sujets techniques. Capacité d'analyse et de synthèse avec un esprit critique. L'anglais et le français courants à l'écrit comme à l'oral sont indispensables. Horaires et lieux de travail Le poste est basé à Paris XIe sur le Campus de La Digital Factory. Des déplacements occasionnels pourront être nécessaires en France ou à l'étranger. Manager : Data Platform Product Manager Ce que nous offrons L'utilisation des dernières technologies et la possibilité de travailler avec des experts techniques très reconnus dans leur domaine La possibilité d'apprendre et de monter en compétences en continu dans une équipe récente, agile et en croissance Des perspectives d'évolution au sein du groupe grâce à notre politique de mobilité interne Un cadre de travail stimulant et multiculturel au cœur de Paris, avec un accord télétravail en place (3 jours par semaine de télétravail) De nombreux avantages : Participation/Intéressement, prime vacances, carte tickets restaurants, CE, 152€/mois de CESU pour les personnes ayant à charge un ou plusieurs enfant(s) de 3 ans ou moins …","The Global Data Operations (GDO) department at Air Liquide is seeking a Data Engineer with strong Python development skills and expertise in machine learning libraries, cloud technologies (especially AWS), and Linux operating systems to ensure adoption and support of self-service data products like Data Studio and Data Portal. The successful candidate will be part of the User Service team responsible for coaching, training, and promoting good practices among data users in collaboration with other data scientists, data engineers, and machine learning engineers at Air Liquide. The Data Engineer will also contribute to the AI Readiness program aimed at upskilling data users across Air Liquide and support the development of differentiated solutions for Air Liquide's businesses worldwide. The Data Engineer will be based in the Digital Factory campus in Paris and may need to travel occasionally both in France and abroad.",Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.06924437360389604
133,37393,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/junior-data-engineer-m-f_gentilly,Accelerator - Junior Data Engineer,Sanofi,"{GCP,Splunk,Gitlab,Tibco,GitHub,PowerBI,AWS,Snowflake,Shell,scale,R,Airflow,Kedro,Azure,Github,SQL,Python,Tableau}",Télétravail partiel possible,N,Pharmaceutique / Biotechnologique,CDI,2022-10-18,"At Sanofi, we pursue the miracles of science to improve people’s lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi’s roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Le contenu du poste est libellé en anglais car il nécessite de nombreuses interactions avec nos filiales à l'international, l'anglais étant la langue de travail. CONTEXT Who we are in a nutshell We are a global biopharmaceutical company focused on human health. Our purpose is to find treatment to fight pain and ease suffering. We combine breakthrough science and advanced technology to develop life-changing medicines and vaccines. Digital & Data is at the heart of Sanofi: our ambition is to be the leading digital healthcare platform to develop & deliver medicine faster, enable healthcare professionals to improve treatments and help patients improve their health. Our scale, strong connections within health ecosystems across leveraging the world, and ability to leverage Sanofi’s capabilities make us the best place to push the boundaries of medicine through technology. Why joining Sanofi Digital Executive sponsorship and governance, with newly appointed CDO & leadership team Digital & data culture in place with agile ways of working and a strong ecosystem (Sanofi Ventures, BD Partnerships) Unique diversity of medical & technical challenges, with mobility opportunities Awarded “Top Employers France” 2021 And more specifically, why “Accelerator powered by Sanofi” A new entity launched March 1st to Become the leading Digital Health platform A separate location, in WeWork (Paris 75017), 5 minutes walk away from the future Sanofi HQ location Startup-like streamlined processes to ensure delivery speed Focused on end-to-end building the most transformative and profitable products The products you will work on We are building next-gen health & digital products, Data Analytics and Artificial Intelligence, including Digital Health products improving the patient experience and treatment adherence, through innovative digital products (Software as Medical Devices) Connected ecosystem solutions such as patients’ glycemic control & full disease management, leveraging connected pens Symptoms checking apps able to understand disease and track symptoms Remote treatment solutions providing individual recommendations, accessible by anyone, anytime, anywhere Personalized care model informed by AI to identify symptoms’ early signals and recommend corrective actions to the patient and the care giver Omnichannel products supporting multi-channel engagement with healthcare providers & patients Multi-channel digital targeting platform to deliver tailored digital campaigns Machine learning and predictive analytics to improve engagement (calls, chats) based on feedback Recommendation engines for cross selling/up-selling and next-best action delivery to sales reps Tailored content delivery based on preference and viewing history Digital Marketing products optimizing marketing campaign’s reach and impact Market analytics tools to understand key dynamics across categories and identify growth/uplift potential Strategic allocation tools, able to dynamically model impact of different scenarios and achieve sales targets Tactical allocation tools, with built-in ROI response modelling, at “brand x touchpoint level” JOB PURPOSE You as a Data Engineer You are a dynamic Data Engineer interested in challenging the status quo to ensure the seamless creation and operation of the data pipelines that are needed for the enterprise data and analytics initiatives following industry standard practices and tools for the betterment of our global patients and customers. You are a valued influencer and leader who has contributed to making key datasets available to data scientists, analysts, and consumers throughout the enterprise to meet vital business use needs. You have a keen eye for improvement opportunities while continuing to fully comply with all data quality, security, and governance standards. Your key responsibilities will be Work with business teams to understand requirements, and translate them into technical needs Gather/organize large & complex data assets, and perform relevant analysis Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business case Create data models and optimize queries performance Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new “standard data pipelines” within Sanofi to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community Remains up to date on company’s standards, industry practices and emerging technologies PROFILE Key Technical Requirements & Qualifications Experience with AWS cloud services (Azure & GCP a plus) Good knowledge of SQL and relational databases technologies/concepts Experience working with data models and query tuning Experience in Data warehousing solutions (Snowflake a plus) Experience in Integration Services (IICS, Tibco a plus) Working knowledge of scripting languages (Python, R a plus) Familiarity with Source Code Management Tools (GitHub a plus) Familiarity with Visualization Tools (PowerBI, Tableau a plus) Familiarity with Project Management Tools (JIRA, Confluence a plus) Familiarity with Service Management Tools (Service Now a plus) Experience working in life sciences/pharmaceutical industry is a plus Relevant cloud certifications (AWS, Azure, Snowflake, IICS) are a plus Experience on working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements is a plus Additional qualifications Strong experience in automation tools and methodologies specifically using Gitlab, Github action, Terraform, Ansible Experience with programming languages such as JSON, YAML, Shell Scripting. Experience with backup system like Netbackup & CommVault Good knowledge of ServiceNow and monitoring tool such as Splunk, BPPM Experience with Real World Data (e,g, EHR, Claims) and standard data models (e,g, OMOP, FHIR) Experience using frameworks to create pipelines (e.g. Apache Airflow, Kedro) Soft and behavioral skills Excellent written and verbal communication skills Experience working with multiple teams to drive alignment and results Service-oriented, flexible, positive team player Self-motivated, takes initiative Problem solving & critical thinking Your background 1-3 years of experience in a data team as Data Engineer Bachelor’s Degree or equivalent in Computer Science, Engineering, or relevant field Experience in the healthcare industry is a strong plus #Accelerator At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.","Sanofi, a global biopharmaceutical company focused on human health, is seeking a dynamic Data Engineer to contribute to seamless creation and operation of data pipelines, ensuring compliance with standards for data quality, security, and governance. The candidate should have experience with AWS cloud services, SQL and relational databases, data warehousing solutions, integration services, and scripting languages. Knowledge of Source Code Management Tools, Visualization Tools, Project Management Tools, and Service Management Tools would be an added advantage. The ideal candidate should have excellent verbal and written communication skills, be service-oriented, flexible, a positive team player, and possess good problem-solving skills with a critical thinking approach. The position requires 1-3 years of experience as a data engineer with a Bachelor's Degree in Computer Science, Engineering, or a relevant field.",Non spécifié,N,Non spécifié,2,3,0.06924437360389604
373,57160,https://www.welcometothejungle.com/fr/companies/lita-co/jobs/data-engineer-analyse-esg_paris,Data Engineer/ Analyse ESG - RIFT (CDI),LITA.co,"{MySQL,via,Python}",Télétravail total possible,"24, Rue du Rhin, Paris, 75019","FinTech / InsurTech, Finance",CDI,2023-03-26,"LITA.co est née d’une volonté de répondre à 2 enjeux majeurs : le fort besoin de financement des entreprises à impact social et environnemental positif, et le manque de transparence et de sens des investissements qui sont proposés au grand public. Acteur majeur de l’économie sociale et solidaire, en lien étroit avec le MIF (Mouvement Impact France) agrée ESUS (Entreprise solidaire d’utilité sociale) et certifée B Corp, LITA.co est aujourd’hui le leader européen de l’investissement en ligne dédié à l’impact positif. Pour aller plus loin, LITA.co a développé l’application “RIFT”, permettant de scanner son épargne pour lever le voile d’opacité sur l’impact de nos produits d’épargne (assurance vie, épargne bancaire). Une volonté de transparence qui se concrétise par une analyse personnalisée via des indicateurs aussi concrets qu’innovants. 🤔 Pourquoi nous recrutons sur ce poste ? En tant que Data Engineer, tu auras la charge de développer la base de données, colonne vertébrale de l’application RIFT ( https://riftapp.fr/ ) Tu sera responsable de la structuration, de l’intégration et de la mise à jour des données de mesure d’impact et des données financières, afin d’apporter plus de transparence aux utilisateurs sur la façon dont leur épargne est investie. Au sein d’une équipe de 4 personnes (le directeur, 2 développeurs, 1 chargé de communication), tes principales missions seront : La restructuration du serveur de calcul RIFT et son intégration dans l’écosystème logiciel La mise en place de processus de scraping de données publiques (données extra-financières, composition des portefeuilles, controverse) La participation à l’amélioration des méthodologies de mesure d’impact sur la base des jeux de données les plus aboutis du marché (empreinte carbone, impact biodiversité, indicateurs sociaux) Profil recherché Nous recherchons un profil : Ingénieur avec au minimum 2 ans d’expérience sur un poste similaire, Ayant une grande aisance dans le traitement de données, Maitrisant Python et MySQL (indispensable pour le poste), Ayant de grandes capacités d’apprentissage et d’autonomie sur l’ensemble de l’environnement de développement, Réactif.ve, rigoureux.se, avec l’esprit d’équipe. Le plus ? Un profil ayant des connaissances financières basiques et un intérêt pour la finance à impact. 1 entretien avec Sixtine, Chargée RH 1 entretien avec Léo, Directeur de RIFT 1 entretien avec Eva Sadoun, Présidente de RIFT","LITA.co, a major actor in the social and solidarity economy in France, is seeking a Data Engineer to develop the database structure of its application RIFT, which aims to provide transparency on the impact of investment products. The ideal candidate should have at least two years of experience, be proficient in Python and MySQL, and have a strong ability to learn and work independently. A basic knowledge of finance and an interest in impact investing would be a plus.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
282,56607,https://www.welcometothejungle.com/fr/companies/eldo/jobs/data-engineer-f-h_toulouse_ELDO_r9gzY5G,Data Engineer,Eldo,"{MySQL,Talend,PostgreSQL,Airflow,AWS,via}",Télétravail total possible,"Lab'Oïkos Saint Aubin, Toulouse, 31000","SaaS / Cloud Services, Bâtiment / Travaux publics, Digital",CDI,2023-03-26,"Eldo, c’est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s’améliorer au quotidien pour développer leur activité 🚀💚 À propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l’amélioration de l’habitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la première plateforme européenne de solutions digitales à destination des professionnels, marques et consommateurs du secteur de l’amélioration de l’habitat. Nous sommes une équipe de passionnés qui souhaitent révolutionner le secteur de l’amélioration de l’habitat (76 milliards d’€). Avec notre suite SaaS nous accompagnons les pros et marques du secteur à développer leur activité en optimisant chaque étape du cycle de vente avec leurs clients. Du moment où ils les trouvent sur le web, jusqu’à leur satisfaction à la fin des travaux. Sur notre site B2C, nous aidons les particuliers à trouver des pros de confiance grâce aux avis et photos de leurs voisins, pour réaliser les travaux de leurs rêves. Nous avons un positionnement et un service unique avec : 💻📲 une suite applicative SaaS, développée avec et pour les pros et marques du bâtiment 📷💬 + 100 000 avis accompagnés de photos, vidéos ; 👨‍🔧 des milliers d’entreprises référencées avec un taux de renouvellement/satisfaction de 90%. 🏡💰 un partenariat avec Google et une certification AFNOR Lauréats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs à succès comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d’ici 2030 la première plateforme mondiale de solutions digitales à destination des professionnels de l’amélioration de l’habitat. Eldo, c’est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s’améliorer au quotidien pour développer leur activité 🚀💚 À propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l’amélioration de l’habitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la première plateforme européenne de solutions digitales à destination des professionnels, marques et consommateurs du secteur de l’amélioration de l’habitat. Nous sommes une équipe de passionnés qui souhaitent révolutionner le secteur de l’amélioration de l’habitat (76 milliards d’€). Avec notre suite SaaS nous accompagnons les pros et marques du secteur à développer leur activité en optimisant chaque étape du cycle de vente avec leurs clients. Du moment où ils les trouvent sur le web, jusqu’à leur satisfaction à la fin des travaux. Sur notre site B2C, nous aidons les particuliers à trouver des pros de confiance grâce aux avis et photos de leurs voisins, pour réaliser les travaux de leurs rêves. Nous avons un positionnement et un service unique avec : 💻📲 une suite applicative SaaS, développée avec et pour les pros et marques du bâtiment 📷💬 + 100 000 avis accompagnés de photos, vidéos ; 👨‍🔧 des milliers d'entreprises référencées avec un taux de renouvellement/satisfaction de 90%. 🏡💰 un partenariat avec Google et une certification AFNOR encore renouvelée cette année ! (processus de collecte, modération et restitution des avis) Lauréats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs à succès comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d’ici 2030 la première plateforme mondiale de solutions digitales à destination des professionnels de l’amélioration de l’habitat. Descriptif du poste Chez Eldo notre Dream Team s’agrandit ! 👩‍🚀 Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer. Si tu aimes la donnée et que les statistiques n’ont aucun secret pour toi… alors Alessandro et la team n’attendent que toi ! Regarde par la fenêtre de l’équipe Product Engineering ! 👁 La Team Product Engineering, c’est plus d'une dizaine de collaborateurs passionnés et ambitieux accompagnés par nos équipes marketing, sales, grands comptes…! Ton rôle chez Eldo Tu travailleras quotidiennement à l’ amélioration de nos applications (modifications de l’actuel et création) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualité et granularité de cette dernière, le tout, en étant un support pour les équipes en interne. Pour la partie “Engineer”, tu seras attendu sur la scalabilité de la partie Data, la mise en place d’architecture dédiée, la gestion de la sécurité de la data, la connexion entre l’architecture data et la partie applicative et développement produit. Pour la partie “Analyste” , tu seras en charge de recueillir les données internes (bases de données, fichiers…) et externes (HubSpot, Google Analytics, Partoo…), puis de les centraliser au sein d’un datawarehouse pour ensuite permettre leur restitution via un outil dédié à la Business Intelligence (tu seras force de proposition sur les outils à utiliser). Tu devras bien évidemment documenter et spécifier les éléments de services ou modèles développés, ainsi que maintenir une veille active sur les services utilisés et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus adéquates solutions. Ayant un rôle fortement orienté et drivé par l’Impact business et utilisateur, tu seras naturellement au sein de l’équipe Produit, composée de Product Manager, Product Designer. Tes échanges quotidiens seront bien évidemment avec cette équipe, mais pas que. Les développeurs et toutes les autres équipes seront pour toi des stakeholders privilégiés afin de répondre au mieux au besoin de la stratégie Produit et Entreprise. Les équipes Product Engineering (PE) travaillent en utilisant la méthodologie Agile. Ton environnement de travail sera le suivant: MySQL, PostgreSQL ETL/ELT, Jobs Talend orchestrés par Airflow, Hevo data pour la partie no code. APIs d’outils externes à une entreprise (ex : Google Analytics, HubSpot…). Outils de reporting/dashboarding (Amazon QuickSight°. Toucan Toco pour la partie embed dans l’application) Outils de documentation, Confluence, et outils de suivi des tâches/incidents, JIRA. Environnement cloud (AWS) Cela pour être un super fit si en plus, tu as/es : Soft skills autonome curieux(se) une bonne communication diplomate un esprit de synthèse flexible Social skills Ouverture d’esprit Orienté Business Bienveillance Sens de l’initiative 🔝😍 Ce que l’équipe aime par-dessus tout sur ce poste L’humour au quotidien, via des petites blagues souvent de bonne qualité (mais pas toujours) La team Product Engineering Les afterworks L’aventure d’une belle croissance Pouvoir mettre sa pierre à l’édifice 👍 Les petits + qui font kiffer Contrat forfait jour + RTT Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge à 70% Un club employé (billetterie, produits high-tech, voyage, etc..) La carte tickets resto --> Swile est notre ami Primes cooptations Remote ponctuel où tu veux en France Goodies, welcome lunch & drinks (et pas que de bienvenue) 1 break dans l’année dans une destination surprise Eldo est la société qu’il te faut si tu aimes … 💚 Le management de proximité et impliquant L’autonomie, les prises d’initiatives, les challenges #growthmindset Évoluer au sein d’une équipe fun et bienveillante Les moments de partage en équipe L’idée de mettre ta pierre à l’édifice et de participer à une aventure humaine et professionnelle INCROYABLE 🔎 Le process de recrutement chez Eldo 1 - Échange visio RH (45’) 2 - Use case 3 - Échange avec des membres de l'équipe Product Engineering ! (60') 4 - Échange avec ton futur manager, le CPTO (60') Ce poste peut-être en 100% en full remote avec des déplacements à prévoir 1 fois par mois sur Toulouse pris en charge par Eldo Alors, séduit(e) ? poste sans tarder ton CV et sors ta plus belle plume 😎 Eldo est une entreprise handi-accueillante","Eldo is looking for a Data Engineer to improve their applications, propose architectures, data pipelines and algorithms on large sets of data, support internal teams and centralize data to enable BI tools. The ideal candidate should have knowledge of MySQL, PostgreSQL, ETL/ELT, and AWS, as well as soft skills such as autonomy, curiosity, and communication. Eldo is a handi-friendly company that provides remote work, benefits, and a fun and challenging work environment.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,3,1,0.05539549888311683
380,33985,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/ios-software-engineer-paris_paris,iOS Software Engineer - Mobile Data Collection,Contentsquare,"{Node,Azure,Datadog,React,go,Typescript,Kafka,Flink,Grafana,Golang,Akka,AWS,Contentsquare,Java,regard,color,Scala,Kibana,Spark,ClickHouse,Python}",Télétravail total possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We’ve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we’re not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! 🚀 Our mission At Contentsquare, all employees share one goal: to help brands create exceptional online experiences with our industry-leading digital experience analytics platform. In the mobile data collection team, we are on a mission to build the industry leading digital experience analytics SDK. With a stellar growth, billions of users , a complex business environment and the need for us to have a very high level of quality, performance and privacy, you’ll find an engaging, rewarding and supportive work environment at Contentsquare. We are looking for developers who understand that development is a team effort, who are proud of a job well done and know how to implement simple and efficient solutions to solve challenging and unique problems. 💻 Our stack On the data collection side, our SDK works on native iOS applications (implemented in Swift) and native Android applications (SDK is in Java - converted to Kotlin over time -, Unit Tests and Sample App in Kotlin). We also support various multi-platform frameworks (React Native, Flutter, Capacitor/Ionic, Cordova) with specific bridges. The Tag (implemented in Typescript) that collects data on websites (both desktop and web mobile) is implemented and maintained by the Web Team. Our APIs are mostly designed with our specific constraints in mind. For example, the most data intensive ones use Protocol Buffers . Our backend uses a combination of technologies such as Kafka , Spark, Flink , Akka , ClickHouse and languages such as Scala , Golang, Python , C++. Our monitoring and deployment are handled through Kibana, Grafana , Terraform, Datadog and finally, everything is hosted on AWS and Azure. Our frontend is a micro-frontend SPA developed mainly in Angular / Vue.js and Node.js . 🧠 Our challenges Our first challenge is to navigate through uncharted territories, native APIs and poorly documented features to make sure we collect all the relevant data we need to compute our insights. In addition we obviously must ensure a very high level of performance (as well as the least impact on user experience), stability and be very mindful about data and CPU consumption. Our rapid growth requires a strong focus on software architecture, code sharing and automation to sustain our delivery capacity while increasing our teams' size. Finally, we are not a tracking company, so collecting PII (Personal Identifiable Information) is an absolute no-go for us and we take it very seriously! 🤗 Skills & Mindset If you have already worked on any kind of software SDK your experience will be of great interest to us. In the same way, if you have notable experience in high performance code, automated non-regression and performance testing, software bridges (between technologies, native and non-native), or if you enjoy testing new technologies or frameworks such as Flutter/Dart, Swift UI, Compose, React Native/Typescript, we would love to hear from you. As a team we are really involved in producing a high quality SDK. We expect our developers to know how to unit test their code, to write easy to read & maintain code and documentation as well as being comfortable doing pair programming with their team members. 🏝 What we offer An healthy working environment with supportive team members, a place to grow both technically and as an individual Autonomy, responsibilities and opportunities An Engineering Career Path (with clear defined progression steps and opportunities to mentor and be mentored) to make sure you always learn something new Plenty of opportunities for training and development Attractive salary and stock options Flexible working conditions (full remote, 100% in office or any hybrid setup of your choice) A dynamic and multi-cultural company with +50 nationalities Good health insurance Many benefits such as reductions on gym membership and leisure activities While we are offering fully remote opportunities, employees need to be fiscally based in one of our main countries to be hired by one of our office. Please ask your recruiter for more information. Why you should join Contentsquare - We’re humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we’d like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company’s success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is seeking developers to join their mobile data collection team to build the industry-leading digital experience analytics SDK. The ideal candidates will have experience with software SDKs, high-performance code, automated testing, and software bridges. The company offers a supportive work environment, career development opportunities, a competitive salary and benefits package, and the chance to work with a dynamic and multicultural team.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,3,1,0.05539549888311683
150,56383,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-h-f_brest,Data Engineer confirmé(e) –,Thales,"{durable,GIT,R,JAVA,Python}",Télétravail total possible,Brest,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES-VOUS ?PROFIL :Vous venez d'être diplômé(e) d'un master d'une école d'ingénieur et justifiez d'une expérience significative d'environ 2 ans (stages professionnels/stages, projets universitaires ou personnels tels que GIT Hub, Meet Ups, etc.)Vous êtes débrouillard(e), innovant(e) et orienté(e) solutionsVous avez l'esprit d'équipeVous aimez également travailler de manière indépendante et recherchez les responsabilités COMPÉTENCES : Vous êtes capable de vous adapter et de réagir au changement Vous savez et aimez concevoir, développer et tester des solutions et/ou des composants logiciels sécurisés Vous pouvez démontrer votre connaissance des langages et cadres de programmation Full Stack ou pure back/pure front (JAVA, C, C++, Python, ou tout autre) Vous êtes familier(ère) avec la compilation/construction de code/intégration continue. Vous avez connaissance des plateformes informatiques, des systèmes d'exploitation et des hyperviseurs du SI Vous connaissez les principes Agile CE QUE NOUS POUVONS FAIRE ENSEMBLE :En tant que ""Software Solutions Engineering Role"" chez Thales, vous serez amené(e) à : Travailler au sein d'une équipe Scrum avec d'autres développeurs de logiciels, en mode Agile Contribuer à la définition des besoins, à la conception du logiciel et être impliqué(e) dans les aspects architecturaux des projets logiciels Intégrer les composants logiciels dans un système logiciel entièrement fonctionnel Ecrire un code bien conçu, documenté et testable Développer, tester et exécuter le cycle de vie complet du développement logiciel Concevoir, mettre en œuvre et tester des fonctionnalités en tenant compte de l'évolutivité, des performances, du déploiement/de l'exploitation et de l'expérience de l'utilisateur(ice) final(e). Faire des estimations et contribuer à la planification avec les membres de l'équipe Collaborer avec d'autres ingénieur(e)s en solutions logicielles afin de partager les connaissances et d'améliorer le produit/solution dans son ensemble.VOTRE CARRIÈRE CHEZ THALESDifférentes opportunités vous permettront de découvrir d'autres domaines ou sites. Vous pourrez évoluer et développer vos compétences dans différents domaines :Explorez un espace attentif au développement personnelDéveloppez vos talents dans un autre domaine du groupe Thales, en découvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexeChoisissez entre une expertise technique ou un parcours de leadershipConstruisez une carrière internationale au sein d'un groupe d'ingénierie de premier plan. Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d’habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l’IGI 1300 SGDSN/PSE du 09 août 2021. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales seeks a Software Solutions Engineering graduate to join their team, with diverse opportunities to work within the information and communication security sectors, and provide global solutions for vital systems. The ideal candidate has a technical aptitude for designing, developing, and testing collaborative full-stack software solutions, familiar with coding languages and frameworks such as JAVA, C++, or Python. Join an Agile Scrum team, contribute to defining software specifications and architectural aspects, and collaborate with other software engineers to continuously develop and test the product. Thales upholds an inclusive, flexible work culture with international career opportunities.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
86,73554,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/front-software-engineer-f-m-d-data-observability_paris,Front Software Engineer  - Data Observability,Decathlon Digital,"{NodeJS,Github,AWS,GraphQL,via,Kafka,Javascript,Docker,Kubernetes,React,Git,GitHub,GCP,TypeScript}",Télétravail total possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES DATA DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour accompagner cette transformation digitale internationale de Decathlon, les équipes Data évoluent et mettent au cœur de leurs enjeux : La qualité et l’accessibilité de la donnée La scalabilité des processus associés au cycle de vie de la donnée (ingest, store, transform, expose) L’élasticité des infrastructures et des services Intégré au cœur de la data platform votre rôle sera de servir ces deux enjeux majeurs Garantir l'accès et l'usage de la donnée pour tous nos utilisateurs data en délivrant outils et guidelines La scalabilité REJOINS L'ÉQUIPE DATA OBSERVABILITY En fournissant la capacité à identifier, diagnostiquer, tracer et résoudre les évènements de transformation de la donnée dans le SI de Decathlon, nous donnons le pouvoir aux équipes data de fiabiliser leurs produits et d'en mesurer la qualité. En tant que Software Engineer Frontend tu auras pour mission de créer les meilleures expériences possibles et unifiées via des interfaces pour nos équipes internes. Dans le cadre de l’ouverture d’un poste en CDI, nous recrutons un-e Software Engineer, basé-e, au choix à Paris où à Lille. Périmètre d’action Tu prendras part de bout en bout au développement d'un portail complet et de nouvelles fonctionnalités (React/ Svelte) en lien avec le Product Manager. Tu évolueras également au contact des autres coéquipières et coéquipiers : l’amélioration continue et l’autonomie sont particulièrement valorisées chez Decathlon ! Ton exigence technique (qualité du code, pratiques, patterns, outils…) et tes qualités relationnelles permettent de diffuser les bonnes pratiques dans l’équipe, en collaboration avec le Tech Lead. TES RESPONSABILITES Construire une plateforme front pour rendre l'observabilité accessible à tous intervenir sur toute la chaîne de livraison des fonctionnalités : conception, implémentation, tests, documentation technique, exemples, API, SDK… être moteur dans le processus d'intégration et de livraison continue se montrer force de proposition dans les choix techniques mais aussi aussi dans nos moyens de collaboration Le périmètre technique : HTML / CSS : accessibilité, standards W3C, web performance… Svelte / Vue JS / ReactJS / GraphQL / Material UI Javascript / TypeScript, NodeJS Git (Github Actions) Tests unitaires et fonctionnels Outils collaboratifs : Confluence, Slack, Jira… Infrastructure : AWS, Kafka, Docker, Kubernetes… CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience (minimum 3-5 ans) du développement web frontend (Svelte / Vue JS / React), des architectures micro services / micro frontend, et de déploiement continu et tu as déjà effectué de l'UX design Tu as un bon niveau d’anglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu as un état d'esprit agile tourné vers l'amélioration continue, l'intelligence collective, l’entraide et la solidarité Tu aimes travailler dans un environnement collaboratif (Pair Prog, Code Review, et écosystème GitHub) Tu as une passion de la technique que tu aimes partager Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style relationnel et la vie en équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon à Lille où à Paris (prévoir un déplacement régulier sur Lille, à un rythme d'1 ou 2 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Digital, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantés notamment à Paris, Lille et Amsterdam. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .",,Non spécifié,> 2000 salariés,> 5 ans,3,1,0.05539549888311683
277,56775,https://www.welcometothejungle.com/fr/companies/la-releve/jobs/data-engineer-chez-l-un-de-nos-1000-clients-f-h_paris,Data Engineer chez l’un de nos 1000 clients,La Relève,"{PostgreSQL,Dagster,Azure,Docker,MySQL,MongoDB,Beam,Django,Kafka,GCS,Dataflow,NoSQL,MariaDB,PyTorch,Flink,Kubernetes,AWS,Argo,SQL,Tensorflow,Scala,Airflow,S3,R,Spark,BigQuery,GCP,Python}",Télétravail partiel possible,"26, Rue Laffitte, Paris, 75009",Recrutement,CDI,2023-03-26,"Créée en 2014, La Relève est un acteur incontournable dans le recrutement sur-mesure de talents auprès des acteurs de la French Tech : de la startup en quête de croissance au grand groupe en pleine transformation digitale. Nous sommes une 15aine de recruteurs passionnés et accompagnons plus de 900 entreprises dans la recherche de la perle rare dans les domaines suivants : tech, marketing, sales, produit et design. En 2021, ce sont plus de 400 talents qui ont trouvé le projet de leurs rêves grâce à notre équipe d’experts basés à Paris et Madrid. La Relève ne cesse d’évoluer et de se réinventer. Depuis plus d’un an déjà, nous continuons notre belle évolution avec le lancement de La Relève On Demand, notre service RPO (délégation d’expert en recrutement dans les entreprises), et l’ouverture de notre bureau à Madrid. Échanger avec l’un de nos recruteurs, c’est rencontrer un expert du recrutement tech et se voir proposer une multitude d’offres dans des entreprises diverses et variées. Nous travaillons avec de nombreux acteurs économiques, de la start-up au grand groupe, avec tout type de technologie data ! Vous avez une appétence particulière ? Nous travaillons avec des entités évoluant dans de nombreux secteurs : éducation, média, food, RH, art, écologie, santé, e-commerce, logistique et bien d’autres. Bien que de nombreuses entreprises soient localisées à Paris, nous travaillons avec des entreprises basées dans toutes les régions françaises, et/ou proposant du télétravail partiel ou total. Nous travaillons avec des entreprises évoluant sur tout type de stack technique et avec des outils et méthodologies divers et variés. Voici une liste d’exemples courants, mais non exhaustifs : S3, Delta Lake, BigQuery, GCS Spark, Google Dataflow Airflow, Argo, Dagster Kafka, Beam, Flink Terraform, Kubernetes, Docker AWS, GCP, Azure, OpenStack R, Scala, Python, Django, PyTorch, Sci-Kit Learn, Tensorflow SQL, MySQL, NoSQL, PostgreSQL, MongoDB, MariaDB ETL Les qualifications : du Bac+2 au Doctorat en passant par les profils en reconversion, les critères des entreprises sont tout aussi variés qu’ils sont nombreux, et nous prenons plaisir à rencontrer tout type de profil ! L’expérience : nous accompagnons tout type de séniorité. La rémunération : très variable selon les profils et les entreprises auxquelles vous postulez, nous nous assurons qu’elle soit toujours juste et en phase avec vos prétentions, et nous sommes aussi présents pour vous assister dans la négociation si nécessaire. Le télétravail : également très variable selon les niveaux de séniorité, de responsabilité et les pratiques au sein des entreprises auxquelles vous postulez, nous vous communiquons la politique de télétravail de l’entreprise dès notre premier échange pour que vous puissiez immédiatement vous projetez. Vous postulez à cette offre et vous remplissez les champs demandés. Votre profil est étudié attentivement, pour déterminer si nous sommes ou non en mesure de vous accompagner de manière pertinente dans votre recherche. Si ce n’est pas le cas, nous vous en informerons ! Vous échangez de vive voix avec un membre de notre équipe tech, qui prend le temps de comprendre votre besoin et vos appétences. Et nous vous sélectionnons uniquement nos offres en CDI qui vous correspondent. Nous vous suivons pendant tout le processus : nous vous accompagnons avant et après les entretiens pour vous y préparer et recueillir vos retours, et vous partager ceux de l’entreprise. Vous obtenez le poste qui vous convient : si tout le processus de recrutement se passe bien, vous serez bientôt prêt pour votre futur emploi. Pour autant, nous ne vous laissons pas tomber, loin de là ! Nous restons disponibles pour toute question supplémentaire, et nous gardons contact avec vous lors de vos premières semaines pour s’assurer que votre intégration se déroule bien.","La Relève is a recruitment agency specializing in personalized talent recruitment in the French Tech sector. They have over 900 clients in the tech, marketing, sales, product, and design industries, and work with companies of all sizes and regions in France. They are looking for candidates with a diverse range of qualifications and experience, and provide assistance throughout the recruitment process, as well as continuing support during the candidate's first few weeks in their new position.",Bac +5 / Master,Entre 15 et 50 salariés,> 6 mois,2,2,0.05539549888311683
83,56993,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-big-data-h-f_montpellier_CGI_LALwMW5,Data Engineer Big Data,CGI,"{Python,MongoDB,Neo4j,Scala,Kafka,Cassandra,Hive,Spark,Git,Java,NoSQL,Hadoop,nifi}",Télétravail total possible,"Montpellier, 34000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, … Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python. Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 200 consultants) ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial. En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants. Vos missions seront : • Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques • Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…) • Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…) • Participer à l'élaboration et la révision de normes / documentation technique • Animer des formations internes. Accompagner la montée en compétences des équipes • Assurer un support technique Big Data aux équipes et aux clients au quotidien Accompagné.e et entouré.e par une communauté Data passionnée, l’échange, le partage et les formations vous offriront un véritable espace pour vous épanouir. La proximité et le suivi personnalisé de votre manager, puis un bon nombre d’événements tout au long de l'année, renforceront encore la convivialité et l’esprit d'équipe ! Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data. - Passionné.e d’informatique et de données, vous aimez le travail en équipe, apprendre et partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez de 2 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le Domaine du Big Data. - Vous disposez d'une vision large des technologies et vous maîtrisez au moins une technologie Big Data. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, is looking for a passionate and experienced Data Engineer with expertise in data engineering, pipeline construction, data science application industrialization, and database modeling, among others. The candidate must have knowledge of Big Data tools, such as Hadoop, Spark, Hive, Kafka, Nifi, and/or NoSQL solutions. They must also have proficiency in at least one of the following programming languages: Java, Scala, or Python, and be willing to diversify their skill set. The position involves working on large-scale national and international projects for various industries, while collaborating with technical engineers and other experts. The role requires analyzing, recommending, implementing, and providing technical support for Big Data solutions. Additionally, CGI offers a supportive and inclusive work culture, professional development opportunities, and a clear career path. CGI is also an employer that supports inclusion and values the well-being and career advancement of its employees.",Non spécifié,> 2000 salariés,> 5 ans,3,1,0.05539549888311683
180,56860,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/developpeur-data-engineer-teletravail_MD_W0ZLb0V,Développeur / Data Engineer - Télétravail,MP DATA,"{Azure,MongoDB,Django,Git,Airflow,AWS,Snowflake,S3,Kafka,GCS,Spark,GCP,Java,SQL,Hadoop,Python,Postgres}",Télétravail total possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-03-26,"Bonjour ! MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance, l’exploitation de leur données et leur décarbonation. Les collaborateurs, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français. MP DATA accompagne ses clients sur toute la chaine de la donnée au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences. Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort, et des possibilités d’évolution intéressantes. MP DATA, recrute un développeur , avec des affinités pour le métier de Data Engineer (ou un Data Engineer) afin de travailler pour un client, acteur majeur du secteur transport, le tout en télétravail. Accompagné par un Lead Data Engineer, vous monterez en compétences sur l’utilisation de nombreuses technologies notamment AWS , Python , Snowflake , Spark , Airflow, Ansible. Vos missions seront les suivantes : Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données Création de pipelines de données, traitement et transformation de la donnée. Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles Assurer le suivi de la production De formation Bac+5 (ou plus) en développement informatique / data engineering, vous justifiez d’une première expérience professionnelle au cours de laquelle vous avez pu développer les compétences techniques suivantes : Python Spark, Kafka, Hadoop Cloud : AWS (S3, Lambdas,…) / GCP / Azure Technologies de stockage : Snowflake / GCS / Azure Blob SQL : Postgres / MongoDB Django / Flask CI/CD : Ansible / Git Terraform C/C++ / Java / Rust Alors venez grandir avec nous ! 1 entretien RH -> 1 entretien technique -> 1 entretien dans les locaux","MP DATA is seeking a developer or data engineer with experience in Python, AWS, Snowflake, Spark, and Airflow to work remotely with a major player in the transportation industry. The successful candidate will propose architectures, design and implement data pipelines, ensure data quality, and identify and integrate data for business and operational issue resolution. The company offers the opportunity to work on exciting projects with a strong technical framework and interesting career growth prospects.",Bac +5 / Master,Entre 15 et 50 salariés,> 1 an,3,1,0.05539549888311683
181,56969,https://www.welcometothejungle.com/fr/companies/thales/jobs/dataengineer-departement-ia-bigdata_sophia-antipolis_THALE_q0DLXgG,DataEngineer - Département IA & BigData,Thales,"{Oracle,PostgreSQL,Cassandra,Hive,Nvidia,Microsoft,durable,MongoDB,Kafka,NoSQL,Flink,AWS,HBase,Storm,Java,SQL,Hadoop,GCP,MinIO,Scala,HDFS,S3,Spark,Pig,AZURE}",Télétravail total possible,Sophia Antipolis,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces. Nos équipes de la Direction de l’Ingénierie Logicielle ( DIL ) fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces . Le département IA & Big Data recherche plusieurs Ingénieurs DataEngineer (H/F) basés à Sophia Antipolis (06). QUI ETES-VOUS ? De formation Bac+4 ou Bac +5 (type école d’ingénieur), vous possédez de bonnes connaissances dans le domaine de la donnée (Data Science, Data Engineering, Stockage), en ingénierie logicielle globalement. Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, AZURE) ou privé. Principales activités que vous réaliserez : Mise en place de pipelines de traitement de données Utilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / Storm Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie) Utilisation de tous les types de stockage actuels SQL : Oracle, SQLServer, PostgreSQL NoSQL : Cassandra / MongoDB / HBase Objet : S3 / MinIO Vous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala & Java). Vous êtes à l’aise en Anglais. Vous êtes curieux(se) et rigoureux(se). Vous aimez travailler en équipe au quotidien. Pour vous le succès n’est que collectif. Vous vous reconnaissez ? Alors parlons missions … CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Le département IA & Big Data fédère et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d’une structure permettant d’accélérer la transformation des enjeux Data de nos clients. Nos savoir-faire : Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie Projets d’intégration système Nos domaines métier : Maintenance prédictive, Traitement d’image pour la santé Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de réponse Aerospace : Centre de Mission et de Contrôle, Dynamique du Vol, Qualité Image, Occupation des sols, Sondage Atmosphérique Nos partenaires : Recherche : INRIA, CNRS, 3IA Externes : Nvidia, Microsoft En collaboration avec les membres de notre département : Vous contribuerez au développement et à la scalabilité de nos plateformes au travers d’activités d’automatisation, de création de services managés et d’API. Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes. Vous participerez à l’intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com) Vous collaborerez à nos publications, conférences et webinars. Vous serez partie prenante de la 3ème révolution industrielle impactant tous les secteurs d’activité, énergie, santé, industrie, … La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant à cette offre . Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is seeking a Data Engineer with a background in data science, data engineering, and storage, with knowledge in cloud technologies (public or private). The position involves setting up data processing pipelines, utilizing current technologies such as Kafka, Spark, and Flink, and working with Hadoop stacks, SQL and NoSQL databases, and object storage systems. The position also involves collaborating with team members and clients to provide technical and functional solutions for data valorization projects.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
390,34754,https://www.welcometothejungle.com/fr/companies/l-oreal/jobs/data-security-engineer-l-oreal-france_clichy,Data Security Engineer - L'Oréal France,L'Oréal France,{IAM},Télétravail total possible,Clichy,"Luxe, Cosmétique, E-commerce",CDI,2022-08-08,"Notre Raison d’être : Créer la beauté qui fait avancer le monde. Le désir de beauté est une force puissante qui nous fait avancer. La beauté ne se limite pas à l’apparence. Elle nous donne confiance en nous, en qui nous voulons être, et dans notre relation avec les autres. Depuis plus d’un siècle, nous exerçons ce métier unique : créateur de beauté. Notre but est d’offrir à tous, partout dans le monde, le meilleur de la beauté en termes de qualité, d’efficacité, de sécurité et de sincérité pour satisfaire tous les besoins et désirs de beauté dans leur infinie diversité. Et parce que nous sommes le leader de la beauté, nous sommes conscients que tout ce que nous faisons peut avoir un impact significatif. C’est pourquoi nous agissons pour : Inventer le futur de la beauté en ayant recours au meilleur de la technologie et de la science, inspirées par la nature. Faire avancer l’innovation sociale en offrant à nos collaborateurs le meilleur en matière de conditions de travail, de formation et de protection sociale. Construire une entreprise toujours plus inclusive qui reflète la diversité des consommateurs que nous servons. Nouer des partenariats durables avec nos clients et fournisseurs, basés sur la confiance et le développement mutuels. Œuvrer partout pour la cause des femmes et au développement des communautés qui nous entourent. Protéger la beauté de la planète en luttant contre le changement climatique, en respectant la biodiversité et en préservant les ressources naturelles. Here are some more insights concerning your missions: Ensure compliance of the Data Platform with L’Oréal group security rules Be proactive to analyze security weaknesses/data leaks and propose solutions consistent with L’Oréal eco-system and in partnership with Global Enterprise Architecture team and Security team. Define security, privacy, and quality tools & services for Data Platform in collaboration with data platform and data services managers. Be part of the development team for the defined tools & services defined. Define the continuous improvement plan (plan, do, check act) to improve data & platform security quality: define the KPI, implement and get the feedback loop. Handle internal and externa audits (feedbacks, follow-up) Communicate, train, and educate data platform security topics in front of stakeholders (business platform teams, IT teams, zones teams, etc.) Do a proactive technology watch about Data and Cloud Security In this specific position, it will be important for you to: Have a solid experience in Google Cloud Platform Have an experience in API security management Have a confirmed experience Google Cloud Platform security (IAM, secrets management, Zerotrust – OAuth2, serverless security and constraint) Have already a first experience on Google Cloud Platform cost management Have an appetency for IT security in application and enterprise level Be able to lead technical presentations, workshops, architecture design sessions, proofs of concept to prove the legitimacy of proposed solutions Be able to interact with all levels of management, Team spirit with other Data Tech Lead and be empathic: share difficulties and ideas; solve problem together Be determined to ensure the application of security rules by teams Innovator: Aware of new IT innovations and development best practices Advanced degree in engineering or technical/scientific field of study 4-6 years technical experience 3-4 years technical experience in google cloud platform 1-2 years technical experience in security cloud We love people that are curious, collaborative, eager to have an impact and who value innovation, autonomy, and team spirit.","L’Oréal is seeking for a Data Tech Lead who will ensure compliance of the Data Platform with L’Oréal group security rules, analyze security weaknesses/data leaks, handle internal and external audits, communicate and train data platform security topics, and do a proactive technology watch about Data and Cloud Security. To qualify, the applicant must have solid experience in Google Cloud Platform, API security management, Google Cloud Platform security, and Google Cloud Platform cost management, as well as possess an appetency for IT security in the application and enterprise level. An advanced degree in engineering or technical/scientific field of study is required.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
149,56432,https://www.welcometothejungle.com/fr/companies/tactill/jobs/operations-engineer-100-remote_paris,Data & Automation Engineer (100% Remote),Tactill,"{Javascript,Intercom,Zapier,DataStudio,DBT,scale,BigQuery,SQL}",Télétravail total possible,"48 avenue du Général Leclerc, Paris, 75014","Application mobile, Objets connectés",CDI,2023-03-26,"TL;DR Poste : Data & Automation Engineer Contrat : CDI Seniorité : Expérimenté Salaire : 45 - 65K€ /an Localisation : 100% Remote Stack : Amplify / BigQuery / DBT / Zapier / ReTool / SaaS Tech Team : 9 personnes Sociétés de recrutement / pré-embauche / SSII / ESN nous n’externalisons pas le recrutement. Merci Plus d’infos 👇 Chez Tactill, nous nous sommes fixés une mission audacieuse : permettre aux commerçants de vendre partout où ils en ont besoin. C’est pourquoi, en boutique ou dans la rue, nous leur offrons les meilleurs outils pour encaisser et gérer leur business. Tu veux en savoir plus -> https://www.tactill.com Notre solution s’appelle Tactill et elle transforme iPhones et iPads en caisses enregistreuses mobiles et connectées. Déjà utilisée par des milliers d’entreprises, nous voulons faire de Tactill la référence de l’encaissement mobile. La Team 👩‍💻 Notre équipe tech est constituée de 9 personnes complémentaires : [ Grégoire - Founder & CEO ] ( https://www.linkedin.com/in/gr%C3%A9goire-lopez-232b6334 /) [ Elodie - Founder & CPO ] ( https://www.linkedin.com/in/elodie-godart-a47a6437 /) [ Giorgi - ArchiTech & iOS ] ( https://www.linkedin.com/in/giorgi-shavgulidze-77aaa856 /) [ Alexandre - Backend ] ( https://www.linkedin.com/in/alexandre-bernard-89561ab7 /) [ Jennifer - Frontend ] ( https://www.linkedin.com/in/jennifer-c-575b46153 /) [ Ugo - Senior UX/UI ] ( https://www.linkedin.com/in/ugo-jauffret /) [ Tristan - UX/UI ] ( https://www.linkedin.com/in/tristan-chapelle-a4763a54 /) [ Stephane - QA ] ( https://www.linkedin.com/in/stephane-hildbrand /) [ Mathias - QA ] ( https://www.linkedin.com/in/mathias-porzier-b50654194 /) De la spécification fonctionnelle aux tests automatiques en passant par le design, toutes les étapes de notre process ont été réfléchies, construites et automatisées (quand c’est possible). Nous connaissons le coût de la dette technique et nos décisions tendent à s’en affranchir tant que faire se peut. Mission 🎯 Tactill n’est pas qu’un logiciel SaaS. C’est également une entreprise qui dépend de nombreux process pour servir ses clients. Notre ambition est de les améliorer et de les automatiser. Cette ambition s’inscrit dans un projet global de refonte de toutes nos stacks (produit, marketing, sales, support, data, logistique, comptabilité …) Pour y arriver, notre équipe produit cherche aujourd’hui un Data & Automtation Engineer pour prendre en charge la construction de la v2 de notre stack opérationnelle. Cette mission est vaste et tu interviendras sur de nombreux projets : Data -> update de notre stack data (Stich Data + BigQuery + DBT + DataStudio) Marketing -> update et automatisation de la stack markeing (Intercom + Pipedrive + custom code) Sales -> update de la stack sales (Pipedrive + RingOver + custom code) Logistique -> automatisation de nos process logistiques (Chargebee + FlxPoint + custom code) Acquisition -> construction de la stack de tracking et referring (Referral) NoCode -> construction d’apps internes Nous creuserons chacun de ces sujets ensemble et tu seras accompagné par notre CEO qui a construit le v1 de cette stack. Tu seras “a team of one” mais pas de panique … Tu seras accompagné par l’équipe qui a déjà construit la v1 de la stack opérationnelle La stack actuelle est documentée et nous avons une vision claire de la stack v2 Tu seras intégré à l’équipe produit et tu profiteras des process de devs déjà en place Cette mission n’inclut pas de composante managériale (en tous cas pas à moyen terme) Formation 🧑‍🎓 Le niveau d’abstraction de notre stack est important. Nous cherchons donc une personne à l’aise avec les concepts avancés de l’ingénierie informatique (architecture, modélisation de données, design pattern, programmation fonctionnelle, compléxité algorithmique …). Ton niveau académique est moins important pour nous que ta capacité à comprendre et améliorer l’éxistant, cependant un diplôme scientifique du supérieur sera un plus. Compétences 🧠 Javascript : Ton niveau en JS est irréprochable et tu maîtrises le paradigme fonctionnel. Data : Tu maitrises SQL sur le bout des doigts. Clean code : Ton code est propre, lisible, testé et documenté. Documentation : Tu sais écrire une documentation claire et tu sais à quel point c’est important. Low Code : Tu as l’ambition de déléguer le maximum de compléxité à des outils robustes. Business : Tu comprends les enjeux business d’une entreprise de logiciels BONUS - DBT : Une première expérience avec l’outil sera un plus. Expérience 💪 Nous cherchons quelqu’un qui a roulé sa bosse et rencontré les pièges classiques du développement. Fort d’au moins 2 ans d’expérience dans un poste similaire, tu as idéalement travaillé dans une startup et participé à son scale. En revanche, tu es plus intéressé par la tech et le logiciel que par le startup game, game auquel nous ne jouons pas. Profil 👀 Excelsior est la devise que nous portons tous. Ainsi, nous cherchons une personne passionnée par ce qu’elle fait et qui consacre du temps à sa passion. Un projet personnel qui t’animes à beaucoup de valeur à nos yeux. Notre team est 100% remote, avec ses avantages et ses inconvénients. Il est important pour nous que tu aies déjà eu une expérience similaire et que tu sois à l’aise avec ce mode de fonctionnement. En résumé, autonomie et responsabilité font partie de tes qualités. Bonus ⭐️ Tu as déjà participé à un projet entrepreneurial en temps que co-founder Avantages 🍭 100% Remote Tactill n’est pas là pour te dire où travailler. Tu aimes bosser sous le soleil ? On part du principe que tu es adulte et que tu connais les conditions de ta productivité. Boite tech Les fondateurs de Tactill sont des ingénieurs amoureux du beau logiciel. Nous avons conscience de la difficulté de construire des systèmes robustes et maintenables et nous ne prenons pas de décisions hâtives pour gagner trois francs six sous. Off-sites au soleil Nous organisons plusieurs fois par an des off-sites dans des endroits chauds et ensoleillés pour que la team puisse se retrouver. Ton arrivée devrait d’ailleurs coller avec notre spring break 2023. Santé et frugalité Chez Tactill, on prend en charge 100% de ta mutuelle. En revanche, pas de CE, tickets restau ou chèques vacances. On préfère te rémunérer à ta juste valeur plutôt que de te donner de la monnaie de singe en échange de quelques euros sur ton salaire. Sociétés de recrutement / pré-embauche / SSII / ESN passez votre chemin. Merci Tu postules ici On étudie ton profil et on te fait un retour (max 1 semaine) On fait connaissance sur Google Meet (30 minutes) Petit test technique (4 heures max) On t’invite à rencontrer la team On célèbre ton arrivée au soleil","Tactill, a mobile and connected cash register software company, is seeking an experienced Data & Automation Engineer for a fully remote position. The engineer will work on a broad range of projects to update and automate the company's operational stack, including data, marketing, sales, and logistics. The ideal candidate should have a strong command of JavaScript, SQL, clean code, low code, business concepts, and documentation, as well as at least two years of experience in a similar role. Being passionate about software engineering, having a personal project, and being comfortable with remote work are additional desirable qualities.",Bac +3,< 15 salariés,> 2 ans,3,1,0.05539549888311683
323,56514,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_bordeaux,Data Engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,GCP,Java,Python}",Télétravail total possible,Bordeaux,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-03-26,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Description du poste Participer à la définition des besoins et à la rédaction des User Stories, Collaborer avec les Data Scientists au développement des modules d’analyse de donnée, Concevoir et construire des architectures de données, Intégrer des sources de données, Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives, Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux. Profil Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple, Vous maitrisez les bases de l’analyse statistique, Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous êtes familiarisé avec l’environnement Linux, Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts. #LI-JH1 Efficace , vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui Méthodique , les plans d’action sont dans votre ADN Organisé , vous êtes l’as des to-do list","Extia, a consulting firm for IT, digital, and engineering, is looking for a Data Analyst to work with data scientists in developing data analysis modules, integrating data sources, and executing ETL processes. The ideal candidate should have experience in ETL, data mining, machine learning, big data, and graph theory, as well as knowledge of statistical analysis and programming languages such as Python and R. Experience in Linux, storage tools, cloud infrastructure, and real-time streaming is a plus. Methodical, efficient, and organized candidates are preferred.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
77,73484,https://www.welcometothejungle.com/fr/companies/schneider-electric/jobs/cloud-data-engineer-f-h_grenoble,Cloud Data Engineer,Schneider Electric,"{Github,Python,Presto,Scala,Microsoft,Azure,durable,Databricks,Spark,Kubernetes,Docker,R,AWS,Flink,Java}",Télétravail total possible,"160, Avenue des Martyrs, Grenoble, 38000","Ingénieries Spécialisées, Objets connectés, Energie",CDI,2023-04-22,"Schneider Electric est leader mondial de la gestion de l’énergie et des automatismes. Nous concevons, réalisons et mettons en œuvre des solutions innovantes pour une gestion de l’énergie sûre, efficace, fiable et durable. La raison d’être de Schneider Electric est de permettre à chacun de tirer le meilleur de son énergie et de ses ressources, afin de concilier progrès et développement durable pour tous. Nous nommons cette ambition : Life is On. Notre mission est d’être le partenaire digital du développement durable et de l’efficacité de nos clients. Nous menons la transformation numérique en intégrant les technologies de l’énergie et des automatismes les plus avancées. Nous connectons jusqu’au cloud, produits, plateformes de contrôle, logiciels et services sur l’ensemble du cycle de vie de vos activités pour une gestion intégrée de l’habitat résidentiel, des bâtiments tertiaires, des data centers, des infrastructures et des industries. Chez Schneider Electric , nous nous engageons à résoudre des problèmes concrets pour créer un avenir électrique durable et numérisé. L' Intelligence Artificielle a le potentiel de transformer les industries et d'aider à débloquer l'efficacité et la durabilité.Au sein de notre Global AI Hub , nous combinons notre expertise de longue date en matière de fabrication et de domaine avec une innovation de pointe en matière d'IA, d'apprentissage automatique et d'apprentissage profond pour favoriser une prise de décision plus intelligente, l'agilité et la décarbonisation.Au sein de l'équipe AI Technology, nous recrutons un.e Cloud Data Engineer. Le groupe AI Technology (70 personnes) développe 2 plateformes d'IA s'appuyant sur Azure et AWS pour répondre aux besoins externes et internes. Vos responsabilités : Ingénierie de pipelines de données efficaces, évolutifs et adaptables pour traiter des données structurées, semi-structurées et non structurées. Maintenir et repenser les ensembles de données et les pipelines existants pour servir une grande variété de cas d'utilisation. Mettre en œuvre l'observabilité des données et surveiller les pipelines de données en production afin d'en assurer le bon fonctionnement. Agir en tant que partenaire de l'équipe d'ingénierie de la plateforme et de l'équipe d'apprentissage automatique, comprendre leurs défis et faire des recommandations avisées qui leur permettent d'avoir des solutions de données. Ecrire de l'infrastructure en tant que code pour déployer notre infrastructure de données Rédiger des travaux ETL pour collecter et agréger des données. Construire des modèles de données de haute qualité. Identification, mise en œuvre de composants et de bibliothèques partagés à réutiliser d'un contexte à l'autre. Spécification, conception, mise en œuvre, test, validation et industrialisation de fonctions avancées de gestion des données à intégrer dans les produits, systèmes et solutions. Collaboration avec des experts en données et en domaines afin d'identifier les méthodes, les outils et les technologies de transformation des données en vue d'élaborer des plateformes et des offres de produits. Contribution à l'identification et à l'évaluation de partenaires externes potentiels. Contribution à la protection de la propriété intellectuelle, à la capitalisation des connaissances et à la communication interne et externe. Votre profil : Master ou doctorat ou diplôme équivalent en traitement de données, informatique avec minimum 2 ans d'expérience. Expert en ingénierie de pipeline de données utilisant des technologies telles que Presto, Spark ou Flink et ou les services gérés équivalents des fournisseurs de cloud public. Compétences/expérience en génie logiciel : capacité à coder, déboguer, tester (y compris les tests unitaires, les tests fonctionnels et les tests d'intégration) et dépanner tout au long du processus de développement de l'application et en mode agile. Idéalement, connaissance du marché de la gestion et de l'automatisation de l'énergie. Orientation vers la résolution de problèmes, l'obtention de résultats et l'application de la technologie à des cas concrets. Compétences de communication efficaces, y compris une aptitude à raconter des histoires basées sur des données : convaincre avec des mots, avoir un impact avec des données et influencer avec des images. Autonomie ET capacité à coopérer. Ouverture d'esprit ET rigueur scientifique. Anglais courant. Technologies : Langages : Python, Java, Scala Plateformes cloud : Microsoft Azure, AWS Outils : Kubernetes, Databricks, Docker, Spark, OpenDataSoft, Github, Terraform.Notre offre comprend une rémunération attractive et va bien au-delà. Nous offrons des avantages compétitifs, un environnement de travail qui encourage le développement professionnel, un onboarding qualitatif et un accompagnement tout au long des différentes étapes de votre vie (formation, opportunités de carrière, parentalité, flexibilité…), dans un lieu de travail formidable.Pourquoi nous? Schneider Electric est le chef de file de la transformation numérique de la gestion et de l'automatisation énergétique. Nos technologies permettent au monde d'utiliser l'énergie de manière sûre, efficace et durable. Nous nous efforçons de promouvoir une économie mondiale à la fois viable sur le plan écologique et hautement productive. 25,7 milliards d'euros de chiffre d'affaires global 137 000+ employés dans plus de 100 pays 45 % du chiffre d'affaires de l'IdO 5 % du chiffre d'affaires consacré à la R&D Vous devez soumettre une demande en ligne pour être pris en considération pour ce poste. Ce poste sera posté jusqu'à ce qu'il soit rempli.",,Non spécifié,> 2000 salariés,> 2 ans,3,1,0.05539549888311683
137,34411,https://www.welcometothejungle.com/fr/companies/addixware/jobs/data-engineer-f-h_sophia-antipolis_ADDIX_eNAO97Y,Data Engineer,AddixGroup,"{Azure,explosion,Python,DataBricks}",Télétravail total possible,Sophia Antipolis,Logiciels,CDI,2022-08-08,"AddixData (ADD) fait partie du premier groupe français d’ingénierie informatique spécialisé dans la transformation digitale. ADD constitue l’un des 2 hub technologiques et B2B d’AddixGroup. Il fournit des solutions et des services aux entreprises qui veulent apporter de l’intelligence à leurs données informatiques. L’offre Data est née de l’explosion du volume des données informatiques et du fait que nous considérons qu’une donnée informatique dénuée d’intelligence n’a aucune valeur. Il est devenu essentiel d’en faire le tri et d’apporter de l’intelligence humaine à toutes ces données afin de construire un monde qui soit plus vertueux. Composé d’Ingénieurs et Docteurs en Data Science, ADD répond à l’ensemble des problématiques liées à la Data : Analyse des données, nettoyage et traitement, machine learning, business Intelligence, déploiement de bases de données et intégration de solutions data. Nous sommes présents sur Paris, Aix-en-Provence et Sophia-Antipolis. AddixData a remporté un projet innovant pour son partenaire spécialiste de la valorisation immobilière. Notre client recupère, traite et valorise beaucoup de données provenantes de différentes sources, afin de proposer à leurs clients des informations clés des biens immobiliers, les points d’intérêts et les risques permettant à l’acheteur de se positionner en sécurité sur l’achat d’un bien. Dans ce contexte, vous intervenez en temps que Data Engineer pour piloter ce projet. Vous maîtrisez DataBricks et vous connaissez Azure. Python n’a pas de secret pour vous? Vous souhaitez rejoindre une équipe dynamique et agile ? Ce projet est fait pour vous !","AddixData is a hub of AddixGroup that provides data solutions and services to businesses. They are looking for a Data Engineer with expertise in DataBricks and Azure, and proficiency in Python to pilot a data project for their client specializing in real estate valuation. The ideal candidate will be part of a dynamic and agile team.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,3,1,0.05539549888311683
147,56321,https://www.welcometothejungle.com/fr/companies/thales/jobs/s3ns-site-reliability-engineering-engineer-data-platform-f-h_paris_THALE_LaQzel6,S3NS - Site Reliability Engineering - Engineer Data Platform,Thales,"{durable,shell,Go,Git,Kubernetes,Docker,Spanner,Linux,Unix,GCP,Java,NoSQL,Python}",Télétravail total possible,Paris,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? S3NS est né du partenariat industriel entre Thales, leader mondial de la cyber sécurité, et Google Cloud, leader mondial des solutions cloud. Nous avons pour ambition d’offrir le meilleur des deux mondes à l’ensemble des organisations soucieuses de protéger leurs données sensibles (institutions publiques, OIV, OSE…). C’est-à-dire une solution équivalente à Google Cloud Platform (incluant à la fois les services IaaS et PaaS de GCP) et respectant les exigences du label SecNumCloud. Une première offre, ‘Contrôles locaux avec S3NS’, est déjà disponible depuis juillet 2022 pour permettre à nos clients de bénéficier d’un premier niveau de transparence et contrôles additionnels, et d'accélérer la trajectoire vers le cloud de confiance. QUI ETES-VOUS ? Vous êtes passionné par l’innovation technologique, le Cloud et les déploiements de services et d’infrastructure “as code” ? Vous aimez opérer des systèmes critiques de grande envergure ? Diplômé d’école d’ingénieur vous justifiez d'une expérience reconnue sur des marchés régulés (secteur bancaire/médical…) avec une exposition internationale. Vous justifiez de 5 ans d'expérience minimum dans le software engineering, l’automatisation, et le développement (Sécurité et conformité, Automatisation, Résolution de problèmes). Vous avez une expérience de migration d’infrastructure privée ou hybride vers le cloud. Vous maitrisez : Un ou plusieurs des langages suivants : C, C++, Java, Python, Go Les chaînes de valorisation de données incluant les aspects fonctionnels (Collecte et transport hétérogènes et/ou nombreuses, le traitement -normalisation, enrichissement, corrélation, analyse - maintenance prédictive, détection d’anomalies, clusterisation - notification, … “temps-réel” et/ou “batch”), le stockage, archivage, indexation et l’exposition, exploration des données. Les aspects techniques d’infrastructure sous-jacente, file de message, BD relationnelle, BD NoSQL, stockage objet,orchestrateurs et moteurs de traitements (pipeline, machine learning, IA), outils de visualisation et d’exploration Les aspects opérationnels tel que le MCO, de Sécurité et de Modernité de la solution, intégrité, confidentialité, haute disponibilité, élasticité, utilisabilité Les technologies de containerisation (ex. Docker, Kata Containers) et d’orchestration (ex. Kubernetes, Swarm), d‘hébergement Open Source (Linux, Docker, Kubernetes, Openstack) A minima un cloud public (ex. GCP) Les OS Linux / Unix et langages de scripting shell Les pratiques du SRE (Infra-As-Code, Git, Continuous Deployment, Terraform, Ansible) CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : En intégrant l’équipe, vous serez dans un premier temps contributeur de la construction d’une stack data pour délivrer les services du Cloud de Confiance: design, définition SLO/SLI, mise en œuvre des services, tests, etc. Vous bénéficierez d’une latitude importante quant aux choix effectués dans ces phases de design et d'implémentation. En partenariat avec Google, vous pouvez bénéficiez d’un parcours de formation accéléré et intense sur les technologies GCP, afin d’être parfaitement formé à la stack technique de Google (ex. Borg, Colossus, Spanner). Vos responsabilités: Mettre en œuvre et opérer en respectant l'état de l’art de la cyber sécurité toutes les solutions et/ou outils afin d’améliorer l'offre Plateforme Cloud de Confiance : depuis l’architecture, le développement, le déploiement, jusqu’aux opérations d’infrastructure. Contribuer au design, au développement et à l’intégration des solutions d’automatisation et de suivi des infrastructures afin de nous permettre une mise à l’échelle de nos opérations sensibles et processus critiques de hautes disponibilités. Identifier, initier, développer une boucle d’amélioration continue pouvant être déployée rapidement. Participer à la construction de chaînes de valorisation de données permettant d’implémenter nos Trust Services ET opérer les services data et IA de Google dans un environnement Cloud de Confiance.","Thales, in partnership with Google Cloud, is seeking a Senior Software Engineer experienced in software engineering, automation, and development, with at least 5 years of experience in regulated markets. The successful candidate will be responsible for implementing and operating cybersecurity solutions and tools to improve the Cloud Platform of Trust, contributing to the development and integration of infrastructure automation solutions, and providing technical input for the continuous improvement of data monetization chains. A strong knowledge of infrastructure, message queues, databases, containerization, and orchestration tools is required.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
392,34765,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_el2OOAy,BI Engineer & Data Visualisation,Numberly,"{SQL,PowerBI}",Télétravail total possible,Paris,"Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2022-08-08,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception à la réalisation d’applications d’outils d’aide à la décision et monitoring de performance répondant aux problématiques métiers de nos clients. Vous êtes amené à : Intervenir sur des missions de cadrage et d’analyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de répondre aux attentes des clients; Concevoir et réaliser les reporting d’aide à la décision en apportant une attention aux enjeux de self BI, ainsi que sur l’UX/UI Desktop et mobile; Déployer des projets de Data Visualisation sous PowerBI en priorité mais possiblement en participant aux choix d’autres outils de restitution; Accompagner les clients dans la bonne compréhension et montée en compétence sur l’exploitation et le maintien des tableaux de bord. Vous assurerez également une veille technologique, et proposerez des solutions standardisées, fiables, évolutives liées à votre activité. Chez Numberly, on partage une passion pour la transmission : des séminaires hebdomadaires, des talks avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment grâce :- aux Jedi Masters attribués aux nouvelles recrues ;- aux Vis ma vie dans des équipes différentes ;- aux Happy Meetings suivis par toutes les équipes dans le monde pour partager l’actualité du groupe. Nous cultivons la liberté de parole qui permet à tous de participer au rayonnement du groupe. A travers 1000mercis impacts mais aussi par nos activités qui créent de la valeur dans l’open Internet, nous agissons positivement sur notre écosystème. Numberly est Gender Equal by design (index de l’égalité Femmes / Hommes de 97/100 en 2020, certification WeConnect International). Numberly est un environnement international (vous interagissez au quotidien avec de nombreuses nationalités) où l’on se sent comme chez soi : des bureaux à notre image, des cuisines conviviales, une bibliothèque pointue, un grand studio de musique tout équipé, de la place pour les vélos. Du café, du thé et des tisanes à volonté. Des mystery lunchs, des soirées déguisées et des cours de sport. Possibilité d'être en remote jusqu'à 50% de votre temps (à organiser comme vous le souhaitez). Carte Swile (titres-restaurants). Poste disponible à Paris. Numberly accueille les candidats en situation de handicap. Vous avez au moins 2 ans d'expérience dans la mise en place de projets datawarehouse et datamart. Vous avez une appétence particulière au domaine du Big Data, avec des réalisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et compétences sur les technologies suivantes : ETL et SQL. Vous êtes curieux(se), autonome, force de proposition et avez l’esprit d'équipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont récompensé le travail de Numberly en Europe et aux USA) au sein d’une équipe jeune (27 ans de moyenne d’âge) et internationale (25 nationalités). Encore mieux si Vous avez de l’expérience sur PowerBI. Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, média et la relation client.","Numberly, a marketing technology company, seeks a Data Visualization Project Manager with at least 2 years of experience in data warehouse and datamart projects. The ideal candidate will have strong knowledge of ETL and SQL, proficiency in Big Data, and experience with BI/reporting and dataviz. The role involves working on all phases of application design and development, from requirements analysis to reporting and KPI identification, and the successful candidate will have the ability to work autonomously, take initiative, and be a team player. Remote work up to 50% of the time is possible, and the company is committed to a diverse and inclusive workplace.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
74,56537,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad_paris_BM_qldjWyN,Data Engineering Manager - Customer squad,Back Market,"{color,dynamodb,Scala,Lambda,AWS,via,Spark,GCP,Datadog,Python}",Télétravail total possible,"199, Rue Championnet, Paris, 75018","Environnement / Développement durable, Économie collaborative, E-commerce",CDI,2023-03-26,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world’s leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of 963,226 tons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: “be a coach not a dictator” is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc… - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We’re here to SABOTAGE: It’s our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team.","BackMarket is seeking an Engineering Manager for their Customer data team. The candidate must have the skills to build and develop sustainable and efficient teams, manage a team of data and analytics engineers, have a tech vision for the team, execute effective growth plans, improve processes and product, and work well with non-tech partners. The stack is AWS, GCP, Spark, Terraform, Python, and Scala. BackMarket offers an attractive salary, equity, and various benefits. They are an Equal Opportunity Employer and committed to reducing electronic waste.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
146,50483,https://www.welcometothejungle.com/fr/companies/immortal-game/jobs/analytics-engineer_paris,Analytics Engineer,Immortal Game,"{DBT,Looker,Fivetran,dbt,Snowflake,scale,Stitch,BigQuery,SQL,Python,Tableau}",Télétravail total possible,"29, Rue de Clichy, Paris, 75009","Application mobile, Blockchain",CDI,2023-02-07,"👋 About Us Immortal Game is the World’s First Play-and-Earn Chess Platform. Our mission is simple: create the best online chess experience for players, streamers, and professionals, while striving to transform the chess industry for the better. We are building the community-driven chess platform for the next generation, adding a new layer of strategy and monetization through NFTs to this over 1000-year-old game. Based in Paris, our 30 employees come from diverse backgrounds and we plan to scale to 50+ people in the next six months. Our platform is live, we’re growing fast and are backed by some of the top investor firms in Web3 and Entertainment. Do you have experience in data product development? Are you skilled in SQL data modeling using dbt, Snowflake or similar tools? Do you know what is the difference between ETL and ELT? If yes, you could be our first Analytics Engineer! As we ambition to build the best online chess platform, we need the best data analytics stack to help us! About the team Led by Boris, Immortal Game’s Data Team take care of building and maintaining the data pipeline using modern cloud-based tools. On the Analytics branch we define and monitor company KPIs and analyze player and games data to drive new features and improve our chess platform. The AI branch deploys ML models for cheat detection, recommendation systems and other coming applications like our Chess Academy. Responsibilities 🚀 Work closely with all stakeholders (game design/tech/business) on data & analytics initiatives. Participate actively in KPI’s definitions. Build and maintain our data pipeline and data models. Analyze and solve data quality and performance issues. Write accurate data documentation and top-quality code following best practices. Maintain and advocate for these standards through code and doc review. Find a good balance between ad hoc requests and long-term projects. Participate in recruitment to build our modern data team from scratch. 💼 What we are looking for 5+ years of experience in data product development. Advanced knowledge of SQL based data modeling and Python. Experience in DBT and maintaining large scale ETL / ELT processes. Experience working with data warehouses like Snowflake or BigQuery and data visualization tools such as Looker or Tableau. Fluent in English with excellent communication skills (written and verbal). Working proficiency in French. 🤩 Nice-to-have Analytic industry experience with video games. Experience with Fivetran / Stitch / Segment to automatically integrate data from different sources. You are a chess lover ♟️ 🔥 Why you should join us An experienced core team of business leaders with many successes already under their belt A spicy package of cash and tokens. Flexibility to work from anywhere in the world. Great employee perks! Benefits 💰 Competitive salary As we plan to attract and retain the best talents on the market, we offer enticing salaries, benefits, and development opportunities. If you are the right person for the job, there won’t be much to haggle. 🩺 Health Extremely comprehensive health insurance through Alan’s best plan. 🍎 Wellbeing Gym subscription contribution and a break room stocked with fresh fruit every day. 🏝Team Getaways Immortal Game getaways with the whole team to have fun and work together. ☀️Offices Enjoy our brand-new Paris office, full of natural light and awesome people! 🚲 Commuting Country-specific commuter benefits.","The Immortal Game, the world's first play-and-earn chess platform, is seeking an Analytics Engineer with experience in SQL data modeling using tools such as Snowflake or dbt. The position involves building and maintaining the data pipeline and models, analyzing data quality and performance issues, and defining and monitoring company KPIs. The company offers a competitive salary, comprehensive health insurance, gym subscription contribution, and other benefits with the flexibility to work from anywhere in the world. Fluency in French and experience with Fivetran/Stitch/Segment are desirable, as is prior experience in the video games analytics industry.",Bac +5 / Master,Entre 15 et 50 salariés,> 5 ans,3,1,0.05539549888311683
186,37138,https://www.welcometothejungle.com/fr/companies/owkin/jobs/data-engineer-semantic_paris_OWKIN_GQ696Dq,Data Engineer Semantic,Owkin,"{go,regard,color,owkin,via,Owkin}",Télétravail total possible,N,"Intelligence artificielle / Machine Learning, Big Data, Santé",CDI,2022-10-18,"Owkin exists to find the right treatment for every patient. Our focus is to use artificial intelligence to discover and develop better treatments for unmet medical needs, starting with the fight against cancer. In November, Owkin became a ‘unicorn’ - a startup worth more than $1 billion - through a $180 million investment from pharmaceutical company Sanofi. As a result, we are now looking for the brightest and best talent to help us to go even further in achieving our mission. About us Owkin exists to find the right treatment for every patient. Our focus is to use artificial intelligence to discover and develop better treatments for unmet medical needs, starting with the fight against cancer. In November, Owkin became a 'unicorn' - a startup worth more than $1 billion - through a $180 million investment from pharmaceutical company Sanofi. As a result, we are now looking for the brightest and best talent to help us to go even further in achieving our mission. Learn more about us About the role You will stablish a harmonized data management practice, specifically to manage data quality and delivery for internal and external projects, with the assistance of external experts when required.You will coordinate internal and external data throughout the whole life cycle (governance, curation, processing) In particular, you will: Evaluate and implement the structure and content of different standardization tools such as Common Data Models (e.g. FHIR, OMOP, PCORnet) or standard terminologies (e.g. SNOMED-CT, LOINC, ATC) Promote data quality by searching and properly evaluating sources of information to determine possible limitations in reliability or usability, apply sampling techniques to effectively determine and define ideal categories to be questioned Compare and analyze statistical information to identify patterns, relationships and problems Prepare detailed reports for management and other departments by analyzing and interpreting data Ensure project management for data delivery to ensure all projects can start in the timely manner, following phases of the implementation lifecycle using FAIR approach and classical project management lifecycle Manage external suppliers (like Clinical Research Associate profiles) for specific projects Train people on how to properly organize findings and read data collected Contribute to the maintenance of the Owkin’s Data Catalog on a functional data layer as well as maintain internal data knowledge to answer RFPs and by providing support to commercial teams on topics related to data (questions, studies…) Possibility to design or contribute to computer code using various languages to improve and update software and applications Position is based in the Paris or Nantes office, under the responsibility of the Data Platform Lead. The responsibilities missions described are not an exhaustive list; additional tasks may be assigned or the scope of the job may change as necessitated by business demands. About you Required qualifications / experience: Bachelor’s degree in mathematics, statistics, computer science or related field Experiences on Health Data management and FAIR principles, data governance, Common Data Models (CDMs) Knowledge of healthcare Information System and principles softwares Strong math and analytical skills are essential to complete job requirements successfully Ability to complete milestones and work toward multiple deadlines simultaneously Excellent multitasking skills and task management strategies Ability to use necessary databases and software Able to compile and organize statistical information retrieved and present findings to management Good level in English Preferred qualifications/bonus: Experience working with private and sensitive personal information Interpersonal and customer service skills are required when meeting with and interviewing potential clients What we offer Competitive salary & excellent benefits package Flexible work organization and access to remote work Friendly and informal working environment Opportunity to work with an international team with high technical and scientific backgrounds Recruitment Process & Security Please attach a cover letter and a CV. Owkin is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, sex, gender, sexual orientation, age, color, religion, national origin, protected veteran status or on the basis of disability. Owkin is a great place to work. Unfortunately, being a coveted workplace means we are vulnerable to recruitment phishing scams. We urge all job seekers and candidates to be wary of potential scams. Most of these have individuals posing as representatives of prominent companies, including Owkin, with the aim of obtaining personal, sensitive, or financial information from applicants. These scams prey upon an individual’s desire to obtain a job and can sometimes “feel” like a genuine recruitment process. Some red flags are identified below. Should you encounter a recruitment process that claims to be for Owkin but is not consistent with the below, please do not provide any personal or financial information: Legitimate Owkin recruitment processes include communication with candidates through recognized professional networks, such as LinkedIn. However, further communication is always through an official Owkin email address (from the @owkin.com domain), over the phone or though Recruitment platforms (WelcomeKit, talent.io, hidden.market, Fifty Talent or Hiresweet); Legitimate Owkin recruiters will not solicit personal data from candidates during the application phase including, but not limited to, date of birth, social security numbers, or bank account information; Legitimate Owkin interviews may be conducted over the phone, in person, or via an approved enterprise videoconferencing service (such as Google Meets or Highfive). They will never occur via Signal, Telegram or Messenger Legitimate Owkin offers of employment are based on merit and only extended once a candidate has interviewed with members of the hiring team. Offers will be extended both verbally and in written format. Owkin may request some personal information to initiate the hiring process, but this will be through protected means. If you think that you have been a victim of fraud, Check the identity of recruiters on LinkedIn and the website https://owkin.com/team/ Check the existence of the position on our website https://owkin.welcomekit.co/ Notify Owkin's recruitment unit at this address hiring@owkin.com contact the following authorities: [FR] https://www.internet-signalement.gouv.fr/ [UK] https://www.actionfraud.police.uk/reporting-fraud-and-cyber-crime [US] https://www.ftccomplaintassistant.gov/#crnt&panel1-1","Owkin, an AI-driven biotech startup focused on discovering and developing better treatments for unmet medical needs, is seeking a Data Manager to establish a harmonized data management practice, manage data quality and delivery for projects, evaluate and implement tools for standardization, and manage external suppliers. The ideal candidate will have a bachelor's degree in mathematics, statistics, computer science, or a related field, experience in health data management and FAIR principles, strong math and analytical skills, and the ability to use necessary databases and software. The position is based in Paris or Nantes, France, and offers a competitive salary and benefits package, flexible work organization, and an opportunity to work with an international team with high technical and scientific backgrounds. Owkin is an equal opportunity employer.",Bac +3,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
144,57083,https://www.welcometothejungle.com/fr/companies/sicara/jobs/data-engineer_paris_SICAR_qgQrRM5,Data Software Engineer - CDI - Paris,Sicara,"{Microsoft,Scala,AWS,Spark,Azure,Hadoop,Python}",Télétravail partiel possible,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"Sicara est une startup experte en data, basée à Paris : nous révolutionnons les projets data en combinant notre méthodologie agile de delivery de projet et notre savoir-faire en data science et data engineering afin d’aider nos clients à capitaliser sur le potentiel de la donnée. Filiale du groupe Theodo, un écosystème de 9 filiales et +400 personnes situées à Paris, Londres, New York et Casablanca, créée en novembre 2016 , Sicara est passée de 2 à 35 personnes en quatre ans. Pour soutenir notre croissance de 50%, nous cherchons à faire grandir notre portefeuille client. Régulièrement en contact avec les équipes techniques et les consultants Sicara seniors, nos AI Project Managers utilisent leurs compétences pour déployer la méthodologie projet de développement de solution en data science. Sur nos projets, tu seras amené(e) à : Analyser les données sources et échanger avec les experts métier afin d’identifier et évaluer des cas d’usage métier Travailler en équipe de 2 à 4 data software engineers épaulés par un coach agile et un coach technique Mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels) sur le cloud Déployer les pipelines de données (ETL et ELT) Assurer la migration des données vers les nouveaux environnements Mettre en place des outils de contrôle de la qualité de la donnée Accompagner et former les équipes clients Au sein de Sicara, tu seras amené·e à : Contribuer à notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog. Contribuer à améliorer nos savoir-faire en expérimentant continuellement de nouvelles méthodes et de nouveaux outils afin d’améliorer l’efficacité des équipes. Diplômé(e) d’une école d’ingénieur Tu as une forte appétence pour le secteur de la data et tu as idéalement une première expérience dans le conseil ou dans la tech Tu as une expérience passée en tant que Data Software Engineer Tu as envie de progresser et d’évoluer dans un environnement challengeant et bienveillant au quotidien Tu as une bonne connaissance de Python et tu as déjà utilisé des technologies Big Data (Spark, Scala, Hadoop) Tu connais ou as envie d’apprendre à utiliser l’un des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure) 1 entretien RH + 2 entretiens techniques + 1 entretiens dirigeants","The AI Project Manager at Sicara, a data startup in Paris, will work in a team of 2-4 data software engineers to implement data science solution development methodology. The candidate should have experience in data software engineering, knowledge of Python and Big Data technologies, and experience using cloud providers like AWS or Google Cloud Platform. The role involves analyzing data sources and working with business experts, deploying data pipelines, and ensuring secure data systems. The company offers a challenging and supportive work environment, with opportunities for learning and growth.",Bac +5 / Master,Entre 15 et 50 salariés,> 6 mois,2,2,0.05539549888311683
372,56964,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_london,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",Télétravail total possible,"Shoreditch High Street, London, E1 6","FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they’re given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We’ve raised over €260M from leading investors, and been named a French tech unicorn. And we’re not stopping there! About our people & culture We believe that people do their best work when they’re given the freedom to thrive and grow. That’s why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth — with benefits to match! -Fully covered Oyster card for traveling to and from our new office (up to £250 monthly depending on location) -£45 monthly wellness allowance, accruable, to be used on whatever wellness means to you - through the Ben platform - Access to Moka.care for emotional and mental health wellbeing - Pension scheme (on salary sacrifice): 5% employee / 5% employer (by Aviva) - 28 days of holidays - Latest Apple Mac equipment - Company virtual events - Visit our other offices: Paris, Berlin & Hamburg - Great office snacks to fuel your day - A positive team to work with daily! - Vitality private health insurance (for you and your family/partner) - Bupa private dental care Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk, a spend management platform for finance teams, is seeking an Analytics Engineer to join their team responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. The role involves designing, developing and maintaining the company's analytics infrastructure, including data pipelines, data warehousing and data visualisation tools to support reporting and analytics needs of the organisation. The ideal candidate should have at least 1-2 years of experience in analytics engineering, business intelligence or a similar role, with strong proficiency in SQL and experience with data modelling, ETL processes and data warehousing.",Non spécifié,Entre 250 et 2000 salariés,> 1 an,3,1,0.05539549888311683
370,56886,https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/data-engineer,Data Engineer,52 Entertainment,"{Deepnote,Airbyte,Prefect,Looker,Kubernetes,Prometheus,dbt,BigQuery,GCP,SQL,Github,Python}",Télétravail total possible,Villeneuve-D'ascq,Jeux vidéo,CDI,2023-03-26,"52 Entertainment is a leading e-gaming company, worldwide leader on the Online Bridge with recognized brands like Bridge Base Online , Funbridge , Exoty , Casualino and on the e-sailing thanks to its well known Virtual Regatta . One of the worldwide leader on a lot of e-mind and strategy games like Tarot, Canasta or Belote to name a few. At the crossroads of gaming, entertainment and e-sport 52 entertainment provides unique experiences to truthful communities. Based in France (Lille) with offices and people all around the globe 52 entertainment invents the tomorrow’s company based on People , Innovation and Mindset . Job description We are looking for a Data Engineer to join our Data Team. You will be responsible for developing, implementing, and monitoring the Data Pipelines of several games of the group . You will work inside the Data Team (1 Data Engineer, 2 Analytics Engineers, 4 Data Analysts, 1 Data scientist) and you will report to the Head of Growth and Data. We use a modern data stack that is primarily composed of Google BigQuery, dbt, Airbyte, Prefect, Deepnote and Looker . The Data Engineering activities focus on GCP, Airbyte, Prefect but also includes Prometheus, Thanos, Graphana tools and Kubernetes nodes management. Team description The Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia). The Data team is fully remote (but all the team is currently based in Europe). We are using top notch communication & project management tools (Slack/Jira/Confluence) and a fantastic stack of technical tools (Airbyte, Prefect, Google Big Query, dbt, Looker, …) . We talk to each other on a daily basis and organize frequent virtual coffees ☕️. Some are geeks, some are not, apply as you are, we’re a diversity-friendly team 🧕 👧🏽 🥷 👨🏿 👩 🦾. Stack Data: Airbyte, Prefect, Google BigQuery, dbt, Github, VSCode, Deepnote & Looker Project Management: Slack, Google Drive, Confluence, Jira Missions Create, monitor, and optimize Data Pipelines for existing Games and third-party sources. Manage relations with B.U. Developers and be proactive to prevent pipeline deprecation because of products evolution. Ingest third-party data and setup data consumption endpoints. Ensuring best practices for data integrity and performances. Investigate new initiatives like Data Cataloging, Data Discovery, ML Ops Provide our Data Scientists with Big Data tools that will allow them to process our data more easily (prediction, machine learning, …). We’re excited about you because… You’ve been hesitating between Dev Ops and Data Engineering for a while, but realized that the later was much more fun While you already have some experience in this role, you are passionate to learn even more and want to grow as an expert in a friendly team, while being coached by a senior Data Engineer. You can easily discuss technical concepts with other Dev Ops to help other teams create systems you will need to connect your pipelines to. You like to learn new concepts and tools and are not afraid of getting your hands dirty. Benefits Work in a start-up with exceptional growth Highly interesting work environment with flat hierarchies, fast pace and fun You’ll have a real impact on people’s lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development. Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best. Extreme autonomy. No micro-managing here. After onboarding, you’ll be given high-level direction and then left to solve it the way you feel is best. Amazingly friendly Data team. Your Profile Minimum 1.5 year of experience either in Data Engineering, Big Data or DevOps Familiar with modern data stacks and principles (cloud-based platforms/data-lakes and managed services) Skilled in SQL and Python Experienced in working in interdisciplinary teams and in multi-cultural team environments Strong communication skills and facilitation abilities Priorities management & time management skills Highly open minded Diplomacy, pedagogy and humility Fluent English. Collecting applications until April 7th 2023 First interviews from March 27th 2023 onward. Our hiring process is sequential : we know job seeking is a stressful time of life, and we’ll make sure things are transparent from our side. If you don’t pass step 2, we won’t waste your time on step3. Interview steps Step 1 Visio-call - Preliminary interview where the scope of mission, our company, your aspirations, and salary compensation are discussed to see if we agree on the important things on both sides (30 min) Step 2 Written case-study - Few questions to check that written communication is clear Step 3 Technical case-study - Skills check (take home assignment) on some data problems (no more than 2 hours of involvement) Step 3 Visio-call - Debrief from assignment + Experience and background discussion to get to know you and your experience in Data. Interview questions will be sent ahead of time.","52 Entertainment, a leading e-gaming company, is hiring a Data Engineer to work on developing, implementing, and monitoring the Data Pipelines of several games. The successful candidate should have experience in either Data Engineering, Big Data, or DevOps, be skilled in SQL and Python, have strong communication skills, and be familiar with modern data stacks and cloud-based platforms. The Data team is fully remote and uses top-notch communication and project management tools. The company offers flexibility, autonomy, and a friendly team environment with opportunities for personal and professional growth.",Non spécifié,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
330,49657,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote-uk_london,Software Engineer Data Presentation - Remote UK,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",Télétravail total possible,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer with experience in software development and an interest in data visualization tools. The ideal candidate is customer-oriented, at ease with both frontend and backend development, and has firsthand experience building a real product. The engineer will work with a team to create usable, intuitive, and beautiful interfaces for Dataiku DSS and will prototype new ways to interact with data or integrations with other products. Dataiku's culture offers flexible work-life balance, autonomy, and opportunities to learn from colleagues. They value diversity and are an equal opportunity employer.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
153,56458,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-engineer-adot_saint-denis,Data Engineer - Adot,Veepee,"{Node,Docker,React,MongoDB,Pytorch,Trino,Kafka,Presto,Git,ScyllaDB,Postgres,Akka,AWS,scale,RabbitMQ,Java,SQL,Hadoop,Redis,spark,Scala,Airflow,dbt,Druid,Spark,GraphQL,Python,Tableau}",Télétravail total possible,"249 Avenue du Président Wilson, Saint-Denis, 93210","Application mobile, E-commerce",CDI,2023-03-26,"In 2001, the vente-privee concept was born. Based on the simple but revolutionary idea of transforming the old stock clearance business through digital technology. Back then, the e-commerce was just starting up in Europe, vente-privee set up a digital platform, so that major brands could sell their stock at greatly reduced prices in an attractive environment that protected their image. Vente-privee invented the digital model of event-driven sales, and became a pure player retailer that completely disrupted retail codes in its historical sector: fashion. In 2019, vente-privee changed its name, becoming a European brand: Veepee. The site thus asserted its position as the European leader in online event-driven sales. Every day, the Veepee website offers its members access to these sales. Ready-to-wear, fashion accessories, home equipment, toys, sports articles, high-tech, gastronomy products and more are sold in limited quantities for a certain period (between 3 and 5 days) at significant discounts, with a high-quality presentation. By 2022, Veepee had over 66 million members in ten countries around the world. This success is due to a constant quest for innovation, creativity and quality in terms of both offer and service, under the leadership of Jacques-Antoine Granjon. “Our mission is to create an event every day, to maintain that spark of desire.” A tried and tested recipe that is now being copied on a global scale. But because innovation and diversification are important to Veepee, they constantly reinvent it, with connected business, Brandsplace, second-hand goods, etc. Veepee’s pioneering and entrepreneurial spirit continuously drives it to develop and create new activities like Re-cycle and Re-turn, which prove its determination to combine profitable growth with social and societal responsibility. 20 years after its creation, Veepee was the first French unicorn to cross the €1 billion threshold in turnover in 2014 – without ever resorting to fundraising. Veepee occupies a prominent place in the French Tech landscape, and is again one of the Next 40, for the fourth year running. The group now has a workforce of 5,500 in 10 countries and posted a turnover of €3.2 billion in 2021. The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee . With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Le groupe vente-privee a regroupé ses différentes marques européennes, composées de 6000 employés, au sein d'un conglomérat unifié : Veepee . Avec Privalia, vente-exclusive, Designer & Friends, Eboutic et vente-privee, Veepee a réalisé un chiffre d'affaires de 3,7 milliards d'euros en 2018. Présent dans 14 pays désormais, Veepee prend une place prépondérante dans le paysage européen du commerce digital. Adot, filiale de veepee, est une solution marketing, possédant un DSP propriétaire permettant à ses clients (annonceurs) de diffuser de façon ciblée, leurs campagnes publicitaires. Grâce à notre DMP propriétaire nous utilisons aussi nos données pour réaliser des études marketing. 📄 DESCRIPTION DU POSTE Nous cherchons une personne intéressée par le stockage, le traitement et l’analyse de données volumineuses (10 To bruts par jour, 500 000 requêtes par seconde), que ce soit en batch ou en streaming. 🎯 MISSIONS Au sein de l’équipe Data, vous serez amené.e à travailler directement avec les Data Engineers, Scientists, Analystes. Vous aurez également une relation privilégiée avec l'équipe Dev. Vous serez confronté.e à nos différentes problématiques : Ingestion, formatage et contrôle de la qualité des données en temps réel et en batch, venant de partenaires ou d’autres équipes Adot, avec différentes contraintes (at most once ou at least once, selon l'importance de la source) Développement de services autour de la donnée Mise à disposition des données aux différentes équipes Automatisation des agrégations et analyses de données Gestion de l'infrastructure de l'équipe Data Revues de code, intégration continue ⚙️Notre stack actuelle Pipeline de données : Spark, dbt, Scala, Kafka, Airflow, Akka, Python, Presto/Trino, Pytorch Dataviz : Tableau Cloud : AWS Mais aussi : Node.js, React, Redux, GraphQL, Druid, ScyllaDB, MongoDB, Postgres, Redis, Docker, Nomad, Consul, Terraform, Ansible,... 👉 PRÉ REQUIS Vous avez de bonnes connaissances en Python & SQL Vous avez des notions en Scala et/ou Java Vous portez un intérêt pour Spark Vous maitrisez les systèmes de stockage distribués, leurs avantages et leurs contraintes Vous connaissez les pratiques classiques de software engineering : usage de Git et pratique de code reviews, culture du test, CI/CD. Vous êtes responsable de votre code de l'IDE jusqu'à la prod Vous êtes très curieux·euses et aimez être à la pointe en faisant régulièrement de la veille technologique. 👉 LE PETIT PLUS Vous avez travaillé sur un projet à forte volumétrie et/ou dans un environnement Spark/Hadoop Vous avez travaillé avec Kafka ou une file de message telle que RabbitMQ ou ActiveMQ Vous avez déjà travaillé avec dbt Vous êtes familier des plateformes cloud, si possible AWS Vous avez déjà travaillé avec Airflow Vous aimez travailler en collaboration avec des profils différents du vôtre et partager vos connaissances Vous aimez faciliter et automatiser les tâches répétitives ✅ AVANTAGES Un environnement enrichissant et humain Vous apprendrez beaucoup de choses techniques mais pas seulement Un environnement de travail stimulant avec de nombreux projets et innovations Politique de télétravail pouvant aller jusqu'à 3 jours par semaine Un parcours d'intégration complet pour rencontrer l'ensemble des équipes et être formé sur son poste et aux process internes Une qualité de vie au travail : budgets team building, cours de yoga, sensibilisation à la santé mentale, événements internes de cohésion... ❓ WHO WE ARE Veepeeᵀᵉᶜʰ is a part of Veepee and one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you’ll be sure to find your place, no matter the technology you want to work with. If you love to try things why don’t you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, and to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, a European online retailer, is seeking a Data Engineer with experience in handling large volumes of data in both batch and streaming. The successful candidate will work closely with Data Engineers, Scientists, Analysts, and the Dev team to develop services around data, handle infrastructure, automate data analysis, and manage the data pipeline. Proficiency in Python and SQL, familiarity with Scala and Java, and knowledge of Spark and distributed storage systems are required. Experience with Kafka, dbt, Airflow, and cloud platforms is preferred. Veepee offers a stimulating work environment with opportunities for growth, telecommuting up to three days a week, and various benefits.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
307,56462,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_berlin,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",Télétravail total possible,Berlin,"FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they’re given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We’ve raised over €260M from leading investors, and been named a French tech unicorn. And we’re not stopping there! About our people & culture We believe that people do their best work when they’re given the freedom to thrive and grow. That’s why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth — with benefits to match! - 100% reimbursed public transport to the office or bike perk of 30 Euro - Latest Apple equipment (MacBook Air) - 28 days of annual leave - Monthly budget of €50 for wellness-related spending - Access to Moka.care (platform for emotional and mental well-being) - A friendly remote policy - 3 days onboarding trip to Paris & access to our other offices across Europe - Great office snacks to fuel your day - A positive team to work with daily! Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk is looking for an Analytics Engineer to join their data team and build the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. The responsibilities of the role include collaborating with stakeholders to identify business requirements, developing and maintaining ETL processes, designing and developing data models, leading data governance initiatives, and monitoring and troubleshooting issues with the infrastructure. The ideal candidate should have at least 1-2 years of experience in analytics engineering or business intelligence, strong proficiency in SQL, knowledge of database design, optimization, and maintenance, and experience with data modeling, ETL processes, and data warehousing.",Non spécifié,Entre 250 et 2000 salariés,> 1 an,3,1,0.05539549888311683
121,73599,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-scientist-environnement-full-teletravail_MD_1lgk0dx,Data Engineer / Scientist - Environnement - Full télétravail,MP DATA,"{Postgres,GCS,Azure,Django,SQL,Kafka,Spark,MongoDB,AWS,Git,S3,Snowflake,Java,GCP}",Télétravail total possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-04-22,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance, l’exploitation de leur données et leur décarbonation. Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français. MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences. Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort, et des possibilités d’évolution intéressantes. MP DATA, recrute un(e) Data Scientist avec des affinités pour le métier de Data Engineer (H/F) afin de travailler pour un client, acteur majeur du secteur de la santé à Paris. Vous serez amené à intervenir sur plusieurs problématiques notamment : travail des données, développement d’algorithmes de machine learning, déploiement de ces algorithmes. Tout cela autour de cas d’usages industriels à forte valeur ajoutée et impact environnemental positif. Accompagné par un Lead Data Scientist et un Lead Data Engineer, vous monterez en compétences sur : le management des flux de données (pré processing, feature engineering…) ainsi que la mise en place et l’industrialisation de ces modèles de machine learning. Les seniors vous guideront step by step dans l’utilisation de ces nouvelles technologies. Ingénieur d’une Grande École, vous avez des connaissances en machine learning acquises lors de votre scolarité ou de vos expériences passées (stage ou césure). Votre autonomie, votre capacité à être force de proposition et votre esprit de synthèse ont été reconnues durant vos précédentes expériences (stage ou césure). Vous êtes intéressés pour vous dépasser en data science & data engineering et vous avez des premières expériences dans ce domaine, comme par exemple : C/C++ / Java / Rust Spark Kafka Cloud : AWS / GCP / Azure Technologies de stockage : Snowflake / S3 / GCS / Azure Blob Django / Flask Git SQL : Postgres / MongoDB CI/CD. Alors venez grandir avec nous !",,Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,3,1,0.05539549888311683
345,34212,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris-or-remote-france_paris,Software Engineer Data Presentation - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",Télétravail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do : We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do : With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if : You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. (Note: This is a Software Engineering job. We have separate Data Scientist positions open) Dataiku’s culture is right for you if : You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer with experience in data visualization tools to create usable, intuitive, and beautiful interfaces and scalable engines for Dataiku DSS. The ideal candidate should be customer-oriented and comfortable with both frontend and backend development, with firsthand experience building real products. The position offers autonomy, flexible work-life balance, and a commitment to diversity, equity, and inclusion. Dataiku's technical stack includes Javascript, AngularJS, Angular, D3.js, Java, Spring, and Python.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
342,56340,https://www.welcometothejungle.com/fr/companies/thales/jobs/s3ns-site-reliability-engineering-engineer-data-platform-f-h_paris,S3NS -  Data Platform Engineer,Thales,"{durable,shell,Go,Git,Kubernetes,Docker,Spanner,Linux,Unix,GCP,Java,NoSQL,Python}",Télétravail total possible,Paris,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? S3NS est né du partenariat industriel entre Thales, leader mondial de la cyber sécurité, et Google Cloud, leader mondial des solutions cloud. Nous avons pour ambition d’offrir le meilleur des deux mondes à l’ensemble des organisations soucieuses de protéger leurs données sensibles (institutions publiques, OIV, OSE…). C’est-à-dire une solution équivalente à Google Cloud Platform (incluant à la fois les services IaaS et PaaS de GCP) et respectant les exigences du label SecNumCloud. Une première offre, ‘Contrôles locaux avec S3NS’, est déjà disponible depuis juillet 2022 pour permettre à nos clients de bénéficier d’un premier niveau de transparence et contrôles additionnels, et d'accélérer la trajectoire vers le cloud de confiance. QUI ETES-VOUS ? Vous êtes passionné(e) par l’innovation technologique, le Cloud et les déploiements de services et d’infrastructure “as code” ? Vous aimez opérer des systèmes critiques de grande envergure ? Diplômé d’école d’ingénieur vous justifiez d'une expérience reconnue sur des marchés régulés (secteur bancaire/médical…) avec une exposition internationale. Vous justifiez de 5 ans d'expérience minimum dans le software engineering, l’automatisation, et le développement (Sécurité et conformité, Automatisation, Résolution de problèmes). Vous avez une expérience de migration d’infrastructure privée ou hybride vers le cloud. Vous maitrisez : Un ou plusieurs des langages suivants : C, C++, Java, Python, Go Les chaînes de valorisation de données incluant les aspects fonctionnels (Collecte et transport hétérogènes et/ou nombreuses, le traitement -normalisation, enrichissement, corrélation, analyse - maintenance prédictive, détection d’anomalies, clusterisation - notification, … “temps-réel” et/ou “batch”), le stockage, archivage, indexation et l’exposition, exploration des données. Les aspects techniques d’infrastructure sous-jacente, file de message, BD relationnelle, BD NoSQL, stockage objet,orchestrateurs et moteurs de traitements (pipeline, machine learning, IA), outils de visualisation et d’exploration Les aspects opérationnels tel que le MCO, de Sécurité et de Modernité de la solution, intégrité, confidentialité, haute disponibilité, élasticité, utilisabilité Les technologies de containerisation (ex. Docker, Kata Containers) et d’orchestration (ex. Kubernetes, Swarm), d‘hébergement Open Source (Linux, Docker, Kubernetes, Openstack) A minima un cloud public (ex. GCP) Les OS Linux / Unix et langages de scripting shell Les pratiques du SRE (Infra-As-Code, Git, Continuous Deployment, Terraform, Ansible) CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : En intégrant l’équipe, vous serez dans un premier temps contributeur de la construction d’une stack data pour délivrer les services du Cloud de Confiance: design, définition SLO/SLI, mise en œuvre des services, tests, etc. Vous bénéficierez d’une latitude importante quant aux choix effectués dans ces phases de design et d'implémentation. En partenariat avec Google, vous pouvez bénéficiez d’un parcours de formation accéléré et intense sur les technologies GCP, afin d’être parfaitement formé à la stack technique de Google (ex. Borg, Colossus, Spanner). En tant qu' Engineer Data Platform , vos missions seront les suivantes : Mettre en œuvre et opérer en respectant l'état de l’art de la cyber sécurité toutes les solutions et/ou outils afin d’améliorer l'offre Plateforme Cloud de Confiance : depuis l’architecture, le développement, le déploiement, jusqu’aux opérations d’infrastructure. Contribuer au design, au développement et à l’intégration des solutions d’automatisation et de suivi des infrastructures afin de nous permettre une mise à l’échelle de nos opérations sensibles et processus critiques de hautes disponibilités. Identifier, initier, développer une boucle d’amélioration continue pouvant être déployée rapidement. Participer à la construction de chaînes de valorisation de données permettant d’implémenter nos Trust Services ET opérer les services data et IA de Google dans un environnement Cloud de Confiance Intéressé(e) Rejoignez-nous!","Thales is seeking an Engineer Data Platform with experience in software engineering, automation, and development, and exposure to regulated markets such as banking or healthcare. The ideal candidate should have a minimum of five years' experience in the migration of private or hybrid IT infrastructure to cloud. They should be proficient in at least one programming language such as C++, C, Python, or Java, have knowledge of containerization, orchestration technologies, and Linux/Unix, and have experience with security and compliance. The role's responsibilities will include working with Thales and Google to build secure cloud platforms and data handling systems for clients.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
306,34611,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-paris-or-remote-france_paris_DATAI_3Nw4a3o,Software Engineer Data Preparation - Paris or Remote France,Dataiku,"{Python,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Jupyter}",Télétravail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings, to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly visual interfaces or code. To help us fulfil this mission, we are looking for a talented fullstack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers such as: - Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, '¦ and processing data using the latest processing engines: Spark on K8s, SQL with UDFs - SQL workbench & Jupyter notebooks - Integration with IDEs - Help and onboarding experience - Plugins infrastructure - Automation & public REST APIs Our current technical stack is based on a mix of Java, Javascript and Python. What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphical explain plans in our SQL workbench (Note: This is a Software Engineering job. We have separate Data Scientist positions open) You are the ideal recruit if: You have experience in software development and are interested in data processing You are customer-oriented '” you want to understand how the product is used and solve actual customer problems You know Data science is 80% preparing data and 20% complaining about preparing data You are curious about working 'œunder the hood' and want to learn how things are built You have firsthand experience (either professional or personal) building a real product You are humble and kind You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku, a New York City-based provider of a platform which automates AI, requires a full-stack software engineer, who will be responsible for developing Dataiku's data-preparation, integration and core features. The successful candidate should be customer-orientated, curious about working behind-the-scenes, and have worked on a real-life project before.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
347,56354,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-h-f_bordeaux_NEXTO_0L3eOd,Data Engineer -,NEXTON,{powerBI},Télétravail total possible,Bordeaux,"Design, IT / Digital, Digital",CDI,2023-03-26,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, Nexton connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, professionnalisme et performance. Et pour vous ? Notre politique de développement des compétences dynamique saura vous séduire avec un programme de suivi de carrière sur-mesure. NEXTON, leader du conseil digital opérationnel recrute un Data Engineer H/F , en CDI , à Bordeaux ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, Nexton connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance. Et pour vous ? Notre politique de développement des compétences dynamique saura vous séduire avec un programme de suivi de carrière sur-mesure. Le contexte: Vous évoluez au sein d'une squad agile qui gère l'ensemble de l'outillage des postes de travail et smartphones de notre client grand compte (secteur bancaire) et de ses filiales. Vos missions : Participer au montage d'un datalake / Datawarehouse, Elaborer le dossier d'architecture, Analyser les données en fonction des besoins utilisateurs, Mettre en place l'outil powerBI et le configurer, Contribuer à la mise en place d'API pour offrir de la donnée aux utilisateurs en ayant besoin, Concevoir les architectures et les combinaisons technologiques qui permettent de résoudre les problèmes identifiés, Configurer les solutions big data appropriées aux équipes. Vous avez étudiez les systèmes d'informations, la Big Data ou le traitement de données lors d'un parcours supérieur de type école d'ingénieurs (BAC+5). Votre capacité à régler des problèmes techniques complexes et votre autonomie dans le recherche de solutions liées à la Big Data font partie de vos qualités professionnelles. Vous travaillez de manière autonome dans un contexte agile, un minimum de quatre années d'expériences sur un poste de data engineer est nécessaire pour être opérationnel sur ce poste. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'année : - Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'année - Des moments privilégiés avec votre manager Prêts à nous rejoindre ? Rencontrons-nous !","Nexton, a company specialized in digital transformation, is hiring a Data Engineer with a minimum of four years of experience in a similar role to join their agile team in Bordeaux. The successful candidate will participate in the development of a Data Lake/Datawarehouse, build the architecture dossier, analyze data based on user needs, configure PowerBI, and contribute to the implementation of APIs. The ideal candidate should have a degree in Information Systems, Big Data, or Data Processing and possess problem-solving skills related to Big Data. Nexton offers career advancement opportunities and networking events throughout the year.",Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
123,72226,https://www.welcometothejungle.com/fr/companies/inato/jobs/data-engineer_paris,Data Engineer,Inato,"{Airbyte,Looker,PostgreSQL,Airflow,Kubernetes,dbt,scale,MixPanel,BigQuery,GCP,SQL,Python}",Télétravail total possible,"14, Boulevard Montmartre, Paris, 75009","Logiciels, Pharmaceutique / Biotechnologique, Santé",CDI,2023-04-08,"Inato is a tech-for-good company striving to bring clinical research to each and every patient across the globe. To do this, they are building the world’s first clinical trial marketplace designed to improve visibility, access, and engagement across a more diverse population of doctors and their patients. Drug development is a complex and rewarding endeavor: their platform enables sponsors and community-based researchers to work together when developing effective treatments for diseases affecting millions of people. WHO WE ARE Inato is a Tech for Good company striving to bring clinical research to each and every patient, regardless of who they are or where they live. To do this, we are building the world's first clinical trial platform to create greater visibility, access, and engagement across a more diverse population of doctors and their patients. Drug development is a challenging, intellectually complex, and rewarding endeavor : we enable global pharmaceutical companies to confidently partner with community-based researchers to increase patient access to the latest medical innovations. The platform currently offers clinical trials from leading companies to over 1,000 sites across the globe. And we are well poised for growth in 2023. We are a growing team of passionate pharmaceutical experts, software engineers, professional services members, and many more - all bringing their unique perspective to solve the challenges facing clinical research. Our team members live by our company values to be bold, resilient, caring, and pragmatic. If this sounds like you, join us! The role We are seeking an experienced Data Engineer to join our fast-growing data team. In this role, you will play a critical part in helping us build a scalable data infrastructure that supports the data team's mission to provide high-value analysis and tools to Inato’s team so they can make faster and better data-driven decisions. This is an exciting opportunity to make a meaningful impact in a small and dynamic team that is changing the face of the industry. Our stack includes Google BigQuery, Segment, Airbyte, Looker Studio, Husprey, Retool, dbt, MixPanel, and more. 💊 Responsibilities Design, build and maintain our data pipelines and infrastructure to ensure efficient and reliable data ingestion and processing. Collaborate with the Data and Product team to expose data to the product and implement machine learning models into production. Monitor and troubleshoot our data infrastructure to ensure maximum uptime and performance. Work with cross-functional teams to ensure data availability, quality, and consistency across the organization. 💊 Requirements 3+ years of experience in data engineering, with experience in building and maintaining data pipelines at scale. Strong experience with data processing languages such as Python and SQL. Experience with database technologies such as PostgreSQL. Familiarity with cloud-based data infrastructure and storage, preferably GCP. Experience with ETL/ELT tools such as Airflow, Segment, Airbyte Familiarity with infrastructure tools such as Terraform, and Kubernetes. 💊 Perks Remote-first philosophy & flexible hours Amazing office in Grands Boulevards, Paris where you can meet with colleagues if this is important for you Top-of-the-line equipments Compensatory time (RTT) Free health insurance (Alan Blue, 100% paid by Inato) Meal vouchers (Swile) Contribution to healthy activities (Gymlib) Free books & learning material Inato is an Equal Opportunity Employer for any minority, disability, gender identity, or sexual orientation.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
114,57114,https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer_bruxelles,Data Engineer,LittleBigCode,"{GCP,Mongo,Scala,AWS,Kafka,Cassandra,R,Spark,Azure,SQL,Hadoop,Python}",Télétravail total possible,"54, Avenue Louise, Bruxelles, 1050","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"LittleBigCode is a digital consulting laboratory specializing in Data and Artificial Intelligence. Our mission is to democratize the use of these technologies by co-building useful applications with our customers for the Society of the future, particularly on subjects related to health, mobility or the environment. For this, we deliver turnkey projects and also work on consulting assignments while developing our own solutions. Finally, we combine Cloud technologies, AGILE methods and DevOps culture to facilitate industrialization and scaling up. Our big success so far: A community of more than 40 enthusiasts of Data Science & Data Engineering domains International presence & missions – we are launching our new office in Belgium! Workshops, Innovation contests, customers challenges taken up As such, we are looking to build our technical team in Belgium ! Join us ! What will be your tasks with us? Concretely on a daily basis, you will work in AGILE mode and as a team (made up of Data Scientists, architects, Devops coach, etc.). You’ll support our customers on their Data, delivery & release challenges. You will be working in the following areas: Consulting & expertise among our customers on their strategic projects: Analyze our customers’ strategic challenges around Data issues Make your contribution to define their ambitions and their Data roadmap Audit & projects framing (architecture, methodology, code quality) Achievements/ support of projects that involve Data centric architecture set up R&D and Solutions: Participation in the development of internal solutions Proposal and creation of innovative solutions Who are you? You have a Master in engineering (Computer Science, Mathematics, Statistics…) and you have some experiences as a Data Scientist! You have some relevant programming experiences, and you are familiar with Big Data technologies such as Spark, Hadoop, Kafka, Cassandra, Mongo among others You are fully proficient with the following languages: Python, SQL (if possible, Scala) You are familiar with data services of at least one major Cloud Provider (Azure, AWS, GCP) and with the different Database types You are strong on data structuration & modulization concept You are familiar with ETL use & set up Note that we are also big devotees of DevOps so the more you are comfortable with it, all the better! Fluent in English + in Dutch and/or French","LittleBigCode is seeking a Data Scientist who will join their technical team in Belgium. The ideal candidate should have a master's in engineering with relevant programming experience and expertise in Big Data technologies such as Spark, Hadoop, Kafka, Cassandra, and Mongo. They should also be proficient in Python, SQL, and Scala and have familiarity with data services of major cloud providers. Additionally, the candidate should be familiar with ETL setup and have strong data structuration and modulization concept skills. The candidate should also have experience in consulting and expertise, audit and project framing, R&D, and solutions development. Fluency in English and Dutch or French is required.",Bac +5 / Master,Entre 15 et 50 salariés,Non spécifié,3,1,0.05539549888311683
341,34770,https://www.welcometothejungle.com/fr/companies/mediaperformances/jobs/data-engineer-f-h_courbevoie,Data Engineer,Médiaperformances,"{Javascript,Beam,Git,Collibra,Tableau,PowerBI,Snowflake,via,GCS,Bigquery,GCP,Sql,SQL,Python,Datastudio}",Télétravail total possible,Courbevoie,"Média, Grande consommation, Publicité",CDI,2022-08-08,"Depuis plus de 35 ans, Médiaperformances aide les marques de grande consommation à développer leurs ventes dans les enseignes de la grande distribution alimentaire. Ils mettent en place des campagnes publicitaires omnicanales à destination des personnes qui font leurs courses (les shoppers) pour influencer leur comportement d’achat. Ils proposent des média en magasin et aussi en digital : des campagnes publicitaires achetées en programmatique et ciblées grâce à de la data comportementale, des applications mobiles, des bons de réduction dématérialisés, des écrans digitaux, etc. Le métier de Médiaperformances évoluant en même temps que les comportements d’achat, ils doivent toujours suivre les tendances et s’adapter aux évolutions de la consommation. En 2022 et pour la troisième année consécutive nos collaborateurs nous ont élus “Great Place To Work” officialisant ainsi qu’il faisait bon travailler chez Médiaperformances. Nous sommes engagés depuis plusieurs années dans un démarche RSE volontariste. D’abord en définissant notre raison d’être “promouvoir via nos médias une consommation plus responsable” puis en étant certifiés B Corp, la certification internationale qui répond aux standards les plus élevés en matière de performances sociale, sociétale et environnementale. Au cœur de cette stratégie d’accélération digitale, le Data Engineer aura un rôle central. Il aura, en effet, pour missions principales de : Participer à la conception et à la construction de notre plateforme de données Construire des pipelines de données en ayant recours à différentes technologies et langages (Python, Sql, Beam …) Assurer la qualité des données collectées, préparer et optimiser le stockage et le chargement, Travailler de pair avec nos data scientists pour optimiser la performance de nos projets et développer de nouveaux cas d’usage Assurer et améliorer le monitoring des différents flux déjà existants en mettant en place des processus d’automatisation et d’industrialisation Assurer le Cataloging des données au sein de la plateforme Définir des KPIs et créer des tableaux de bord de coût et d’utilisation Il sera amené à collaborer avec différents services dans l’entreprise : La DSI, les développeurs de nos filiales, le trading desk, ainsi que des partenaires extérieurs retailer et GAFAM… Il dépendra du Chief Data Officer, direction de l’accélération digitale. Vous êtes passionné par le domaine de l’informatique et la data et avez déjà une expérience sur des enjeux data engineering et big data sur un environnement cloud. Vous avez une grande capacité à recueillir le besoin, le designer et le mettre en place. Les problématiques retail, marketing client et médias ne vous sont pas étrangères. • Vous êtes diplômés d’un minimum BAC +5 d’une école d’ingénieur ou d’un master dans un domaine connexe à la data. • Vous êtes Automne. Vous savez vous adapter (notamment pour assurer la gestion multi projet) et faites preuve de curiosité. Votre expérience : Vous justifiez d’au moins 2 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…) Vous disposez de solides connaissances sur les architectures de données et le cloud. Vous êtes certifié et/ou avez de l’expérience sur l’environnement cloud GCP (Bigquery, GCE, Cloud run, Source repository, GCS, data proc, data flow) Vous avez de solides compétences en Python, SQL Vous avez une bonne connaissance des processus et outils de développement modernes (DevOps, Terraform, Git, CI/CD…) ; Vous connaissez un ou plusieurs outils de cataloging et de data lineage (Collibra, Dataedo, etc) Les plus : Vous disposez d’une expérience en visualisation de données démontrée sur un outil au moins (Datastudio, PowerBI, Tableau) Vous maîtrisez Javascript, compréhension des API Vous avez travaillé avec des solutions du type DMP/CDP, Snowflake Médiaperformances s’engage dans l’insertion des personnes en situation de handicap et traite l’ensemble des candidatures dans le respect des grands principes de non discrimination.","Mediaperformances is seeking a Data Engineer to help build its data platform and construct pipelines using different technologies and languages. The successful candidate must have at least two years of experience in data engineering, solid knowledge of data architectures and cloud, and be familiar with Python, SQL, and development tools. A degree in engineering or a data-related field is required. Experience with data visualization tools and DMP/CDP solutions is a plus. The company is committed to non-discrimination and welcomes applications from candidates with disabilities.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
111,34563,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-dataiku-online-paris-or-remote-france_remote,Software Engineer Dataiku Online - Paris or Remote France,Dataiku,"{React,go,Dataiku,python,regard,Kubernetes,dataiku,Docker,Python}",Télétravail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online’s team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku subscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is either at the company HQ in Paris (Gare de Lyon) or remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented — you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: Hands-on expertise working with Docker and Kubernetes Experience on an high availability SaaS Knowledge in DataScience, AI and Machine Learning Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking an experienced developer with interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. The platform consists of a cloud infrastructure and a launchpad where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources, and manage the Dataiku subscription. The ideal recruit should have experience working on a full-stack application, building a real SaaS portal, and understanding the customer's needs. Bonus points for those with hands-on expertise working with Docker and Kubernetes, knowledge in Data Science, AI, and Machine Learning, advanced knowledge in Python, and Vue.JS. Dataiku culture promotes work-life balance, autonomy, and caring for their employees.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
291,56997,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/data-engineer-f-h_la-defense_INGNI_z7g6P2,Data Engineer -,Ingéniance,"{GCP,Redis,Scala,Kubernetes,AWS,Storm,Cassandra,Hadoop,Azure,Java,NoSQL,SQL,Python,Cloudera,docker}",Télétravail total possible,La Defense,IT / Digital,CDI,2023-03-26,"Ingéniance, est une société de conseil spécialisée dans des projets liés aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajoutée en associant innovation technologique, transformation digitale, expertise métier (Banque, Finance et Assurance) & méthodes agiles. Technology-oriented, elle offre une réelle expertise à ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l’Agilité. Son projet d’entreprise s’appuie aussi sur des valeurs humaines, sociétales et environnementales (Label EcoVadis Gold). La proximité, la performance, la convivialité et le progrès sont des atouts sur lesquels elle bâtit sonévolution collective au quotidien. Quelles seront vos missions ? Vos missions s'inscrivent dans un contexte de travail Agile, au sein du centre d'expertise Data en charge du développement et de la gestion des systèmes de collecte, normalisation croisement et restitution des données. Dans ce cadre, vous contribuerez à : Développer de nouveaux pipelines de données (ingestion, traitement, stockage) Développer des moyens de restitution de la donnée (APIs, génération fichier, autres...) Industrialiser et automatiser les tests des APIs (Swagger, Postman, ...) Développer des moyens de parallèlisation des processus (Apache Storm, Multithreading, ...) Définir les bonnes pratiques de développements sur le cloud (AWS, Azure, GCP, ...) Rédiger la documentation nécessaire au partage et à la maintenance du code Faire partie d'une équipe agile et suivre la méthodologie Scrum Qui êtes-vous ? Entre 5 et 10 ans d'expérience en développement dont au moins 3 sur un programme DATA Vous maîtriser un langage de programmation (Java, C#, Scala, Python) Vous êtes à l'aise avec les architectures distribuées ou sur le cloud et leur mise en place. Vous avez de solides connaissances en SQL ainsi que sur des bases de données NoSQL (Mango, Redis, Cassandra) Vous avez déjà travaillé avec des outils de conteneurisation comme docker et d'orchestration tel que Kubernetes Enfin vous avez déjà implémenté des solutions dans le cloud (AWS, Azure, GCP...) Les compétences que vous renforcerez : Vous interviendrez sur la conception et le déploiement d'environnements « clusturisés » de type Datalake (Hadoop/Cloud & distributions Hortonworks, Cloudera) Vous pourrez vous confronter et contribuer à une communauté d'experts Vous accompagnerez les équipes de Datascientist, d'experts du Machine Learning et des approches statistiques, sur des projets de mise en oeuvre de ces approche s et du traitement des données associées. Vous évoluerez dans un environnement fonctionnel riche","Ingéniance is seeking a Senior Data Engineer with 5-10 years of experience in Java, C#, Scala, Python, and related cloud technologies such as AWS, Azure, and GCP. The successful candidate will be responsible for developing data pipelines, building data ingestion and storage solutions, and implementing NoSQL databases. The job entails working in an Agile environment and following Scrum methodology. The role is focused on developing new pipelines, creating means of data restitution, automating testing, and parallelizing processes.  The successful applicant will work within Ingéniance's Data Excellence Centre team, supporting the development and management of data collection, cross-checking, and restitution systems.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
333,57164,https://www.welcometothejungle.com/fr/companies/javelo/jobs/data-engineer_paris,Data Engineer,Javelo,"{CircleCI,React,Ruby,Airbyte,DBT,AWS,Snowflake,Docker,Elastic,Datadog,SQL,Github,Python,Postgres,Tableau}",Télétravail total possible,"26 rue Henry Monnier, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Vous avez déjà entendu que les “RH ne sont pas compétents” et que de nombreux managers ne traitent pas leurs collaborateurs à “leur juste valeur” ? Nous aussi. Pourtant, les managers et RH ne manquent ni de compétences, ni de volonté… Simplement d’outils efficaces ! Chez Javelo, nous proposons une plateforme SaaS permettant aux RH de mettre en place des rituels managériaux réguliers. Tout ça pour quoi ? Pour échanger un feedback objectif et individualisé… Et permettre à chacun de s’épanouir dans un environnement de travail sain ! C’est ça l’ADN de Javelo : beaucoup de feedbacks et de transparence pour permettre à chacun d’évoluer et atteindre nos objectifs ambitieux ! Le tout dans une entreprise qui a a coeur de maintenir un environnement de travail sain et convivial :) Au sein de l’équipe tech et produit, tu as un rôle clé dans la valorisation et le partage de la donnée business et produit en interne. ✔ ️Pourquoi nous rejoindre? Tu auras une forte responsabilité dans la construction d'une application utilisée par des centaines d’entreprises de 300 à 20.000 collaborateurs. Tu travailleras au sein d’une équipe à taille humaine Tu auras une grande autonomie dans le choix de tes approches et outils. Tu rejoindras une équipe de passionnés qui aiment partager 🧢 Tes missions : Avec de plus en plus de clients utilisateurs de notre application SaaS, nous voulons augmenter notre capacité à écouter nos utilisateurs en ajoutant une analyse Data de l’utilisation de notre application. L’objectif est de s’inspirer de nos utilisateurs pour mieux répondre à leurs attentes. Pour cela, nous souhaitons intégrer un Data Engineer au sein de notre équipe technique. Tu seras en charge des missions suivantes : Concevoir et implémenter l’architecture Data de l’application pour assurer un stockage et un accès aux données pertinents Mettre en place les pipelines d’analyse Data Concevoir et intégrer dans le produit des fonctionnalités Data Réfléchir avec l’équipe produit et l’équipe tech à la mise en place des bons indicateurs. Gérer la maintenance technique : s’assurer que les pipelines et features fonctionnent correctement, tiennent la charge… Participer à la vie de l’équipe, être impliqué dans l’amélioration de nos process, nos standards et nos outils. La stack Data sort à peine de terre : il y a tout (ou presque) à mettre en place de la bonne manière 😉! 🛠️ Notre Stack Technique Data Snowflake Airbyte DBT AWS Tableau Google Analytics Backend / Infrastructure Ruby/ RubyOnRails, AWS, ECS, Fargate, Postgres, Elastic, Docker, Github, CircleCI, Datadog Front-end React Webpack, ViteJS Jest, React Testing Library, ESLint, Prettier In-House UIKit, Storybook 🎓 Ton profil : Comme tu feras partie d'une équipe de plusieurs développeurs avec des bonnes pratiques déjà mises en place, il te faut être familier avec les méthodes agiles et les workflow de travail en équipe ( GitFlow, Github flow ou similaire) Tu es diplômé d'une école d'ingénieur ou d’une école spécialisée en développement (type 42) . Tu as une expérience d'au moins 4 ans en tant que Data Engineer. Tu est engagé à concevoir, implémenter une architecture Data maintenable, testable et documentée. Tu es autonome et responsable - capable de porter une mission de la conception à la livraison en communiquant avec les bons interlocuteurs, et t'assurant de la qualité de la livraison. Tu es passionné et volontaire pour partager ton expertise au sein de l’équipe (sharing, reporting…) Tes Compétences: Tu disposes de compétences/connaissances dans les domaines suivants : Expérience confirmée en développement de pipelines de données Solides compétences en SQL et modélisation de bases de données Bonnes compétences en visualisation de données Connaissance d’Airbyte, DBT, Snowflake ou outils équivalents Une compétence en Ruby et Python est un plus. 🎯 Si tu souhaites rejoindre une équipe dynamique, dans aventure internationale, ta candidature est la bienvenue - même si tu ne coches pas toutes les cases! 🎯 Si tu es motivé par l’idée de répondre à un vrai besoin: aider les entreprises à avoir un suivi plus fin de la performance de leurs collaborateurs et favoriser leur engagement et leur montée en compétence, rejoins-nous! 🗂 Bon à savoir : Type de contrat - Cadre - CDI 💼 Rémunération entre 40 et 60k 💸 Bureaux situés au coeur de Paris, situés entre Pigalle et St Georges🗼 Politique de télétravail flexible 🏠 Mutuelle Alan Blue ❤️‍🩹 Carte Swile 🍭 Pass Navigo pris en charge à 50% 🚅 34 jours de congés par an 🌴 1 séance de sophrologie par mois 🧘 Abonnement à Mokacare pour prendre soin de toi 💆 Environnement international 🌍 Nos offres sont ouvertes aux salarié(e)s reconnu(e)s travailleurs et travailleuses handicapé(e)s (RQTH)","Javelo is seeking a Data Engineer with at least 4 years of experience to implement and design a maintainable, testable, and documented data architecture. The ideal candidate should have experience in SQL and data pipeline development, and should be familiar with agile workflows, GitFlow, Github Flow, or similar methods. The candidate should be passionate and willing to share their knowledge with the team. Javelo’s stack includes Snowflake, Airbyte, DBT, AWS, Tableau, Google Analytics, Ruby, RubyOnRails, React, Webpack, ViteJS, and Jest, among others. Benefits include flexible telecommuting, health insurance, subsidized public transportation, monthly relaxation sessions, and an international work environment.",Non spécifié,Entre 50 et 250 salariés,> 4 ans,3,1,0.05539549888311683
400,35712,https://www.welcometothejungle.com/fr/companies/pricehubble/jobs/data-engineer_milan,Data Engineer,PriceHubble,"{GCP,Azure,Kubernetes,PostgreSQL,Airflow,AWS,via,Spark,Docker,SQL,Python}",Télétravail total possible,N,"Logiciels, Immobilier particulier",CDI,2022-09-28,"PriceHubble is a B2B proptech company that develops valuation and analysis solutions for the residential real estate market. To get straight to the point, its solutions allow real estate professionals (investors, developers, banks, real estate agents, brokers, etc.) to evaluate their real estate assets as closely as possible, to advise their individual customers and to offer a digital and personalized experience. Big data and machine learning are at the heart of its model. PriceHubble is already present in 9 countries (Switzerland, France, Germany, Austria, Japan, the Netherlands, Belgium, Czech Republic and Slovakia) and now has more than 130 employees worldwide. Data engineers are the central productive force of PriceHubble. As a mid-level data engineer, your mission will be to improve the data-engineering work in PriceHubble. You will be given the responsibility for parts of our data engineering systems. Your daily challenges will be to add, improve, and maintain a wide range and variety of datasets. Doing so will expose you to a wide variety of tasks ranging from building the infrastructure (Spark on Kubernetes), through generating pipeline to process and expose new data sources, to building machine-learning models extracting features from raw data. Your Mindset You are convinced that success in data science is achieved via data-monopolies. You are highly motivated to join an organization who is committed to building the best in class data-engineering software for acquiring, processing, and enriching real-estate data. The following challenges speak to you: gather vast amounts of data about real estate consolidate, improve, and link this data to generate data sets no one else has on the market do that all over the world You are keen to join a startup right in its growth phase, and are not afraid to refactor code to get it to the new engineering standards that will support the growth of the organisation. At work, your team is your main asset: you are keen to mentor junior team members. In the startup, you are committed to create the company you want to work in; in terms of competence, standards, and mindset. Responsibilities Extract, clean, structure and transform complex raw and processed datasets to extract insights from them Retrieve a wide variety of datasets and integrate them into the data pipeline Create and maintain an efficient data infrastructure Build data enrichment pipelines, using machine-learning when appropriate Continuously provide new ideas to improve our engines and products Requirements MSc in Computer Science or equivalent At least 2 years of experience in a similar position Proficiency in at least one object-oriented programming language and at least one scripting language; Experience in working with Python and its ecosystem In-depth understanding of basic data structures and algorithms Familiarity with software engineering best practices (clean code, code review, test-driven development, ...) and version control systems Advanced knowledge of relational databases and SQL Comfortable working in English; you have a great read, good spoken command of it Nice to haves Experience with the ETL and data processing tools we’re using is a strong advantage: PySpark, PostgreSQL, Airflow Experience with Docker and Kubernetes orchestration is a strong advantage Working experience with cloud providers (GCP, AWS or Azure) Understanding of core machine learning concepts is an advantage Worked previously in ‘agile’ team(s) and looking forward to doing it again * We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas. Benefits Join an ambitious and hungry team and enjoy the following benefits: 💰 Competitive salary because we always want to attract the best talents. 📘 Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success. 🏢 Very well-located offices with a great remote work policy and the possibility to work from different places. 🕓 Flexible working hours and work life balance.","PriceHubble is seeking a mid-level data engineer to improve the data engineering work in the company, which develops valuation and analysis solutions for the residential real estate market. The successful candidate will need at least two years of experience in a similar position, proficiency in at least one object-oriented programming language and one scripting language, advanced knowledge of relational databases and SQL, and experience with software engineering best practices and version control systems. Strong advantages include experience with ETL and data processing tools like PySpark, PostgreSQL, and Airflow, as well as experience with Docker and Kubernetes orchestration and cloud providers like GCP, AWS, or Azure. The successful candidate will be motivated to gather vast amounts of data about real estate and consolidate and improve it to generate data sets that no one else has on the market. They will also work to mentor junior team members and help create a culture of competence, standards, and mindset. PriceHubble offers flexible working hours, a work-life balance, and a learning and development program.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
302,57005,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_VR3jad9,BI Engineer & Data Visualisation,Numberly,"{via,SQL,PowerBI,BigQuery}",Télétravail total possible,"28 rue de Châteaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-03-26,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception à la réalisation d’applications d’outils d’aide à la décision et monitoring de performance répondant aux problématiques métiers de nos clients. Vous êtes amené à : Intervenir sur des missions de cadrage et d’analyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de répondre aux attentes des clients; Concevoir et réaliser les reporting d’aide à la décision en apportant une attention aux enjeux de self BI, ainsi que sur l’UX/UI Desktop et mobile; Déployer des projets de Data Visualisation sous PowerBI en priorité mais possiblement en participant aux choix d’autres outils de restitution; Accompagner les clients dans la bonne compréhension et montée en compétence sur l’exploitation et le maintien des tableaux de bord. Vous assurerez également une veille technologique, et proposerez des solutions standardisées, fiables, évolutives liées à votre activité. Chez Numberly, nous partageons une passion pour la transmission : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment grâce : - aux “Jedi Master”, attribués à chaque nouvel arrivant- aux Vis ma vie dans des équipes différentes ;- aux Happy Meetings : des rendez-vous mensuels internes pour se retrouver avec toutes nos équipes dans le monde et partager l’actualité du groupe. Nous cultivons la liberté de parole qui permet à tous de participer au développement du groupe. Nous agissons positivement sur notre écosystème à travers 1000mercis impacts et via nos activités qui créent de la valeur dans l’Open Internet et participent à l’enrichissement de l’Open Source. Numberly est acteur de la diversité et Gender Equal by design : certification WeConnect International Un gender equity score de 97/100 Numberly est un environnement international avec plus de 30 nationalités dans nos équipes. Des bureaux à l’image de chacune des équipes, une bibliothèque généreuse, un grand studio de musique tout équipé, deux chats, du tri sélectif et du lombricompostage, la possibilité de venir avec votre animal de compagnie et de la place pour les vélos ! Dans chaque cuisine : café, thé, infusions à volonté et aussi des mystery lunchs, des cours de yoga, des cours de sport et des soirées (souvent déguisées). Possibilité d'être en remote jusqu'à 50% de votre temps (à organiser comme vous le souhaitez) et de travailler jusqu’à 60 jours (ouvrés) consécutifs en remote. Carte Swile ( titres-restaurants ). Mobilité possible dans nos différents bureaux à l'international. Numberly accueille les personnes en situation de handicap. Poste disponible à Paris ou Londres. Vous avez au moins 2 ans d'expérience dans la mise en place de projets datawarehouse et datamart. Vous avez une appétence particulière au domaine du Big Data, avec des réalisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et compétences sur les technologies suivantes : ETL et SQL. Vous êtes curieux(se), autonome, force de proposition et avez l’esprit d'équipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont récompensé le travail de Numberly en Europe et aux USA) au sein d’une équipe jeune (27 ans de moyenne d’âge) et internationale (25 nationalités). Encore mieux si Vous avez de l’expérience sur PowerBI et/ou BigQuery Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, média et la relation client.","Numberly is looking for a BI/Reporting Project Manager to design and implement data visualizations and monitoring tools to meet clients' business challenges. The ideal candidate should have a minimum of 2 years of experience in datawarehouse and datamart projects, knowledge of ETL and SQL, and a particular interest in Big Data. The role involves working closely with clients to understand their needs, proposing KPIs, and designing and implementing self BI UX/UI desktop and mobile. The successful candidate will join an agile, innovative and international team of more than 500 people in Paris, London, Dubai, Montreal, and New York. Remote work is possible up to 50% of the time, and mobility across the international offices is an option. Numberly is an advocate for diversity and gender equal by design, with leadership in open source and open internet.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
105,34139,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/senior-android-software-engineer_paris,Android Software Engineer - Mobile Data Collection,Contentsquare,"{Node,Azure,Datadog,React,go,Typescript,Kafka,Flink,Grafana,Golang,Akka,AWS,Contentsquare,Java,regard,color,Scala,Kibana,Spark,ClickHouse,Python}",Télétravail total possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We’ve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we’re not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! 🚀 Our mission At Contentsquare, all employees share one goal: to help brands create exceptional online experiences with our industry-leading digital experience analytics platform. In the mobile data collection team, we are on a mission to build the industry leading digital experience analytics SDK. With a stellar growth, billions of users , a complex business environment and the need for us to have a very high level of quality, performance and privacy, you’ll find an engaging, rewarding and supportive work environment at Contentsquare. We are looking for developers who understand that development is a team effort, who are proud of a job well done and know how to implement simple and efficient solutions to solve challenging and unique problems. 💻 Our stack On the data collection side, our SDK works on native iOS applications (implemented in Swift) and native Android applications (SDK is in Java - converted to Kotlin over time -, Unit Tests and Sample App in Kotlin). We also support various multi-platform frameworks (React Native, Flutter, Capacitor/Ionic, Cordova) with specific bridges. The Tag (implemented in Typescript) that collects data on websites (both desktop and web mobile) is implemented and maintained by the Web Team. Our APIs are mostly designed with our specific constraints in mind. For example, the most data intensive ones use Protocol Buffers . Our backend uses a combination of technologies such as Kafka , Spark, Flink , Akka , ClickHouse and languages such as Scala , Golang, Python , C++. Our monitoring and deployment are handled through Kibana, Grafana , Terraform, Datadog and finally, everything is hosted on AWS and Azure. Our frontend is a micro-frontend SPA developed mainly in Angular / Vue.js and Node.js . 🧠 Our challenges Our first challenge is to navigate through uncharted territories, native APIs and poorly documented features to make sure we collect all the relevant data we need to compute our insights. In addition we obviously must ensure a very high level of performance (as well as the least impact on user experience), stability and be very mindful about data and CPU consumption. Our rapid growth requires a strong focus on software architecture, code sharing and automation to sustain our delivery capacity while increasing our teams' size. Finally, we are not a tracking company, so collecting PII (Personal Identifiable Information) is an absolute no-go for us and we take it very seriously! 🤗 Skills & Mindset If you have already worked on any kind of software SDK your experience will be of great interest to us. In the same way, if you have notable experience in high performance code, automated non-regression and performance testing, software bridges (between technologies, native and non-native), or if you enjoy testing new technologies or frameworks such as Flutter/Dart, Swift UI, Compose, React Native/Typescript, we would love to hear from you. As a team we are really involved in producing a high quality SDK. We expect our developers to know how to unit test their code, to write easy to read & maintain code and documentation as well as being comfortable doing pair programming with their team members. 🏝 What we offer An healthy working environment with supportive team members, a place to grow both technically and as an individual Autonomy, responsibilities and opportunities An Engineering Career Path (with clear defined progression steps and opportunities to mentor and be mentored) to make sure you always learn something new Plenty of opportunities for training and development Attractive salary and stock options Flexible working conditions (full remote, 100% in office or any hybrid setup of your choice) A dynamic and multi-cultural company with +50 nationalities Good health insurance Many benefits such as reductions on gym membership and leisure activities While we are offering fully remote opportunities, employees need to be fiscally based in one of our main countries to be hired by one of our office. Please ask your recruiter for more information. - Why you should join Contentsquare - We’re humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we’d like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company’s success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is looking for developers to join its mobile data collection team. The team is responsible for building the industry-leading digital experience analytics software development kit (SDK) for native iOS and Android applications, as well as various multi-platform frameworks. The role requires experience in software development as a team effort, unit testing, and developing simple and efficient solutions to solve challenging and unique problems. The company offers a healthy working environment, autonomy, opportunities for growth and development, flexible working conditions, and a multicultural environment.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,3,1,0.05539549888311683
297,56975,https://www.welcometothejungle.com/fr/companies/spikeelabs/jobs/data-engineer-f-h-nice_nice,Data Engineer  Nice,SpikeeLabs,"{MongoDB,Flink,Talend,Scala,PostgreSQL,PowerBI,Kafka,R,Elasticsearch,Hadoop,Hive,Spark,Azure,NoSQL,SQL,Python,Tableau}",Télétravail total possible,"Nice, 06300","Logiciels, IT / Digital",CDI,2023-03-26,"SpikeeLabs est une société d’ingénierie, implantée à Paris, Rennes, Nantes et Saint-Malo. Son objectif ? Offrir aux entreprises une expertise en termes de développement et d’intégration de solutions au cœur des systèmes d’information (SI). Créée en 2016, elle se démarque aujourd’hui par : sa focalisation sur les problématiques enfouies et les applications back-office, son approche « métier » notamment grâce à son expertise reconnue dans les domaines des télécoms et du transport, sa transparence et ses valeurs, vécues et véhiculées au quotidien par ses salariés, son mode de fonctionnement qui favorise les liens, l’esprit d’équipe, les montées en compétence, les initiatives et la bonne humeur ! Vous connaissez les systèmes d’information et la circulation de la donnée ? Vous avez un goût prononcé pour la transformation de données brutes en information valorisée ? Alors venez donc nous rencontrer, vous évoluerez au sein d’une toute nouvelle agence à Nice, accompagné par nos équipes issues des agences de Paris, Rennes, Nantes et Saint-Malo, dans une ambiance start-up au cœur de Nice ! A propos du poste Au sein de l’entité basée à Nice, vous interviendrez en tant que Data Engineer sur les données applicatives des systèmes d’information de nos clients ou celles générées par notre solution in-house de facturation BillingLabs. Votre poste comportera deux dimensions : • Technique : architecture et solutions techniques associées au traitement de la donnée • Fonctionnelle : capacité à analyser les processus métier du client et les données associées afin de les valoriser Vos responsabilités ou missions seront principalement : • Analyser et documenter les besoins de nos clients en matière de collecte et traitement de la donnée • Concevoir des solutions techniques permettant la collecte et le traitement de volumes importants de données (mise en place de pipeline de données, datalake …). • Définir et mettre en œuvre des processus de validation, correction et nettoyage des données. • Mettre en place des solutions d’exploitation de ces données (en particulier des solutions de calcul parallèle). • Déployer des solutions de visualisation et présentation des données. Et vous ? • Vous maitrisez les grands principes d’un système d’information, du stockage, de la circulation et la transformation de la donnée • Vous avez déjà mis en œuvre ou utiliser les technologies suivantes : o Bases de données SQL (SQL Server, PostgreSQL) et NoSQL (ex : MongoDB, Elasticsearch…) o Langages de développement adaptés au traitement de la donnée (ex : Python, Scala, R…) o Technologies “Big Data” (ex : Hadoop, Hive, Spark, Flink…) o Middlewares - ETL, ESB, Message Broker (ex : Talend, Azure Data Factory, Apache Kafka…) o Data visualization (ex : Tableau Software, PowerBI, ELK…) • Vous maitrisez l’anglais technique sur votre périmètre • Vous avez l’envie et vous vous sentez la capacité de partager votre savoir au sein d’une équipe pour la faire grandir • Vous êtes pragmatique, proactif et orienté résultat • Et si : o Vous avez déjà porté la responsabilité d’une migration de données o Vous avez déjà porté la mise en place d’un datalake ou d’une base BigData Dites-le-nous, ce serait un vrai plus ! Rejoignez-nous ! Notre société SpikeeLabs travaille depuis 2016 auprès de ses clients à la réalisation de technologies centrées sur l’ouverture des systèmes d’informations aux nouvelles applications, notamment les applis digitales. Depuis, SpikeeLabs connait une forte croissance tant en termes de chiffre d’affaires que de clients servis. Notre expertise est développée en mode agile et s’adresse aujourd’hui en particulier aux acteurs du monde des télécoms, du transport mais aussi de la banque ou de l’énergie. L’entreprise a également développé et commercialise sa propre solution de facturation (BSS). Les bonnes raisons de nous rejoindre : • Vous aimerez aller de l’avant, être efficace et contribuer au développement d’une entreprise qui monte, qui monte… tout en gardant la tête sur les épaules ! • Une idée, une intuition, une proposition ? Chez SpikeeLabs, on a confiance en vous, on vous écoutera et on s’appuiera sur vous pour aller de l’avant ! • Vous travaillerez dans un esprit empreint de valeurs humaines fortes, vécues au quotidien et volontairement ancrées par nos fondateurs passionnés. Nos agences sont implantées sur Paris, Rennes, Nantes, Saint-Malo et Nice. Modalités • Prise de poste : dès que vous le pouvez, nous vous attendons ! Nous ne recrutons que sur profil ! • CDI et statut Cadre (Convention SYNTEC) • Rémunération à négocier ensemble selon votre profil et vos expériences • Avantages : tickets restaurant, 12 jours de RTT, Mutuelle, accord d’entreprise, intéressement, Compte Epargne temps, Télétravail. • Lieu : Nice « Grand Arénas » En toute simplicité, nous sommes disponibles pour répondre à vos questions si vous en avez. Alors…n’hésitez pas par téléphone au 02.30.96.21.60 ou par mail à recrutement@spikeelabs.fr","SpikeeLabs, a Paris-based engineering company, is seeking a Data Engineer in Nice to work on clients' application data and in-house billing solution. The chosen candidate must have experience with data storage, processing, and transformation, as well as SQL and NoSQL databases, data processing languages, and Big Data technologies. The role is both technical and functional, involving the analysis of business processes and data to generate value. The position is a permanent full-time role with benefits such as meal vouchers, RTT days, and telecommuting.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
293,57054,https://www.welcometothejungle.com/fr/companies/follow-health/jobs/data-engineer_rennes,Data Engineer,Follow,"{MySQL,MongoDB,Beam,via,Spark,Docker,PHP,NoSQL,SQL}",Télétravail total possible,"2 Rue de la Mabilais, Rennes, 35000","Logiciels, Santé",CDI,2023-03-26,"Construit en collaboration avec des médecins et des chirurgiens spécialisés, Follow est un logiciel innovant de suivi du dossier patient. En constante évolution, il propose à ses utilisateurs une interface ludique, et aide les médecins à optimiser le suivi de leurs patients en les rendant acteurs. De parents médecins, Roman Collin a fait naître l’idée en 2015. Soutenu par des médecins, 118 médecins investisseurs et le fond de Xavier Niel, le produit évolue rapidement, l’équipe grandit et triple en un an. Les membres de l’équipe, dont la bonne humeur dicte le quotidien, ont tous le même but : celui de révolutionner le suivi patient ! Nous avons actuellement 20 postes ouverts ! Ci-après une interview de Roman COLLIN, président et fondateur de Follow, qui communique notamment sur ces postes pour faire grandir notre équipe: https://www.linkedin.com/posts/fwhealth_follow-la-start-up-de-solution-digitale-activity-6993490658019704832-dbb8 La solution Follow offre une nouvelle perspective aux professionels de santé ainsi que leurs patients: la garantie d’une donnée accessible, claire, mais qui contribue aussi à favoriser la sécurité des prescriptions ainsi que les échanges avec d’autres confrères ou directement les bénéficiaires de soins. Dans le but de péréniser la donnée chez Follow, nous créons une équipe Data au travers de laquelle tu auras l’occasion de rejoindre notre autre Data Engineer. Missions Tes principales missions en tant que Data Engineer seront de : 💪 Travailler à la robustesse de flux de données, de la collecte à la transformation 🏭 Industrialiser les stratégies d’intégration de gros volumes de données 📊 Proposer des métriques de suivi de notre donnée 🛠 Contribuer à l’élaboration et l’optimisation de notre modèle de données 🙋 Mettre au point et faire évoluer un système de self-extraction de données à destination de nos utilisateurs 🧪 Générer des exports de données à destination de recherches médicales L’équipe tech Nous sommes portés avant tout sur la collaboration mutuelle pour avancer ensemble autour des sujets fonctionnels et techniques. Voici quelques-unes de nos valeurs : La bienveillance La remise en question et l’amélioration continue La haute technicité L’humour même dans l’adversité L’équipe tech est aujourd’hui composée de : ⚙️ 3 Backend Developers 🖼️ 2 Frontend Developers 🛠️ 1 Full Stack Developer 💽 3 Data Engineers Perks Vous profiterez entre autres choses de : 7 semaines de congés par an Une mutuelle prise en charge à 100% par Follow Tickets restaurants via carte Swile Des stock options (BSPCE) Un budget conférence annuel (300€ et un “jour offert”) Un accès à un compte PluralSight Premium Encore plus à venir ! 📣 Mais nous recrutons aussi un QA Engineer, un Senior Full Stack Developer et un Product Manager, tous sur des créations de postes! Consultez nos différentes offres. 😊 Tu fais déjà preuve de deux ans d’expérience dans le Data Engineering, et ton approche pragmatique et expérimentale te permet d’obtenir rapidement des résultats. Tu as pour vocation de péréniser la donnée, que ce soit lors de son intégration jusqu’à sa restitution. Tu as a minima les compétences/connaissances suivantes : Apache Spark SQL (MySQL) NoSQL (MongoDB) Google Cloud Platform Docker Aussi, les compétences suivantes seront un plus : Apache Beam Trifacta Dataprep PHP (Symfony) Rencontre avec Yoann, VP of Engineering (45min) Tech, team & culture fit avec l’équipe tech (1h30) Rencontre avec Roman, CEO (30min)","Follow, a patient tracking software, is seeking a Data Engineer to work with their team of developers to create robust data flows, collect and transform data, and propose metrics for data tracking. The ideal candidate will have at least two years of experience in Data Engineering and be proficient in Apache Spark SQL, MySQL, NoSQL, Google Cloud Platform, and Docker. Additionally, experience with Apache Beam, Trifacta Dataprep, and PHP (Symfony) is a plus. Follow offers benefits such as seven weeks of annual leave, 100% covered health insurance, and stock options.",Bac +3,Entre 15 et 50 salariés,> 2 ans,3,1,0.05539549888311683
292,56926,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-h-f_brest_THALE_NRKa2Y3,Data Engineer confirmé(e) –,Thales,"{durable,GIT,R,JAVA,Python}",Télétravail total possible,Brest,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES-VOUS ?PROFIL :Vous venez d'être diplômé(e) d'un master d'une école d'ingénieur et justifiez d'une expérience significative d'environ 2 ans (stages professionnels/stages, projets universitaires ou personnels tels que GIT Hub, Meet Ups, etc.)Vous êtes débrouillard(e), innovant(e) et orienté(e) solutionsVous avez l'esprit d'équipeVous aimez également travailler de manière indépendante et recherchez les responsabilités COMPÉTENCES : Vous êtes capable de vous adapter et de réagir au changement Vous savez et aimez concevoir, développer et tester des solutions et/ou des composants logiciels sécurisés Vous pouvez démontrer votre connaissance des langages et cadres de programmation Full Stack ou pure back/pure front (JAVA, C, C++, Python, ou tout autre) Vous êtes familier(ère) avec la compilation/construction de code/intégration continue. Vous avez connaissance des plateformes informatiques, des systèmes d'exploitation et des hyperviseurs du SI Vous connaissez les principes Agile CE QUE NOUS POUVONS FAIRE ENSEMBLE :En tant que ""Software Solutions Engineering Role"" chez Thales, vous serez amené(e) à : Travailler au sein d'une équipe Scrum avec d'autres développeurs de logiciels, en mode Agile Contribuer à la définition des besoins, à la conception du logiciel et être impliqué(e) dans les aspects architecturaux des projets logiciels Intégrer les composants logiciels dans un système logiciel entièrement fonctionnel Ecrire un code bien conçu, documenté et testable Développer, tester et exécuter le cycle de vie complet du développement logiciel Concevoir, mettre en œuvre et tester des fonctionnalités en tenant compte de l'évolutivité, des performances, du déploiement/de l'exploitation et de l'expérience de l'utilisateur(ice) final(e). Faire des estimations et contribuer à la planification avec les membres de l'équipe Collaborer avec d'autres ingénieur(e)s en solutions logicielles afin de partager les connaissances et d'améliorer le produit/solution dans son ensemble.VOTRE CARRIÈRE CHEZ THALESDifférentes opportunités vous permettront de découvrir d'autres domaines ou sites. Vous pourrez évoluer et développer vos compétences dans différents domaines :Explorez un espace attentif au développement personnelDéveloppez vos talents dans un autre domaine du groupe Thales, en découvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexeChoisissez entre une expertise technique ou un parcours de leadershipConstruisez une carrière internationale au sein d'un groupe d'ingénierie de premier plan. Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d’habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l’IGI 1300 SGDSN/PSE du 09 août 2021. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales seeks a Software Solutions Engineering Role, who needs to be a newly graduated engineer with significant experience of around 2 years. The candidate must be able to develop full-stack solutions, compile/construct code, integrate continuous design, have knowledge about programming languages like JAVA, C, C++, Python, etc. and work in a team under Agile principles. The position requires the ability to uncover secrets for the national defense and perform national defense habilitation procedures under Code de la defense and IGI 1300 SGDSN/PSE.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
168,56663,https://www.welcometothejungle.com/fr/companies/reech/jobs/data-engineer-h-f_rennes,Data Engineer,Reech,"{ElasticSearch,Solr,AWS,Kafka,Hadoop,Spark,RabbitMQ,NoSQL,SQL}",Télétravail total possible,"61 rue Jean Guéhenno, Rennes, 35000","SaaS / Cloud Services, Marketing / Communication, AdTech  / MarTech",CDI,2023-03-26,"Créée en 2015 par Guillaume et Maxime DOKI-THONON, Reech est une entreprise experte du Marketing d’Influence . Grâce à sa technologie propriétaire permettant d’identifier et de qualifier les bons influenceurs (parmi 7 millions !), couplée à l’expertise de ses 50 collaborateurs, Reech construit l’écosystème d’influence des marques qu’elle accompagne, telles que Coca-Cola, Carrefour, Spontex, Philips, Groupe Galeries Lafayette, Yves Rocher, autour de deux offres : Avec Reech Agency , le cœur de métier de Reech est d’accompagner de A à Z les marques dans leur stratégie d’influence, et ce depuis 2015. Avec son offre technologique lancée en 2020, Reech Influence Cloud , Reech permet aux marques et aux agences d’utiliser une solution SaaS modulaire basée sur la donnée et l’IA, facilitant l’activation, l’analyse et l’amplification de l’Influence. Qu’elles souhaitent un accompagnement clé en main, un socle technologique leur permettant d’internaliser l’influence ou un entre-deux, grâce à ses différentes offres, Reech est désormais le seul acteur qui permet aux marques de placer le curseur d’un accompagnement en Influence Marketing sur une infinité de positions. 💪 VOS RESPONSABILITÉS : À Rennes, au sein d’une équipe Agile au top, tes missions seront : Étudier, concevoir et implémenter l’architecture pour la collecte, le stockage et l’exploitation des données Garantir la disponibilité des bases de données pour une exploitation optimale par l’ensemble des équipes Assurer et surveiller l’automatisation des mises à jour des données depuis le sourcing à la génération d’entités et d’attributs 🌱 ENVIRONNEMENT : Reech est fier d’avoir été élu entreprise où il fait bon vivre , avec un premier prix venant récompenser sa culture d’entreprise et managériale ♡ L’équipe : Tech, rattachée au CTO et co-fondateur, Maxime DOKI-THONON Locaux : dans le centre de Rennes, 61 Rue Jean Guéhenno Télétravail : 2 jours par semaine à partir de 3 mois d’ancienneté Avantages : mutuelle Alan et carte Swile pour le déjeuner Tu possèdes 1 an d’expérience minimum. Tu as de bonnes connaissances des technos big data (ElasticSearch ou Solr, Hadoop/Spark, etc.) et des bases de données (SQL et NoSQL). Tu es affuté sur le service bus (RabbitMQ, Kafka, …) et orienté micro-services, CI/CD et scalabilité. Tu es à l’aise avec l’anglais technique. Tu es bon communiquant, capable de pitcher un chantier technique important. Curieux et rigoureux, tu es en veille techno permanente. Les + Tu as déjà travaillé sur la partie infra (AWS, OVH, Terraform, …). Tu as déjà travaillé dans un contexte Agile (Scrum). Tu es intéressé par le machine learning, data-science la data visualisation.","Reech, a marketing agency specializing in influencer marketing, is seeking a Data Engineer in Rennes. The role entails designing and implementing an architecture for data collection, storage, and exploitation and ensuring the availability of databases for optimal use by all teams. The ideal candidate should have at least one year of big-data technos experience, familiarity with service bus, and excellent communication skills. The agency offers telecommuting two days a week, healthcare benefits, and an on-site culture that has earned awards for employee satisfaction.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
363,50452,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote-germany_berlin,Software Engineer Data Presentation - Remote Germany,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",Télétravail total possible,Berlin,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer to develop usable and intuitive software interfaces and scalable engines for its platform. The ideal candidate should have experience in software development, be customer-oriented, and have experience with either frontend and backend development or mastery of frontend coding with no fear of diving into backend coding. They should also have firsthand experience building products and a keen eye for design. The environment at Dataiku is flexible and autonomous, with a culture that encourages learning and collaboration. Dataiku is committed to diversity, equal opportunity, and fair treatment of all employees.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
110,73013,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/dataops-engineer-data-solutions-factory-f-m-d_paris,DataOps Engineer - Data Solutions Factory,Decathlon Digital,"{GCS,Github,Linux,DynamoDB,Jupyter,Kafka,Dataflow,Hive,Kinesis,Redshift,Hbase,Jenkins,Superset,Tableau,Airflow,AWS,YARN,Talend,Datastudio,Druid,BigQuery,Elasticsearch,PostgreSQL,Spark,S3,Sagemaker,Prisma,Hadoop,Kubernetes,NoSQL,EMR,GCP}",Télétravail total possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOINS L'EQUIPE DATAOPS DE LA DATA SOLUTIONS FACTORY DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Au sein de la BU Data, l ’équipe DataOPS innove tous les jours pour répondre au mieux aux besoins de notre data platform . Nos enjeux sont : Une plateforme data entièrement multi-cloud (AWS & GCP) De la haute disponibilité, avec une plateforme résiliente et des technologies innovantes La sécurité au coeur de nos projets Les besoins de nos data scientist, data engineers data analystes, et développeurs traduits en solutions techniques Composée d’une 15aine d’experts, l’équipe DataOPS t’attends pour apporter ta contribution à ce grand enjeu qu’est la Data. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e DataOPS Engineer, basé-e, au choix à Lille ou Paris (si tu es localisé.e hors de la région lilloise, prévoir une déplacement sur Lille à un rythme d'1 journée / par semaine ou 2 jours tous les 15 jours). TES RESPONSABILITES Expert.e dans ton domaine, tu conçois, déploies et maintiens les offres techniques pour l’ensemble des infrastructures de la BU Data, tout en suivant les stratégies techniques de l’entreprise (excellence opérationnelle, full cloud, full automatisation, sécurité). Tu participes et contribues aux stratégies techniques de l’entreprise au sein de la communauté OPS . En tant que référent.e sur les technologies que tu gères, tu partages et fais grandir tes collègues Tu participes au processus de support, en prenant en charge avec l’équipe les demandes, incidents et problèmes en escalade sur ton périmètre d’expertise Tu contribues à la transformation du SI Tu accompagnes les changements stratégiques liés à l’infrastructure Tu aides au recrutement de profils OPS externes, tu les formes et les animes. Le périmètre technique : Un environnement full cloud (AWS-GCP) complètement infra-as-code (Terraform, Ansible) ; Une plateforme Kubernetes, avec full CI/CD (Flux, Jenkins, Github Action…), haute disponibilité, haute sécurité (Prisma,...) ; Une infrastructure d'échange de données, en pleine évolution pour être 100% industrialisable, avec de multiples technologies : Kafka, Talend, Airflow, Kinesis, Dataflow... Une infrastructure DataViz : QlikSense, Superset, Quicksight, Datastudio, Tableau ; De multiples technologies de stockage : S3, Redshift, PostgreSQL, GCS, BigQuery ; Une plateforme Hadoop : EMR, Hive, Spark, YARN, Ranger, Atlas ; Des bases de données NoSQL : Elasticsearch, Druid, DynamoDB, Hbase ; De multiples environnements de développements Data : Github, Jupyter, RStudio, Sagemaker ; Une grande communauté OPS très soudée, qui partage les bonnes pratiques, construit des process communs, etc. CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as au moins 2 ans en tant qu'OPS sur Linux, conteneurisation, monitoring, CI/CD, automatisation & industrialisation ET en environnement Cloud (AWS fortement apprécié) Tu as une appétence pour la data (Spark, Airflow, Sagemaker, BigQuery), et la gestion de bases de données relationnelles et NoSQL ; Tu aimes évoluer en contexte Agile et tu as envie de travailler dans un environnement international (anglais technique maîtrisé). Tu es f orce de propositions, et aimes le challenge ! Passionné·e de technique et de sécurité, la veille technologique sera une part importante de ton activité ; Rejoindre une entreprise qui rend accessible au plus grand nombre le plaisir et les bienfaits du sport fait sens pour toi et tu as envie de partager tes passions en équipe ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .",,Non spécifié,> 2000 salariés,> 2 ans,3,1,0.05539549888311683
142,72447,https://www.welcometothejungle.com/fr/companies/shine/jobs/lead-data-engineer_paris,Lead Data Engineer,Shine,"{Beam,Metabase,grid,scale,BigQuery,GCP,Python}",Télétravail total possible,"Paris, 75001","Application mobile, FinTech / InsurTech",CDI,2023-04-08,"Shine simplifie le quotidien des indépendant·es et petites entreprises pour leur permettre de se concentrer sur ce qui compte vraiment : leur réussite. ✨ C’est un compte pro responsable , qui propose des services en ligne et un véritable copilote administratif . Shine simplifie l’expérience bancaire et administrative des indépendant·es, grâce à un équilibre entre service en ligne et accompagnement humain. Les entrepreneur·es peuvent se reposer sur une équipe d’expert·es disponibles sept jours sur sept pour répondre à toutes leurs interrogations administratives et sur une application et des fonctionnalités innovantes: un compte pro 100% en ligne, avec une application simple et intuitive, pour gérer leur activité un copilote administratif, pour les accompagner de la création de leur entreprise à la gestion quotidienne des assurances inédites, pour protéger l’activité des indépendant·es Au delà de cette mission, Shine en tant qu’entreprise aspire à avoir un impact social et écologique positif . La startup a à cœur de favoriser la diversité et l’inclusion au sein de ses équipes et de sa communauté. Elle est également labellisée B Corp. Enfin, Shine fait partie du mouvement 1% pour la planète et reverse 1% de son chiffre d’affaires annuel à des associations environnementales. Lancé en 2018, Shine a levé 10,8 millions d’euros auprès de Daphni, Kima Ventures, XAnge et plusieurs business angels. La startup a rejoint en 2020 la Société Générale et accélère son développement tout en restant une structure indépendante. Rejoindre Shine aujourd’hui, c’est faire partie d’une équipe internationale de 130 personnes passionnées qui travaillent en remote ou dans leurs bureaux dans le centre de Paris. C’est aussi aider 100 000 entrepreneur·es et prendre part à leur croissance pour impacter des millions de personnes ! Shine’s engineering team Data engineering at Shine is about designing efficient data pipelines and backend development. We build the most reliable data architecture to insure the best collect, analysis and data visualisation possible - it goes without saying that data team play an essential role for Shine ! Our squad is made of 4 Data Engineers, 1 scientists, 5 analysts and a head of data to insure top synchronisation with our product and or business ✨ Regarding our stack we are using : Python , GCP , BigQuery , App engine , Pub/Sub , Beam , Mode , Metabase , Data studio & Segment Joining as a Lead Data Engineer means 👋 Hiring, mentoring and leading a 4 Data engineers team ( Reshma , Patrice , Timothé , Romain ) Lead billions of data in an efficient & ethical way Developing strong data pipelines for 100K+ users Creating a reliable and consistent code to insure our technical scale Having a strong impact on our data architecture by proposing new implementations It's a match if 🤝 You have a strong experience (5+ years) in Data engineering You are proficient and comfortable with Python, writing production-ready code, testing and monitoring You have experience in managing or leading a team You already worked in a cloud environnement (not necessarily GCP) You are also interested about Data science / Data analysis and operational subjects You give a lot of attention to details in your work You stick to Shine’s values 💛 You can communicate clearly in English (our data team is international!) Working at Shine is joining a fast paced scale-up, a useful and UX driven product but not only… Before anything else, it’s being a part of a great human experience in a company driven by amazing values toward people and ecological matters We do believe that caring is not only about giving autonomy, responsibility and encouraging proactivity. That’s why we offer: 💰 A fair and transparent salary grid - Level D to E (70K€ to 85K€) for this job ( More informations ) 🏠 A flexible and remote-friendly environnement. From France and Europe! 🏢 A brand new and stunning office in Paris - Also a nice corner in Station F 🖥️ Everything you need to work in perfect conditions (Co-working space, furniture, monitors, mouse, etc.) And a lot more ! Feel free to ask to Annaïg during your first call. But also 👩‍💻 1 freelancing day / month. The perfect occasion to put yourself in a Shine’s user’s shoes (Shine premium is offered to help ofc) 👪 A second parent leave extended to 8 weeks + 3 days of parental leave for sick child 💚 Healthcare program 100% covered by Shine for you and your family 🎶 Culture budget : 275€/ year to buy books or listen to music (Spotify, Deezer …) 🤸 Sport pack: 300€ per year to subscribe to gym, participate in sport competitions … Take care of yourself! 🚴‍♂️ Bike + transport : Refund of your fees, on jump seats like on bike paths! ☀️ 35 days of holidays for everyone! 🏝 1% salary bonus in June to enjoy your Holiday You wonder about our hiring process ? 1️⃣ A 30’ first call with Annaïg, our data talent acquisition specialist, to get to know each other and tell you more about Shine. 2️⃣ A 60’ interview about your data experiences with Nicolas , our Head of data 3️⃣ A a 45’ case study with Reshma and Timothé + a 45’ cultural interview to give you more context about Shine’s values. 4️⃣ An immersion day for you to understand Shine’s culture, meet the team and introduce our data engineering with some reflectional exercices.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
459,56439,https://www.welcometothejungle.com/fr/companies/free2move/jobs/data-engineer-h-f_paris,Data Engineer,Free2move,"{Gitlab,Airflow,PostgreSQL,AWS,S3,dbt,Snowflake,Lambda,SQL,Python,EC2,Tableau}",Télétravail total possible,"45, Rue de la Chaussée-d'Antin, Paris, 75009","Mobilité, Économie collaborative, Tourisme",CDI,2023-03-26,"Créée en 2016, Free2Move 🚀 simplifie les usages liés à la mobilité en proposant une large offre de services pour satisfaire les besoins de 🚘 déplacement de tous. Avec Free2Move, vous pouvez louer un véhicule pour faire une course ou une citadine pour votre séjour en Italie 🏖️, réserver un parking durant votre week-end à Paris… le tout en un clic, sur notre plateforme web/mobile ! 📲 Née du rapprochement du Groupe Stellantis 🚗 et de la start-up TravelCar, Free2Move, grâce à son agilité et à son esprit de conquête a réussi à s’imposer en à peine 6 ans 🚀 comme un acteur de référence pour révolutionner la mobilité de tous les voyageurs. Devenu le réflexe #1 pour plus de 6 millions d’utilisateurs 👑, Free2Move opère dans plus de 170 pays à travers les 5 continents 🌎 et est disponible en 30 langues et 26 devises. 5000 partenaires nous font confiance et plusieurs centaines de milliers de véhicules sont disponibles ! Si vous souhaitez rejoindre une équipe de +250🏆 experts et des projets internationaux audacieux, alors vous êtes au bon endroit ! 🎯 Vous évoluerez dans une structure ultra-dynamique, innovante, agile, tournée vers l’international et intégrerez nos talentueuses ❤️équipes♥️, pleines d’idées et de motivation et aux compétences pluridisciplinaires, à la croisée de l’éco-système digital et du secteur de l’automobile, en pleine mutation. 💺 REJOIGNEZ-NOUS ! 💯 C’est passionnant, vous verrez🔥! Your next missions : We have a great new opportunity for a Data Engineer to join our Data Team. He / She will join the Data department composed of 26 people divided into 5 teams. As part of the SHARE NOW Data Warehouse Team, you are in charge of the end-to-end development of our Data Warehouse and Business Intelligence solutions. You will be in constant knowledge exchange with all team members and always taking on new challenges. As part of the job, you will have the opportunity to continually expand your technical and methodical expertise as well as strengthen your business sense. More specifically, you will be responsible for : You work as part of the team on the conception, design, implementation, optimization and technical management of our Data Warehouse and Business Intelligence solutions. You implement ETL processes to integrate and enrich data from different sources like Amazon S3, PostgreSQL or REST API. You design and implement relational and multidimensional database systems as well as different types of reports and dashboards according to the business requirements. You develop our Business Intelligence solution using a modern tech stack (Snowflake, dbt, Airflow, Gitlab CI/CD and other Amazon Web Services). You identify potentials both with respect to architecture and the technologies used. You are in exchange with different business departments to support them in their data needs. Expected skills: 🔧 You have successfully completed your master’s degree in Computer science or a related field. 🔧 You are passionate about creating a well architected modern data infrastructure and working on projects with business impact. 🔧 Expert in SQL and/or SQL-based languages and performance tuning of SQL queries. Some hands-on experience in Python is good to have. 🔧 You have knowledge in the technologies we use, especially AWS (e.g. S3, Lambda, EC2) and Snowflake, ideally also Airflow and dbt. 🔧 You are comfortable with CI/CD pipelines and DevOps workflows. 🔧 You ideally have several years of experience in developing and maintaining complex Data Warehouse solutions. 🔧 You ideally bring first experience in Tableau and visualizing complex data 🔧 Your strengths include an analytical mind and an affinity towards data and facts 🔧 You have a strong command of English (spoken and written). 🔧 You enjoy working in a dynamic environment and are known for working in an effective, efficient and motivated manner. What we offer: Working at Free2Move means becoming part of a tribe in which the culture of performance rhymes with a good atmosphere. It is also: A start-up spirit supported by a large Group 🥇 Depending on your mission, a possibility to work in full remote wherever you are, in hybrid or within our different offices! ⛵️ The opportunity to revolutionize the uses of mobility with us! 🚘 A neat integration to start well 🎁 Lots of possibilities for development 📈 Collaboration with multidisciplinary and international teams 💪🏼 International projects to perfect your background! 🌍 An attractive salary 💸 A Swile card to enjoy all the restaurants around you! 🍝 A mutual insurance financed at 60% and a providence in case of hard times financed at 100%! An access to our E-Learning platform 📚 : for the development of languages and other skills Table football battles to relax ⚽️ ...This list is not exhaustive... Job type: - CDI OR PERM OR within the head office in the heart of the 9th district in Paris - To be filled asap 👀 *Psst...! On vous file une combine :) Postulez, de préférence, en anglais 🇺🇲","Free2Move, a mobility services company, is seeking a Data Engineer to join its data team. The team member will be responsible for end-to-end development of the company's data warehouse and business intelligence solutions, including implementing ETL processes, designing and implementing database systems, developing BI solutions using modern tech stack, and identifying potential areas for architecture and technology improvements. The ideal candidate will have a master's degree in computer science or a related field, expertise in SQL and/or SQL-based languages, knowledge of AWS, Snowflake, Airflow, and dbt, and experience in developing and maintaining complex data warehouse solutions. Free2Move offers competitive compensation, career development opportunities, and a dynamic work environment.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
197,56785,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-business-intelligence-f-h_rennes,Data Engineer,Micropole,"{Microsoft,durable,Talend,SAP,Informatica,AWS,R,GCP,SQL,Qlik,Tableau}",Télétravail total possible,"14 Rue du Patis Tatelin, Rennes, 35700",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Data Engineer F/H Localité : Rennes Type de contrat : CDI Niveau d’expérience minimum : 2 ans Vous souhaitez rejoindre une entreprise pionnière des grandes innovations data et digitales, au sein d’une agence à taille humaine où règnent entraide et convivialité, engagée en faveur d’un numérique plus responsable au service de clients principalement implantés régionalement ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur grâce à la puissance du Cloud ? Rejoignez Micropole ! Dans vos missions quotidiennes , vous serez amené(e) à : Participer aux recueil du besoin auprès des Directions Métiers ; Rédiger les dossiers de conception technique ; Intervenir sur toute la chaîne de valeur de la donnée : extraction, modélisation & dataviz ; Préparer et dérouler les tests ; Accompagner la maîtrise d’ouvrage dans la validation de livrables, l’assistance à la recette et la conduite du changement sur le projet ; Capitaliser et partager les bonnes pratiques, connaissances et retours d’expérience au sein de nos communautés. Vos compétences techniques : Vous maîtrisez parfaitement au moins un ETL du marché (Informatica, Talend, Big Query, Data Factory, etc) et la création de tableaux de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI...) idéalement dans un environnement Cloud ; SQL n’a plus de secrets pour vous. Vos atouts : Vous êtes diplômé(e) d’une formation supérieure en Informatique parcours Données ; Vous possédez une expérience d'au moins 2 ans dans la fonction ; Votre esprit d’analyse, de synthèse, votre organisation et vos capacités rédactionnelles sont souvent reconnus ; Vous appréciez travailler en équipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C’EST : - Intégrer une communauté de 1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. - Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. - S’assurer d’une innovation continue grâce à : Notre écosystème de partenaires technologiques Notre accélérateur de start’up databoost’R Nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C’EST : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; La participation à des projets internes sur la base du volontariat. PROCESSUS DE RECRUTEMENT : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – Si votre profil correspond à nos attentes, vous êtes recontacté(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist en Région pour un premier échange téléphonique ; Etape 2 – Un premier entretien est programmé avec l’un d’entre eux sur site ou à distance Etape 3 – Vous rencontrez Stéphanie ou Camille les manager de l’équipe Data de l’Ouest pour un second entretien En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole/mycompany/ MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un développement rapide sur le Data, le Digital et Cloud, les équipes portent l’ensemble de la proposition de valeur du Groupe. Présent au plus près de l’écosystème de partenaires, de réseaux professionnels et d’acteurs du développement économique, nous accompagnons nos clients des secteurs de l’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et du public dans leur transformation data et digitale, notamment au travers de méthodologies innovantes comme le Datathinking® ou Lego Serious Play®. L’agence Grand Ouest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit et met en place des méthodes, compétences et expertises pour le développement d’un numérique responsable au sein des organisations #LI-CB1 Compétences Talend QlikSense","Micropole seeks a Data Engineer with at least 2 years of experience in the field, to join their team in Rennes. The ideal candidate should possess expertise in at least one ETL tool and experience creating data visualizations with tools such as Power BI, Tableau or Spotfire. They will work with the team to assist clients with data-driven transformation and responsible cloud-based solutions. Micropole encourages a team-oriented approach and offers a range of training opportunities for continuous growth.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,3,1,0.05539549888311683
41,73121,https://www.welcometothejungle.com/fr/companies/weefin/jobs/lead-data_paris,Lead Data Engineer,WeeFin,"{Github,Python,Node,Linux,Pandas,durable,scale,PostgreSQL,Bash,NoSQL,AWS,SQL}",Télétravail total possible,"71, Rue du Faubourg Saint-Martin, Paris, 75010","Stratégie, Transformation, FinTech / InsurTech",CDI,2023-04-22,"Weefin est une startup à impact dont le but est de démocratiser la finance durable. Nous construisons ESG Connect, le produit WeeFin, se positionnant au coeur de l’analyse extra-financière : entre les fournisseurs de données ESG (Environnement, Social et Gouvernance des entreprises) et les institutions financières (nos clients). Notre produit leur permet de noter les entreprises dans lesquelles elles investissent pour mesurer l’impact de leurs investissement sur l’environnement et la société. ESG Connect a pour vocation de faciliter la validation, l’exploitation et l’enrichissement des données fournisseurs dans le contexte particulier de chacun de nos clients. Ce qui nous conduit à mettre en place des pipelines data, des mécanismes de notification, une librairie de calculs configurables par les utilisateurs… Nos challenges : Normaliser les données provenant des différents fournisseurs Proposer des moyens innovants de présenter la donnée normalisée, sa qualité et les résultats des calculs aux différents métiers gravitant autour du produit Gérer la donnée et les résultats dans le temps pour satisfaire des besoins de simulation, d’audit… Notre stack : Cloud provider : AWS, principalement du serverless Infra As Code : Terraform/Terragrunt CI/CD : Github Scripting : Python, Bash Front : Node, Vue3, Cypress OS : Linux Bases de données : SQL et NoSQL Depuis notre levée de fonds, WeeFin est entrée en phase de scale et recherche de nouveaux profils pour renforcer l’équipe Tech ! Au sein de l’équipe Tech, les missions du/de la lead data sont les suivantes : Participer au développement de notre plateforme : amélioration de nos processus de développement ; amélioration de notre architecture data ; Choisir et benchmarker de nouvelles technos data (PolarRS, Pandas 2.0) ; Participer à l’élaboration de la roadmap technique ; Comprendre et intégrer les spécifications fonctionnelles ; Participer à la montée en compétences de l’équipe : partager les bonnes pratiques et retours d’expérience, faire des feedbacks… Vous avez de l’expérience avec des moteurs de calcul Vous maîtrisez Python, PostgreSQL et avez déjà travaillé avec Pandas Vous êtes prêt.e à travailler sur l’évolution de l’architecture en gardant du temps pour la production en continu",,Non spécifié,Entre 15 et 50 salariés,Non spécifié,3,1,0.05539549888311683
258,56824,https://www.welcometothejungle.com/fr/companies/yousign/jobs/data-engineer-h-f-x_paris,Data Engineer /X),YOUSIGN,"{Typescript,Airflow,Kubernetes,Uber,dbt,scale,Dagster,Docker,PHP,SQL,Python}",Télétravail total possible,"4, Rue Royale, Paris, 75008",SaaS / Cloud Services,CDI,2023-03-26,"At Yousign, we are reinventing the electronic signature experience with a fast, legal, secure and 100% European SaaS solution. 🖊⚡ Founded in 2013 by Luc Pallavidino and Antoine Louiset in Caen, our scale-up is now present in France 🇫🇷, Italy 🇮🇹 and Germany 🇩🇪 ! Our goal? To become the European leader in electronic signatures by enabling freelancers and SMBs, to simplify their workflows. 🤸♀️ 🚀 In order to achieve this… 2019: we integrated into the eFounders, one of the best SaaS start-up studios in Europe, 2021: we raised 30 million euros from the eFounders and Lead Edge Capital, famous for having invested in BlaBlaCar, Asana, Zoom, Spotify and Uber. We offer two e-signature solutions: a web app, ready to use and accessible from anywhere, an API (Application Program Interface), which can be easily integrated into business softwares At this time, Yousign is : more than 200 yousigners in our offices in Paris and Caen, or in full-remote (+40% are working remotely) 👦 💻 more than 12,000 customers who trust us on a daily basis 🤝 over 4 million signatures every month 🔝 An impressive annual growth rate, which makes us the most successful e-signature scale-up in Europe 🇪🇺 Ton équipe Tu rejoindras l'équipe Data composée de 5 Analystes et 2 Data Engineer, et rattachée à Product & Engineering. La Team Product & Engineering est le coeur de Yousign et c’est l’équipe la plus grande de la société. Nous sommes actuellement en pleine croissance et cherchons des talents expérimentés pour rejoindre cette aventure. Ton rôle La squad Data Engineering - au sein de l'équipe data - de Yousign est en charge de la construction et de la maintenance de la Data Platform. Tu seras donc un des garants de cette Data Platform, en charge de son développement et de son amélioration continue pour accompagner Yousign dans ses besoins croissants ! Tu partageras aussi ton expertise technique avec les autres membres de l'équipe data pour les aider à monter en compétence et à répondre aux besoins des équipes métier. Tu participeras aussi plus globalement à l'évangélisation de la data au sein de Yousign. Missions Les principales missions sont les suivantes : Développer et maintenir l’infrastructure Data de Yousign Mettre à disposition les données pour les utilisateurs internes et externes Participer aux choix technique de l’équipe Data et conseiller les data analystes Construire des pipelines de Data sécurisés, fiables et robustes reposant sur Apache Airflow et dbt Participer à l’administration de notre Data Platform Participer à l'évangélisation de la Data pour nos employés et à l’amélioration de notre maturité Data chez Yousign L'équipe Product & Engineering de Yousign Le rôle de l’équipe Product & Engineering de Yousign est de concevoir, faire évoluer et maintenir l’ensemble des fonctionnalités de notre produit ainsi que les outils permettant son bon fonctionnement. Elle est composée d’une cinquantaine de personnes : Des développeur•ses front (JS/ReactJS/Typescript) Des développeurs•ses back (PHP/Symfony) Des SRE Des Product managers et des Product designers Des Data Engineers et Data Analysts Une équipe IT, Sécurité et Conformité Profil recherché Tu es passionné.e par la Data, avec au moins 3 années d’expériences comme Data Engineer (H/F/X) Tu as déjà mis en place un ELT Tu as déjà travaillé avec un orchestrateur comme Airflow, Dagster, etc. Tu maîtrises Python et SQL Tu as déjà utilisé Docker et tu as une appétence pour les sujets DevOps Tu as l'esprit d'équipe et tu es à l'écoute Tu as la volonté d'apprendre, de progresser et de t'adapter rapidement à notre environnement technique Les + Tu maîtrises Airflow et dbt Tu as déjà contribué au développement d'API Tu as déjà utilisé Kubernetes Tu as une expérience sur le suivi des Data d’un produit Ce que tu trouveras chez Yousign : Une scale up qui place le Produit et la Technologie au coeur de sa stratégie Une méthode de management qui favorise l’autonomie et l’alignement de toutes les équipes sur des objectifs communs ( OKR ) Un environnement propice à l’apprentissage et à la progression Une rémunération attractive et des BSPCE Un environnement à la fois bienveillant, exigeant et très stimulant Un vrai équilibre entre vie personnelle et professionnelle Une véritable culture du travail en remote Les meilleures conditions de travail, quelle que soit ta préférence Si tu es à Paris: les locaux en plein coeur de Paris au sein du Musée de la Marine Si tu es à Caen: les locaux sur le port de Plaisance Si tu es en full-remote: un budget qui te permet de t'équiper chez toi La carte Swile : 9,5 € de tickets restaurants par jour travaillé Le CE Leeto : plein d’avantages pour les loisirs, bons d’achats, etc. Une très bonne mutuelle et prévoyance RTT + journée de solidarité offerte Un budget de 400€/an pour participer à un event de ton choix Si tu ne remplis pas 100% des critères ci-dessus, dis-nous pourquoi tu serais quand même un bon candidat pour ce rôle dans ta candidature ! Blog Tech Career Page & Values Stack","Yousign, a European electronic signature scale-up, is looking for a Data Engineer to maintain and develop their Data Platform. The successful candidate should have at least three years of experience as a Data Engineer, have worked with an orchestrator like Apache Airflow, and be knowledgeable in Python and SQL. Compensation includes an attractive salary and BSPCE, a favorable work-life balance, and excellent working conditions in Paris or Caen, or a full-remote option.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
203,55422,https://www.welcometothejungle.com/fr/companies/homeserve/jobs/analytics-engineer-h-f_lyon,Analytics Engineer,HomeServe,"{durable,moderne,BigQuery,Git,SQL,Tableau}",Télétravail total possible,"9, Rue Anna Marly, Lyon, 69007",Assurance,CDI,2023-03-24,"Lancée en 2001, HomeServe France est une société de services pour la maison. Notre mission ? Améliorer, entretenir et intervenir en faveur d’un habitat durable, avec une offre de travaux pour la maison, d’installation des équipements et de réparation des pannes 7j/7 pour nos clients partout en France. Pour assurer le bon fonctionnement de l’habitat et contribuer à son efficience globale, nos 4 000 professionnels experts en plomberie, électricité, chauffage, climatisation et rénovation énergétique interviennent toutes les deux minutes chez nos 1,3 million de clients. HomeServe France emploie plus de 1200 talents animés par un seul objectif : déployer leur énergie au service de la transition énergétique de la maison de chacun de nos clients. Chaque année, plus d’une centaine de collaborateurs prennent part à l’aventure HomeServe. Issus d’horizons très différents, ils participent pleinement à notre croissance, notre transformation digitale, nos engagements RSE formulés au sein de notre programme “Empreinte 2030” et l’accompagnement de nos clients au quotidien. Alors, pourquoi pas vous ? A propos de nous HomeServe est une société de service experte de la maison depuis plus de 20 ans en France. Nous améliorons, entretenons et intervenons en faveur d’un habitat durable auprès de nos 1,3 million de clients. Comment ? Avec un service d’assistance et de dépannage simple et rapide, l’installation et l’entretien d’appareils de chauffage et climatisation et l’investissement sur l’ensemble des infrastructures de la maison permettant d’agir sur son bilan carbone final. Notre ambition est de couvrir toutes les réparations et tous les travaux, pour chaque maison. Intégrer HomeServe, c’est rejoindre Une entreprise “Great Place to Work” et “Best Workplaces 2021 et 2022” Un service client certifié « Élu Service Client de l’Année » 7 années consécutives, dans la catégorie Services à l’Habitat Une entreprise engagée en faveur du développement durable avec son programme RSE Empreinte 2030 qui repose sur 3 piliers stratégiques : l'environnement, les Hommes et la société et le Client LE POSTE: Rattaché(e) au responsable Analytics Engineer, vous êtes en charge de fournir, sous le meilleur format, l’information la plus adaptée pour répondre aux enjeux des métiers. Grâce à votre contribution, le pôle Business Analytics met en œuvre la stratégie Data dans une logique de création de valeur en termes de génération de revenus, d’amélioration de l’expérience client et d’efficience opérationnelle. Sur ce poste, vous jouerez un rôle clé dans une nouvelle organisation Data positionnée au cœur des ambitions stratégiques de HomeServe. Vos principales missions : Fournir et maintenir des jeux de données propres et documentés Etre garant et référent des sujets de modélisation de données de manière à faciliter leur exploitation Mettre en place et opérer les contrôles sur les données Veiller à l’exploitation du code analytique (environnement IDE, versionning, testing,…) Agir comme bras armé “technique” au pôle gouvernance pour appliquer des bonnes pratiques de développement, comme le contrôle des versions et l’intégration continue pour permettre aux Data Analyst et Scientist d’être plus efficaces Travailler en étroite collaboration avec les équipes métier. Vous serez garant du delivery Data et référent dans le cadre des évolutions menées Enfin, vous serez amené à collaborer largement avec les autres équipes du département (Data Governance, Data Platform et Datalab) respectivement garantes du socle technologique, de la qualité des données et de l’analytique avancée Etre Analytics Engineer chez HomeServe, c’est aussi : Avoir l’esprit d’analyse, être rigoureux et factuel Être autonome, vos prises d'initiatives sont fortement encouragées. Etre curieux et participer activement à l'amélioration continue de nos process déjà en place Partager son expertise auprès de la communauté Data Avoir une aisance relationnelle, l’esprit d’équipe et être un bon communiquant Être rythmé(e) par la diversité des missions et de nombreux projets Votre profil pour réussir dans ce rôle : De formation supérieure Bac+4/5, vous bénéficiez d’au moins 3 ans d’expérience dans la data Maîtrise des concepts de modélisation de données Orientation business démontrée dans vos précédentes expériences : vous êtes familiers des problématiques métiers et savez vous adapter au contexte de vos interlocuteurs Compétences techniques (SQL) combinées avec des capacités d’analyses et un sens prononcé du business. Connaissance des outils de CI/CD : (Git, Dataform, …) Capacité à challenger l’existant et essayer de nouvelles approches Capacité à gérer l’incertitude et d’avoir une approche “Test & Learn” Capacité à travailler dans un environnement transverse et multiculturel La maîtrise de BigQuery et de Tableau Software sont des plus La maîtrise des outils de Digital Analytics (type GA, Piano Analytics) est un plus. Ce que HomeServe vous propose : Prise de poste : dès que possible Lieu : Lyon 7ème Jean-Macé (desservi bus, métro, tram, train) Type de contrat : CDI Rémunération : 45-48 K€ Avantages: Participation, intéressement , carte ticket restaurant, transport en commun remboursés à 70%, train à 85% et indemnité kilométrique vélo, chèque CESU… Un espace de travail moderne qui favorise le bien-être au travail (locaux, outils, conciergerie…) Télétravail nomade possible 10 jours /mois Process Recrutement : - Un échange téléphonique avec le recruteur pour faire connaissance - Un entretien avec manager et recruteur - Cas pratique : Une mise en situation permettant de vous projeter dans le poste Pour en savoir plus, rendez vous sur le site HomeServe : www.homeserve.fr","HomeServe France, a company providing services for homes, is seeking an Analytics Engineer to provide and maintain clean and documented datasets for the Business Analytics team. The ideal candidate should have at least 3 years of experience in data and be proficient in data modelling, SQL, and Git, preferably with knowledge of BigQuery and Tableau Software. They should also have strong communication skills, be autonomous, curious, and able to adapt to different contexts. This is a full-time position based in Lyon, France, with a salary range of €45-48K and benefits including remote work, training, and development opportunities.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,3,1,0.05539549888311683
457,50246,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-remote-germany_berlin,Software Engineer Data Preparation - Remote Germany,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",Télétravail total possible,Berlin,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working 'œunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a full-stack software engineer to work on data preparation and other core features of its platform. The ideal candidate should have experience in software development and data processing, be customer-oriented, and have firsthand product building experience. Skills in Java, Javascript, and Python are also preferred. Dataiku's culture emphasizes work-life balance, autonomy, and caring for employees, and the company is committed to diversity and equal opportunity employment.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
422,38988,https://www.welcometothejungle.com/fr/companies/datadog/jobs/data-engineer-data-science-engineering_paris_DATAD_qgKMNzV,Data Engineer - Data Science Engineering,Datadog,"{Java,Go,color,Scala,observable,GitHub,scale,Luigi,Kafka,Spark,Datadog,Hadoop,Python}",Télétravail total possible,"21 Rue de Châteaudun, Paris, 75009",SaaS / Cloud Services,CDI,2022-11-21,"Datadog (NYSE: DDOG) is a world-class SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers for engineers, Datadog is used by organizations of all sizes across a wide range of industries. We bring together end-to-end traces, metrics, and logs to make applications, infrastructure, and third-party services entirely observable. These capabilities help businesses secure their systems, avoid downtime, and ensure customers are getting the best user experience. About Datadog: We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way. We need you to design and build machine learning-powered products that help our customers learn from their data and make better decisions in real-time. The Team: We extract and manage data and events from our core products and live systems to make them centrally available for our Data Science team in both batch and real-time ways. We enable Data Scientists to productionize their models and expose their data assets to the rest of the company. If you’re excited to work on a fast-moving data engineering team with the best open-source data tools at high scale, we want to meet you. You Will: Build distributed, real-time, high-volume data pipelines and work together with others to enable high-scale Data Science Do it with Spark, Luigi, Kafka and other open-source technologies Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more Join a tightly knit team solving hard problems the right way Own meaningful parts of our service, have an impact, grow with the company Requirements: You have a BS/MS/PhD in a scientific field or equivalent experience You have built and operated data pipelines for real customers in production systems You are fluent in several programming languages (JVM & otherwise) You enjoy wrangling huge amounts of data and exploring new data sets You value code simplicity and performance You want to work in a fast, high growth startup environment that respects its engineers and customers You are preferably familiar with Spark and/or Hadoop and know how to put machine learning models in production Is this you? Send your resume and link to your GitHub if available. #LI-ER1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice .","Datadog is seeking a data engineer who can design and build machine learning-powered products that help customers make better decisions in real-time. Candidates must be comfortable working with Spark, Luigi, Kafka, and other open-source technologies to build distributed, real-time, high-volume data pipelines. The ideal candidate has a scientific degree or equivalent experience, experience building and operating data pipelines, and enjoys wrangling big data sets. Fluency in multiple programming languages and familiarity with Spark and/or Hadoop are also preferred.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
421,38955,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-f-h_massy,Data Engineer,Thales,"{MongoDB,Ruby,Java,moderne,R,PHP,Python}",Télétravail total possible,Rungis,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2022-11-21,"Ceux qui font avancer le monde s’appuient sur Thales. Dans un monde en constante mutation, à la fois imprévisible et riche d’opportunités, ils sont aux côtés de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus sûr. Riches de la diversité de leurs expertises, de leurs talents, de leurs cultures, leurs équipes d’architectes conçoivent un éventail unique de solutions technologiques d’exception, qui rendent demain possible dès aujourd’hui. Du fond des océans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients à maîtriser des environnements toujours plus complexes pour prendre des décisions rapides, efficaces, à chaque moment décisif. Quel que soit l’enjeu. QUI SOMMES-NOUS ? L’activité Systèmes terrestres et aériens conçoit des systèmes, des équipements, des capteurs et des services pour le contrôle du trafic aérien civil et militaire, la défense aérienne ainsi que le combat naval et terrestre.Le site de Rungis est idéalement situé à proximité de l’aéroport d’Orly. Site à l’architecture moderne, il compte aujourd’hui plus de 1000 collaborateurs travaillant pour nos trois domaines d’activité : les radars, le contrôle du trafic aérien et les systèmes d’armes avancés. QUI ETES-VOUS ? Vous êtes une personne de défis et de terrain. Vos expériences ont forgé votre conviction que l’Agilité et le Lean permettent à tous et chacun d’apprendre, et à l’entreprise de progresser et de s’adapter dans la durée. Au sein de notre équipe de Data Management du centre de compétence commun aux Business Lines Airspace Mobility Solutions (AMS) et Integrated Airspace protection Solutions (IAS), vous construisez et optimisez le système de gestion des données d’ingénierie. Dans ce cadre, vous êtes responsable de la construction des pipelines de données. Vous êtes titulaire d'un (BAC +5) type une école d'Ingénieur ou d'un parcours universitaire et vous avez une expérience en analyse de données; Vous faites preuve de motivation, d'autonomie et d'initiative; Vous faites preuve d'une grande disponibilité et d'une très forte réactivité; Votre esprit d'équipe n’est plus à prouver et vous aimez le travail collaboratif. CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Vous serez en charge de : Utiliser vos compétences analytiques pour améliorer les outils et techniques, et collaborer ainsi à la conception et au développement de solutions innovantes Établir une documentation technique en rassemblant les données et les besoins Agir en tant qu'interface entre l'équipe Data Engineering, les clients et les autres contributeurs internes de Thales Déployer l'approche DevOps et Continuous Delivery sur un développement, ainsi que les outils associés Déployer des technologies Back End (langages de programmation ou frameworks), notamment PHP, ASP, C++, C#, Java, Python, Ruby, REST, MongoDB, PaaS...) et Front End pour l’affichage des données (Power BI, …) Interagir avec un cloud (privé ou public), dans tous ses aspects (Infrastructure as a Service=IaaS, Container as a Service=CaaS, Platform as a service=PaaS) Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d’habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l’IGI 1300 SGDSN/PSE du 09 août 2021. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is seeking a Data Engineer to construct and optimize the engineering data management system in the Data Management team. The ideal candidate should possess a degree from an engineering school or university and have experience in data analysis. They should also be a team player, self-motivated, and exhibit a great deal of availability and initiative. The role involves using analytical skills to enhance advanced solutions, working as an interface between clients, and contributing to designing innovative solutions. The successful applicant will need to possess Level 1 Defense Secret clearance.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
66,73402,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech-londres_london,DataOps Engineer - Big Data & Analytics Fintech LONDRES,Opensee,"{go,kubernetes,aws,golang,pandas,python,numpy,scale,Unix,AWS,lambda,bash,azure,SQL,docker,Python,Bash,Docker,Kubernetes,linux}",Télétravail total possible,"London, EC2V 7NA","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee’s commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What’s in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client’s internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Duration : permanent contract Salary : Competitive, profile based Location : London (the City) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!",,Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,3,1,0.05539549888311683
16,73021,https://www.welcometothejungle.com/fr/companies/oh-bibi/jobs/data-software-engineer_paris,Data Software Engineer,Oh BiBi,"{Python,SQL}",Télétravail partiel possible,"16, rue d'Athènes, Paris, 75009","Application mobile, Jeux vidéo, Digital",CDI,2023-04-22,"Fondé en 2012 par d’anciens Gameloft, Oh BiBi rassemble actuellement une 60aine de salariés passionnés. Au commencement de Oh BiBi, il y avait un rêve très simple : libérer la créativité des équipes pour créer des jeux mobiles qui seraient les nouveaux standards de demain. Oh BiBi produit des jeux entre le casual et le midcore, c’est-à-dire des jeux qui sont jouables par le plus grand nombre possible, mais qui ont quand même une certaine profondeur. Loin de se cantonner à un genre de jeu unique, Oh BiBi ne s’impose aucune limite et travaille aussi bien sur des jeux de course, de tir, de simulation… avec à chaque fois une seule ambition : révolutionner le genre sur mobile ! Oh BiBi a fait de la performance, du plaisir de jeu et de la qualité esthétique des piliers de son travail. Join our innovative Data team as a Data Software Engineer, where you will collaborate closely with a Data Analyst, Data Scientist, and Head of Data. This role offers the opportunity to work on diverse projects and make a significant impact on our products. Responsibilities : Design and implement Reinforcement Learning systems for informed decision-making in A/B testing scenarios Develop state-of-the-art Recommender Systems to enhance our gaming experience Create cutting-edge Generative AI tools for generating personalized content Build efficient Data Analysis pipelines to empower Game and Marketing teams with key business insights Requirements : Master’s degree in engineering Strong proficiency in Python and SQL Prior experience in development, with a focus on data-driven products Ambition to grow and excel in various aspects of Software and Data Engineering Ability to quickly grasp and work with existing codebases Proactive mindset with a strong capacity for problem-solving Open to self-assessment and continuous improvement Thrive in a dynamic, agile environment and confidently communicate ideas and needs to team members",,Non spécifié,Entre 50 et 250 salariés,> 6 mois,2,2,0.05539549888311683
46,73223,https://www.welcometothejungle.com/fr/companies/ascor-communication/jobs/data-engineer-h-f_cesson-sevigne,Data Engineer,Ascor Communication,"{tableau,SAP,Qlik,Informatica,Tableau,SQL,Talend}",Télétravail total possible,"19, Rue du Chêne Germain, Cesson-Sévigné, 35510",Formation,CDI,2023-04-22,"Ascor Communication est une entreprise familiale rennaise, en forte croissance, co-dirigée par un trinôme femmes/homme, parfaitement complémentaire. Nous sommes l’une des références françaises dans le secteur du digital learning , et proposons notamment des formations dans le secteur de la beauté, de la petite enfance, de la cuisine, de la pâtisserie… Notre raison d’être : rendre la formation accessible au plus grand nombre . Certifiés AFNOR et QUALIOPI, (1ers en France dans notre secteur), nous formons ainsi chaque année plus de 6000 apprenants. Notre haut niveau d’exigence de la satisfaction client repose sur l’implication et l’adhésion de tous les salariés. Dans le cadre d’une création de poste et de la mise en place de notre entrepôt de données, nous recherchons : Un Data Engineer H/F. Rattaché au Directeur des Systèmes d’Information (DSI), vous aurez la responsabilité de ce projet. Vous aurez notamment pour missions de : Mettre en œuvre un projet Data/Business Intelligence ; Participer au recueil du besoin auprès des directions métiers ; Rédiger des spécifications fonctionnelles, applicatives, et techniques ; Collecter les données depuis diverses sources et les traiter dans un entrepôt de données ; Accompagner les services métiers dans l’élaboration de tableau de bord ; Préparer et dérouler les tests ; Accompagner dans la validation de livrables, l’assistance à la recette et la conduite du changement sur le projet ; Participer à la maintenance corrective et évolutive de l’entrepôt de données. Nous vous proposons : Une formation interne de plusieurs jours (produits, outils, process…) et un accompagnement tout au long de la collaboration ; Un cadre de travail à taille humaine ; Une forte dynamique du fait de notre croissance ; Des bureaux desservis par les transports en commun ; 6 semaines de congés. Nos sites internet : www.espace-concours.fr https://www.welcometothejungle.com/fr/companies/ascor-communication De formation supérieure, vous justifiez d’une expérience de 5 ans. Vous maîtrisez les sujets de construction d’entrepôt de données et êtes capable d’en échanger avec des interlocuteurs métiers. Vous bénéficiez d’une expertise sur des outils ETL du marché (Informatica, Talend, Big Query, Data Factory, etc) et sur la création de tableau de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI…). SQL n’a plus de secrets pour vous. Votre esprit d’analyse et de synthèse sont souvent reconnus. Vous êtes autonome et organisé, et vous savez piloter des projets. Vous appréciez travailler en équipe, dans un contexte multi-projets. 1. Merci de nous faire parvenir un CV ainsi que quelques lignes de votre motivation pour ce poste ; 2. Si votre candidature est retenue, un premier échange téléphonique sera réalisé ; 3. Si ce dernier est concluant il aboutira à second entretien.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
417,38957,https://www.welcometothejungle.com/fr/companies/side/jobs/data-engineer_paris_SIDE_kJgLeMw,Data Engineer,Side,"{git,Go,Airflow,scale,Luigi,Kafka,Spark,Docker,SQL,Python}",Télétravail total possible,"33, Rue La Fayette, Paris, Paris, 75009","Application mobile, Recrutement",CDI,2022-11-21,"👉​ Side est l’agence d’intérim 100% en ligne et humaine. Elle a été lancée en 2016 par 4 amis tout juste sortis de leurs études. Après de nombreux jobs étudiants, ils étaient convaincus qu’en utilisant le digital, il était possible de créer une nouvelle expérience de travail temporaire, plus simple, plus fiable et plus épanouissante. 🤝​ En Mai 2022, Side a rejoint le groupe Randstad, pour avoir le plus d’impact possible sur le marché de l’intérim, et pérenniser son business model. Side pourra bénéficier de l’expertise du géant de l’intérim, des connaissances métiers des différentes filiales du groupe, et d’un réseau d’agences avec lesquelles ils pourront collaborer, tout en gardant l’ADN start-up, la vélocité et l’atmosphère bienveillante et dynamique qui a toujours existé au sein de l’entreprise. 🧑‍🤝‍🧑 Side a donc rassemblé une équipe de +60 collaborateurs, tous mobilisés pour créer la meilleure expérience intérimaire en France, ainsi que 300,000 “Siders” et 2,000 clients - de la start-up au grand groupe (Etam, Go Sport, DB Schenker, Stuart, Blablacar…). 👔​ La mission de Side est d’équiper les entreprises et candidats avec une technologie au service de l’humain, pour que les contrats courts soient synonymes de sérénité et d’intégration sur le marché de l’emploi. 📱​ Ils développent une app mobile pour les candidats et un outil en ligne pour les entreprises, qui leur permettent de travailler ensemble en moins de 24h, sans se soucier de la charge administrative. Pourquoi rejoindre Side ? 💥 Tu souhaites avoir un réel impact sur le marché du travail de demain ? Nous avons besoin de talents comme toi ! 💫 Notre mission est d’apporter une nouvelle expérience du travail temporaire à nos candidats et entreprises partenaires : plus fiable, plus simple et plus humaine que ce qui existait jusqu’à présent. Nous sommes une agence en ligne d’intérim, qui se différencie des autres par : la fiabilité du service la simplicité d’usage l’ humain incarné par nos équipes et nos solutions. Notre rôle est d’apporter un tremplin vers l’emploi pour les candidats et une haute qualité de service pour les entreprises qui recrutent. 🌟 Les 3 valeurs clés chez Side sont les suivantes : Fight For “Yes” signifie : rester positif, quoiqu’il arrive, car les choses se passent rarement comme prévues. Chercher et trouver des solutions. Vivre l’aventure avec enthousiasme. Chez Side nous prenons du plaisir autant dans les grandes victoires que dans les petits accomplissements du quotidien. Be Champions signifie : voir les choses en grand ! Se mettre à la place de l’utilisateur, construire la meilleure expérience de travail en faisant preuve de créativité, d’excellence et d’engagement. Travailler à devenir chaque jour un peu meilleur.es, tels des sportifs de haut niveau, pour avoir un impact réel sur le futur du travail en France et dans le monde. Be Buddies signifie que Side était d’abord une équipe avant d’être une entreprise. Les intérêts collectifs passent toujours avant les intérêts personnels. Nous demandons à chacun de faire preuve d’empathie et de solidarité avec les autres. De communiquer régulièrement sur son état d’esprit, notamment dans le cadre du télétravail. Ta future équipe : 👫 L’équipe Produit est une équipe soudée et animée par des valeurs fortes forgées au fil des années. Rejoindre Side, c’est rejoindre une équipe d’une dizaine de personnes aux expertises diverses qui valorise : L’impact : avoir un état d’esprit positif, mettre du coeur à l’ouvrage et chercher à avoir un impact à la hauteur des problèmes rencontrés par les utilisateurs·trices en faisant preuve de curiosité et de pragmatisme ; L’apprentissage : adorer apprendre et relever de nouveaux challenges, comme ça a été le cas lorsque notre produit s’est restructuré pour transitionner vers le modèle intérim ; L’empathie : s’efforcer de se mettre à la place des autres, saisir le contexte et capter les priorités de chacun·e ; L’esprit d’équipe : mettre le collectif au centre, délivrer des retours constructifs et célébrer les réussites ; Le sens des responsabilités : construire des solutions durables grâce à une approche méthodique, organisée et exigeante qui permette de gagner la confiance des autres. Side garantit l’égalité des chances à tous les candidat.e.s. Chaque candidature reçue est prise en considération indépendamment de l’origine ethnique et raciale, des opinions, des croyances, du sexe, de l’orientation sexuelle, de la santé ou du handicap. Concernant le rôle : L’équipe Produit recherche un Data Engineer expérimenté pour renforcer ses rangs, et propulser nos produits to the next level ! ↗️ Ta mission : 💥 A l’aide de tes connaissances, de tes compétences, et de l’environnement Data stable et mature de Side, ton but sera de développer et d’approfondir notre culture très data-driven , pour permettre à Side de scale-up. Travaillant main dans la main avec l’équipe BI et l’équipe Produit, tu seras la personne en charge de fournir de la donnée à chaque Business Unit de Side : fournir de nouvelles sources de données, les enrichir pour obtenir des informations pertinentes et utiles, transformer la data grâce à nos outils d’analyse et proposer des retours qualitatifs (et vulgarisés) à chaque équipe en demande. En t’appuyant sur ton expérience et ton expertise, tu apporteras ton point de vue technique, dans le but d’améliorer la fiabilité et la qualité de notre donnée. Tu cherches à évoluer et à monter en compétence dans un environnement qui favorise l’efficacité et l’autonomie ? Alors rejoins-nous ! Nous avons besoin de ton aide pour : 🌟 Automatiser l’intégration de sources externes avec notre Data Warehouse, et améliorer les existantes, Concevoir et mettre en place du code Python et SQL pour créer et améliorer nos flux de données, et réduire les bottlenecks. Définir les processus et les règles qui viendront façonner la data de demain Aider Side à être encore plus data-driven ! Mettre en place des fonctionnalités ayant de l’impact, de la discovery jusqu’à la livraison. Améliorer (ou créer) des analyses existantes pour aider chaque business unit de Side à performer. Devient les yeux des BU ! Perfectionner nos processus de documentation et de schématisation de la donnée. Informations supplémentaires : 💡 Pense au futur : toujours anticiper un volume deux fois plus grand que prévu. Pense à l’équipe : les BU doivent être autonomes et doivent pouvoir exploiter ton travail sans être bloqués. Sois force de proposition : tu es libre d’expérimenter des modèles de machine learning sur des sujets qui te semblent appropriés. Ton profil : Un bon niveau d’anglais 1 ou 2 ans d’expérience réussi en Python deployé en production Expérience avec différents types de base de données, notamment celles avec du SQL. Expérience en développement conteneurisé (Docker) Expérience avec un VCS (git ou équivalent). Une expérience réussie sur un poste similaire est un plus Bonus 💯 Expérience passée avec des framework ETL (Apache Airflow, Spotify Luigi). Expérience passée avec des “stream processing frameworks” (comme Kafka ou Spark). Expérience précédente avec des frameworks Big Data et/ou OLAP databases. Connaissances basiques en statistiques descriptives Un appel de 15min avec une personne de l’équipe Produit Un entretien d’1h autour du mindset et des valeurs Sur une période de 48h - un (petit) test technique 30min à 1h de rencontre avec les membres de ton équipe Welcome on board !🎉 Les étapes peuvent être adaptées suivant les besoins des candidats.","Side, an online temporary work agency, is seeking an experienced Data Engineer to lead their data-driven culture and scale-up the business. The successful candidate will be responsible for providing data to each Business Unit of Side, automating external sources integration, and improving data extraction and transformation workflows. Side seeks someone who is proficient in Python, SQL, containerization, and version control systems, and has prior relevant experience. Fluency in English is required. Framework ETL, stream processing frameworks, OLAP databases, and basic knowledge of descriptive statistics are a plus.",Non spécifié,Entre 50 et 250 salariés,> 1 an,3,1,0.05539549888311683
436,49828,https://www.welcometothejungle.com/fr/companies/pricehubble/jobs/engineering-manager-data-ml-platform_vienna_PRICE_ZwAdjAL,Engineering Manager - Data & ML Platform,PriceHubble,"{Kubeflow,Azure,GCP,Tensorflow,scipy,AWS,scale,K8s,Keras,Sagemaker,Python}",Télétravail total possible,Vienna,"Logiciels, Immobilier particulier",CDI,2023-02-07,"PriceHubble is a Swiss B2B proptech company that builds innovative digital solutions for the real estate industry based on property valuations and market insights. Leveraging big data, cutting-edge analytics and great visualisation, PriceHubble’s products suite brings a new level of transparency in the market, enabling their customers to make real estate and investment decisions based on the most accurate data-driven insights (such as valuations, market analyses, value forecasts or building simulations) and enhance the dialogue with end consumers. PriceHubble’s digital solutions are designed to help all players across the entire real estate value chain (banks, asset managers, developers, property managers and real estate agents). PriceHubble is already active in 10 countries (Switzerland, France, Germany, Austria, Japan, Netherlands, Belgium, Czech Republic, Slovakia and the United Kingdom) and employs more than 200 people worldwide. About PriceHubble PriceHubble is a PropTech company with over 220 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Zürich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, Amsterdam and Tokyo. We work on international markets and we are backed by world-class investors. We have a startup environment, low bureaucracy, and an international team and business. The opportunity You will be part of the Data Products team, heading a team of experienced ML and software engineers who build PriceHubble’s Data and ML Platform. The Data & ML Platform Manager has a key role in supporting the excellence of PriceHubble’s products, by directing the development of the ideal environment for data engineering and science teams to innovate and deliver PriceHubble’s world-class, high scale, customer-facing real-estate inference products. As the leading member of the team, the empowerment and growth of your team members will be your main responsibilities. Moreover, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems. Through your contributions, you will help to: Build a team of experts focused on large scale data systems engineering. Manage, maintain and develop the organization’s ML and Data platforms, with a focus on usability, reliability, performance and efficiency. Define robust, maintainable, state-of-the-art distributed system architectures, to identify improvements to engineering processes and to improve efficiency and reduce effort in platform operation by creating repeatable and automated processes. Steer the development of infrastructure and systems supporting the deployment, monitoring, optimization and scaling of AI-based prediction and insight services in production, from conception to launch. Define requirements, create a roadmap and work with engineers to build, release, assess and iterate. Optimize and streamline the work of data engineering and data science teams, by designing tools and products to facilitate data exploration, model training, deployment and serving processes to achieve insights quality and service quality SLOs We will also expect you to always stay at the forefront of ML engineering, quality management, cloud and data ops best practices in the industry. Requirements BSc or MSc in computer science or related fields At least 1 year of professional experience managing a team of more than 3 engineers At least 2 years of professional experience working on ML platforms Passionate about data and engineering at scale Keen to help teams grow and learn, and to nurture an harmonious engineering culture Solid experience in communicating with both business and technical stakeholders Strong oral, written and presentation skills with ability to clearly explain complex concepts to a variety of audiences Strong practice using agile methodologies and DevOps methods Excellent skills in object-oriented programming, data structures, algorithms as well as designing distributed service architectures in a cloud environment Proficient in the Python data science ecosystem Experience with data systems, ML and ML ops in production, at scale: K8s, Kubeflow, Dataproc, Sagemaker, Tensorflow, scipy, Keras… Experience working with public cloud platforms (AWS, Azure or GCP) Value end to end ownership of projects, simplicity and getting the right things done Fluent in English both in writing and speaking * We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas. Benefits Join an ambitious and hungry team and enjoy the following benefits: 💰 Competitive salary because we always want to attract the best talents. 📘 Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success. 🏢 Very well-located offices with a great remote work policy and the possibility to work from different places. 🕓 Flexible working hours and work life balance.","PriceHubble is seeking a Data & ML Platform Manager with experience in managing teams of more than three engineers, ML platforms, and designing distributed service architectures in a cloud environment. The ideal candidate should possess proficiency in Python data science, object-oriented programming, and agile methodologies, and have excellent communication skills to interact with both business and technical stakeholders. The company offers competitive salaries, flexible working hours, and a learning and development program.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.05539549888311683
49,73261,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_RKKVNm,BI Engineer & Data Visualisation,Numberly,"{via,PowerBI,BigQuery,SQL}",Télétravail total possible,"28 rue de Châteaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception à la réalisation d’applications d’outils d’aide à la décision et monitoring de performance répondant aux problématiques métiers de nos clients. Vous êtes amené à : Intervenir sur des missions de cadrage et d’analyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de répondre aux attentes des clients; Concevoir et réaliser les reporting d’aide à la décision en apportant une attention aux enjeux de self BI, ainsi que sur l’UX/UI Desktop et mobile; Déployer des projets de Data Visualisation sous PowerBI en priorité mais possiblement en participant aux choix d’autres outils de restitution; Accompagner les clients dans la bonne compréhension et montée en compétence sur l’exploitation et le maintien des tableaux de bord. Vous assurerez également une veille technologique, et proposerez des solutions standardisées, fiables, évolutives liées à votre activité. Chez Numberly, nous partageons une passion pour la transmission : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment grâce : - aux “Jedi Master”, attribués à chaque nouvel arrivant- aux Vis ma vie dans des équipes différentes ;- aux Happy Meetings : des rendez-vous mensuels internes pour se retrouver avec toutes nos équipes dans le monde et partager l’actualité du groupe. Nous cultivons la liberté de parole qui permet à tous de participer au développement du groupe. Nous agissons positivement sur notre écosystème à travers 1000mercis impacts et via nos activités qui créent de la valeur dans l’Open Internet et participent à l’enrichissement de l’Open Source. Numberly est acteur de la diversité et Gender Equal by design : certification WeConnect International Un gender equity score de 97/100 Numberly est un environnement international avec plus de 30 nationalités dans nos équipes. Des bureaux à l’image de chacune des équipes, une bibliothèque généreuse, un grand studio de musique tout équipé, deux chats, du tri sélectif et du lombricompostage, la possibilité de venir avec votre animal de compagnie et de la place pour les vélos ! Dans chaque cuisine : café, thé, infusions à volonté et aussi des mystery lunchs, des cours de yoga, des cours de sport et des soirées (souvent déguisées). Possibilité d'être en remote jusqu'à 50% de votre temps (à organiser comme vous le souhaitez) et de travailler jusqu’à 60 jours (ouvrés) consécutifs en remote. Carte Swile ( titres-restaurants ). Mobilité possible dans nos différents bureaux à l'international. Numberly accueille les personnes en situation de handicap. Poste disponible à Paris ou Londres. Vous avez au moins 2 ans d'expérience dans la mise en place de projets datawarehouse et datamart. Vous avez une appétence particulière au domaine du Big Data, avec des réalisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et compétences sur les technologies suivantes : ETL et SQL. Vous êtes curieux(se), autonome, force de proposition et avez l’esprit d'équipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont récompensé le travail de Numberly en Europe et aux USA) au sein d’une équipe jeune (27 ans de moyenne d’âge) et internationale (25 nationalités). Encore mieux si Vous avez de l’expérience sur PowerBI et/ou BigQuery Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, média et la relation client.",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
455,57058,https://www.welcometothejungle.com/fr/companies/payplug/jobs/data-engineer_paris,Data Engineer,Payplug,"{MySQL,MongoDB,python,gitlab,Kubernetes,Docker,RabbitMQ,BigQuery,GCP,SQL,Python,Tableau}",Télétravail partiel possible,"110, Avenue de France, Paris, 75013","FinTech / InsurTech, E-commerce",CDI,2023-03-26,"Payplug est la solution de paiement française pensée pour les commerçants, e-commerçants de toutes tailles et fintechs. Avec notre plateforme technologique de pointe, nos outils dédiés à la conversion et notre maîtrise unique de la chaîne de paiement, nous vous invitons à viser le meilleur, et plus encore. Payplug, c’est une équipe de 400 passionnés dédiés à la réalisation de vos plus grandes ambitions. Nous accompagnons aujourd’hui 20 000 PME telles que Hast et Plantes pour tous, mais aussi de grands groupes comme Maisons du Monde, Veepee et kiwi.com. Payplug fait partie du Groupe BPCE depuis 2017. Payplug est la solution de paiement française pensée pour les commerçants, e-commerçants de toutes tailles et fintechs. Avec notre plateforme technologique de pointe, nos outils dédiés à la conversion et notre maîtrise unique de la chaîne de paiement, nous vous invitons à viser le meilleur, et plus encore. Payplug, c’est une équipe de 400 passionnés dédiés à la réalisation de vos plus grandes ambitions. Nous accompagnons aujourd’hui 20 000 PME telles que Hast et Plante pour tous, mais aussi de grands groupes comme Maisons du monde, Veepee et kiwi.com . Payplug fait partie du Groupe BPCE depuis 2017 NOTRE AMBITION : Garantir la qualité de nos produits Permettre aux équipes, et à nos clients, d’accéder à des données fiables et de couvrir leurs besoins dans chaque domaine ! Nous développons : Des reports à destination de nos clients. Des calculs d’indicateurs stratégiques. Des dashboards de pilotage, de launch control et de discovery. Des reporting et des analyses de données. Des contrôles industrialisés et des alertes. Des flux de données avec nos partenaires. NOTRE MÉTHODE DE TRAVAIL : Nous sommes 10 dans l’équipe Data (Head of Data, Team Lead BI, Data Analysts & Data Engineers) répartis entre 2 squads. Rattachés au pôle Product & Tech, nous collaborons avec toutes les équipes de PayPlug. Pour relever les challenges métiers et clients, nous construisons une plateforme de données sur GCP (Google Cloud Platform), sur laquelle nous développons nos pipelines et nos solutions. Celle-ci remplacera à terme intégralement notre système existant. Les développements se font principalement en SQL et Python. Notre stack technique : ● Data : BigQuery, Cloud Composer/Apache Airlfow, Cloud Data Proc, Cloud PubSub ● BI: Tableau ● Infrastructure générale : Google Cloud Platform ● Conteneur et Orchestration : Docker, Kubernetes ● Versionning et CI/CD : gitlab & gitlab-CI ● Databases : BigQuery, MongoDB, MySQL, Vertica ● Message broker : RabbitMQ Tes missions Tu intégreras la squad Data, composée d’un data engineer, d’un Lead Technique et rattachée au Head of Data. Le rôle de cette squad est clé dans la construction et le maintien de la plateforme de données ! Tu assureras la mise en place des flux et modèles de données, en fonction des usages métiers. Tu seras garant de la qualité des données, du maintien des pipelines, de la documentation et de la performance de nos solutions. Dans tes missions tu seras aussi amené à échanger avec les autres équipes de Product & Tech (SRE, squads Product & Tech, squad BI, …). Requirements Data engineer avec au moins une première expérience ; Tu as déjà développé en SQL et python ; Tu as déjà travaillé avec GCP ; Tu as de l’expérience dans la construction, le maintien de pipelines de données, la modélisation, le monitoring et l’alerting. Autonome et rigoureux.se, tu as de bonnes qualités relationnelles, ainsi qu’un bon esprit d’équipe. Ce qui te démarque : De nature curieuse, tu aimes investiguer et comprendre les usages et pratiques en data engineering. Tu as de l’expérience avec le production-grade code (design pattern, test unitaire et d’intégration, CI/CD, …) Tu souhaites rejoindre une nouvelle équipe et construire une plateforme de données modernes et scalables. À l’écoute, tu es soucieux.se de répondre aux besoins de tes collègues. Hiring Process Appel de qualification avec Justine , Talent Managers (20-30') ; Test avec l’équipe Data (1h) ; Interview avec Guillaume , Head of Data (1h) ; 2 références. Benefits Modalités / avantages de travai l : Organisation de travail hybride ; 25 CP / an & 10 RTT / an ; Des bureaux dans le 13e arrondissement de Paris (Bibliothèque François Mitterrand). Avantages financiers : Carte Apetiz (titres restaurants) d’une valeur de 9€ par jour (52% pris en charge) ; Santé / Famille : Mutuelle santé Malakoff Humanis Abonnements aux transports publics ou Velib pris en charge à 50% par PayPlug. Autres : Moka.care pour le soutien à la santé mentale de chacun ; Windoo : activités de sport, bien-être et développement personnel ;","Payplug is looking for a Data Engineer with GCP experience to join their team, responsible for building and maintaining their data platform. The ideal candidate should have experience in pipeline construction and maintenance, data modelling, monitoring and alerting, as well as strong skills in SQL and Python. The company offers a hybrid work organization, 25 days of vacation, and benefits such as meal tickets, health insurance, and transportation benefits.",Non spécifié,Entre 250 et 2000 salariés,> 6 mois,2,2,0.05539549888311683
51,62906,https://www.welcometothejungle.com/fr/companies/kooperativa/jobs/data-engineer-m-z_praha_KOOPE_eb4q0pZ,Data Engineer (m/ž),Kooperativa,"{Jupyter,NiFi,MapR,Git,Gitlab,Airflow,Informatica,Kafka,Hadoop,Hive,Spark,Docker,Github,SQL,Zeppelin}",Télétravail total possible,"Pobřežní 665 , Praha, 18600","Assurance, Finance",CDI,2023-03-31,"Kooperativa funguje na českém trhu už čtvrt století a za tu dobu vyrostli do velké české firmy s mezinárodním rozhledem i partnery. Mají přes dva miliony klientů a chtějí víc než jen vyhovět jejich přáním a požadavkům, chtějí je předčít. Nechtějí být neosobní společností, ví, že aby byli úspěšní, musí dobře rozumět lidem a jejich osudům. To platí i o přístupu k zaměstnancům, v němž chtějí jít naproti specifickému potenciálu každého z nich a přistupovat férově ke všem bez výjimky. V týmu 6 Data Scientistů a nyní budujeme datalake pro uložení a analytiku velkých a nestrukturovaných dat. Hledáme nadšence pro moderní technologie, který nám pomůže s rozvojem nové platformy. Především pak s automatizací datových toků, architekturou uložení dat, nasazením ML modelů apod. Společným cílem je využít data pro rozvoj společnosti od reportingu až po implementaci modelů ML/AI a posouzení jejich praktického přínosu. Máme spoustu zajímavých analytických úloh zejména z oblastí rizikovosti smluv a klientů, identifikace a generování obchodních příležitostí, segmentace klientského portfolia a online chování klientů. V rámci skupiny VIG zastřešujeme Advanced Analytics Hub pro tvorbu statistických a ML modelů aBig Data Hub pro uchování a velké a nestrukturované data. Co vás čeká? Práce na zajímavých projektech s vysokým pozitivním dopadem na fungování pojišťovny a její klienty Práce s velkými a nestrukturovanými daty obsaženými v datech (telematika, IOT, kalkulace, přepisy hovorů, fotografie nehod, dokumenty …) Zajištění a automatizace datových toků uvnitř i mimo firmu Úzká spolupráce s data scientisty a datovým architektem, budeme součástí jednoho týmu Spolupráce při monitorování a provozu datového prostředí Co budete určitě potřebovat? Dobrou znalost Pythonu nebo PySparku včetně notebooků Jupyter nebo Zeppelin Dobrou znalost práce s relačními databázemi pomocí SQL Znalosti technologií pro DWH nebo datalake Zájem poznávat a učit se nové metody a technologie Co byte mohli znát, ale není to nutností? Předešlé zkušenosti s budováním big data řešení ve velké společnosti Znalost některých z nástrojů a technologií Spark, Airflow, MapR, Hadoop, Docker, OpenShift, Hive, NiFi Zkušenosti s integračními nástroji SSIS, ODI, Informatica, Pentaho Zkušenosti s technologiemi pro datové toky REST API, Kafka apod. Zkušenosti s nástroji pro správu a verzování kódu Git, Gitlab/Github Znalost principů datového modelování ETL/ELT Zkušenosti s nasazením a automatizací DevOps, CI/CD a MLOps Znalost principů a aplikací ML/AI modelů Co vám za to nabídnete? 32 dnů dovolené v roce (25 dnů dovolené + 5 volných dnů + 1 charitativní den + 1 den péče) Flexibilní pracovní doba + možnost práce z domova Cestovní pojištění zdarma, nadstandardní příspěvek na penzijní připojištění (až 1 000 Kč měsíčně) a životní pojištění (až 3 150 Kč měsíčně), těšit se můžete také na velké slevy na naše produkty a na produkty našich obchodních partnerů V rámci bonusového programu Cafeterie dostanete 12.000 Kč (v benefit bodech) a to, jak je uplatňovat, je jen na vás (sport, relax, kultura, dovolená, pobyty, apod.) Dotovaná karta MultiSport za 500 Kč měsíčně Stravné 130 Kč/den (Kooperativa nám nájem 105 Kč) - v Praze máme vlastní jídelnu, bistro a kavárnu Interní i externí kurzy (IT a jazykové kurzy, vzdělávací platforma Seduo), firemní kouč a psycholog, využít můžete i naši firemní knihovnu Rozvojové a sportovní akce, zdravotní a preventivní programy, ale také možnost nadstandardní zdravotní péče (fyzioterapie, jóga, očkování) Za doporučení nového kolegy vás oceníme až 45 000 benefit body do Cafeterie Zaměstnanecký mobilní tarif, pracovní telefon a notebook je samozřejmostí","Data Scientist with experience in Python or PySpark, SQL, and DWH/Datalake technologies sought by Kooperativa to work as part of a team of 6 data scientists to build a datalake for storing and analyzing large and unstructured data. The successful candidate will be involved in automating data flows, deploying ML models, and collaborating in the development of analytical solutions in the areas of risk management, customer segmentation and behavior. Kooperativa offers a range of employee benefits, including flexible working hours, home-office opportunities, and access to training and development programs.",Non spécifié,> 2000 salariés,Non spécifié,3,1,0.05539549888311683
33,56777,https://www.welcometothejungle.com/fr/companies/betclic/jobs/data-engineer-h-f_bordeaux,Data Engineer,Betclic Group,"{durable,Jenkins,Scala,AWS,Uber,Snowflake,Java,Github,Python}",Télétravail total possible,"117 Quai de Bacalan, Bordeaux, 33300",Application mobile,CDI,2023-03-26,"Entreprise française leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c’est : 🧑‍🤝‍🧑 11 millions de joueurs vibrants au rythme des compétitions sportives ⭐️ Une offre très large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ⚽️ Plus de 50 sports ouverts aux paris 📅 300 000 évènements sportifs disponibles aux paris chaque année 🖥 60 000 évènements sportifs diffusés en live chaque mois 🎰 Plus de 3 000 jeux de casino à expérimenter 🃏 Plus de 2 millions de parties de poker jouées chaque mois 🚀 De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l’UBB, les Boxers de Bordeaux… Depuis sa création en 2005, Betclic est une société de technologie “mobile-only”, animée par une passion inébranlable pour le sport. Guidé par l’émotion et le plaisir du jeu, Betclic développe des applications de divertissement mobile et place ses clients au cœur d’une expérience de jeu unique en innovant avec agilité et rapidité pour offrir toujours plus de jeux et plus de fun à ses joueurs. Notre ambition ? Proposer à nos clients l’expérience de jeu la plus divertissante grâce à des applications simples, immersives et innovantes. Betclic, dont le siège est à Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalités parmi ses 800 collaborateurs répartis dans 5 pays d’Europe : France, Italie, Malte, Pologne, et Portugal. WE ARE BETCLIC Entreprise française leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c'est : ‍‍ 11 millions de joueurs vibrants au rythme des compétitions sportives ⭐ Une offre très large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ⚽ Plus de 50 sports ouverts aux paris 300 000 évènements sportifs disponibles aux paris chaque année 60 000 évènements sportifs diffusés en live chaque mois Plus de 3 000 jeux de casino à expérimenter Plus de 2 millions de parties de poker jouées chaque mois De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l'UBB, les Boxers de Bordeaux… Depuis sa création en 2005, Betclic est une société de technologie 'mobile-only', animée par une passion inébranlable pour le sport. Guidé par l'émotion et le plaisir du jeu, Betclic développe des applications de divertissement mobile et place ses clients au cœur d'une expérience de jeu unique en innovant avec agilité et rapidité pour offrir toujours plus de jeux et plus de fun à ses joueurs. Notre ambition ? Proposer à nos clients l'expérience de jeu la plus divertissante grâce à des applications simples, immersives et innovantes. Betclic, dont le siège est à Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalités parmi ses 800 collaborateurs répartis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal. Les profils recherchés sont ceux qui ont l'ambition de construire en équipe, qui sont prêts à relever des challenges tous plus passionnants les uns que les autres, et qui ont cette volonté de créer des solutions offrant une expérience client inédite. L'univers du sport et du jeu vous fait vibrer ? Vous aimez les défis et participer à l'effort collectif ? Betclic vous propose de rejoindre l'aventure ! #JoinBetclic #WeAreBetclic ENTER THE GAME En tant que Data Engineer / Data Ops, vous intégrez l'équipe Data Platform composée de Data Engineer, Data/ML Ops, architecte et dont le rôle est de garantir la disponibilité de la plateforme et mettre en place les outils et bonnes pratiques autour de la data. Les équipes Tech Betclic sont organisées autour des principes de développement agiles et s'organisent en squad et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique. Grâce à cette organisation vous bénéficierez de la responsabilité de A à Z de vos projets : conception, développement, livraison, suivi de production. You build it, you run it ! En rejoignant nos équipes Betclic, vous intégrerez une équipe Fullstack où vous jouirez d'une autonomie vous permettant de vous enrichir au contact de développeurs Backend ou Frontend, de testeurs et de guildes transversales en charge d'expertises complémentaires (DBA, SRE, ARCHI, CI/CD, DATA, etc…). YOUR ROLE WITHIN BETCLIC A partir de l'existant, contribuer à la définition et à la mise en œuvre de la nouvelle génération de l'écosystème data qui supporte la proposition d'expériences toujours plus fun pour nos joueurs. Dans ce cadre, vos missions sont les suivantes : Participer aux phases de conception et de développement des projets et services data, accompagné par les autres membres de l'équipe et des architectes / SRE Accompagner les Data Scientist/Analyst dans la mise en place des algorithmes de data science (passage à l'échelle, suivi des bonnes pratiques) Automatiser le déploiement des projets réalisés par le développement d'InfraAsCode (IaC) et de pipelines CI/CD Maintenir et monitorer la plateforme data En fonction du niveau d'expérience, accompagner les développeurs juniors dans leur montée en compétence technique TECHNICAL ENVIRONMENT Python / Terraform / Serverless AWS Snowflake Jenkins / Github WHO WE ARE LOOKING FOR? Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, [un amour pour la technique], un peu de zèle et une réelle passion pour leur métier ! Ce job est fait pour vous si : Vous êtes diplômé(e) d'une école d'ingénieur, école informatique, MIAGE Vous disposez d'une expérience professionnelle réussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud Public Vous êtes doté(e) de fortes compétences en développement, d'une appétence pour l'automatisation (CI/CD) et le scripting et vous souhaitez rejoindre un environnement professionnel challengeant. Vous êtes sensible à la performance, la fiabilité, la maintenabilité et la scalabilité de votre code et des architectures que vous concevez Vous maîtrisez impérativement un des langages de développement Python, Scala, Java et vous avez une expérience réussie avec l'Infrastructure As Code Et enfin, vous parlez anglais couramment WHAT CAN YOU EXPECT? Un package de rémunération attractif 25 jours de congés payés et 10 jours de repos compensateurs Une carte Ticket Restaurant® financée à hauteur de 50% (10€/ jour) Une mutuelle d'entreprise prise en charge à 100% pour vous et vos enfants Un abonnement de transport pris en charge à hauteur de 50% ou une prime annuelle de mobilité durable (200€ pour les trajets domicile – travail en transport durable) Un pack mobilité (aide au déménagement) Une flexibilité de travail encadrée par un accord sur le télétravail Un souci constant de développement des compétences avec un programme de formation annuel personnalisé Des évolutions de carrière dans un environnement international • Des locaux hors du commun avec un rooftop aménagé pour profiter d'animations régulières, de pauses et de déjeuners au soleil face à la Cité du Vin Des cours de sports 2 fois par semaine Et l'opportunité de travailler dans une atmosphère conviviale, jeune et fun ! Poste en CDI à pourvoir dès que possible à Bordeaux Betclic Group - 117 quai de Bacalan 33300 BORDEAUX Tous nos postes sont ouverts aux personnes en situation de handicap.","Betclic, a French leader in online sports betting and gaming, is seeking a Data Engineer/Data Ops to join their Data Platform team. The role involves contributing to the development of a new generation of data ecosystem for improved player experiences, participating in the conception and development of data projects, and monitoring the platform's data. The ideal candidate has at least three years of experience in data engineering or operations within a public cloud environment, strong development skills, and fluency in Python, Scala, or Java. Betclic offers an attractive remuneration package, opportunities for career advancement, a flexible work environment, and a fun office culture.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
230,60556,https://www.welcometothejungle.com/fr/companies/eldo/jobs/data-engineer-f-h_toulouse_ELDO_995WWwA,Data Engineer,Eldo,"{MySQL,Talend,PostgreSQL,Airflow,AWS,via}",Télétravail total possible,"Lab'Oïkos Saint Aubin, Toulouse, 31000","SaaS / Cloud Services, Bâtiment / Travaux publics, Digital",CDI,2023-03-28,"Eldo, c’est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s’améliorer au quotidien pour développer leur activité 🚀💚 À propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l’amélioration de l’habitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la première plateforme européenne de solutions digitales à destination des professionnels, marques et consommateurs du secteur de l’amélioration de l’habitat. Nous sommes une équipe de passionnés qui souhaitent révolutionner le secteur de l’amélioration de l’habitat (76 milliards d’€). Avec notre suite SaaS nous accompagnons les pros et marques du secteur à développer leur activité en optimisant chaque étape du cycle de vente avec leurs clients. Du moment où ils les trouvent sur le web, jusqu’à leur satisfaction à la fin des travaux. Sur notre site B2C, nous aidons les particuliers à trouver des pros de confiance grâce aux avis et photos de leurs voisins, pour réaliser les travaux de leurs rêves. Nous avons un positionnement et un service unique avec : 💻📲 une suite applicative SaaS, développée avec et pour les pros et marques du bâtiment 📷💬 + 100 000 avis accompagnés de photos, vidéos ; 👨‍🔧 des milliers d’entreprises référencées avec un taux de renouvellement/satisfaction de 90%. 🏡💰 un partenariat avec Google et une certification AFNOR Lauréats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs à succès comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d’ici 2030 la première plateforme mondiale de solutions digitales à destination des professionnels de l’amélioration de l’habitat. Eldo, c’est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s’améliorer au quotidien pour développer leur activité 🚀💚 À propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l’amélioration de l’habitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la première plateforme européenne de solutions digitales à destination des professionnels, marques et consommateurs du secteur de l’amélioration de l’habitat. Nous sommes une équipe de passionnés qui souhaitent révolutionner le secteur de l’amélioration de l’habitat (76 milliards d’€). Avec notre suite SaaS nous accompagnons les pros et marques du secteur à développer leur activité en optimisant chaque étape du cycle de vente avec leurs clients. Du moment où ils les trouvent sur le web, jusqu’à leur satisfaction à la fin des travaux. Sur notre site B2C, nous aidons les particuliers à trouver des pros de confiance grâce aux avis et photos de leurs voisins, pour réaliser les travaux de leurs rêves. Nous avons un positionnement et un service unique avec : 💻📲 une suite applicative SaaS, développée avec et pour les pros et marques du bâtiment 📷💬 + 100 000 avis accompagnés de photos, vidéos ; 👨‍🔧 des milliers d'entreprises référencées avec un taux de renouvellement/satisfaction de 90%. 🏡💰 un partenariat avec Google et une certification AFNOR encore renouvelée cette année ! (processus de collecte, modération et restitution des avis) Lauréats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs à succès comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d’ici 2030 la première plateforme mondiale de solutions digitales à destination des professionnels de l’amélioration de l’habitat. Descriptif du poste Chez Eldo notre Dream Team s’agrandit ! 👩‍🚀 Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer. Si tu aimes la donnée et que les statistiques n’ont aucun secret pour toi… alors Alessandro et la team n’attendent que toi ! Regarde par la fenêtre de l’équipe Product Engineering ! 👁 La Team Product Engineering, c’est plus d'une dizaine de collaborateurs passionnés et ambitieux accompagnés par nos équipes marketing, sales, grands comptes…! Ton rôle chez Eldo Tu travailleras quotidiennement à l’ amélioration de nos applications (modifications de l’actuel et création) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualité et granularité de cette dernière, le tout, en étant un support pour les équipes en interne. Pour la partie “Engineer”, tu seras attendu sur la scalabilité de la partie Data, la mise en place d’architecture dédiée, la gestion de la sécurité de la data, la connexion entre l’architecture data et la partie applicative et développement produit. Pour la partie “Analyste” , tu seras en charge de recueillir les données internes (bases de données, fichiers…) et externes (HubSpot, Google Analytics, Partoo…), puis de les centraliser au sein d’un datawarehouse pour ensuite permettre leur restitution via un outil dédié à la Business Intelligence (tu seras force de proposition sur les outils à utiliser). Tu devras bien évidemment documenter et spécifier les éléments de services ou modèles développés, ainsi que maintenir une veille active sur les services utilisés et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus adéquates solutions. Ayant un rôle fortement orienté et drivé par l’Impact business et utilisateur, tu seras naturellement au sein de l’équipe Produit, composée de Product Manager, Product Designer. Tes échanges quotidiens seront bien évidemment avec cette équipe, mais pas que. Les développeurs et toutes les autres équipes seront pour toi des stakeholders privilégiés afin de répondre au mieux au besoin de la stratégie Produit et Entreprise. Les équipes Product Engineering (PE) travaillent en utilisant la méthodologie Agile. 🔝😍 Ce que l’équipe aime par-dessus tout sur ce poste L’humour au quotidien, via des petites blagues souvent de bonne qualité (mais pas toujours) La team Product Engineering Les afterworks L’aventure d’une belle croissance Pouvoir mettre sa pierre à l’édifice 👍 Les petits + qui font kiffer Contrat forfait jour + RTT Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge à 70% Un club employé (billetterie, produits high-tech, voyage, etc..) La carte tickets resto --> Swile est notre ami Primes cooptations Remote ponctuel où tu veux en France Goodies, welcome lunch & drinks (et pas que de bienvenue) 1 break dans l’année dans une destination surprise Eldo est la société qu’il te faut si tu aimes … 💚 Le management de proximité et impliquant L’autonomie, les prises d’initiatives, les challenges #growthmindset Évoluer au sein d’une équipe fun et bienveillante Les moments de partage en équipe L’idée de mettre ta pierre à l’édifice et de participer à une aventure humaine et professionnelle INCROYABLE Ton environnement de travail sera le suivant: MySQL, PostgreSQL ETL/ELT, Jobs Talend orchestrés par Airflow, Hevo data pour la partie no code. APIs d’outils externes à une entreprise (ex : Google Analytics, HubSpot…). Outils de reporting/dashboarding (Amazon QuickSight°. Toucan Toco pour la partie embed dans l’application) Outils de documentation, Confluence, et outils de suivi des tâches/incidents, JIRA. Environnement cloud (AWS) Cela pour être un super fit si en plus, tu as/es : Soft skills autonome curieux(se) une bonne communication diplomate un esprit de synthèse flexible Social skills Ouverture d’esprit Orienté Business Bienveillance Sens de l’initiative 🔎 Le process de recrutement chez Eldo 1 - Échange visio RH (45’) 2 - Use case 3 - Échange avec des membres de l’équipe Product Engineering ! (60’) 4 - Échange avec ton futur manager, le CPTO (60’) Ce poste peut-être en 100% en full remote avec des déplacements à prévoir 1 fois par mois sur Toulouse pris en charge par Eldo Alors, séduit(e) ? poste sans tarder ton CV et sors ta plus belle plume 😎 Eldo est une entreprise handi-accueillante","Eldo is hiring a data engineer to improve their applications by proposing data architectures, pipelines, and algorithms. The role involves ensuring data quality and granularity, supporting internal teams, and scaling data. The successful candidate will be responsible for collecting and centralizing internal and external data, maintaining a watch on industry developments, and suggesting appropriate solutions. The role is focused on business impact and user needs, working closely with the product management team. Eldo provides remote work opportunities and employee benefits.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,3,1,0.05539549888311683
64,73385,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f-h-f_paris,Data Engineer,TotalEnergies Digital Factory,"{Python,Azure,Spark,AWS,SQL}",Télétravail total possible,"31 rue des Jeuneurs, Paris, 75002","Logiciels, Big Data, Energie",CDI,2023-04-22,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. TotalEnergies a décidé d'accélérer la production interne de solutions digitales pour ses activités en créant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilité et l'esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Nous créons et déployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. Nous considérons les personnes comme la ressource la plus précieuse pour réussir, c'est pourquoi nous tenons non seulement à recruter les meilleurs talents, mais aussi à créer des liens uniques entre nos employés. En tant que Data Engineer, tu garantis la qualité des pipelines data du produit, tu assures le développement des programmes pour collecter, préparer, transformer et diffuser les données. Dans l'écosystème ultra dynamique des nouvelles mobilités (notamment électriques), en phase avec de grands enjeux sociétaux, nous attendons de toi que tu : · Conçoives, construises et intègres des données au sein de la Squad et en collaboration avec les autres Squads. · Assures le stockage, la consommation, l'intégration et la gestion des données des cas d'utilisation. · Fasses l'analyse de l'analyse de l'accessibilité des données et que tu recommandes des solutions pour leur intégration. · Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de données. Tu intègres également les données dans le data lake. · Collabores avec les data scientists pour la réalisation des modèles de prédiction. · Produises un code de qualité, mettes en place des tests automatisés et systématiques pour le contrôler. · Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacité des solutions et apporter des préconisations techniques. En parallèle, tu auras également des missions transverse. Pour ce faire, nous attendons de toi que tu : · Assures la veille technologique sur les architectures data et les nouvelles technologies. Coaches et accompagnes la communauté des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une expérience d'au moins 4 ans en data engineering, tu es diplômé d'un master ou d'une école d'ingénieur spécialisée en informatique ou mathématiques. Et si tu as déjà une expérience dans l'écosystème de la mobilité, de la recharge électrique ou du digital fueling, c'est top ! Les compétences qui sont attendues de toi en tant que Data Engineer : · La maitrise de Python, Spark et SQL. · Une bonne connaissance sur les bases de données relationnelles et non relationnelles. · La capacité à concevoir et à mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle. · Maîtrise des bonnes pratiques de monitoring des flux de données. · Une bonne compréhension du machine learning. · Une bonne connaissance des méthodes Agile (Scrum, Kanban, voir même SAFe ou Nexus). · Une culture tech tu sais concevoir et modéliser une solution informatique. · Si tu as toi-même de bonnes notions de développement, c'est un plus notable (stack technique : Cloud Azure ou AWS, C#, .Net). · Une expérience avec les outils de gestion de Backlog comme Jira ou Azure DevOps. Si tu en connais plusieurs, c'est encore mieux. · Une première expérience sur un provider de Cloud, AWS de préférence.",,Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
29,54715,https://www.welcometothejungle.com/fr/companies/wuest-partner/jobs/data-engineer_paris,Data Engineer,Wüest Partner,"{MySQL,MongoDB,ElasticSearch,Python}",Télétravail total possible,"1 Boulevard de la Madeleine, Paris, 75009","Logiciels, Intelligence artificielle / Machine Learning, Immobilier commercial",CDI,2023-03-24,"Wüest Partner est une société de conseil indépendante et innovante du secteur immobilier. Pionnière, l’entreprise combine depuis 1985, expertise immobilière, data et solutions digitales pour faciliter et fiabiliser les prises de décisions. Leur équipe, pluri disciplinaire et à taille humaine, apporte sa contribution à chacun de ces 3 piliers. • Vous piloterez vos projets dans l’extraction, l'uniformisation et la structuration des données • Vous améliorerez la qualité et enrichissez les bases de données existantes • Vous optimisez les flux de données entrants et sortants • Vous suivez des projets clients • Vous assurerez la veille technologique sur les outils Data et les nouvelles méthodes de modélisation Tout ceci en collaboration étroite avec les équipes internationales Vous êtes diplômé d’une école d’ingénieur ou équivalent (BAC +5), vous bénéficiez d’une première expérience dans la gestion de projet Data et vous souhaitez vous investir dans une structure innovante de taille humaine. Vous avez une aisance particulière pour prendre des responsabilités et pour travailler avec les autres équipes technologiques : Dev et Design Facilité de manipulation de tout type de base de données relationnelles (MySQL, Postgre) et non-relationnelles ( MongoDB, ElasticSearch) Développement machine learning (Python) et/ou backend (JS) – La maîtrise des deux est un énorme plus Vous êtes : - Curieux - Aimez les environnement agile - Travaillez en mode projet - Grande prise d'initiative, esprit ""self-starter"", autonomie dans l'exécution des tâches - Pro-actif Vous avez un anglais professionnel","Wüest Partner, an independent and innovative real estate consulting company, is seeking a Project Manager with expertise in data management and manipulation. The ideal candidate will have a degree in engineering or a related field, experience in project management, and skills in handling both relational and non-relational databases, machine learning development, and backend development. The role includes improving data quality, optimizing data flow, and keeping up with new data tools and methods. The candidate should be a self-starter with strong communication skills and the ability to work collaboratively with technology teams.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
249,2704,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote_paris,Software engineer Data Presentation - Remote EMEA,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",Télétravail total possible,N,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku’s culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . #LI-Remote About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku, a platform for Everyday AI, is seeking a software engineer with experience in software development and an interest in data visualization tools to build scalable, user-friendly interfaces for their platform. The ideal candidate will be customer-oriented, comfortable with both frontend and backend development, and have firsthand experience building a real product. Dataiku values a culture of autonomy, flexibility, inclusivity, and caring for employees' work-life balance. They are an equal opportunity employer committed to treating all employees with dignity, decency, and fairness.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
63,73377,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-quality-engineer-m-w-d_hamburg,Data Quality Engineer,Groupe SeLoger,"{AZURE,python,java,scala,sql,javascript,AWS,GCP}",Télétravail total possible,Hamburg,"Application mobile, IT / Digital, Média",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Français dans la réalisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d’offrir à chacun de nos utilisateurs, une expérience immobilière simple et efficace afin qu’ils concrétisent leurs projets d’achat, de vente ou de location en toute sérénité. Nous mettons à disposition des Français le plus large choix d’annonces afin de leur faciliter la recherche d’un bien selon leurs critères propres, et répondre à toutes les questions soulevées par la réalisation d’un projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque préférée des Français pour se repérer et se lancer dans leur projet immobilier. WHAT WE DO IN Marketplace Design– Product and Tech at AVIV The Marketplace Design Domain at AVIV group is part of the Product & Tech organization and its objective is to deliver the internal services that powers Actor teams to brings safety, trustworthiness and remove opacity from the experience. Building on local expertise from Immowelt (Germany & Austria), Immoweb (Belgium), Groupe SeLoger and Meilleurs Agents (France), we deliver fraud / cheat / information reliability assessment services to raise marketplace safety and reliability in the interactions between Seekers and Owner / Agent. WE ARE LOOKING FOR AN INDIVIDUAL WHO CAN: Will be part of an agile, multidisciplinary, international team and work closely with them to Identify data quality issues, and implement solutions to verify, validate, and monitor data quality. Contributes to analysis of data issues and help identifying business processes and technical improvements that contribute to higher quality data. Work with the product team to establish data quality standards within the sprints, develop a test plan and deliver high quality builds on time. Work with product owners and data engineers to improve the overall experience by suggesting improvements and changes. Design and maintain QA reports for the internal data systems. Align and collaborate with the rest of the data quality team to improve the overall quality, assess risks, promote consistency, identify common needs. Develop test strategies for automation both for backend and data. Write and execute both functional and non-functional data tests. You convince with your analytical way of thinking. INDIVIDUAL WHO HAS: Solid experience (at least 3 Years) as Data Quality Engineer. Practical experience working with agile methodologies. Degree in Computer Science or other relevant qualifications. ISTQB Certification is a plus. Practical experience creating and maintaining ETL and API tests. Experience in automating data tests with frameworks like Deequ or other. Experience in automating APIs tests with javascript or java libraries like fetch, superAgent, restAssured... You are comfortable reading and writing code in at least one programming language, ideally java, scala, python. Basic understanding of sql. Experience with CI/CD Tools. Basics in cloud experience like AWS, GCP, AZURE is plus. A proactive team player that analyses the risk and impact of issues and is working with the team to prioritise and resolve them. Any experience with performance, GDPR, accessibility, interoperability and security testing is a plus. Excellent communication skills, with fluency in English. Willingness to travel from time to time is available.",,Non spécifié,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
62,56598,https://www.welcometothejungle.com/fr/companies/blent-ai/jobs/data-engineer-poei_paris,Data Engineer (POEI),Blent.ai,{},Télétravail total possible,"198 Av. de France, Paris, 75013","Intelligence artificielle / Machine Learning, Big Data, EdTech",CDI,2023-03-26,"Tu es demandeur d’emploi et tu souhaites devenir Data Engineer ? Rejoins Blent.ai et intègre notre parcours d’excellence afin d’acquérir les compétences clés pour devenir Data Engineer, le métier le plus demandé du marché de la Data. Notre parcours mêle compétences techniques et softskills pour te rendre opérationnel dès ta sortie du parcours et faciliter ton intégration au sein de ta nouvelle entreprise. À l’issue de notre parcours tu intégreras d’ailleurs les équipes d’un de nos partenaires, en CDI. Les candidats retenus bénéficieront d’un parcours de montée en compétences d’excellence, entièrement pris en charge par Pôle Emploi dans le cadre du dispositif POEI (Préparation Opérationnelle à l’Emploi Individuel). Le Data Engineer accompagne les entreprises dans la construction d’infrastructures informatiques pour stocker, gérer et administrer de grandes quantités de données. Les compétences du Data Engineer peuvent être regroupées en 4 blocs de compétences : La mise en place et la maintenance de systèmes de stockage de fichiers et de bases de données. La création de clusters de calcul parallèle et de systèmes distribués. L’implémentation de systèmes de gestion de données en temps réel (Data Streaming). L’automatisation de pipelines de données et de déploiement de modèles de Machine Learning. Le Data Engineer est capable de construire des solutions techniques permettant de répondre aux problématiques de l’entreprise, aussi bien sur des sujets de marketing, commerciaux ou opérationnels. A qui cette formation s’adresse ? Les Data Analysts et Data Scientists qui souhaitent profiter de leur expertise Data pour devenir Data Engineer. Les développeurs qui souhaitent prendre le virage technologique du Data Engineering. Les étudiants et jeunes diplômés qui souhaitent apprendre le Data Engineering par la pratique et se familiariser avec le monde de l’entreprise. Ce que nous t’offrons : La garantie d’être opérationnel à la sortie de notre parcours d’excellence de 3 mois Un CDI auprès d’un de nos partenaire Un salaire attractif à la clé : 35 000€ à 50 000€ selon ton profil","Blent.ai is offering a three-month program for job seekers to become a Data Engineer, one of the most demanded roles in the data market. The program combines technical and soft skills to make candidates operational upon completion, and they will be guaranteed a permanent position with one of Blent.ai's partners. The Data Engineer's role involves the implementation of data management systems, real-time data management, and automated pipelines and machine learning deployment. The program is suitable for data analysts, data scientists, developers, and students who want to learn data engineering through practical experience.",Bac +5 / Master,< 15 salariés,Non spécifié,3,1,0.05539549888311683
4,58091,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_bordeaux,Data Engineer,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",Télétravail total possible,"Bordeaux, 33000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. • Conseil, Audit et Maitrise d’œuvre. • Études d’opportunité, cadrage de projet d’intégration de données et aide au choix de solution. • Accompagnement à la mise en place de Data Lake / Big Data. • Accompagnement de profil junior. • Conception et développement de flux d’intégration des données (ETL, ELT, streaming , API … ). • Conception et mise en œuvre de plateformes On Premise ou Cloud de stockage des données dans un Data Lake (Big Data). • Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.). • Migration des données. • Move to Cloud. • Compétences avérées en gouvernance des données, qualité des données et catalogue des données (>4 ans d’expérience dans le domaine) • Animation d’ateliers Métier/ IT de définition des processus d’intégration des données. • Animation d’atelier de définition de plateforme d’intégration et de stockage des données. • Proposition de type d’architecture de gouvernance (centrale, décentralisée, etc.). • Capacité à intégrer une équipe d’intégration des données. • Capacité à proposer des solutions & architectures de données. • Capacité à configurer des outils d’intégration et de Reporting des données. • Formation et pratique d’outils de Data Intégration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. ). CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital services and consulting, is seeking a Data Integration Consultant with experience in data governance, quality, and cataloging. The ideal candidate will have skills in advising and supporting businesses in their digital transformation, developing ETL workflows, and implementing storage solutions in Data Lake/Big Data platforms. Other required skills include proficiency in Cloud platforms, data migration, architecture governance, and tool configuration. CGI is an inclusive employer that values diversity, career growth, and employee well-being.",Non spécifié,> 2000 salariés,> 4 ans,3,1,0.05539549888311683
466,56887,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-data-reliability_paris_DATAD_234AOm7,Software Engineer - Global Data Platform,Datadog,"{Redis,color,Golang,Kafka,scale,Cassandra,Elasticsearch,Datadog,Python,Postgres}",Télétravail total possible,"21 Rue de Châteaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. How do you provide data to a real-time service that monitors hundreds of thousands of servers 24 hours a day? How do you ensure data correctness in the face of infrastructure failures and network partitions, in a high-volume, low-latency environment? What should the infrastructure look like when data may double in size or in throughput on short notice? If you think you have the answers, join us on the Global Data Platform team and help us ensure that we're providing reliable data, at scale, and quickly. At Datadog, we place value in our office culture - the relationships that it builds, the creativity it brings to the table, and the collaboration of being together. We operate as a hybrid workplace to ensure our employees can create a work-life harmony that best fits them. What You’ll Do: Keep our datastores reliable, available and fast. Respond to, investigate and fix issues, whether it’s deep in the database code or in the client application. Build tooling to minimize customer-facing downtime, and scale up resources on short notice Protect and ensure the consistency of customer data. Work with developers to design data models, and choose the correct datastores, to support orders of magnitude more customer data and traffic. Who You Are: You have min 5 years of experience in software engineering You value correctness and efficiency; you leave no stone unturned when diagnosing production issues You handle infrastructure with code because automation lets you focus on the more difficult and rewarding problems You have production experience with distributed datastores, e.g. Cassandra, Postgres, Kafka, Elasticsearch, Redis You have created tooling for, or submitted contributions to, an open-source datastore You are fluent in Python or Golang Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our Internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-AD1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice .","Datadog is seeking an experienced software engineer to join its Global Data Platform team. The successful candidate will be responsible for ensuring that the company is providing reliable data, at scale and quickly. Key responsibilities will include responding to, investigating and fixing issues, building tooling to minimize customer-facing downtime, and scaling up resources on short notice. The ideal candidate will have at least five years’ experience in software engineering, be comfortable handling infrastructure with code, and have production experience with distributed datastores. Strong Python or Golang skills are also required.",Non spécifié,> 2000 salariés,> 5 ans,3,1,0.05539549888311683
6,72850,https://www.welcometothejungle.com/fr/companies/spacefill/jobs/data-engineer_paris,Lead Data Engineer,Spacefill,"{Git,PostgreSQL,NoSQL}",Télétravail total possible,"29, Rue du Faubourg Poissonnière, Paris, 75009","Logistique, Supply Chain, SaaS / Cloud Services",CDI,2023-04-22,"La mission de SpaceFill est de flexibiliser les chaînes logistiques Européennes. Pionnier de la logistique digitale, SpaceFill a construit le premier réseau européen d’entrepôts, embarqué sur un logiciel SAAS. La plateforme permet à ses clients (PME comme grands groupes) de mieux gérer leurs stocks et flux de marchandises en quelques clics. Ils peuvent ainsi construire des chaînes logistiques plus efficaces, vertes et résiliantes au plus proche de leurs marchés. Fondée en juin 2018 et basée à Paris, SpaceFill connaît une croissance exponentielle dès le lancement de son service. Quelques mois plus tard l’équipe réalise une levée de fonds d’1M€ et remporte le premier prix Gallion Booster. Aujourd’hui, Spacefill : Une hypercroissance depuis 3 ans (9M€ CA) Plus de 350 clients à travers plus de 3000 entrepôts en France et en Allemagne, et se prépare à conquérir l’Europe. A levé 8M€, puis 25M€ début 2022 75 employés Spacefill permet à ses clients de piloter leur activité logistique à travers un réseau connecté d’entrepôts en Europe. En tant Lead Data Engineer, tu as la responsabilité de la modélisation de notre base de données, de la mise en place d’une data pipeline et de sa maintenance / évolution. Notre modèle repose actuellement sur une base de données PostgreSQL et la logique métier est encapsulée dans celle-ci. Sous la responsabilité du VP Engineering, tu auras comme mission d’établir la stratégie et le futur modèle qui permettra à Spacefill de “scaler” son produit et les use cases de ses clients. Tu travailleras étroitement avec les autres Leads techniques ainsi qu’avec l’équipe Produit. Informations complémentaires: Équipement : 1 Macbook Pro 16” M1Pro 32Go Ram ou ThinkPad + budget de set up de bureau Carte tickets restaurant Swile RTTs Assurance santé Alan Stock options (BSPCE) Télétravail partiel ou total possible Convention collective : Syntec Période d’essai : 4 mois renouvelable Maitrise de PostgreSQL, PL/PGSQL, triggers, migrations, etc Expérience et force de proposition dans le développement de data-pipelines / event driven architecture dans le cloud Connaissances ETL, traitement et agrégation de données Connaissances NoSQL Une bonne maîtrise de la communication orale et écrite Maîtrise de Git Forte autonomie Un premier échange téléphonique pour comprendre tes motivations à nous rejoindre, puis on se rencontre très rapidement! Un process simple et rapide en moins d’une semaine.",,Non spécifié,Entre 50 et 250 salariés,> 7 ans,3,1,0.05539549888311683
55,63027,https://www.welcometothejungle.com/fr/companies/alef-nula/jobs/data-centr-networking-engineer_praha,Data Center Networking Engineer,ALEF,"{Microsoft,Splunk,AWS}",Télétravail total possible,"Pernerova 691 , Praha, 18600","IT / Digital, SaaS / Cloud Services, Cybersécurité",CDI,2023-03-31,"…působí na českém trhu již od roku 1994. Za tu dobu se vypracovala v předního poskytovatele řešení s přidanou hodnotou v oblasti informačních technologií. Spolu s pobočkami na Slovensku, v Maďarsku, Slovinsku, Chorvatsku, Srbsku, Rumunsku a Řecku je významným partnerem značek Cisco, NetApp, F5, Microsoft, AWS a dalších v regionu střední a východní Evropy. Hluboké technologické znalosti jednotlivých řešení umožňují rozšiřovat nejen podíl samotných služeb, ale též portfolio nabízeních řešení a značek, mezi které například patří Splunk, AWS, Palo Alto a další. Tím hlavním, co ALEF odlišuje od ostatních je jedinečný přístup a zaměstnanci, kteří disponují dlouholetými špičkovými znalostmi Co Tě napadne jako první, když uslyšíš termín Datové Centrum? Pokud jsou to věci jako Cisco Nexus, VXLAN BGP EVPN, Cisco ACI, nebo REST API a DevNet, nepřestávej číst, do týmu totiž hledáme nového kolegu se zaměřením na sítě a automatizaci v datových centrech. Co tě u nás čeká? Možnost práce na celém životním cyklu technických projektů: Pre-sales – Aktivity zahrnující prezentace a konzultace pro zákazníky a partnery, výběr vhodného řešení, jeho nacenění, technická specifikace, podpora obchodného oddělení. Design – Vytváření High-Level a Low-Level design dokumentace, která detailně popisuje navrhované řešení, spolupráce v rámci různých týmů ve firmě na návrhu komplexních řešení. Proof-of-Concept – Ověřování designových rozhodnutí v interním labovém prostředí, případně přímo u zákazníka Implementace – Konfigurace zařízení podle navrhovaného designu, ladění a testování dodávaného řešení Post-implementační podpora – Oprava nestandardních stavů, chyb, konzultace, další rozvoj zákaznické infrastruktury Školení – Předávání znalostí a zkušeností zákazníkům, partnerům či kolegům prostřednictvím odborných kurzů a konzultací se zaměřením na sítě v datových centrech a související technologie Práce s nejmodernějšími (nejenom) síťovými technologiemi Práce v kolektivu špičkových odborníků a CCIE techniků Široká paleta možností a podpora sebevzdělávání a rozvoje Co bys měl umět a znát? Obecné znalosti sítí a TCP/IP stacku minimálně na úrovni CCNP Technologie druhé vrstvy (Ethernet, VLAN, STP, Port-channel, …) Technologie třetí vrstvy (IPv4, IPv6, ARP, ICMP, BGP, OSPF, VRF, multicast, redistribuce,…) Praktické zkušenosti s konfigurací a provozem síťových prvků společnosti Cisco Zkušenosti s přepínači Cisco Nexus a systémem NX-OS Komunikační a prezentační dovednosti v Češtině a Angličtině Schopnost týmové i samostatné práce Pozitivní přístup k životu a práci Výhoda: Znalost technologií vPC, BGP VXLAN EVPN, Cisco ACI … Výhoda: Zkušenosti s programováním/skriptováním a použitím API. Výhoda: Zkušenosti s orchestrátory typu Ansible, Terraform nebo Nornir Výhoda: CCNP Data Center / DevNet Sítě v datových centrech nejsou zase tak odlišné od klasických enterprise sítí a zkušenosti z této oblasti jsou velmi dobrým odrazovým můstkem pro přepnutí se do „DC módu“ A co ti můžeme nabídnout? Stravenkový paušál Možnost pracovat občasně z domova a neomezené sick days Služební telefon a pracovní notebook, což bereme jako samozřejmost :) Work life balance nám není cizí. Možnost až 10 dnů dovolené navíc dle odpracované doby Roční kupon na MHD, případně osobní automobil Výuku anglického jazyka Možnost multisport karty Výkonové odměny Benefits Bonusy/prémie Mobilní telefon Nadstandardní lékařská péče Notebook Příspěvek na dopravu Stravenky/příspěvek na stravování Vzdělávací kurzy, školení Občerstvení na pracovišti Zvýhodněné půjčky zaměstnancům Zdravotní volno/sickdays Možnost občasné práce z domova Firemní akce plat Dog-friendly office","A leading IT solutions provider in the Czech Republic seeks a networking and automation specialist for data centers. The ideal candidate should possess practical experience in configuring and operating Cisco network devices, knowledge of networking technologies, and proficiency in English and Czech. The job involves working on technical projects' entire life cycle, from pre-sales to post-implementation support, with a team of expert CCIE technicians. The company offers an attractive package, including training opportunities, flexible working hours, health benefits, and a dog-friendly office.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
247,4941,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-dataiku-online-remote-emea_paris,Software engineer Dataiku Online - Remote EMEA,Dataiku,"{React,Dataiku,python,regard,Kubernetes,Docker,Python}",Télétravail total possible,N,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online’s team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku souscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is fully remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented — you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: - Hands-on expertise working with Docker and Kubernetes - Experience on an high availability SaaS - Knowledge in DataScience, AI and Machine Learning - Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking a full-stack developer with experience in creating real SaaS portals to join its team in charge of developing the Dataiku Online Launchpad. The role involves actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Candidates should be customer-oriented, have a humble and kind attitude, and be proficient in Python (Flask) for the backend of the launchpad and VueJS for the frontend. Bonus points for experience working with Docker and Kubernetes, high availability SaaS, knowledge of Data Science, AI and Machine Learning, and highly advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular). This is a fully remote position.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
266,56943,https://www.welcometothejungle.com/fr/companies/ecovadis/jobs/data-engineer-f-m-d_berlin_ECOVA_VQ51pWx,Data Engineer,EcoVadis,"{MongoDB,Databricks,Mongo,color,Airflow,PostgreSQL,Prometheus,DVC,scale,Azure,SQL,Python,Postgres}",Télétravail total possible,Berlin,"Environnement / Développement durable, SaaS / Cloud Services, SocialTech / GreenTech",CDI,2023-03-26,"EcoVadis is the leading provider of business sustainability ratings. Their solutions are backed by an international team of experts and powerful technology. They analyze data and build sustainability scorecards that give companies actionable insights into their environmental, social and ethical risks. EcoVadis is driven by a diverse team of over 1000 talented professionals representing more than 60 nationalities. The team is based around the globe, including offices in Paris, Barcelona, London, Dusseldorf, Warsaw, Mauritius, New York, Tunis, Hong Kong, Toronto and Tokyo. They hire remotely as well. We are looking for a Data Engineer to contribute to the evolution of our IQ Plus product. IQ Plus leverages intelligence from the world’s largest sustainability performance database, customer procurement data and screening of supplier-specific documents using the latest data mining and AI technologies. In this new role, reporting to the Engineering Manager, you will work alongside a team of Data Scientists and Machine Learning Engineers. Your will: Build and maintain a distributed data pipeline architecture that can process large volumes of data from multiple sources with high availability and low latency. (MongoDB, Postgres, Prometheus related data extraction processes) Implement data quality checks to ensure data consistency, completeness, and accuracy. (Cleaning data from MongoDB, Postrgres, Google Storage etc) Design and maintain data models and schema structures to support analytics and reporting needs. (Any changes to Mongo, Logging etc) Collaborate with data scientists to develop data pipelines for machine learning models and data science operations. Design and implement data processing workflows for log data to enable effective analysis and visualization. Build and maintain data visualization and monitoring tools to track system performance and detect anomalies. Additional Information Location: Berlin / Remote in Germany Start date: ASAP Everyone at EcoVadis contributes to a culture of trust, respect and empowerment. Our growing team in Germany is full of talented professionals from various sectors who all share a desire to make an impact. We offer competitive salaries and support personal growth from day one with extensive onboarding, mentoring and a brand new e-learning platform bursting with courses and modules so you can learn new skills and fine-tune old ones. Benefits: • Support with all the necessary office and IT equipment • Wellness allowance for mental and physical wellbeing • Annual performance bonus • Remote work from abroad policy • Flexible working hours • Hybrid/ full remote work • Health coverage and optional pension scheme • Internet and electricity bill allowance • CSR activities • Subsidized travel and BahnCard 50 • Community service day when volunteering. Our hiring team looks forward to reviewing your CV, in English, with a guaranteed response to every application. A new job with purpose awaits you! Don’t fit all the criteria but still think you’d be a good candidate? Please apply anyway to give our hiring team the opportunity to assess your skills and to learn more about what you could bring to EcoVadis. We’re interested in hiring capable people, regardless of professional and educational background. Can the hiring process be adjusted to suit my needs? Yes. We want everyone going through the hiring process with EcoVadis to feel confident that you are able to demonstrate your full potential. We welcome applications from disabled people, people with long-term health conditions, and neurodiverse candidates. If you need any adjustments, including the provision of interview questions, please let the hiring team know. Our team’s strength comes from everyone’s uniqueness and is founded upon mutual respect. EcoVadis commits to equity, inclusion and reducing bias in our hiring processes. EcoVadis does not accept any form of discrimination based on color, national or ethnic origin, ancestry, citizenship, religion, beliefs, age, sex, gender identity, sexual orientation, neurodiversity, disability, parental status, or any other protected characteristic that makes you unique. In your application, we encourage you to remove personal information such as: photographs, marital status, number of children, religion, gender, residential postal code, university graduation date, past medical or parental leave(s) taken, nationality (instead, please state if you are legally eligible to work in the job region/country), university name (instead, please state any degrees obtained and the study major). Experience in data modeling, pipelines, data warehousing, and transformation of large-scale data sources Experience building ETL processes, data pipelines and orchestrators (e.g. Airflow, DVC) Extensive experience in No-SQL databases (MongoDB) and SQL (PostgreSQL) Systems-level understanding of Machine Learning concepts and technologies Optimize data storage and retrieval processes using cloud-based solutions such as Azure and Databricks Develop and implement data analytics workflows using Python, SQL, or other programming languages","EcoVadis is hiring a Data Engineer to work with their team of Data Scientists and Machine Learning Engineers, contributing to the evolution of their IQ Plus product. The successful candidate will build and maintain a distributed data pipeline architecture, implement data quality checks and design and maintain data models and schema structures. They should have experience in data modeling, ETL processes, data pipelines, and data warehousing, as well as extensive experience with No-SQL databases and SQL.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,3,1,0.05539549888311683
238,64302,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris_TDF_pP7ANV8,Data Engineer,TotalEnergies Digital Factory,"{AWS,via,Spark,Azure,SQL,Python}",Télétravail total possible,"31 rue des Jeuneurs, Paris, 75002","Logiciels, Big Data, Energie",CDI,2023-04-03,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. TotalEnergies a décidé d'accélérer la production interne de solutions digitales pour ses activités en créant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilité et l'esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Nous créons et déployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. Nous considérons les personnes comme la ressource la plus précieuse pour réussir, c'est pourquoi nous tenons non seulement à recruter les meilleurs talents, mais aussi à créer des liens uniques entre nos employés. Rejoins-nous en plein cœur de Paris en tant que Data Engineer et intègre la tribu Bemo Tech qui développe la plateforme de mobilité Bemo. Cette plateforme connecte des réseaux de mobilité (bornes de recharge pour véhicules électriques et stations-service) et les solutions à destination des conducteurs via leur app ou leur véhicule connecté pour une mobilité plus connectée, plus partagée, plus responsable. Au sein de la tribu Bemo Tech, tu rejoindras en particulier la Squad « Data Places » en tant que Data engineer, l'une des 6 Squads de Bemo Tech. Ta Squad « Data Places » est en charge de la collecte, de la normalisation et de l'enrichissement des données utilisées par la plateforme de mobilité pour offrir la meilleure expérience client. Un autre aspect de ton rôle est de travailler avec l'entité business de Bemo pour préparer les datasets nécessaires au reporting et à l'activité d'intelligence économique. En tant que Data Engineer, tu garantis la qualité des pipelines data du produit, tu assures le développement des programmes pour collecter, préparer, transformer et diffuser les données. Dans l'écosystème ultra dynamique des nouvelles mobilités (notamment électriques), en phase avec de grands enjeux sociétaux, nous attendons de toi que tu : Conçoives, construises et intègres des données au sein de la Squad et en collaboration avec les autres Squads. Assures le stockage, la consommation, l'intégration et la gestion des données des cas d'utilisation. Fasses l'analyse de l'analyse de l'accessibilité des données et que tu recommandes des solutions pour leur intégration. Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de données. Tu intègres également les données dans le data lake. Collabores avec les data scientists pour la réalisation des modèles de prédiction. Produises un code de qualité, mettes en place des tests automatisés et systématiques pour le contrôler. Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacité des solutions et apporter des préconisations techniques. En parallèle, tu auras également des missions transverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies Coaches et accompagnes la communauté des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une expérience d'au moins 4 ans en data engineering, tu es diplômé d'un master ou d'une école d'ingénieur spécialisée en informatique ou mathématiques. Et si tu as déjà une expérience dans l'écosystème de la mobilité, de la recharge électrique ou du digital fueling, c'est top ! Les compétences qui sont attendues de toi en tant que Data Engineer La maitrise de Python, Spark et SQL. Une bonne connaissance sur les bases de données relationnelles et non relationnelles. La capacité à concevoir et à mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle Maîtrise des bonnes pratiques de monitoring des flux de données. Une bonne compréhension du machine learning. Une bonne connaissance des méthodes Agile (Scrum, Kanban, voir même SAFe ou Nexus). Une culture tech tu sais concevoir et modéliser une solution informatique. Si tu as toi-même de bonnes notions de développement, c'est un plus notable (stack technique : Cloud Azure ou AWS, C#, .Net) Une expérience avec les outils de gestion de Backlog comme Jira ou Azure DevOps. Si tu en connais plusieurs, c'est encore mieux. Une première expérience sur un provider de Cloud, AWS de préférence.","The TotalEnergies Digital Factory is seeking a Data Engineer to join the Bemo Tech tribe, responsible for creating and deploying digital solutions across TotalEnergies sites to provide clean, reliable, and affordable energy. The Data Engineer will work within the ""Data Places"" squad, responsible for collecting, normalizing, and enriching data for the mobility platform. The ideal candidate will have at least four years of data engineering experience, expertise in Python, Spark, and SQL, and a good understanding of big data processing and machine learning. A background in the mobility or digital fuelling ecosystem is a plus.",Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,3,1,0.05539549888311683
242,57152,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-talend-big-data-h-f_levallois-perret,Data Engineer / Talend Big Data,Micropole,"{Microsoft,durable,Talend,Scala,AWS,R,Spark,GCP,SQL}",Télétravail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer Talend Big Data Localité : Levallois-Perret Type de contrat : CDI Niveau d’expérience : au moins 3 ans Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services. Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus ! Au sein de notre agence basée à Levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vousaccompagnerez les directions métiers dans l'évaluation de l'efficacité de leurprocessus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions Cloud & Data ; Participer au développement de notre centre d’excellence. Vos compétences techniques : Vous avez un minimum de 3 années d’expérience sur des projets Data avec Talend Spark ou SSIS. Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ; Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visio Etape 3 – Vous rencontrez un manager technique avec l’un de nos experts. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) LA VIE CHEZ MICROPOLE, C’est : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; Participation à des projets internes sur la base du volontariat. #LI-DM1 Compétences SQL Scala Spark Talend SSIS","Micropole, a digital transformation accelerator, is seeking a data engineer with at least three years of experience in Talend Big Data. The ideal candidate must be passionate about data and optimization, possess comprehensive knowledge of data modelling and analysis, and constantly updated with new tech solutions. The successful candidate will join Micropole's expert cloud team in Levallois-Perret, helping businesses with data-driven digital transformation, modelling and analysing data, and providing consultation and support in security and compliance.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
240,56815,https://www.welcometothejungle.com/fr/companies/klanik/jobs/data-ingenieur-spark-scala_paris,Data ingénieur SPARK & SCALA,KLANIK,"{via,ORACLE,SPARK,SCALA}",Télétravail partiel possible,"37 Rue Etienne Marcel, Paris, 75002","Logiciels, IT / Digital, Formation",CDI,2023-03-26,"KLANIK est une société de conseil en Ingénierie IT qui accompagne ses clients dans leurs projets digitaux et technologiques. Le groupe KLANIK compte désormais plus de 750 talents, évoluant dans 16 agences en Europe, Amérique du Nord, Afrique et Moyen-Orient. Des experts engagés, atypiques et passionnés, impliqués dans des projets stratégiques grâce à leur haut niveau de compétences en Software, DevOps, Cloud, Agilité, Cybersécurité, Big Data & IA. En parallèle de leurs métiers, les collaborateurs du groupe KLANIK sont accompagnés au quotidien dans leur développement personnel et professionnel, via différentes initiatives engageantes et innovantes : KONSCIOUS : communauté interne engagée dans les enjeux écologiques, sociaux et environnementaux KAMPUS : institut de formation technique certifié KORNER : incubateur de start-ups technologiques KLANIK ESPORT : club professionnel e-sport ouvert aux collaborateurs Au sein de l’équipe projet Business Intelligence & Big Data, l’expert SPARK/SCALA aura les activités suivantes : - Conception détaillée, fonctionnelle et technique. - Développements SPARK / SCALA - Contribution à la formalisation des plans de tests, exécution des tests unitaires et d’un premier niveau de tests d’intégration. - Résolution des anomalies pendant les phases d’intégration fonctionnelle et de recette utilisateur. - Packaging et déploiement en pre-production et production. - Optimisation des traitements afin de garantir la qualité de service standards du DWG. - Mise en œuvre des solutions industrielles et de réentrance permettant une reprise optimum des traitements en cas d’incident en production. - Mise en service et accompagnement au déploiement. - Suivi des environnements. Le consultant devra travailler en étroite collaboration avec le Chef de Projet, responsable du lot et l’équipe de développement du Programme. Vous êtes la bonne personne si pour vous la qualité, la maintenabilité et la performance sont des sujets primordiaux. Mais également une expérience de minimum 5 ans sur les technologies suivantes : SPARK SCALA Avec une bonne connaissance de l’application ORACLE Le processus démarre par un premier entretien avec un.e HR puis un entretien technique avec l’un de nos experts, ensuite vient la rencontre avec le ou la Business Manager en charge de l’offre.","KLANIK is looking for an experienced expert in SPARK/SCALA with a minimum of 5 years' experience in these technologies and a good knowledge of the Oracle application. The role involves detailed design, development, testing, packaging, deployment, and optimization of processes to ensure quality of service standards. The consultant will work closely with the project manager and development team. KLANIK offers innovative initiatives for personal and professional development such as KONSCIOUS, KAMPUS, KORNER, and KLANIK ESPORT.",Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
241,56491,https://www.welcometothejungle.com/fr/companies/esens-consulting/jobs/ingenieur-big-data-senior_paris,Data Engineer (confirmé) - Hadoop | Spark | MongoDB,ESENS,"{MongoDB,DynamoDB,Scala,portable,Kafka,R,Cassandra,Spark,Elasticsearch,Hadoop,Python}",Télétravail partiel possible,"40 Rue du Colisée, Paris, 75008",IT / Digital,CDI,2023-03-26,"ESENS accompagne l’innovation technologique de ses clients et l’évolution professionnelle de ses équipes à Paris, Lille, Bordeaux, Nantes, Lyon, Rennes et Caen. Web, Mobile, DevOps, Design, Data, BI, QA et MOA, ESENS répond aux besoins Web, Mobile, IoT, Design, DevOps et Big Data des entreprises dans tous les secteurs d’activité. En tant que prestataire de services en technologie numérique, Lab de R&D, agence digitale, partenaire associatif impliqué dans de nombreuses causes (environnement, santé, lutte contre la fracture numérique, soutien scolaire, insertion professionnelle des jeunes issus des quartiers, soutien à la transformation numérique des petits commerces…) ou encore sponsor de jeunes talents sportifs, nous avons à cœur de nous investir dans des projets qui ont du sens pour tous. C’est notre façon d’innover, d’élargir nos univers, d’enrichir les connaissances et les possibilités de chacun, de construire un futur dans lequel tous se retrouvent et de faciliter l’épanouissement professionnel et personnel de celles et ceux qui se reconnaissent et s’inscrivent avec nous dans cet état d’esprit d’équipe, de découverte, d’entraide, de partage et d’échange. En tant que Data Engineer chevronné.e, rejoins nos équipes sur des projets pour l’ensemble des clients d’ESENS, qu’ils soient start-up ou leader de leur marché. Présents dans tous les secteurs d’activité, nous te proposons de développer des projets à long terme (2 à 3 ans) sur des stacks modernes et pensés ‘sur-mesure’ en fonction de tes appétences techniques et personnelles. Nos objectifs ? Te proposer des nouveaux challenges qui répondent à tes attentes et assurer ta montée en compétence entouré.e de véritables passionnés de dev. Chez ESENS, nous sommes investis en continu dans le suivi et l’accompagnement personnalisé de chacun des membres de notre équipe et nous sommes convaincus que prendre du plaisir au travail est l’une des clefs principales de la satisfaction de nos salariés et de nos clients ! Tech Specs : Salaire fixe + variable Prime(s) Ordinateur portable Accès au programme de formation interne et externe Organisation de travail flexible : présentiel, télétravail, travail hybride, on en discute ? Excellente couverture santé en partenariat avec Generali Une vie d’entreprise et associative riche en événements ! Issu(e) d’une école d’ingénieur ou d’une formation Bac +5 équivalente, et avec au minimum 5 années d’expérience dans la mise en place d’architecture cloud et de projets data, tu es déjà lead sur le plan technique. De nature curieuse, dynamique, en constante veille technologique, tu souhaites te challenger en continu dans un contexte d’innovation et aux côtés d’une équipe aussi passionnée que toi pour faire évoluer tes compétences et continuer de tracer ton parcours professionnel. Ton esprit de synthèse et tes capacités à structurer ton raisonnement seront des qualités également très appréciées ! Aujourd’hui, tu es a la recherche d’un nouveau projet qui allie management, technique, esprit d’équipe et montée en compétences tout en respectant l’équilibre pro / perso. Ta stack de prédilection : Hadoop, Spark, Kafka MongoDB, Cassandra, DynamoDB Python, R, Scala, Elasticsearch Machine Learning, Deep Learning Intégration dans le Cloud Sans oublier un bon niveau d’anglais ! Tu as poursuivi ta lecture jusqu’ici ? Nous sommes par conséquent à quelques jours de notre rencontre dans nos locaux WeWork parisiens situés 40 rue du Colisée, à deux pas des Champs Elysées : Rooftop en plein centre de Paris avec vue sur la tour Eiffel Open Bar à Bière Accès aux espaces WeWork du monde entier Lors de notre première rencontre, nous nous ferons un plaisir de te présenter ESENS, de te parler de nos équipes et de notre projet d’entreprise. Ce sera aussi, bien sûr, l’occasion de discuter de ton parcours et d’évaluer tes attentes, tes motivations et tes souhaits d’évolution. Un second entretien nous permettra de valider tes compétences techniques, fonctionnelles et managériales. Ce sera également l’occasion de te faire rencontrer un ou plusieurs membres de notre équipe pour échanger sur différents contextes de missions et sur le poste proposé. Pour clôturer notre process de recrutement, tu rencontreras les membres de la direction pour une validation finale qui nous permettra de concrétiser notre proposition de collaboration. Bienvenue chez ESENS !","ESENS is seeking an experienced Data Engineer to work on long-term projects for their clients, both startup and leaders in their respective market. The company offers a flexible working environment, personalized support, and continuous training to ensure career growth. The ideal candidate should have a minimum of 5 years of experience in cloud architecture and data projects, as well as expertise in Hadoop, Spark, Kafka, MongoDB, Cassandra, DynamoDB, Python, R, Scala, Elasticsearch, Machine Learning, Deep Learning, and Cloud Integration. The position offers a fixed salary with bonuses, a laptop, access to internal and external training programs, and an excellent health plan. The company also values work-life balance and offers a rich company and associative life with various events.",Bac +5 / Master,Entre 15 et 50 salariés,> 5 ans,2,1,0.04154662416233763
272,60442,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer_rouen,Data Engineer,Groupe SII,"{Informatica,Talend}",Télétravail partiel possible,Rouen,IT / Digital,CDI,2023-03-28,"Le Groupe SII est une société de conseil en technologies implantée dans 18 pays au travers de 100 implantations. Plus de 13 000 collaborateurs interviennent quotidiennement sur les problématiques de transformation numérique des grands-comptes. Une entreprise où il fait bon travailler. Labellisée Great Place To Work pour la 5ème année consécutive, SII mène de nombreuses actions liées à la qualité de vie au travail. Nous recherchons un(e) Data Engineer (H/F) pour accompagner les développements faits auprès des applications de l’un de nos clients Grand Compte.
En mode Agile et organisée en "" Feature Team "", l'équipe technophile vous permettra de participer à toute la chaine projet. En quête de défis techniques ? Alors n’hésitez plus, postulez ! Votre mission : Préparer les données à traiter, Analyser les modèles, Concevoir des algorithmes, Programmer en back-end, Interpréter et présenter les résultats, Mettre en production des solutions. Votre profil : Diplômé(e) d’un Bac+5 en informatique, mathématique ou statistique (Grandes Ecoles, Universités), vous justifiez d'au moins une première expérience significative dans le traitement de donnée avec utilisation ou connaissance d’un ETL (Talend ou Informatica).Vous êtes curieux(se), investi(e) et surtout passionné(e) par le monde du web. Vous savez travailler en équipe et vous vous intégrer rapidement, vous êtes autonome, organisé(e) et rigoureux (se), bon communiquant et doué(e) du sens de l'écoute. Qui sommes-nous ? Le Groupe SII est au coeur de l’innovation au service de grands comptes dans des secteurs d’ingénierie variés. En 2022, nous avons été labellisés Great Place To Work pour la 5e année consécutive et reconnus 3e entreprise de « + de 2500 salariés » où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières. Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur. Notre nouvel accord télétravail permet de l’appliquer jusqu’à 50% de notre temps de travail en fonction de la mission. Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous ! Compétences requises : Informatica, Talend. Qualités désirées : Esprit de synthèse, Adaptabilité, Capacités d'analyse, Autonomie, Bon relationnel, Organisation, Qualités rédactionnelles, Réactivité. Avantages : Très bon CSE, Mutuelle et prévoyance, Tickets restaurant, Places en crèche, Participation aux bénéfices de l'entreprise, Participation aux frais de transport, Primes de cooptation, Télétravail.","SII is seeking a skilled Data Engineer to work on development projects for one of its major customers. The position requires the candidate to have a degree in computer science, mathematics, or statistics (Grandes Écoles, Universities) and at least one significant experience in data processing, including knowledge of an ETL such as Talend or Informatica. The ideal candidate will be curious, passionate, organised, rigorous, and an effective team player with excellent communication skills. SII is a handi-welcoming company that offers a great workplace and numerous employee benefits, including participation in profit-sharing, teleworking opportunities and participation in transport expenses.",Bac +5 / Master,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
308,57087,https://www.welcometothejungle.com/fr/companies/maltem/jobs/data-engineer-h-f_bordeaux,Data Engineer,Maltem,"{Airflow,S3,Kafka,Spark,Java,Hadoop}",Télétravail partiel possible,"41, Rue Bergeret, Bordeaux, 33000","Organisation / Management, Big Data, Cybersécurité",CDI,2023-03-26,"Fondé en 2001 par Jean-Luc Clamen et Pascal Mennesson, Maltem est un groupe expert en conseil transformation digitale et de l’innovation qui rassemble aujourd’hui plus de 1 100 collaborateurs, répartis dans 12 pays. L’activité du groupe couvre un large champ de compétences, organisées en communautés : Consulting, Data, Agility, Dev, Design Experience et Cyber Security avec une expertise spécifique dans les domaines de la banque, de l’assurance, de l’énergie et des médias. 👀 Qui sommes-nous ? Depuis son lancement en 1999, OMNILOG met au cœur de ses priorités l’accompagnement, la proximité et la stabilité de ses collaborateurs afin de permettre à ses équipes de travailler dans des conditions idéales et de fournir un travail de qualité. Accrédités par le label “Choosemycompany : HappyAtWork®”, nous permettons à nos collaborateurs d’évoluer dans un cadre professionnel idéal : événements, formations, missions longues, équilibre vie pro/vie perso, télétravail et bien d’autres. Nos clients sont des acteurs majeurs des médias, du sport et du e-commerce, avec qui nous collaborons pour certains depuis plus de 10 ans (TF1, Canal+, l’Equipe, la FFF, Bedrock, Place des Tendances, JCDecaux… 🧠 Que recherchons nous ? Nous recherchons notre futur Data Engineer F/H afin de renforcer nos équipes. Le poste est situé à Bordeaux, pour notre client, acteur historique en télécommunications, sur un rythme de travail de 3 jours de présentiel et de 2 jours de télétravail. 💪 Tes missions seront les suivantes : Mise en place de flux de données en temps réelle, mais aussi en batch. Avec l’équipe, tu seras l’ambassadeur de la qualité des données, de la maintenabilité et de la performance des flux. Études du besoin des clients et proposition d’une solution technique en lien avec les attentes de celui-ci Test et déploiement de la solution mise en œuvre et sa maintenance Maintenir ses compétences à jour et les faire grandir, tu auras en effet du temps dédié pour ta montée en compétences dans une logique d’amélioration continue 🎯 Les indispensables : Au moins 3 ans d’expérience en développement Java La maitrise du framework Spark Connaissances sur les modules Big Data (Kafka, Airflow, Hadoop, S3) ❤️‍ Les plus : Un esprit d’équipe L’envie de découvrir de nouvelles technos L’envie d’animer ou de participer à des évènements au tour de la tech Une appétence pour le devOps et la Data Tu te reconnais et tu cherches un nouveau challenge ? N’hésite pas à postuler et à nous contacter ! Notre process est le suivant : Entretien RH en visio Entretien technique Entretien projet Bienvenue dans les équipes","Maltem is seeking a Data Engineer with at least 3 years of experience in Java development, who has expertise in Spark framework, and knowledge of Big Data modules such as Kafka, Airflow, Hadoop, and S3. The successful candidate will be responsible for implementing real-time and batch data flows, ensuring data quality, proposing technical solutions for clients, testing and deploying solutions, and maintaining their skills through continuous improvement. A team player with a passion for learning new technologies and a desire to participate in tech events is preferred. The position will be located in Bordeaux, with a schedule of 3 days on-site and 2 days of telework.",N,N,N,2,1,0.04154662416233763
309,56594,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer-copy_barcelona,Data Engineer,Contentsquare,"{regard,Go,color,Scala,Akka,Contentsquare,Kafka,scale,Elasticsearch,Spark,R,ClickHouse,Java}",Télétravail partiel possible,"Barcelona, 08007","SaaS / Cloud Services, E-commerce",CDI,2023-03-26,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team – known as the CSquad – representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of hard-working and dedicated developers, crafting and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at Contentsquare ! We collect several billion events per day and query hundreds of terabytes in real time. Your daily work will consist of: Crafting efficient architectures to store and analyze petabytes of data Leading large-scale projects and mentoring developers Implementing sophisticated acquisition workflows Thinking of inventive data formats to serve the functionalities of the product, while minimizing the cost Developing tools to help data-scientists ....by using some open-source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum of 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have curiosity about functional programming and seek to develop your skills in Data engineering programming languages. Ideally, you have experience with a wide range of databases and are interested in streaming. You would like to challenge yourself, developing distributed infrastructure with a real-time and data-intensive environment. You would like to share your skills and take part in technical choices. Why you should join our R&D department? Here is our R&D Manifesto We write our own story. We think for ourselves, keeping an open mind and engaging in constructive criticism. We are transparent in what we do and why we do it. We build and leverage tech expertise to answer business challenges. Learning from all experiences, we deliver continuous improvements in production. We empower all team members to have an end-to-end impact, take initiative, and bring new ideas to life. We stand together and thrive together; team spirit and solidarity matter even more than strong expertise. We live a human adventure. Why you should join Contentsquare: ▪️ We’re humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ▪️ We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ▪️ We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ▪️ Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ▪️ Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ▪️ Work flexibility: hybrid and remote work policies. ▪️ Generous paid time-off policy (every location is different). ▪️ Immediate eligibility for birthing and non-birthing parental leave. ▪️ Wellbeing allowance. ▪️ Home Office Allowance. ▪️ A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ▪️ Every full-time employee receives stock options, allowing them to share in the company’s success. ▪️ We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don’t meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is seeking a Data Engineer to join their team and develop a new data architecture using open-source technologies like Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. Candidates should have proficiency in either Scala, Java or Go, and experience with a wide range of databases and streaming. Contentsquare offers competitive benefits including remote and hybrid work policies, paid time-off, parental leave, wellbeing allowance, and stock options. The company values uniqueness and creates a culture of solidarity and team spirit.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
237,63032,https://www.welcometothejungle.com/fr/companies/everysens/jobs/data-engineering-manager-h-f_lille,Data Engineering Manager,Everysens,"{DBT,FiveTran,BigQuery,Java,Python}",Télétravail partiel possible,"165 Avenue de Bretagne, Lille, 59000","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Objets connectés",CDI,2023-03-31,"Everysens est un éditeur de logiciel SaaS spécialisé dans l’optimisation des flux ferroviaires et multimodaux. Grâce à notre solution, les plus grands industriels européens (Arkema, Total, Saint Gobain, ArcelorMittal, etc) réduisent leurs coûts de transport et l’empreinte carbone associée. La logistique est devenue ces dernières années un terrain de jeu pour la digitalisation : IoT, IA et Digital Twin y trouvent de nombreuses applications. Nous intégrons ces 3 technologies pour apporter visibilité et automatisation à une industrie qui gère encore fréquemment ses opérations sur papier ou Excel. En 5 ans, nous sommes devenus le leader européen du logiciel transport sur le mode ferroviaire, et avons doublé notre équipe chaque année. Nous avons gagné la confiance du marché au cours de ces années, ce qui nous permet de poursuivre notre expansion internationale. Si tu veux nous aider à forger une supply chain décarbonée, résiliente et collaborative : rejoins-nous ! L’équipe Data Engineering Cette équipe d’une dizaine d’ingénieur (Java Backend Software Engineers, Data Engineers, Data Scientist, EDI Integration Engineer) a pour mission de développer et maintenir nos solutions autour de la DATA, regroupant la gestion des “Digitals Twins”, de la Data Visualization, de l’IA, et des échanges EDI. La stack technique de l’équipe : Java - Spring Boot / DBT / FiveTran / BigQuery / Toucan Toco / Gravitee / Python. La mission Ta mission consistera, sous la responsabilité du VP of Engineering et en lien direct avec les équipes produit et direction technique, à : PEOPLE MANAGEMENT Fédérer ton équipe pour atteindre les objectifs; Assurer le suivi de carrière de tes collaborateurs; Assurer le coaching de tes collaborateurs; Recruter les bonnes personnes. DELIVERY MANAGEMENT Assurer l’alignement avec les équipes Produit, Projet, Direction Technique et les autres managers de l’Engineering; Valider les spécifications entrantes; Réaliser la planification des tâches de l’équipe et l’adapter dès que nécessaire; Assurer l’organisation et l’animation quotidienne des collaborateurs. Assurer la connaissance et le respect du processus de production au sein de l’équipe; Assurer le respect des engagements de livraisons; Identifier et mettre en oeuvre les axes d’amélioration de la performance de l’équipe; Assurer la mise en place des indicateurs et le reporting régulier associé. TECHNICAL MANAGEMENT Accorder une partie de ton temps aux aspects techniques avec l’objectif d’améliorer les pratiques et la performance de l’équipe; Lorsque nécessaire, arbitrer les décisions techniques; Garantir la qualité technique des livrables de l’équipe en s’assurant du respect des normes de l’entreprise. Participer activement aux guildes Backend-Java & Data. Notre ambition, faire de la technologie un atout pour notre croissance. Nos valeurs : Bienveillance, Curiosité, Excellence et Esprit d’équipe Tu as travaillé au moins 5 ans dans le développement logiciel et le domaine de la Data et tu as une première expérience en management. Tes compétences sont : La gestion et le management d’équipe IT dans un contexte multi-projets La mise en place et l’application de processus et de bonnes pratiques Une expertise technique Java et dans au moins un domaine de la Data Une facilité de la compréhension du métier Tu es un facilitateur capable d’écoute et d’assertivité, tu sais trouver rapidement des solutions et recherche constamment l’amélioration. Proactif et bon communicant, tu démontres un réel leadership et tu es reconnu comme un interlocuteur exigeant et fiable. Nous offrons Poste basé à Lille, tu bénéficieras de l’environnement stimulant d’Euratechnologies au cœur de la French Tech’ Lilloise ! Le télétravail peut faire partie de ton quotidien. Enfin, tu travailleras au sein d’une équipe où la bienveillance est une Valeur Essentielle. 1. Un entretien de pré-qualification de 15 minutes pour valider l’adéquation de ton profil au poste recherché 2. Un entretien avec notre VP of Engineering 3. Un call avec notre CEO","Everysens, a SaaS software publisher specializing in railway and multimodal flow optimization, is seeking a Data Engineering Manager. The successful candidate should have over five years of experience in software development and data management with previous management experience. The position requires technical knowledge of Java and at least one domain of data, as well as experience in IT team management. Responsibilities include organizing and leading a team, overseeing processes, and ensuring the quality of deliveries while focusing on improving performance. The company offers a position based in Lille with the possibility of telecommuting and a stimulating environment at the heart of French Tech.",Non spécifié,Entre 15 et 50 salariés,> 5 ans,2,1,0.04154662416233763
311,56302,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-snowflake-h-f_lyon,Data Engineer snowflake,CGI,"{Talend,Scala,GitLab,Tibco,jenkins,AWS,Snowflake,Informatica,Spark,SQL,Python}",Télétravail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous travaillerez en partenariat avec nos clients pour la livraison de leur parcours de transformation digitale sur des projets à la fine pointe de la technologie, au développement de plateformes analytiques « nouvelle génération » dans le cloud. A ce titre vous serez amené à : • Appréhender le contexte et les enjeux Métier du client ; • Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire ; • Participer aux conceptions d’architecture de base de données relationnelles et non-relationnelles, les entrepôts de données et les lacs de données « big data ». • Déployer en production des solutions analytique de données, entièrement opérationnelle sur une plateforme Snowflake. • Accompagner à l'optimisation de stockage, la réplication et transformation des données, et l’optimisation de performance. • Participer à la vie de la communauté Data. • De formation Bac +5, spécialisée en informatique, vous justifiez d'une première expérience d'au moins 2 ans au sein d'une équipe client ou un projet dans la mise en œuvre de solutions autour de la Data. • Maîtrise des méthodes d’intégration de données ETL et ELT • Maîtrise d’un ou plusieurs outils d’intégration de données serait un plus (Talend, Informatica cloud, Tibco, etc.) • Expérience pratique sur Snowflake, Snowpipe, SnowSQL. • Solide connaissance dans le cloud AWS. • Expérience en programmation avec Python, SQL, Scala ou Spark. • Expérience Devops (GitLab, jenkins, etc.) • Vous aimez évoluer dans des contextes internationaux, avec une très bonne maitrise du français et de l'anglais à l’écrit comme à l’oral. Atouts pour ce poste : • Certifications Snowpro, AWS. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, is looking for a Data Integration Consultant to work with clients on cutting-edge technology projects. The ideal candidate should have experience in data integration and modeling, cloud technologies (particularly AWS), programming languages (Python, SQL, Scala, or Spark), and DevOps practices. Certifications in Snowflake and AWS would be advantageous. Fluency in both French and English is mandatory, and CGI is an inclusive employer attentive to the well-being and career development of all employees, including those with disabilities and LGBT+ individuals.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
250,56996,https://www.welcometothejungle.com/fr/companies/dgse/jobs/data-engineer-h-f_paris,Data engineer,Direction Générale de la Sécurité Extérieure,"{Jenkins,Scala,bash,Storm,Kafka,Spark,Git,Java,Python}",Télétravail partiel possible,"Paris, 75001","Stratégie, Cybersécurité, Administration publique",CDD / Temporaire,2023-03-26,"La DGSE est le service secret français. Sa mission ? Recueillir des renseignements dans le monde afin de fournir aux autorités politiques la meilleure compréhension possible des situations qu’elles ont à traiter. Ses 7 000 agents œuvrent dans l’ombre pour connaitre et anticiper les menaces venant de l’étranger. Du contre-terrorisme à la cybersécurité, ils agissent pour protéger la France et les français. La Direction Générale de la Sécurité Extérieure, DGSE, recrute un Data engineer (H/F). Le poste est situé à Paris. La nationalité française est obligatoire. Domaine métier Sciences et Technologies Votre environnement de travail Intégré au sein d’une équipe d’une dizaine de personnes, organisée en projets avec une gestion agile, vous développez et déployez des algorithmes de traitement en streaming et en batch, construits autour des technologies Big Data open-source majeures (Kafka, Spark, Storm). Les volumétries traitées imposent d’exploiter pleinement les capacités offertes par ce type de technologie, notamment en cherchant à optimiser leur fonctionnement de base pour passer à l’échelle. L’équipe maîtrise intégralement le développement, le déploiement, l’optimisation et l’exploitation des clusters. Vos missions Vous serez en charge de plusieurs activités parmi les suivantes : • implémenter, optimiser et maintenir des algorithmes de traitement de données distribués (Scala, Spark, Java), • participer à l’évolution de l’architecture, en intégrant de nouveaux composants (frameworks, bibliothèques, …) permettant de mieux répondre aux besoins, • assurer une veille technologique constante pour rester au plus haut niveau et garantir une adéquation des clusters existants avec l’état de l’art du domaine, • interagir avec l’équipe SRE/Devops pour améliorer la fiabilité des architectures et l’automatisation des déploiements. Les plus de l’offre • Diversité des projets • Absence de routine • Contexte d’activités unique Titulaire d’un diplôme informatique, niveau master universitaire ou école d’ingénieur. Data engineer junior, senior ou lead d’équipe. Vous devez posséder les compétences et qualités suivantes : • bonnes connaissances fondamentales logicielles (Structures de données, algorithmique, architecture), • maîtrise d’au moins un langage parmi : Scala, Java, Python, • connaissances des bonnes pratiques de l’intégration continue (Jenkins/Travis) et des processus de développement (Git, code review, …), • connaissances supplémentaires appréciées : scripting bash, gestion de configuration (Puppet, Ansible, Chef), • passion pour les nouvelles technologies. Envoyez-nous votre candidature à l’adresse : recrutement.scientifique01@intradef.gouv.fr Plus d’information sur www.dgse.gouv.fr > Nous rejoindre. RESTER DISCRET SUR VOTRE CANDIDATURE A LA DGSE","The DGSE is recruiting a data engineer in Paris to develop and deploy streaming and batch processing algorithms using open-source Big Data technologies such as Kafka, Spark, and Storm. The successful candidate will implement, optimize, and maintain distributed data processing algorithms and remain up-to-date with the latest technological developments. The ideal candidate should have a university master's degree or engineering degree, competence in Scala, Java, or Python, proficiency in continuous integration (Jenkins/Travis), and a passion for new technologies. The role requires French nationality and offers the opportunity to work on diverse projects within a unique context of activities.",Bac +5 / Master,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
312,56723,https://www.welcometothejungle.com/fr/companies/hove/jobs/data-engineer-lyon-h-f_paris,Data Engineer - Lyon -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilité, SaaS / Cloud Services",CDI,2023-03-26,"Hove est un acteur incontournable de la data-mobilité, en plus d’être une filiale de Keolis. Depuis sa création il y a 24 ans, Hove est un acteur clé dans ce domaine et l’un des premiers experts. Il occupe une place considérable dans l’écosystème de la mobilité et fait partie d’une communauté de 20 000 développeurs, qui participent à leur stratégie d’innovation ouverte et collaborative. Acteur de la Greentech, Hove porte une vision évolutive des mobilités douces, pour un impact plus positif et plus responsable de notre environnement grâce à ses 2 produits et métiers : Avec Navitia , Hove travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire, tout en tenant compte du contexte et des préférences du voyageur. L’objectif ? permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’impact possible sur la planète. Avec Patterns , Hove analyse les motifs que dessinent les mobilités sur un territoire ciblé. L’objectif ? Suivre la fréquentation, à travers des matrices origine – destination, les parts modales… À partir du recueil et de l’analyse des traces GPS et WiFi, entre autres. En tant que Data engineer Hove, vous êtes intégré à une équipe pluridisciplinaire mêlant développeurs, Product Owner, Architectes dont l’objectif est de créer des services à fortes valeur ajouté dans le domaine du transport. Vous avez la charge de définir et mettre en œuvre le pipeline d’acquisition des données (datahub) global pour Hove, d’organiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Créer et faire évoluer le moteur d’ingestion des données (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilité des flux de données Travailler en collaboration avec les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégrations continues, scalabilité des modèles, craftsmanship, etc…) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Déployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des données Superviser et monitorer le déploiement et la robustesse des composants mis en production Participer activement à la qualité de l’ingénierie logicielle (Relecture de code, test, intégration continue, déploiement, etc.) Participer aux évènements internes à la communauté data interne et externes (AWS Summit, workshops, meetups…) Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.* Vous justifiez d’une expérience d’au moins 2 ans en tant que Data engineer Vous opérez dans le conseil et pouvez justifier de vos missions Vous maitrisez l’anglais professionnel Vous maitrisez au moins : Un framework de calcul distribué tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala…). Différents systèmes de base de données (SQL et NoSQL) et le langage SQL. Un framework de streaming de données tel que Kafka, Kinesis, … Une expérience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks… Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez être capable de livrer du code de qualité dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l’équipe tech Un entretien avec notre CTO","Hove, a subsidiary of Keolis and a key player in data-mobility, is seeking a Data Engineer to define and implement a global datahub pipeline, organize data storage and support data scientists and analysts. The role involves creating and evolving data ingestion engines, working with product managers and business owners to understand client needs, deploying cloud infrastructures, participating in internal and external data events, and delivering quality code on time and within budget. Applicants should have over two years of experience, be fluent in English and have knowledge of distributed calculation frameworks, programming languages, streaming data frameworks, and SQL and NoSQL databases.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
1,56620,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_5lgyYxK,Data Engineer,TotalEnergies Digital Factory,"{Databricks,AWS,Spark,Azure,SQL,Python}",Télétravail total possible,"Rue des jeuneurs, Paris 02, 75002","Logiciels, Big Data, Energie",CDI,2023-03-26,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. La Digital Factory de TotalEnergies est composée de 300 personnes, 30 Squads, 39% de femmes et 25 nationalités. Elle offre un environnement de travail international et interculturel en plein cœur de Paris, engagé dans la diversité et l'inclusion. Elle permet d' accélérer la production interne de solutions digitales pour les activités de la Compagnie dans les 130 pays où elle est présente. Elle allie l' agilité et l' esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Elle crée et déploie des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. Rejoins-nous en plein coeur de Paris en tant que Data Engineer et intègre une de nos 30 squads qui réunit 8 à 10 personnes (data scientist, data engineer, software engineers…). Chacune des squads est dédiée à un projet métier et intervient dans la production des Minimum Viable Products (MVPs). Tu évolueras dans un contexte agile (scrum/scrumban), en mode itératif et co-constructif, en t'appuyant sur l'intelligence collective. En tant que Data Engineer, tu garantis la qualité des pipelines data du produit, tu assures le développement des programmes pour collecter, préparer, transformer et diffuser les données. En tant Data Engineer, nous attendons techniquement de toi que tu : Conçoives, construises et intègres des données au sein de la Squad et en collaboration avec les autres Squads. Assures le stockage, la consommation, l'intégration et la gestion des données des cas d'utilisation. Fasses l'analyse de l'analyse de l'accessibilité des données et que tu recommandes des solutions pour leur intégration. Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de données. Tu intègres également les données dans le data lake. Collabores avec les data scientists pour la réalisation des modèles de prédiction. Produises un code de qualité, mettes en place des tests automatisés et systèmatiques pour le contrôler. Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacité des solutions et apporter des préconisations techniques. En parallèle, tu auras également des missions tranverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies. Coaches et accompagnes la communauté des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une expérience d'au moins 4 ans en data engineering, tu es diplômé d'un master ou d'une école d'ingénieur spécialisée en informatique ou mathématiques. Les compétences qui sont attendues de toi en tant que Data Engineer : La maitrise de Python, Spark et SQL. Une bonne connaissance sur les bases de données relationnelles et non relationnelles. La capacité à concevoir et à mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle. Maîtrise des bonnes pratiques de monitoring des flux de données. Une bonne compréhension du machine learning. Une première expérience sur un provider de Cloud, AWS de préférence. Ce que nous t'offrons : Le développement de tes compétences avec le support de la Digital Academy et une enveloppe équivalente à 10 jours de formations par an que tu peux choisir en toute autonomie. La possibilité de te certifier AWS et Azure, Databricks... Un programme de mentorat. Un équilibre vie professionnelle et vie personnelle avec le recours possible aux horaires flexibles et au télétravail.","TotalEnergies is looking for a Data Engineer with at least 4 years of experience in data engineering and a degree in computer science or mathematics. The ideal candidate should have expertise in Python, Spark, SQL, relational and non-relational databases, data loading, manipulation, processing, analysis, and exploration at a large scale. The candidate must also have a strong understanding of machine learning and experience with AWS. The role involves working in an agile environment with a team of 8-10 people, developing Minimum Viable Products (MVPs), ensuring the quality of data pipelines, coordinating the implementation, industrialization, and maintenance of data architecture, and collaborating with data scientists. The company offers flexible working hours, telecommuting, and an allowance for ten days of training annually.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,3,0,0.04154662416233763
233,57116,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_lyon_CGI_W1K5QmG,Data Engineer,CGI,"{Azure,GITLAB,Jenkins,Talend,Shell,Kubernetes,AWS,Snowflake,Docker,Kafka,Linux,GCP,Java,Python}",Télétravail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Au sein de l’équipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux équipes d’expert et de déploiement des solutions. Vous participerez au développement stratégique d’un projet d’un client et vous évoluerez dans un contexte international, et bénéficierez de l’expertise de consultants CGI, en immersion chez le client. A ce titre vos principales responsabilités seront : • Appréhender le contexte et les enjeux Métier du client ; • Comprendre et expérimenter le cadre Agile et Lean ; • Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire avec l’accompagnement de Consultant senior ; • Participer au développement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; • Établir et dérouler des scénarios de tests ; • Participer à la vie de la communauté Data. Environnement technique : • Cloud provider : AWS, GCP , Azure • Data Acquisition : Kafka, Kafka Connect , Talend, Snowflake • Script : Java, Angular, Python, Shell, • Environnement : Linux, Docker, Kubernetes • Outils : Jenkins, GITLAB CI • Ticketing : JIRA • Reporting: Power BI, Qliksense De formation bac+5 ou de formation supérieure en informatique, vous disposez de 2 ans expériences réussie dans le déploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP. Des connaissances métiers dans le domaine du manufacturing ou ses métiers de la santé , alliés à des compétences techniques fortes sont également des atouts pour la réussite de ce projet. Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer. Vous aimez évoluer dans des contextes internationaux, avec une très bonne maitrise du français et de l'anglais à l’écrit comme à l’oral ; CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, is seeking a candidate with experience in deploying Kafka, Datalake AWS, and Datalake CGP platforms. The ideal candidate should have strong technical skills and knowledge in manufacturing or healthcare industries. They should be adaptable, independent, customer-oriented, and have excellent communication skills. Fluency in French and English is required, and working in an international environment will be required. CGI encourages applications from people with disabilities and supports career advancement for women and LGBT+ employees.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
231,56451,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer_villeurbanne,Data Engineer,Micropole,"{Microsoft,durable,GCP,Talend,Scala,AWS,R,Spark,Azure,Python,Tableau}",Télétravail partiel possible,"131 Bd de Stalingrad, Villeurbanne, 69100",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. Enrésumé : Poste: Data Engineer F/H Secteur de l'entreprise :experts conseil dans les secteurs de la banque-assurance, le luxe-retail etl’Industrie Localité : Lyon Type de contrat : CDI Niveau d’expérience :au moins 3 ans Vous êtes passionné(e)s par la data ? Vous êtesconvaincus que l’optimisation du patrimoine data des entreprises est laclé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveauxterritoires ? Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitale ? Si vous avez répondu « Oui » à chacune de cesquestions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/services. Alors,prêt à rejoindre l’aventure Micropole ? N’attendez plus ! EN TANT QUE DATA ENGINEER : Vous rejoignez notre entité Data Analytics basée à Lyon, oùvous interviendrez sur l’intégralité de plusieurs projets avec une vision« Data 360° », mêlant Conseil, Architecture, Intégration et DataScience. En tant que Data Engineer, vous accompagnerezles directions métiers dans l'évaluation de l'efficacité de leur processus etdans leur stratégie pour optimiser leur performance. Vous serez rattaché(e) à l’équipe Data Analytics,composée de 50 #InnovativePeople. Dans vos missions quotidiennes , vous serezamenés : A comprendrele besoin de nos clients au travers de missions de type : aide aux choixd’outils, cadrage des besoins, Proof Of Concept ; Accompagnerles équipes commerciales sur des rendez-vous client et en phase d’avant-vente ; Recueilliret analyser les besoins et proposer une architecture technique adaptée aux casd’usage des clients ; A réalisernos projets de construction de Data Platform au travers des activités : refonte,migration ou développement de tableaux de bord dans le respect des exigences dequalité et sécurité ; Rédiger ladocumentation des livrables pour rendre les utilisateurs autonomes et lesformer ; Rédiger ladocumentation permettant à l'IT d'assurer la maintenance ; Accompagnerles consultants moins expérimentés dans leur montée en compétence ; Capitaliseret partager les bonnes pratiques, connaissances et retours d’expérience ; Vos compétences techniques : Vous avez un minimum de 3années d’expérience sur des projets Data sur les outils ETL (Talend, SQLServer) et Reporting (Power BI, Tableau Software). Idéalement au moins unepremière expérience sur des projets Cloud AWS ou Azure Vous maîtrisez au minimumun langage de programmation (Python, Spark, Scala, R) ; Vous avez une maitrise desthéories et outils de modélisation de données, Vous maitrisez des conceptsd’industrialisation, Ia C, CI/CD et/ou gestion de version, Vos atouts : Véritablecoéquipier, vous avez à cœur de contribuer à la montée en compétence de votreéquipe, Vousrecherchez la variété et l’excellence dans votre travail. Autonome et impliqué(e),vous avez le goût du challenge, Doté(e) d’unexcellent relationnel et du sens du service, vous avez la capacité de gérer unerelation client, Vousdévelopperez votre créativité et votre curiosité grâce à une veilletechnologique accrue qui vous permettra de challenger les besoins de vosclients. Voussouhaitez vous impliquer dans le développement d’équipes et de communautés techniquesautour du Cloud et des solutions Data Enfin, vousdisposez d’un bon niveau de français et d’anglais, à l’oral comme à l’écrit. Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg,la Suisse, l’Espagne et la Chine. Construire ensemble lessolutions stratégiques et innovantes de demain pour accompagner nos clientsdans leur transformation data et digitale. Participer au développementde nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement autravers de formations et de certifications sur les plus grandes technologiesgrâce à Micropole Campus. S’assurer d’une innovationcontinue grâce : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et deco-construction avec les clients ; anagement par les talents naturels (regarder le mot de laDRH) Processus de recrutement : Chez Micropole, le processus de recrutement estréactif et transparent. Etape 1 – Si votre profilcorrespond à nos besoins, vous êtes recontactés dans les 72 heures qui suiventvotre candidature par Justine ou Nathan nos Talent Specialist dédiés à l'agencede Lyon pour une qualification téléphonique ; Etape 2 - Un premierentretien est programmé avec Justine ou Nathan en physique ou visio ; Etape 3 – Vous rencontrez Matthieu,un manager technique avec l’un de nos experts Data Analytics En fonction du poste, vous pouvez passer des étapessupplémentaires (entretien supplémentaire ou test technique) LAVIE CHEZ MICROPOLE, C’est : Une vie interne rythméepour se familiariser à la culture d’entreprise et aux valeurs deMicropole ; Des évènements internesréguliers pour partager les connaissances aussi bien techniques quefonctionnelles ; Une politique de formationattractive et éclectique (certifications prises en charge) ; Un travail en équipevalorisé pour une meilleure cohésion ; Participation à des projetsinternes sur la base du volontariat. ÀPROPOS DU GROUPE MICROPOLE Groupe international deconseil et technologies innovantes, MICROPOLE est spécialisé dans les domainesde la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine,les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists,architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leursclients partout dans le monde sur l'ensemble des phases de leurs projets, duconseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% deson chiffre d’affaires à l’international et est coté sur le marché Eurolistcompartiment C d’Euronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole A PROPOS DE L'AGENCE MICROPOLE LYON L’agence Micropole Lyons’appuie sur son implantation stratégique et son expertise technique pourporter et accompagner les ambitions de croissance du groupe Micropole. Sousl’impulsion de notre Directrice d’Agence, Armelle Descaillot, nous souhaitonscréer une synergie entre la data et le digital afin d’apporter une réellevaleur ajoutée à nos clients et les accompagner sur les défis technologiques dedemain. Les marques fortes du groupetelles que Wide (agence digitale intégrée au groupe Micropole) etLucy in the Cloud (entité conseil du groupe Micropole dédiée à AWS) noussoutiennent et nous permettent de nous positionner comme acteur conseil de référencedans la région Centre-Est. Véritable agence à taillehumaine où règnent esprit d’équipe et convivialité, nos talents allientsavoir-faire et expertise pour répondre aux besoins de transformation desentreprises. #LI-JHE","Micropole seeks a Data Engineer in Lyon to work on a variety of projects with a ""Data 360°"" vision, consulting, architecture, integration and data science. Ideal candidates should have a minimum of three years of experience in projects relating to ETL tools and reporting, with at least one experience working on AWS or Azure projects. Candidates should possess communication skills, problem-solving ability, and a desire to develop themselves and others through constant growth, learning and sharing their knowledge.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
313,56615,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/big-data-engineer-f-h_la-defense_INGNI_ko6eQmz,BIG DATA ENGINEER-,Ingéniance,"{Jenkins,Git,HDFS,Linux,Hive,Spark,Docker,Java,Hadoop,Python}",Télétravail partiel possible,La Défense,IT / Digital,CDI,2023-03-26,"Ingéniance, est une société de conseil spécialisée dans des projets liés aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajoutée en associant innovation technologique, transformation digitale, expertise métier (Banque, Finance et Assurance) & méthodes agiles. Technology-oriented, elle offre une réelle expertise à ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l’Agilité. Son projet d’entreprise s’appuie aussi sur des valeurs humaines, sociétales et environnementales (Label EcoVadis Gold). La proximité, la performance, la convivialité et le progrès sont des atouts sur lesquels elle bâtit sonévolution collective au quotidien. Missions : Rattaché à nos experts, au sein de notre lab « Big Data » , vous : aurez en chargela réalisation d'un prototype Big Data(technologies Hadoop HDFS, Hive, Spark, etc) participerez aux activités de veille technologique sur le domaine du Big Data (recherches, expérimentations, etc) participerez à la rédaction d'articles et à l'animation de nos réseaux sociaux sur le domaine du Big Data évoluerez dans des équipes fonctionnant en méthode Agile utiliserez les outilsDevOpsdéployés sur nos chaînes d'intégration continue (Jenkins, Docker, Git, etc) Ce poste sera l'occasion d'intégrer notre programme de formation interne avec pour objectif d'acquérir les compétences fonctionnelles de base sur nos secteurs d'activité (finance de marché, banque et assurances) mais aussi de solides connaissances techniques. Profil recherché : Vous êtes diplômé d'une école d'ingénieurs ou équivalent. Une spécialisation dans le génie logiciel sera vivement appréciée. Réactif, avec le sens du service, vous justifiez de bonnes capacités d'écoute, d'un bon relationnel et une bonne gestion du stress. Curieux, autonome, et proactif, vous avez les qualités nécessaires à ce projet. Vous êtes intéressé par le conseil , les systèmes d'informations et le secteur de la Banque/ Finance/ Assurance Compétences requises : Des compétences en développement : Java ou Python. Des compétences des OS Linux et Windows ; Des compétences sur le framework Hadoop ; Une connaissance théorique et idéalement pratique de la gestion d'un projet informatique; A minima une connaissance théorique des méthodes Agile (Scrum par exemple).","Ingéniance seeks a Big Data Prototype Developer with expertise in Craft Development, Big Data, Cloud/DevOps, and Agile methods to join their Big Data lab. Candidates must be engineering graduates with knowledge in Java/Python for coding, and experience with Hadoop framework, Linux and Windows OS. Along with developing a Big Data prototype, consultants will also participate in technology watch activities, social media campaigns, and agile teams. The role will allow for continued professional development.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
314,56334,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-software-engineer-m-f-d_paris,Data & Software Engineer,Artefact,{},Télétravail partiel possible,"19 rue Richer, Paris, 75009","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that’s why we identify as “marketing engineers”. In order to improve the performance and impact of brands, and consumers’ experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). From design to deployment , you manage your solution end-to-end, while also optimising the performance, security and scalability. Our working language is in English and preferably the local language of the office. The team The most tech people of our Data & Consulting division, the title of ""Data engineer"" or ""Software engineer"" does not describe everything our amazing women and men can do: data engineering, operation management, security, cloud architecture, MLOps, and more. Presenting in each and every office of Artefact, working seamlessly with our consultants and data experts, our Data & Software engineers are the ones who make our data projects come true. Mission You will work with the team to identify your clients' needs and define innovative solutions of which you will be ownership from start to end. You manage both its conception and implementation, while also optimising the performance and scalability. You will also coach others, keep abreast of industry news/updates and get stuck into training sessions with our business partners and suppliers, such as Google & Amazon. You share your knowledge, learnings and success, with the capability of presenting and communicating. Desirable skills You are the master of several, or all the value chain's activities of the projects: cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, continuous integration and deployment; You have no problem popularizing technical terms or solutions to more business-oriented profiles, you can work in a team with very diversified profiles. You know how to prioritize your tasks, respect deadlines, and anticipate projects' risks. ... or soon you will be, contact us! Why should you join us Artefact is the place to be: come and build the future of data and marketing Innovation: We have a passion for creating impacting projects, and believe innovation can come from anyone. Action: We make things rather than telling people how to make them. Collaboration: We believe in bringing talented people together, in winning together, and in learning from each other. Come join us!","Artefact, a consulting firm specialized in AI and Data, is seeking a Data or Software Engineer with skills in cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, and continuous integration and deployment. The ideal candidate should have the ability to communicate sophisticated solutions to business-oriented profiles and work in a team with diversified profiles while prioritizing tasks and anticipating project risks. Artefact offers a collaborative work environment where innovation and action are encouraged.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
229,56508,https://www.welcometothejungle.com/fr/companies/ekinox/jobs/data-scientist-machine-learning-engineer_paris,Data Scientist / Machine Learning Engineer,Ekinox,"{PyTorch,TensorFlow}",Télétravail partiel possible,"Paris, 75001","Logiciels, Intelligence artificielle / Machine Learning, Incubateur / Accélérateur",CDI,2023-03-26,"Ekinox est une jeune entreprise ayant deux activités distinctes : le service aux entreprises d’une part et la Startup Factory d’autre part. Sur ces deux activités, Ekinox a deux moteurs principaux : La culture de l’excellence, synonyme de beauté, de simplicité et d’une quête de perfectionnement continue, grâce notamment à des sessions d’entrainement et de partages de connaissances. la data et l’IA, qui permettent d’atteindre un niveau de valeur ajoutée supérieur, lorsqu’utilisées à bon escient Le poste: Data Scientist/Machine Learning Engineer Vous travaillerez main dans la main avec d’autres personnes aux profils variés (Data Ingénieurs, Data Scientists, Machine Learning Engineers, Product Owners, Scrum Masters, …), au sein d’une équipe multidisciplinaire et soudée, avec des automatismes et des pratiques de travail avancées. Ensemble, vous vous focaliserez sur la meilleure manière de générer de la valeur, ce qui selon nous passe généralement par des solutions simples. Vos principales missions Participer à la réalisation des produits de Data Science de bout en bout dans le cadre la Startup Factory et de la prestation de services Apporter votre expertise et savoir-faire en Data Science et en intelligence artificielle à l’ensemble de l’entreprise et à ses partenaires Participer au développement de la stratégie et de l’expertise Data Science de l’entreprise Aider à développer l’image de marque Ekinox sur la Data Science et l’Intelligence Artificielle Profil recherché Vous avez une bonne connaissance des principaux algorithmes et bibliothèques de Machine Learning (parmi scikit-learn, TensorFlow, PyTorch, etc.) Vous êtes curieux, et aimez expérimenter de nouvelles approches De préférence, vous avez déjà participé à des projets à base de Machine Learning en production, et avez du recul sur ce que cela implique Vous avez une appétence forte pour le développement logiciel et les bonnes pratiques associées Vous êtes pédagogue, et savez expliquer des concepts complexes à des audiences non-techniques Démarrage ASAP","Ekinox is seeking a Data Scientist/Machine Learning Engineer with expertise in data science and artificial intelligence. The ideal candidate will have knowledge of major ML algorithms and libraries (such as TensorFlow and PyTorch), experience with ML projects in production, and a strong interest in software development and pedagogy. They will work within a multidisciplinary team to generate value through simple solutions, participate in end-to-end data science product creation, develop the company's data science strategy and expertise, and promote Ekinox's brand in the field. The position is available as soon as possible.",Bac +5 / Master,Entre 15 et 50 salariés,> 5 ans,2,1,0.04154662416233763
305,57144,https://www.welcometothejungle.com/fr/companies/ornikar/jobs/data-engineer_paris_ORNIK_4Jq2W8W,Data Engineer,Ornikar,"{Jenkins,Airbyte,Metabase,Airflow,dbt,scale,moderne,via,BigQuery,GCP,Mixpanel,Python}",Télétravail partiel possible,"France, Paris, 23230","Mobilité, FinTech / InsurTech, EdTech",CDI,2023-03-26,"Ornikar étoffe son offre historique d’auto-école et devient une plateforme d’accès à la mobilité pour les jeunes ! Leur volonté : réinventer l’expérience des jeunes générations autour de l’apprentissage de la conduite, et les accompagner grâce à un écosystème de services tels que l’assurance automobile. Fondée en 2013 et leader sur la modernisation du permis de conduire, l’équipe Ornikar continue d’évoluer et de militer pour l’émancipation des jeunes et la transition vers leur indépendance ! Aujourd’hui constituée de 260 collaborateurs, leur équipe connaît une croissance continue construite sur de solides fondations : leur produit permis de conduire (plateforme d’e-learning et marketplace de mise en relation avec nos enseignants de la conduite) d’une part, mais également leur connaissance utilisateur approfondie qui leur permet d’offrir une assurance auto plus proche des besoins des jeunes assurés : modulable, simplifiée, adaptée à tous avec un prix et des options personnalisées. À propos de l'équipe Data 🦸 L’équipe Data chez Ornikar existe depuis plus de 3 ans et est composée d'une vingtaine de personnes (Data Analysts, Data Engineers, Machine Learning Engineers). Nous avons principalement 3 missions : L’aide à la décision : on accompagne les équipes à tous les niveaux de management, que ce soit pour des objectifs stratégiques, de développement produit, de métier… Nous menons des analyses complexes pour permettre aux équipes de prendre les décisions basées sur des chiffres qui nous permettront d’atteindre nos objectifs ou d’identifier de nouveaux leviers de croissance. L’efficacité opérationnelle : Les équipes chez Ornikar sont très sensibles aux enjeux data, ce qui nous a permis de mettre en place d’une part le self-service BI pour leur permettre d’effectuer leurs recherches quantitatives en parfaite autonomie, et d’autre part nous répondons à des problématiques d’automatisation de flux de données pour enrichir leurs outils et accélérer leur quotidien. Le développement de features data et d’algorithmes pour apporter encore plus de valeur différenciante à nos produits. Nous recherchons un.e Data Engineer 🌋 Pour soutenir ces missions, toute l’équipe participe à la construction d’une stack Data de pointe répondant aux enjeux d’une équipe Data moderne. Afin de faire grandir encore l’équipe, nous cherchons notre prochain(e) Data Engineer. Nous recherchons un profil confirmé pour aider au développement data d’Ornikar, notamment : Construire une vision unifiée du parcours utilisateur sur toutes nos plateformes Créer, modéliser, enrichir et faire évoluer nos Datamarts Travailler à la robustesse de flux de données , de la collecte à la transformation S’assurer de la qualité de la donnée en interne pour une confiance toujours plus forte dans les productions de l’équipe Data Implémenter et améliorer les différentes briques de notre socle technique, pour nous faire gagner en efficacité et en qualité de service : ELT & reverse ELT, reporting & self-service BI… Notre stack en quelques mots : Airbyte, Mixpanel, Airflow, GCP (BigQuery), dbt, Periscope, Metabase and so on ^^ Aussi, nous restons très ouverts aux initiatives (technos / outils / etc.) Nous rejoindre, c’est la garantie de travailler dans un environnement stimulant, d’avoir de l’impact dans la structuration de l’équipe et de ses process et de participer à la croissance d’un super projet. Tu es notre candidat.e idéal.e si tu… 🤩 Tu as au moins 4 ans d’expérience en tant que Data Engineer Tu possèdes de solides connaissances dans les stacks Data modernes Tu possèdes de solides connaissances en bases de données et modèles de données Tu maîtrises parfaitement Python ou un autre langage de programmation Tu es curieux·se, enthousiaste, et tu as une démarche proactive Tu as un profil technique et es capable de travailler avec l’équipe Tech/Produit Tu aimes travailler en équipe et communiquer avec des audiences pas nécessairement techniques Si tu as des connaissances sur les sujets suivants, c’est bonus : Mise en production de modèles de Machine Learning Outils d’ intégration continue (Jenkins) Collecte et flux de données en temps réel Le process de recrutement pour ce poste 💪 Un premier échange téléphonique avec Romane, notre Talent Acquisition Specialist Entretien avec Joris , VP Engineering assurance (ton futur manager) pour vous préciser les contours du poste et les enjeux de la team Une étude de cas à préparer à la maison, puis à restituer autour d'un échange d'1h avec Thibault et Nicolas , nos deux Head of Data sur nos produits Assurance et Education pour vous projeter sur des missions du poste en conditions réelles Une rencontre avec notre CTO, Cédric, parce qu’il est cool Un entretien de culture fit avec les membres actuels de l'équipe pour partager sans pression sur nos valeurs et notre quotidien. Ce qu’Ornikar a à vous offrir… 🎁 Une rémunération fixe entre 60k€ et 70k€, en fonction de votre profil La possibilité de travailler en remote depuis n’importe où en France Nous sommes votre entreprise idéale si vous recherchez… 🔍 Une start-up française devenue scale-up qui se structure, développe de nouveaux produits et s’exporte à l’international 🌎 La possibilité de passer votre permis gratuitement 😉 Un environnement de travail respectueux de tous et toutes. En tant que membre fondateur du pacte IDEA, nous nous engageons pour la diversité, l'équité & l’inclusion Une aventure dans laquelle vous pourrez apprendre et sortir de votre zone de confort, avec une grande variété de missions et beaucoup d’autonomie Beaucoup de place pour des initiatives innovantes et créatives, nous adaptons nos process et méthodes sans cesse Parmi nos avantages collectifs 🙌 Un abonnement sport et bien-être Gymlib 🏑 Une assurance santé complémentaire avec Alan Une Swile pour vos tickets restaurants (11€ par jour) Les frais de gestion pour votre épargne salariale avec Epsor Des centaines de réductions et avantages via Leeto, partenaire de notre Comité Social Économique Le remboursement des frais de transport en commun à 50% ou le forfait mobilités durables jusqu'à 450€/an avec la carte Worklife 🌳 Et si vous nous rejoignez en remote… Une carte de dépenses Spendesk pour assurer vos déplacements et nuits d'hôtels lors de vos séjours au bureau à Paris La prise en charge de la carte SNCF Liberté utilisable pour vos déplacements personnels également","Ornikar, a platform providing driving courses and related services, is seeking an experienced data engineer to join its data team. The successful candidate will be responsible for improving the quality of data, constructing unified user journeys, and building data models and new features to boost efficiency and service quality. The platform uses a stack that includes Airbyte, Mixpanel, Airflow, GCP (BigQuery), dbt, Periscope, Metabase, and others. The ideal candidate should possess more than four years of experience, be proficient in Python and other programming languages, and demonstrate a proactive and communicative approach. The platform offers a respectful, diverse, and inclusive work environment, free driving courses, and a range of benefits.",Non spécifié,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
255,56345,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_639bXKJ,Data Engineer,FACILECOMM (SHIPPINGBO),"{Redis,MongoDB,Pandas,PostgreSQL,Redshift,Airflow,AWS,R,SQL}",Télétravail partiel possible,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-03-26,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait mené(e) jusqu’à cette annonce ! Peut-être est-ce toi, le/la futur(e) Data Engineer que nous attendons… En tout cas, nous l’espérons. Dans un premier temps, permets nous de nous présenter. Qui est Shippingbo ? La première chose que tu dois te demander c’est “qui est Shippingbo” et c’est une très bonne question ! Shippingbo est une technologie logistique e-commerce fondée en 2016, par la société facilecomm. Nous mettons à disposition des vendeurs en ligne une technologie qui leur permet d’optimiser toute leur chaîne logistique : depuis la récupération des commandes, jusqu’à leur expédition, en passant par la préparation. Pour la faire très simple, on est la technologie de l’ombre qui permet à ton site favori de te livrer dans les meilleurs délais, tout en te notifiant de l’avancée de ta commande. Pas mal, non ? Notre ambition : permettre à nos clients de proposer aux consommateurs un parcours d’achat au top, digne des géants du e-commerce ! Aujourd’hui, nous comptons pas moins de 1000 clients aux activités e-commerce assez variées : e-commerçants, retailers, fournisseurs, grossistes…. mais dont le point commun reste la vente en ligne ! Avec près de 72% de croissance en 2021 et plus d’1 milliard d’euros de GMV, nous sommes bien décidés à poursuivre sur cette lancée pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage européen d’ici 3 ans ! Shippingbo cherche aujourd’hui à développer les outils d’analyse qu’elle met à disposition de ses clients ainsi qu’à développer de nouvelles fonctionnalités se fondant sur l’analyse des données. En tant que data engineer, votre rôle sera de construire et maintenir les entrepôts et pipelines de données. Vos missions principales consisteront à : Participer à la définition des schémas de données et aux choix d’architecture ; Définir et optimiser les requêtes faîtes par l’API et celles au cœur des pipelines ; Préparer des datasets exploitables à des fins d’analyse ; Identifier de facon plus générale les moyens optimaux de répondre à l’ensemble des requêtes de données ; Optimiser également le fonctionnement des pipelines et maintenir les systèmes surveillant leur bon fonctionnement et la qualité des données ; Participer à l’administration, la configuration et le paramétrage des bases de données. - Vous avez au moins 2 ans d’expérience comme data engineer (ou des rôles similaires) et dans la construction et la maintenance de pipelines de données ; - Vous avez une connaissance approfondie de SQL , de l’optimisation de requêtes et des entrepôts de données ; - Vous avez une expérience avec au moins une base de donnée orientée colonnes ; - Idéalement vous avez également une expérience avec une base de donnée orientée documents et une base de donnée clé-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en métro, arrêt Ramonville) Rattaché au département R&D de l'entreprise Mise à disposition d’outils informatiques Tickets restaurant >>> Venez découvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversité occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'égalité professionnelle et l'emploi des travailleurs en situation de handicap. A compétences équivalentes, ce poste est ouvert à tous.","Shippingbo, a logistics technology company, is seeking a data engineer to build and maintain data warehouses and pipelines, optimize queries, and prepare data for analysis. Requirements include at least 2 years of data engineer experience, expertise in SQL, data warehousing, and experience with column-oriented, document-oriented, and key-value databases. The position is a full-time contract and located in Toulouse, France. Shippingbo values diversity and encourages applications from individuals with disabilities.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
252,56635,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-science-engineering-manager-f-h_massy_CARRE_e3jl00Z,Data science Engineering manager,Carrefour,"{durable,Kubernetes,Airflow,R,Spark,BigQuery,SQL,Python,Tableau}",Télétravail partiel possible,"AUDREY ALLIEN, Massy","Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux défis de notre époque, Carrefour a pour ambition de rendre le meilleur accessible à tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos équipes. Nous nous épanouissons en équipe : Métiers du commerce, métiers d'expertise, entrepreneurs unissent leurs compétences et leurs efforts pour construire ensemble une chaîne de valeur au service des consommateurs. Au plus près de nos clients ou en coulisses, chacun a un rôle à jouer mais peut compter sur les autres pour réussir. Nous veillons à ce que chacun puisse aller loin : L'envie et le mérite sont les seuls pré-requis pour nous rejoindre, accéder à une formation, changer de métier, être promu ou créer son entreprise. Nous partageons la victoire : nos collaborateurs sont engagés et nous nous engageons en retour. En offrant des rémunérations et des avantages parmi les meilleurs de notre secteur, en permettant à chacun d'être associé aux résultats, en veillant à la santé de tous. Créateur de l'hypermarché et pionnier de la consommation de masse, Carrefour reste fidèle à ses racines mais se réinvente pour permettre à chacun, chaque jour, de manger mieux : plus sain, plus local, plus responsable. Nos atouts pour y parvenir ? Un réseau multiformat de + 5 300 magasins, la création de services et d'une offre digitale de référence, une coopération renforcée avec les acteurs du monde agricole, de la chaîne alimentaire, de la Tech... En pleine transformation, la DATA France se renforce et recherche un(e) : Data science Engineering manager F/H BON A SAVOIR: CDI/ ASAP/ CADRE N8/MASSY L'utilisation de la data et le développement des capacités analytiques sont un axe majeur du plan stratégique du Groupe Carrefour à horizon 2027. Directement rattachée au COMEX France, l'Analytics Factory de Carrefour France est le pilier de cette transformation analytique, au service des clients et de l'ensemble des équipes métier de Carrefour France - Marketing, Marchandises, Exploitation, E-commerce, Supply Chain, Services Financiers, etc… À propos du poste Au sein du pôle de data science de l'Analytics Factory, vous mènerez une équipe rassemblant data scientists et data engineers sur des projets de science des données, au service de la définition de l'offre. L'objectif de cette équipe est de construire les solutions automatisés, fondées sur les données, pour choisir quels produits vendre, dans quel magasin, à quel prix, en adéquation avec les objectifs stratégiques de Carrefour. Ces solutions reposent notamment sur des algorithmes de machine learning et operation research. Vos missions seront de : suivre, conseiller, guider, former les différents ingénieurs de l'équipe planifier et organiser l'exécution de projets techniques complexes en collaborant activement avec les product owners, les équipes métiers et les autres équipes techniques de Carrefour recruter pour assurer l'adéquation des effectifs de l'équipe aux besoins actuels et futurs être garant des méthodologies de science des données et de développement logiciel agile de l'équipe contribuer à la conception d'architectures de services sécurisées, fiables, facilitant la maintenance évolutive Vous évoluerez dans un environnement agile et collaboratif. Vous pourrez également participer aux échanges réguliers de notre communauté d'une trentaine d'ingénieurs (data scientists, engineers, devops) : retour d'expérience, débats sur les problématiques ML, de développement logiciel, ... En tant que Engineering Manager , vous rapporterez à l' Engineering Director du département. À propos de vous Diplômé en informatique ou mathématique appliquée, au moins au niveau master, ou justifiant d'une expérience professionnelle équivalente, vous disposez de très solides connaissances sur les algorithmes d'apprentissage statistique. À l'issue d'au moins 5 années d'expérience professionnelle, vous avez développé une solide expertise et un recul sur chaque étape du cycle de vie d'un projet de data science et la manipulation de base de données à grande échelle. Vous êtes désormais capable d'aborder n'importe quel champ de la data science, et également de conseiller et guider des data scientists et data engineers juniors sur ces projets. Vous avez également participé à l'industrialisation de solutions fondées sur du machine learning, idéalement dans un contexte cloud, et maîtrisez les bonnes pratiques architecturales. Vous avez déjà managé des profils techniques, avec différents niveaux d'expérience, et vous souhaitez continuer de vous spécialiser sur ce rôle d'encadrement. Vous êtes motivés par les problématiques opérationnelles très concrètes, que l'on peut notamment rencontrer dans l'univers de la grande distribution. Pour cela, vous aimez interagir avec des professionnels, d'horizons différents. Grâce à d'excellentes qualités relationnelles et de communication, vous êtes en mesure de communiquer vos idées complexes à différents publics non-techniques.. Vous avez pris part à des projets de développement collaboratifs, et la qualité et la simplicité du code vous tiennent à cœur. Vous maîtrisez le français et êtes en mesure de mener des discussions avec les opérationnels de Carrefour France. Vous maîtrisez un anglais technique a minima. Environnement technique Python, BigQuery, Spark, Kubernetes, Terraform, Airflow Informations complémentaires Siège mondial du groupe Carrefour, Massy Possibilité de télétravail plusieurs fois par semaine. Avantage 10% Carte Pass pour le collaborateur et PEE (plan épargne entreprise) Rémunération sur 13,5 mois L'accès aux Services exclusifs à Massy : Salle de sport, crèche, plusieurs options de restauration au sein du siège avec participation CE, infirmerie, téléconsultation médicale, conciergerie, Coiffeur Chez Carrefour, nous avons à cœur de ne passer à côté d'aucun talent et sommes fiers de compter des équipes représentatives de la société dans son ensemble. Nous encourageons ainsi tous types de profils à postuler à cette offre et garantissons un processus de recrutement dénué de toutes formes de discriminations. Vos compétences : Compréhension du business et goût du commerce ; la connaissance du retail, en particulier alimentaire, est un plus Excellentes capacités analytiques et statistiques, capacité à comprendre les principes de modèles data science Très bonnes capacités dans la manipulation de grandes volumétries de données ; maîtrise d'un langage de requêtage des données (SQL , Big Query), d'outils de datavisualisation (Tableau, Google Data Studio) ; la maîtrise de Python / R est un plus Bon relationnel et capacités de synthèse écrite et orale.","Carrefour is looking for a Data Science Engineering Manager to lead a team of data scientists and engineers in developing automated data solutions to inform product pricing and selection. The ideal candidate will have a master's degree in computer science or applied mathematics, at least five years of experience in data science, and expertise in statistical learning algorithms, database manipulation, and machine learning industrialisation. The role involves mentoring team members, collaborating with different teams, and advocating for best practices in software development and data science methodologies. The position reports to the Engineering Director and requires excellent communication skills and fluency in French and technical English. The role is based in Massy, France, but teleworking is possible. Carrefour is an equal opportunity employer and encourages candidates from all backgrounds to apply.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
283,56628,https://www.welcometothejungle.com/fr/companies/ekinox/jobs/data-engineer_paris,Data engineer,Ekinox,"{GCP,Azure,Jupyter,Kubeflow,Tensorflow,Git,Scala,Gitlab,Kubernetes,AWS,Kafka,Hadoop,Spark,Docker,Java,Github,Python}",Télétravail partiel possible,"Paris, 75001","Logiciels, Intelligence artificielle / Machine Learning, Incubateur / Accélérateur",CDI,2023-03-26,"Qui sommes-nous ? Ekinox, jeune entreprise à taille humaine (<30 collaborateurs) fondée par des ingénieurs, pour les ingénieurs. Nous exerçons deux activités principales: D’un côté, le service numérique , notamment dans la Data, le Machine Learning et le Cloud. De l’autre côté, la “Start-up Factory”, espace de création des pépites numériques d’aujourd’hui et de demain. Exemple d’entreprise fraîchement sortie de notre factory : Moovance [L’app qui récompense ta mobilité - Moovance] Ce qui nous fait avancer ? La culture de l’excellence et de la simplicité, dans une quête de perfectionnement continue. Vous trouverez chez nous : Une journée par mois dédiée au partage de connaissances Une autre journée par mois dédiée à la Startup Factory et à l’entraînement de nos équipes Deux journées par mois, la possibilité de participer à l’élaboration et au développement de nos OKRs (objectifs d’entreprise) Le parti pris de ne pas faire de choix entre l’individu et le collectif. Les deux étant, selon nous, essentiels et complémentaires. Qu’est-ce qui nous anime ? Nous sommes en quête de sens permanente. Notre objectif est de créer des produits qui répondent aux vrais besoins de notre monde en mettant en œuvre des technologies de pointe qui s’appuient sur les connaissances tirées ingénieusement de la Data. Nous aspirons à développer des équipes d’experts soudées. À terme, nous souhaitons n’avoir plus aucune mission individuelle. Les consultants interviendront en équipe chez nos clients pour favoriser le collectif Ekinox. Et, dans cette même idée de recherche de l’excellence, nous guidons celles et ceux qui en ont envie à devenir les entrepreneurs de demain grâce à la Startup Factory. A propos de votre mission : Avec nous, vous travaillerez en équipe. Vous vous entraînerez avec des coéquipiers à votre image (et donc à notre image) dans un cadre agile (souvent Scrum), jusqu’à entrer en résonance avec eux. Lorsque vous travaillez pour votre client, votre sens de l’empathie vous pousse à toujours mieux comprendre ses problématiques de fond. Votre socle méthodologique sera sérieusement constitué de TDD, BDD, pair programming et autres principes établis de qualité tirées notamment des pratiques prônées par Extreme Programming ou du Craftsmanship Manifesto. Fortement impliqué dans la vision produit, vous considérez le Product Manager au même titre que n’importe quel autre de vos coéquipiers. Ce qu’Ekinox recherche chez vous : Vous avez une expérience de 2 ans ou plus (mais on peut toujours en discuter) Vous vous sentez concerné·e par le software craftsmanship et faites de la veille technologique Vous aimez travailler en équipe et partager vos connaissances Vous êtes ouvert·e aux autres et acceptez leurs points de vue avec bienveillance Vous contribuez à la progression des personnes qui vous entourent Compétences techniques : Voici une liste non-exhaustive des technologies que nous utilisons. Vous aurez pour mission de produire de la valeur avec un certain nombre d’entre elles: Langages de programmation suivants : Python, Java, Scala Outils d’industrialisation : Gitlab CI / Github Actions / Google Cloud Build Infrastructure et déploiement : Docker / Kubernetes, Terraform Travail en équipe : Git Web : Spring et autres frameworks Services cloud : AWS / GCP / Azure Big Data: Spark, Hadoop, Kafka, Terraform, Jupyter Machine Learning : Tensorflow, Scikit learn, Kubeflow et toutes les autres technologies que vous viendrez ajouter à la liste Déroulement du processus de recrutement: Etape 1: Première rencontre RH en visio (1 h) Etape 2: Test technique (rapide et à réaliser sans pression chez vous, 30-45 minutes) Étape 3: Rencontre avec 1 ou 2 data ingénieurs de chez Ekinox (environ 2 h) Étape 4: Rencontre avec l’un des co-fondateurs d’Ekinox (30 minutes)","Ekinox, a small-scale digital service company, is seeking a Data Engineer with a minimum of 2 years' experience. The candidate must have expertise in programming languages like Python, Java, and Scala, and tools such as Docker/Kubernetes, Terraform, Gitlab CI/Github Actions/Google Cloud Build, AWS/GCP/Azure, and Spring frameworks. The company values teamwork, sharing knowledge, and continuous self-improvement. The recruitment process includes virtual interviews, technical assessments, and meetings with data engineers and cofounders.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
315,56355,https://www.welcometothejungle.com/fr/companies/agaetis/jobs/data-engineer_aubiere,Data Engineer,Agaetis,"{Hive,Elasticsearch,Docker,Azure,tensorflow,MySQL,Nosql,MongoDB,Databricks,Kafka,hadoop,Flink,Kubernetes,AWS,Akka,Storm,Hadoop,SQL,Tensorflow,spark,Mongo,k8s,Scala,Spark,kafka,sql,Python,AirFlow}",Télétravail partiel possible,"9 Allée Evariste Galois, Aubière, 63170","Intelligence artificielle / Machine Learning, Big Data, Cybersécurité",CDI,2023-03-26,"Depuis 2017, Agaetis est une filiale du groupe Novencia. Ils apportent leur expertise technologique et leur savoir-faire pour lever les freins à l’innovation. Basée à Clermont-ferrand, Lyon et Paris, Agaetis apporte à ses clients une vraie réponse basée sur l’analyse du besoin et la compréhension de leurs enjeux. Ils mettent le conseil, l’expertise technologique, l’intelligence collective et l’engagement humain au service de leurs clients, afin d’apporter la meilleure solution. Ils capitalisent également sur de la Recherche Développement Innovation (RDI) pour fournir des solutions clés en main et répondre aux enjeux de demain. Depuis 2007, la croissance de Agaetis a été progressive et maîtrisée afin de garantir la continuité d’un écosystème passionnant. Leur organisation permet à chaque membre de Agaetis, de participer et de partager ses idées pour définir ce que sera l’Agaetis de demain. Ce qu’ils proposent à leurs clients, ils se l’appliquent aussi en interne. Chez Agaetis, il ne faut pas avoir peur du changement, leur mot d’ordre : L’amélioration continue, que ce soit pour leur bien-être mais aussi pour la satisfaction de leurs clients. Ils sont maintenant une équipe complémentaire et désireux d’en apprendre tous les jours. Ils travaillent dans un écosystème varié entouré de start-ups, PME et grands groupes issues de différents secteurs : Industrie, Agriculture, Bâtiment, Santé, Finance, Assurance, E-commerce. Vous êtes passionné, créatif, savez imaginer et concevoir des solutions permettant le traitement de volumes importants de données, tout en garantissant la sécurité de celles-ci ? Ce poste est peut-être pour vous ! Le Data Engineer est un pilier pour les projets data . Il construit les structures de données et met en place les briques technologiques nécessaires pour l’acquisition, l’analyse et l’implémentation des modèles qui utilisent les données dans un contexte massif de données. Son rôle est de choisir les bonnes technologies selon les besoins en collaboration avec différents métiers/projets. Le Data Engineer travaille avec les Data Scientist pour savoir quelle architecture est nécessaire au développement des modèles scientifiques afin d’aider à industrialiser son modèle et de garantir la montée à l’échelle. Le Data Engineer chez Agaetis est en charge de : S’assurer que les données de nos clients soient facilement accessibles afin qu’elles puissent être exploitées par les différents métiers (DS, BI, applicatifs…) Veiller à la performance des modèles et applicatifs créés à partir des données Extraire, uniformiser et structurer les données depuis les datalakes de nos clients Maitriser la modélisation des données dans un datalake pour assurer la bonne exécution de ses traitements S’assurer de la fiabilité des données utilisées Mettre en place des flux de données entre les systèmes en ingestion et en exposition (batch, API, temps réel …) Explorer de nouvelles technologies, faire de la veille technologique Comprendre l’architecture Datalake dans son ensemble et préconiser des adaptations pour le déploiement et le traitement de ses modèles Le Data Engineer que nous recherchons pour intégrer notre équipe Clermontoise, devra disposer d’au moins deux ans d’expérience à un poste similaire. De formation Bac + 5 ou École d’Ingénieur, vous disposez déjà de compétences sur les différentes technologies autour du flux de données (Nosql, sql, ETL, hadoop, kafka…) et vous connaissez l’environnement de Machine Learning (sklearn, spark ml, tensorflow..). Connaissances recherchées : Rest-API (Flask, FastAPI), Databricks, Maîtrise de Python Maîtrise de différentes technologies autour du flux de données : Mongo, Nosql, SQL ETL, Hadoop, Kafka, Databricks, … Connaître l’environnement de Machine Learning : Sklearn, Spark ml, Tensorflow… Azure, Docker, k8s Rest-API (Flask, FastAPI) Autres connaissances souhaitées : Ecosystème Apache Hadoop : Spark, Hive, Kafka streaming, AirFlow Cloud : Azure, AWS, Google Cloud… Langages Big Data : Scala, Python Outils de virtualisation et container : Docker, OCI, … Orchestrateurs : Kubernetes… Base de données : SQL Server, MySQL, MongoDB, Elasticsearch Conception de pipeline d’ingestion de données sur des frameworks de calcul distribués (Spark, Akka, Flink, etc.) temps réel (Kafka, Storm, Spark Streaming). Les qualités requises sont : La créativité L’esprit d’équipe La rigueure La communication L’adaptabilité La curiosité Veille technologique Trois entretiens : Entretien de préqualification Entretien technique Entretien posture et intégration","Agaetis, a subsidiary of Novencia Group, is seeking a Data Engineer to join their team in Clermont-Ferrand. The role involves building data structures and implementing technological components to handle data acquisition, analysis, and model implementation in the context of massive data. The ideal candidate should have at least 2 years of experience and expertise in different data flow technologies, as well as knowledge of machine learning environments, Rest-API, and cloud computing. Qualities needed for the role include creativity, teamwork, communication, adaptability, attention to detail, and curiosity. Three interviews are involved, including a pre-qualification interview, technical interview, and a posture and integration interview.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
274,58072,https://www.welcometothejungle.com/fr/companies/safran-aircraft-engines/jobs/data-engineer-projets-industriels-f-h_gennevilliers,Data Engineer - Projets industriels,Safran Aircraft Engines,"{via,SQL,Mirage,python}",Télétravail partiel possible,"91 avenue d'Argenteuil, Gennevilliers, 92230",Aéronautique / Spatiale,CDI,2023-03-26,"Safran est un groupe international de haute technologie opérant dans les domaines de l'aéronautique (propulsion, équipements et intérieurs), de l'espace et de la défense. Sa mission : contribuer durablement à un monde plus sûr, où le transport aérien devient toujours plus respectueux de l'environnement, plus confortable et plus accessible. Implanté sur tous les continents, le Groupe emploie 79 000 collaborateurs pour un chiffre d'affaires de 16,5 milliards d'euros en 2020, et occupe, seul ou en partenariat, des positions de premier plan mondial ou européen sur ses marchés. Safran s'engage dans des programmes de recherche et développement qui préservent les priorités environnementales de sa feuille de route d'innovation technologique. Safran est classé meilleur employeur mondial 2020 dans son secteur par le magazine Forbes. Safran Aircraft Engines conçoit, produit et commercialise, seul ou en coopération, des moteurs aéronautiques civils et militaires aux meilleurs niveaux de performance. La société est notamment, à travers CFM International*, le leader mondial de la propulsion d'avions commerciaux courts et moyen-courriers. Dans le domaine de la propulsion militaire, la société a intégralement conçu développé et produit le M88 et le M53 qui équipent respectivement le Rafale et le Mirage 2000 et sera intégrateur du moteur du futur avion de combat européen. *CFM International est une société commune 50/50 de Safran Aircraft Engines et GE. Partie 1 : Data Engineer/Scientist Manufacturing Explorer les données et en extraire des tendances via des méthodes de visualisation et des méthodes statistiques d'analyse de données (outils power BI, BrainCube, script python, extraction de base SQL …), notamment en support en cas de crises et dans l'exploitation de liens produit-process forge, ainsi que sur l'évaluation de la pertinence de certains contrôles Contribuer à la création et l'enrichissement d'un référentiel d'outils facilement réutilisables, de méthodes d'analyse et les déployer auprès des équipes Partie 2 : Chef de projet Maitrise des Procédés (MdP) Anime le déploiement de la Maitrise des Procédés au sein de IBG - Recueillir auprès des responsables hiérarchiques de l'Unité Forge les besoins et propositions de mise en oeuvre des méthodes de MdP, et participer à la définition des projets de MdP - Coordonner l'ensemble des projets de MdP de l'Unité, et rendre compte de leur avancement en copil - Piloter le plan de formation des personnels impliqués ou destinés à être impliqués dans des projets de MdP, et assurer le coaching et le soutien méthodologique des pilotes de projets MdP Participation au réseau Maitrise des Procédés Safran Aircraft Engines Point focal avec Informatique Industrielle pour la partie projet (mise en place nouvelles solutions, problèmes récurrents etc…). Faire le lien entre la partie métier forge et l'informatique industriel. Ingénieur généraliste ou systèmes informatiques Autonome, rigoureux Gout pour l'industrie, la digitalisation et le pilotage de projets Force de proposition Fait preuve de leadership","Safran Aircraft Engines is looking for a Data Engineer/Scientist Manufacturing and a Chef de projet Maitrise des Procédés. The Data Engineer/Scientist Manufacturing will explore data trends and statistical analysis using tools such as Power BI, BrainCube, Python scripts, SQL, etc., and contribute to the creation and deployment of reusable analysis methods. The Chef de projet Maitrise des Procédés will oversee the implementation of manufacturing process methods through coordinating projects, providing training and support, and serving as a liaison between the forge business and industrial IT. The ideal candidates should be autonomous, rigorous, proactive, and have a passion for industry, digitalization, and project management.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
275,57057,https://www.welcometothejungle.com/fr/companies/exotec/jobs/data-engineer-3d-simulation_lille,R&D Data Engineer,Exotec,"{Docker,Kubernetes,Python}",Télétravail partiel possible,Lille,"Logistique, Objets connectés, Robotique",CDI,2023-03-26,"Exotec met l’excellence technologique au service de la redéfinition des relations entre humains et robots. A travers le monde, leurs solutions révolutionnent la façon dont leurs clients délivrent leurs produits aux consommateurs finaux. Ils contribuent au succès des plus grandes marques du commerce et de l’industrie, tout en améliorant les conditions de travail de leurs salariés. Par l’alliance de l’intelligence artificielle et d’un hardware performant, leurs robots sont désormais déployés dans le monde entier et leur succès a fait d’Exotec la première licorne industrielle française. Rejoindre Exotec, c’est l’opportunité de donner du sens à vos compétences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos idées, des réalités. La révolution robotique portée par Exotec ne fait que commencer, vous en êtes ? En rejoignant Exotec, vous ferez partie d’une équipe grandissante d’une dizaine de personne et vous contribuerez à l’amélioration de nos systèmes. Vous aurez l’opportunité de travailler avec un large éventail de spécialités différentes et sur plusieurs projets faisant usage du deep learning et d’algorithmes de pointe. En tant d’ingénieur software vous participerez au développement de nos outils de génération, d’annotation et de traitements des données utilisées pour entraîner nos systèmes de vision. Vos missions : Outils d’annotation de données Concevoir et implémenter des outils permettant de collecter et annoter les données d’entraînement Automatiser les taches répétitives liées à l’annotation et à la vérification des données Génération de données synthétiques Contribuer à la conception et l’amélioration de notre système de génération de données 3D synthétiques Implémentation de scripts de génération procédurale Performance et qualité Travailler en collaboration sur du code en Python Proposer et mettre en œuvre de bonnes pratiques de développement Optimiser les algorithmes et les faire passer à l’échelle sur le cloud Requirements Vous êtes diplômé d’une grande école d’ingénieur ou détenteur d’un doctorat Vous avez de l’appétence pour le Deep Learning et la Computer Vision Vous êtes à l’aise en développement avec Python et/ou C++ Vous avez des connaissances en modélisation 3D et rendu photoréaliste avec un logiciel tel que Blender Vous maîtrisez Docker et Kubernetes Vous savez prendre des initiatives et collaborer dans une ambiance décontractée au sein d’une équipe jeune et dynamique Un niveau d’Anglais opérationnel, à l’oral comme à l’écrit, est nécessaire","Exotec, a leading robotics company, is seeking a software engineer with experience in deep learning, computer vision, Python, and C++ to join their growing team. The successful candidate will work on developing tools for data generation and annotation, collaborate on Python code, optimize algorithms, and contribute to various projects using cutting-edge technology such as Kubernetes and Docker. Applicants should have a degree from a top engineering school or hold a Ph.D., as well as an operational level of English.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
271,61325,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-bi-data-engineer-f-h_paris,ALIT - BI Data Engineer,Air Liquide,"{Azure,Dax,SQL}",NaN,"Paris, 74000","Environnement / Développement durable, Santé, Energie, Digital",CDI,2023-03-29,"Air Liquide a entamé avec succès sa transformation Digitale et IT , centrée sur l'expérience client et l'amélioration de de la profitabilité des opérations, deux piliers majeurs de notre programme NEOS. Cette transformation impacte notre façon de réaliser, gérer et monitorer nos opérations. Elle implique aussi la définition de nouveaux modes de collaborations, la création de nouvelles compétences et de nouveaux postes. Aujourd'hui, le département Digital & IT poursuit cette transformation tant au niveau de l'infrastructure (GIO), des plateformes data (GDO), que des applications métiers (DSI ou BIS) et des dispositifs créés autour de l'innovation, des méthodes d'innovation et de la data (Fabs et Factory). Le département Global Data Operations (GDO) a été créé dans l'entité Air Liquide IT pour supporter les ambitions du Groupe en matière de gestion des données, apporter l'expertise technologique pour le développement de nouvelles solutions différenciantes pour le business Air Liquide, avec un focus particulier sur les sujets autour de la data dans un premier temps. GDO dans sa phase initiale opère trois plateformes : Business Intelligence, Data Lake et API. Au sein de GDO, et rapportant au Product Line Manager BI Group le ou la Technical Lead défini la roadmap technique pour la Product Line en cohérence avec la stratégie et les besoins exprimés par le Solution Owner et le Product Line manager. Il agit en référent pour l'ensemble des développeurs et data engineers de l'équipe mais aussi des parties externes, en particulier les BIS et entités GDO internationales, requérant son expertise. Il ou elle est intégré.e sur les projets structurants et travaille en coordination avec les product managers et le métier afin de s'assurer de la bonne réponse technologique face aux besoins exprimés. En tant que BI Data Engineer vous aurez les responsabilités suivantes : Concevoir, développer, tester et mettre en production des traitements de données dans différents contextes métier et applicatifs Concevoir, mettre en oeuvre et optimiser, avec les data architects et devops, les pipelines de traitement de la donnée permettant l'alimentation des applications data depuis les sources de données du Groupe Assurer le support des traitements de données mis en oeuvre Contribuer à la définition des processus, standards et méthodes techniques permettant d'assurer un haut niveau de qualité de service et de livrables Réaliser et partager avec l'équipe la veille technologique/l'état de l'art des technologies utilisées et être force de proposition S'assurer de la bonne application des règles de sécurité et de confidentialité du Groupe au sein de la plateforme, et des traitements de données (security by design, privacy by design) Assurer le rôle de référent technique auprès des data engineer junior intervenant dans l'équipe Compétences techniques Expérience minimum de 3-5 ans dans le design et l'implémentation de solution Azure BI de grande envergure Certification sur les produits Data Azure nécessaires ( e.g. AZ-900, DP-200, DP-201 ) Excellente maîtrise SQL & Dax Connaissance des méthodologies de développement Compétences non techniques Faire preuve d'autonomie, d'esprit d'initiative et de motivation Expérience passée de larges projets de BI en connexion directe avec le métier Capacité à travailler dans un environnement matriciel international (BIS, GIO, Fabs Digitales, IT industriel, entités business) Esprit critique, analyse et résolution des problèmes Capacités de communication écrites et orales, en particulier pour vulgariser les sujets techniques L'anglais et le français lus, écrits et parlés sont indispensables. Localisation géographique : France / Ile de France / Paris - Le poste est basé à Paris XIe sur le Campus de La Digital Factory. Des déplacements occasionnels pourront être nécessaires en France ou à l'étranger. Astreintes à prévoir Télétravail 3jrs/semaine","Air Liquide is seeking a Technical Lead for Global Data Operations (GDO) to define the technical roadmap for the Product Line, act as a reference for developers and data engineers, and work with product managers and business stakeholders to ensure the right technological response to evolving requirements. The position is based at the Digital Factory Campus in Paris and requires an extensive knowledge of Azure BI solutions and relevant certification, as well as excellent SQL and Dax mastery, project management experience, and strong communication skills in English and French.",Bac +5 / Master,> 2000 salariés,< 6 mois,0,3,0.04154662416233763
270,61466,https://www.welcometothejungle.com/fr/companies/linxea/jobs/data-engineer_paris,Data Engineer,Linxea,"{PostgreSQL,SQL,DataBricks}",Télétravail partiel possible,"58, Avenue Hoche, Paris, 75008","Banque, FinTech / InsurTech, Finance",CDI,2023-03-29,"Linxea, c’est le leader indépendant de l’épargne en ligne pour les particuliers et depuis plus de 20 ans nous œuvrons à ce que l’épargne soit toujours plus simple à placer et à gérer pour tous. Linxea est né de la conviction qu’une épargne idéale passe par une gamme de produits sécurisés, à bas frais, et un conseil adapté au profil de chacun. Au sein d’une équipe agile aux multiples compétences et de taille humaine, tu travailleras en tant que Data Engineer sur l’infrastructure Linxea. Ce que l’on attend de toi : Assurer le run et le monitoring de nos bases de données : Etre garant(e) de l’intégrité de la donnée et du bon fonctionnement des systèmes Etre force de proposition sur l’amélioration des requêtes en production Mise en place de l’alerting et du profiling des requêtes Porter la connaissance data auprès de l’ensemble des équipes de Linxea Participer au sprint sur les problématiques de modélisation des données et tests de performances Mettre à disposition et maintenir à jour les environnements de recette et production de données Anonymiser les données en fonction des environnements Faire évoluer le système actuel avec la construction d’un nouveau référentiel data Fiabiliser les sources de données Mettre à disposition la donnée à tous les services de Linxea Construire un datalake Intégrer des outils de data visualisation et d’analytique Tes compétences : Pré requis = la maîtrise SQL Server 2019 Capacité à évoluer vers d’autres systèmes de bases de données (PostgreSQL, DataBricks, …) 4 à 5 ans d’expérience avec une visibilité assez globale sur un projet data dans des environnements de PME, startup et/ou scaleup Mise en place d’alerting et de profiling des requêtes Maîtrise de la programmation SQL, T-SQL Orienté(e) résultat Esprit d’équipe, autonomie, pragmatisme et positivité ! Une visio/un appel téléphonique avec Anne-Charlotte, notre Talent Acquisition Manager Un entretien tech en visio avec Islem, l’un de nos Développeurs Un entretien tech avec Vincent, notre CTO Un entretien RH avec Anne-Charlotte et Laure, notre DRH, avant - on l’espère - une proposition finale !","Linxea is seeking a data engineer with 4-5 years of experience in managing databases and a strong command of SQL Server 2019, as well as proficiency in query optimization, data integrity, and data visualization tools. The role involves ensuring data accuracy and system efficiency, proposing improvements, and collaborating with Linxea's teams towards achieving the company's objectives. The ideal candidate should be a team player, results-oriented, self-sufficient, and pragmatic. An interview process includes a discussion with Linxea's Talent Acquisition Manager, a technical interview with a developer, and an HR interview with the HR Director.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
269,61606,https://www.welcometothejungle.com/fr/companies/ascor-communication/jobs/data-engineer-h-f_rennes,Data Engineer,Ascor Communication,"{Talend,SAP,Informatica,tableau,SQL,Qlik,Tableau}",Télétravail partiel possible,"31, Rue Guy Ropartz, Rennes, 35700",Formation,CDI,2023-03-29,"Ascor Communication est une entreprise familiale rennaise, en forte croissance, co-dirigée par un trinôme femmes/homme, parfaitement complémentaire. Ascor Communication est l’une des références française dans le secteur du digital learning. Première entreprise en France dans son secteur à être certifiée Qualiopi, Ascor Communication a un haut niveau d’exigence de la satisfaction client qui repose sur l’implication et l’adhésion de tous les salariés à cet objectif. Dans le cadre d’une création de poste et de la mise en place de notre entrepôt de données, nous recherchons un Data Engineer H/F. Rattaché au Directeur des Systèmes d’Information (DSI), vous aurez la responsabilité de ce projet. Vous aurez notamment pour missions de : Mettre en œuvre un projet Data/Business Intelligence ; Participer au recueil du besoin auprès des directions métiers ; Rédiger des spécifications fonctionnelles, applicatives, et techniques ; Collecter les données depuis diverses sources et les traiter dans un entrepôt de données ; Accompagner les services métiers dans l’élaboration de tableau de bord ; Préparer et dérouler les tests ; Accompagner dans la validation de livrables, l’assistance à la recette et la conduite du changement sur le projet ; Participer à la maintenance corrective et évolutive de l’entrepôt de données. De formation supérieure, vous justifiez d’une expérience de 5 ans. Vous maîtrisez les sujets de construction d’entrepôt de données et êtes capable d’en échanger avec des interlocuteurs métiers. Vous bénéficiez d’une expertise sur des outils ETL du marché (Informatica, Talend, Big Query, Data Factory, etc) et sur la création de tableau de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI…). SQL n’a plus de secrets pour vous. Votre esprit d’analyse et de synthèse sont souvent reconnus. Vous êtes autonome et organisé, et vous savez piloter des projets. Vous appréciez travailler en équipe, dans un contexte multi-projets. Nous vous proposons : Une formation interne de plusieurs jours (produits, outils, process…) et un accompagnement tout au long de la collaboration ; Un cadre de travail à taille humaine ; Une forte dynamique du fait de notre croissance ; Des bureaux desservis par les transports en commun ; 6 semaines de congés. Processus de recrutement : 1. Merci de nous faire parvenir un CV ainsi que quelques lignes de votre motivation pour ce poste ; 2. Vous recevrez un accusé de réception de votre candidature ; 3. Si votre candidature est retenue, un premier échange téléphonique sera réalisé ; 4. Si ce dernier est concluant il aboutira à second entretien.","Ascor Communication, a French digital learning reference, is seeking a Data Engineer to implement a Data/Business Intelligence project. The ideal candidate should have at least 5 years of experience with data warehouse construction, ETL tools, dashboard creation, SQL, and project management skills. The company offers an internal training, a small working environment, and six weeks of holiday per year. The recruitment process includes CV submission, a reception confirmation, two telephone interviews, and final approval.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
267,56755,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-azure-h-f_levallois-perret,Data Engineer / Azure,Micropole,"{Microsoft,durable,GCP,Databricks,Scala,SPARK,AWS,Synapse,R,Spark,Azure,Java,SQL,Python}",Télétravail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer /Azure Localité : Levallois-Perret Type de contrat : CDI Niveau d’expérience : au moins 2 ans Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services. Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus ! Vous accompagnez nosclients à travers toutes les étapes de leur transformation numérique dans unenvironnement Microsoft Azure : De la définition des axes stratégiquesd'adoption du cloud, du design, au déploiement des outils, à la migration desapplications et services. Vous aidez nos clients à gagner en performance,agilité, flexibilité du SI et à intégrer les Innovations les plus avancées. Dans vos missions quotidiennes , vous serez amené(e) à : Apporter votre expertise à nos clients pour garantir une valeur ajoutée rigoureuse et innovante Participer activement à la réalisation technique des projets de nos clients Accompagner et conseiller les clients sur les meilleures pratiques, les technologies et outils les plus adaptés au contexte. Réaliser des présentations, démonstrations, POC ou Pilotes pour mettre en lumière les recommandations technologiques. Être constamment en veille technologique Transférer des compétences spécifiques aux équipes techniques de nos clients Vous avez un minimum de 2 années d’expérience sur des projets Data dont au moins une sur des projets Cloud Microsoft Azure ou à défaut une certification Azure avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Solide ExpérienceTechnique Dans Les Domaines Suivants Azure Data Factory Azure Synapse Pipeline Spark/Scala pyspark Python SQL, PL-SQL Azure Databricks Les plus selon l’expérience Connaissancede Azure DevOps (Repos, Pipeline, Test) ou autres outils de gestion CI/CD Connaissancede la méthodologie Agile Scrum Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ; Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visio Etape 3 – Vous rencontrez un manager technique avec l’un de nos experts. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) LA VIE CHEZ MICROPOLE, C’est : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; Participation à des projets internes sur la base du volontariat. À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole #LI-DM1 Compétences Python SPARK Scala Azure/AWS/GCP Data Services PYSPARK","Micropole is seeking a Data Engineer with at least 2 years of experience on data projects, including at least one on Microsoft Azure cloud or an Azure certification. The candidate must have a solid technical background in Azure Data Factory, Azure Synapse Pipeline, Spark/Scala, Python, SQL, PL-SQL, and Azure Databricks. The successful candidate will be responsible for providing expertise to clients, participating in technical project implementation, advising clients on the best practices, creating demonstrations, and staying updated on technological developments.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
276,58083,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont_NATIX_o09wgpL,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"avenue de la liberté , Charenton-Le-Pont, 94018","Banque, Transformation, Assurance",CDI,2023-03-26,"Natixis fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France. Fort d’un portefeuille de marques comprenant notamment Natixis Investment Managers et Natixis Corporate and Investment Banking, Global Financial Services est composé de deux métiers – la gestion d’actifs et de fortune et la banque de grande clientèle. Avec plus de 12 000 collaborateurs dans 35 pays, nos experts accompagnent leurs clients, partout dans le monde, en leur proposant des solutions de financement et d’investissement innovantes et durables. Engagés en faveur de la transition environnementale, technologique et sociétale, ils se distinguent par un fort esprit entrepreneurial. Au sein de la direction CIO CIB Risks, dans le département Data Processing and Metrics, vous rejoignez l'équipe Metric Services P&L Explain qui est composée de 5 personnes. Dans cette équipe nous travaillons à calculer l'explication du P&L (profit and loss) par les sensibilités. Notre application est également partie prenante des calculs de Stress Tests et IPV (indépendance price validation). Nous intervenons donc sur plusieurs chaînes de valeurs, auprès de notre client : le département des risques de marché. Au quotidien vous avez pour missions de : Contribuer aux spécifications techniques et fonctionnelles ; Intervenir de la phase de concéption aux tests : développement de nouvelles fonctionnalités, revue de code, documentation, ... ; Travailler sur des problématiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et améliorer la software factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 pour avoir une production ponctuelle, de qualité et maîtrisée. Nos principaux interlocuteurs sont : le département des risques de marché (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk) et les équipes support et production à Porto. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Vous travaillez dans un environnement international, au sein d'une communauté d'experts qui place l'excellence, l'impact et l'action collective au cœur de tout ce qu'elle entreprend. Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en finance et/ou en informatique avec une spécialisation en big data, vous avez une expérience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous maîtrisez : * La finance de marché, et plus précisément le marché des risques et PNL (méthode d'explication du PNL) ; * Les spécifications des besoins de l'équipe et vous êtes capable de proposer des maquettes aux utilisateurs en autonomie. Vous êtes : * Pédagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des améliorations continues. Vous maîtrisez l'anglais avec un niveau B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis, a leading financial services company, is seeking a Data Engineer with at least 2 years of experience in Hadoop, Spark, and Scala. The role involves contributing to technical and functional specifications, developing new functionalities, optimizing performance, and maintaining software and development environments. The successful candidate must have a background in finance and/or computer science with expertise in finance market and PNL explanation, and possess pedagogical, autonomous, and improvement-oriented skills. The position is based in Charenton-le-Pont, France with 10 days of telework per month and a comprehensive benefits package.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
265,56955,https://www.welcometothejungle.com/fr/companies/cenova/jobs/data-engineer-retail-h-f_marcq-en-baroeul,Data Engineer | Retail –,Cenova,"{PowerBI,Kafka,GCS,BigQuery,GCP,SQL,Github}",Télétravail partiel possible,"869 Avenue de la République, Marcq-En-Baroeul, 59700",IT / Digital,CDI,2023-03-26,"Cabinet à forte croissance, Cenova accompagne ses clients du #Luxe, du #Retail et du #Tourisme/Loisirs dans leurs projets de transformation digitale et data. Présent à Paris et Lille, Cenova c’est avant tout un cabinet à taille humaine avec : ✅ Un respect de vos attentes concernant vos missions et une réelle proximité managériale pour vous accompagner, ✅ La CenoLife pour vous apporter une vie de cabinet stimulante (afterworks, séminaires, évènements sportifs…), ✅ La CenoAcademy pour vous former et nos CenoTalk pour partager nos expertises et connaissances, ✅ De multiples avantages en complément d’une rémunération attractive : la mutuelle Alan, un CSE, des titres restaurants - Swile, des primes vacances, le télétravail et plein d’autres jolis avantages… Ces quelques mots suscitent votre curiosité ? Candidatez ! Votre personnalité et votre savoir-faire feront le reste. Notre processus se déroule en 3 entretiens : RH, Manager et rencontre avec un associé ! Vous travaillerez chez l’un de nos clients, spécialiste du retail, au sein de l’équipe Data sur le développement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes : • Participer aux rituels agiles de l’équipe, • Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de l’entreprise, • Développer les solutions data (Alimentation, stockage, modélisation, restitution), • Valider la qualité des développements de votre équipe, • Améliorer et optimiser le patrimoine actuel de votre équipe, • Maintenir les solutions existantes (Run), • Contribuer à la construction du nouveau socle et des services sur GCP (Google Cloud Platform), • Accompagner les métiers sur les bonnes pratiques de l’exploitation de la Data. Cela fait au moins 2 ans que vous travaillez sur des missions de Data Engineer et vous disposez d’une grande appétence technique. Vous appréciez comprendre le cycle de vie de la donnée et vous êtes à l’aise avec les concepts de data lineage, data gouvernance, data privacy. Vous êtes amateur.e de datavisualisation, idéalement avec PowerBI. Travailler en mode agile ? Vous adorez ! Bien évidemment, vous avez le contact facile et vous comprenez les enjeux Business et adaptez vos analyses en ce sens. Vous êtes proactif(ve), autonome, bon(ne) communiquant(e), fluent in english et à l’aise dans un environnement matriciel et challengeant. Environnement technique : SQL, ETL Power BI, Data Studio CI/CD, Github, Terraform, Kafka Google Cloud Platform (GCS, BigQuery) 3 entretiens! C’est rapide et efficace! Le 1er avec l’équipe RH, le 2d avec un manager et le 3ème avec l’un de nos associés.","Cenova, a growing company serving clients in luxury, retail, and tourism sectors in their digital and data transformation projects, seeks a data engineer with at least two years of experience. The ideal candidate must possess technical expertise in data lineage, governance, and privacy, have excellent communication skills, and be comfortable working in an agile environment. Fluency in English is essential, as is familiarity with SQL and ETL, Power BI, Data Studio, CI/CD, GitHub, Terraform, Kafka, and Google Cloud Platform.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
278,56699,https://www.welcometothejungle.com/fr/companies/devoteam-creative-tech/jobs/creative-tech-fimakers-data-engineer-f-h_levallois-perret,Creative Tech - FIMAKERS - Data engineer,Devoteam Creative Tech,"{GCP,Microsoft,Azure,Scala,DataStudio,Looker,TensorFlow,AWS,QlikView,R,Keras,Python,Tableau}",Télétravail partiel possible,"73 Rue Anatole France, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"La tribu Tech, est l’équipe experte en technologie de Devoteam Creative Tech. Au sein d’un collectif de 800 professionnels experts du digital, ils imaginent et concrétisent des produits & services performants dans la durée aux côtés de designers, product owners/managers et d’experts data. Leur engagement ? Agir positivement sur la transformation de la culture et de l’organisation de leurs clients par la transmission de leurs savoir faire. L’agilité et les bonnes pratiques de développement sont au cœur de leur ADN, qu’ils interviennent au sein des équipes de leurs clients ou en feature teams depuis leur studio parisien. Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé. Intégré(e) à une équipe d’experts techniques, tu auras pour missions de : Analyser les besoins clients Animer des ateliers afin d’étudier et cadrer les besoins clients Préconiser les solutions et architectures cibles Définir les méthodologies de déploiement et plans de migration Rédiger les dossiers d’architecture et spécifications techniques Construire les architectures de données Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels) Construire et déployer les pipelines de données (ETL) Assurer la migration des données vers les nouveaux environnements Analyser les données Analyser les données sources afin d’identifier et évaluer des cas d’usage métier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…) Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les équipes clients aux méthodes et concepts du cloud Tu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice. Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données. Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python). Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyse Tu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine Learning Une connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus. Tu as une solide compréhension de la dimension technique et fonctionnelle des projets IT Curieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyse Ta maîtrise de l'anglais te permettra de gérer des projets en contexte international","The La Tribu Tech team at Devoteam Creative Tech is seeking a Data Engineer to assist clients with digital transformation through the implementation of data projects with Google Cloud Platform and associated open source solutions. The ideal candidate should have experience in data architecture, as well as knowledge of programming languages like Scala, Python, or R. Additionally, proficiency in cloud provider data tools and a strong understanding of IT project technical and functional dimensions are preferred.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
281,56466,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret,Data Engineer / GCP,Micropole,"{Microsoft,durable,Scala,AWS,R,Spark,GCP,Java,Python}",Télétravail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer / GCP Localité : Levallois-Perret Type de contrat : CDI Niveau d’expérience : au moins 2 ans Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services. Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus ! Au sein de notre agence basée à levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer GCP (F/H) , vousaccompagnerez les directions métiers dans l'évaluation de l'efficacité de leurprocessus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP. Vos compétences techniques : Vous avez un minimum de 2 années d’expérience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou à défaut une certification GCP avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ; Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visio Etape 3 – Vous rencontrez un manager technique avec l’un de nos experts. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) LA VIE CHEZ MICROPOLE, C’est : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; Participation à des projets internes sur la base du volontariat. #LI-DM1 Compétences GCP","Micropole is seeking a Data Engineer, with a minimum of 2 years of experience on Cloud GCP, to develop and maintain customer use cases, model and analyze data in the cloud, and ensure data security/compliance. The successful candidate should have programming skills, knowledge of data modeling tools and industrialization, and be passionate, rigorous, curious, and able to work as part of a team. Micropole offers opportunities for personal and professional development, as well as a dynamic internal life with regular knowledge-sharing events and the opportunity to participate in internal projects.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
285,56660,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_paris,DATA ENGINEER,ACTINVISION,"{Microsoft,MySQL,GCP,Talend,Matillion,AWS,Snowflake,Alteryx,Azure,Java,SQL,Python,Tableau}",Télétravail partiel possible,"64-66 Rue des Archives, Paris, 75003","Intelligence artificielle / Machine Learning, Transformation, Big Data",CDI,2023-03-26,"Fondée en 2014, Actinvision est un regroupement de Data Heroes accompagnant différents acteurs dans leur transformation vers une culture data. Créant un lien de confiance avec ses clients, elle donne à ces derniers les moyens d’analyser leurs innombrables données. Mêlant expertise technique de haut niveau et créativité sans limites, elle développe des approches personnalisées destinées à valoriser les données de l’organisation. Actinvision, c’est aujourd’hui plus de 300 clients en France et à l’international dans divers secteurs, allant de l’industrie à la grande distribution en passant par le secteur financier. Son fief se trouve dans la région Grand Est et plus précisément en Alsace, à Strasbourg. C’est de là qu’est dirigé l’ensemble des opérations, notamment mené à travers un second bureau, positionné à Paris. Actinvision est, en interne, une communauté multiculturelle “fun” orientée autour de la data et, en externe, un partenaire reconnu et privilégié par de nombreuses entreprises leaders du marché : Tableau, Alteryx, Snowflake, Microsoft, Talend, etc. Entreprise accréditée “Happy at Work” par ChooseMyCompany Vous serez amené(e) à travailler sur différents projets innovants , pour des clients de toute taille , dans des secteurs divers et variés tels que l’agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l’énergie, l’industrie, la pharma/chimie ou encore la santé. En tant que Data Engineer passionné(e), vous aiderez nos clients à relever les challenges d’aujourd’hui et de demain en intégrant leurs données au sein d’infrastructures, On-Premise et Cloud. A la suite d’une période d’intégration destinée à vous familiariser avec la méthodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l’analyse du besoin client à la livraison de la solution technique en passant par le chiffrage et les développements. Vous évoluerez en équipe mais également de manière autonome dans un environnement technique porteur d’innovations incluant par exemple la modélisation et la construction d’entrepôts de données (Data Warehouses), le design de flux d’intégration au moyen d’outils (e.g. Talend ou ADF, Matillion etc. ) permettant l’alimentation de ces derniers, ou encore la mise en place et l’optimisation dans le respect des bonnes pratiques d’architectures Data, notamment Cloud (e.g. Snowflake ou Azure). Le développement des compétences est un aspect primordial. Ce développement continu est appuyé par les ressources officielles mises à disposition par l’ensemble des éditeurs partenaire d’Actinvision et complété par des ressources internes. Les compétences acquises pourront être valorisées aux travers de certifications éditeurs hautement qualifiantes. MISSIONS PRINCIPALES : • Participer en équipe ou de façon autonome à la mise en œuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intégration et stockage de la donnée • Recueil du besoin client technico-fonctionnel permettant la mise en place d’ architectures pour la collecte et l’extraction de données depuis diverses sources (bases de données Cloud, applications métier, API, etc.), la manipulation et la transformation de ces données, puis le chargement de ses dernières au sein de base de données de type Data Warehouses (DWH) • Design des infrastructures/architectures Data et modélisation des DWH cibles, lesquels seront principalement utilisés dans le cadre d’opérations de Reporting et/ou de Data Visualisation • Réalisation de flux d’intégration et transformation de donnée De formation Bac+5 en informatique, vous disposez de minimum 1 an d’expérience sur un poste similaire. Savoir-faire, compétences techniques requises : • Langage SQL et modélisation DWH • Pratique d’un outil d’intégration ETL / ELT • Connaissances en bases de données relationnelles (e.g. SQL Server ou MySQL) • Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP) • Connaissances de la chaîne de valeur de la Data, et particulièrement de la BI Savoir-faire, compétences techniques appréciées : • Connaissances en architectures Cloud (sécurité, performances, maîtrise des coûts, etc.) • Programmation procédurale, e.g. T-SQL ou PL/SQL • Un langage de programmation orienté objet, e.g. Java ou Python • A l’aise avec l’utilisation d’API / de Web Services • Notions sur l’ESB Savoir-être, compétences fonctionnelles : • Passion pour la Data • Autonomie / Travail et esprit d’équipe (incluant le partage des connaissances) • Force de proposition / Capacité à rechercher et trouver des solutions • Créativité et curiosité • Dynamisme et réactivité • Sens du service • Capacité à participer à l’animation de la communauté (interne et externe) • Anglais technique • Pour un poste confirmé : Expérience probante dans les domaines du DWH et de l’intégration de données (cloud et/ou on-prem) Moyenne de temps du process de recrutement chez Actinvision : 15 jours Pré qualification téléphonique : 15 à 20 minutes Entretien technique : 1h00 Entretien RH : 1h00","Actinvision, a Data Heroes group, seeks a passionate Data Engineer with at least one year of experience to help clients integrate their data into On-Premise and Cloud infrastructures. The role involves working on innovative projects across various sectors, participating in all project phases, and designing data architecture and models. Required skills include SQL, DWH modeling, ETL/ELT tools, and Cloud Data platforms. Knowledge of BI and familiarity with Cloud architectures, procedural programming, Web Services, and ESB is desirable. The position requires autonomy, teamwork, creativity, and a service-oriented mindset.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,2,1,0.04154662416233763
304,57109,https://www.welcometothejungle.com/fr/companies/learning_planet_institute/jobs/data-engineer_paris,Data Engineer,Learning Planet Institute,"{Microsoft,Azure,Grafana,PostgreSQL,Airflow,Kubernetes,Docker,via,R,Spark,Git,NoSQL,SQL,Python,Bash}",Télétravail partiel possible,"Rue Charles V, Paris, 75004",Association,CDI,2023-03-26,"Depuis 2006, en s’appuyant sur l’intelligence collective, l’association Learning Planet Institute réinvente l’apprentissage à tous les âges de la vie afin de construire des sociétés apprenantes, durables et inclusives, aptes à relever les défis complexes auxquels nous sommes confrontés. L’Institut a pour mission d’explorer, d’expérimenter et de partager des nouvelles manières d’apprendre et de coopérer afin de répondre aux besoins de la jeunesse et de la planète. Il encourage et essaime une culture, des méthodes et des outils d’empowerment pour transformer les organisations. Enfin, il anime des communautés et accompagne des « Learning Planetizens » à prendre soin d’eux, des autres et de la planète. Pour atteindre ses objectifs, le Learning Planet Institute crée des programmes de recherche et d’enseignement basés sur l’interdisciplinarité, la diversité et l’initiative. Il s’appuie sur les synergies entre ses activités : R&D (chercher), Éducation (former), Alliance internationale (fédérer), Transformation des organisations (transformer) et Écosystèmes numériques (outiller). Conçu et développé au Learning Planet Institute, WeLearn est une plateforme numérique de navigation au sein des ressources d’apprentissage. Elle est propulsée par des algorithmes à l’état de l’art de Intelligence Artificielle. À partir d’un texte fourni par l’utilisateur, WeLearn recommande des ressources pertinentes de grande qualité lui permettant de découvrir des informations, d’acquérir des connaissances et d’identifier des experts. Le Learning Planet Institute travaille actuellement avec des organisations partenaires pour adapter WeLearn à leurs utilisateurs et à leurs ressources spécifiques et recrute , dans ce cadre, un Product manager pour renforcer l’équipe. Sous la responsabilité du Directeur R&D, vous aurez ainsi pour missions: Concevoir/améliorer l’architecture technique autour de services de Machine Learning (système de recommandation) Concevoir/améliorer les pipelines en alimentant ces services Préparer le passage à l’échelle de ces services Maîtrise des outils “classiques” : Python, SQL, Bash et Git Expérience des bases de données relationnelles (PostgreSQL) Expérience des technologies Big Data, comme les bases de données NoSQL et le traitement distribué via Spark Expérience d’une plateforme cloud, de préférence Microsoft Azure Expérience des outils de gestion des flux de données (Airflow) Expérience avec les mécaniques de travail et les outils liées à la CI/CD (Airflow Connaissances des outils Ops (Docker, Kubernetes, Grafana…) Connaissances en Machine Learning Excellence opérationnelle et sens du détail Nous nous engageons à effectuer des recrutements aussi inclusifs que possible. Nous nous basons donc uniquement sur votre personnalité et vos compétences pour la sélection. Ce recrutement est assuré par notre partenaire The Allyance, cabinet de recrutement. Vous pouvez également envoyer votre candidature à l’adresse mail suivante : morgane@theallyance.one","The Learning Planet Institute is seeking a Product Manager to strengthen its team's adaptation of WeLearn, a digital learning resources platform, to partner organizations. The role includes improved architecture and pipelines for Machine Learning services, and proficiency in Python, SQL, Bash, Git, PostgreSQL, Airflow, CI/CD, and Docker/Kubernetes necessary. The ideal candidate also possesses knowledge of Ops tools and Machine Learning. Furthermore, the Learning Planet Institute is committed to inclusive hiring based on personality and skills alone.",N,N,N,2,1,0.04154662416233763
264,57156,https://www.welcometothejungle.com/fr/companies/stoik/jobs/senior-software-engineer_paris,Data Engineer,Stoïk,"{Metabase,SQL,python,AWS}",Télétravail partiel possible,"4 Rue Euler, Paris, 75008","FinTech / InsurTech, SaaS / Cloud Services, Cybersécurité",CDI,2023-03-26,"Stoïk est la première insurtech spécialisée sur le risque cyber en Europe. Notre mission est de protéger les PME des cyberattaques en associant une couverture d’assurance avec des outils de monitoring du risque dans un seul et même produit simple, digital, et distribué principalement à travers notre réseau de courtiers partenaires. En quelques mois, nous avons construit une équipe de près de 30 talents, créé et lancé notre produit sur le marché français, fait signer plus d’une centaine de clients et levé quelques millions d’euros avec les meilleurs fonds d’investissement de la planète. À l’origine de Stoïk, un étonnement : comment les petites entreprises peuvent-elles rester si vulnérables face à une menace aussi dévastatrice que les cyberattaques ? Aujourd’hui, les dirigeants de TPE et PME ont conscience de ce risque. Mais la plupart manque de connaissances techniques et de ressources financières pour s’en prémunir convenablement. Stoïk offre la possibilité aux entreprises de réduire fortement leur risque grâce à un ensemble de bonnes pratiques. Et comme le risque zéro n’existe pas, nous les assurons ! Nous avons levé près de 15 millions d’euros avec certains des meilleurs investisseurs au monde (Andreessen Horowitz, Alven & Anthemis) et d’incroyables Business Angels (CEO de wefox, Luko, Dashlane, KKR, etc.), et nous avançons rapidement pour devenir les leaders européens sur le marché en plein essor de la cyber-assurance. Trouver des solutions simples a des problèmes complexes / capacité à expliquer et convaincre. Comprendre le risque cyber. Vous travaillerez en étroite collaboration avec nos experts cyber et backend pour identifier, collecter et synthétiser les données utiles, obtenues ou non à travers nos outils, pour la quantification du risque cyber. Le but final est de comprendre finement l’exposition d’une entreprise donnée afin de l’aider à améliorer sa posture de sécurité. Structurer l’entreprise. Vous travaillerez au maintien et à l’amélioration de nos pipelines, de notre data lake et de nos dashboards. Faire partie d’une équipe. Nous avons l’ambition de croître rapidement. Chacun chez Stoïk y participera, notamment en recrutant des personnes, en améliorant nos processus et en nous aidant à nous développer en tant qu’entreprise. Must-haves Maitrise avancée de python (notamment web scrapping) et de SQL Expérience en stockage de données et pipelines ETL Expérience en architecture de données dans le cloud (AWS idéalement) Appétence pour la cybersécurité Nice to have Compétence en cybersécurité (OSCP, expériences passées, etc) Expérience sur Metabase Notre offre Un projet ambitieux. Une équipe hautement qualifiée avec laquelle travailler au quotidien. La propriété, la liberté et l’autonomie. Un package attractif et des BSPCEs. Un lieu de travail agréable dans le centre de Paris. Le télétravail partiel est possible. Nous avons besoin de vous dès que possible. Screening (30 min) Test techniques (chez vous) Rencontre de l’équipe (2h)","Stoïk, Europe's first insurtech specializing in cyber risk, seeks a cybersecurity data analyst to work closely with their expert cyber and backend teams to collect and synthesize critical data. The ideal candidate must have advanced proficiency in Python (particularly web scraping) and SQL, experience in data storage and ETL pipelines, and proficiency in cloud data architecture (preferably AWS). Additional cybersecurity competency and experience with Metabase are desirable. Stoïk offers a highly skilled team, autonomy, an attractive package, partial telecommuting, and an ambitious project.",Bac +3,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
286,56677,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-f-h_nantes,Data Engineer GCP,Micropole,"{Microsoft,durable,Azure,Scala,AWS,R,Spark,GCP,Java,Python}",Télétravail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. Comme nous vous êtes convaincu(e) que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez aider les entreprises à devenir plus agiles, et à améliorer leur niveau de performance grâce à la puissance du Cloud ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer au travers des nouvelles technologies qu’amène le cloud ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data, cloud et digitales ? Si vous avez répondu « Oui » à chacune de ces questions et êtes prêt(e) à rejoindre l’aventure Micropole en tant que Data Engineer GCP (F/H). N'attendez plus ! devenez un(e) innovativePeople pour l’un de nos clients grands-comptes. Micropole accompagne les entreprises à devenir “Data-centric” grâce à la puissance du Cloud. Forte de consultants, d’experts techniques et d’architectes spécialisés dans les solutions AWS, Azure et GCP, Micropole aide les entreprises à devenir plus agiles, et à améliorer leur niveau de performance. En tant que Data Engineer GCP (F/H): Au sein de notre agence basée à Nantes, vous rejoindrez nos experts Cloud & DevOps. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP. Vos compétences techniques : Vous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou à défaut une certification GCP avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts : Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud GCP et des solutions Data. DEVENIR #INNOVATIVEPEOPLE, C'EST : Intégrer une communauté de 1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine ; Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale ; Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft Azure, Salesforce, GCP ; Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. PROCESSUS DE RECRUTEMENT: Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – Si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Céline notre Talent Specialist ; Etape 2 - Un premier entretien est programmé avec Céline en physique ou visio ; Etape 3 – Un Codin’Game vous sera envoyé à la fin de votre entretien ; Etape 4 – Vous rencontrez nos managers et porteurs d’offres Samuel et Stéphanie. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien ou test technique). LA VIE CHEZ MICROPOLE, C'EST: Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique ; Un travail en équipe valorisé pour une meilleure cohésion ; La participation à des projets internes sur la base du volontariat. À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, Data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un développement rapide sur le Data, le Digital et Cloud, les équipes portent l’ensemble de la proposition de valeur du Groupe. Présent au plus près de l’écosystème de partenaires, de réseaux professionnels et d’acteurs du développement économique, nous accompagnons nos clients des secteurs de l’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et du public dans leur transformation data et digitale, notamment au travers de méthodologies innovantes comme le Datathinking® ou Lego Serious Play®. L’agence Grand Ouest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit et met en place des méthodes, compétences et expertises pour le développement d’un numérique responsable au sein des organisations. Pour en savoir plus : https://www.linkedin.com/company/micropole/ #LI-CB1","Micropole is seeking a data engineer with a minimum of three years' experience in data projects, including at least one project on GCP, or a GCP certification. The ideal candidate should be skilled in developing and maintaining client use cases with big data/cloud GCP infrastructure and be knowledgeable in modelling and analysing data in the cloud. Good problem-solving skills and the ability to identify the most relevant data sources are also required, as is an ability to provide concise and visual results. The role includes the responsibility for ensuring the security and compliance of data.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
287,56822,https://www.welcometothejungle.com/fr/companies/klanik/jobs/ingenieur-big-data-h-f_lyon,Ingénieur Big Data 💻,KLANIK,"{python,Jenkins,PostgreSQL,via,R,Teradata,Hadoop,Git,NoSQL,SQL,Python}",Télétravail partiel possible,Lyon,"Logiciels, IT / Digital, Formation",CDI,2023-03-26,"KLANIK est une société de conseil en Ingénierie IT qui accompagne ses clients dans leurs projets digitaux et technologiques. Le groupe KLANIK compte désormais plus de 750 talents, évoluant dans 16 agences en Europe, Amérique du Nord, Afrique et Moyen-Orient. Des experts engagés, atypiques et passionnés, impliqués dans des projets stratégiques grâce à leur haut niveau de compétences en Software, DevOps, Cloud, Agilité, Cybersécurité, Big Data & IA. En parallèle de leurs métiers, les collaborateurs du groupe KLANIK sont accompagnés au quotidien dans leur développement personnel et professionnel, via différentes initiatives engageantes et innovantes : KONSCIOUS : communauté interne engagée dans les enjeux écologiques, sociaux et environnementaux KAMPUS : institut de formation technique certifié KORNER : incubateur de start-ups technologiques KLANIK ESPORT : club professionnel e-sport ouvert aux collaborateurs Klanik recrute pour l’un de ses grands partenaires du secteur de l’Energie, un Ingénieur Big Data (H/F) sur Lyon. Vos missions tournent autour de 4 axes : o Apporter une expertise en Big Data pour faciliter la manipulation des données o Définir les solutions techniques permettant le traitement massif de données o Mettre en place des solutions de stockage de données (SQL, NoSQL, etc.) o Veiller la sécurisation et la clarté des pipelines de données pour faciliter l’analyse et la transformation Si nécessaire, vous pouvez vous appuyer sur les référents techniques des diverses briques si ces dernières sortent du cadre de votre mission. Activité principale : A ce titre, vous serez amené(e) à assurer les activités suivantes : • Participation à des ateliers avec des experts métiers pour collecter le besoin et comprendre les données • Conception et développement de traitements de données, • Réalisation d’études statistiques • Présentation de résultats sous la forme de rapports d’étude ou de tableaux de bord • Développement d’outils de visualisation de données pour faciliter les analyses • Documentation des traitements en vue d’une industrialisation • Participation aux cérémonies agiles de l’équipe • Diffusion et vulgarisation des résultats d’étude Activité secondaire : o Veille technologique sur les outils utilisés au sein du projet o Partage et formation sur les guides de bonnes conduites Stack technique du projet : L’environnement technique du projet est le suivant : • Python • R • PostgreSQL • Teradata • Hadoop • Jenkins • Ansible • Jira / Confluence / Bitbucket • Git Forte compétence python avec connaissance de R. Bonne qualité en développement logiciel. Compétence de data science (stat / machine learning / programmation). 4 - 5 ans d’expérience.","Klanik, an IT engineering consultancy, is seeking to hire a Big Data Engineer with expertise in Python, R, PostgreSQL, Teradata, Hadoop, Jenkins, Ansible, Jira/Confluence/Bitbucket, and Git, and a strong software development background. The ideal candidate should have 4-5 years of experience in data science, statistics, machine learning, and data programming. The job responsibilities include participating in workshops with subject matter experts to collect information, designing and developing data processing, conducting statistical studies, and creating data visualization tools.",Non spécifié,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
288,56852,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_5waAL8r,Data Engineer,EXTIA,"{GCP,git,Jenkins,Git}",Télétravail partiel possible,Paris,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-03-26,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. DESCRIPTION DU POSTE • Analyse et Conception de l’architecture • Industrialisation et automatisation des déploiements • Expertise sur le déploiement de la solution • Expérience du développement logiciel agile avec multiples contributeurs ( git, code review, CI/CD ) • Expérience du cloud, idéalement GCP PROFIL RECHERCHÉ • Niveau Bac+5, vous justifiez au minimum d’une première d’expérience significative en tant que Data Engineer d'au moins 2 ans • Bonne connaissance des outils et pratiques DEVOPS : Industrialisation de l’intégration et du déploiement de la solution : Git/Jenkins/Artifactory/Ansible • Application des méthodes Agile : Scrum et Kanban : JIRA/Confluence #LI-PRZ Curieux(se) , vous adorez partager les dernières idées innovantes que vous avez découvertes, Analytique , vous avez une âme d’enquêteur et les énigmes n’ont aucun secret pour vous , Proactif(ve) , vous aimez les projets qui avancent vite et bien.","Extia, a specialized consulting company in IT, digital, and engineering, is seeking a Data Engineer with at least 2 years of experience. The ideal candidate should have expertise in agile software development, cloud platforms (preferably GCP), and practice in DevOps tools such as Git, Jenkins, Artifactory, and Ansible. Candidates should have good knowledge of agile methodologies (Scrum and Kanban) and the ability to analyze and design architecture, automate deployments, and deploy solutions. A curious, analytical, and proactive approach is preferred.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
263,57001,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris,Data engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,Spark,GCP,Java,Hadoop,Python}",Télétravail partiel possible,Paris,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-03-26,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse… Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes. Vous serez en charge de : ● Participer à la définition des besoins et à la rédaction des User Stories, ● Collaborer avec les Data Scientists au développement des modules d’analyse de donnée, ● Concevoir et construire des architectures de données, ● Intégrer des sources de données, ● Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives, ● Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux #LI-GG1 ● Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple, ● Vous maitrisez les bases de l’analyse statistique, ● Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, ● Vous maitrisez Spark et Hadoop ● Vous êtes familiarisé avec l’environnement Linux, ● Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.","The role involves providing technical support to analysis teams by structuring data, conducting statistical and technical data analysis, developing analysis tools, and evaluating new technologies in Big Data, Data Mining, and Machine Learning. The ideal candidate should have expertise in ETL, data mining, machine learning, big data, graph theory, statistical analysis, and scripting languages like Python and/or R, as well as experience with Spark, Hadoop, Linux, cloud infrastructure, and real-time streaming tools.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
259,56910,https://www.welcometothejungle.com/fr/companies/neolynk/jobs/data-engineer-h-f_paris,Data Engineer 3 ans d'expériences,NeoLynk,"{Python,SQL,Spark,AWS}",Télétravail partiel possible,"91 rue du faubourg saint honore, Paris, 75008",IT / Digital,CDI,2023-03-26,"Une manière innovante de répondre aux challenges digitaux de nos clients, une manière différente de valoriser nos consultants. Depuis plus de 6 ans, NeoLynk évolue dans le domaine de l’Open Source, passionnément ! Au travers de notre Tribu JVM et de nos projets innovants, nous conduisons nos consultants vers une maturité technologique toujours plus forte ! Passionné(e) par le Big Data ? Intègre notre Tribu et participe à son évolution, le tout en contribuant à des projets clients challengeants au sein d’équipes expérimentées ! Quelques clients : Rakuten, Société Générale, Saint Gobain, Kering … Vous évoluez au quotidien au sein de la tribe transverse Data Tools and Services, constituée de 7 pôles : Data Science, Data Engineering, BI/DATAVIZ, Data Analysis, Product Analysis, Data Quality, Data discovery. Vous aurez le soutien de l’entreprise qui a une ambition de révolutionner l’usage et le business model grâce aux nouvelles technologies. Vous travaillerez conjointement avec l’équipe Data Science et l’équipe data engineering. Vos missions: Vous travaillerez sous la responsabilité conjointe des deux managers Data Engineer & Data Science. Vous participerez à la mise en place d’un important chantier data au sein du client “la Data Plateform (DP)” qui permettra la centralisation, la creation et la mise à disposition de segments d’utilisateurs. Cette DP permettra d’alimenter différents use cases produit du client (Pub, CRM,Premium, Service Client, …). Vous serez en charge d’apporter votre expertise et votre support sur 3 principaux composants de cette DP :  La librairie de création de segment existante : qui permet l’intégration et la gestion des tables de référencement et d’archivage de segments. Des modifications seront apportées à cette librairie pour s’adapter à la DP  La table de référencement des segments : Changement de la table permettant de répertorier les segments disponibles dans la DP.  Les notebooks permettant de créer les segments existants : o Refactoring de ces notebooks en tenant compte des nouveaux changements de la librairie et des nouvelles bases de données (Xiti) • Vous justifiez d’une expérience d’au moins 3 ans dans le domaine de la data • Une expérience dans des environnements cloud avec des connaissances en Spark et AWS est très souhaitée. • Une bonne maitrise du langage Python et du SQL. • Capacité de synthèse, de vulgarisation de communication. • Être force de proposition. • Sens du partage et esprit d’équipe. • Prise d’initiative. Entretien téléphonique Test technique Entretien physique","NeoLynk is seeking a passionate Big Data specialist with at least 3 years of experience in data management, cloud environments, Spark and AWS, Python, and SQL. The candidate will work on a data development project for a client's Data Platform, collaborating with Data Science, data engineering teams, and contributing to changing libraries, referencing tables, and creating existing segments. The ideal candidate is a team player, proactive, with excellent communication skills, and willing to learn and grow.",Bac +5 / Master,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
256,56414,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_lyon,Data engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,GCP,Java,Python}",Télétravail partiel possible,"129 rue Servient, Lyon, 69003","Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-03-26,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Ensuite quoi Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse… Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes. Vous serez en charge de : Participer à la définition des besoins et à la rédaction des User Stories, Collaborer avec les Data Scientists au développement des modules d’analyse de donnée, Concevoir et construire des architectures de données, Intégrer des sources de données, Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives, Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux. Profil : Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple, Vous maitrisez les bases de l’analyse statistique, Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous êtes familiarisé avec l’environnement Linux, Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts. #LI-YKH Curieux , vous adorez partager les dernières idées innovantes que vous avez découvertes, Analytique , vous avez une âme d’enquêteur et les énigmes n’ont aucun secret pour vous , Proactif , vous aimez les projets qui avancent vite et bien.","Extia, a consulting firm specialized in IT, digital, and engineering, is seeking a Technical Support Analyst with expertise in ETL, data mining, machine learning, big data, and graph theory, and familiarity with statistical analysis and Python or R scripting. Experience with Linux, large file storage tools, AWS or GCP cloud infrastructure, and real-time streaming is also valued. The ideal candidate will be curious, analytical, and proactive.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
298,56959,https://www.welcometothejungle.com/fr/companies/energisme/jobs/data-integration-engineer-etl-iot_boulogne-billancourt,Data Integration Engineer (ETL/IOT),Energisme,"{NIFI,via,SQL}",Télétravail partiel possible,"88 Avenue du Général Leclerc, Boulogne-Billancourt, 92100","Logiciels, Big Data, Energie",CDI,2023-03-26,"Nous développons une solution logicielle SaaS visant à accélérer la performance énergétique des entreprises (prestataires de services à l’énergie, fournisseurs et distributeurs d’énergie, industriels et gestionnaires de patrimoines immobiliers) grâce à l’intelligence des données, ainsi qu’une plateforme PaaS dédiée au traitement en temps réel des données massives et hétérogènes. Forts des atouts technologiques et opérationnels décisifs de notre plateforme, nous comptons plus de 170 clients grands comptes. Au sein de l’équipe Data Acquisition, constituée de 3 personnes, tu auras la charge de la conception et du développement des connecteurs d’acquisition des données de nos clients. Orienté(e) sur les données de consommation énergétique avec des volumétries type Big Data, tu travailleras via une solution low code (Apache NIFI) sur des flux de données de type IOT, API, fichiers plats… Tes missions Spécification & conception des flux de données (30%) Comprendre les besoins d’intégration des flux Accompagner nos chefs de projet dans la spécification des besoins de flux de données client Les orienter sur les informations à récupérer chez les clients Leur présenter les choix possibles d’implémentation Les accompagner, si besoin, en réunion client Prioriser avec eux les différents besoins Développement des flux (50%) Création et paramétrage de flux sur la solution Apache NIFI Développement de script en Groovy ou JS Interrogation de bases de données (SQL) Appels d’API REST/SOAP Manipulation de données (JSON, XML, CSV, …) Code Review Communication sur l’avancée des développements Validation & déploiement (20%) Test de chaque flux développé Documentation Mise à disposition d’un environnement de test au Chef de projet pour validation Mise à disposition de jeux de données Exécution du flux Déploiement et maintenance des flux en production Tu possèdes une expérience dans le domaine des ETL et de l’acquisition de donnée. Tu es issu(e) d’une formation Bac + 4/5, Diplôme d’ingénieur ou équivalent en informatique. Tu es sensibilisé(e) aux environnements Big Data & IOT et as un intérêt pour le marché de l’énergie. Rémunération selon profil. Tu hésites encore ? Travailler chez Energisme c’est également : Rejoindre un collectif engagé, avec un véritable esprit d’équipe Une ambiance jeune et dynamique, des afterworks réguliers Une mutuelle avantageuse prise en charge à 100% par l’employeur 13 jours de RTT par an et un compte épargne-temps Une réelle flexibilité d’organisation grâce au télétravail Si le poste t’intéresse et que tu recherches une entreprise à fort impact sur la transition énergétique qui a à cœur d’accompagner ses clients dans la réduction de leur impact environnemental, nous attendons ta candidature ! 1 entretien téléphonique (environ 45 min) 1 entretien avec étude de cas (environ 2h)","Energisme is seeking a Data Acquisition Developer with experience in ETL and data acquisition to design and develop data acquisition connectors for their clients, using low code solutions like Apache NIFI, SQL databases, and APIs. The ideal candidate should be familiar with Big Data and IOT environments and possess a Bachelor's or Master's degree in Computer Science or a related field. Energisme offers a dynamic team, flexible work schedule, generous benefits, and a genuine commitment to environmental impact reduction.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
299,56920,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-scientist-data-engineer-confirme-f-h_le-plessis-robinson,Data Scientist / Data Engineer confirmé -,CS GROUP,"{git,python,tensorflow,mlflow,R,kafka,numpy}",Télétravail partiel possible,"22 Avenue Galilée, Le Plessis-Robinson, 92350","Ingénieries Spécialisées, Aéronautique / Spatiale, Energie",CDI,2023-03-26,"La mission de CS GROUP : être à la pointe des technologies pour garantir la sécurité de tous dans un monde en pleine mutation. L’expertise reconnue de CS GROUP lui permet d’intervenir là où les enjeux de sécurité sont les plus sensibles : défense, spatial, aéronautique, énergie… Et, aussi, là où les réponses sont à inventer ou à réinventer: lutte anti-drone, cybersécurité, traitement de données satellitaire… Le positionnement de CS GROUP en fait un acteur unique sur son marché : son expertise technique se combine avec une forte affinité avec les métiers de ses clients. À la clé, un capital confiance qui lui ouvre les portes d’un fort développement partout dans le monde pour des interventions tout au long de la chaîne de valeur. Conseil, conception, développement, intégration, maintenance et support aux opérations… Rattaché au manager « projets IA / R&D » au sein d’une équipe en croissance, le Data Scientist / Data Engineer participera au développement d’un nouveau produit alliant IA et cybersécurité, qui s’intégrera dans un contexte de SIEM. Vous contribuez à la réalisation de nos projets de Cybersécurité et de R&D dans des contextes nationaux et internationaux. Détails des missions : En tant que Data Scientist : Analyser des données de systèmes de sécurité cyber et physique pour construire des modèles Développer des modèles IA en python En tant que Data Engineer : Participer à l’architecture globale du système Développement des pipelines d’entrée et de sortie et du moteur d’exécution Rédiger de la documentation Participer aux événements et projets IA Vous êtes issu(e) d’une formation universitaire bac +5 ou d’une école d’ingénieur et vous souhaitez rejoindre une équipe expérimentée et dynamique au sein d’une entreprise en forte croissance. Vous avez une expérience significative (5 ans) sur un poste de Data Scientist / Data Engineer, sur des systèmes de Machine Learning en production avec des évolutions majeures et impliquant un suivi de la production. Compétences techniques requises : Connaissances avancées et opérationnelles des algorithmes et traitement de Machine Learning Bonnes connaissances en programmation python et librairies ML (numpy, scikit-learn, tensorflow…) Connaissances en architecture de Machine Learning et middleware support (kafka, mlflow…) Connaissances générales des outils de développement (git …) Savoir-être et savoir-faire attendus : Capacité de conception de logiciel de Machine Learning Capacité à développer et implémenter une vision de solution logicielle Rigueur Bonne expression orale et écrite et idéalement en anglais","CS GROUP is seeking a Data Scientist/Data Engineer with 5 years’ experience in machine learning algorithms, python programming, and ML libraries to develop a new product in the field of AI and cybersecurity that will integrate with SIEM. The ideal candidate should possess advanced knowledge and operational skills in ML algorithms and treatment, programming python and ML libraries, and development tools (git, MLflow) along with the ability to design/implement a solution software and exhibit strong communication skills.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
303,57060,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech_london,DataOps Engineer - Big Data & Analytics Fintech LONDRES,Opensee,"{python,bash,lambda,Docker,go,pandas,Bash,linux,docker,azure,Kubernetes,AWS,scale,golang,kubernetes,SQL,numpy,aws,Unix,Python}",Télétravail partiel possible,"London, EC2V 7NA","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-03-26,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee’s commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What’s in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client’s internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Duration : permanent contract Salary : Competitive, profile based Location : London (the City) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!","Opensee is seeking an Ops/DevOps professional with a problem-solving mindset, creativity, and autonomy to install the company's solutions in clients' infrastructure, help them integrate the product in their ecosystem, and ingest and analyze data. The ideal candidate should have experience with Unix systems, Bash, networks, Terraform, Golang, Docker, Kubernetes, big data, distributed databases, SQL, and Python. Good written and verbal communication skills in English are required, while proficiency in French is a plus. The position offers a permanent contract, a competitive salary, and opportunities to develop skills and grow within the company.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
253,59932,https://www.welcometothejungle.com/fr/companies/securitesociale/jobs/data-engineer-f-h_rennes,Data Engineer,La Sécurité Sociale,"{durable,Databricks,Spark,Azure,SQL,Python}",Télétravail partiel possible,"Rue de Châteaugiron, Rennes, 35000",Administration publique,CDI,2023-03-28,"Vous souhaitez vous engager dans une entreprise aux valeurs humaines, sociales et solidaires ? Vous souhaitez prendre part à la construction d'un SI de premier plan en France ? Pour vous, le travail d'équipe et le partage de compétences sont sources d'émulation ? Les nouvelles technologies vous inspirent ? Vous avez répondu « Oui » à chacune de ces questions, ne cherchez plus votre futur job ! Vous l'avez trouvé ! Devenez Data engineer F/H en CDI au sein de notre DSI. Qui sommes-nous ? L'entreprise : La CNAF (Caisse Nationale des Allocations Familiales), tête de réseau des 101 CAF, représente la branche famille de la Sécurité Sociale et a pour mission de piloter la politique familiale et l'aide aux populations en situation de précarité ainsi que la politique d'action sociale. Votre futur service : Au sein de la DSI, comptant environ 800 collaborateurs, la direction « Prestations Individuelles et Référentiels Métiers » a pour mission principale de concevoir, développer et maintenir le système d'information lié aux prestations individuelles (prestations versées aux allocataires telles que l'allocation familiale, l'allocation logement, la prime à la naissance, le RSA, la prime d'activité, …). Le département Décisionnel et Big Data collecte, consolide, modélise, et met à disposition les données de la branche aux directions métiers de la CNAF ainsi qu'à l'ensemble des CAFs. Il comporte 3 services répartis sur Rennes et Lyon/Macon. Vous rejoindrez le service ""Architecture et développement Restitutions"" basé à Rennes. Actuellement en pleine refonte de notre système Décisionnel, nous migrons vers une solution Décisionnel et Big Data (Lakehouse) innovante. Cette nouvelle plateforme va nous permettre à la fois de gérer les besoins purement BI et également Big Data (Machine Learning, IA..). Parmi les futurs thèmes de développement identifiés, citons la connaissance Client (CRM) adaptée à notre population d'allocataire, la lutte contre la fraude, la fiabilisation de certains stocks de données… Mission/Activités Concrètement votre futur quotidien ? Intégré(e) au service « Architecture et Développement Restitutions », vous êtes en charge de : Participer au projet de migration de notre système Décisionnel vers un écosystème Big Data ; Construire des solutions dans un environnement Big Data sur des technologies telles que Spark, Python, Databricks, Azure, Power BI ; Participer à la réalisation de cas d'usage Big Data définis en collaboration avec les Data Scientists. Des déplacements occasionnels sont à prévoir sur Paris et à Lyon. Conditions particulières Votre futur environnement de travail ? Vous évoluerez au sein d'un environnement de travail collaboratif, engageant et en mouvement ! Intégrer la CNAF, c'est aussi pouvoir bénéficier de nombreux avantages : Télétravail possible, Flexibilité des horaires , Congés / RTT : le bénéfice de + ou - 9 semaines par année pleine, Transport : remboursement à 50% de votre abonnement, bénéfice d'un forfait mobilité durable d'un maximum de 500€/an si vous utilisez des modes de transport alternatifs à la voiture individuelle, Tickets restaurant (prise en charge à hauteur de 60%), Rémunération fixe : négociable selon profil et rémunération actuelle / à partir de 37,5 K€ (sur 14 mois) + prime de résultats + prime d'intéressement CSE avec des œuvres sociales avantageuses (sport, loisirs, voyages, …). Alors n'hésitez plus, rejoignez-nous ! Dans le cadre de sa politique de diversité, la CNAF ouvre ses offres d'emploi à toutes les candidatures. Etes-vous notre prochain(e) Data engineer ? Vous avez une formation supérieure de type Bac +3 à Bac+5, idéalement en informatique décisionnelle ou Big Data, complétée par une expérience de 2 ou 3 ans dans le Big Data souhaitée. Une expérience dans les environnements Big Data ou/et Cloud sera très appréciée. Vos compétences : Excellente aptitude au développement informatique Capacité à appréhender des environnements complexes techniquement Capacité à concevoir des solutions dans un souci d'industrialisation en Production Capacité à promouvoir les solutions développées et à les présenter devant divers publics Capacité à travailler en équipe avec des interlocuteurs variés Excellent relationnel Vos compétences techniques : Indispensables : Spark, PySpark, SQL Souhaitées : Power BI, Databricks, Cloud Azure","The Caisse Nationale des Allocations Familiales (CNAF) is seeking a data engineer to join their Decisional and Big Data department in Rennes, France. The ideal candidate should have a degree in decisional IT or big data, along with two to three years of experience in the field. The role requires extensive expertise in Spark, PySpark, and SQL, with desirable skills in Power BI, Databricks, and Cloud Azure. Benefits include flexible working hours, telecommuting options, and an attractive salary package.",Bac +3,> 2000 salariés,> 1 an,2,1,0.04154662416233763
273,60622,https://www.welcometothejungle.com/fr/companies/edf/jobs/ingenieure-ingenieur-data-h-f_lyon,Ingénieure / Ingénieur Data,EDF,"{Oracle,Jenkins,Git,PostgreSQL,Kubernetes,AWS,Docker,elastic,GCP,Java,SQL,Python}",Télétravail partiel possible,"Lyon, 92400","Environnement / Développement durable, Energie",CDI,2023-03-28,"Au croisement d'enjeux essentiels et captivants, rejoignez un groupe à la dimension internationale, champion de la croissance bas carbone et activement engagé dans la lutte contre le réchauffement climatique ! Rejoindre EDF, c'est également travailler dans un Groupe porteur de valeurs fortes, qui innove avec de solides actifs industriels et vous confie des missions qui ont du sens. Au sein du Groupe EDF, si vous souhaitez travailler dans le domaine du SI & des Télécommunications en lien avec les centrales de productions d'électricité, alors rejoignez l'UNITEP, l'opérateur numérique industriel d'EDF !) Avec près de 800 collaborateurs, l'UNITEP contribue à la numérisation, à la performance des centrales de production d'électricité nucléaires, thermiques et hydrauliques. En tant qu'Ingénieur Data, vous rejoindrez la Manufacture Digitale de l'UNITEP. Au sein d'une équipe agile, organisée sur les bases de Scrum, d'une quinzaine de personnes, vous contribuerez à l'utilisation de données métier pour le développement de solutions digitales ainsi qu'au choix et à la mise en oeuvre des différents composants SI (progiciel, bases de données, développements spécifiques…). Vos missions seront riches et variées : Apporter votre expertise sur le patrimoine de données disponible dans le Datalake EDF et les solutions SI Apporter vos connaissances de tous les moyens d'obtenir, stocker et gérer de la donnée (pipelines, bases de données, cloud) Participer à l'élaboration des modèles de données des applications développées Etre très connecté avec les personnes en lien avec le Datalake EDF Etre force de proposition dans l'approche et les échanges avec le métier Vous contribuerez à l'assurance du respect des exigences techniques de réalisation tout au long du cycle de vie d'un projet : cyber-sécurité, architecture retenue pour le projet, cohérence des flux inter-applications, intégrité des données... Type de sujets traités : Développement d'applications à destination des métiersModélisation des bases de données, injection de données existantes, traitements en batch Gestion des données de l'équipeBackup de données, gestion d'instances et config des bases de données Basés sur les solutions cloud (AWS, GCP)Migration sur une infrastructure cloud, mise en place de pipeline, PoC Participer à la stratégie Data de l'unitéElaboration de solutions de mise à disposition et d'accès à la donnée Faire vivre la communauté Data et acculturer les profils non techniques Données : PostgreSQL, API-Rest (webservice), elastic search, Oracle Langages : Python, SQL, Java Autres : Docker, Jenkins, Openshift, Kubernetes, Git, AWS, GCP Alors prête/prêt pour l'aventure ? Titulaire d'un diplôme Bac+5 (formation universitaire ou école d'ingénieur) avec spécialisation en informatique / système d'informations, numérique et DATA, vous disposez d'une expérience minimale de 2 ans en tant qu'Ingénieure / Ingénieur Data. Vous disposez de solides compétences techniques sur les bases de données et leurs utilisations Votre esprit d'analyse et votre sens critique vous permettront d'appréhender la complexité des systèmes SI et d'optimiser les solutions proposés Votre curiosité et sens du client vous permettront de comprendre les enjeux et besoins de partenaires métiers et de les challenger Vous avez le sens du collectif et saurez travailler en coopération tant en interne UNITEP avec vos collègues EDF (et prestataires) qu'en externe UNITEP avec nos partenaires métiers Si ces talents sont les vôtres, alors rejoignez-nous ! Rémunération : Rémunération attractive selon profil et expérience qui s'inscrit dans un package global de rémunération intégrant notamment : 13ème mois Intéressement Prime individuelle Tarifs préférentiels pour l'électricité et le gaz Une politique familiale développée (prime mariage, naissance, sursalaire, aide aux études des enfants, jours de congés pour événements familiaux, …). Avantages à nous rejoindre : Un job varié et intéressant, riche en interactions Un domaine d'activité en plein essor Une équipe à taille humaine Un package de rémunération attractif Des possibilités de professionnalisation et d'évolution en interne UNITEP ou au sein du Groupe EDF Politique d'accueil et d'intégration des nouveaux arrivants. Vous voulez en savoir plus ? Découvrez l'UNITEP : https://www.linkedin.com/posts/cedric-chabert-623908a0_unitep-maeztiers-it-activity-6909408356776513536-Q1Bb?utm_source=linkedin_share&utm_medium=member_desktop_web Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","The UNITEP, EDF's industrial digital operator, is seeking a data engineer with at least two years of experience in data engineering and a degree in computer science or digital technology to join their agile team of 15 people. The successful candidate will have strong technical skills with databases and their uses, the ability to understand complex IT systems and propose solutions, and a strong focus on collaboration with internal and external stakeholders. EDF offers an attractive compensation package and opportunities for professional development and internal growth. The position is open to all candidates, including those with disabilities.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
0,56433,https://www.welcometothejungle.com/fr/companies/matera/jobs/data-engineer_paris,Data Engineer,Matera,"{python,Kubernetes,Airflow,CSM,DBT,Meltano,Fivetran,Looker,Stitch,BigQuery,Docker,SQL}",Télétravail partiel possible,"10, Rue Treilhard, Paris, 75008","SaaS / Cloud Services, Immobilier particulier",CDI,2023-03-26,"Créée en 2017, Matera est une start-up à forte croissance qui révolutionne le secteur bien poussiéreux des syndics de copropriété. Matera permet aux copropriétaires de se passer d’un syndic professionnel pour la gestion de leur immeuble en remettant au goût du jour un modèle laissé aux oubliettes : le syndic coopératif. Grâce à Matera, les copropriétaires gèrent eux-même leur immeuble rapidement et sereinement. Concrètement, la start-up met à disposition des syndics coopératifs un logiciel SaaS intuitif et clé en main qui automatise les tâches de la gestion de copropriété ainsi que des experts en interne qui prennent le relai sur des sujets complexes : juristes, comptables, experts en bâtiment… Matera a déjà séduit plus 6 500 copropriétés partout en France et en Allemagne ! En tant que Data Engineer de l’équipe, tu épauleras Hugo, notre Head of Data et les 4 Data Analysts pour construire la plateforme centrale de données. Au programme : Gestion de la data plateforme (développement, maintenance et sécurité) Développement de pipelines d’ETL et de reverse ETL Analyse des besoins d’accès aux données en collaboration avec les Data Analysts des équipes Sales, CSM, Acquisition, Finance. Mise en place de contrôles automatiques de la qualité des données Tests et intégrations de nouveaux outils d’accès et de transformation des données Notre stack : Data warehouse : BigQuery Orchestrateur : Airflow et Kubernetes Infrastructure: Terraform Transformation de données : SQL / DBT Outils d’extraction et de chargement de données : python / Meltano Singer-SDK, Stitch, Fivetran BI : Looker Idéalement, Tu as obtenu un diplôme d’ingénieur Tu as au moins 2 ans d’expérience en data engineering Tu maîtrise parfaitement python et SQL Nice to have : Expérience sur Airflow, DBT et BigQuery Expérience sur Docker et Kubernetes Expérience sur Looker On étudie ta candidature Entretien téléphonique avec Maurine, Talent Acquisition (30 min) Rencontre avec Hugo et mise en situation (1h) Final Round avec Laurent (CFO) Rencontre avec les équipes, puis offre 🎉 Pourquoi nous rejoindre Un onboarding aux petits oignons pour te permettre de découvrir le monde de la copropriété, notre organisation et te donner toutes les clés pour réussir ton intégration; Un environnement stimulant, où tout est à construire! Un produit répondant aux problèmes des copropriétaires qui est minutieusement conçu et bichonné par nos équipes; Travailler sur d’autres projets en parallèle pour faire briller Matera et developper tes skills; Apprendre & évoluer: culture du feedback et un suivi pendant tout le long de ton stage; Des fondateurs qui ont à coeur le bien-être et le rayonnement de toute la team; Si tu as une passion pour les jeux de société en tout genre (et les apéros qui vont avec), tu seras comblé·e tous les vendredis! Détails Locaux: 10 rue treilhard 75008 Paris Remote: Hybrid Type de contrat: CDI Début: ASAP Sache que chez Matera, nous garantissons l’égalité des chances et la diversité, c’est pourquoi tous nos postes sont ouverts aux personnes en situation de handicap, seules les compétences et la motivation font la différence !","Matera, a rapidly growing start-up revolutionizing traditional property management, seeks a Data Engineer to join their team. The successful candidate will be responsible for developing, maintaining and securing the central data platform, streamlining ETL and reverse ETL pipelines, analyzing data access needs and implementing automated data quality checks. Ideal qualifications include a degree in engineering, at least two years of data engineering experience, proficiency in Python and SQL, and experience with Airflow, DBT, and BigQuery. The position is a CDI with the option for hybrid remote work.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
316,56829,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-databricks-h-f_levallois-perret,Data Engineer / Databricks,Micropole,"{Microsoft,durable,Azure,AZURE,Databricks,Scala,AWS,R,Spark,GCP,SQL}",Télétravail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer Databricks Localité : Levallois-Perret Type de contrat : CDI Niveau d’expérience : au moins 2 ans Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services. Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus ! Au sein de notre agence basée à levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer Databricks (F/H) , vousaccompagnerez les directions métiers dans l'évaluation de l'efficacité de leurprocessus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Databricks. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence. Vos compétences techniques : Vous avez un minimum de 2 années d’expérience sur des projets Data dont au moins une sur des projets Databricks (sur GCP et/ou Azure), ou à défaut une certification Databricks avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ; Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visio Etape 3 – Vous rencontrez un manager technique avec l’un de nos experts. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) LA VIE CHEZ MICROPOLE, C’est : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; Participation à des projets internes sur la base du volontariat. #LI-DM1 Compétences Databricks Spark Scala SQL AZURE GCP","Micropole is seeking a Data Engineer Databricks to join their team in Levallois-Perret. The successful candidate will have at least two years of data project experience (including Databricks projects or certification) and will work closely with business leaders to evaluate efficiency of processes while optimizing performance. Key responsibilities include developing and maintaining customer use cases with Big Data/Databricks tools and frameworks, modeling and analyzing data in the cloud, ensuring data security and compliance, and identifying relevant data sources. The ideal candidate will be passionate, detail-oriented, curious, and have a strong command of at least one programming language (Spark, Scala, or SQL).",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
396,39822,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineer-confirme-e-python-scala-aws-stack-f-m-d_nantes,Data Engineer Confirmé.e - Python / Scala & AWS Stack,Decathlon Technology,"{Databricks,Talend,Scala,Redshift,Airflow,Logstash,Lambda,S3,Kibana,Druid,AWS,GitHub,Spark,BigQuery,GCP,Java,Python,Elastic}",Télétravail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2022-11-29,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOIGNEZ LES EQUIPES DATA DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour accompagner cette transformation digitale internationale de Decathlon, les équipes Data évoluent et mettent au coeur de leurs enjeux : La qualité et l’accessibilité de la donnée La scalabilité des processus associés au cycle de vie de la donnée (ingest, store, transform, expose) L’élasticité des infrastructures et des services Si tu as envie de contribuer à cette transformation et de co-construire la plateforme data de demain, alors tu seres intégré·e dans une équipe data domain centric : Stock / supply chain Products Forecast Pricing Users Finance Performance Economique Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e Data Engineer, basé-e, au choix à Paris, Lille, Lyon ou Nantes. TES RESPONSABILITES Tu seras en charge de: Construire des pipelines scalables de données structurées et non structurées ; Définir la stratégie de nos stacks techniques et garantir la CI/CD ; Maintenir et repenser les datasets et pipelines existants pour servir une plus large variété de use cases ; Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ; Contribuer activement à notre communauté de data engineers ; Le périmètre technique : Big Data : Amazon Web Services, Lambda, Redshift, S3 Code Programming : Python, Scala, Java Data Science / ML : Spark, Databricks Data Pipeline : Airflow Real Time Database : Druid Big data analytics : Stack ELK (Elastic Search, Logstash, Kibana) Environnement Google GCP : BigQuery, Composer, Data Studio Data integration : Talend CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as au moins 2 ans d’expérience comme Data Engineer, sur l'environnement Big Data d’AWS, sachant utiliser ses composants (Lambda, Redshift, S3) ainsi qu’optimiser leurs performances ; Tu maîtrises l’un des langages suivants : Python, Scala, Java ; Tu maitrises la mise en oeuvre de pipeline de processing de données ; Tes pairs te reconnaissent pour ta grande appétence technique ; Tu comprends le cycle de vie de la donnée et tu es à l’aise avec les concepts de data lineage, data gouvernance et data privacy ; Tu as un bon niveau d’anglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu aimes travailler en agilité dans un environnement collaboratif ( GitHub , Mob programming). Tu as un sens du service développé. Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et la vie d'équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) Cerise sur le gâteau : Tu déjà travaillé avec les technologies comme Spark, Databricks, Airflow, Druid, Stack ELK (Elastic Search, Logstash, Kibana), Environnement Google GCP ( BigQuery, Composer, Data Studio), Talend. CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a Data Engineer to join their Data team in Paris, Lille, Lyon or Nantes. The role involves working on building scalable data pipelines and defining the technical stacks strategy, as well as working with AWS Big Data components, Python, Scala and Java programming languages, data pipeline implementation, and data lineage, governance, and privacy concepts. The ideal candidate should have at least 2 years of experience as a Data Engineer and be comfortable working in an agile and collaborative environment. Decathlon offers a range of benefits including teleworking, international projects, and training and certification opportunities.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
432,49754,https://www.welcometothejungle.com/fr/companies/ioda/jobs/consultant-data-engineer-h-f-paris-bordeaux-barcelone-ile-de-la-reunion-barcelone,Consultant(e) Data Engineer - Paris - Bordeaux - Barcelone - Ile de la Réunion - Barcelone.,IODA Group,"{Azure,Javascript,PHP,AWS,Spark,GCP,Java,SQL,Python}",Télétravail partiel possible,Paris,"Digital Marketing / Data Marketing, IT / Digital, Stratégie",CDI,2023-02-07,"Acteur à taille humaine et orienté business, IODA, cabinet de conseil mixe, la Technologie, la Data & IA, le CRM & Digital. IODA accompagne ses Clients avec Intelligence et pragmatisme dans l’Optimisation de la transformation Digitale et son Accélération. Fort de plus de 10 ans d’expérience et de passion, IODA réserve un service personnalisé et adapté à chaque client et partage son savoir-faire et son professionnalisme autour d’échanges sincères et humains. Travailler ensemble relève davantage du partenariat que de la simple collaboration. Nous avons 4 bureaux, Paris, Bordeaux, Ile de la Réunion, Barcelone En pleine accélération de son développement en France et à l’international, IODA Group , cabinet de conseil à taille humaine et orienté business, mixant la Data, le CRM, le Digital & la Technologie, recherche des collaborateurs de talents. Dans ce cadre, IODA Group recrute un(e) Consultant(e) Data Engineer H/F- Paris - Barcelone - Ile de la Réunion - Barcelone. Poste et missions Participer à la conception de solutions : choix d’outils, proposition de solutions alternatives Assister le client au cadrage du projet, et participer au design fonctionnel et technique Structurer et planifier la réalisation des développements Collaborer à l’intégration des produits dans le SI avec l’architecte technique. Participation à la réalisation de développements complexes Assurer le suivi et la qualité des développements ainsi que la réalisation du projet Maîtriser les techniques et les méthodes Agiles Planifier et garantir les mises en production : industrialisation, package…. Assurer le rôle de référent et coacher les consultants juniors, faire progresser les équipes Faire de la veiller technologique o Compétences techniques Le poste à pourvoir nécessite une forte polyvalence, une capacité d’adaptation afin de pouvoir répondre à l’environnement technique des différents Clients : Prise en main de nouveaux progiciels, réalisation de paramétrages avancés, développement de briques applicatives fortement intégrées dans un environnement existant. Capacité à s’approprier les concepts de progiciels du marché sur l’ensemble des briques applicatives (CRM, BI, E-commerce …) et big data avec une expérience sur un ou plusieurs environnements cloud (GCP, Azure, AWS…) Le candidat devra pouvoir justifier de solides connaissances sur : Python et Spark Les bases de données (langage SQL), tant en conception (MCD, MPD) qu’en utilisation (SQL, procédures stockées) et la connaissance d’un ETL La connaissance des langages courants, plutôt orientés Web : HTML 5, CSS, Java / Javascript, C#, PHP, Ajax…est un plus o Profil De formation supérieure en informatique BAC+4/5, vous disposez de solides expériences dans le développement de solutions dans le domaine du CRM et le Digital. Vous êtes attirés par l’activité́ de Conseil et vous possédez de solides compétences techniques avec une faculté à proposer des solutions opérationnelles à forte valeur ajoutée ? Si vous souhaitez : Intégrer une équipe dynamique et motivée ou vos talents, idées et proactivité seront reconnus et encouragés, Découvrir une diversité de projets et plusieurs secteurs d’activité/métiers en France ou à l’international Avoir de réelles perspectives d’évolution Vous aurez la possibilité de pourvoir travailler à Paris, Bordeaux, Barcelone ou l’Ile de la Réunion CDI - Rémunération Fixe attractive + Variable selon le profil. Alors REJOIGNEZ NOUS! 1er entretien avec l’équipe RH 2ème entretien avec les Consultants 3ème entretien avec la Directrice Générale","Consulting firm IODA Group is seeking a Data Engineer with strong skills in Python and Spark, as well as knowledge of SQL, ETL and web languages, to work on the company's data, CRM, digital and technology projects in Paris, Bordeaux, Ile de la Réunion or Barcelona. The role involves developing and integrating products into existing systems, coaching junior consultants, ensuring project quality and following Agile methodologies. The position requires adaptability and versatility in mastering new systems, while offering real opportunities for skill development and career progression.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
426,40475,https://www.welcometothejungle.com/fr/companies/cgi/jobs/consultant-data-ingenieur-big-data-h-f_bordeaux,Data Engineer,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",Télétravail partiel possible,"Bordeaux, 33000","IT / Digital, Transformation, Big Data",CDI,2023-01-29,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. - Conseil, Audit et Maitrise d’œuvre. - Etudes d’opportunité, cadrage de projet d’intégration de données et aide au choix de solution. - Accompagnement à la mise en place de DataLake/Big Data. - Conception et développement de flux d’intégration des données (ETL,ELT, streaming ,API … ). - Conception et mise en œuvre de plateformes On Premise ou Cloud de stockage des données dans un Data Lake (Big Data). - Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.). - Migration des données. - Move to Cloud. - Compétences avérées en Gouvernance des données, qualité des données et catalogue des données. - Minimum 2-5 ans d’expérience dans le domaine. - Animation d’ateliers Métier/ IT de définition des processus d’intégration des données. - Animation d’atelier de définition de plateforme d’intégration et de stockage des données. - Proposition de type d’architecture de gouvernance (Centrale, décentralisée, etc.). - Capacité à intégrer une équipe d’intégration des données. - Capacité à proposer des solutions & architectures de données. - Capacité à configurer des outils d’intégration et de Reporting des données. - Formation et pratique d’outils de Data Intégration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. ). CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, seeks experienced professionals for its Data Integration team. The role requires proven competency in data governance, quality, and cataloging. Key responsibilities include designing and developing data integration workflows, conceiving and implementing Cloud storage platforms, and coordinating with business and IT teams on data integration processes. The company provides a supportive work environment and is committed to diversity and inclusion.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
425,43941,https://www.welcometothejungle.com/fr/companies/ba-sh-1/jobs/data-engineer-f-h_paris_BASH_1ZqxpLP,data engineer f/h,ba&sh,"{durable,Azure,RedShift,Talend,DBT,AWS,Snowflake,Synapse,GCP,Java,Python}",Télétravail partiel possible,"67 Av. Raymond Poincaré, Paris, 75116",Mode,CDI,2023-02-01,"En 2003, Barbara Boccara & Sharon Krief, entrepreneuses et créatives, se lancent pour créer ba&sh et son vestiaire idéal où toutes les femmes pourraient s’exprimer, avec modernité, simplicité et chic. Elles offrent la possibilité d’être libres, belles et bien. Puis, en 2015, L Catterton, le fonds d’investissement de LVMH, accompagne ba&sh dans son expansion internationale et son développement en hyper-croissance, dans un environnement transformé par la révolution digitale. ba&sh est une maison innovante, dynamique et tournée vers les problématiques de demain. Elle lance officiellement en 2021, son programme de développement durable BLOSSOM et établit un plan d’action concret tourné vers une profonde transformation ambitieuse. Bien plus qu’une marque, ba&sh souhaite couvrir les thématiques sociales, environnementales et sociétales par le choix de matières éco responsables, transparence & traçabilité dans la chaine de valeur, accompagnement des fournisseurs, suivi et réduction des émissions de gaz à effet de serre, économie circulaire et innovations durables. Au sein de l’équipe de la DSI, vous serez intégré dans le cadre de la création d’une équipe Data ayant pour but de centraliser l’ensemble des silos de données de l’entreprise et proposer à ses métiers des vues d’ensemble. La plateforme technique et les premiers USE CASE sont en cours de réalisation. Vous serez en charge de l’ensemble des développements d’extraction, modélisation, transformations et optimisation des données en collaboration avec le Responsable de projets IT. Vous serez assisté d’un consultant Data visualisation afin de proposer aux différents acteurs de ba&sh les analyses et les rendus les plus performant possible. La plateforme Snowflake sera votre outil principal couplé à Talend pour réaliser l’ensemble des extractions et modifications. A ce titre, vos missions sont les suivantes : Implémenter et améliorer les différentes briques de notre socle technique Data dans un environnement Snowflake / Tableaux Travailler à la robustesse de flux de données, de la collecte à la transformation Talend Créer, modéliser, enrichir et faire évoluer nos Datamarts Transformer les données brutes en informations organisées et utilisables par les Data Analystes Optimiser et être force de propositions sur nos solutions existantes de traitement des données Identifier les manques et dépendances à faire évoluer côté Data (données sources, process, modélisation) Intégrer de nouvelle source de donnée au sein de l’écosystème Data Cette liste n’est pas exhaustive et sera susceptible d’évoluer avec le développement de ba&sh. Vous vous reconnaissez dans ce parcours : Formation supérieure en école d’ingénieur ou école spécialisée en informatique Intérêt prononcé pour le domaine de la Data Au moins 4 années d’expérience dans un environnement Data évoluée Une première expérience dans le monde du Retail est appréciés mais non obligatoire Vous vous démarquez pour votre : Autonomie, proactivité, rigueur et organisation Force de proposition technique et structurelle Capacité de restitution technique Bon relationnel et goût pour le travail en équipe Appétence pour faire de la veille technique et suivre les sujets liés à la data Vous maitrisez : L’univers Data Cloud (AWS,GCP,Azure) La connaissance d’une plateforme de gestion datawarehouse (Synapse, Snowflake, RedShift), Snowflake serait un plus Un langage de programmation type Python, Java Les modèles de données relationnelles Une expérience approfondie en ETL et ELT (Talend, DBT) est requise ba&sh n’attend plus que vous ! Chez ba&sh, nous croyons que la diversité est une force, et nous nous engageons à la cultiver. La diversité sous toutes ses formes (genre, âge, nationalité, culture, croyances religieuses, orientation sexuelle, …) enrichit les échanges et le cadre de travail, favorisant ainsi le développement de l’entreprise & de chacun des individus qui la composent. En tant qu’employeur qui positionne l’égalité des chances au cœur de son système de valeurs, nous accueillons et considérons les candidatures de l’ensemble des candidats qualifiés et compétents. Nous nous engageons à continuer à avancer vers un ba&sh toujours plus inclusif, où chaque employé développe un fort sentiment d’appartenance. Si vous souhaitez rejoindre une marque en pleine expansion avec une vraie philosophie, faites-nous parvenir votre candidature.","Ba&sh, a fast-growing fashion brand, is seeking an experienced Data Engineer to join its team in centralizing the data silos and proposing an overview to its business. The ideal candidate will have at least 4 years of experience in an advanced Data environment, a strong interest in Data, and familiarity with Snowflake, Talend, Python, and Cloud Data Warehousing. The position's responsibilities include creating, modeling, enriching, and evolving Datamarts to transform raw data into organized information that can be used by Data Analysts, optimizing existing data processing solutions, and identifying gaps and dependencies to evolve the data environment further.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
424,43614,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_lyon,Data Engineer,CGI,"{Azure,GITLAB,Jenkins,Talend,Shell,Kubernetes,AWS,Snowflake,Docker,Kafka,Linux,GCP,Java,Python}",Télétravail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-01-30,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Au sein de l’équipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux équipes d’expert et de déploiement des solutions. Vous participerez au développement stratégique d’un projet d’un client et vous évoluerez dans un contexte international, et bénéficierez de l’expertise de consultants CGI, en immersion chez le client. A ce titre vos principales responsabilités seront : • Appréhender le contexte et les enjeux Métier du client ; • Comprendre et expérimenter le cadre Agile et Lean ; • Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire avec l’accompagnement de Consultant senior ; • Participer au développement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; • Établir et dérouler des scénarios de tests ; • Participer à la vie de la communauté Data. Environnement technique : • Cloud provider : AWS, GCP , Azure • Data Acquisition : Kafka, Kafka Connect , Talend, Snowflake • Script : Java, Angular, Python, Shell, • Environnement : Linux, Docker, Kubernetes • Outils : Jenkins, GITLAB CI • Ticketing : JIRA • Reporting: Power BI, Qliksense De formation bac+5 ou de formation supérieure en informatique, vous disposez de 2 ans expériences réussie dans le déploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP. Des connaissances métiers dans le domaine du manufacturing ou ses métiers de la santé , alliés à des compétences techniques fortes sont également des atouts pour la réussite de ce projet. Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer. Vous devrez être en capacité de participer / animer des ateliers en anglais. A propos de CGI: Chez CGI, leader mondial du conseil et des services numériques, nous sommes convaincus que le digital et l’innovation sont de formidables leviers pour accélérer la transformation de la société et mettre la technologie au service du plus grand nombre. Nos 78 000 experts dans le monde, dont 11 000 en France, accompagnent au quotidien les entreprises et les administrations de la stratégie à la mise en œuvre de leur transformation IT pour les rendre plus performantes, autant d’enjeux qui rythmeront votre quotidien aux côtés de nos professionnels.","CGI, a global leader in digital consulting and services with a presence in 30 locations across France, is seeking a candidate for the role of Data Engineer with a background in Kafka, Datalake AWS, and Datalake CGP. The role involves working with stakeholders from all levels of the organization and participating in strategic project development. The ideal candidate should have strong technical skills, business acumen, and communication abilities. The position offers a chance to work with cutting-edge technologies such as Cloud providers AWS, GCP, and Azure, and participate in the development of the Data community.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
418,39830,https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-h-f-lyon_lyon_EVOTE_RyRO0eA,Data Engineer (H-F) - Lyon,evoteo,"{GIT,shell,Jenkins,Scala,GitHub,Glue,AWS,S3,Spark,Java,Python}",Télétravail partiel possible,"23, Rue Crépet, Lyon, 69007","Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2022-11-29,"evoteo est une entreprise de prestation spécialisée en #DATA. L’évolution des structures, établies depuis plusieurs années, voire plusieurs décennies, est en marche et evoteo accompagne ses partenaires pour y faire face. Les équipes d’evoteo sont composées d’ingénieurs, de chefs de projets et de transformations managers tous passionnés par ce changement technologique. La réussite de l’entreprise repose sur un management de carrière simple et efficace de ses collaborateurs dont les axes principaux sont : L’évolution La curiosité L’exigence La collaboration Dans le cadre de notre croissance et pour répondre aux besoins évolutifs de nos clients, nous recherchons un #DATA Engineer afin d’intégrer nos équipes. Missions : Analyser les besoins avec les équipes métiers et #DATA analystes Participation aux choix des solutions à mettre en place Concevoir, développer et garantir la qualité des traitements de données et réaliser les tests de validation Collecte, sauvegarde et traitement des données Administration du cluster AWS Réaliser les ordonnancements des traitements Industrialiser les traitements #DATA science au sein du #DATA lake Travailler sur la mise en place du déploiement Assurer la mise en œuvre, le suivi, l’exploitation et la mise à jour des différents outils déployés Nous recherchons avant tout des personnalités : curieuses, habiles, sociales, adaptables et passionnées. De formation BAC+5 (Master 2,DESS,DEA), formation ingénieure ou informatique, tu as une expérience d’au moins 2 ans en engineering des environnements Big #DATA Les technos : Développement (Python - pyspark, Scala, Java, Script shell) Intégration continue (GIT, Jenkins, Ansible) Connaissances du Cloud AWS (S3, Glue, Stepfunction…) Technologies Big #DATA (Spark) Outils DevOps et déploiement automatisé : Jenkins, Ansible, Cloudformation, GitHub Nous insistons sur les compétences Spark/scla en ecosysteme AWS. Ce poste en CDI est à pourvoir dès que possible sur la région lyonnaise. Tu es un futur collaborateur acteur, en quête de perspectives d’évolution, capable de rigueur et d’esprit d’analyse ? Rejoins-nous ! Comme évoqué, nous aimons les choses simples – envoie-nous ta page Linkedin ou bien un CV, ensuite nous te proposerons : Un échange téléphonique permettant de cibler parfaitement tes souhaits Un entretien de découverte mutuelle afin de savoir si nous avons envie de travailler ensemble Tu reviens vers nous si tu es intéressé pour un dernier échange avec le PDG pour partager la vison, parler de ta carrière et valider ta candidature.","Evoteo is seeking a Data Engineer with at least two years of experience in engineering Big Data environments. The successful candidate will analyze business needs, participate in the selection of solutions, develop high-quality data processing, and ensure successful testing and validation. Experience with Spark, Scala, AWS, and DevOps is required. The company values individuals who are curious, adaptable, and passionate, with strong collaboration skills. The position is based in Lyon, France.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
415,39750,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-paris-h-f_paris,Data Engineer - Paris -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilité, SaaS / Cloud Services",CDI,2022-11-29,"Avec plus de 15 milliards de requêtes par an, Kisio Digital business unit de Kisio et filiale numérique du Groupe Keolis est un acteur majeur de la mobilité. Les trois grands domaines d’intervention de Kisio Digital portent sur les systèmes d’information-voyageur (recherche d’itinéraire multimodal, porte-à-porte et temps-réel) ; l’achat de titres de transport dématérialisés et le mobile-ticketing. Sa vision de la mobilité : permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’emprise possible sur la planète. C’est ce qu’on appelle la « responsive locomotion » ! Kisio Digital travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire en tenant compte du contexte et des préférences du voyageur. Pour répondre aux enjeux d’une mobilité plus intelligente, plus ouverte et plus écologique, Kisio Digital réalise des applications mobiles, des sites web et des SDK basés sur notre API www.navitia.io. Cette plateforme propose des services numériques de mobilité dans le monde entier. Elle rassemble une communauté de 20 000 développeurs et participe à leur stratégie d’innovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, vélomanes, bussophiles, et autres passionnés de montgolfière ou de transports pas toujours très communs. Curieux et ouverts d’esprit, ils sont passionnés par la mobilité au sens large, les nouvelles technologies et les communs numériques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communauté Open transport. Si vous souhaitez vous épanouir dans un environnement multiculturel, sachez que Kisio Digital va désormais lancer des services à l’étranger. Rejoignez-les ! En tant que Data engineer Hove, vous êtes intégré à une équipe pluridisciplinaire mêlant développeurs, Product Owner, Architectes dont l’objectif est de créer des services à fortes valeur ajouté dans le domaine du transport. Vous avez la charge de définir et mettre en œuvre le pipeline d’acquisition des données (datahub) global pour Hove, d’organiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Créer et faire évoluer le moteur d’ingestion des données (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilité des flux de données Travailler en collaboration avec les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégrations continues, scalabilité des modèles, craftsmanship, etc…) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Déployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des données Superviser et monitorer le déploiement et la robustesse des composants mis en production Participer activement à la qualité de l’ingénierie logicielle (Relecture de code, test, intégration continue, déploiement, etc.) Participer aux évènements internes à la communauté data interne et externes (AWS Summit, workshops, meetups…) Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.* Vous justifiez d’une expérience d’au moins 2 ans en tant que Data engineer Vous opérez dans le conseil et pouvez justifier de vos missions Vous maitrisez l’anglais professionnel Vous maitrisez au moins : Un framework de calcul distribué tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala…). Différents systèmes de base de données (SQL et NoSQL) et le langage SQL. Un framework de streaming de données tel que Kafka, Kinesis, … Une expérience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks… Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez être capable de livrer du code de qualité dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l’équipe tech Un entretien avec notre CTO","Kisio Digital, a major player in mobility with over 15 billion queries per year, is seeking a Data Engineer with at least two years of experience to create and implement a global data acquisition hub and storage solution for the Hove team. The successful candidate will work with a multidisciplinary team to create high-value services in the transport sector, and must have knowledge of at least one distributed computing framework, multiple programming languages, and SQL and NoSQL databases. Fluency in professional English is also required.",N,N,N,2,1,0.04154662416233763
413,37249,https://www.welcometothejungle.com/fr/companies/bcg-gamma/jobs/forward-deployed-data-engineer_paris,Data Engineer,BCG Gamma,"{React,python,spark,Pandas,JavaScript,Kubernetes,AWS,Docker,scale,Hadoop,Spark,TypeScript,Azure,GraphQL,SQL,SCALA}",Télétravail partiel possible,N,"Intelligence artificielle / Machine Learning, IT / Digital, Organisation / Management",CDI,2022-10-18,"Location: PARIS Amsterdam, Barcelona, Berlin, Cologne, Copenhagen, Dusseldorf, Frankfurt, Helsinki, London, Madrid, Milan, Munich, Oslo, Sao Paulo, Stockholm, Vienna, Warsaw, Zurich Geography: Central & South America, Europe & The Middle East Capabilities: Big data & advanced analytics, Innovation & product development, Technology & digital Industries: Automotive & Mobility, Biopharmaceuticals, Consumer products, Education, Energy & environment, Engineered products & infrastructure, Financial institutions, Health care payers & providers, Insurance, Media & entertainment, Medical devices & technology, Metals & mining, Private equity and principal investment, Process industries & building materials, Public sector, Retail, Social sector, Technology industries, Telecommunications, Transportation, travel & tourism Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we work closely with clients to embrace a transformational approach aimed at benefiting all stakeholders—empowering organizations to grow, build sustainable competitive advantage, and drive positive societal impact. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives that question the status quo and spark change. BCG delivers solutions through leading-edge management consulting, technology and design, and corporate and digital ventures. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, fueled by the goal of helping our clients thrive and enabling them to make the world a better place. Practice Area Profile BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you’ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology. What You’ll Do As a forward-deployed Data Engineer, you’ll be part of our rapidly growing engineering team and help build the next generation of AI solutions. You’ll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions. Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG GAMMA. WHO YOU ARE We are looking for talented individuals with a passion for data engineering, software development and transforming organizations into AI led innovative companies Apply data engineering practices and standards to develop robust and maintainable solutions Actively involved in every part of the software development life cycle Experienced at guiding non-technical teams and consultants in best practices for large-scale data engineering Motivated by a fast-paced, service-oriented environment and interacting directly with clients on new features for future product releases Enjoy collaborating in teams to share software design and solution ideas A natural problem-solver and intellectually curious across a breadth of industries and topics What You’ll Bring (Experience & Qualifications) Master’s Degree in Computer Science or relevant field Experience in data engineering and working with global and remote agile squads Proficiency with analytic software programming ideally in python, C++, or SCALA Fluency with the storage, manipulation, and management of relational, non-relational and streaming data structures, specifically SQL, Spark, and Hadoop Proficiency with infrastructure as code principles Experience working on AWS, Azure, or Google cloud infrastructure NICE TO HAVE DevOps: Docker, Kubernetes, CI/CD, Terraform Understanding of parallel computing Full stack development: GraphQL, React, JavaScript, TypeScript Data Science and machine learning (Pandas, Scikit learn) WORK ENVIRONMENT Fluency in English is required as well as fluency in the local language for most locations Ability to travel based on client and business needs. Expect 30-50%","BCG GAMMA seeks forward-deployed data engineers with a master's in computer science to help build new AI solutions, partner with clients in various industries, and deliver thought leadership in scientific communities. The ideal candidate can use data engineering practices to create robust solutions, work on global remote agile squads, and fluently work with relational, non-relational, and streaming data structures. Preference will be given to candidates with proficiency in Python, C++, or Scala, and knowledge of Docker, Kubernetes, CI/CD, Terraform, parallel computing, full-stack development, and data science and machine learning. Travel between 30-50% for client and business needs is expected.",N,N,N,2,1,0.04154662416233763
411,37148,https://www.welcometothejungle.com/fr/companies/leboncoin/jobs/data-engineer-team-bi-engineering-f-h_paris_LEBON_We2V3W,"Data Engineer, team BI Engineering -",leboncoin,"{Athena,Airflow,Redshift,Kubernetes,AWS,S3,PostgreSQL,Kafka,R,Spark,Unix,Docker,Java,Github,SQL,Python}",Télétravail partiel possible,N,"Économie collaborative, E-commerce",CDI,2022-10-18,"Créé en 2006, leboncoin.fr est une plateforme d’échanges d’un nouveau genre, qui simplifie l’accès à la consommation, privilégie la relation locale et fait du digital un outil au service de tous. En facilitant le rapport des individus à l’échange et à la consommation, leboncoin a su s’imposer en quelques années comme phénomène de société français et faire du bonheur des uns le bonheur des autres. En France, nous nous positionnons comme un acteur numérique, économique, sociétal, innovant, avec toujours le même objectif : faciliter tous les échanges au quotidien de l’ensemble de nos utilisateurs. Grâce à notre plateforme de petites annonces, nous donnons une seconde vie à des milliers de biens. L’impact positif de ces échanges a été évalué à 5,8 millions de tonnes de C02 économisés sur une année. Derrière cette apparente simplicité, se trouve une entreprise en forte croissance de plus de 1500 salariés, où il fait bon travailler, une entreprise qui cultive une démarche RH responsable et collective. Leboncoin réunit également les sites Agriaffaires, MachineryZone, Truckscorner, AvendreAlouer, Paycar, Locasun, Videdressing, L’argus et Pilgo Vous aimez travailler en équipe , faites preuve de réelles qualités humaines et vous êtes fortement motivé pour rejoindre une entreprise innovante , où vous pourrez proposer vos idées et les mettre en pratique: nous vous attendons ! En tant que Data Engineer, vous occuperez un poste clé entre les analystes et l’infrastructure data, dans un contexte où la donnée joue un rôle capital. La data chez leboncoin, c’est : Des centaines de milliers d’annonces déposées chaque jour Des centaines de téraoctets de données à valoriser Le contexte : Vous évoluerez au quotidien au sein de l’équipe BI Engineering composée de data engineers et d’un engineering manager. La principale mission de l’équipe est d’assurer la tuyauterie technique permettant l’exploitation des données par les équipes business du groupe Leboncoin, en étroite collaboration avec l’équipe Data Visualisation. Vous serez un référent data auprès de plusieurs feature teams pour les conseiller sur les contrats d’interface des données et évangéliser sur les usages de données qu’ils produisent. Dans un environnement à la pointe des technologies data engineering actuelles: Airflow, Spark, Kafka, AWS (S3, Redshift, Athena), JupyterHub, Kubernetes. Cet environnement et ses bonnes pratiques sont partagées lors de démos et lors de journée de guilde (communauté de pratique) data engineering. Développement sous Ubuntu en Java, Python et SQL avec IntelliJ, Travis, Docker, Github, Terraform. Ce que vous ferez : Analyser et formaliser les besoins utilisateur afin de les intégrer aux évolutions Développer des data pipelines complexes assurant une circulation optimale des données Accompagner la conception de nouvelles sources de données en temps réel (Kafka / Avro) Être au contact et coordonner les métiers fonctionnels et techniques concernés par la mise en place d'un projet BI Participer activement à la veille technologique et à l'effort de R&D Garantir le bon fonctionnement, la disponibilité, l’évolution et la performance des outils Poste basé à Paris (75010) Disponibilité : dès que possible Processus de recrutement : Entretien téléphonique avec Mélody (RH) Entretien avec Céline (manager) et un membre de l'équipe Entretien avec deux membres de l'équipe data engineer Entretien avec Julien (directeur technique) + Mélody (RH) Idéalement de formation type Bac +4/5 école d’ingénieur, vous justifiez d’une expérience d’au moins 2 ans sur ce type de poste. Vous connaissez les environnements Unix, possédez un niveau avancé en SQL et un bon niveau en développement, idéalement Python (ou volonté de monter en compétences). Vous êtes familier de la modélisation décisionnelle, de la conception et/ou de l'implémentation d'un data warehouse. La connaissance de PostgreSQL / Redshift et d’Apache Spark serait un plus. Autres qualités recherchées : Excellent sens du résultat et de la qualité Aptitudes à communiquer , en particulier avec les directions métiers Sens du travail en équipe Curiosité technique en général Aptitudes rédactionnelles","Leboncoin is looking for a data engineer to join their BI Engineering team responsible for the technical pipeline that enables exploitation of data by the Leboncoin business teams. The ideal candidate will be working in a cutting-edge data engineering environment, developing data pipelines, and ensuring optimal circulation of data across hundreds of thousands of ads posted daily on the Leboncoin platform. The candidate should have at least 2 years of experience in a similar role, with advanced SQL, UNIX and development skills.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
408,37184,https://www.welcometothejungle.com/fr/companies/thales/jobs/dataengineer-departement-ia-bigdata_sophia-antipolis,DataEngineer - Département IA & BigData,Thales,"{Oracle,PostgreSQL,Cassandra,Hive,Nvidia,Microsoft,MongoDB,Kafka,NoSQL,Flink,AWS,HBase,Storm,Java,SQL,Hadoop,GCP,MinIO,Scala,HDFS,S3,Spark,Pig,AZURE}",Télétravail partiel possible,N,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2022-10-18,"Ceux qui font avancer le monde s’appuient sur Thales. Dans un monde en constante mutation, à la fois imprévisible et riche d’opportunités, ils sont aux côtés de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus sûr. Riches de la diversité de leurs expertises, de leurs talents, de leurs cultures, leurs équipes d’architectes conçoivent un éventail unique de solutions technologiques d’exception, qui rendent demain possible dès aujourd’hui. Du fond des océans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients à maîtriser des environnements toujours plus complexes pour prendre des décisions rapides, efficaces, à chaque moment décisif. Quel que soit l’enjeu. QUI SOMMES-NOUS ? Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces. QUI SOMMES-NOUS ? Rejoignez Thales, leader mondial des technologies de sûreté et de sécurité pour les marchés de l’Aérospatial, du Transport, de la Défense, de la santé, de l’énergie et de la Sécurité . Fort de 80 000 collaborateurs dans 56 pays , le Groupe bénéficie d’une implantation internationale qui lui permet d’agir au plus près de ses clients, partout dans le monde . Nos équipes de la Direction de l’Ingénierie Logicielle ( DIL ) fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces . Le département IA & Big Data recherche plusieurs Ingénieurs DataEngineer (H/F) basés à Sophia Antipolis (06). QUI ETES-VOUS ? De formation Bac+4 ou Bac +5 (type école d’ingénieur), vous possédez de bonnes connaissances dans le domaine de la donnée (Data Science, Data Engineering, Stockage), en ingénierie logicielle globalement. Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, AZURE) ou privé. Principales activités que vous réaliserez : Mise en place de pipelines de traitement de données Utilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / Storm Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie) Utilisation de tous les types de stockage actuels SQL : Oracle, SQLServer, PostgreSQL NoSQL : Cassandra / MongoDB / HBase Objet : S3 / MinIO Vous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala & Java). Vous êtes à l’aise en Anglais. Vous êtes curieux(se) et rigoureux(se). Vous aimez travailler en équipe au quotidien. Pour vous le succès n’est que collectif. Vous vous reconnaissez ? Alors parlons missions … CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Le département IA & Big Data fédère et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d’une structure permettant d’accélérer la transformation des enjeux Data de nos clients. Nos savoir-faire : Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie Projets d’intégration système Nos domaines métier : Maintenance prédictive, Traitement d’image pour la santé Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de réponse Aerospace : Centre de Mission et de Contrôle, Dynamique du Vol, Qualité Image, Occupation des sols, Sondage Atmosphérique Nos partenaires : Recherche : INRIA, CNRS, 3IA Externes : Nvidia, Microsoft En collaboration avec les membres de notre département : Vous contribuerez au développement et à la scalabilité de nos plateformes au travers d’activités d’automatisation, de création de services managés et d’API. Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes. Vous participerez à l’intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com) Vous collaborerez à nos publications, conférences et webinars. Vous serez partie prenante de la 3ème révolution industrielle impactant tous les secteurs d’activité, énergie, santé, industrie, … La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant à cette offre . Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is seeking multiple Data Engineers to join their team in Sophia Antipolis, France. The ideal candidates will have a degree in engineering or related field, experience in data engineering, software engineering, and cloud knowledge. Responsibilities include designing data processing pipelines, developing on Hadoop stacks, and utilizing a variety of storage types. Successful candidates will contribute to the scalability of platforms, coordinate AI and Big Data operations, and participate in the integration of secure technical platforms.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
407,37125,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_6XzD6Lx,Data Engineer,TotalEnergies Digital Factory,"{Kafka,Spark,Azure,SQL,Python}",Télétravail partiel possible,N,"Logiciels, Big Data, Energie",CDI,2022-10-18,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. TotalEnergies a décidé d'accélérer la production interne de solutions digitales pour ses activités en créant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilité et l'esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Nous créons et déployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. Nous considérons les personnes comme la ressource la plus précieuse pour réussir, c'est pourquoi nous tenons non seulement à recruter les meilleurs talents, mais aussi à créer des liens uniques entre nos employés. En accord avec les politiques HSE de la compagnie et celles de la Digital Factory, le/la Data Engineer intégrera l'équipe « Delivery », qui intervient dans la production des Minimum Viable Products (MVPs). En soutien de la Squad dans l'organisation des données, cette équipe évolue dans un contexte agile (scrum/scrumban), en mode itératif et co-constructif, en s'appuyant sur l'intelligence collective. Votre rôle est de garantir la qualité des pipelines data du produit, assurer le développement des programmes pour collecter, préparer, transformer et diffuser les données. Missions : Concevoir, construire et intégrer des données, au sein de la squad et en collaboration avec les autres squads Assurer le stockage, la consommation, l'intégration et la gestion des données des cas d'utilisation. Faire l'analyse de l'accessibilité des données et recommander des solutions pour leur intégration. Coordonner la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de données. Intégrer les données dans le data lake. Collaborer avec les data scientists pour la réalisation des modèles de prédiction. Produire un code de qualité, mettre en place des tests automatisés pour le contrôler. Interagir avec les architectes et les autres data engineers, pour s'assurer de l'efficacité des solutions et apporter des préconisations techniques Maîtriser les bonnes pratiques de monitoring des flux de données. Assurer la veille technologique sur les architectures data et les nouvelles technologies. Coacher et accompagner la communauté des Data Engineers de la Digital Factory. Vous êtes diplômé/e d'un Master ou d'une école d'ingénieur spécialisée en informatique ou mathématiques. Vous avez au minimum 2 ans d'expérience en data engineering. Vos compétences techniques sont reconnues en Python, Spark et SQL. Vous avez une bonne connaissance sur les bases de données relationnelles et non relationnelles Vous mettez en place des pratiques de test systématiques pour vérifier la qualité de votre code. Vous avez la capacité à concevoir et à mettre en uvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle. Vous avez une première expérience sur un provider de Cloud, Azure de préférence et maîtrisez la scalabilité en temps réel (Kafka). Vous comprenez le machine learning. Vous avez un niveau de français et d'anglais courant.","TotalEnergies is seeking a Data Engineer with at least 2 years of experience in data engineering to join its Digital Factory team responsible for producing Minimum Viable Products. The successful candidate will be responsible for designing, building, and integrating data, ensuring the quality of data pipelines, developing programs to collect, prepare, transform, and disseminate data, and collaborating with data scientists to produce prediction models. The candidate must have experience with Python, Spark, SQL, and cloud providers like Azure, an understanding of machine learning, and the ability to implement large-scale data loading, manipulating, processing, analyzing, and exploring solutions.",Bac +5 / Master,Entre 250 et 2000 salariés,> 1 an,2,1,0.04154662416233763
406,36869,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-f-h_lille,Data Engineer,Atos,"{GCP,AWS,Talend}",Télétravail partiel possible,N,IT / Digital,CDI,2022-10-12,"Atos est un leader international de la transformation digitale avec plus de 110 000 collaborateurs dans 73 pays et un chiffre d’affaires annuel de plus de 11 milliards d’euros. Numéro un européen du Cloud, de la cybersécurité et des supercalculateurs, le groupe fournit des solutions intégrées de Cloud Hybride Orchestré, Big Data, Applications Métiers et Environnement de Travail Connecté. Partenaire informatique mondial des Jeux Olympiques et Paralympiques, le Groupe exerce ses activités sous les marques Atos, Atos Syntel, et Unify. Atos est une SE (Société Européenne) cotée sur Euronext Paris et fait partie de l’indice CAC 40. La raison d’être d’Atos est de contribuer à façonner l’espace informationnel. Avec ses compétences et ses services, le groupe supporte le développement de la connaissance, de l’éducation et de la recherche dans une approche pluriculturelle et contribue au développement de l’excellence scientifique et technologique. Partout dans le monde, Atos permet à ses clients et à ses collaborateurs, et plus généralement au plus grand nombre, de vivre, travailler et progresser durablement et en toute confiance dans l’espace informationnel. La Mission : Au sein de l'équipe Data, en tant que Data Engineer, vous participez à la réalisation de divers projets et vos missions sont : Apporter votre connaissance en Big Data permettant la manipulation des données Concevoir les plateformes permettant de traiter des volumes de données importants Mettre en place des bases de données Préparer le pipeline de données pour que les données déployées soient sécurisées et claires afin d'être analysées et transformées Environnement technique : Stambia, ODI, Talend, AWS, GCP Nous rejoindre c’est : Faire partie d’une équipe à taille humaine en fort développement dans la région Hauts de France Echanger directement avec ton manager de proximité T’ouvrir à de belles perspectives de carrière dans le groupe : priorité à la mobilité interne Construire ta trajectoire professionnelle : certifications & formations, missions Bénéficier d’un bon environnement de travail : télétravail, locaux neufs et faciles d’accès dans le centre-ville de Lille, afterworks, … Un package salarial attractif : CDI, Rémunération selon profil, Frais de transport, Tickets Restaurants, Mutuelle intéressante, Prime de vacances, Plans Entreprise (épargne, actionnariat), CET, avantages CSE (billetterie, vacances, …) #TheFutureIsOurChoice#JoinAtosTeam #Atos Profil recherché : Qui êtes-vous ? De formation ingénieure en informatique Bac + 5 informatique ou scientifique vous justifiez d'une expérience réussie en tant que scrum master. Une bonne communication orale et écrite en français est fortement recommandé ainsi qu'un niveau d’anglais professionnel . Savoir- être : Bon esprit d'analyse et de synthèse, sens de l'organisation et de la qualité, force de proposition, rigueur, travail en équipe, adaptabilité.","Atos, a global leader in digital transformation, is seeking a Data Engineer with strong skills in Big Data, database design, and data security. The ideal candidate must have a degree in computer science or a related field, along with experience working on large data projects. The role involves designing platforms to handle large volumes of data, creating databases, and setting up data pipelines. Atos offers an attractive salary package, opportunities for career growth, and a supportive work environment with new, easy-to-access offices in Lille. Candidates should have strong communication skills, both written and verbal in French and English, and possess analytical, organizational, and teamworking skills.",Bac +3,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
405,36688,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-tableau-dataviz-bi-factory-f-m-d_paris,BI Engineer Tableau / DataViz - BI Factory,Decathlon Technology,"{AWS,dataset,github,GCP,SQL,Tableau}",Télétravail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-10-12,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour répondre aux mieux a son ambition de pilotage par la data, Decathlon a organisé une DATA UNIT à laquelle la BI Factory est rattachée. TA RESPONSABILITE : Ta mission principale consiste à : Répondre à des demandes d’analyses récurrentes de KPIs en mettant à disposition des métiers, de manière automatique et régulière, des outils de data visualisation performants. Intervenir dès la finalisation du cadrage projet par le Project Manager jusqu’à la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : Project Manager, les autres BI Engineers, les métiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e BI Engineer, basé-e, au choix à Paris, Lille, Lyon ou Nantes. Le périmètre technique : maîtrise du SQL maîtrise d’une BDD maîtrise d’un ETL maîtrise d’un outil de datavisualisation (idéalement Tableau software) Rédaction de documentation dans github et/ou wiki Méthodologie AGILE CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience d’au moins 3 ans en développement BI et parle un Anglais courant (relation avec des équipes à l'international). Tu as déjà produit de la data visualisation performant avec Tableau Software ; Pour réussir, tu dois savoir: Comprendre le besoin métier / interagir avec les interlocuteurs fonctionnels Comprendre un modèle de données et t'en servir. Modéliser un dataset afin de développer des visualisations en assurant les performances techniques Développer le flux d’extraction des data nécessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages métiers exprimés lors du cadrage Maîtriser les technologies utilisées et les bonnes pratiques de développement Partager ton avancement et les difficultés rencontrées lors des instances AGILE dédiées. Rédiger la documentation technique permettant d’assurer un run efficace Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et la vie en équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a BI Engineer to provide automated and regular data visualization tools to the company's departments. The successful candidate must have at least three years of experience in the development of BI and be able to develop data extraction flows, understand business requirements, deal with technical performance issues, and be fluent in English. The position is based in Paris, Lille, Nantes, or Lyon, and offers two days of remote work per week, flexible work locations, and internal and external training opportunities, among other benefits. Decathlon is committed to inclusion and non-discrimination, such as promoting diversity, innovation, and performance.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
404,36585,https://www.welcometothejungle.com/fr/companies/thefork/jobs/data-analytics-engineer_paris,Data Analytics Engineer,TheFork,"{dbt,SQL,Airflow,Python}",Télétravail partiel possible,N,"Application mobile, Tourisme, FoodTech",CDI,2022-10-12,"TheFork, a TripAdvisor® Company is the leading online restaurants reservation platform in Europe, Australia and Latin America, with a network of more than 80,000 restaurants worldwide, more than 30.5 million monthly visits and present in 22+ countries around the globe. TheFork connects restaurants and diners. Through TheFork (website and application), as well as through TripAdvisor, users can easily select a restaurant according to preference criteria (such as the localisation, type of cuisine, restaurant type and average price), consult user reviews, check real-time availability and instantly book online. From the restaurants’ side, TheFork provides them with a software solution, TheFork Manager, which enables restaurants to optimize reservations management, streamline operations and ultimately improve service and revenues. TheFork team aims to inspire and enable people to confidently discover, experience and share food. We operate under a shared set of values that define how we do business and how we interact with our colleagues, our partners, our customers and our food community. We strongly believe that building a diverse workforce of people from all walks of life helps us have a richer, more vibrant, more successful workplace. W elcome to our fabulous world. 🍴 We are TheFork . Our mission is to bring happiness through amazing dining experiences, thanks to our 3 main products : 📱 TheFork App : the restaurant discovery and booking app for every occasion 🖥️ TheFork Manager : the tool to digitize restaurant operations and be in full control of your business 💳 TheFork Pay & gift cards : the new and amazing dining payment experience Creator of a unique model that disrupted the restaurant industry 15 years ago, we are now the leading dining platform across Europe and Australia. We are experiencing an exciting period of growth, and we need the greatest folks onboard. Together, we will make our wildest dreams come true! We strongly believe that our mission can only be achieved if we also bring happiness to our working environment. We do this by providing a flexible, multicultural and positive environment where each individual has the space to grow. We nurture this happy culture through our core values : We are better together - We act like an owner - We genuinely care for our users and customers - We believe in transparency - We never stop learning - Speed wins Oh! And we are also part of the big Tripadvisor family ❤️ With love, Your future buddies, the Forkies. Data / Analytics Engineer @ TheFork What You Will Do: As a Data / Analytics Engineer, you will be part of the Business Intelligence Factory (itself part of the Data team, a transverse organization supporting our Business) The Data Team has 3 missions : Accelerate the Business thanks to data and insights Support company transformation towards a Data-driven Culture Develop a valuable and actionable data asset As a member of the BI FactoryBI @ TheFork, you will help the company leverage its data asset to make the right business decisions thanks to modern and cutting-edge business intelligence solutions. You will deliver quality products conforming to business requirements, data quality, data management and business intelligence best practices using an agile methodology. You will report to the BI Factory Manag and be part of a team of ~40 People including Analytics, BI and Data Engineers Data Scientists Web Analysts Data Analysts Product owners & product managers Role As Analytics Engineer, you will be part of a team of data integration and BI experts which role is to Gather and understand business requirements (autonomously or teamed up with data analysts) Design and develop robust, scalable and industrialized BI assets (data integration flows / ETL, dimension and fact tables, datamarts, metrics, KPIs,…) aiming to facilitate and make consistent the data consumption supporting Business teams in the monitoring of their performance and goals achievement Help the team leverage moden data stack tools and setup best practices in order to bring the BI Factory to the next level Help other analytics engineers upskill on technical aspects of the data platform as Airflow, dbt, Python Develop support approaches (documentation, communication, tooling, training, etc.) towards technical & business teams to ensure progressive acceleration of the organization towards an easier and more systematic usage of BI assets in their day-to-day activities Play a temple keeper role to ensure that TheFork BI ecosystem develops in an optimal and consistent way (efficient, optimized, consistent overall metrics and KPIs, etc.) You will mainly have a technical role with a foot in the business. You will partner with various functional (data analysts) and technical (data engineers, data scientists, product engineers, ...) teams in order to turn technical issues into user friendly, business oriented BI solutions. You will be continuous-improvement-oriented You will identify areas of improvement to make existing ETL and reporting processes more efficient You will work with data and business teams to identify bottlenecks, possible solutions, and determine resource requirements You will bring to TheFork your knowledge of the State-of-the-art for data integration / ETL development (methodology, tooling, etc.) Who You Are: You are working in an autonomous, proactive, accountable and solution-oriented way: you don’t wait to be told what to do. You deliver high in-depth and reliable analysis in a fast-paced environment, with excellent organization and time management You demonstrate an obsession towards excellence: you systematically consider that good is not enough and constantly consider how to improve and reach the next level of quality, performance and impact You play agile and fast: delivering in a fast-paced environment is an easy business for you. You are comfortable to manage several topics in parallel, with different stakeholders involved. You are familiar with agile methodologies. You bring the outside in: seeking excellence, you have developed habits to benchmark and consider how other companies are doing, what best practices could be source of inspiration and systematically consider how they can apply in your specific business context You have a Master’s Degree from a Engineering School You have 4 to 8 years of experience in the Data domain You master data transformation patterns (ELT), ideally on a modern tool (example: dbt) You have experience in Airflow and Python You master SQL You have a sharp knowledge of BI practices Dimensional data modeling techniques ETL design Reporting / Data visualization techniques You are able to challenge the data integration flows architecture Your soft skills are a key personal asset to develop partnership interactions with other departments Excellent French & English verbal and written communication skills (Spanish or other European language is a plus) The position is based in Paris What we offer you: 😄 An awesome team (not everybody like our jokes, but we try our best) 🏠 A Permanent contract (that can be useful in life) ⚖️ Flexible working environment (2 days home office per week) 💚 Complementary time off to spend with your loved ones 💸 Competitive fixed salary, bonus and equity (yes, equity!) 🍕 Lunch vouchers available for each working day (because yes, we like to try our best restaurants ) 🌎 International teams - More than 30 nationalities and 16 offices worldwide 🏳️‍🌈 Highly inclusive working environment 🤸‍♀️ Lifestyle benefits that can be used to reimburse physical, leisure activities, family support, travel etc 🎓 Continuous learning and development programs (with full access to LinkedIn Learning!) 👶 Financial benefits in the events of a birth, adoption, pacs, or wedding 😌 Free access to the Calm app 🏡 Housing assistance plan to help find accommodations, or with repairs for your home 🏥 72% of health insurance fully covered by the company 👩‍🦽 Life Insurance and Disability at no cost to the employee 🍴 Amazing offices with dining, coffee point on each floor, and leisure area 🎤 Team building events (we love karaoke. A lot. A lot.) #LI-AD1","The Fork, a leading online restaurant reservation platform, is seeking a Data/Analytics Engineer to help accelerate its business with data and insights, as well as support the company's transformation towards a data-driven culture. The ideal candidate will be proactive, solution-oriented, demonstrate an obsession towards excellence, and have experience with data transformation patterns, Airflow, Python, SQL, and BI practices. The position is based in Paris and offers a flexible, multicultural, and positive environment, as well as competitive compensation and benefits.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
403,35937,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-engineer-data-science-team_barcelone,Data Science Engineer,Veepee,"{Azure,Flink,Beam,Git,Kubernetes,HDFS,HBase,AWS,scale,Kafka,dbt,Spark,BigTable,BigQuery,GCP,Java,SQL,Python}",Télétravail partiel possible,N,E-commerce,CDI,2022-09-28,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire européenne avec la convergence des différentes sociétés qui le composent et leurs 6 000 collaborateurs vers une seule et même marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd’hui présent dans 14 pays et devient un acteur majeur du commerce digital européen, avec 72 millions de membres et un volume d’affaires de 3,7 milliards d’euros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour réveiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos stratégies, afin de proposer la meilleure expérience possible à nos clients. Vous avez soif d’apprendre ? Veepee vous permet de construire votre parcours parmi une pluralité de métiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes… prenez part à une aventure humaine au cœur d’enjeux digitaux. Impatients de les rencontrer ? Ils ont hâte aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a data engineer, you will join one of our Data Science Teams, which is fully cloud-native and distributed between Paris, Barcelona and Brussels. The team’s responsibility lies in providing forecasts to operational and business entities within Veepee. Your mission will be to support the team in building data pipelines, deploying machine learning models on GCP and developing microservices to expose ML-based predictions to customer-facing products. Responsibilities: Develop, deploy and maintain high-load API’s on Kubernetes with strong SLA requirements and high business value; Version and deploy machine learning models at scale in a cloud environment; In the context of machine learning projects, develop and maintain data pipelines and ensure data quality; Identify, design, and implement internal process improvements: automating manual processes, optimizing code and data delivery, re-designing infrastructure for greater scalability etc; Keep improving your technical knowledge and expertise by animating the Veepee data engineering community, attending conferences, contributing to open-source projects, organizing and attending meetups. Requirements: At least 3 to 5 years experience in software engineering, preferably in the data field; Strong knowledge of Java, SQL, and Python; Experience with data processing technologies like Apache Beam (or Flink), Spark, Kafka, etc; Experience with distributed data systems: No-SQL databases (HBase, BigTable), data lakes (BigQuery), storage (HDFS); Used to work in a cloud environment (GCP, AWS, Azure,...); Familiar with the concepts of a microservice architecture. Prior experience with deploying containers on a platform like Kubernetes and its ecosystem is a big plus; Proficiency with version control Git; Experience with tools like dbt is a plus; Interest in machine learning and data analytics; A strong team player, willing to share knowledge with other team members and help out where needed; Strong verbal and written English language skills. What we offer: The dynamic and creative environment within international teams; Opportunity to work on a large-scale e-commerce platform with tens of millions of users across Europe; Be part of our vpTech IT community of >800 tech enthusiasts; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences sponsored by vpTech locally and internationally; 3 days of remote work per week or remotely if you prefer so; Excellent team spirit and thriving after-work atmosphere. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you’ll be sure to find your place, no matter the technology you want to work with. If you love to try things why don’t you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, the conglomerate made up of Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic, and vente-privee, achieved a €3.7bn ($4.4bn) turnover in 2018. The company is now taking a leading role in European digital commerce, with more than 72 million members in 14 countries. As a data engineer, the successful candidate will join one of the Data Science Teams, working on responsibilities that include developing, deploying and maintaining high-load APIs on Kubernetes, versioning and deploying machine learning models in a cloud environment, and automating manual processes.
",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
402,35839,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-science-engineer_nice,Data Science Engineer,Veepee,"{Azure,Flink,Beam,Git,Kubernetes,HDFS,HBase,AWS,scale,Kafka,dbt,Spark,BigTable,BigQuery,GCP,Java,SQL,Python}",Télétravail partiel possible,N,E-commerce,CDI,2022-09-28,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire européenne avec la convergence des différentes sociétés qui le composent et leurs 6 000 collaborateurs vers une seule et même marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd’hui présent dans 14 pays et devient un acteur majeur du commerce digital européen, avec 72 millions de membres et un volume d’affaires de 3,7 milliards d’euros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour réveiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos stratégies, afin de proposer la meilleure expérience possible à nos clients. Vous avez soif d’apprendre ? Veepee vous permet de construire votre parcours parmi une pluralité de métiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes… prenez part à une aventure humaine au cœur d’enjeux digitaux. Impatients de les rencontrer ? Ils ont hâte aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a data engineer, you will join one of our Data Science Teams, which is fully cloud-native and distributed between Paris, Barcelona and Brussels. The team’s responsibility lies in providing forecasts to operational and business entities within Veepee. Your mission will be to support the team in building data pipelines, deploying machine learning models on GCP and developing microservices to expose ML-based predictions to customer-facing products. Responsibilities: Develop, deploy and maintain high-load API’s on Kubernetes with strong SLA requirements and high business value; Version and deploy machine learning models at scale in a cloud environment; In the context of machine learning projects, develop and maintain data pipelines and ensure data quality; Identify, design, and implement internal process improvements: automating manual processes, optimizing code and data delivery, re-designing infrastructure for greater scalability etc; Keep improving your technical knowledge and expertise by animating the Veepee data engineering community, attending conferences, contributing to open-source projects, organizing and attending meetups. Requirements: At least 3 to 5 years experience in software engineering, preferably in the data field; Strong knowledge of Java, SQL, and Python; Experience with data processing technologies like Apache Beam (or Flink), Spark, Kafka, etc; Experience with distributed data systems: No-SQL databases (HBase, BigTable), data lakes (BigQuery), storage (HDFS); Used to work in a cloud environment (GCP, AWS, Azure,...); Familiar with the concepts of a microservice architecture. Prior experience with deploying containers on a platform like Kubernetes and its ecosystem is a big plus; Proficiency with version control Git; Experience with tools like dbt is a plus; Interest in machine learning and data analytics; A strong team player, willing to share knowledge with other team members and help out where needed; Strong verbal and written English language skills. What we offer: The dynamic and creative environment within international teams; Opportunity to work on a large-scale e-commerce platform with tens of millions of users across Europe; Be part of our vpTech IT community of >800 tech enthusiasts; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences sponsored by vpTech locally and internationally; 3 days of remote work per week or remotely if you prefer so; Excellent team spirit and thriving after-work atmosphere. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you’ll be sure to find your place, no matter the technology you want to work with. If you love to try things why don’t you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, the newly unified conglomerate comprising of Privalia, vente-exclusive, Designer & Friends, Eboutic, and vente-privee, is looking for a data engineer to join one of its data science teams distributed between Paris, Barcelona, and Brussels. The team is responsible for developing machine learning models and providing operational forecasts. The ideal candidate should have experience in software engineering and a strong knowledge of Java, SQL, and Python. Experience with data processing technologies, distributed data systems, and cloud environments is preferred. Additionally, the candidate should be interested in machine learning and data analytics and have strong communication skills.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
401,35742,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineer-confirme-e-h-f_croix,Data Engineer Confirmé·e -,Decathlon Technology,"{Databricks,Talend,Scala,Redshift,Airflow,Logstash,Lambda,S3,Kibana,Druid,GitHub,github,Spark,BigQuery,GCP,Java,Python,Elastic}",Télétravail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-09-28,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. Mission DECATHLON accélère sa transformation digitale avec pour ambition de devenir LA plateforme numérique du sportif qui permettra aux utilisateurs d'accéder à tout l'univers du sport en un clic ( Equipement , Activities , Coaching ). Pour accompagner cette transformation, les équipes Data évoluent et mettent au coeur de leurs enjeux: La qualité et l’accessibilité de la donnée La scalabilité des processus associés au cycle de vie de la donnée (ingest, store, transform, expose) L’élasticité des infrastructures et des services Si vous avez envie de contribuer à cette transformation et de co-construire la plateforme data de demain, alors vous serez intégré·e dans une équipe data domain centric. Vos responsabilités Vous serez en charge de: Construire des pipelines scalables de données structurées et non structurées Définir la stratégie de nos stacks techniques et garantir la CI/CD. Maintenir et repenser les datasets et pipelines existants pour servir une plus large variété de use cases. Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents. Contribuer activement à notre communauté de data engineers. Compétences techniques souhaitées: Vous comptez déjà une expérience sur l'environnement Big Data d’Amazon Web Services. Vous savez utiliser ses composants (Lambda,Redshift, S3) ainsi qu’optimiser leurs performances. Vous maîtrisez l’un des langages suivants : Python, Scala, Java. Vous maitrisez la mise en oeuvre de pipeline de processing de données. Avoir déjà travaillé avec les technologies suivantes est un plus : Spark Databricks Airflow Druid Stack ELK (Elastic Search, Logstash, Kibana) Environnement Google GCP ( BigQuery, Composer, Data Studio) Talend <<<<<<<<<< english version >>>>>>>>>> DECATHLON is accelerating its digital transformation, with the ambition to become THE sports digital platform that will enable users to reach the sports universe with one click ( Equipment , Activities , Coaching ). The Data teams are evolving to support this transformation and put a special emphasis on the following topics: Data quality and accessibility Scalability of processes associated with the data lifecycle (ingestion, storage, transformation, exposure) Infrastructure and service scalability/elasticity Join the data-domain centric teams if you would like to contribute to the digital transformation and collaborate in the building of the data platform of tomorrow. Your accountability You will be in charge of: Building structured and unstructured, scalable data pipelines Defining the strategy of our technology stacks and guaranteeing CI/CD Maintaining and improving existing data sets and pipelines, in order to serve a wider variety of use cases Enabling smart analytics by building robust and relevant data sets Actively contributing to our data engineer community Required technical skills: You have extensive experience with the Amazon Web Services big data environment. You have excellent knowledge of its components (Lambda, Redshift, S3) and of how to optimize their performance. You have extensive knowledge of and experience with at least one of the following languages: Python, Scala, Java. You have extensive experience in setting up data processing pipelines Knowledge or experience of the following technologies a plus: Spark Databricks Airflow Druid Stack ELK (Elastic Search, Logstash, Kibana) Google GCP environment ( BigQuery, Composer, Data Studio) Talend Profil Fort d’au moins 2 ans d’expérience sur le métier, vous possédez une grande appétence technique. Vous comprenez le cycle de vie de la donnée et vous êtes à l’aise avec les concepts de data lineage, data gouvernance et data privacy. Votre bon niveau d’anglais vous permet de communiquer avec nos clients et partenaires. Vous aimez travailler en agilité dans un environnement collaboratif ( GitHub , ,Mob programming). Vous avez un sens du service développé. Sportif·ve, passionné·e et expérimenté·e Les étapes de recrutement: Votre candidature est évaluée. Peu importe le résultat, vous recevrez une réponse de notre part. Si vous êtes sélectionné·e, nous vous contacterons dans les deux semaines qui suivent votre candidature. Le processus de recrutement contiendra à minima deux entretiens avec des leaders / RH ainsi qu’un entretien technique. Ce que nous vous proposons: Flexibilité de l’organisation de travail (lieu, rythme) Liberté de choix de l'outil de travail (Mac, Windows) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétence (diversité de projets, langages et technologies) Formations internes et externes Actionnariat Primes mensuelles et trimestrielles Nous étudions aussi les candidatures à temps partiel. Decathlon est engagé dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien . <<<<<<<<<< english version >>>>>>>>>> Profile You have a strong technology/technical interest. You have at least two years of data engineering experience. You understand the data lifecycle and are familiar with concepts of data lineage, data governance and data privacy. You are comfortable communicating with customers and partners in English You value working in an agile and collaborative environment (github, mob programming, etc) You have a strong sense of service You are passionate about sports Recruitment steps: Following the evaluation of your application, you will receive an answer from us, no matter if positive or negative. If you are selected, we will contact you within two weeks of your application, to setup at least two interviews with leaders/HR, as well as a technical interview. We consider also application for a part time job. What we propose: Flexibility in the organization of your work (location, time) Choice of your preferred laptop (Mac, PC) Local project team International mobility Training and development (project diversity, languages, technology; on-the-job and formal trainings) Company share plans Monthly and quarterly bonus scheme Decathlon commits to inclusion and non-discrimination, and acts daily in favor of people with disabilities, seniors, social diversity, and gender equality. We recruit mainly based on personality, and diversity within our teams is a major objective, since it brings innovation and performance. If you would like to know more about our commitments, please follow this link .","Decathlon is seeking a Data Engineer to contribute to the company's digital transformation and collaborate in the building of the data platform of tomorrow. The successful candidate will be responsible for building structured and unstructured, scalable data pipelines, defining the strategy of technology stacks, and actively contributing to the data engineer community. They should have at least two years of data engineering experience, a strong technical interest, and knowledge of data lineage, governance, and privacy. Experience with AWS components, such as Lambda, Redshift, and S3, as well as experience with Python, Scala, or Java, is required. Knowledge or experience with Spark, Databricks, Airflow, Druid Stack, ELK, Google GCP, or Talend is a plus.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
399,34932,https://www.welcometothejungle.com/fr/companies/hellofresh/jobs/data-engineer-bi-m-f-x_paris,Data Engineer & BI (m/f/x),HelloFresh,"{durable,color,Airflow,scale,Docker,Github,SQL,Python,Tableau}",Télétravail partiel possible,Paris,"Application mobile, E-commerce, FoodTech",CDI,2022-08-08,"La mission HelloFresh ? Changer notre façon de manger. Pour toujours. Leader mondial des Box à Cuisiner, HelloFresh a distribué plus de 280 millions de repas en 2019 et atteint près de 3 millions de clients actifs au quatrième trimestre 2019. Présente dans 14 pays, la start-up berlinoise créée il y 8 ans a dépassé tous ses objectifs. Le Financial Times la place en tête de son classement Europe’s Fastest Growing Companies de 2017. HelloFresh compte aujourd’hui plus de 5,000 collaborateurs. Quel est leur ingrédient secret ? Des recettes inspirantes et savoureuses, un menu complet et varié, des ingrédients frais et de saison, le tout livré chez vous et pensé pour vous faciliter la vie. Adieu courses, listes et tracas. HelloFresh challenge la supply chain de l’industrie agroalimentaire en alliant excellence opérationnelle, souci du client et conduite du business au plus près des datas. En 2021, ils cherchent à renforcer rapidement leur présence en France et développent une équipe et des bureaux au cœur de Paris. At HelloFresh, we want to change the way people eat forever by offering our customers high quality food and recipes for different meal occasions. Over the past 10 years, we've seen this mission spread around the world and beyond our wildest dreams. Now, we are a global food solutions group and the world's leading meal kit company, active in 17 countries across 3 continents. So, how did we do it? Our weekly boxes full of exciting recipes and fresh ingredients have blossomed into a community of customers looking for delicious, healthy and sustainable options. The HelloFresh Group now includes our core brand, HelloFresh, as well as: GreenChef, EveryPlate, Chef's Plate, Factor, and Youfoodz. Rejoins une superstar de la foodtech en France Chez HelloFresh, nous bousculons les habitudes alimentaires des français grâce à nos Box à cuisiner ! Notre ambition ? Révolutionner le quotidien de nos abonnés, en promouvant une façon plus durable de cuisiner et en leur faisant découvrir de délicieuses recettes, créatives et équilibrées. L’alliance parfaite entre technologie et gastronomie, pour un maximum de gourmandise. HelloFresh est présent dans plus de 17 pays en 2022. La France, un jeune marché lancé en 2019, connaît une ascension fulgurante : nous y sommes déjà leaders depuis 2021. Le moment parfait pour rejoindre notre équipe et avoir un impact fort dans l'une des scales up françaises les plus prometteuses ! Comment rendre tout cela possible ? Grâce à une équipe débordante de talents et de dynamisme et une ambition commune de conquérir le marché de la food. Le tout associé à une culture d’entreprise et un ADN uniques. Si tu souhaites prendre part à cette incroyable aventure humaine, internationale et entrepreneuriale, rejoins-nous ! Le poste : En tant que Data Engineer & Business Intelligence (BI) dans l'équipe Ops Tech et Data, reportant au Senior Ops Tech Product Manager France , tu seras au coeur de la stratégie B.I et Tech pour les opérations France. Ton rôle sera : d'analyser des données et produire des analyses stratégiques pour l’équipe Opérations France. de contribuer à construire le stack tech pour les Opérations de HelloFresh France (outils, scripts, algorithmes, optimisation, api). Tu auras un impact direct sur notre performance et les milliers de clients qui vont compter sur toi pour recevoir leur délicieuse Box HelloFresh chaque semaine ! Ce que tu feras : Identifier les KPIs clés de notre business et construire des dashboards pour les équipes Opérations Animer le processus de prévisions opérationnelles par la création de rapports et tableaux de bord (estimation vs. réel) Adapter, définir et développer nos outils tech, notamment sur la base d’outils déjà existants dans le groupe HelloFresh Coordonner les sujets Tech et BI avec les équipes internationales et locales HelloFresh Construire la projection long terme de notre capacité supply-chain, identifier les points d’amélioration et lancer les projets d’augmentation de nos capacités Ce qu’on recherche chez un.e candidat.e : Tu es issu.e d’une top école d’ingénieur ou commerce Tu as 2 à 3 ans d’expérience, en préférence dans une scale up/start up, et idéalement dans une équipe tech ou data. Tu as une passion pour la programmation et tu adores construire ou résoudre des algorithmes Tu as une excellente maîtrise de Python, Excel/ Gsheet, SQL et un fort attrait d’analyse Tu connais (ou tu as envie d’apprendre) Docker, Airflow, Tableau, Jira et/ou Github Tu es logique et structuré.e Tu parles couramment français et l’anglais (écrit et oral) Ce que nous t’offrons ? Un environnement dynamique et international, avec une culture d'entreprise et un ADN forts De délicieuses réductions sur nos Box HelloFresh Une équipe française bienveillante, passionnée, proactive et dynamique Des bureaux au coeur de Paris Avantages employés (mutuelle Alan Blue, réduction sur le transport, Gymlib, carte SWILE, budget de training) Voilà le déroulé du process de recrutement : Nous examinons ton CV et ta lettre de motivation. Si c’est un match, nous t’invitons à une série d’entretiens et un case study. Nous nous engageons à enchaîner rapidement les entretiens, afin de t’accueillir chez HelloFresh au plus vite ! About HelloFresh We believe that sharing a meal brings people of all identities, backgrounds, and cultures together. We are committed to celebrating all dimensions of diversity in the workplace equally and ensuring that everyone feels a sense of inclusion and belonging. We also aim to extend this commitment to the partners we work with and the communities we serve. We are constantly listening, learning, and evolving to deliver on these principles. We are proud of our collaborative culture. Our diverse employee population enables us to connect with our customers and turn their feedback into meaningful action - from developing new recipes to constantly improving our process of getting dinner to our customers’ homes. Our culture attracts top talent with shared values and forms the foundation for a great place to work! At HelloFresh, we embrace diversity and inclusion. We are an equal opportunity employer and do not discriminate on the basis of an individual's race, national origin, color, gender, gender identity, gender expression, sexual orientation, religion, age, disability, marital status or any other protected characteristic under applicable law, whether actual or perceived. As part of the Company’s commitment to equal employment opportunity, we provide reasonable accommodations, up to the point of undue hardship, to candidates at any stage, including to individuals with disabilities. We want to do adapt our processes and create a safe space that welcomes everyone so please let us know how we can accommodate our process. In case you have any accessibility requirements you can share that with us in the application form. To learn more about what it's like working inside HelloFresh, follow us on Instagram and LinkedIn","HelloFresh, a global food solutions group and the world's leading meal kit company, is seeking a Data Engineer & Business Intelligence (BI) to join its team in Paris, France. The ideal candidate should have experience working in a tech or data team in a start-up or scale-up and have a passion for programming. The role will involve analyzing data and producing strategic analysis for the Operations team, building the tech stack for HelloFresh France's operations, and coordinating tech and BI with international and local teams. HelloFresh offers a dynamic and international environment, employee benefits, and opportunities for growth. The company is committed to diversity and inclusion and welcomes candidates from all backgrounds.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
433,49602,https://www.welcometothejungle.com/fr/companies/atawiz/jobs/data-engineer_paris,Data Engineer,Atawiz,"{Microsoft,NoSQL,Databricks,Scala,Spark,Azure,SQL,Hadoop,Python}",Télétravail partiel possible,"6, Rue de la Victoire, Paris, 75009","Application mobile, Logiciels, SaaS / Cloud Services, Big Data",CDI,2023-02-07,"Pour la petite histoire, Atawiz a été créé en 2016, pour devenir le cabinet d’expertise spécialisé dans le web, la data et le cloud que l’on connaît aujourd’hui. Pure Player Microsoft dès l’origine, nous sommes Microsoft Gold Partner dans plusieurs domaines de compétences et partenaire Databricks. Les domaines d’expertise d’Atawiz s’adaptent aux nouveaux enjeux des entreprises Au-delà d’un groupe d’experts, nous sommes des passionnés qui collaborent ensemble dans différents domaines d’expertises répondant à des enjeux majeurs pour nos différents clients : Le Cloud, spécialement Azure Le DevOps Le Big Data Le développement d’application mobile et web Les architectures micro-services Alimenté par une forte culture d’entreprise, chaque salarié est l’acteur d’un environnement de travail qui se veut convivial et respectueux des valeurs de tous. Entre esprit de challenge, bon sens, pragmatisme et communication, Atawiz a su regrouper en son sein des personnalités aussi différentes qu’expertes dans leurs domaines. Votre rôle au sein d’ATAWIZ Intégré(e) à nos équipes agiles, vous participez à la mise en place de plateformes data selon les meilleures pratiques. En qualité de Spécialiste, vous intégrez la squad Data sur de vastes projets de stratégie de données. Vous évoluez dans un environnement Cloud principalement Microsoft Azure mais également dans un environnement Big Data (Databricks, Spark, Ecosystème Hadoop) Vous concevez et mettez en œuvre des stratégies sécurisées d’acquisition et d’intégration de données Vous participez à la définition de l’architecture permettant de répondre aux use cases business Vous participez au design de la solution et à la construction d’un datalake / lakehouse Vous implémentez des référentiels de données dans des environnements distribués sur le cloud. Vous construisez des pipelines de données pour l’ingestion, le nettoyage et la transformation de la donnée afin de répondre aux exigences de la modélisation de données d’analyse avancée. Vous mettez à disposition la donnée pour l’analyse et la dataviz Vous participez à la mise en place de la gouvernance des données, notamment avec la Compliance (RGPD). Nous recherchons une personne dynamique, ambitieuse, rigoureuse et aimant le travail en équipe. Votre environnement technique : Python/Scala/SQL Spark Azure Data Factory Azure Databricks Azure Synape Analytics DevOps (CI/CD) Hadoop Base de données (SQL / NoSQL) La maîtrise de l’anglais est un plus Vous êtes sensible à la qualité du code et à l’optimisation des structures de données et des algorithmes (sorting, indexation, etc.) En tant qu’ingénieur développeur (BAC+5) avec une expérience professionnelle de 4 ans minimum dans le data engineering, nous attendons de vous une connaissance de tout ou partie des technologies précitées (ou équivalentes). Un premier échange téléphonique avec notre Senior Talent Acquisition Specialist pour faire connaissance. Un entretien teams avec l’un de nos experts techniques pour vous challenger techniquement. Pour finir un entretien avec le CEO pour découvrir nos projets futurs.","Atawiz, a web, data, and cloud specialist company, is looking for a dynamic, ambitious, and collaborative data engineer to join their Agile team. The ideal candidate should have at least 4 years of experience in data engineering and expertise in technologies such as Azure, Databricks, Spark, Hadoop, SQL/NoSQL databases, Python/Scala/SQL, and DevOps. Responsibilities include implementing secure data acquisition and integration strategies, designing solution architecture, constructing datalakes, creating data pipelines, ensuring data governance compliance, and providing data analysis and visualization. Fluency in English is a plus.",Non spécifié,Entre 15 et 50 salariés,> 4 ans,2,1,0.04154662416233763
435,49914,https://www.welcometothejungle.com/fr/companies/antler-france/jobs/startup-founder-i-software-engineer-developer-data-scientist_paris,Startup Founder I Software Engineer/Developer/Data Scientist,Antler,{scale},Télétravail partiel possible,"45, Rue des Petites Écuries, Paris, 75010","Incubateur / Accélérateur, Finance, Accompagnement d'entreprises",Autres,2023-02-07,"Antler is the investor backing the world’s most driven founders, from day zero to greatness. Founded on the belief that people innovating is the key to building a better future, we partner with people across six continents to launch and scale high-potential startups that address meaningful opportunities and challenges. Knowing that exceptional founders can come from anywhere with any background, we have offices in 25 cities, including New York, London, Berlin, Jakarta, Singapore, Tokyo & Sydney. APPLY HERE 👉 https://www.antler.co/location/france 👈 Are you a full-stack software developer, data scientist, machine learning engineer, or DevOps engineer with excellent programming skills, strong problem-solving abilities, a leadership track record, and a passion for developing tech solutions using cutting-edge technologies? Have you spent your career building game-changing software/hardware? Most importantly, are you looking to build a disruptive tech venture in the vibrant ecosystem of Paris? If so, we would like to hear from you! Antler is a start-up generator and an early-stage VC. Our programs bring together experienced and driven professionals from diverse backgrounds to build strong founding teams to launch their own companies. We are present in 14 locations worldwide, have supported 2,000+ founders through our program, invested in 400+ startups, and received over 50,000+ applications. Antler provides an unrivaled setting for the world’s brightest minds looking to make a mark on the world to make it a better place. It’s where the top 1% of talent comes together, pursues purpose, and works on some of the greatest opportunities and problems of today. Whether you have built your own company before or are looking to found a company for the first time, tomorrow’s disruptive tech could be built by you. Details of the program: The program runs for an initial 10 weeks, full-time in Paris (France) and starting on the 17th of April 2023. In the first phase (10 weeks), you are required to ideate and find your co-founder(s) from the cohort of 50-70 founders. After two months you will present your team and business idea to the Antler Investment Committee. If accepted, you will receive a pre-seed investment of €150k for 10% equity with €40k program fees. If you get an investment, you will continue to be part of the program for another 3 months throughout which Antler will work closely with you to accelerate your growth. At the end of this period, Antler arranges a demo day where we invite VCs, institutional investors, and local angel investors to help you connect with investors and raise your seed round. Who are we looking for? Startup founders, serial entrepreneurs, and strong business leaders that love building new products and teams CTO’s, engineering leaders, tech leads, developers, software architects, growth hackers, product managers, designers, and anyone who has built and scaled products from scratch Experts in their field Excellent communicators People who are always on top of the latest tech trends and have a genuine passion to build next-generation products Driven and hungry individuals that want to build a successful company Life at Antler: Our ten-week, full-time program is designed to give you the best possible start for your entrepreneurial journey. Whether you have founded a company before or are just getting started, we will help you find a co-founding team among the 50-70 people that will be joining the program. Founders that join our programs come from a variety of backgrounds and have an assortment of skills and expertise. Our program will facilitate you and your co-founder to quickly build on an idea (either you come with an idea or you will be defining it with your team). If you enjoy a fast-paced, diverse, demanding, and incredibly engaging environment, join us! Benefits Potential investment at the pre-seed stage Help finding your co-founder(s) Personalized coaching sessions with business experts Shared office space at a premium co-working space with access to various amenities Access to a global network of start-up advisors and experts in their field Who are we looking for? Startup founders, serial entrepreneurs, and strong business leaders that love building new products and teams CTO’s, engineering leaders, tech leads, developers, software architects, growth hackers, product managers, designers, and anyone who has built and scaled products from scratch Experts in their field Excellent communicators People who are always on top of the latest tech trends and have a genuine passion to build next-generation products Driven and hungry individuals that want to build a successful company","Antler is seeking full-stack software developers, data scientists, machine learning engineers, or DevOps engineers with strong programming skills and leadership abilities to join their accelerator program in Paris. The program runs for 10 weeks, during which participants will ideate and find co-founders, build their businesses, and present to the Antler Investment Committee. Accepted teams receive a pre-seed investment of €150k for 10% equity with €40k program fees. Ideal applicants are startup founders or entrepreneurs, excellent communicators, and experts in their field with a passion for building next-generation products.",Bac +5 / Master,< 15 salariés,> 5 ans,2,1,0.04154662416233763
437,49709,https://www.welcometothejungle.com/fr/companies/prismic/jobs/analytics-engineer_paris_PRISM_K5ZjOke,Analytics Engineer,Prismic,"{Amplitude,Athena,AWS,dbt,Lambda,snowflake,SQL,Python}",Télétravail total possible,"9 Rue de la Pierre Levée, Paris, 75011","Logiciels, SaaS / Cloud Services",CDI,2023-02-07,"Hello. We are Prismic, a headless CMS with an API. We aim to simplify editing content on your website and make work enjoyable for developers, marketers, and content teams. We’ve built in the past four years one of the leaders in the Headless CMS market. It means that more than 10000 teams around the world store the content of their websites in Prismic. We made our mission to deliver their content in a stable and reliable way. To give you an idea, we are now serving content for dozens of thousands of Websites through our APIs and serving more than 20B of API calls every month. We managed to grow thanks to our background in architecture, our talented team, and our love for well-mastered technologies. Understanding deeply what’s happening in our system is at the core of our engineering process and we want to guarantee that this will stay true while growing our team. Because yes, we’ll grow a lot and that’s where you come into play. Prismic is a rapidly growing website builder and platform. We use data to determine the direction of the business and need help from a creative and flexible analytics engineer (you will be our first analytics engineer and will report to our head of Engineering). You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth. Prismic has already built a Customer Data Platform (using segment.com ), and we're ready to expand and move to a full fledged data warehouse architecture (including dbt, snowflake and more). You will collaborate with our platform team to build data pipelines and warehouse architecture, to process data and to build and deploy infrastructure that supports all of our data needs. We have a strong desire to gravitate our architecture toward the state of the art, and will rely on you to help us get there. What will you be doing?🔧 Your insights will help us improve our technical stack and also combine effectively with Usability Research. Your business savviness will be fueled by automated data models and confirmed through dashboard communications to keep us all aware of the status of our data and avoiding compromises in data quality. Growth will be based on pinpointing with confidence our challenges and opportunities: – Marketing: Helping in identifying the right audience, the most effective channel to communicate our promise, and properly onboard our prospect into our product. Evaluate the impact of marketing initiatives on conversion and word of mouth. – Revenue: help lead growth hypotheses and sales decisions by detecting decision makers, and communicate macro trends and patterns to drive total customer success – Product: helping our outcome-oriented product team to set their goals, evaluate the delivered value, improve user satisfaction, reduce churn, improve usage and upsell. You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth. You’re a master communicator who wants broad technical and business exposure. You’ll help to enable our business teams, our most important stakeholders, to understand and satisfy their own needs through analytics. In turn, this will help support our customers and their growing set of needs, and thus help us to grow and run our business. Your fresh ideas will be warmly welcomed. Are you the one? 🧠 – 3+ years of experience as a data analyst, analytics engineer or data engineer, mastery of data libraries – Coding (Python; SQL) – Customer data (dbt) – Leadership (rapid and autonomous assumption of new topics or tools among many teams in a new frontier) – Communication (understanding and reflection of business initiatives, including transforming needs into insights) – Data visualisation (analysis, synthesis, critical thinking, presentation, storytelling) It would be super cool (but not required) if you had experience with SaaS solutions like Segment, Amplitude, Hubspot, Google Tag Manager, and also AWS Services like Athena, Step Functions or even Lambda. If you have a tester’s mindset, all the better. A dream candidate would be a strong contributor and have all of these. What are the perks? 🎉 – Latest Macbook; – A budget for you to equip your home-office setup; – English classes for all levels; – Solving challenging problems, while building cutting-edge technology; – Working in a super culturally-diverse team, with fun and curious folks. (also other benefits, that may depend on the country you’re based in) When you come to the office, indulge! – Healthy snacks and drinks; – Yoga classes 3x/week. Afraid of missing out if you’re remote? 🌍 Worry not! You get the chance to visit us every once in a while and spend some days at the office, in Paris; We have virtual initiatives and events, for us to stay connected with each other and be able to have the precious water-cooler conversation. We also have regular global meetings, where every team member is free to raise their hand and discuss any topic with the whole company - we do our best to nurture a relaxed and informal atmosphere, where you can have the conditions to feel supported, thrive at your job and keep learning. So, no matter where you are, it’s important for us to make you a part of that culture.","Prismic, a leading headless CMS with an API, is seeking an analytics engineer to join its team. The successful candidate will be responsible for building data pipelines and warehouse architecture, processing data, and deploying infrastructure to meet the company's data needs. They will use their creativity to help the company make strategic decisions, challenge the team in growth, report to the head of Engineering, and have a strong background in data analytics, data engineering, and data visualisation. Prismic is offering a range of perks, including a budget for home-office setup, English classes, yoga classes, and healthy snacks and drinks.",Non spécifié,Entre 50 et 250 salariés,> 3 ans,3,0,0.04154662416233763
454,57128,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-science-engineering-manager-f-h_massy_CARRE_l3lyyWV,Data science Engineering manager,Carrefour,"{durable,Kubernetes,Airflow,R,Spark,BigQuery,SQL,Python,Tableau}",Télétravail partiel possible,"93 Avenue de Paris , Massy, 91300","Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux défis de notre époque, Carrefour a pour ambition de rendre le meilleur accessible à tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos équipes. Nous nous épanouissons en équipe : Métiers du commerce, métiers d'expertise, entrepreneurs unissent leurs compétences et leurs efforts pour construire ensemble une chaîne de valeur au service des consommateurs. Au plus près de nos clients ou en coulisses, chacun a un rôle à jouer mais peut compter sur les autres pour réussir. Nous veillons à ce que chacun puisse aller loin : L'envie et le mérite sont les seuls pré-requis pour nous rejoindre, accéder à une formation, changer de métier, être promu ou créer son entreprise. Nous partageons la victoire : nos collaborateurs sont engagés et nous nous engageons en retour. En offrant des rémunérations et des avantages parmi les meilleurs de notre secteur, en permettant à chacun d'être associé aux résultats, en veillant à la santé de tous. Créateur de l'hypermarché et pionnier de la consommation de masse, Carrefour reste fidèle à ses racines mais se réinvente pour permettre à chacun, chaque jour, de manger mieux : plus sain, plus local, plus responsable. Nos atouts pour y parvenir ? Un réseau multiformat de + 5 300 magasins, la création de services et d'une offre digitale de référence, une coopération renforcée avec les acteurs du monde agricole, de la chaîne alimentaire, de la Tech... En pleine transformation, la DATA France se renforce et recherche un(e) : Data science Engineering manager F/H BON A SAVOIR: CDI/ ASAP/ CADRE/MASSY L'utilisation de la data et le développement des capacités analytiques sont un axe majeur du plan stratégique du Groupe Carrefour à horizon 2027. Directement rattachée au COMEX France, l'Analytics Factory de Carrefour France est le pilier de cette transformation analytique, au service des clients et de l'ensemble des équipes métier de Carrefour France - Marketing, Marchandises, Exploitation, E-commerce, Supply Chain, Services Financiers, etc… À propos du poste Au sein du pôle de data science de l'Analytics Factory, vous mènerez une équipe rassemblant data scientists et data engineers sur des projets de science des données, au service de la définition de l'offre. L'objectif de cette équipe est de construire les solutions automatisés, fondées sur les données, pour choisir quels produits vendre, dans quel magasin, à quel prix, en adéquation avec les objectifs stratégiques de Carrefour. Ces solutions reposent notamment sur des algorithmes de machine learning et operation research. Vos missions seront de : suivre, conseiller, guider, former les différents ingénieurs de l'équipe planifier et organiser l'exécution de projets techniques complexes en collaborant activement avec les product owners, les équipes métiers et les autres équipes techniques de Carrefour recruter pour assurer l'adéquation des effectifs de l'équipe aux besoins actuels et futurs être garant des méthodologies de science des données et de développement logiciel agile de l'équipe contribuer à la conception d'architectures de services sécurisées, fiables, facilitant la maintenance évolutive Vous évoluerez dans un environnement agile et collaboratif. Vous pourrez également participer aux échanges réguliers de notre communauté d'une trentaine d'ingénieurs (data scientists, engineers, devops) : retour d'expérience, débats sur les problématiques ML, de développement logiciel, ... En tant que Engineering Manager , vous rapporterez à l' Engineering Director du département. À propos de vous Diplômé en informatique ou mathématique appliquée, au moins au niveau master, ou justifiant d'une expérience professionnelle équivalente, vous disposez de très solides connaissances sur les algorithmes d'apprentissage statistique. À l'issue d'au moins 5 années d'expérience professionnelle, vous avez développé une solide expertise et un recul sur chaque étape du cycle de vie d'un projet de data science et la manipulation de base de données à grande échelle. Vous êtes désormais capable d'aborder n'importe quel champ de la data science, et également de conseiller et guider des data scientists et data engineers juniors sur ces projets. Vous avez également participé à l'industrialisation de solutions fondées sur du machine learning, idéalement dans un contexte cloud, et maîtrisez les bonnes pratiques architecturales. Vous avez déjà managé des profils techniques, avec différents niveaux d'expérience, et vous souhaitez continuer de vous spécialiser sur ce rôle d'encadrement. Vous êtes motivés par les problématiques opérationnelles très concrètes, que l'on peut notamment rencontrer dans l'univers de la grande distribution. Pour cela, vous aimez interagir avec des professionnels, d'horizons différents. Grâce à d'excellentes qualités relationnelles et de communication, vous êtes en mesure de communiquer vos idées complexes à différents publics non-techniques.. Vous avez pris part à des projets de développement collaboratifs, et la qualité et la simplicité du code vous tiennent à cœur. Vous maîtrisez le français et êtes en mesure de mener des discussions avec les opérationnels de Carrefour France. Vous maîtrisez un anglais technique a minima. Environnement technique Python, BigQuery, Spark, Kubernetes, Terraform, Airflow Informations complémentaires Siège mondial du groupe Carrefour, Massy Possibilité de télétravail plusieurs fois par semaine. Avantage 10% Carte Pass pour le collaborateur et PEE (plan épargne entreprise) Rémunération sur 13,5 mois Chez Carrefour, nous avons à cœur de ne passer à côté d'aucun talent et sommes fiers de compter des équipes représentatives de la société dans son ensemble. Nous encourageons ainsi tous types de profils à postuler à cette offre et garantissons un processus de recrutement dénué de toutes formes de discriminations. Vos compétences : Compréhension du business et goût du commerce ; la connaissance du retail, en particulier alimentaire, est un plus Excellentes capacités analytiques et statistiques, capacité à comprendre les principes de modèles data science Très bonnes capacités dans la manipulation de grandes volumétries de données ; maîtrise d'un langage de requêtage des données (SQL , Big Query), d'outils de datavisualisation (Tableau, Google Data Studio) ; la maîtrise de Python / R est un plus Bon relationnel et capacités de synthèse écrite et orale.","Carrefour is seeking a Data Science Engineering Manager with a strong background in statistical learning algorithms and machine learning industrialisation. The successful applicant will lead a team of data scientists and data engineers in producing automated data-based solutions to contribute to the definition of Carrefour's products, in accordance with the firm's strategic goals. The ideal candidate should have at least five years of paid work experience, excellent analytical and statistical abilities and good knowledge of big data handling. Excellent communication and business comprehension skills are a must.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
469,56895,https://www.welcometothejungle.com/fr/companies/aqemia/jobs/data-engineer_paris_AQEMI_qRy8e1y,Data engineer,Aqemia,"{python,regard,color,Kubernetes,AWS,scale,K8s,instrumental,SQL}",Télétravail partiel possible,"1, Boulevard Pasteur, Paris, 75015","Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, Santé",CDI,2023-03-26,"Aqemia is a next-gen pharmatech company generating one of the world’s fastest-growing drug discovery pipeline. Their mission is to design fast innovative drug candidates for dozens of critical diseases. What sets them apart is their unique quantum and statistical mechanics algorithms fueling a generative AI to design novel drug candidates. The disruptive speed and accuracy of their technology platform allows them to scale drug discovery projects as technology projects. At Aqemia you will work in a multi-disciplinary team of passionate drug hunters, AI engineers and developers who are committed to our mission of finding many drugs, at high pace, to cure diseases. As part of our growing team, you will enjoy a fast-paced, challenging, science-driven and creative environment, working at the very forefront of AI & Deep physics-powered drug discovery. This is a tremendous opportunity to bring your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team. We are looking for highly skilled and collaborative individuals who are naturally curious, have a passion for learning and solving complex problems with a “can-do” mindset. If this sounds exciting to you, come and join us! The difference you’ll make As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia's engineering teams. You will also support engineering Teams to build their Data pipeline and assets. This way, you will be instrumental in all engineering teams' success. What you'll do Contribute in defining the relevant Data Architecture and stack for Aqemia Contribute to build the relevant Data infrastructure for Aqemia in AWS In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets Support engineering team in designing their Data pipelines and assets Bring the Data Engineering expertise in engineering projects from design to delivery Your profile 2+ years experience as a Data or Software engineer in an engineering team of 4+ engineers Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus) Good knowledge of Data Engineering building blocks (storage, orchestrator) Fluent in object-oriented language development (ideally python) Experience in delivering technical projects from start to finish Preferred skills Proficient in SQL Experience in backend engineering Experience in infrastructure-as-code techniques (ideally Terraform) Knowledge in ML Ops and DevOps Knowledge of Kubernetes, K8s administration You know how to interact with technical stakeholders Who you are You are eager to play an active role in contributing to Aqemia’s strategy to develop drugs for patients. You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds. You are keen to solve tough problems on issues that truly matter. You are inquisitive, and proactive with a can-do attitude. You are excited to join a small team and make your mark on drug discovery. You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track. Our Workplace Environment - Fast-paced, intellectually and scientifically demanding, results-driven. - Our Founders boast : 10+ years experience in research at Ecole Normale Supérieure in Paris, not to mention a stint in Oxford and Cambridge / 10+ years experience in strategy consulting at BCG. - Aqemia has a rapidly growing team of +40 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale Supérieure, Ecole Polytechnique, BCG) - Our premises are conveniently located in center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work. - Working language: English We are growing fast, if you feel that you don't fit this job description but you’re still excited to join, then please get in touch! ‍ Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law.","Aqemia, a next-gen pharmatech company, is looking for a data engineer with AWS and data engineering building blocks knowledge to build a modern, reliable, and scalable data platform for engineering teams. The ideal candidate should have experience in delivering technical projects from start to finish, experience in backend engineering, knowledge of infrastructure-as-code techniques, and the ability to interact with technical stakeholders. Aqemia offers a challenging, science-driven and creative environment, working at the forefront of AI and deep physics-powered drug discovery in a fast-paced, interdisciplinary team.",Non spécifié,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
467,56548,https://www.welcometothejungle.com/fr/companies/bureau-veritas/jobs/wind-data-analyst-ila-engineer-f-h-x_la-defense,Wind Data Analyst ILA Engineer (F-H-X),Bureau Veritas,{},Télétravail partiel possible,"La Défense, 92060","Environnement / Développement durable, Energie",CDI,2023-03-26,"Découvrez un projet qui vous correspond vraiment Agir et développer vos talents ? Créer votre carrière ? Oser, proposer, inventer et transformer le monde dans lequel nous vivons ? Oui, oui et oui ? Alors, rejoignez Bureau Veritas, en tant que Wind Data Analyst ILA Engineer (F-H-X), en CDI, pour notre département éolien en mer, dans nos bureaux de La Défense (92) ou de Nantes (44), avec possibilité de télétravail partiel. Nous sommes acteurs du quotidien et un des leaders mondiaux du testing, de l’inspection et de la certification depuis près de 200 ans. Acteurs de la transformation du monde, aux côtés de nos clients, avec rire, passion et ambition. Nous aimons relever des défis, révéler les talents, faire bouger les lignes et élargir les horizons. Notre culture ? La confiance ! Exprimez vos talents ! Rattaché(e) à Jérôme, Manager Opérationnel de l’équipe en charge de la certification des projets éoliens offshore, vous participez à l’évaluation de conformité des projets éoliens en mer. Vous : Intervenez majoritairement sur l’évaluation des conditions de vent et le calcul des chargements dans le cadre de certification des champs d’éoliennes offshore posées ou flottantes, Contribuez de manière transverse aux développements techniques internes, groupes de travail de standardisation ou dimensionnement structurel des fondations d’éoliennes. On continue ? Description du profil : Bâtissons ensemble un monde de confiance ! De formation Bac +5 en Mécanique des structures/Matériaux ou ingénierie offshore, vous possédez une expérience de 2 à 3 ans acquise en ingénierie de structures en mer, idéalement sur des projets éoliens en mer. Vous : Avez une bonne connaissance de l’éolien, du calcul des chargements et des standards utilisés en éolien offshore (IEC 61400, DNV, etc), Avez une bonne maitrise d’un logiciel aero-elastique pour calcul des chargements éolien (Bladed, DeepLines Wind, Hawc2, etc), et de l’analyse des données des mâts de mesures ou autres systèmes de mesure du vent sur site (LIDAR). La connaissance en sciences de la mesure, modélisation météo-océanique et sciences statistiques serait un plus, ainsi que l’expérience sur outil de modélisation du vent et/ou de calcul de sillage et/ou du productible des parcs d’éoliennes. Anglais courant obligatoire. Autonome, rigoureux et possédant un bon relationnel, vous portez un intérêt pour les énergies renouvelables et l’éolien en particulier. Pourquoi nous rejoindre ? Vous bénéficiez d’un salaire fixe (€40 000,00-€50 000,00 selon profil) + ticket restaurant + intéressement/participation + PEG. Travailler chez Bureau Veritas, c’est oser voir grand et avoir les moyens de ses ambitions. C’est enfin conjuguer sens et performance, pour nos clients et pour la société dans son ensemble. Vous êtes à un clic de votre carrière ! Bureau Veritas est aussi engagé en faveur de l’égalité des chances, c’est pourquoi nous soutenons l’égalité entre les femmes et les hommes et favorisons l’insertion professionnelle, l’accès et le maintien dans l’emploi des personnes en situation de handicap.","Bureau Veritas is seeking a Wind Data Analyst ILA Engineer with 2-3 years of experience in offshore engineering for certification of offshore wind projects. The candidate should have knowledge of wind, wind load calculations, and standards used in offshore wind, and must be proficient in aeroelastic software for wind load calculations and the analysis of measurement data. A master's in offshore engineering, materials or structure mechanics is required, and a background in weather-ocean modeling, statistical sciences or wind modeling would be an added advantage. A professional working proficiency in English is mandatory. The position offers a fixed salary, meal vouchers, and company benefits.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
465,56308,https://www.welcometothejungle.com/fr/companies/leroy-merlin/jobs/data-engineer-f-h_lille,DATA ENGINEER,Leroy Merlin,"{Qlikview,omni,Qlik,Looker,PowerBI,Kafka,Merlin,GCS,Linux,BigQuery,SQL,Github,Python}",Télétravail partiel possible,"rue de chanzy, Lille, 59000","Grande distribution, E-commerce",CDI,2023-03-26,"Notre mission chez Leroy Merlin ? Construire avec tous les nouvelles façons d’habiter, pour mieux vivre demain. Pour poursuivre cette grande ambition, nous nous appuyons sur la force du groupe international dont on fait partie : le groupe Adeo. Mais ce qui fait notre originalité, c’est de réussir à garder une culture d’entreprise à taille humaine, en étant une (très) grosse boîte. Chez nous, vous expérimentez des relations très simples, on vous fait confiance, et chacun participe – vraiment- à l’écriture de la stratégie d’entreprise. Oser et avancer, c’est notre état d’esprit au quotidien : des milliers de projets sont menés simultanément par nos équipes. Leroy Merlin est une entreprise en pleine croissance (et ça dure depuis près de 100 ans 😃). Et comme nous sommes leader sur le marché de l’amélioration de l’habitat et qu’on entend bien le rester, on fait tout pour garder un temps d’avance. Chez Leroy Merlin, nous sommes convaincus que travailler sur des projets passionnants est la clé d'un parcours professionnel réussi ! Vous êtes un.e passionné.e de la donnée, et de la conception de solutions avancées ? Nous avons peut-être le poste qu’il vous faut ! Organisée en pôles de compétences techniques DATA (ingénierie, analyse et science), notre direction DATA Leroy Merlin France compte aujourd'hui plus de 100 talents. Nous recrutons un.e Ingénieur.e Data pour rejoindre le pôle Data Engineering, constitué d’une 40ène de personnes. En tant que Data Engineer, vous serez chargé.e de concevoir, de développer et de maintenir les infrastructures de traitement de données. Vous travaillerez au sein de l’une de nos 8 squads, qui adressent les enjeux de l'omni-commerce, la performance, les ressources humaines, le RSE, la supply et l'offre. En étroite collaboration avec les Data Scientists, Data Analysts et les autres membres de l'équipe pour trouver des solutions innovantes à des problèmes de données complexes. Vous serez également impliqué(e) dans la conception et le développement de nouvelles fonctionnalités et de nouveaux produits. ⚡ Votre futur métier : En collaboration forte avec nos différents métiers, l’équipe Data Engineering est chargée de proposer des solutions adaptées aux besoins clients, et de délivrer des produits de manière agile. Comment ? En mettant l'accent sur le développement de nos solutions data. Vous serez par exemple amené.e à travailler sur : La mise en œuvre de pipelines de données pour la diffusion de statistiques, permettant le pilotage et la prise de décision, La modélisation de notre patrimoine de données afin d'en faciliter son accès et ses usages, La projection de la croissance de l'activité de Leroy Merlin France, et de ses impacts sur les activités de la Supply Chain, Le suivi et pilotage des activités dans les centres d'appels, L'amélioration de notre parcours client et de sa relation avec la marque Leroy Merlin. Le Data Engineer est également responsable de : L'analyse des besoins des métiers et la proposition de solutions innovantes, La définition, le déploiement et l'industrialisation des flux de données au sein de son périmètre, La qualité et l'efficience des développements de son équipe et le maintien des solutions existantes (RUN), La mise en place de rituels agiles au sein de son équipe, et la veille technologique, Contribuer à la construction de la plateforme data et des services, L'accompagnement et l'acculturation des métiers sur les bonnes pratiques de l'exploitation de la data. ⭐ Votre profil : Vous avez une première expérience significative dans la data engineering (minimum 5 ans), Vous maîtrisez le langage SQL, les ETL, et les ELT, Vous aimez automatiser, mettre en place vos data pipelines et en maîtriser les technologies : CI/CD, Terraform, Github, Python, Kafka, Vous possédez des compétences en data visualisation, idéalement sur Business Objects, Qlikview, Qlik Sense, PowerBI ou Data Studio, Vous êtes sensible à l’approche Data-Driven des produits, Vous connaissez Google Cloud Platform (GCS, BigQuery), Vous êtes à l’aise sous Linux et maîtrisez les commandes avancées. ✨ Comment réussir sur ce poste : En ayant un fort esprit d’équipe, et la culture du partage : vous aimez collaborer avec les équipes opérationnelles, et vous intéresser à leurs sujets et problématiques, En étant autonome, curieux et proactif : vous aimez innover, proposer des initiatives et tester de nouvelles choses ! En affirmant votre esprit de synthèse et d’analyse, En mettant l’accent sur votre pédagogie : vous savez vulgariser des notions techniques en les connectant aux besoins métiers. ⛔ Ce qui ne fonctionne pas sur ce poste : Penser qu’améliorer en continue des solutions est inutile, et ne pas vouloir s’inscrire dans une démarche Agile, Ne pas savoir s’adapter à un environnement complexe et changeant, Manquer de communication et d’ouverture aux autres, ne pas aimer partager. ✋ Ce que vous retirerez de ce métier ? Le plaisir de pouvoir innover et d’essayer beaucoup choses, dans un environnement technologique riche : Google Cloud Platform, BigQuery, Github, Looker, PowerBI, Un accompagnement et une évolution continues dans votre domaine d’expertise et sur votre projet professionnel Et aussi, parce que nous sommes Leroy Merlin : une qualité de vie au travail, dans une équipe soudée et fière de travailler ensemble ! ⏳ Et si on regarde plus loin ? Selon vos attentes, la réussite à ce poste vous permettra de continuer sur un poste de MLOPS Engineer ou Data Product Leader. 📣 Quelles étapes lors du process de recrutement ? Un premier échange de 30min avec notre Talent Recruiter, Une rencontre d’1h avec le Manager Opérationnel du poste, Un entretien technique, mené par l’un de nos Data Engineer (1h), Un entretien RH avec questionnaire de personnalité (Predictive Index), débriefé par le Talent Recruiter (1h). Conditions du poste CDI à temps plein. 2 jours de Télétravail / Semaine Localisation : Lezennes (59) Postulez : l'aventure Leroy Merlin commence maintenant !","Leroy Merlin, a leading home improvement company, is looking for an experienced Data Engineer to join its Data Engineering team. The successful candidate will be responsible for designing, developing, and maintaining data processing infrastructures, working closely with Data Scientists, Data Analysts, and other team members to find innovative solutions to complex data problems. The ideal candidate should have at least five years of experience in data engineering and be proficient in SQL, ETL, ELT, and automation. Additionally, they should possess knowledge of data visualization and Google Cloud Platform. The position offers a chance to work with a diverse range of projects and technologies, with opportunities for professional growth and development.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
461,56362,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer_paris_CONTE_KlRVNqe,Data Engineer,Contentsquare,"{regard,Go,color,Scala,Akka,Contentsquare,Kafka,scale,Elasticsearch,Spark,R,ClickHouse,Java}",Télétravail partiel possible,"7, Rue de Madrid, Paris, 75008","SaaS / Cloud Services, E-commerce",CDI,2023-03-26,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team – known as the CSquad – representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of hard-working and dedicated developers, crafting and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at Contentsquare ! We collect several billion events per day and query hundreds of terabytes in real time. Your daily work will consist of: Crafting efficient architectures to store and analyze petabytes of data Leading large-scale projects and mentoring developers Implementing sophisticated acquisition workflows Thinking of inventive data formats to serve the functionalities of the product, while minimizing the cost Developing tools to help data-scientists ....by using some open-source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum of 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have curiosity about functional programming and seek to develop your skills in Data engineering programming languages. Ideally, you have experience with a wide range of databases and are interested in streaming. You would like to challenge yourself, developing distributed infrastructure with a real-time and data-intensive environment. You would like to share your skills and take part in technical choices. Why you should join our R&D department? Here is our R&D Manifesto We write our own story. We think for ourselves, keeping an open mind and engaging in constructive criticism. We are transparent in what we do and why we do it. We build and leverage tech expertise to answer business challenges. Learning from all experiences, we deliver continuous improvements in production. We empower all team members to have an end-to-end impact, take initiative, and bring new ideas to life. We stand together and thrive together; team spirit and solidarity matter even more than strong expertise. We live a human adventure. Why you should join Contentsquare: ▪️ We’re humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ▪️ We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ▪️ We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ▪️ Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ▪️ Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ▪️ Work flexibility: hybrid and remote work policies. ▪️ Generous paid time-off policy (every location is different). ▪️ Immediate eligibility for birthing and non-birthing parental leave. ▪️ Wellbeing allowance. ▪️ Home Office Allowance. ▪️ A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ▪️ Every full-time employee receives stock options, allowing them to share in the company’s success. ▪️ We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don’t meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is hiring a Data Engineer to join their global and distributed team. The Data Engineer will be responsible for crafting and developing a new data architecture, leading large-scale projects, and mentoring developers. The ideal candidate should possess 2-3 years of experience with a proficiency in Scala, Java, or Go, and have an interest in functional programming and data engineering programming languages. The company offers a range of benefits, including remote work policies, wellbeing allowances, home office allowances, and the opportunity for every full-time employee to receive stock options. Contentsquare is an equal opportunity employer.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
460,57006,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/ingenieur-e-data-experimente-e-cdi,Ingénieur·e Data Expérimenté·e - CDI - Caen ou Paris,SoyHuCe,"{PostgreSQL,Snowflake,Azure,Docker,Dataiku,Shell,Gitlab,Kafka,GCS,Git,NoSQL,PyTorch,Kubernetes,AWS,RabbitMQ,Java,SQL,Github,regard,Minio,Tensorflow,Scala,Pandas,S3,MXNet,via,R,Spark,BigQuery,GCP,Python,Tableau}",Télétravail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Transformation",CDI,2023-03-26,"Tech Lab spécialisé en algorithmes et en IA, SOYHUCE accompagne ses clients en proposant une offre adéquate et complète avec ses équipes Parisienne et Caennaise. La démarche de SOYHUCE se décline en 3 expertises : Une usine digitale ; Un laboratoire R&D en algorithmie & IA ; La data factory SOYHUCE se positionne sur le marché du digital et de la Data comme un « valorisateur de données ». Elle se repose sur des logiciels et des algorithmes personnalisables, centrés sur les métiers, et sur sa capacité à faire ressortir les besoins au-delà de ceux exprimés au travers d’une approche analytique fine. Créée en 2013, SOYHUCE souhaite apporter un nouveau regard dans les innovations. Tout en plaçant l’humain au cœur des entreprises, nos solutions sont adaptées aux enjeux économiques, sociales et sociétales d’aujourd’hui. Leurs produits : OctoData : La plateforme d’orchestration de technologies Big Data, prête à l’emploi et dédiée au traitement et à la valorisation de vos données massives. iStoryPath : La webapp de génération de parcours touristiques et événementiels personnalisés. AlgoRH : L’outil de gestion de planning intelligent à destination des Centres de Relation Clients. Vous travaillerez conjointement avec les Data Scientists, Data Ingénieurs et le Data Architect déjà en poste et vous serez impliqué.e dans la prise de décisions liée à notre solution Big Data et à son évolution. Vous participerez également à la construction d’un pôle Data au sein de l’entreprise. Vos missions au quotidien : Contribuer au développement de notre offre Big Data, Comprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets des BUs, Définir l’architecture logiciel en collaboration avec vos pairs Travailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage), Rédiger de la documentation technique, Partager votre savoir-faire entre les différents membres de l’équipe, Concevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateforme, Concevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data, Assurer une veille technologique. Compétences attendues : Expérience en développement : Python, Java, Scala (notions) Spark, Pandas Git Connaissance en bases de données : SQL (DataWarehouse Snowflake / Big Query, Bases de données PostgreSQL) NoSQL (orientée documents, timeseries) Connaissance message broker RabbitMQ Kafka Compétences cloud : Kubernetes, Conteneurisation Fournisseur cloud (AWS, GCP ou Azure) Infrastructure As Code (Terraform) Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managés Cartographie des données Notre stack : Stockage de données: AWS S3, Google GCS, Minio ; Cloud: AWS, GCP, Azure, OVH ; Message Broker: RabbitMQ, Kafka ; Orchestrateurs: Kubernetes, Docker Compose ; Technologies Big Data : Spark ; Bases de données : PostgreSQL, Snowflake, BigQuery ; Machine learning: Tensorflow, PyTorch, MXNet, Scikit-Learn ; Recherche opérationnelle: Optaplanner, OrTools ; Langages: Python, Java, Scala, Shell ; Outils : Dataiku, Power BI, Tableau ; IAAS : Terraform ; Versioning : Gitlab, Github ; Diplômé·e d’études supérieures dans le système d’information, computer sciences, big data (école d’ingénieurs, école spécialisée ou équivalent universitaire), vous justifiez d’au moins 5 ans en Data engineering. Vous avez une expertise reconnue sur la mise en place de pipelines complets de valorisation de données massives, de la collecte à la mise à disposition d’applications en passant par le traitement. D’un naturel curieux et créatif, vous aimez évoluer dans des environnements innovants. Vous êtes un·e bon·ne communiquant·e et possédez une vraie culture de services et de succès client. Animé.e par votre métier et proactif.ve, vous aimez apprendre en permanence. L’innovation, l’acquisition de nouvelles technologies et le partage sont au cœur de votre ADN tout comme le nôtre. Vous êtes autonome, rigoureux, vous apprenez en permanence. Vous avez l’esprit d’équipe mais également des opinions et savoirs à faire valoir. Vous exprimez clairement vos analyses. Vous êtes passionné·e par votre métier, aimez le faire partager, même à des personnes qui ne le connaissent pas. Un pré-qualification avec notre Talent Acquisition Senior Un entretien avec un Référent Technique Métier Un challenge technique Un entretien avec notre CEO","Soyhuce, a tech lab specialized in algorithms and AI, is seeking a Data Engineer with at least 5 years of experience in data engineering. The ideal candidate should have expertise in implementing complete pipelines, from data collection to application development, and possess skills in Python, Java, Scala, Spark, Pandas, SQL, NoSQL, RabbitMQ, Kafka, Kubernetes, and Terraform. They should also be innovative, proactive, communicative, and have a passion for learning and sharing knowledge. The role involves contributing to the development of Soyhuce's big data offerings, architecting software, developing data connectors and pipelines, and conducting research and development work in data science.",Bac +5 / Master,Entre 15 et 50 salariés,> 5 ans,2,1,0.04154662416233763
458,50445,https://www.welcometothejungle.com/fr/companies/m13h/jobs/analytics-engineer-france-europe-f-h_paris,Analytics Engineer - (France / Europe) -,M13h,"{Azure,OneTrust,Fivetran,AWS,dbt,Snowflake,Contentsquare,via,Adverity,BigQuery,GCP,SQL,Python}",Télétravail partiel possible,"3 rue d'Uzès, Paris, 75002","Digital Marketing / Data Marketing, Stratégie, Big Data",CDI,2023-02-07,"A propos de M13h 👋 M13h est une équipe de consultant·e·s passionné·e·s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Stratégique et expertises Data, Marketing & Technologies pour accélérer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous maîtrisons toute la chaîne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, … à accroître leurs performances, au travers de missions variées : Stratégie Data : définir sa stratégie, ses cas d’usage data et le socle technologique pour la déployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donnée pour créer de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et améliorer les taux de conversion Privacy : s’adapter aux évolutions technologiques et règlementaires tout en développant ses performances marketing Modern Data Platforms : construire des plateformes de données sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des données pour prendre des décisions éclairées (dashboards, data analyse, data science, modélisation avancée, …) M13h est membre du Groupe Labelium et met ses compétences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure à taille humaine où il fait bon travailler ! En plein mouvement de régionalisation et d’internationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l’Europe (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N’hésitez pas à en discuter en entretien. Description du poste 📢 En tant qu’ Analytics Engineer , tu interviens sur des problématiques à la croisée de la data science, de la data analyse et de la data ingénierie et ton rôle est de mettre en place pour nos clients ou nos besoins internes des datasets pertinents : bien modélisés, documentés, fiables en termes de qualité et de disponibilité, répondant aux besoins des usages ultérieurs. Pour cela, tu interviens à différents stades des projets : Analyse des besoins d’accès aux données , en collaboration avec les utilisateurs business, data analysts et dataviz engineers Mise en place des flux et modèles de données , en se basant sur des stacks data modernes (SQL, dbt, outils ELTs, GCP/Azure/AWS/Snowflake, …) Exposition des données dans les outils BI & visualisation Maintenance des pipelines et mise en place d’alertes & tests de qualité de données Quelques exemples de missions à titre d’illustration : Construction d’une Customer Data Platform pour un grand retailer (8 marques / 30+ pays) Migration d’une large infrastructure de dashboards basés sur un stack Supermetrics vers un stack Adverity+BigQuery Mise en place d’outils de pilotage de bout en bout pour plusieurs startups en forte croissance Packaging d’outils internes sur l’attribution custom Polyvalent·e , tu as à cœur de comprendre les besoins de tes interlocuteurs pour les traduire en structures de données exploitables et de bonne qualité . En tant que Junior , tu seras encadré par des profils plus séniors te permettant de progresser rapidement dans notre environnement et sur les stacks data modernes. Profil recherché 👨👩 Issu·e d’une grande école de commerce, d’ingénieurs ou équivalent , tu souhaites t’orienter vers un rôle à la croisée des métiers de la data. Tu maîtrises très bien SQL et souhaites travailler sur les modern data stacks : plateformes cloud (Google Cloud, AWS, Azure, Snowflake), outils ELTs, dbt, … La maîtrise de Python est un plus. Tu as de bonnes capacités d’analyse et souhaite travailler sur des projets analytique de bout en bout en faisant preuve d’autonomie et de rigueur. Pourquoi nous rejoindre ❓ M13h, c’est avant tout une équipe qui aime les challenges et porte des valeurs de bienveillance et de progrès collectif . Tu as déjà lu ça ailleurs ? Contactes nos consultant·e·s sur LinkedIn pour vérifier directement :) Démarrer chez M13h, c’est aussi une belle opportunité de développer tes compétences conseil et ton expertise rapidement sur des missions variées, au sein d’une structure à taille humaine tout en profitant des avantages d’un groupe international. Tu es accompagné par un parrain ou une marraine dès ton arrivée en plus de ton manager, profites de formations, accèdes à de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, … Et puis M13h, c’est aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d’arrivée pour s’équiper pour le télétravail Une politique souple de télétravail Un abonnement gratuit à des salles de sport 2 séminaires par an et de nombreux moments de cohésion d’équipe Des locaux au coeur de grandes villes françaises (Paris, Bordeaux, Lyon) et européennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge à 100% et bien d’autres… Comment postuler 🙋 Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontanée à recrutement@m13h.com","M13h is seeking an Analytics Engineer to work on data science, data analysis, and data engineering projects, creating relevant, well-modeled, documented, reliable, and available datasets. The successful candidate will analyze data access requirements, develop data pipelines, and create dashboards, as well as maintain pipelines and data quality testing. The ideal candidate has a strong SQL background and desires to work with modern data stacks, including cloud platforms (Google Cloud, AWS, Azure, Snowflake) and ELT tools. They should possess excellent analytical skills and a desire to work autonomously and rigorously. M13h is a growing consulting firm that helps companies become data-driven and offers a fun, international work environment with opportunities for professional development.",Bac +5 / Master,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
456,57162,https://www.welcometothejungle.com/fr/companies/leboncoin/jobs/data-engineer-team-data-platform-f-m_paris,Data Engineer team Data Platform,leboncoin,"{DynamoDB,Glue,Elasticsearch,Docker,Hudi,Athena,Kafka,Kubernetes,AWS,Java,SQL,Jupyter,Github,Airflow,Redshift,S3,R,Spark,Unix,Python,MLFlow}",Télétravail partiel possible,"85-87, rue du Faubourg Saint-Martin, 75010, Paris","Économie collaborative, E-commerce",CDI,2023-03-26,"Créé en 2006, leboncoin.fr est une plateforme d’échanges d’un nouveau genre, qui simplifie l’accès à la consommation, privilégie la relation locale et fait du digital un outil au service de tous. En facilitant le rapport des individus à l’échange et à la consommation, leboncoin a su s’imposer en quelques années comme phénomène de société français et faire du bonheur des uns le bonheur des autres. En France, nous nous positionnons comme un acteur numérique, économique, sociétal, innovant, avec toujours le même objectif : faciliter tous les échanges au quotidien de l’ensemble de nos utilisateurs. Grâce à notre plateforme de petites annonces, nous donnons une seconde vie à des milliers de biens. L’impact positif de ces échanges a été évalué à 5,8 millions de tonnes de C02 économisés sur une année. Derrière cette apparente simplicité, se trouve une entreprise en forte croissance de plus de 1500 salariés, où il fait bon travailler, une entreprise qui cultive une démarche RH responsable et collective. Leboncoin réunit également les sites Agriaffaires, MachineryZone, Truckscorner, AvendreAlouer, Paycar, Locasun, Videdressing, L’argus et Pilgo Vous êtes rattaché.e à l’équipe Data Engineering , composée de data engineers et de SRE. Cette équipe vous accompagne sur la stack technique data, vous permet d’échanger sur des sujets transverses et de participer aux rituels data engineering (guilde, rétro…). Cette équipe appartient à la tribe “Data Tools & Services“, qui regroupe les services data centraux La stack : Développement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm Dans un environnement à la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi Ce que vous ferez : Développer des applicatifs complexes assurant une circulation optimale des données, et assurer leur fiabilité : API d’exposition de données, applications de streaming, industrialisation de modèles de machine learning Optimiser notre architecture et notre environnement AWS : stockage, sécurité, automatisation, scalabilité Assurer la sécurité des données de nos utilisateurs sur la data platform, dans le respect de la réglementation en vigueur (GDPR, e-privacy) Participer activement à la veille technologique et à l'effort de R&D Garantir le bon fonctionnement, la disponibilité, l’évolution et la performance des outils Assurer l’interface avec les équipes techniques du produit Poste basé à Paris 10 Les étapes : Premier échange avec Simon (RH) Entretien managérial avec Thomas (Engineering Manager) Entretien technique avec deux membres de l'équipe (Data Eng) Entretien Fit/RH avec Julien (directeur data) et Simon (RH) Vous avez au moins 5 ans en tant que Data Engineer Vous connaissez les environnements Unix, et possédez un niveau avancé en Java / Python . Vous êtes familier avec l'environnement cloud AWS , et avez de solides notions d’architecture distribuée et de gestion de data platform à forte volumétrie. Vous êtes à l’aise en anglais tant à l’écrit qu’à l’oral.","Leboncoin.fr is looking for a Data Engineer with at least 5 years of experience in Java/Python, Unix and AWS. The successful candidate will develop complex applications for data optimization, ensure data security, and participate in R&D efforts. The job is based in Paris and requires fluency in English.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
452,56932,https://www.welcometothejungle.com/fr/companies/exotec/jobs/data-engineer_lille,Data Engineer,Exotec,"{Microsoft,durable,Oracle,Beam,PostgreSQL,SAP,BigQuery,SQL,DataFlow,Python}",Télétravail partiel possible,Lille,"Logistique, Objets connectés, Robotique",CDI,2023-03-26,"Exotec met l’excellence technologique au service de la redéfinition des relations entre humains et robots. A travers le monde, leurs solutions révolutionnent la façon dont leurs clients délivrent leurs produits aux consommateurs finaux. Ils contribuent au succès des plus grandes marques du commerce et de l’industrie, tout en améliorant les conditions de travail de leurs salariés. Par l’alliance de l’intelligence artificielle et d’un hardware performant, leurs robots sont désormais déployés dans le monde entier et leur succès a fait d’Exotec la première licorne industrielle française. Rejoindre Exotec, c’est l’opportunité de donner du sens à vos compétences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos idées, des réalités. La révolution robotique portée par Exotec ne fait que commencer, vous en êtes ? Exotec multiplie les usages de ses données et souhaite structurer ses outils et méthodes : collecte, stockage, transformation, exposition et partage des données. Exotec conçoit des systèmes robotisés permettant l'optimisation des chaînes d'approvisionnement. Nous proposons une valeur ajoutée claire : une collaboration élégante entre les travailleurs humains et les robots pour une productivité durable des entrepôts. Pour accompagner la forte croissance de l’entreprise dans le monde entier (Japon, USA), l'équipe IT s’étoffe et crée de nouveaux postes en Data. En intégrant Exotec, vous rejoignez la première licorne industrielle française et vous prenez part à la forte croissance d’une équipe IT de 30 personnes aujourd’hui. En tant que Data Engineer : Vous participez à la mise en œuvre des composants techniques de la plateforme de données d'Exotec Vous travaillez sur la collecte dans la plateforme de données provenant de sources multiples : Salesforce, ERP, logiciels développés en interne Vous nettoyez, mettez en qualité et préparez les données afin de les rendre disponibles pour les différents cas d'usage qui en ont besoin Vous migrez des reportings existants vers la plateforme de données et mettez en œuvre de nouveaux cas d'usage pour répondre aux besoins de l'entreprise Vous travaillerez au sein de l'équipe data et en étroite collaboration avec la software factory, ainsi qu’avec les utilisateurs des métiers qui ont besoin de rendre intelligibles les données disponibles Requirements Diplôme d'ingénieur ou équivalent Vous justifiez d'au moins 5 ans d'expérience en Data Engineering ou Data Science Vous avez de bonnes capacités d’analyse, aimez résoudre les problèmes et faites preuve d’un fort esprit critique Vous avez une bonne connaissance des solutions Google BigQuery et DataFlow et avez de l'expérience en programmation : Python et Apache Beam Vous êtes formé(e) aux bases de données de type SQL server et PostgreSQL Vous maîtrisez l’ETL et avez une expérience des requêtages sur des API REST Une certification sur les technologies Google et Microsoft serait un plus Vous avez une appétence à comprendre les métiers, et idéalement une expérience de travail avec des ERP de type SAP, Microsoft Dynamics ou Oracle, ou des outils tels que Salesforce ou Workday. Vous êtes économes de vos moyens et mettrez cette qualité en œuvre dans la recherche de solutions simples et efficaces (« sans couture ») Vous vous positionnez dans une recherche d'amélioration et d'automatisation constante de l'existant Vous avez un bon niveau d’anglais Vos softs skills sont : Bonne aisance relationnelle, proactivité, force de propositions, rigueur, esprit d'analyse et de synthèse, organisation et respect des échéances Pourquoi nous rejoindre Parce que nous avons une forte culture d'entreprise qui favorise l'épanouissement pro et perso Parce que nous aimons travailler dur, et aussi fêter nos succès Parce que nous avons été élus champion de la croissance en 2022 et que nous sommes la 1ère licorne industrielle française Parce que nous avons de nombreux avantages : prime d'intéressement, ticket-restaurant, mutuelle, primes mobilité durable, jours de congés supplémentaires, politique famille... Parce que nous travaillons sur des projets innovants, et surtout des produits Processus de recrutement Si votre candidature est retenue, nous vous proposons : Un premier échange téléphonique Un entretien technique en visio avec un membre d'Exotec Un entretien final à notre siège afin de vous présenter nos équipes et nos systèmes Si votre candidature n'est pas retenue, nous nous engageons à vous communiquer un retour dans un délai de 2 à 3 semaines maximum. Chez Exotec, nous garantissons l’égalité des chances dans notre processus de recrutement. L’ensemble des candidatures reçues sont étudiées indépendamment de l’âge, du genre, de l’origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l’orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s’engage pour un écosystème French Tech plus paritaire.","Exotec, the first French industrial unicorn, is seeking a Data Engineer with at least 5 years of experience in Data Engineering or Data Science. The successful candidate should have a degree in engineering or equivalent, skills in programming languages such as Python and Apache Beam, and experience with Google BigQuery and DataFlow. Experience in ETL and queryings on REST APIs and SQL servers and PostgreSQL is also required. The Data Engineer will work collaboratively with the data team and software factory while collaborating closely with the business users. Exotec offers a range of benefits, including additional days off, a sustainable mobility allowance, and a family policy.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
438,50061,https://www.welcometothejungle.com/fr/companies/pwc/jobs/consultant-experimente-data-engineer-cdi-f-h_neuilly-sur-seine_PF_KWAjldY,Consultant expérimenté Data Engineer | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",Télétravail partiel possible,"63 Rue de villiers, Neuilly-Sur-Seine, 92200","Stratégie, Audit",CDI,2023-02-07,"PwC poursuit sa stratégie mondiale The New Equation, portée par l'humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes. Notre communauté Data et IA réunit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la chaîne de valeur, de la stratégie à l'exécution, afin d'accompagner nos clients sur l'ensemble de leurs métiers et de leurs entités, dans leur ""data transformation. Ce que vous pouvez attendre de nous En tant que Data engineer dans les équipes Data & IA de PwC votre mission sera de: - Contribuer à la définition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en étroite collaboration avec les data architects - Mettre en œuvre ces solutions en mode Agile en optimisant : - La performance et le passage à l'échelle - La qualité des données et des modèles au fil du temps - La cohérence avec les outils et les frameworks existants - La qualité et conformité (revue cyber, Cloud, auditabilité des traitements, RGPD) - Mise en place de CI/CD pour le déploiement des solutions chez les clients Notre boite à outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous êtes diplômé(e) ou futur(e) diplômé(e) d'une école d'ingénieur ou d'une université (type Master2..) avec une majeure en système d'information, en Data ou en Datascience. Vous êtes particulièrement intéressé par la mise en oeuvre de solutions data complète et par la gestion des flux et leur orchestration (notamment événementielle) tout cela dans des environnements cloud Vous avez pu exercer cet intérêt et vos talents dans vos expériences passées sur une ou plusieurs composantes de la chaîne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD… Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte écologique","PwC is seeking a Data Engineer to join its Data & AI team in France to contribute to the design and implementation of innovative Data Analytics/Big Data solutions in cloud environments. The ideal candidate should have a degree in Data or Data Science, experience in cloud infrastructure, data pipelines, machine learning algorithms using tools such as Python and familiarity with Microsoft Azure, Google Cloud Platform and Amazon Web Services.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
450,56737,https://www.welcometothejungle.com/fr/companies/pwc/jobs/consultant-experimente-data-engineer-cdi-f-h_neuilly-sur-seine_PF_QggKwLY,Consultant expérimenté Data Engineer | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,durable,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",Télétravail partiel possible,"rue de villiers, Neuilly-Sur-Seine, 92208","Stratégie, Audit",CDI,2023-03-26,"PwC poursuit sa stratégie mondiale The New Equation, portée par l'humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes. Notre communauté Data et IA réunit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la chaîne de valeur, de la stratégie à l'exécution, afin d'accompagner nos clients sur l'ensemble de leurs métiers et de leurs entités, dans leur ""data transformation. PwC poursuit sa stratégie mondiale The New Equation, portée par l'humain, nos engagements responsables, sociétaux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la réalité virtuelle et de technologies émergentes. Notre communauté Data et IA réunit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la chaîne de valeur, de la stratégie à l'exécution, afin d'accompagner nos clients sur l'ensemble de leurs métiers et de leurs entités, dans leur ""data transformation. Ce que vous pouvez attendre de nous En tant que Data engineer dans les équipes Data & IA de PwC votre mission sera de: - Contribuer à la définition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en étroite collaboration avec les data architects - Mettre en œuvre ces solutions en mode Agile en optimisant : - La performance et le passage à l'échelle - La qualité des données et des modèles au fil du temps - La cohérence avec les outils et les frameworks existants - La qualité et conformité (revue cyber, Cloud, auditabilité des traitements, RGPD) - Mise en place de CI/CD pour le déploiement des solutions chez les clients Notre boite à outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ces avantages que nous vous offrons : Flexibilité avec la charte FlexWork : télétravail étendu, mobilité géographique, FlexTime , Dress for your day Pass mobilité durable pour couvrir vos dépenses de mobilité durable Programme Be Well, Work Well pour prendre soin de sa santé (partenariat Gymlib, application United heroes, associations sportives, formations mindfulness…) Programme Family Care pour vous accompagner dans vos projets de parentalité comme dans les moments difficiles Écosystème de santé pour trouver à qui parler, être écouté et aidé quelles que soient vos difficultés professionnelles ou personnelles Crédit de 3 jours par an sur le temps de travail pour des missions d'engagement sociétal Mobilité interne et internationale possible à partir de 18 mois d'ancienneté Crystal Park (site de Neuilly-sur-Seine) : parc privatif de 2 hectares, conciergerie, salle de musique, salle de sport, Café Joyeux… Programme New World. New Skills pour monter en compétences sur les enjeux de demain (ESG, technologies, inclusion des diversités) et plateforme Vantage de formation à la demande Et aussi : RTT, mutuelle santé et prévoyance, restaurants d'entreprise et titres-restaurants, avantages du Comité Inter-Entreprises… Toutes nos offres sont ouvertes aux personnes en situation de handicap Ce que nous attendons de vous Vous êtes diplômé(e) ou futur(e) diplômé(e) d'une école d'ingénieur ou d'une université (type Master2..) avec une majeure en système d'information, en Data ou en Datascience. Vous êtes particulièrement intéressé par la mise en oeuvre de solutions data complète et par la gestion des flux et leur orchestration (notamment événementielle) tout cela dans des environnements cloud Vous avez pu exercer cet intérêt et vos talents dans vos expériences passées sur une ou plusieurs composantes de la chaîne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD… Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte écologique","PwC seeks a data engineer to contribute to the definition and design of innovative data analytics/big data solutions and their deployment in cloud environments. The candidate should have experience in data pipelines, data lakes, machine learning algorithms, and cloud infrastructure, as well as knowledge of Python, Docker, Kubernetes, and CI/CD practices. PwC offers several benefits, including teleworking, flexible work hours, mobility, health and well-being programs, and professional development opportunities. The company seeks candidates with a degree in information systems or data science and an interest in developing complete data solutions and managing data flows in cloud environments.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
447,56407,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"5 Avenue de la lierté, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de votre âge, origine, orientation sexuelle, handicap... Au sein du département CIO CIB, vous rejoignez l'équipe de Sensitivities, au sein de l'IT Risks, composée de 10 personnes. En nous rejoignant, vous prenez part à plusieurs programmes de transformation de notre système d'information afin de répondre aux besoins du département des risques, des régulateurs, tout en accompagnant les front offices dans leurs nouvelles activités. L'équipe est en charge de la maintenance et des évolutions de deux applications clés pour la gestion des risques de marchés : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities répondant à la réglementation FRTB). Nos principaux interlocuteurs sont le département des risques de marchés (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk), les équipes support/production à Porto et les équipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques à mettre en œuvre et estimer le coût avec l'équipe ; Développer de nouvelles fonctionnalités de la phase de conception aux tests, dans une démarche durable (haute qualité du code, respect des principes d'architecture et de sécurité informatique, documentation, automatisation des tests, utilisation maitrisée de l'infrastructure) ; Travailler sur des problématiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et améliorer la Software Factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 et les développements nécessaires pour maintenir une production ponctuelle, de qualité et maîtrisée. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Paris et à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en informatique avec une spécialisation en big data, vous avez au moins 3 ans d'expérience en tant que data engineer. Vous maîtrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La préconisation de solutions techniques. Vous êtes : - Reconnu pour votre leadership ; - Capable de proposer des améliorations continues ; - Rigoureux, autonome et pédagogue. Vous maîtrisez l'anglais avec un niveau minimum B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis Corporate & Investment Banking is seeking a data engineer with at least three years of experience in big data, who is proficient in Spark, Scala and Hadoop. The successful candidate will be responsible for developing new functionalities, optimizing performance, and proposing innovative solutions within an agile development process. They must be autonomous, pedagogical, and have a strong leadership aptitude. The position is based in Paris and Charenton-le-Pont, offers ten days of telework per month, and includes a variety of benefits such as on-site services, RTT days, and an employee savings plan.",Bac +4,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
446,56402,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"AVENUE DE LA LIBERTE, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-03-26,"Natixis fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France. Fort d’un portefeuille de marques comprenant notamment Natixis Investment Managers et Natixis Corporate and Investment Banking, Global Financial Services est composé de deux métiers – la gestion d’actifs et de fortune et la banque de grande clientèle. Avec plus de 12 000 collaborateurs dans 35 pays, nos experts accompagnent leurs clients, partout dans le monde, en leur proposant des solutions de financement et d’investissement innovantes et durables. Engagés en faveur de la transition environnementale, technologique et sociétale, ils se distinguent par un fort esprit entrepreneurial. Au sein de la direction CIO CIB Risks, dans le département Data Processing and Metrics, vous rejoignez l'équipe Metric Services P&L Explain qui est composée de 5 personnes. Dans cette équipe nous travaillons à calculer l'explication du P&L (profit and loss) par les sensibilités. Notre application est également partie prenante des calculs de Stress Tests et IPV (indépendance price validation). Nous intervenons donc sur plusieurs chaînes de valeurs, auprès de notre client : le département des risques de marché. Au quotidien vous avez pour missions de : Contribuer aux spécifications techniques et fonctionnelles ; Intervenir de la phase de concéption aux tests : développement de nouvelles fonctionnalités, revue de code, documentation, ... ; Travailler sur des problématiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et améliorer la software factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 pour avoir une production ponctuelle, de qualité et maîtrisée. Nos principaux interlocuteurs sont : le département des risques de marché (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk) et les équipes support et production à Porto. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Vous travaillez dans un environnement international, au sein d'une communauté d'experts qui place l'excellence, l'impact et l'action collective au cœur de tout ce qu'elle entreprend. Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en finance et/ou en informatique avec une spécialisation en big data, vous avez une expérience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous maîtrisez : * La finance de marché, et plus précisément le marché des risques et PNL (méthode d'explication du PNL) ; * Les spécifications des besoins de l'équipe et vous êtes capable de proposer des maquettes aux utilisateurs en autonomie. Vous êtes : * Pédagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des améliorations continues. Vous maîtrisez l'anglais avec un niveau B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis is seeking a Data Engineer with at least 2 years of experience in Hadoop, Spark, and Scala, specialized in big data with a background in finance and/or computer science. The ideal candidate must have a strong understanding of market finance, specifically risk and PNL, and be able to propose models to users independently while maintaining a flexible and innovative approach. The position is remote with 10 days of telework per month, offering a fixed salary, annual bonus, employee savings plan, career development opportunities, and work benefits such as onsite catering, sports facilities, and a concierge service.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
444,56406,https://www.welcometothejungle.com/fr/companies/elevate/jobs/manager-data-analysis-engineering-science_paris,"Manager Data Analysis, Engineering & Science",Elevate,"{GCP,R,SQL,Python}",Télétravail partiel possible,Paris,"Digital Marketing / Data Marketing, IT / Digital, Recrutement",CDI,2023-03-26,"Elevate est la nouvelle agence de conseil dédiée 100% à la data. Nous intervenons à la croisée du conseil et de la mise en œuvre opérationnelle sur des projets Digital & Data en délivrant un accompagnement bout-en-bout. Chez Elevate nous nous positionnons en tant que partenaire stratégique data de nos clients et rendons possible leur transformation customer-centric par notre méthodologie data-driven reconnue. Nous accompagnons nos clients sur l’ensemble de la chaîne de valeur Data. Nous avons décomposé notre offre autour de 3 practices d’expertise : Data Marketing Conseil Data et Stratégie - Faire de la data et du digital un accélérateur business Collecte & Analytics - Collecter, unifier, structurer et visualiser des données de performance fiables (Tracking) Expérience client - Exploiter la data et les technologies du marché pour délivrer des expériences clients uniques (CRO) Performance média - Optimiser les budgets et les performances media grâce aux outils et méthodes de pointe du marché Data & Tech Data Management - Identifier l’ensemble des data points pouvant être vecteurs de croissance et élaborer une stratégie pour l’activation de ces leviers Data Engineering & Architecture - Construire une architecture data résiliente et scalable, permettant son exploitation par le métier Data Analysis - Déployer des outils facilitant la prise de décision sur des points clefs du business et former les équipes sur la prise de décision data driven Data Science - Modéliser et programmer pour assister la prise de décision à l’aide de statistiques descriptives et d’algorithmes de prédiction et de classification Consumer & Market Insights Social Listening & Analytics - Ecouter la voix du client là où il s’exprime Notre ADN nous pousse à être constamment à la pointe des sujets data. Pour cela, nos consultants accordent une part importante de leur temps à de la veille, de la formation ou de la R&D. Nous recherchons un.e Manager Data Analysis, Engineering & Science ✨ Dans le cadre de la forte croissance d’Elevate et de notre practice Data & Tech, nous cherchons un ou une Manager afin de piloter une équipe d’une dizaine de consultants en mode régie ou agence et d’ accompagner nos clients sur des problématiques techniques et business liées à la data. Opérant pour des comptes internationaux et de secteurs très variés (automobile, ecommerce, énergie, foodtech, fintech, banque, etc.) vous accompagnez nos clients dans leur transformation customer-centric. Alors si être en charge d’un projet intrapreneurial dans une agence de conseil data en forte croissance vous inspire, ce poste est fait pour vous ! Parmi vos missions 🛠 Management & recrutement : Vous avez sous gestion une équipe de consultants Data & Tech (juniors, confirmés, seniors) afin de mener à bien des missions de data analyse, data sciences ou data engineering. Vous accompagnez dans leur carrière (appui d’expertise, besoin de formation, taux de staffing, entretiens annuels et carrière…) votre équipe de consultants. Vous contribuez de manière active au recrutement des nouvelles recrues en participant aux entretiens. Développement commercial de l’agence et de votre practice : Vous gérez directement un portefeuille de clients grands comptes multisectoriel pour lesquels vous conduisez des projets data & tech innovants : Définition, cadrage, mise en œuvre, application de méthodologies data-driven Transformation des organisations : désilotage, logique test&learn centrée client etc.* Vous participez également activement au développement de l’agence et en particulier sa Practice Data & Tech en prenant à charge divers projets internes en fonction des opportunités : Publication de comparatifs outils Participation à des salons / conférences Animation de retours d’expériences et formation interne Contribution active au Knowledge Center Elevate* Vous accompagnez les associés sur le volet commercial en participant aux appels d’offres et aux efforts d’avant-vente, afin de transformer les opportunités business et pérenniser la relation client. Vous assurez le développement commercial d’un portefeuille client au périmètre délimité en identifiant et/ou favorisant l’émergence de nouveaux besoins chez vos clients (upsell & cross-sell). Qui pourrait vous accompagner ? 🤝 Aurélien, co-Fondateur : après un Master à HETIC et différentes expériences dans la data marketing, il se lance dans le freelance pendant 3 ans. Aux côtés de Maxime, partenaire de toujours depuis HETIC, ils se rendent vite compte que cette aventure entrepreneuriale dépasse leurs attentes et souhaitent créer un projet commun qui les ressemble. Ils décident tous les deux, de créer leur propre agence de conseil spécialisée data. En octobre 2017, Elevate Agency voit le jour ! Aujourd’hui, il est responsable de la Team Talent, de l’activité Marketing & Communication de l’agence & pilote le lancement en Espagne. Si vous cherchez une personne incollable sur l’univers de la data et son actualité, Aurélien est votre homme 🦸‍♂️ La data révèle que nous sommes moins susceptibles de postuler pour une offre d’emploi, si nous pensons ne pas avoir toutes les compétences requises. 🐑 Notre mouton à 5 pattes coche les cases suivantes, mais si vous n’en avez que 4, postulez quand même ! Au sein d’Elevate nous saurons vous accompagner dans votre montée en compétences. Vous justifiez d’au moins 4 ans d’expérience dans le domaine et d’une première expérience en conseil et en gestion d’équipe. Niveau soft skills, on attendra de vous : Un esprit analytique, rigueur, logique et approche méthodique Un bon esprit d’initiative, capacité à travailler de manière autonome et dynamique dans une activité en pleine croissance Le sens du service, aisance relationnelle Première expérience managériale (de deux personnes ou plus) est appréciée Vous disposez également des hard skills suivantes : De solides compétences pratiques en data analyse (manipulation de données, statistiques, visualisation) et en machine learning au moins sur données tabulaires (classification, régression, clustering) Vous parlez SQL et Python couramment Vous avez piloté et mis en place techniquement plusieurs projets data Vous avez une connaissance approfondie de l’état du marché / des méthodologies / des techniques sur ces trois domaines complémentaires Vous êtes familier.e avec l’offre d’au moins un fournisseur cloud (GCP est un plus) et de la manière dont celle-ci peut répondre aux use-cases marketing Vous avez des compétences reconnues en gestion de projet Une excellente communication écrite et orale Une maîtrise professionnelle de l’anglais 🛫Le processus de recrutement se fait en 3 étapes : Entretien téléphonique d’environ 30 minutes avec notre équipe Talent Acquisition afin de vous laisser la parole pour mieux vous connaître. Entretien incluant un test de compétences et de connaissances en data analyse, data sciences ou data engineering avec un.e manager & un.e consultant.e Elevate. Entretien approfondi avec l’un des co-fondateurs de l’agence à l’occasion duquel nous testons votre capacité de structure, d’analyse et de synthèse à travers une ou deux études de cas. Nous attachons une importance toute particulière à votre rigueur, votre méthodologie d’analyse et de structuration de problèmes ainsi que votre créativité pour les résoudre. Elevate s’engage à donner une réponse au candidat dans les plus brefs délais. Elevate c’est avant tout ⛺ Rejoindre une agence de conseil à taille humaine. Une entreprise fondée autour de la formation et la montée en compétences de chaque membre de l’équipe. Un management humain et respectueux de toutes et tous. De la place pour les initiatives innovantes et créatives. Une politique de télétravail flexible et basée sur le choix ! Des parcours de carrières adaptés à chacun.es Mais aussi 🌞 Une rémunération fixe, attractive et basée en fonction de votre niveau d’impact et d’expertise observé durant nos entretiens Des bureaux en plein Paris (mais aussi à Bordeaux, Nantes, Lille et Lyon) Une assurance santé complémentaire avec Alan 🩺 Une carte Swile pour vos tickets restaurants (10€ par jour) 🍽 Le remboursement des frais de transport en commun à 50% Des primes d’abondement, d’intéressement et une épargne salariale avec Epsor Un abonnement Urban Sport Club Nos consultant.es témoignent 🤝 Chez Elevate, nous avons à cœur d’écouter, valoriser et respecter l’avis de nos consultant.es. Nous vous encourageons à lire les avis de chacun et chacune sur notre page Glassdoor pour avoir plus de détails sur les coulisses de notre aventure 🙂 Notre page Glassdoor 👈 Si vous avez besoin d’un dispositif spécial à l’emploi (situation de handicap) ou d’une autorisation de travail sur le territoire français, faites-nous en part le plus tôt possible pour que les démarches administratives ne ralentissent pas votre arrivée chez nous !","Elevate is seeking a Manager for Data Analysis, Engineering & Science to lead a team of consultants and support clients in their technical and business-related data problems. The position also includes managing and recruiting a team of consultants, developing the agency's commercial practice, transformation of organizations, and participating in avant-garde efforts. Candidates should have at least four years of experience in data analytics, a first-time management experience, and familiarity with GCP, Python and SQL.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,2,1,0.04154662416233763
443,56618,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-h-f_lille,Data engineer,Groupe SII,"{Scala,Dataflow,Java,JAVA,SQL,Python}",Télétravail partiel possible,Lille,IT / Digital,CDI,2023-03-26,"Le Groupe SII est une société de conseil en technologies implantée dans 18 pays au travers de 100 implantations. Plus de 13 000 collaborateurs interviennent quotidiennement sur les problématiques de transformation numérique des grands-comptes. Une entreprise où il fait bon travailler. Labellisée Great Place To Work pour la 5ème année consécutive, SII mène de nombreuses actions liées à la qualité de vie au travail. Au palmarès Great Place To Work 2021 à la première place, le Groupe SII est au cœur de l’innovation et apporte son savoir-faire en accompagnant ses clients sur la transformation numérique. Chez SII Lille, nous leur apportons notre expertise technologique dans les métiers du logiciel et l’ingénierie d’infrastructure pour les secteurs de la distribution, des télécoms, banques et mutuelles. Nos 170 collaborateurs sont animés de cette même passion pour la technologie et la veille permanente, et exercent leur métier dans un cadre bienveillant, de proximité avec une dose de créativité et de fun ! En intégrant le mouvement #fungenieur, vous pourrez mettre en pratique vos acquis et développer de nouvelles compétences dans un climat de responsabilisation, de confiance et de transparence. SII Lille recherche un(e) : Data Engineer (H/F) Intégré à un acteur majeur de la grande distribution, vous intervenez en tant que Data Engineer au sein de l’équipe IT Data en charge des plateformes Big Data. Vous développez et gérez la maintenance de la plateforme Data et d’autres outils mais aussi des flux entre les différentes sources de données de l’entreprise. Vous contribuez à :
• Concevoir et développer les futures fonctionnalités de la plateforme Big Data sous Google Cloud Platform,
• Concevoir les flux d’alimentation et les tables (structure de donnée),
• Automatiser et industrialiser les flux,
• Assurer le run applicatif, le cas échéant. Profil : De formations supérieure en informatique, type Bac+3/5, vous justifiez d’une expérience significative en développement sur un environnement BI et Big Data. Compétences techniques : o Maitrise des langages suivants : SQL, Python (Java/Scala serait un plus)
o Connaissances de Google Cloud Dataflow (Python)
o Anglais nécessaire à l’écrit
o Notion de programmation fonctionnelle Au-delà des compétences techniques, vous faîtes preuve de rigueur, de curiosité et aimez relever les challenges. Vous êtes doté(e) d’un bon sens du service client, êtes organisé et pragmatique. Ces qualités vous permettent de mener à bien le projet. Vous vous reconnaissez dans ces compétences et qualités ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #Fungénieur de SII dans lequel la créativité et l’esprit d’équipe sont mis à l’honneur ! Vous êtes les créateurs de demain, osez mettre en avant vos compétences, investissez-vous dans des projets innovants et venez relever de nouveaux défis technologiques. Expertise, Innovation et fun est le mix que nous vous proposons ! Compétences requises : JAVA, Python, Scala, SQL. Qualités désirées : Organisation, Rigueur, Satisfaction client. Avantages : Très bon CSE, Mutuelle et prévoyance, Tickets restaurant.","SII Lille is seeking a Data Engineer with experience in BI and Big Data to work with a major player in the retail industry. The role involves designing and developing future functionalities of the Big Data platform under Google Cloud Platform, designing data structure and feeding flows, automating and industrializing data flows, and ensuring the application run. The ideal candidate should have a degree in computer sciences and be proficient in SQL, Python, Java/Scala, and Google Cloud Dataflow. Organizational skills, client satisfaction, and curiosity are additional qualities needed for this position. SII offers a positive work environment, and great benefits including a good CSE, health coverage, and restaurant tickets.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
441,56825,https://www.welcometothejungle.com/fr/companies/kooperativa/jobs/data-engineer-m-z_praha,Data Engineer (m/ž),Kooperativa,"{Jupyter,NiFi,MapR,Git,Gitlab,Airflow,Informatica,Kafka,Hadoop,Hive,Spark,Docker,Github,SQL,Zeppelin}",Télétravail partiel possible,"Pobřežní 665 , Praha, 18600","Assurance, Finance",CDI,2023-03-26,"Kooperativa funguje na českém trhu už čtvrt století a za tu dobu vyrostli do velké české firmy s mezinárodním rozhledem i partnery. Mají přes dva miliony klientů a chtějí víc než jen vyhovět jejich přáním a požadavkům, chtějí je předčít. Nechtějí být neosobní společností, ví, že aby byli úspěšní, musí dobře rozumět lidem a jejich osudům. To platí i o přístupu k zaměstnancům, v němž chtějí jít naproti specifickému potenciálu každého z nich a přistupovat férově ke všem bez výjimky. V týmu 6 Data Scientistů a nyní budujeme datalake pro uložení a analytiku velkých a nestrukturovaných dat. Hledáme nadšence pro moderní technologie, který nám pomůže s rozvojem nové platformy. Především pak s automatizací datových toků, architekturou uložení dat, nasazením ML modelů apod. Společným cílem je využít data pro rozvoj společnosti od reportingu až po implementaci modelů ML/AI a posouzení jejich praktického přínosu. Máme spoustu zajímavých analytických úloh zejména z oblastí rizikovosti smluv a klientů, identifikace a generování obchodních příležitostí, segmentace klientského portfolia a online chování klientů. V rámci skupiny VIG zastřešujeme Advanced Analytics Hub pro tvorbu statistických a ML modelů aBig Data Hub pro uchování a velké a nestrukturované data. Co vás čeká? Práce na zajímavých projektech s vysokým pozitivním dopadem na fungování pojišťovny a její klienty Práce s velkými a nestrukturovanými daty obsaženými v datech (telematika, IOT, kalkulace, přepisy hovorů, fotografie nehod, dokumenty …) Zajištění a automatizace datových toků uvnitř i mimo firmu Úzká spolupráce s data scientisty a datovým architektem, budeme součástí jednoho týmu Spolupráce při monitorování a provozu datového prostředí Co budete určitě potřebovat? Dobrou znalost Pythonu nebo PySparku včetně notebooků Jupyter nebo Zeppelin Dobrou znalost práce s relačními databázemi pomocí SQL Znalosti technologií pro DWH nebo datalake Zájem poznávat a učit se nové metody a technologie Co byte mohli znát, ale není to nutností? Předešlé zkušenosti s budováním big data řešení ve velké společnosti Znalost některých z nástrojů a technologií Spark, Airflow, MapR, Hadoop, Docker, OpenShift, Hive, NiFi Zkušenosti s integračními nástroji SSIS, ODI, Informatica, Pentaho Zkušenosti s technologiemi pro datové toky REST API, Kafka apod. Zkušenosti s nástroji pro správu a verzování kódu Git, Gitlab/Github Znalost principů datového modelování ETL/ELT Zkušenosti s nasazením a automatizací DevOps, CI/CD a MLOps Znalost principů a aplikací ML/AI modelů Co vám za to nabídnete? 32 dnů dovolené v roce (25 dnů dovolené + 5 volných dnů + 1 charitativní den + 1 den péče) Flexibilní pracovní doba + možnost práce z domova Cestovní pojištění zdarma, nadstandardní příspěvek na penzijní připojištění (až 1 000 Kč měsíčně) a životní pojištění (až 3 150 Kč měsíčně), těšit se můžete také na velké slevy na naše produkty a na produkty našich obchodních partnerů V rámci bonusového programu Cafeterie dostanete 12.000 Kč (v benefit bodech) a to, jak je uplatňovat, je jen na vás (sport, relax, kultura, dovolená, pobyty, apod.) Dotovaná karta MultiSport za 500 Kč měsíčně Stravné 130 Kč/den (Kooperativa nám nájem 105 Kč) - v Praze máme vlastní jídelnu, bistro a kavárnu Interní i externí kurzy (IT a jazykové kurzy, vzdělávací platforma Seduo), firemní kouč a psycholog, využít můžete i naši firemní knihovnu Rozvojové a sportovní akce, zdravotní a preventivní programy, ale také možnost nadstandardní zdravotní péče (fyzioterapie, jóga, očkování) Za doporučení nového kolegy vás oceníme až 45 000 benefit body do Cafeterie Zaměstnanecký mobilní tarif, pracovní telefon a notebook je samozřejmostí","Data Scientist with strong knowledge of Python, PySpark, SQL, and technology for DWH or datalake. The successful candidate will work on interesting projects with a positive impact on the insurance company and its customers, including working with large and unstructured data, automating data flows, and collaborating with data scientists and data architects. Bonus skills include experience with big data solutions, Spark, Airflow, MapR, Hadoop, Docker, OpenShift, and ML/AI models. The company offers flexible working hours, 32 days of vacation, travel insurance, and various bonus programs.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
440,50349,https://www.welcometothejungle.com/fr/companies/neoxia/jobs/canada-data-engineer-scientist-confirme-senior-2-ans-d-experience-minimum_montreal,Canada 🇨🇦 Data engineer/scientist confirmé/sénior (2 ans d'expérience minimum),Neoxia,"{Snowflake,Synapse,Azure,Microsoft,Dask,NoSQL,AWS,Teradata,http,Java,SQL,Hadoop,Scala,Prefect,Redshift,Airflow,via,R,Spark,BigQuery,GCP,Python}",Télétravail partiel possible,"Montréal, H2L","Logiciels, IT / Digital",CDI,2023-02-07,"À propos de Neoxia Créée en 2000, Neoxia accompagne des entreprises, de la start up au très grand groupe, dans leur transformation numérique en réalisant des projets informatiques ambitieux et innovants sur le Cloud. Nous sommes aujourd’hui un partenaire certifié auprès d’Amazon Web Service (AWS), Google Cloud Platform (GCP) et Microsoft Azure. Passionnés de technologie, les “Neoxiens” ont des profils variés, du data engineer au développeur full-stack, en passant par le designer UX/UI, le développeur mobile, le Scrum master, ou encore le DevOps pour accompagner les entreprises à toutes les étapes de leur transformation numérique. Les avantages Neoxia sont : Du télétravail en mode hybride (1 jour par semaine au bureau minimum) Une assurance collective 4 semaines de vacances Être accompagné et progresser dans des technos qui te font vibrer, le tout dans une ambiance de solidarité et de bienveillance 20 % du temps consacré à la R&D Du temps et du financement pour des certifications et des sandbox Cloud De la formation en interne avec des formations et une plateforme de partage de connaissances : la Nx-Academy ! Partager avec tes collègues aussi bien une partie de PS4 que des bonnes pratiques de dév Des événements d’équipes fréquents (barbecue, fins de semaines, etc.) De beaux locaux en centre-ville Évoluer au sein d’équipes d’une grande diversité Du carburant pour coder (kombucha, thé et café bien sûr) Des possibilités d’évoluer rapidement au sein d’une entreprise en pleine croissance Collaborer avec des ONG partenaires de Neoxia sur des projets à fort impact social et environnemental Tu peux en découvrir plus sur la culture de Neoxia sur https://discover.neoxia.com / Rencontre l’équipe en vidéo - Matthieu Chappaz, directeur de Neoxia Montréal / http://www.youtube.com/watch?v=JmD7gnHZ4q8 Gilles Mergoil, Président du groupe Neoxia / https://www.youtube.com/watch?v=FMV_C44tppU Yann Coleu, architecte Cloud / https://www.youtube.com/watch?v=Vk-znZBsL1k&list=PLUndIPKSZI5TZViwSoNuAnNbdqr2XlY3W Côté Data, de la partie Engineering jusqu’à la partie Ops en passant par le Machine Learning, notre équipe de spécialistes en pleine croissance s’attaque à tous les challenges autour des données qui nous entourent. Google Cloud, Amazon Web Service et Microsoft Azure sont nos partenaires, et nous construisons avec eux des solutions Data robustes, performantes et innovantes. En tant que Data engineer/scientist confirmé/sénior, tu rejoindras une équipe Data en pleine croissance, et pourras participer à la faire grandir. Tu apporteras également ton expertise sur les projets tout au long des cycles de conception, de développement et de déploiement pour continuer à apprendre tout en aidant les personnes autour de toi à grandir. Tes actions pourront regrouper notamment : Préconiser une architecture et des technologies adaptées au contexte du client Définir des standards technologiques internes à partir de benchmark et d’une analyse des spécificités du client Garantir dans le temps la cohérence technique des plateformes Data Prototyper les solutions techniques préconisées Assister les équipes internes du client ou celles déployées par Neoxia dans la mise en oeuvre des solutions techniques préconisées Encadrer les équipes de consultants grâce à la formation et au coaching, et suivre la mise en place des bonnes pratiques Assurer une veille technologique et diffuser les connaissances via l’organisation d’ateliers au sein de neoxia ou de meetup ouverts à la communauté Participer aux réponses aux appels d’offres et assister l’équipe commerciale en tant qu’expert technique de la Data Dans ton quotidien, tu contribueras au partage et à la capitalisation des savoirs et des pratiques sur notre plateforme de partage NX-Academy Maîtrise du français Tu justifies d’au moins 2 ans d’expérience sur des projets 100% Data Diplômé(e) en informatique ou en sciences Dynamique et rigoureux(se), tu as un bon relationnel. Tu es à la fois autonome et à l’écoute des autres. Humble, tu sais ce que tu sais faire et ce que tu ne sais pas faire pour tenir et respecter tes engagements Tu es passionné(e) de technologie et curieux(se) au sujet de l’évolution des pratiques d’ingénierie logicielle (Continuous Delivery, DevOps, …) Compétences Maîtrise d’au moins un langage de programmation : Python, Scala, Java Maîtrise des bases de données SQL et/ou NoSQL Maîtrise des services Data d’un des Cloud Provider GCP, AWS ou Azure Maîtrise des fondamentaux liés aux bases de données et aux Datawarehouse, avec de précédentes expériences sur Redshift, Teradata, BigQuery, Snowflake ou Azure Synapse Maîtrise des concepts et des solutions d’orchestration des données : Airflow, Prefect Maîtrise des principaux concepts autour des traitements distribués des données (Spark, Dask ou Hadoop) Connaissances autour des bonnes pratiques DevOps (Optionnel) Connaissances en machine learning Un échange RH d’environ 30 minutes pour te présenter l’entreprise et le process de recrutement Un test technique en ligne pour découvrir tes connaissances Data (optionnel pour certains profils) Un “use case” d’1h30 avec l’un de nos lead tech Une dernière étape avec Matthieu Chappaz, directeur de Neoxia Montréal, pour vérifier que Neoxia correspond à ce que tu recherches, et vice-versa","Neoxia, a digital transformation company, is seeking a senior Data Engineer/Scientist to join their growing team. The successful candidate will have at least 2 years of experience in 100% data projects, a degree in computer science or sciences, and proficiency in programming languages such as Python, Scala, and Java, as well as SQL and/or NoSQL databases. Additionally, experience with cloud providers such as AWS, GCP, or Azure, as well as data orchestration tools and distributed data processing technologies like Spark and Dask, are desired. The role includes defining technological standards, assisting with project implementation, coaching and training colleagues, staying up-to-date with technological developments, and participating in the recruitment process. Neoxia offers benefits such as work-life balance, health insurance, vacations, R&D time and financing, internal training and knowledge-sharing platforms, and a collaborative team environment.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
398,34914,https://www.welcometothejungle.com/fr/companies/veepee/jobs/software-engineer-for-data-h-f_lyon,Software Engineer for Data,Veepee,"{Beam,k8s,Protobuf,gitlab,Kubernetes,Airflow,dbt,gRPC,kubernetes,Bigquery,Dataflow,Java}",Télétravail partiel possible,Lyon,E-commerce,CDI,2022-08-08,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire européenne avec la convergence des différentes sociétés qui le composent et leurs 6 000 collaborateurs vers une seule et même marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd’hui présent dans 14 pays et devient un acteur majeur du commerce digital européen, avec 72 millions de membres et un volume d’affaires de 3,7 milliards d’euros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour réveiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos stratégies, afin de proposer la meilleure expérience possible à nos clients. Vous avez soif d’apprendre ? Veepee vous permet de construire votre parcours parmi une pluralité de métiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes… prenez part à une aventure humaine au cœur d’enjeux digitaux. Impatients de les rencontrer ? Ils ont hâte aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a Software Engineer in Veepee’s data organization, you will.. .. be part of our data organization Veepee’s data organisation came into existence in 2018 and consists of a strong team of 40-50 data professionals, spread across different data domains (engineering, analytics, data science & ML and governance). You will be part of a multidisciplinary, multinational team that fosters collaboration, transparency, respect and of course… a good amount of fun in the working environment. .. build and maintain APIs, tools and pipelines that form Veepee’s data platform For its data platform, Veepee firmly believes in a Push - Load - Transform strategy of ingesting data. Products are responsible for the data they produce and our data platform should enable them to push that information (in real-time) into our data platform in a governed way. Hence, we adopted data contracts to define which data comes in and have built our own set of tools and API’s around this to facilitate data ingestion, Veepee style. Furthermore, we keep improving our toolchain for data transformation (using dbt) and data exposure downstream. Responsibilities: Be part of a team running a set of applications with high SLA requirements; Develop, deploy and maintain a large Java stack serving a set of APIs mainly developed in gRPC & Protobuf Support, design, implement and deploy microservices running on Kubernetes with a Gitops approach; Identify data producer and consumer requirements and implement pragmatic and robust solutions based on solid architecture patterns (Reactive, Operator, Resilient..); Maintain data pipelines and data jobs mainly developed with Apache Beam and Apache Airflow; Keep improving your technical knowledge and expertise by attending conferences, contributing to open-source projects organizing and attending meetups Requirements: You have a strong experience (3-5 years) working on a large Java stack; You know how to implement and consume APIs, preferably in Protobuf & gRPC; You love making clean code and you are interested in having successful software engineering practices (Unit tests, pair programming, code reviews). You would like to help the team to grow in the quality of what they produce and their methodologies; You have experience with setting up CI/CD pipelines, preferably in gitlab; You have significant experience working with microservices and Kubernetes; You know or want to use helm charts as a templating language for k8s crd’s; You know or want to use the concept of a GitOps strategy for deploying kubernetes resources, preferably using ArgoCD; You are willing to learn data engineering concepts, tools and frameworks (Apache Beam, Apache Airflow, dbt); You would like to work with Google Cloud Platform (Bigquery, GKE, Dataflow); You know or want to learn Infrastructure as Code tools like terraform, atlantis; You are a strong team player. What we offer: The dynamic and creative environment within international teams; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences locally and internationally; Hybrid work organization and flexibility for full remote contracts; Advanced remote practices and tools. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you’ll be sure to find your place, no matter the technology you want to work with. If you love to try things why don’t you jump on this new adventure? Need more info > https://careers.veepee.com/en/careers/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, part of the vente-privee group, is looking for a software engineer to join its data organisation. The successful candidate will be responsible for building and maintaining APIs, tools and pipelines on Veepee's data platform, developing microservices and deploying them on Kubernetes with a Gitops approach. The ideal candidate will have three to five years of experience working on a large Java stack and experience implementing and consuming APIs, preferably in Protobuf and gRPC. Furthermore, experience with microservices, Kubernetes, CI/CD pipelines and data engineering tools like Apache Beam, Apache Airflow, and dbt is sought.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
395,39813,https://www.welcometothejungle.com/fr/companies/easypicky/jobs/data-engineer_montpellier,Data Engineer,Easypicky,"{NoSQL,SQL,Python}",Télétravail partiel possible,"621, Rue Georges Méliès, Montpellier, 34000","Application mobile, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",CDI,2022-11-29,"Start-up montpelliéraine créée en 2017, EasyPicky révolutionne l’univers de la grande distribution avec son application vidéo basée sur de la reconnaissance vidéo offline. Sa solution permet aujourd’hui aux marques de contrôler, organiser et optimiser à chaque instant la présence et la visibilité de leurs produits en magasin. La technologie de reconnaissance d’images développée par EasyPicky peut être déployée sur n’importe quel système embarqué et utilisée partout sans connexion, et ça, c’est une véritable révolution technologique ! Le poste : Dans un contexte de forte croissance de nos équipes - 🚀 x4 en 2021 🚀 – tu rejoindras l’équipe Tech & Product en tant que Data Engineer. Ton rôle en tant que responsable de la donnée sera de mettre en place et maintenir les services nécessaires pour fournir de manière optimale une donnée structurée et propre aux différentes équipes de l’entreprise. Dans ce cadre, tes missions seront de : • Faire un diagnostic des bases de données existantes ; • Concevoir et mettre en place une base de données unifiée, afin d’organiser et structurer nos données ; • Exécuter des requêtes de données (SQL/NoSQL) performantes ; • Détecter et réparer les anomalies dans la base de données ; • Définir les KPIs permettant de mesurer la qualité et la performance de la base de données ; • Gérer plusieurs workflows intégrant la donnée à destination du reste des équipes Tech ; • Apporter son savoir-faire technique afin d’améliorer et de moderniser la gestion de nos bases de données. Ton profil : • Titulaire d’une formation Bac+5 de type école d’ingénieur en informatique ou équivalent universitaire, tu disposes d’une expérience de 6 ans minimum en Data Engineering. • Tu as eu l’occasion de mettre en place des outils et plateformes de traitement de données. • Tu es à l’aise avec les bases de données SQL/NoSQL, Python, gestion workflows, la construction et la maintenance de pipelines de données. • Tu possèdes un niveau suffisant d’anglais technique. • Tu es curieux, bon communiquant et as une bonne compréhension du business pour traduire les besoins en termes de collecte et de transformation de données. Premier entretien RH de pré-séléction Rencontre avec Manager IT et Team-Leads Entretien avec CEO","EasyPicky, a start-up that revolutionizes the retail industry with offline video recognition technology, is seeking a Data Engineer to join its Tech & Product team. The successful candidate will diagnose existing databases, design and implement a unified database, execute performant data queries, detect and fix anomalies, define KPIs, manage multiple workflows integrating data, and use technical expertise to improve database management. The ideal candidate must have a minimum of six years of experience in data engineering, comfort with SQL/NoSQL databases, Python, workflow management, and data pipeline construction and maintenance. Good communication skills, business acumen, and technical English proficiency are also essential.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,2,1,0.04154662416233763
317,56303,https://www.welcometothejungle.com/fr/companies/inferensia/jobs/consultant-data-engineer-data-scientist_lyon,Consultant Data Engineer - Data Scientist,Inferensia,"{Git,Talend,Kubernetes,PowerBI,Informatica,AWS,Docker,Kafka,R,Spark,GCP,Java,NoSQL,SQL,Python,Postgres}",Télétravail partiel possible,"136 Cr Lafayette, Lyon, 69003","Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",CDI,2023-03-26,"Inferensia est un acteur du marché Data et Innovation qui attache une grande importance au pragmatisme et à la valeur de ses interventions. En tant que cabinet de conseil, nous : accompagnons nos clients sur leurs besoins leur permettons de se focaliser sur leur cœur de métier amenons/apportons nos savoir-faire et expertises donnons à nos clients les moyens de devenir autonomes suite à notre mission/intervention Nos domaines d’intervention : transformation et diagnostic des organisations pilotage & AMOA data (roadmap, modélisation, intégration, reporting/dataviz…) expertise technique (architecture, cloud, API management…) Nous nous nourrissons de ces missions et expériences afin d’en retirer les meilleures idées et d’industrialiser des solutions au sein de notre DataLab. Ce dernier est en construction permanente et permet de valoriser et pérenniser les projets internes de R&D. Un des premiers produits de ce DataLab est une plateforme SaaS multi-usages fondée sur la data qui centralise les diligences liées aux Risk & Compliance : la solution Kantik. Notre originalité est de réussir à garder une forte identité et une appartenance à Inferensia tout en étant en mission pour nos clients. Nos valeurs sont le fondement de notre fonctionnement et constituent le moteur de cette belle aventure qu’est Inferensia : Compétence, Proximité, Ecoute et Innovation. Dans un contexte de forte croissance, Inferensia renforce ses équipes en recrutant un(e) Consultant(e) Data Engineer / Data Scientist Confirmé(e) ayant une forte appétence pour les sujets techniques. Vous avez déjà 2 à 5 ans d’expérience professionnelle. Véritable couteau-suisse, vous avez une connaissance pratique des différents enjeux de la réalisation et de l’industrialisation d’un projet Data/IA de même que les méthodologies, outils et techniques d’implémentation des différentes briques techniques et applicatives composantes. Vos missions consisteront en : L’écoute et l’analyse du besoin client La conception des solutions par des propositions d’architectures applicative, fonctionnelle et technique La conduite et le suivi de l’implémentation des solutions L’optimisation des performances des algorithmes de traitement de données, des pipelines Data ou encore des algorithmes d’intelligence artificielle Vous aimez encadrer techniquement les équipes et les accompagner dans leur montée en compétence. Vous êtes à l’aise pour rédiger des documents techniques comme des normes de développement ou des spécifications. Vous souhaitez évoluer vers un poste d’expert ou de référent technique. Vous interviendrez sur des sujets tels que : des projets clients (Data Science, Data Engineering, Data Analytics…) des missions d’aide au choix d’outils la définition de roadmaps data l’avant-vente (réponses à appels d’offres, démonstrations…) la formation des collaborateurs Vous serez également amené(e) à participer à nos projets internes. Doté d’un excellent relationnel, avec l’ambition d’évoluer dans un contexte innovant et challengeant lié aux sujets Data / Big Data / IoT / Data Science / Cloud… Innovation ! Vous aimez travailler en équipe, and you are fluent in english ! Nous sommes basés sur Lyon et ouverts au télétravail. Possibilité de déplacements ponctuels. Compétences minimum attendues : Bac +5 Minimum 2 ans d’expérience professionnelle Maitrise des solutions de collecte, traitement, analyse et visualisation de la data Capacité d’écoute et d’analyse Capacité d’adaptation Stack technologique : Langage de programmation : Java, Python … Gestion et stockage des données : SQL, RDBMS (Postgres), NoSQL Big Data : Spark, Kafka, .. ETL : Talend, Informatica… Analytics : ML/DL Visualisation : QlikSense, PowerBI Cloud : AWS / GCP/ Scaleway/ … Versioning & Déploiement : Git, Outils CI/CD, Docker, Kubernetes, MLOps Deux entretiens pour échanger sur votre parcours et vos envies, et comprendre l’ADN d’Inferensia Inferensia s’engage à accorder une attention particulière à la promotion de la diversité, de l’inclusion et de l’égalité au sein de ses équipes, et ainsi, à étudier équitablement chaque candidature.","Inferensia is seeking an experienced Data Engineer/Scientist with a strong technical background to join their team in Lyon. The ideal candidate will have 2-5 years of professional experience and be proficient in data collection, analysis, visualization, and architecture. The role involves analyzing client needs, designing technical solutions, overseeing implementation, and optimizing data processing algorithms. The company emphasizes practical expertise and innovation and values competence, proximity, listening, and innovation. Candidates should have excellent communication skills, be comfortable working in a team, and have a strong desire to work in a challenging and innovative environment. Fluency in English is also required.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
394,50467,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-f-h_bordeaux,Data Engineer Confirmé,Thales,"{MySQL,durable,Qlikview,python,Talend,Nifi,Gitlab,bash,PostgreSQL,Docker,Kafka,Azure}",Télétravail partiel possible,Bordeaux,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2023-02-07,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Sur le Campus Thales Bordeaux, nous concevons, développons et livrons des systèmes, des équipements et des services pour assurer la réussite des missions aéroportées de nos clients, dans les domaines du transport, de la surveillance et du combat. Le Département Ingénierie des Solutions Digitales et des Servcices (ISDS), recherche un Data Engineer Confirmé (F/H) , en CDI à Bordeaux. QUI ETES-VOUS ? Vous possédez une réelle expérience de TechLead dans le domaine du data management ? Vous maîtrisez la chaine de traitement de la donnée de sa collecte à sa restitution, en passant par son stockage, sa fiabilisation et ses traitements ? Nos technologies et concepts vous sont familiers ? Azure, Azure Stack Gitlab-ci, Docker Nifi, Talend , Dataïku, Kafka Langage de scripting (bash, python, …), PostgreSQL, MySQL Suite ELK Qlikview, Qliksense Vous savez défendre vos convictions auprès de clients internes ? Vous souhaitez combler votre curiosité technique dans un cadre de travail agile ? Vous aimez travailler en autonomie dans votre expertise au sein d’une équipe dynamique ? Pédagogie, bonne communication et esprit d’équipe sont des atouts que l’on vous reconnait ? Si la réponse à toutes ces questions est oui, alors la suite va vous intéresser ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Au sein de la Direction Soutien et Services Client (CSS), vous intégrez le pôle DATA de l'Ingénierie des Solutions Digitales des Services (ISDS) afin d'accompagner la croissance d'une équipe à taille humaine. Vous rejoignez une équipe pluridisciplinaire de 18 personnes , au cœur des relations avec l'ensemble des intervenants techniques de notre écosystème. En tant que Data Engineer Confirmé, vos principales missions sont de concevoir, mettre en œuvre et maintenir des chaines de traitements de la donnée tout en apportant un support technique aux membres de l'équipe. En nous rejoignant, vos principales missions seront les suivantes : • Comprendre le besoin métier et être force de proposition pour les exigences formulées par les Product Owner, • Définir des solutions techniques, en accord avec l'architecte Solution, permettant de gérer le flux de données, • Accompagner l'équipe dans la réalisation et la maintenance des solutions, • Travailler la mise en qualité de la donnée et contribuer à sa gouvernance, • Participer à la modélisation de bases décisionnelles et au maintien et à l’évolution de bases de données relationnelles, • Apporter un support aux métiers et assurer une veille technologique. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is seeking an experienced Data Engineer who is familiar with Azure, Gitlab-ci, Docker, and other technologies to join their team in Bordeaux. The ideal candidate should possess excellent technical skills and be able to work independently while collaborating with a dynamic team. They will be responsible for designing, implementing, and maintaining data processing chains while providing technical support to team members. They should have experience as a TechLead in data management and strong communication and team skills.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
355,37369,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-big-data-h-f_montpellier,Data Engineer Big Data,CGI,"{Python,MongoDB,Neo4j,Scala,Kafka,Cassandra,Hive,Spark,Git,Java,NoSQL,Hadoop,nifi}",Télétravail partiel possible,N,"IT / Digital, Transformation, Big Data",CDI,2022-10-18,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 25 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, … Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python. Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 200 consultants) ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial. En tant que Data Engineer, vous serez intégré à un pôle de consultants spécialistes du Big Data intervenants sur des projets stimulants. Vos missions seront : • Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques • Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…) • Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…) • Participer à l'élaboration et la révision de normes / documentation technique • Animer des formations internes. Accompagner la montée en compétences des équipes • Assurer un support technique Big Data aux équipes et aux clients au quotidien Accompagné et entouré par une communauté Data passionnée, l’échange, le partage et les formations vous offriront un véritable espace pour vous épanouir. La proximité et le suivi personnalisé de votre manager, puis un bon nombre d’événements tout au long de l'année, renforceront encore la convivialité et l’esprit d'équipe ! Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data. Passionné d’informatique et de données, vous aimez le travail en équipe, apprendre et partager. Vous êtes également doté d'un esprit audacieux et ambitieux. Vous faites preuve d’initiative et travaillez sur le long terme. Vous justifiez de 2 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le Domaine du Big Data. Vous disposez d'une vision large des technologies et vous maîtrisez au moins une technologie Big Data. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital services and consulting, is seeking a Data Engineer to work in its Big Data team, which provides services to different sectors, including Banking, Retail, Energy, and Transportation. The ideal candidate should have experience in data engineering, understanding of Big Data tools such as Hadoop, Spark, Hive, Kafka, and NoSQL databases, and capable of working with one of these languages, Java, Scala, or Python. The successful candidate will participate in analyzing, advising, developing, and implementing solutions while working in an agile environment. This role offers opportunities for professional growth and development, including leading technical teams or consulting Data Solutions.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
354,34807,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_VbP0ybe,Data Engineer,TotalEnergies Digital Factory,"{Kafka,Spark,Azure,SQL,Python}",Télétravail partiel possible,Paris 02,"Logiciels, Big Data, Energie",CDI,2022-08-08,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. TotalEnergies a décidé d'accélérer la production interne de solutions digitales pour ses activités en créant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilité et l'esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Nous créons et déployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. Nous considérons les personnes comme la ressource la plus précieuse pour réussir, c'est pourquoi nous tenons non seulement à recruter les meilleurs talents, mais aussi à créer des liens uniques entre nos employés. En accord avec les politiques HSE de la compagnie et celles de la Digital Factory, le/la Data Engineer intégrera l'équipe « Delivery », qui intervient dans la production des Minimum Viable Products (MVPs). En soutien de la Squad dans l'organisation des données, cette équipe évolue dans un contexte agile (scrum/scrumban), en mode itératif et co-constructif, en s'appuyant sur l'intelligence collective. Votre rôle est de garantir la qualité des pipelines data du produit, assurer le développement des programmes pour collecter, préparer, transformer et diffuser les données. Missions : Concevoir, construire et intégrer des données, au sein de la squad et en collaboration avec les autres squads Assurer le stockage, la consommation, l'intégration et la gestion des données des cas d'utilisation. Faire l'analyse de l'accessibilité des données et recommander des solutions pour leur intégration. Coordonner la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de données. Intégrer les données dans le data lake. Collaborer avec les data scientists pour la réalisation des modèles de prédiction. Produire un code de qualité, mettre en place des tests automatisés pour le contrôler. Interagir avec les architectes et les autres data engineers, pour s'assurer de l'efficacité des solutions et apporter des préconisations techniques Maîtriser les bonnes pratiques de monitoring des flux de données. Assurer la veille technologique sur les architectures data et les nouvelles technologies. Coacher et accompagner la communauté des Data Engineers de la Digital Factory. Vous êtes diplômé/e d'un Master ou d'une école d'ingénieur spécialisée en informatique ou mathématiques. Vous avez au minimum 2 ans d'expérience en data engineering. Vos compétences techniques sont reconnues en Python, Spark et SQL. Vous avez une bonne connaissance sur les bases de données relationnelles et non relationnelles Vous mettez en place des pratiques de test systématiques pour vérifier la qualité de votre code. Vous avez la capacité à concevoir et à mettre en uvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle. Vous avez une première expérience sur un provider de Cloud, Azure de préférence et maîtrisez la scalabilité en temps réel (Kafka). Vous comprenez le machine learning. Vous avez un niveau de français et d'anglais courant.","TotalEnergies is seeking a Data Engineer to join their Digital Factory team, which is responsible for creating and deploying digital solutions for the company's energy production and supply activities. The successful candidate will ensure the quality of data pipelines, develop programs for collecting, preparing, transforming, and disseminating data, coordinate the implementation of data architecture, and collaborate with data scientists to build prediction models. The ideal candidate should have at least 2 years of experience in data engineering, strong technical skills in Python, Spark, and SQL, and familiarity with relational and non-relational databases and cloud providers (preferably Azure). They should also be able to design and implement large-scale data loading, manipulation, processing, analysis, and exploration solutions, understand real-time scalability, and have a good understanding of machine learning. Fluency in French and English is required.",Bac +5 / Master,Entre 250 et 2000 salariés,> 1 an,2,1,0.04154662416233763
226,56857,https://www.welcometothejungle.com/fr/companies/ekimetrics/jobs/data-engineering-architect-h-f-n-paris_paris,Data Engineering Architect /N) - Paris,Ekimetrics,"{precisely,durable,GCP,regard,color,pilot,AWS,scale,Spark,Azure,SQL,Python}",Télétravail partiel possible,"36, Rue La Fayette, Paris, 75009","IT / Digital, Stratégie, Audit, Big Data",CDI,2023-03-26,"Ekimetrics est leader en data science et fournisseur de solutions AI. Depuis plus de 16 ans, nous utilisons de performance marketing, business et de la transition vers une performance plus durable. Notre obsession : réconcilier gains business à court terme et création de valeur à long terme. Nous sommes une entreprise indépendante parmi les plus importantes dans le monde avec plus 400 experts data, sur trois continents : Europe, Amériques et Asie. Depuis 2006, nous avons mené plus de 1000 projets data science dans plus de 50 pays, générant milliard de profit pour nos clients. Ekimetrics a pour ambition repenser la manière dont elles opèrent, en réconciliant indicateurs financiers et objectifs durables grâce à la data. Nous développons des solutions d’IA et data science garantissant à nos clients des optimisations à fort impact, alignées avec leur stratégie de marque et leurs enjeux de durabilité Quelques chiffres clés : 16 années d’expérience en Data Science +400 data scientists 4 bureaux à Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit généré pour nos clients depuis 2006 +1000 projets Data Science Ekimetrics is the European leader in data science with +320 data scientists and +1,000 projects since 2006. Thanks to our global presence in Paris, London, NY, HK, we lead projects in +50 countries in all industries (automotive, financial services, retail, telecom, health, etc.). We help companies steer their data opportunity, build data capabilities , and deploy actionable solutions , to power up marketing and operational performance , as well as (re)energizing business models . Our primary focus is to deliver immediate business gains , while guaranteeing sustainable data capital for our clients. We are committed to the most advanced data science, and to building fair and conscious data & AI practices . Key figures: 16 years experience in Data Science +320 consultants, all are also data scientists 4 offices in Paris, London, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1Bn profit generated for our clients since our creation +1,000 Data Science clients projects Data Architecture & Engineering team To help operationalize our data science projects among business lines, actively contribute to the transformation of our clients’ infrastructure and organization, and democratize data driven approaches, we have created a department for data architecture and data engineering. This team is at the core of the ability to industrialize data science and build the environments to scale while supporting wider user access to analytics. By combining our expertise on data analytics with technical expertise, the team builds environments and processes to enable live production systems integrated into our clients’ IT systems, with adequate levels of architecture, governance, security, scalability, maintainability, and resilience. Our Data Architecture & Engineering team consists in Architects, Data Engineers and DevOps Engineers. We are passionate about data processing, data quality and eager to solve data-centric issues. We love sharing our expertise, teach and enjoy our craft. Job responsibilities As a Data Architect, you will be involved in challenging projects with international blue-chip clients across diverse industries, building bespoke analytics solutions to answer the key questions and consulting on the findings, including high-profile presentations to senior clients. You will be working in teams, with other consultants (data scientists, data engineers or web developers) on 1 or 2 projects simultaneously. More precisely, your responsibilities will include: 1. Data Architecture & Innovation · Lead assessments, strategies, and architecture recommendations · Own the full cycle of the industrialization of data projects, from advisory to audit and review activities, with customers interactions ranging from technical teams to CIOs · Be responsible for the data engineering code organization as well as data modelling approaches. The Data Architect will contribute to these topics with the other Lead Data Engineers (Governance, DevOps, etc.) · Present actionable and easy-to-understand recommendations to drive high levels of adoption within client organizations · Acting internally as an innovator and technical lead: we are continuously building engineered and enriched technical custom solutions for our clients 2. People Development · Proactively contribute to the development of more junior team members, for them to have stronger impact across core all areas of the clients’ businesses · Share projects and practices within the team and more generally within Ekimetrics, be an ambassador one of our values: Transmission · Participate and create/give technical trainings withing our internal training program Eki. Academy · Contribute to the recruitment of new Data Engineers, Data Architects and therefore to the growth of the team 3. Business Management & Consulting · Design and scope new projects, using the right analyses to answer client questions · Participate in pre-sales of Ekimetrics projects, · Deliver with excellence – ensure high client satisfaction and make sure that issues are raised and resolved in a timely manner with no surprises · Ensure client's business case is achievable and Ekimetrics has appropriate ability to influence promised outcomes · Drive high client value and broaden relationships at the most senior levels with current and prospective clients and translate this into new business opportunities for Ekimetrics. · Evangelising externally the innovative business solutions we offer to our clients by participating in thematic conferences or other specific tech exhibitions/events Candidate’s profile Qualifications The successful candidate will have a minimum of 8-10 years of professional background, with a proven expertise in both BI and Big Data architectures, either on-prem or in the Cloud. While working closely with the other members of the Data Engineering team, you will need to be autonomous enough to handle all meetings with customers on data architecture topics. The successful candidate will also prove a balance of business strategy understanding, client-facing consulting experience, and significant data and analytics expertise. The work will be rooted in the creation of innovative analytic engagements for clients. Technical skills · A Ph.D. or Master's degree in a quantitative discipline such as computer science, statistics, applied mathematics from a leading academic institution is preferred · 8+ years of experience in Data Analysis / Data Architectures / DWH / Data Lakes in a business setting, preferably in a client-facing consulting-oriented role · Passion for data, extensive knowledge in statistics or applied mathematics, experience with techniques such as Machine Learning · Expertise in key technologies related to Data Management: o SQL, Spark, Python, o Cloud platforms (Azure, GCP, AWS, etc.) · Expertise in some aspects of Data Management and readiness to grow in the others: o Data analytics architectures o Data governance processes and platforms o Data ingestion & transformation in data-warehouses or data-lakes o Data visualization Soft skills · Excellent communication skills – especially translating complex technical findings into plain language insights and stories for stakeholders · Demonstrated ability to develop new and lasting client relationships at senior levels across multiple industries · Team oriented and collaborative working style, both with clients and within Ekimetrics · Management experience and demonstrated ability to develop younger talent and build a high performing team. · Project management and delivery expertise · Passion for joining a small team and desire to help the business grow quickly What we offer For the first time Ekimetrics is certified Great Place to Work ! · Competitive package in a data science company · Challenging, diverse and complex missions with an early client exposure · Creative and entrepreneurial start-up environment with vertical mobility · A unique learning experience: You will be the pilot of your own career development · A culture of Innovation and Knowledge · International mobility opportunities that help boost your career. Ekimetrics is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or other legally protected categories, subject to applicable law.","Ekimetrics, a leader in data science and AI solutions, is seeking a Data Architect with 8-10 years of experience in BI and Big Data architectures. The successful candidate will be responsible for leading assessments, strategies, and architecture recommendations, developing data engineering code organization, presenting recommendations to drive high levels of adoption within client organizations, and contributing to the development of more junior team members. Additionally, the candidate should have expertise in data management technologies such as SQL, Spark, and Python, and possess excellent communication and team-working skills. The job offers a competitive package and international mobility opportunities.",Non spécifié,Entre 250 et 2000 salariés,> 7 ans,2,1,0.04154662416233763
351,37262,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/data-engineer-h-f_wasquehal_EF_RgN1Kwp,Data Engineer,EPSILON France,"{Talend,EPSILON,Informatica,Spark,SQL,Python,marquez}",Télétravail partiel possible,N,"Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2022-10-18,"EPSILON France est l’agence data Marketing du Groupe Publicis. Elle accompagne la transformation business des entreprises grâce à la data, au marketing et à la technologie. C’est le plus grand acteur datamarketing en France, avec 750 talents : Data Scientists, Digital Marketers, IT Experts, Business Analysts qui aident les entreprises à stimuler leur croissance et améliorer leur efficacité opérationnelle grâce et autour de la data. Toute notre équipe Data vous attendent ! Le pôle Data Management est constitué de 60 passionnés et experts et de la data. Le pôle est en charge d’une dizaine de plateformes data internationales et couvrant l’ensemble de use cases CRM et Data Marketing. Sa mission : mettre en place des solutions et plateformes permettant aux clients de valoriser, exploiter et produire leurs données CRM. Au sein d’une équipe dédiée à un client grand compte international vous pourrez travailler sur de la mise en place de processus de data flow ou l’écriture de programmes de calcul d’indicateurs métiers et business. Que fait un Data Engineer ? Analyser les demandes fonctionnelles des clients. Spécifier techniquement les besoins du client en collaboration avec le chef de projet fonctionnel. Rédiger les spécifications techniques associées. Développer les traitements, procédures et flux. Réaliser et formaliser les tests techniques, Optimiser les traitements, procédures et flux Installer et déployer les développements en production Vous marquez des points si : Vous êtes un expert du développement sur SQL, et avez une expérience d’au moins 2 ans en tant que Data Engineer ou développeur ETL. Vous maîtrisez un (ou plusieurs) ETL : Informatica, Datastage, Talend ou Stambia … Votre plus : Une première expérience sur Spark et Python ! Ce qu’on attend de vous : Bon esprit d’équipe. Appétence prononcée pour les nouvelles technologies (Big Data, Cloud...).","EPSILON France is seeking a Data Engineer who will analyze functional client requests and specifications. They must have at least 2 years of experience in SQL development and be proficient in one or more ETL tools such as Informatica, Datastage, Talend or Stambia. A passion for new technologies such as Big Data and Cloud is also expected.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
348,58084,https://www.welcometothejungle.com/fr/companies/groupe-credit-agricole/jobs/data-engineer-h-f_guyancourt,Data Engineer,Groupe Crédit Agricole,"{Jenkins,Talend,unix,Informatica,via,Git,SQL}",Télétravail partiel possible,"Boulevard des chênes, Guyancourt, 78280","Banque, Assurance",CDI,2023-03-26,"Filiale du groupe Crédit Agricole, Crédit Agricole Payment Services, leader des services de paiement en France avec près de 30% de part de marché, conçoit des solutions de paiement destinées aux entités du groupe. Au cœur de la relation client, les paiements font partie des usages quotidiens et évoluent sur un marché dynamique en perpétuelle transformation. Pilote de la stratégie paiement du Groupe, Crédit Agricole Payment Services conçoit le processing des transactions réalisées par les clients des banques du groupe et développe pour eux des offres de services innovantes, conjuguant facilité d’usage, sécurité et répondant aux meilleurs standards du marché. En tant qu’ingénieur data au sein du pôle Data Engineering, vous aurez pour principales missions : 1. La prise en charge de la chaîne CI / CD Conception / Paramétrage / Pilotage et suivi de l’implémentation Intégration de la chaîne dans les processus existants Accompagnement du changement auprès des utilisateurs 2. Le développement de traitements de flux de données Conception générique, développement ETL (dans un premier temps sur les outils on premise puis évolution vers les fonctionnalités natives des cloud providers) Maintenance et évolutions applicatives Intégration et suivi de bout en bout via la chaîne CI/CD 3. D’assurer la qualité et le fonctionnement de la plateforme Data Suivi de la production, gestion et analyse des incidents Rédaction de mode opératoire, documentation de production Support N2 Ce poste est soumis à un régime d’astreinte de nuit et week-end ainsi qu’à des interventions ponctuelles et planifiées de nuit, week-end et jours fériés. Pourquoi nous rejoindre ? CAPS est une entreprise dynamique , portée par les innovations technologiques De nombreuses opportunités professionnelles vous attendent chez CAPS et au sein du Groupe CA Vous bénéficiez également d’un plan de formation et de développement adapté à vos besoins Au sein de nos différents Campus , de nombreux services vous facilitent le quotidien : conciergerie, espaces de travail collaboratifs, choix de restauration variés, équipements digitaux, parkings… Agir chaque jour dans l’intérêt de nos collaborateurs et de la société, cela signifie aussi être attentifs aux sujets de mixité, de handicap, d’engagement solidaire, autant d’axes forts de notre politique RSE et facteurs de performance et d’innovation. Quelques raisons supplémentaires… Un package de rémunération attractif (primes sur objectifs, intéressement et participation) De nombreux avantages sociaux (CSE, offre bancaire groupe, remboursement des transports à 90% etc.) 2 jours de télétravail par semaine en moyenne Un partenariat avec Vivrou.com pour aider nos (futurs) collaborateurs à trouver leur lieu de vie idéal. Formation : Bac +5 / M2 - Spécialisation Ingénieur, Business Intelligence, Data Expérience : 6 à 10 ans d’expérience dont 5 ans dans des fonctions similaires Compétences : Programmation avançée (algorithmique / conception de modèles de données) Méthodologie projet (Agile + Bout en bout / CI CD) Connaissances fonctionnelles des paiements (monétiques, fiduciaire, flux) serait un plus Capacité à réaliser des conceptions détaillées de traitements et à concevoir des traitements génériques Monitoring et suivi d’environnements multiples (dev, intégration, homologation, production) Autonomie et sens de l’initiative Outils informatiques : Excellente maîtrise d’un outil ETL (Datastage, Informatica, Talend) Excellente maîtrise des Systèmes de gestion de base de données (Vertica serait un plus) Très bonne maîtrise du langage SQL, environnement de travail citrix & unix, Jenkins, Ansible & Git Langues : Anglais courant Notre processus de recrutement comprend deux entretiens (managérial, RH associé à un questionnaire de personnalité), avec la possibilité d’un échange supplémentaire.","The Credit Agricole Payment Services is seeking an experienced Data Engineer with advanced programming skills, project methodology, and knowledge of payment functions. The candidate is responsible for the design of processing transactions and the development of innovative payment solutions. The successful candidate should have experience with ETL development, monitoring, and overseeing multiple environments. The role requires autonomy, initiative, excellent technical skills using tools like Unix, Jenkins, Git, and Datastage, and good written and verbal communication in English. The position will work within an environment that requires night and weekend shifts, but it also offers attractive remuneration, benefits, training, and opportunities for professional growth.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
346,57023,https://www.welcometothejungle.com/fr/companies/ergoss-logiciels/jobs/flight-data-analyst-engineer_blagnac,Flight Data Analyst Engineer,Ergoss Logiciels,{},Télétravail partiel possible,"3, Rue des Charrons, Blagnac, 31700","Logiciels, Aéronautique / Spatiale",CDI,2023-03-26,"Créée en 2009, l’entreprise a gardé son esprit de start-up qui lui a permis de devenir le leader mondial des solutions innovantes dans le domaine de l’analyse et du suivi des données de vol. Ergoss a une petite équipe au mode de fonctionnement unique pour maintenir créativité et flexibilité, et c’est ce qui a permis de percer et de devenir un challenger sérieux face aux grandes entreprises. En dix ans, l’entreprise a réussi à bousculer un marché jusque-là très établi en dépoussiérant des idées et des concepts en place depuis plusieurs décennies. Missions : Decode flight data recorders logical frames layout Develop encoded logics to detect deviations from standard and airlines procedures Respond to specific requests of airlines Flight Safety Officers Insure support of level 1 & 2 Produce training documentations & supports Conduct Training sessions for customers (at customers premises) and internal needs. Innovate on flight safety indicators & follow up methodologies Ressources / skills : Engineering degree in aeronautics Deep knowledge on aircraft operations and performances. Familiar with programming methodes and Ability to use different type of programming languages.","Ergoss, world leader in innovative solutions for flight data analysis, seeks an engineer with an aeronautics degree who can develop encoded logics, detect deviations from standard airline procedures, support Level 1 & 2, produce training materials, conduct training sessions for customers, and innovate on flight safety indicators. The ideal candidate has deep knowledge of aircraft operations, familiarity with programming methods, and the ability to use different programming languages.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
343,56454,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-data-science_paris,Software Engineer - Data Science,Datadog,"{Java,Go,Flink,color,Scala,anomaly,scale,Spark,Datadog,Python}",Télétravail partiel possible,"21 Rue de Châteaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. The Data Science team designs and builds algorithmically driven features in the Datadog app. We work across a range of applications, primarily focusing on analysis on streaming data such as anomaly detection , error outliers and faulty deployment analysis . As a Software Engineer on the Data Science team, you will design, build and scale the backend systems that power our growing suite of Watchdog products . You will be working on large-scale distributed systems, horizontally-scalable datastores and a variety of data-processing frameworks to build our next-generation platform and capabilities for Data Science at Datadog. At Datadog, we place value in our office culture - the relationships that it builds, the creativity it brings to the table, and the collaboration of being together. We operate as a hybrid workplace to ensure our employees can create a work-life harmony that best fits them. What You’ll Do: Build common services and components encapsulating data science capabilities for other products and teams to leverage Enable new capabilities for our core products by integrating and preprocessing data from tens of sources and preparing it for incorporation into data science models Ensure that our data science-driven features continue to scale well as Datadog adds more customers and ingests more data per customer Leverage modern tools and frameworks to improve the performance and cost-efficiency of data science services Join an amazing team of data scientists and software engineers building a product that our customers love to use Work all over the stack, moving fluidly between programming languages and technologies Who You Are: You have experience working in Python, Java, Scala or Go You have experience working with microservices and/or distributed systems You value simplicity and getting the right things done (Senior Level) You have built high-volume data pipelines (Senior Level) You have expertise in Python, Go or Scala and are familiar with Spark or Flink Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: Competitive global benefits New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Opportunity to collaborate closely with colleagues across the Datadog offices in New York City and Paris Opportunity to attend and present at conferences and meetups Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-ER1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice .","Datadog, a cloud application monitoring and security platform, is seeking a Software Engineer to join their Data Science team to design and scale the backend systems for their suite of Watchdog products. Candidates should have experience in Python, Java, Scala, or Go, as well as microservices and distributed systems. The company emphasizes a hybrid workplace and values people from diverse backgrounds. Benefits include global benefits, stock equity plans, and opportunities for professional development and networking.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
340,57071,https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-confirme-aws-h-f-lyon_lyon_EVOTE_6Lm3QY3,Data Engineer (H-F) - Lyon,evoteo,"{Glue,Hive,Azure,Docker,scala,Databricks,PowerBI,Python,ElasticSearch,Jenkins,AWS,Hadoop,SQL,Yarn,Flume,S3,Spark,Pig,GIT}",Télétravail partiel possible,"23, Rue Crépet, Lyon, 69007","Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-03-26,"evoteo est une entreprise de prestation spécialisée en #DATA. L’évolution des structures, établies depuis plusieurs années, voire plusieurs décennies, est en marche et evoteo accompagne ses partenaires pour y faire face. Les équipes d’evoteo sont composées d’ingénieurs, de chefs de projets et de transformations managers tous passionnés par ce changement technologique. La réussite de l’entreprise repose sur un management de carrière simple et efficace de ses collaborateurs dont les axes principaux sont : L’évolution La curiosité L’exigence La collaboration Dans le cadre de notre expansion ambitieuse mais contrôlée, et pour satisfaire aux besoins changeants de tous nos clients, nous recherchons une/un Data Engineer pour renforcer nos équipes. Mission Dans le cadre du projet de migration de notre client, de leur ancien système BI vers leur nouvel écosystème Lakehouse (Discover) sur Databricks / AWS, nous sommes à la recherche d’une personne qui peut gérer : La récupération (et surtout la refonte) de leur modèle de données pour qu’il soit la base de leurs futurs cas d’utilisation des données (refonte des procédures SQL Server de Side vers des travaux Databricks en Python / SQL / Spark). La migration des tableaux de bord PowerBI ainsi que la refonte de leur modèle pour les simplifier, en les source sur le Lakehouse au lieu de Side. La refonte des rapports SSRS vers des tableaux de bord Databricks pour les rapports opérationnels. La récupération des exports (principalement des fichiers CSV) gérés par Side aujourd’hui. La durée de ce projet devrait s’étaler sur 2023-2024. Nous recherchons avant tout des personnalités : curieuses, habiles, sociales, adaptables et passionnées. De formation BAC+5 (Master 2,DESS,DEA), formation ingénieure ou informatique, tu as une expérience d’au moins 2 ans en engineering des environnements Big #DATA Les technos: Développement : Spark (scala), Python Intégration continue : GIT, Maven, Jenkins, Ansible, Docker Technologies Big #DATA (Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch) Cloud AWS : S3, Glue, ECS Cloud Azure Nous insistons sur les compétences Spark. Ce poste en CDI est à pourvoir dès que possible sur la région lyonnaise. Tu êtes un futur collaborateur acteur, en quête de perspectives d’évolution, capable de rigueur et d’esprit d’analyse ? Rejoins-nous ! Comme évoqué, nous aimons les choses simples - envois-nous ta page Linkedin ou bien un CV, ensuite nous te proposerons: Un échange téléphonique permettant de cibler au mieux tes souhaits Un entretien de découverte mutuelle afin de savoir si nous avons envie de travailler ensemble Tu reviens vers nous si tu es intéressé pour un dernier échange avec le PDG afin de partager la vison, parler de te carrière et valider ta candidature.","evoteo is seeking a Data Engineer for their expansion. The candidate should have at least 2 years of experience in engineering Big Data environments and possess skills in Spark, Python, GIT, Maven, Jenkins, Ansible, Docker, Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch, Cloud AWS and Cloud Azure. The job entails working on the migration of clients' BI system to their new Lakehouse ecosystem, requiring data recovery and rebuilding, migration of dashboards, reports, and exports over a period of 2023-2024. The company is looking for curious, adaptable, and passionate candidates who can handle the changing needs of clients. Candidates interested in this full-time position can send their LinkedIn page or CV for the first stage of selection.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
336,60320,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-scientists-ml-engineers-h-f_paris-02_TDF_KjX50w0,Data Scientists- ML Engineers,TotalEnergies Digital Factory,"{Databricks,DataBricks,AWS,Azure,Python}",Télétravail total possible,"Rue des jeuneurs, Paris 02, 75002","Logiciels, Big Data, Energie",CDI,2023-03-28,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. La Digital Factory de TotalEnergies est composée de 300 personnes, 30 Squads, 39% de femmes et 25 nationalités. Elle offre un environnement de travail international et interculturel en plein cœur de Paris, engagé dans la diversité et l'inclusion. Elle permet d' accélérer la production interne de solutions digitales pour les activités de la Compagnie dans les 130 pays où elle est présente. Elle allie l' agilité et l' esprit pionnier d'une entreprise technologique à la robustesse et à la rigueur d'une entité de production à grande échelle. Elle crée et déploie des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une énergie propre, fiable et abordable au plus grand nombre. En accord avec les politiques HSE de la Compagnie et de la TotalEnergies Digital Factory, le/la Data Scientist / Machine Learning Engineer a pour rôle de soutenir la Squad en créant des modèles utilisant des diagnostics analytiques avancés. Rôle : analyser des quantités massives de données structurées ou non structurées afin d'aider à la compréhension et à la prise de décisions. Sélectionner des techniques d'analyse et des outils de modélisation, construire des modèles, les déployer et évaluer les résultats et les performances. Missions : Appliquer les statistiques, le machine learning et les approches analytiques pour résoudre les problèmes business Construire des algorithmes de machine learning industrialisables Conduire des projets de Machine Learning de la conception au déploiement (idéation, conception des pipelines MLOps, gestion du cycle de vie des modèles en production...) Transformer les volumes de big data en informations utiles et exploitables Gérer le cadrage et la livraison des cas d'utilisation Contribuer à la formation et à l'animation de la communauté globale de la Data Science chez TotalEnergies. Vous êtes diplômé(e) en Master ou école d'ingénieur spécialisée en statistiques, datamining ou mathématiques Vous avez au moins 5 ans d'expérience dans la mise en production d'algorithmes de Machine Learning Vous maîtrisez Python, DataBricks, AMLS... Vous connaissez les meilleures pratiques du développement et du codage Vous êtes capable de tester des hypothèses à partir d'ensemble de données brutes et d'analyser les résultats Une expérience dans un contexte industriel serait appréciée (logistique, gestion de stocks, maintenance industrielle, analyse de données de capteurs, analyse et modélisation de procédés). Votre niveau d'anglais est courant. Ce que nous t'offrons : Le développement de tes compétences avec le support de la Digital Academy et une enveloppe équivalente à 10 jours de formations par an que tu peux choisir en toute autonomie. La possibilité de te certifier AWS et Azure, Databricks... Un programme de mentorat. Un équilibre vie professionnelle et vie personnelle avec le recours possible aux horaires flexibles et au télétravail.","The TotalEnergies Digital Factory in Paris is seeking a Data Scientist/Machine Learning Engineer to analyze vast amounts of structured and unstructured data to aid in decision-making. The role involves selecting analysis techniques and modeling tools, building and evaluating models, and deploying them to create useful information from big data. The successful candidate will have a master's degree in statistics, datamining or mathematics, at least five years of experience in ML algorithm deployment, and proficiency in Python, DataBricks, and AMLS, among others. An industry background would be advantageous, and fluency in English is essential. The company offers flexible working hours and telecommuting options, as well as training opportunities and mentorship programs.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,3,0,0.04154662416233763
335,60264,https://www.welcometothejungle.com/fr/companies/infinity-advertising/jobs/data-engineer_paris,Data engineer,Infinity Advertising,"{GCP,SQL,Python}",Télétravail partiel possible,"5 Rue des Italiens, Paris, 75009","Digital Marketing / Data Marketing, Big Data, Digital",CDI,2023-03-28,"// LA SOCIETE Le groupe Casino et Intermarché ont créé « Infinity Advertising », société commune chargée de commercialiser en France une offre Retail Media auprès des marques et de leurs agences, en dehors de toute négociation à l’achat, et dans le respect des règles relatives à la protection des données personnelles et du droit de la concurrence. Le Retail Media est LE canal publicitaire actuellement en vogue. A la pointe de l’innovation, les analystes tels que Forrester prévoient qu’aux Etats-Unis les investissements dans ce média vont, dès 2025, dépasser ceux réalisés dans la publicité télévisée. Infinity Advertising a ainsi pour mission de commercialiser tout un éventail de solutions publicitaires digitales sur les sites Intermarché, Casino, Monoprix et Franprix mais aussi sur des sites externes en ciblant finement les personnes exposées grâce aux bases de données constituées par les habitudes d’achats des 17 millions de porteurs de cartes fidélités de ces enseignes. Créé en 2021, Infinity Advertising connaît une forte croissance et appréhende l’avenir sous les meilleurs auspices grâce à sa capitalisation sur une offre très complète. L’entreprise est aujourd’hui forte d’une cinquantaine de collaborateurs. // POSTE & MISSIONS La data est au cœur de notre métier car elle structure totalement notre offre produit. Le Data Engineer a vocation à assurer la responsabilité de la structuration et de la mise à disposition de cette donnée aux utilisateurs. Rattaché(e) à notre CTO, tu auras l’opportunité de collaborer avec l’ensemble des équipes opérationnelles et techniques de l’entreprise. Tu travailleras en mode projet agile pour apporter des réponses aux challenges techniques dans un contexte cloud et Big Data. Tes missions : ● Développer et maintenir un système de traitement de données à grande échelle. ○ Aider à concevoir, construire et maintenir notre architecture de données. ○ S’assurer que les pipelines construits prendront en charge les flux de données à volume élevé. ○ Les développer pour extraire, transformer et charger des données à partir de sources variées. ● Optimiser les performances et la qualité des données. ○ Détecter les opportunités d’acquisition, de stockage et d’interrogation de données de manière performante. ○ Optimiser la performance de nos bases de données et des pipelines de données existants. ○ Effectuer des tests de qualité pour garantir l’intégrité et la précision des données. ● Collaboration ○ Avec les data analysts pour identifier les besoins en matière de données. ○ Avec le devops pour structurer et maintenir l’architecture de données. ○ Avec les utilisateurs pour effectuer des tests de qualité pour garantir l’intégrité et la précision des données. // PROFIL ● Expérience similaire. ● Tu maîtrises SQL et Python. ● Expérience notable dans un contexte GCP : BQ, DataProc, CF, etc… Une certification sera un plus. ● Tu aimes le travail cross team et tu as envie de comprendre les enjeux business majeurs. ● Dynamique et débrouillard(e), tu es polyvalent(e) et tu sais faire preuve d’initiative. // LES AVANTAGES : ● Développer tes compétences et tes connaissances dans le secteur des produits de grande consommation et du Retail Media ● Rejoindre une équipe motivée, dans un esprit start-up, dans une structure en cours de création, et pour autant solide et reconnue sur le marché, grâce à l’appui de deux grands acteurs de la grande distribution ● Travailler dans un cadre sympathique : locaux dans le centre de Paris, avec accès rooftop, babyfoot, billard, salle de karaoké, tickets restaurants… // INFORMATIONS COMPLÉMENTAIRES ● Type de contrat : CDI ● Localisation : Paris 9e – Opéra ● Disponibilité : date de démarrage à discuter avec le (la) candidat(e) retenu(e) ● Rémunération : A définir selon expérience ● Contact : recrutement@infinity-advertising.fr","Infinity Advertising, a joint venture by Casino and Intermarché, seeks a Data Engineer to develop and maintain a large-scale data processing system. The ideal candidate should have experience with SQL and Python, and notable experience in a GCP context. The position offers the opportunity to work in an agile project mode for cloud and big data challenges. The role involves collaborating with data analysts and devops to structure and maintain the architecture and optimize data performance. Infinity Advertising offers a competitive salary and benefits package and a pleasant work environment in the heart of Paris.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
331,34394,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-paris-or-remote-france_paris_DATAI_YzOxG4e,Software Engineer Data Visualization - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",Télétravail partiel possible,Paris,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend). - Prototype and create new ways to import and request data at large scale. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with experience in software development and an interest in data visualization tools to create usable, intuitive, and beautiful interfaces for its platform. The ideal candidate should have knowledge of both front-end and back-end development, an understanding of customer needs, and a passion for high-quality code. Dataiku offers a flexible work-life balance, autonomy for its employees, and a caring culture that prioritizes diversity and inclusivity.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
329,49868,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-paris-or-remote-france_paris_DATAI_PjOXK2w,Software Engineer Data Visualization - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",Télétravail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend). - Prototype and create new ways to import and request data at large scale. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a skilled software engineer to create usable, intuitive, and beautiful interfaces and scalable engines for their platform. The ideal candidate should have experience in software development and data visualization tools, be customer-oriented, have experience building real products, and be comfortable with both frontend and backend development. The company's culture is flexible, autonomous, and caring, with an emphasis on diversity and equal opportunity employment practices.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
328,56982,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_paris,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",Télétravail partiel possible,"51 Rue de Londres, Paris, 75008","FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they’re given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We’ve raised over €260M from leading investors, and been named a French tech unicorn. And we’re not stopping there! About our people & culture We believe that people do their best work when they’re given the freedom to thrive and grow. That’s why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth — with benefits to match! - Lunch 60% funded by Spendesk (Swile Card) - 11 RTT in 2022 on a pro-rata basis, in addition to your 25 paid holiday days - Alan Premium health insurance - A Gymlib pass to let off steam after a productive day at work - Access to Moka.care for emotional and mental health wellbeing - Access to Vendredi allowing us to change the world - Latest Apple equipment (MacBook Air) - Great office snacks to fuel your day - A positive team to work with daily! Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk, a fast-growing fintech company in Europe, is looking for an Analytics Engineer to join its data team. The successful candidate will design, develop and maintain the company's analytics infrastructure, including data pipelines and data warehousing, and ensure data accuracy and integrity. Key skills for the role include experience in analytics engineering or business intelligence, strong proficiency in SQL, and experience with data modeling, ETL processes, and BI tools such as Looker, Tableau or Power BI. Spendesk values freedom, ownership, and positive attitude in its employees and offers various benefits, including health insurance and gym memberships.",Non spécifié,Entre 250 et 2000 salariés,> 1 an,2,1,0.04154662416233763
327,56464,https://www.welcometothejungle.com/fr/companies/canal-group/jobs/cdi-data-engineer-f-h_puteaux,CDI - Data Engineer -,CANAL+ Group,"{Kinesis,DynamoDb,EMR,Scala,Gitlab,Airflow,Lambda,AWS,Snowflake,Spark,Java,Python}",Télétravail partiel possible,"6 Rue Godefroy, Puteaux, 92800","Application mobile, Média, Télévision / Production audiovisuelle, Publicité, Digital",CDI,2023-03-26,"Bienvenue chez CANAL+ Group ! Séries, films, documentaires, émissions, sports, …Ce qui nous tient à ❤ c’est de créer les meilleurs contenus et une expérience immersive : émotions et sensations garanties ! Et si vous passiez derrière l’écran ? Vous trouverez forcément votre place parmi nos 7 500 passionné·es dans le monde 🌍. Pour être au courant de nos dernières actualités, n’hésitez pas à nous suivre sur LinkedIn et Twitter ! 💻 Les équipes TECH CANAL+ ? + de 500 expert·es qui dénichent les dernières technos pour rendre l’expérience de nos abonné·es unique. Un seul mot d’ordre : toujours plus d’agilité et d’innovation ! Ok ça fait 2 mots… 😉 🔎 Rejoignez notre Direction Data , composée de 50 expertes et experts, ayant une place importante et centrale au sein du groupe. Le but étant d’accompagner l’ensemble des métiers business (marketing, études, régie publicitaire…) dans leur quotidien. Vous intégrerez l’équipe Delivery qui est en charge de toute la collecte, l'enrichissement et la mise à disposition des différents types de données. 🌟 Notre stack technique : AWS (Lambda, Kinesis, EMR Serverless, DynamoDb et plein d’autres services AWS), Apache Airflow, Scala, Python, Snowflake, Gitlab et Gitlab CI. 🌟 Nos supers projets en cours ou à venir : Data quality : notre équipe collecte 1,3 milliard de données par jour et 400 gigas par heure en moyenne. Dans ce contexte nous devons veiller à ce que les données soient de qualité, mais aussi disponibles en temps et en heure. La collecte de ces données va nous permettre, entre autres, de recommander du contenu à nos abonné·es ainsi que la transmission de messages ciblés visant au renforcement de leur engagement. 🌟 Fun facts : Ces données vont nous permettre de convertir les prospects en abonné·es et de les fidéliser en personnalisant au maximum leurs expériences, mais aussi d’analyser l’impact de certains événements marquants (la signature d’un nouveau partenaire, la prolongation des droits de diffusion de la F1 ou encore la prolongation de Kylian MBAPPE au PSG) sur le comportement de nos abonné·es ! 🎯 Votre rôle et vos missions : Concevoir, implémenter et participer à l'industrialisation des applications data Comprendre les problématiques en jeu de chaque sujet Travailler en collaboration avec des profils DevOps, Tech Lead et PO Participer aux différentes guildes mises en place dans des processus d’amélioration continue autour de la Data Gouvernance, des normes et standards de développements Description du profil : 🏆 Et si on parlait de vous ? Vous justifiez d’une expérience de minimum 3 ans en tant que développeur/développeuse ou ingénieur·e data. Vous maîtrisez Scala (ou Java), Spark ou avez justifiez d’une expérience de développement dans un environnement distribué et vous avez une expérience sur AWS ou au moins un Cloud provider. Une expérience sur Airflow ou en “Infrastructure as Code” avec Teraform serait appréciée. Vous faites preuve d’autonomie, appréciez le travail en équipe et êtes force de proposition. Vous avez déjà travaillé dans un environnement agile Vous êtes sensible aux concepts de clean code, clean architecture et aux best practices pour la réalisation de projets DATA fiables et robustes. Vous avez un bon niveau d’anglais (lu, écrit, parlé) Vous souhaitez rejoindre un grand acteur de l’univers des médias ! 🎁 Les + Un abonnement collaborateur CANAL+ pour être incollable sur nos univers ! Des avant-premières de films et séries dans notre salle de cinéma Des visites de nos plateaux et des participations à nos émissions Participer aux événements de notre communauté CANAL+ TECH : meetups suivi d’afterworks, tech week, … Participation & Intéressement CSE attractif : chèques vacances et noël, prime mariage / pacs / naissance, réduction billetterie sport / voyages / loisirs, prise en charge d’une partie de votre abonnement sportif, … Disposer d’1 jour d’engagement solidaire par an au profit d’une sélection d’associations Devenir intrapreneur ou intrapreneuse avec l’Hack’celerator, notre programme d’incubation interne Et parce que nous voulons vous aider à vous épanouir et vous perfectionner : des formations régulières, des participations à des conférences en interne ou en externe … ! 🏡 Et le télétravail dans tout ça ? Vous pourrez en bénéficier jusqu’à 3 jours par semaine ! Et le process ? Un 1er contact téléphonique avec un tech recruiter + 1 entretien avec le manager, le tech lead et un tech recruiter + 1 test technique + 1 entretien avec notre Directeur Data + 1 rencontre informelle avec l’équipe, environ 3 semaines en tout, en visio ou en physique comme vous le souhaitez ! 👉 Seulement chez CANAL+ à Puteaux (92).","CANAL+ Group is seeking a Data Engineer with a minimum of 3 years of experience in development or data engineering. The role will involve designing, implementing, and industrializing data applications, working collaboratively with DevOps, Tech Lead, and PO profiles, and participating in various guilds related to data governance and development standards. Proficiency in Scala/Java, Spark, and AWS/Cloud provider is required, while experience with Airflow and Terraform is appreciated. The company offers attractive benefits, including an employee subscription to CANAL+, previews of films and series, and participation in the company's events and training programs. The position is based in Puteaux, France, with the possibility of remote work up to 3 days per week.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
325,56528,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-f-h-cio-cib_paris,Data Engineer Risks  CIO CIB,Natixis,"{scala,java,Jenkins,spark,Scala,via,Spark,Java,Hadoop}",Télétravail partiel possible,"rue de montmartre, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de votre âge, origine, orientation sexuelle, handicap... Au sein du pôle CIO CIB (Corporate & Investment Banking), dans le département Risks, vous rejoignez l'équipe DPM/Metrics Services, en tant que data engineer. Vous reportez directement au responsable de l'équipe Metrics Services, des évolutions du composant de l'application « golden data » et des PV de Stress Tests. Ce composant est la clef de voûte d'une chaine applicative FO to Risk pilotée par le programme SUNRISE. Au quotidien, vous avez pour missions de : Assurer l'évolution de l'application développée en spark/scala/java sur plateforme Hadoop dans un contexte projet ; Piloter des sujets multi-systèmes (référentiel market data, référentiel instrument, pricers front) ; Gérer l'industrialisation et la mise en qualité des données ; Faire la coordination avec : les business analyst de l'équipe, les autres équipes de développeurs du programme et les autres équipes IT (production applicative, infrastructure, support Hadoop) ; Assurer le support de niveau 2. La stack technique utilisée est la suivante : Java, Spark/Scala et Hadoop dans un environnement DevOps. Nous travaillons en méthode Agile (SAFe) et vous serez intégré à notre communauté de data engineers. #MuchMoreThanJustAJob Ce poste est basé à Paris avec la possibilité de télétravailler. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de leur âge, origine, orientation sexuelle, handicap... A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure, vous avez au moins 10 ans d'expérience en tant que data engineer dans le domaine fonctionnel de la finance de marché (type DSI). Vous maitrisez : * les problématiques d'optimisation de performance et vous proposez des solutions innovantes ; * la mise en place des protocoles de sécurité dans des environnements de développement ; * les langages Java et Hadoop ; * les bases du DevOps (intégration continue/automatisation, Jenkins, Sonar, XLDeploy, XLRelease …) ; * la méthode Agile (SAFe). Vous êtes : * passionné d'IT et data centric, vous souhaitez développer une véritable expertise technique sur des projets innovants. Vous maitrisez l'anglais avec un niveau B2 minimum. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis Corporate & Investment Banking is seeking a data engineer to join their team in Paris. The successful candidate will have at least 10 years of experience as a data engineer in the functional domain of market finance and will be responsible for evolving the spark/scala/java application on Hadoop platform, ensuring data quality and coordination with business analysts and other IT teams. Skills required include Java, Hadoop, DevOps, and Agile methodology. The position offers opportunities for career development, training, and social engagement. Natixis is an equal opportunity employer committed to building an inclusive workplace.",Bac +5 / Master,> 2000 salariés,> 7 ans,2,1,0.04154662416233763
322,56488,https://www.welcometothejungle.com/fr/companies/la-javaness/jobs/data-engineer_paris_LJ_ArOw53o,Data Engineer,La Javaness,"{Synapse,Hive,Docker,Azure,Dataiku,Athena,Databricks,Talend,Gitlab,Looker,Fivetran,PowerBI,Git,Bash,Kubernetes,AWS,Teradata,Hadoop,SQL,Pandas,Prefect,Airflow,Redshift,HDFS,dbt,R,Spark,Pig,BigQuery,GCP,Python,Tableau}",Télétravail partiel possible,"18, Rue d'Hauteville, Paris, 75010","Logiciels, Intelligence artificielle / Machine Learning",CDI,2023-03-26,"Tu te sens prêt à plonger au cœur de la révolution IA ?! En 6 ans, La Javaness s’est imposée comme leader français de l’IA pour les entreprises (BtoB). Sans tambour ni trompettes (mais avec beaucoup de R&D !), nous avons concentré nos forces à déployer l’Intelligence Artificielle à grande échelle au sein d’organisations publiques et privées en France et en Europe. Mais pas n’importe comment ! Nous croyons en une IA éthique, responsable, au service des salariés et des citoyens européens. Nous militons pour la souveraineté des données et l’indépendance des entreprises européennes. Pragmatiques et rationnels, nous déployons quotidiennement nos solutions « prêt-IA-porter » à un niveau industriel. Nous faisons aussi de la haute couture en développant des solutions IA sur-mesure pour répondre aux défis de certains de nos clients. Notre R&D bout sans relâche pour inventer, tester et déployer l’IA de demain. En d’autres termes, dans la boutique de La Javaness, tu trouveras : Conseil data & IA, accélération par le design, développement front & back de pointe, défis business dans un joyeux mix exigeant d’intelligences. Avec ce super cocktail d’expertises et de créativité, nous intervenons sur tous les secteurs d’activité pour cracker les problèmes de nos clients ! Comment ça marche au quotidien ? 4 labs : Architecture & Ops, IT, Data, Business, travaillent ensemble sur tous les projets afin de concevoir et déployer des solutions complètes et innovantes répondant aux besoins de nos clients. Fort d’un collectif unique, la Javaness investit sans cesse dans des talents pointus, atypiques et complémentaires qui lui confèrent une force de frappe hors norme. Si ça te semble une aventure à ta mesure, c’est par ici pour nous rejoindre ! En tant que data engineer au sein de La Javaness, tu seras amené.e à effectuer les missions suivantes : Participation aux travaux d’architecture, réalisation des benchmarks et accompagnement des choix d’outillage et d’infrastructure Définition et mise en place des pipelines données, pour les besoins d’analytiques et IA Assistance à la définition et à la mise en place de dispositifs de gestion de la donnée (Data Management) ; Participation et contribution à la vie d’équipe : R&D, Partage de connaissance, Recrutement, Code review, etc. Doté.e de 5 ans d’expérience dans un rôle de data engineer, tu disposes des compétences suivantes : Les bases : Python et son écosystème, Pandas, Spark, SQL, Git, Bash, Docker. Tu as déjà travaillé dans un contexte de volumétrie importante de données. Tu fais preuve de synthèse et de rigueur. Tu possèdes de bonnes capacités de communication, orales et écrites. Tu es curieux, avec une forte envie d’apprendre Tu possèdes également plusieurs des compétences techniques suivantes : Outils d’ETL/ELT (Talend, dbt, Fivetran, etc.) Écosystème Hadoop (HDFS, Hive, Pig, Sqoop, etc.) Outils d’orchestration et d’ordonnancement (Airflow, Prefect, Oozie, etc.) Outils de reporting (PowerBI, Tableau, Google Looker, Azure Synapse, etc.) Expérience avec les plateformes cloud (AWS, Azure, GCP, IBMCloud, etc.) et leurs outils (Redshift, Athena, BigQuery, etc.) Plateformes pour le stockage et le traitement de la donnée (Teradata, Dataiku, Databricks, Snowflakes, etc.) Notions de DevOps (CI/CD, Gitlab CI, Docker, Kubernetes, etc.)","La Javaness, a French leader in AI for businesses, is looking for a data engineer to help with architecture work, define and implement data pipelines, and contribute to the team's R&D, code review, and recruitment. The ideal candidate should have a minimum of 5 years of experience with Python, Pandas, Spark, SQL, Git, Bash, and Docker, and have worked with large volumes of data. They should also possess knowledge of ETL/ELT tools, Hadoop, orchestration and scheduling tools, reporting tools, cloud platforms, data storage and processing platforms, and DevOps concepts.",N,N,N,2,1,0.04154662416233763
318,56435,https://www.welcometothejungle.com/fr/companies/citron/jobs/data-engineer-senior_suresnes,Data Engineer Confirmé.e,Citron®,"{Airflow,Glue,AWS,scale,via,Python,Clickhouse}",Télétravail partiel possible,"28, Quai Gallieni, Suresnes, 92150","Logiciels, Big Data, SocialTech / GreenTech",CDI,2023-03-26,"Citron® est une Proptech qui digitalise le management énergétique et technique des entreprises , à l’aide de 3 leviers : La plateforme Citron® Energie , qui centralise, suit et analyse les consommations énergétiques des grands parcs immobiliers. Développée en interne, elle optimise le management énergétique des bâtiments , grâce à des tableaux de bord ergonomiques et des préconisations d’actions. La plateforme Citron® Technique , qui suit et analyse la performance de l’ensemble des systèmes présents dans les bâtiments (ascenseurs, chaufferies, CTA, etc.). Développée en interne, elle réunit tous les acteurs techniques (gestionnaires, prestataires, occupants, propriétaires, etc.) pour une optimisation de la performance et de la transparence . Des Ingénieurs Conseil experts en efficacité énergétique qui accompagnent les clients dans la détection des gaspillages et définissent des plans d’actions, en s’appuyant sur des innovations internes. Citron® compte plus de 70 collaborateurs et accompagne maintenant plus de 500 clients . Les données sont un catalyseur clé pour une entreprise comme Citron® qui récolte plus de 2 millions de données par jour ! En tant que Data Engineer ton rôle sera d’intégrer la team Data Engineering composée de 3 Data Engineers (qui passera à 6 personnes d’ici 2023) et d’un Data Engineering Manager dans un contexte agile et en collaboration avec l’équipe Tech et Produit. Le périmètre des données énergétiques comprend toutes les données (de la collecte à la diffusion des données aux parties prenantes internes et externes) liées au à la plateforme Technique. Citron® récupère toutes les données liées aux consommations et à la vie des bâtiments, notamment les données de facturation issues des fournisseurs d’énergie (électricité, gaz, eau…). Nous collectons aussi des données depuis les objets connectées présents dans les bâtiments (sous-compteurs, sondes de températures, automates, GTB, etc.) et données tierces (données météorologique, linky, Gazpar …) Tu es un.e Data Engineer et recherches une scale-up à impact environnemental ? N’hésite plus, postule ! On a hâte d’avoir ta candidature ! 👇 TES MISSIONS.. 💪 Construire les architectures de données Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, process temps-réels, process batch) Récolter, qualifier, surveiller, transformer et exposer les données produit et métier Implémenter des jobs autour de la data: ingestion/modélisation/transformation/contrôle qualité et détection d’anomalies/exposition (APIs, Data Catalog…) Assurer la migration des données vers les nouveaux environnements Participer à l’évolution de la stack technique (Clickhouse / AWS Glue / Airflow ) et au choix des outils Participer à la gouvernance de la donnée (process, normalisation, MDM) Maintenir et faire évoluer la CI/CD Data Analyser les données Analyser les données sources afin d’identifier et évaluer des cas d’usage métier Mettre en oeuvre des outils de Business Intelligence et visualisation via Cumul.io TU ES LE MATCH PARFAIT SI… 🎯 Tu es diplômé.e d’une école d’ingénieurs Tu possèdes au moins 2 ans d’expérience en tant que Data Engineer Tu maîtrises Python Tu as déjà travaillé sur un environnement AWS Tu as déjà eu une expérience sur Clickhouse Call RH (30mn) Test technique (2h) Double entretien sur site : - Whiteboard avec un Lead Dev et un développeur (1h) - Présentation des plateformes avec notre CTO Adrien (30mn) Culture fit (en visio) avec 2 culture ambassadors (1h)","Citron, a Proptech company, is seeking a Data Engineer to join its Data Engineering team to work on data-related tasks for the Citron platform, including data collection, processing, and analysis. The successful candidate must have at least two years of experience in a similar role, be proficient in Python, have worked with AWS, and have experience with Clickhouse.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
356,37402,https://www.welcometothejungle.com/fr/companies/mantu/jobs/data-engineer_lyon,Data engineer,Mantu,"{Kubernetes,Docker,Spark,Azure,SQL,Python}",Télétravail partiel possible,N,"Logiciels, IT / Digital, Organisation / Management",CDI,2022-10-18,"Mantu est un groupe international de conseil et de services aux entreprises et aux entrepreneurs. Il compte plus de 8500 femmes et hommes, de plus de 100 nationalités différentes, et est présent sur 5 continents et dans plus de 60 pays. Mantu se tient aux côtés des entreprises et des entrepreneurs pour accomplir leurs rêves, réaliser leurs ambitions et concrétiser leurs projets. Le groupe soutient leur croissance, permet leur développement et conduit leur transformation. Leur conviction, c’est que l’entreprise est avant tout une aventure humaine qui fait avancer le monde. C’est la raison pour laquelle l’entrepreneuriat est son principal levier de transformation. Leur raison d’être, c’est de créer des opportunités à une large communauté de talents, de leur transmettre l’esprit d’audace et leur culture de l’entrepreneuriat. Ils veulent contribuer à changer la vie des gens en leur permettant d’avoir un impact, de faire la différence, et tous ensemble de faire avancer le monde. Quels que soient leur spécialité ou leur secteur d’activité, toutes les entreprises de Mantu partagent une seule et même mission : révéler et faire grandir une communauté de talents pour réaliser les ambitions des entreprises et des entrepreneurs. Pour accompagner nos partenaires Français et internationaux, nous recherchons des Data Ingénieurs afin d’évoluer sur des projets à forte valeur ajoutée technologique en IT & Digital. Passionné par les nouvelles technologies et les environnements innovants, vous souhaitez faire partie d’une organisation ayant un vrai impact dans la révolution numérique ? N’attendez plus, rejoignez la communauté Amaris Consulting. Au sein d’une BU, une équipe DATA est dédiée pour créer de la valeur et optimiser nos processus au travers d’outils BI. Le Data Engineer intégrera une équipe composée d’un product manager, de 3 data ingénieurs et de 3 BI ingénieurs. Dans ce cadre vous allez participer aux activités suivantes : Missions : Concevoir et maintenir des programmes Spark en Python/SQL Challenger des jobs existants et trouver des axes d’optimisations Participer au support du parc applicatif Participer au design des solutions et être force de proposition sur l’architecture cible de notre périmètre. Rédiger des documentations Participer à l’alimentation du datalake Profil: Titulaire d’un diplôme d’ingénieur ou universitaire équivalent (BAC+5), vous justifiez d’au moins 2 ans d’expérience en tant qu’ingénieurs cloud. Vous connaissez au moins l’une des technologies suivantes: Azure Cloud, Kubernetes, Terraform, Docker, Ansible, PowerShell, Python. Vous êtes mobile à Nantes. Aimant relever des challenges au quotidien, vous savez travailler en autonomie et être force de proposition auprès de vos interlocuteurs afin d’apporter une valeur ajoutée à vos projets. Grâce à un management de proximité et une politique RH personnalisée, vous serez accompagné dans la construction de votre parcours au sein de l’entreprise. Vos qualités relationnelles seront des atouts importants pour réussir dans la fonction et évoluer au sein de notre groupe. Vous souhaitez intégrer une équipe dynamique et innovante ? Alors rejoignez-nous!","Mantu, a global consulting and service group, is seeking Data Engineers with experience in Python/SQL Spark programming, Azure, Kubernetes, Terraform, Docker, Ansible, or PowerShell to work in Nantes, France. The role involves optimizing data processes, designing solutions, and contributing to a collaborative team of product managers, data engineers, and BI engineers. With a focus on innovation, autonomy, and proposal skills, as well as a proactive and adaptable mindset, candidates who excel in this role will receive sufficient coaching in their career development from Mantu.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
357,39738,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-lyon-h-f_paris,Data Engineer - Lyon -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilité, SaaS / Cloud Services",CDI,2022-11-29,"Avec plus de 15 milliards de requêtes par an, Kisio Digital business unit de Kisio et filiale numérique du Groupe Keolis est un acteur majeur de la mobilité. Les trois grands domaines d’intervention de Kisio Digital portent sur les systèmes d’information-voyageur (recherche d’itinéraire multimodal, porte-à-porte et temps-réel) ; l’achat de titres de transport dématérialisés et le mobile-ticketing. Sa vision de la mobilité : permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’emprise possible sur la planète. C’est ce qu’on appelle la « responsive locomotion » ! Kisio Digital travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire en tenant compte du contexte et des préférences du voyageur. Pour répondre aux enjeux d’une mobilité plus intelligente, plus ouverte et plus écologique, Kisio Digital réalise des applications mobiles, des sites web et des SDK basés sur notre API www.navitia.io. Cette plateforme propose des services numériques de mobilité dans le monde entier. Elle rassemble une communauté de 20 000 développeurs et participe à leur stratégie d’innovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, vélomanes, bussophiles, et autres passionnés de montgolfière ou de transports pas toujours très communs. Curieux et ouverts d’esprit, ils sont passionnés par la mobilité au sens large, les nouvelles technologies et les communs numériques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communauté Open transport. Si vous souhaitez vous épanouir dans un environnement multiculturel, sachez que Kisio Digital va désormais lancer des services à l’étranger. Rejoignez-les ! En tant que Data engineer Hove, vous êtes intégré à une équipe pluridisciplinaire mêlant développeurs, Product Owner, Architectes dont l’objectif est de créer des services à fortes valeur ajouté dans le domaine du transport. Vous avez la charge de définir et mettre en œuvre le pipeline d’acquisition des données (datahub) global pour Hove, d’organiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Créer et faire évoluer le moteur d’ingestion des données (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilité des flux de données Travailler en collaboration avec les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégrations continues, scalabilité des modèles, craftsmanship, etc…) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Déployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des données Superviser et monitorer le déploiement et la robustesse des composants mis en production Participer activement à la qualité de l’ingénierie logicielle (Relecture de code, test, intégration continue, déploiement, etc.) Participer aux évènements internes à la communauté data interne et externes (AWS Summit, workshops, meetups…) Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.* Vous justifiez d’une expérience d’au moins 2 ans en tant que Data engineer Vous opérez dans le conseil et pouvez justifier de vos missions Vous maitrisez l’anglais professionnel Vous maitrisez au moins : Un framework de calcul distribué tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala…). Différents systèmes de base de données (SQL et NoSQL) et le langage SQL. Un framework de streaming de données tel que Kafka, Kinesis, … Une expérience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks… Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez être capable de livrer du code de qualité dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l’équipe tech Un entretien avec notre CTO","Kisio Digital, a digital subsidiary of Group Keolis, seeks a data engineer to join its team in Hove, UK. The company aims to create software of high value in the transportation field. As data engineer, the role will involve creating the pipeline for acquiring data, organising storage, and enabling the use of data by data scientists and analysts, among other tasks. Applicants should have at least two years of experience, proficiency in programming languages such as Python, Java, and Scala, SQL and NoSQL databases, and experience in AWS cloud technologies.",N,N,N,2,1,0.04154662416233763
358,56804,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/ia-project-engineer-data-value-lab-f-m-d_paris,IA Project Engineer - Data Value Lab,Decathlon Digital,"{GCP,SQL,Python,AWS}",Télétravail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES DU DATA VALUE LAB DE l'IA FACTORY DE DECATHLON Le Data Value Lab , au sein de l'unité Decathlon AI factory, est l'équipe chargée de découvrir & définir les cas d'utilisation d'IA qui apportent le plus de valeur ajoutée. Mais aussi d'assurer l'expérimentation de ces cas d'usages. Le terme X4, qui signifie eXplore, eXamine, eXperiment et eXtend, résume parfaitement le modus operandi de l'équipe. Au sein du Data Value Lab, nous utilisons une approche agile ""test & learn"" pour analyser le potentiel de valeur, la faisabilité d'un cas d'usage et mesurer la performance de la solution avant d'en étendre les succès (industrialisation). Nous sommes étroitement liés aux parties prenantes métiers de l'entreprise et aux équipes d'IA (personnalisation, tarification, prévision, optimisation des offres) chargées de déployer à grande échelle les résultats de nos expérimentations . L'équipe joue un rôle central dans l'établissement de nouvelles orientations en matière d'IA au sein de Decathlon, en expérimentant les dernières technologies d'apprentissage automatique pour résoudre des problèmes commerciaux à fort impact et en diffusant la culture de l'IA dans toute l'organisation.Vous serez en charge de projets qui ont le potentiel de définir l'avenir du sport. Rejoindre nos équipes c'est vraiment une chance de façonner l'industrie du sport grâce aux données et à l'IA Dans le cadre de l’ouverture d’un poste en interne, nous recrutons en CDI un-e Data Value Engineer, basé-e à Paris (prévoir des déplacements réguliers de 2 jours tous les 15 jours sur Lille). VOS RESPONSABILITES En tant que Senior Data Value Engineer au sein du Data Value Lab, vous devrez: Être dédié à 100% aux projets digitaux stratégiques liés à la transformation de l'entreprise par l'IA, sur des sujets transverses (Sports & Process, Supply Chain, Marketing, Offre, Pricing, Sustainability principalement) Vous identifierez, cadrerez, prioriserez et construirez des solutions d'IA pour les métiers : réalisation d'un business case, traduction d'un problème métier en solution d'IA, estimation du potentiel de valeur, exploration des données pour déterminer un niveau de faisabilité et enfin pilotage du build avec les équipes de Data Science. Vous remettrez en question les problèmes métiers, la valeur potentielle et la faisabilité technique des besoins remontés . Vous serez amené à projeter des cas d'usages pragmatiques à partir de nos trajectoires digitales priorisées. Vous utiliserez vos connaissances des applications business de l'IA, ainsi que votre maitrise du cycle de vie d'un projet de Data Science , pour définir les cas d'usages d'IA à fort impact et garantir leurs mise en oeuvre. Vous serez en charge de l'organisation, de la préparation et de l'exécution des workshops métiers lors de la phase de Design, avec des parties prenantes à 360° afin d'identifier des besoins ou alors les cadrer. Vous appliquerez la méthodologie agile pour mener à bien votre feuille de route et animer votre roadmap. V ous serez en charge du pilotage du projet lors des phases de Define et de Build , en collaborant avec des parties prenantes techniques et métiers. Vous identifierez les données critiques (à valeur) à collecter et à intégrer dans le domaine des données d'entreprise, en partie grâce à vos cadrages. Vous communiquerez efficacement l'analyse et les résultats des expérimentations, en passant par une mesure concrète de la valeur créée. Et ce par le biais de visualisations, de documents et de présentations à toutes les parties prenantes. CE DONT VOUS AUREZ BESOIN POUR RÉUSSIR Vous avez au moins 3 ans d'expérience en tant que Consultant-e Data, Business Translator, PM Data ou Data Scientist; qui vous as permis-e d'être un-e solide généraliste Data sur l'ensemble du cycle de vie de la donnée. Hards Skills : Vous avez acquis une expertise des applications IA pour les business, de la traduction d'un problème métier en solution d'IA ; Vous comprenez et vous avez une connaissance complète du cycle de vie d'un projet de Data Science, ainsi que des besoins et exigences en matière de données; Vous avez acquis une expérience en Business Analyse; Vous avez de solides compétences de restitution d'analyses, pitch/argumentation ; Vous avez acquis une expérience en management de projet Data, pilotant des équipes transverses à la fois techniques et métiers; Vous avez des compétences en analyse des données : analyse et visualisation exploratoires des données; Vous avez un niveau de base en SQL et/ou en Python ; Vous êtes expérimenté en techniques de Design Thinking et leurs applications aux produits Data; Soft Skills : Vous avez d' excellentes compétences interpersonnelles, analytiques, de communication et de présentation - capacité à communiquer des résultats complexes de manière simple ; Vous avez des compétences solides en matière de résolution de problèmes, l'accent étant mis sur le développement de produits ; Vous aimez découvrir et résoudre des problèmes ; chercher de manière proactive à clarifier les exigences et les orientations ; vous êtes une personne autonome qui prenez des responsabilités lorsque cela est nécessaire ; Vous êtes capable d'explorer différentes directions à partir de données et êtes capable de changer rapidement de direction en fonction de l'analyse ; Vous êtes passionné.e par le sport et la mobilité Vous avez envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, notamment implantées à Paris, Lille, Nantes, Lyon et Amsterdam. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .","Decathlon is looking for a Senior Data Value Engineer with at least 3 years of experience in data consulting or analysis. The role involves identifying and prioritizing AI solutions for various departments, managing agile projects, and communicating results to stakeholders. The ideal candidate will have expertise in AI applications for business, data analysis, communication, and problem-solving skills, as well as a passion for sports and mobility. Decathlon is committed to diversity, inclusion, and non-discrimination and offers benefits such as teleworking, skills development, and employee share ownership.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
378,58097,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/data-engineer_paris_DOCTR_JDmO7pQ,Data Engineer (Squad Produit),Doctrine,"{React,durable,NoSQL,NodeJS,Dask,Airflow,Kubernetes,PostgreSQL,S3,Elasticsearch,SQL,Github,Python}",Télétravail partiel possible,"43, Avenue de Clichy, Paris, 75017","Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique",CDI,2023-03-26,"Doctrine rend l’information juridique plus accessible et intelligible pour les professionnels du droit : avocats, juristes, magistrats, experts… Start-up de la Legal Tech française, Doctrine a convaincu plus de 6 500 clients de lui faire confiance depuis sa création en 2016. Avec plus de 80 collaborateurs aujourd’hui, elle prévoit de recruter des dizaines de talents en 2021 et 2022 afin de poursuivre le développement de ses solutions technologiques innovantes, de faciliter la vie de toujours plus de professionnels du droit, et d’œuvrer encore davantage à la transparence et la modernisation de la justice. Notre mission ⚖️ Nous nous engageons pour un enjeu démocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit. Doctrine est la première plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et défendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et déjà 9000 professionnels du droit nous font confiance. Nos valeurs 🤝 Challenge the status quo. Nous défendons les idées audacieuses et la prise de risque intelligente. Liberty and responsibility. Nous promouvons l’autonomie, l’impact de chacun·e et l’ownership. Knowledge is power. L'information est au cœur de la mission de Doctrine, et nous voulons toujours apprendre plus. Release early, release often and listen to your customers. Nous croyons au pouvoir de l’itération et à l’importance d’écouter en permanence notre marché, nos client·e·s et leurs problématiques. Le contexte Nous sommes actuellement à la recherche d’un profil Data Engineer pour rejoindre l’une de nos squads et participer à la construction de la première plateforme d’intelligence juridique. Tu rejoindras une équipe dédiée à l’acquisition, l’enrichissement et la mise à disposition de la donnée juridique dans notre plateforme. Notre stack technique : on travaille avec NodeJS, NestJS, React & NextJS Tu peux trouver des détails sur l’ensemble de la stack sur Github A savoir : il n’est pas nécessaire d’avoir une expérience professionnelle dans le domaine du droit, cependant l’envie de s’investir et de monter en compétence dans la compréhension des documents juridique est importante :) Les missions 🛠 Contribuer au maintient des pipelines de données du périmètre de la squad. Concevoir, développer, monitorer et maintenir de nouveaux scripts d’acquisition et de traitement des données en Python pour ajouter de nouveaux contenus dans notre plateforme. Travailler en collaboration avec nos Machine Learning Engineers et experts NLP pour les aider à intégrer leur travail dans le pipeline de données. Contribuer à l’évolution de nos outils de pipeline de données (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...) Participer à la vie du Chapter Data Le profil idéal 👀 De bonnes compétences en programmation Python. Connaissance des pratiques d'acquisition et de modélisation des données. Connaissance de SQL, NoSQL, Elasticsearch et du stockage objet. L’envie de partager ton savoir au sein de l'équipe La maîtrise de la langue française, car tu seras amené.e à manipuler des données juridiques en français Les à côtés du poste 👁 Comme tous les Data Engineers de Doctrine, tu participeras à un de nos chapters transverse, en l’espèce le chapter Data. Au sein de ce chapter, tu contribueras à des projets internes pour améliorer nos process et notre vision long-terme. Le chapter se réunit 2 fois par mois pour : 🤝 Partager des connaissances : amélioration continue, bonnes pratiques… 🎯 Proposer des évolutions : nouveaux outils à expérimenter, nouveaux process à mettre en œuvre 👩‍💻 Recruter : tous les contributeurs individuels rencontrent des candidats à l’occasion de tests techniques ou d’entretiens. Ce qui t'attend si tu rejoins Doctrine 🤗 - Contribuer à un projet ambitieux, avec un impact réel et positif sur la société : rendre le droit plus accessible et plus ouvert. - Un accompagnement sur mesure dès ton arrivée sur l'écosystème juridique pour t'aider à naviguer très vite dans cet environnement stimulant. - Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances à l’ensemble de tes collègues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.) - Travailler au sein d’une équipe en ébullition qui cherche sans cesse à se renouveler : de la place pour innover et mener des projets en autonomie ou en équipe. Nos avantages pour faire la différence ☀️ 🏡 Une politique de télétravail flexible, avec 2 jours de présence au bureau par semaine (mardi et jeudi) 🌱 De nombreuses options pour ta carrière, et des mobilités internes ouvertes à toutes et tous chez Doctrine 🌴 Des vacances flexibles et illimitées 📚 Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750€ en usage libre et des formations en équipe et pour toute l'entreprise régulièrement 🏄‍♂️ Des évènements collectifs réguliers 👩‍⚕️ Une bonne assurance santé avec Alan 🚲 Un forfait mobilité durable à hauteur de 66 euros par mois 🏋️‍♀️ Un abonnement Gymlib pour les activités sportives et bien-être 🍱 Une carte Swile pour tes tickets restaurants 🧘 Un accès gratuit à la plateforme d'accompagnement à la santé mentale Moka.care 💡 Des centaines de réductions et avantages négociés grâce à notre CSE 🍏 Un équipement de travail neuf chez Apple Notre processus de recrutement 🚀 - Un premier échange de 30 min avec l’un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te présenter ce qu'on construit chez Doctrine - Une rencontre d’1h avec ton/ta futur.e manager , pour détailler le poste et le scope de l’équipe, mais aussi répondre à toutes tes questions. - Un ou deux tests techniques pour évaluer concrètement tes compétences - Un déjeuner avec 3 personnes de différents départements chez Doctrine, pour te donner un aperçu de tes futur.e.s collègues - Un échange sur les valeurs de l’entreprise pour te partager notre vision - Une rencontre avec Guillaume, notre CEO. (si nécessaire le processus pourra être adapté pour répondre à tes contraintes personnelles et professionnelles) Mesdames, autorisez-vous à candidater ! Certaines études scientifiques montrent qu'en particulier les femmes ont moins tendance à postuler à une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins. Si Doctrine vous intéresse, sachez que nous aurons plaisir à recevoir votre candidature !","Doctrine, a French Legal Tech start-up, is seeking a Data Engineer to help build its first legal intelligence platform. The ideal candidate should have good Python programming skills, knowledge of data acquisition and modeling practices, and familiarity with SQL, NoSQL, Elasticsearch, and object storage. The position offers flexible remote work, unlimited vacation, a focus on individual and collective training, and numerous employee benefits. Applicants who are not lawyers but wish to learn more about legal documents are encouraged to apply.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
393,34782,https://www.welcometothejungle.com/fr/companies/m13h/jobs/dataviz-engineer-france-europe-f-h_paris,DataViz Engineer - (France / Europe) -,M13h,"{OneTrust,DataStudio,Looker,PowerBI,Fivetran,dbt,Contentsquare,via,Adverity,SQL,Qlik,Tableau}",Télétravail partiel possible,Paris,"Digital Marketing / Data Marketing, Stratégie, Big Data",CDI,2022-08-08,"A propos de M13h 👋 M13h est une équipe de consultant·e·s passionné·e·s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Stratégique et expertises Data, Marketing & Technologies pour accélérer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous maîtrisons toute la chaîne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, … à accroître leurs performances, au travers de missions variées : Stratégie Data : définir sa stratégie, ses cas d’usage data et le socle technologique pour la déployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donnée pour créer de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et améliorer les taux de conversion Privacy : s’adapter aux évolutions technologiques et règlementaires tout en développant ses performances marketing Modern Data Platforms : construire des plateformes de données sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des données pour prendre des décisions éclairées (dashboards, data analyse, data science, modélisation avancée, …) M13h est membre du Groupe Labelium et met ses compétences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure à taille humaine où il fait bon travailler ! En plein mouvement de régionalisation et d’internationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l’Europe (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N’hésitez pas à en discuter en entretien. Description du poste 📢 En tant que DataViz Engineer, tu interviens sur les problématiques relatives à la mise en place de dashboards et autres outils de pilotage d’activité pour les clients de M13h. Pour cela, tu interviens à différents stades des projets : Compréhension des besoins métiers et définition des indicateurs pour les représenter de manière efficace Création des indicateurs de suivi Mise en place des dashboards Maintenance et évolution des dashboards Veille sur les évolutions du marché Définition des bonnes pratiques de développement de visualisation efficientes Quelques exemples de missions à titre d’illustration : Création de dashboard centralisant la donnée média issue des principales plateformes d’activation Construction de rapport de suivi de performances marketing Mise en place d’un outil de pilotage de l’attribution média Création de dashboard omnicanaux avec notamment les données issus de Google My Business et Facebook pages Mise en place de dashboards à destination des franchisés Création de templates de dashboards dans le cadre d’une industrialisation du pilotage media Rigoureux·se, tu as à cœur de comprendre les besoins de tes interlocuteurs puis les traduire et les matérialiser via des dashboards pertinents . En tant que Junior , tu seras encadré·e par des profils plus seniors te permettant de progresser rapidement dans notre environnement et sur des outils modernes. Profil recherché 👨👩 Issu·e d’une grande école de commerce, d’ingénieurs ou équivalent , tu souhaites t’orienter vers les métiers de la business intelligence. Tu connais certains outils de marché (Tableau, PowerBI, DataStudio, Qlik, Looker, …) et tu as des bases dans la gestion et la structuration de données notamment en SQL, ainsi que sur la meilleure manière de restituer des données de façon visuelle. Tu souhaites travailler sur des environnements cloud et découvrir les outils ELTs. Au-delà des compétences techniques, tu fais preuve de rigueur, de créativité et d’autonomie. Tu as également une forte capacité de formalisation et fait preuve de pédagogie. Pourquoi nous rejoindre ❓ M13h, c’est avant tout une équipe qui aime les challenges et porte des valeurs de bienveillance et de progrès collectif . Tu as déjà lu ça ailleurs ? Contactes nos consultant·e·s sur LinkedIn pour vérifier directement :) Démarrer chez M13h, c’est aussi une belle opportunité de développer tes compétences conseil et ton expertise rapidement sur des missions variées, au sein d’une structure à taille humaine tout en profitant des avantages d’un groupe international. Tu es accompagné par un parrain ou une marraine dès ton arrivée en plus de ton manager, profites de formations, accèdes à de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, … Et puis M13h, c’est aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d’arrivée pour s’équiper pour le télétravail Une politique souple de télétravail Un abonnement gratuit à des salles de sport 2 séminaires par an et de nombreux moments de cohésion d’équipe Des locaux au coeur de grandes villes françaises (Paris, Bordeaux, Lyon) et européennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge à 100% et bien d’autres… Comment postuler 🙋 Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontanée à recrutement@m13h.com","M13h is seeking a DataViz Engineer to develop dashboards and other activity management tools for clients. The role requires understanding business requirements, creating key performance indicators, and implementing dashboards while remaining up-to-date with market trends. Candidates should have a degree from a top business, engineering, or equivalent school and knowledge of data management tools such as SQL, as well as demonstrate creativity and autonomy. M13h offers a supportive and collaborative work environment and provides training, resources, and perks like telecommuting, gym memberships, and team-building events.",Bac +5 / Master,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
388,35854,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-h-f-innovative-tech_lille_DIT_4DW7Y48,Data Engineer  - Innovative Tech,Devoteam Innovative Tech,"{DataStudio,Looker,Keras,TensorFlow,AWS,QlikView,GCP,Tableau}",Télétravail partiel possible,N,"IT / Digital, Stratégie, SaaS / Cloud Services",CDI,2022-09-28,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs stratégies de modernisation de plateformes. Face à l’avènement du Cloud et des nouvelles méthodes de travail qui en découlent, les DSI doivent aujourd’hui répondre à plusieurs enjeux majeurs pour être agiles, porteuses d’innovation, perçues comme un véritable “business partner” tout en ayant une gestion responsable de la consommation énergétique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant à adopter une posture créative et apprenante. L'équipe lilloise n’attendent que toi pour relever de nouveaux défis. Ensemble nous accompagnerons nos clients dans la transformation de leur projet. Tes missions si tu l’acceptes : Accompagner les grands comptes dans leur projet de mise en place de projets Data avec GCP, AWS ou tout autre système Big data. Analyser les besoins clients : Animer des ateliers Préconiser des architectures cibles Rédiger des dossiers d'architecture et spécifications techniques Définir les méthodologies de déploiement et plans de migration Construire les architectures de données : Concevoir et mettre en place des systèmes de données résilients et sécurisés Construire et déployer les pipelines de données (ETL) Assurer la migration des données vers les nouveaux environnements Analyser les données : Analyser les données sources afin d’identifier et évaluer des cas d’usage métier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…) Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les équipes clients aux méthodes et concepts du cloud Diplômé(e) d’une école d’ingénieurs ou d’un Master 2 en informatique , tu souhaites t'investir dans une équipe dynamique, passionnée et aux valeurs humaines. And You are fluent in english ! Tu es désireux (se) de t'investir dans des projets challengeants et gagner rapidement en responsabilités. Rejoigne la tribu ! Tu veux en savoir plus? Viens échanger directement avec nos ambassadeurs . Le Groupe Devoteam oeuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme dediscrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation.","Devoteam Innovative Tech is seeking an engineer or Master's holder in computer science to join their Lille-based team to aid major businesses with their big data projects using GCP, AWS or other big data systems. Responsibilities include analyzing clients' needs, developing data architectures, migration plans and deploying pipelines while providing constant cloud solutions support and training to clients. The ideal candidate should possess excellent analytical and communication skills, have knowledge of data analysis tools, and be proficient in English.",N,N,N,2,1,0.04154662416233763
386,39788,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer_paris_CONTE_DlplLYM,Data Engineer,Contentsquare,"{go,regard,ContentSquare,Go,color,Scala,Akka,AWS,Contentsquare,scale,Kafka,Elasticsearch,Spark,ClickHouse,Java}",Télétravail partiel possible,"7, Rue de Madrid, Paris, 75008","SaaS / Cloud Services, E-commerce",CDI,2022-11-29,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team – known as the CSquad – representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of passionate and talented developers, designing and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at ContentSquare ! We collect several billions events per day, and query hundreds of terabytes in real time. Your daily work will consist of: •Designing efficient architectures to store and analyze petabytes of data •Leading large scale projects and mentoring other developers •Implementing complex acquisition workflows •Thinking of smart data formats to serve the functionalities of the product, while minimizing the cost •Developing tools to help data-scientists, by using some open source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have an interest in functional programming and seek to develop your skills in Data engineer programming languages. Kafka, Akka, Spark, AWS… You have had the chance to discover or work with these big data technologies. Ideally, you have some experience on a wide range of databases and you are interested in streaming. You would like to challenge yourself developing distributed infrastructure with a real time and data-intensive environment. You would like to share your skills and take part in technical choices. Why join ContentSquare’s Data Engineering team? •You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data. •You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences. •You are looking for an environment where you’ll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategical corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross team innovation days, we are committed to innovate towards tomorrow’s user experience. You’ll also have: flexible working hours, remote ; yoga, and many other activities; after work beers provided every Friday, monthly parties…and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare: ▪️ We’re humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ▪️ We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ▪️ We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ▪️ Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ▪️ Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ▪️ Work flexibility: hybrid and remote work policies. ▪️ Generous paid time-off policy (every location is different). ▪️ Immediate eligibility for birthing and non-birthing parental leave. ▪️ Wellbeing allowance. ▪️ Home Office Allowance. ▪️ A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ▪️ Every full-time employee receives stock options, allowing them to share in the company’s success. ▪️ We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don’t meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, seeks a Data Engineer to design and develop a new data architecture, lead large-scale projects, implement complex acquisition workflows, and develop tools to help data scientists. Candidates should be proficient in Scala, Java, or Go and have experience with big data technologies like Kafka, Spark, and AWS. Benefits include flexible working hours, remote work, career development, mentorship, and competitive benefits. The company values uniqueness and is an equal opportunity employer.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
385,34440,https://www.welcometothejungle.com/fr/companies/veepee/jobs/software-engineer-for-data_barcelone,Software Engineer for Data,Veepee,"{Beam,k8s,Protobuf,gitlab,Kubernetes,Airflow,dbt,gRPC,kubernetes,Bigquery,Dataflow,Java}",Télétravail partiel possible,Barcelone,E-commerce,CDI,2022-08-08,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire européenne avec la convergence des différentes sociétés qui le composent et leurs 6 000 collaborateurs vers une seule et même marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd’hui présent dans 14 pays et devient un acteur majeur du commerce digital européen, avec 72 millions de membres et un volume d’affaires de 3,7 milliards d’euros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour réveiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos stratégies, afin de proposer la meilleure expérience possible à nos clients. Vous avez soif d’apprendre ? Veepee vous permet de construire votre parcours parmi une pluralité de métiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes… prenez part à une aventure humaine au cœur d’enjeux digitaux. Impatients de les rencontrer ? Ils ont hâte aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a Software Engineer in Veepee’s data organization, you will.. .. be part of our data organization Veepee’s data organisation came into existence in 2018 and consists of a strong team of 40-50 data professionals, spread across different data domains (engineering, analytics, data science & ML and governance). You will be part of a multidisciplinary, multinational team that fosters collaboration, transparency, respect and of course… a good amount of fun in the working environment. .. build and maintain APIs, tools and pipelines that form Veepee’s data platform For its data platform, Veepee firmly believes in a Push - Load - Transform strategy of ingesting data. Products are responsible for the data they produce and our data platform should enable them to push that information (in real-time) into our data platform in a governed way. Hence, we adopted data contracts to define which data comes in and have built our own set of tools and API’s around this to facilitate data ingestion, Veepee style. Furthermore, we keep improving our toolchain for data transformation (using dbt) and data exposure downstream. Responsibilities: Be part of a team running a set of applications with high SLA requirements; Develop, deploy and maintain a large Java stack serving a set of APIs mainly developed in gRPC & Protobuf Support, design, implement and deploy microservices running on Kubernetes with a Gitops approach; Identify data producer and consumer requirements and implement pragmatic and robust solutions based on solid architecture patterns (Reactive, Operator, Resilient..); Maintain data pipelines and data jobs mainly developed with Apache Beam and Apache Airflow; Keep improving your technical knowledge and expertise by attending conferences, contributing to open-source projects organizing and attending meetups Requirements: You have a strong experience (3-5 years) working on a large Java stack; You know how to implement and consume APIs, preferably in Protobuf & gRPC; You love making clean code and you are interested in having successful software engineering practices (Unit tests, pair programming, code reviews). You would like to help the team to grow in the quality of what they produce and their methodologies; You have experience with setting up CI/CD pipelines, preferably in gitlab; You have significant experience working with microservices and Kubernetes; You know or want to use helm charts as a templating language for k8s crd’s; You know or want to use the concept of a GitOps strategy for deploying kubernetes resources, preferably using ArgoCD; You are willing to learn data engineering concepts, tools and frameworks (Apache Beam, Apache Airflow, dbt); You would like to work with Google Cloud Platform (Bigquery, GKE, Dataflow); You know or want to learn Infrastructure as Code tools like terraform, atlantis; You are a strong team player. What we offer: The dynamic and creative environment within international teams; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences locally and internationally; Hybrid work organization and flexibility for full remote contracts; Advanced remote practices and tools. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you’ll be sure to find your place, no matter the technology you want to work with. If you love to try things why don’t you jump on this new adventure? Need more info > https://careers.veepee.com/en/careers/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, part of the vente-privee group, is seeking a software engineer to join its data organisation. The role involves building and maintaining the company's data platform, developing and deploying a large Java stack serving a set of application programming interfaces (APIs), designing microservices running on Kubernetes with a Gitops approach and maintaining data pipelines and data jobs largely developed with Apache Beam and Apache Airflow. Candidates are required to have three to five years' experience working on a large Java stack and should be familiar with gRPC, Protobuf and Helm charts.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
384,34338,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-cdi-f-h_niort_ASI_dDRXeKk,Data Engineer - CDI,ASI,"{DynamoDB,Matillion,Glue,Cassandra,Hive,Neo4J,Azure,Cloudera,MongoDB,Talend,Kafka,NoSQL,CouchDB,HBase,Java,Hadoop,Redis,EMR,Scala,Airflow,HDFS,S3,Spark,Python}",Télétravail partiel possible,Niort,"IT / Digital, Transformation, Big Data",CDI,2022-08-08,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Dans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin. Dans le cadre du développement de nos expertises Data et pour répondre aux enjeux de nos clients, nous recherchons un Data Engineer pour intégrer notre équipe Niortaise Au quotidien : Vous concevez et réalisez un sourcing de données Big Data, temps réel ou non Vous maîtrisez les formats de données non structurés et savez les manipuler Vous modélisez un schéma de base de données relationnelle ou non-relationnelle Vous connectez une solution ETL / ELT à une source de données (fichiers, API, base de données, flux temps réel) Vous concevez et réalisez un pipeline de transformation et de valorisation des données et ordonnancez son fonctionnement Vous veillez à la sécurisation des pipelines de données Vous concevez et réalisez des API utilisant les données valorisées Vous réalisez une veille technologique constante. Parlons de vous : Issu d’une formation supérieure en informatique, mathématiques ou spécialisé en Big Data. Vous possédez une expérience minimum de 2-3 ans en ingénierie des données et d'une expérience opérationnelle réussie dans la construction de pipelines de données structurées et non structurées. Vous avez une expérience pratique dans l’un ou plusieurs des environnements technologiques suivants : L’écosystème Data : Spark, Hive, HDFS, Kafka, HBase et idéalement une distribution Hadoop (Cloudera, EMR, HDInsight) Les langages : Scala, Java, Python Les bases de données NoSQL : MongoDB, Cassandra, DynamoDB, CosmosDB, CouchDB, Redis, Neo4J Stockage cloud: S3, Azure Blob Storage… Les ETL/Outils d'orchestration du marché : Matillion, Airflow, Datafactory, Glue, Talend,... Le respect et l’engagement font partie intégrante de vos valeurs. Vous avez l’esprit d’équipe et vos qualités relationnelles vous permettent de vous intégrer facilement au sein de l’équipe. À compétences égales ce poste est ouvert aux personnes en situation de handicap .","ASI, a French digital expertise consultancy, is seeking a Data Engineer to join their Niort team. The successful candidate should have a degree in computer science, mathematics, or big data and at least 2-3 years of experience in data engineering. They should be familiar with technologies such as Spark, Hive, HDFS, Kafka, etc., and have practical experience in building pipelines for structured and unstructured data. Additionally, they should have strong teamwork skills and a commitment to social responsibility. The position is open to candidates with disabilities.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
381,34126,https://www.welcometothejungle.com/fr/companies/lectra/jobs/ingenieur-qa-data-data-qa-engineer-h-f_cestas,Ingénieur(e) QA Data / Data QA Engineer,Lectra,"{Jenkins,GitLab,Scala,Kubernetes,Docker,Kafka,R,via,Git,Java,SQL}",Télétravail partiel possible,Cestas,"Logiciels, SaaS / Cloud Services",CDI,2022-08-08,"Acteur majeur sur les marchés de la mode, de l’automobile et de l’ameublement, Lectra contribue au développement de l’industrie 4.0 avec audace et passion. Le groupe propose des solutions d’intelligence industrielle à la pointe de la technologie qui facilitent la transformation digitale des entreprises. Grâce à ses logiciels, équipements, données et services, Lectra aide ses clients à repousser les frontières et à libérer pleinement leur potentiel. Ses 2 400 collaborateurs sont guidés par trois valeurs fondamentales, qui font la fierté du groupe : faire preuve d’ouverture d’esprit, être des partenaires de confiance et innover avec ardeur. Fondée en 1973, Lectra a réalisé un chiffre d’affaires de 388 millions d’euros en 2021 et est cotée sur Euronext (LSS). Pour plus d’informations, visitez lectra.com. Notre département R&D Software basé à Bordeaux/Cestas est à la recherche de son/sa futur(e) ingénieur(e) QA Data. Rattaché(e) au Team Lead, vous serez intégré(e) dans une équipe agile spécialisée dans le traitement de la donnée et composée d’ingénieurs Data, d’un Tech Lead et d’un chef de projet. Vous aurez en charge la validation des jeux de données et de leur traitement. Pour cela, vous participerez à la définition et mise en œuvre de la stratégie de test au travers de tests manuels et automatisés afin de garantir un très haut niveau de qualité sur l’ensemble des développements. Au sein de la Communauté QA, vous participerez aux activités liées à la stratégie de test, à l’outillage, à la définition des jeux de données et toutes les activités liées à l’amélioration continue. Vous contribuerez de façon active avec les équipes à l’amélioration globale de la qualité logicielle. Intégré(e) à une équipe dans un contexte Lean / Agile, vos missions principales seront les suivantes : • Avoir une bonne compréhension des besoins et des enjeux liés aux produits développés, • Définir et mettre en œuvre de la stratégie de test en accord avec l’ensemble des acteurs du projet, • Rédiger les plans de test et les cas de test, • Automatiser, suivre, analyser et maintenir les tests, • Saisir les anomalies, les suivre et valider leur correction, • Participer à la mise en production des services Cloud dans le cadre des exigences de qualité définies, • Participer à la mise en place d’outils de test ou de processus permettant d’optimiser les tâches de validation dans un contexte d’amélioration continue (scripting, gestion des jeux de données, etc.) et de livraison continue, • Être partie prenante au sein de la communauté QA, • Avoir un fort esprit d’équipe et un bon relationnel contribuant ainsi à travailler dans un environnement productif, collaboratif et agréable. ENVIRONNEMENT TECHNIQUE Outils de test : Postman, Karate DSL, Selenium, Git / GitLab, Jenkins, VersionOne Méthodes : Lean / Agile, Scrum / Kanban, BDD, Continuous Delivery Langages de développement : Java, Scala, SQL De formation Bac+3 à Bac+5, vous justifiez d’une expérience de 2 ans sur le même poste au sein d’une équipe de validation logicielle / qualité logicielle, de préférence en environnement Cloud. Compétences requises : Expertise en méthodologie de test logiciel (une certification ISTQB serait un plus), Maitrise en outillage de test et d’automatisation, Connaissance des environnements d’intégration continue (Jenkins) et de gestion de configuration (Git), Rigueur, analyse, esprit d’équipe, culture du changement et de la qualité. Compétences souhaitées : Notions de programmation Java et/ou Scala, Notions d’utilisation de Docker et Kubernetes, Notions du framework Kafka. Ce que Lectra vous propose ? • Rejoindre une entreprise innovante proposant des solutions et services premiums • Travailler dans un environnement international, multiculturel (32 nationalités) et agile • Des locaux refaits à neuf récemment sur un site boisé de 12 hectares • Un CSE attractif proposant des subventions pour les voyages, de la location de matériel (randonnée, surf, …), des activités culturelles et sportives, une médiathèque… • La mise à disposition du complexe sportif du Bouzet à Cestas (badminton, court de tennis, piscine…) • Un restaurant d’entreprise • Un remboursement de 50% des transports en commun • Une mutuelle d’entreprise prise en charge à 50% • Des primes de cooptation dans le cadre des recrutements • Télétravail : 1jour/semaine Le poste est basé à Cestas (23 chemin de Marticot) - pour nous rejoindre : • Accessible par l’autoroute sortie 25 de l’A63 (parking voiture et deux-roues sur place) • Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de vélo/trottinette pour accéder au campus sur piste cyclable hors route. • Depuis Bordeaux - Pellegrin via le Transgironde 602 : arrêt Marticot : 45 min – depuis Pessac Unitec : 20 min","Lectra is looking for a QA Data Engineer to join their R&D Software department in Bordeaux/Cestas. The role involves validating datasets and their processing using manual and automated tests, working with the QA community to improve test strategies and tools, and contributing to the overall quality of software. Required skills include software testing methodology expertise, test automation proficiency, and experience with Git, Jenkins, Java, and SQL. The company offers an innovative, agile, and multicultural environment, along with attractive benefits and work-life balance opportunities. The position is based in Cestas.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
379,58102,https://www.welcometothejungle.com/fr/companies/altaide/jobs/data-engineer-media-de-premier-plan-h-f_paris,Data Engineer / Media de premier plan,ALTAIDE,"{Dataiku,Jenkins,Talend,GitLab,Shell,Airflow,DBT,Fivetran,Snowflake,via,Git,SQL,Python,linux}",Télétravail partiel possible,"23 rue des Mathurins, Paris, 75008",Recrutement,CDI,2023-03-26,"Pionnier du recrutement digital, Altaïde est reconnu comme « LE » chasseur de têtes des startups et des entreprises en transformation digitale. Présents à Paris, Bordeaux, Barcelone et Lisbonne, ils accompagnent leurs clients en Recrutement, Executive search, RPO et Conseil en France et à l’international. Altaïde a révolutionné la chasse de têtes en inventant le social recrutement et en développant une méthodologie éprouvée qui s’appuie sur leur approche technologique du sourcing (LinkedIn Recruiter, Twitter, Marketing Automation, Programmatic, IA Search…). Ainsi depuis 2000, leur implication dans l’écosystème, leur approche marketing, les moyens déployés en sourcing et la puissance de leur réseau relationnel, sont à la base de leur succès. Dès la création d’Altaïde, ils ont adopté un style différent des cabinets de recrutement et autres chasseurs de têtes. Leur philosophie est basée sur un mélange de fun, de professionnalisme, de proximité avec leurs clients et le secteur, et sur une approche conviviale de la relation candidat-recruteur. Seul cabinet français du Top 25 Europe des Most Socially Engaged de Linkedin, et classé dans les 50 meilleurs cabinets de recrutement des Echos, ils sont fortement reconnus pour leurs méthodes et leurs résultats dans leur métier. Média presse et web de référence en France, nous sommes reconnus pour notre travail d’enquête, de reportage et d’expertise, notamment dans le domaine des idées, du savoir et de la science. Notre marque est historiquement présente en presse, largement établie en numérique, et de façon physique (évènements). Notre qualité éditoriale alliée à notre savoir-faire digital, font de nous un incontournable avec près de 15 millions de lecteurs web et une appli dans le Top 10 des applis d’informations. Dans le cadre de l’accélération de la transformation numérique de notre modèle, nous recherchons un(e) Data Engineer qui deviendra le référent(e) Technologique du service Data. 🎯Une missions riche : En tant que responsable de notre Data Plateforme, votre principale mission consiste à opérer et superviser son implémentation, sa gestion quotidienne (run, maintenance) ainsi que son amélioration continue. Pour cela, vous : Construisez, testez, maintenez et automatisez l’ensemble des pipelines de données Connectez les sources de données à la plateforme Data. Pour chaque source, vous recommandez et précisez les modalités d’ingestion recommandées et les données à récupérer Assurez la transformation des données (bronze vers or) en exploitant les langages et/ou outils ELT adéquats. Vous en structurez et en automatisez progressivement les différentes étapes. Assurez la migration des données ainsi que les traitements qui leur étaient appliqués vers la nouvelle plateforme Data, par priorité. Vous ajustez les nouveaux pipelines associés en tenant compte des pipelines existants. Testez et déployez des solutions d’observabilité et de correction automatique pour améliorer la qualité des données. Savez détecter les potentiels d’évolution associés à chacune de ses composantes pour en maximiser la valeur ajoutée (qualité, disponibilité des données, simplicité d’exploitation…), tout en minimisant ses coûts (de stockage, de requêtes, de maintenance…) Structurez et optimisez l’architecture de la plateforme Data (Warehouses et DataSets) en fonction des uses-cases et usages afin d’en permettre une exploitation simple, harmonieuse, contrôlée et à coûts maîtrisés. Travaillez de manière continue avec l’équipe Data : vous vous servez de ses besoins en matière de Gouvernance / Data Analyse / Data Science / Compliance RGPD, comme use case pour guider vos actions, vos priorités et alimenter votre feuille de route. Mettez ainsi à disposition les données nécessaires aux différents utilisateurs, en adaptant les modalités de mise à disposition en fonction de leurs besoins. Connectez la Plateforme Data avec les solutions d’activation de la donnée actuels ou à venir : BI, marketing automation, CDP… Assurez la gouvernance technique de la plateforme Data : vous structurez ou mettez à jour en continu la partie technique de nos dictionnaires / mapping de données. Vous rédigez les modes opératoires, processus et RACI. Vous mettez en place l’ensemble des règles / scripts / filtres / sécurités / processus nécessaires Diplômé(e) d’une école d’ingénieur ou d’un Master Informatique avec une spécialisation dans la Data, vous disposez d’une expérience d’au moins 4 années dans le milieu du Conseil en Data, ou sur un poste similaire au sein d’un environnement dynamique de transformation ou de croissance accélérée. Vous êtes reconnu pour votre parfaite maîtrise de SQL et de Python . Vous avez une excellente connaissance des environnements Cloud de type Snowflake et des technologies Big Data. La certification SnowPro Core serait un vrai plus. Vous savez gérer la gouvernance d’une plateforme et en optimiser les coûts de fonctionnement (FinOps) . Vous maîtrisez l’environnement DevOps via les outils de versioning (Git), les plateformes d’intégration continue (Jenkins, GitLab). Idéalement, vous savez réaliser des programmes en Shell Script et connaissez les commandes standards sous linux. Vous avez une expérience confirmée de déploiement d’ETL (idéalement Streamset de type Fivetran, Talend), de déploiement de plateformes d’orchestration (Airflow, DBT) et de traitement automatisés des données (Saagie, Dataiku). Vous avez déjà et aimez travailler en méthode Agile/Scrum , et vous êtes à l’aise dans un environnement dynamique. Votre leadership vous permet de mobiliser toutes les énergies des équipes, et faire adhérer les parties prenantes à vos projets. Votre sens du service, de l’écoute, votre esprit d’équipe et votre relationnel vous permettront de réussir pleinement ces missions. Retrouvez notre offre : https://www.altaide.com/offre-emploi/digital-program-manager-ecole-digital/?utm_source=wttj&utm_medium=jobboard&utm_campaign=diffusion_w Pour ce poste, merci de contacter notre conseil en précisant la référence : LDE-12W Altaïde - Sonia Dujardin - 23, rue des Mathurins 75008 Paris E-Mail : sonia.dujardin@altaide.com","Altaïde, a French recruitment company specialized in startups and digital transformation, is looking for a Data Engineer to lead their Data department. The role involves building, testing, maintaining, and improving the company's data pipelines, connecting data sources and recommending ingestion methods, transforming data, migrating and optimizing data architecture, and ensuring governance and compliance. Candidates must have at least four years of experience in data consulting, expertise in SQL and Python, knowledge of Cloud environments and Big Data technologies, and experience in Agile/Scrum methodologies.",Bac +5 / Master,< 15 salariés,> 4 ans,2,1,0.04154662416233763
376,39685,https://www.welcometothejungle.com/fr/companies/tiime/jobs/data-engineer-f-h_paris_TIIME_4dyeeGa,Data Engineer,Tiime,"{Airflow,Kubernetes,Redshift,scale,Python}",Télétravail partiel possible,"15-17 rue Auber, Paris, 75009","Application mobile, Organisation / Management",CDI,2022-11-29,"Tiime est une start-up française créée en 2015. Chez Tiime, nous développons LA super app pour entreprendre, au service des entrepreneurs français et des experts comptables. Côté entrepreneur, la super app regroupe un maximum de fonctionnalités pour gérer son entreprise au quotidien : facturation, achats, stockage des documents, compte pro. Le tout en 1 pour simplifier l’entrepreneuriat ! Côté expert-comptable, Tiime propose le meilleur de la technologie en mettant à disposition des outils simples et puissants pour gagner en productivité, booster la croissance et repenser l’expérience client. Précurseur en matière d’intelligence artificielle, Tiime est un acteur majeur de la digitalisation de la comptabilité et de la gestion financière des entreprises. A travers ses produits, Tiime sert aujourd’hui le quotidien de plus de 100 000 entrepreneurs et 1 000 experts-comptables. Notre ambition ? Accompagner 1/3 des nouveaux créateurs d’entreprise en France et devenir le logiciel comptable leader du marché. Pour atteindre cet objectif, nous renforçons notre équipe Data et recrutons un Data Engineer (F/H). Ça te tente ? Rejoins notre aventure ! Tes missions : Au sein de l’équipe Data, en relation avec différentes équipes (les développeurs back, l’infra, le produit, le care, le marketing, la finance…) tu auras comme principales missions : Déployer, maintenir et améliorer en continu un projet de traitement de données en masse (transactions bancaires, documents justificatifs) dans un environnement de production intégré au cloud; vous aurez notamment l’opportunité d’agir sur : les bases de données; les pipelines qui les alimentent; le code permettant la bonne exécution; l’infrastructure (environnements de tests et de production); les outils de monitoring. Fiabiliser la donnée et en faciliter la distribution vers les autres équipes (back-end, produit, care, marketing, finance). Participer activement aux processus de relecture et contrôle du code. Participer à l’élaboration des spécifications techniques. Être moteur de la veille technique. Contribuer à la montée en compétence de l’équipe en valorisant le partage de compétences et l’échange Issu(e) idéalement d’un Master en computer science ou d’une école d’ingénieur, tu justifies d’une première expérience sur un poste similaire en tant que Data Engineer ou Data Architect (idéalement acquise dans une scale-up). Tu es rigoureux(se), force de proposition, respectueux(se) de l’existant et des équipes en place, humain et empathique. Tu maîtrises les bases de données relationnelles (PostegreSQL, Redshift…) et les outils d’orchestration (Kubernetes, Airflow…). Une connaissance des outils de conteneurisation et de Python est un vrai plus. Ce que Tiime t’offre : Un environnement de start-up made in France en pleine croissance. Un projet entrepreneurial ambitieux et challengeant. Tu rejoindras le leader de demain de notre secteur d’activité Un projet qui impactera le quotidien de milliers d’entrepreneurs Une culture d’entreprise favorisant l’autonomie, la responsabilisation, la communication et la bienveillance… Prends part à une aventure humaine au cœur d’enjeux entrepreneuriaux ! Impatient de nous rencontrer ? Alors n’hésite pas à postuler. Entretien RH Entretien technique avec un membre de l’équipe Entretien de validation avec notre CTO","Tiime, a French start-up that offers a super app for entrepreneurs and accounting experts, is seeking a Data Engineer to join their team. The ideal candidate should have a Master's in Computer Science or an Engineering degree, with experience as a Data Engineer or Data Architect. The role involves working with different teams to deploy, maintain and improve a project for processing large amounts of data in a cloud-integrated production environment, optimizing databases, pipelines, code execution, infrastructure, and monitoring tools. A strong knowledge of relational databases and orchestration tools is necessary, and knowledge of containerization and Python would be a plus. The company offers a challenging entrepreneurial project with autonomous and responsible work culture, a favorable work environment, and a leadership opportunity in the emerging industry.",N,N,N,2,1,0.04154662416233763
359,39648,https://www.welcometothejungle.com/fr/companies/equativ/jobs/data-engineer-business-process-automation_paris,Data Engineer - Business Process Automation,Equativ,"{Talend,color,Airflow,Snowflake,JAVA,SQL,Python,Tableau}",Télétravail partiel possible,"66 rue de la Chaussée d'Antin , Paris, 75009",AdTech  / MarTech,CDI,2022-11-29,"Equativ is a French AdTech offering an advertising monetization platform for the most important websites in the world. Our objective ? Disrupt the digital advertising industry through high-performance solutions, innovative formats, and exceptional quality. Based in the heart of Paris (IXᵉ), the company continues its international development around the world (opening of the Singapore office in 2019). We have been recognized in the “Champions de la Croissance” rankings by Les Echos and the”Fast 500 EMEA” by Deloitte. Our pride? A team of over 500 employees who flourish through a corporate culture advocating ownership and who live through 3 essential values: Be brave, Be thoughtful, Be together. 👫 About the team Helping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Business Process Automation team (BPA) at Equativ, maximize the company’s efficiency by enabling easy and permanent access to quality data, and connecting pieces of software together to create business value. Our responsibility is to ensure fast, accurate delivery of the data within the company: The right data, at the right place at the right time. We truly believe in automation and technology to overcome manual repetitive tasks and make the best possible use of our time and brain. Your mission 👇 We are looking for a Data Engineer to join our growing team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. What you'll do ✏️ - Develop database solutions to store and retrieve company information, and ensure their functionality - Design conceptual and logical data models and flowcharts - Acquire datasets that align with business needs - Build, test, and maintain optimal database pipeline architectures - Improve system performance by conducting tests, troubleshooting and integrating new elements - Assemble large, complex data sets that meet functional / non-functional business requirements. - Design or re-design infrastructure for greater scalability and optimal extraction, the transformation of data from different data sources - Optimize data delivery, and automate manual processes - Ensure a good data quality display - Collaborate with the data-analytics team to ensure a good and sustainable functionalities delivery - Develop algorithms to transform data into useful, actionable information - Collaborate with BPA team members to ensure team and company objectives About you 💪 - Bachelor's degree in computer science, Informatics, Information Systems, or another quantitative field - At least 3 years of experience as a data engineer or in a similar role - Experience using the following software/tools: - Experience with data pipeline and workflow management tools: Airflow - Knowledge of programming languages (SQL, JAVA, Python) - Experience with visualization tool: Tableau - A previous experience using Snowflake, Talend - Technical expertise in building and optimizing data pipelines, architectures and data sets. - Strong project management and organizational skills - Experience supporting and working with cross-functional teams in a dynamic environment. - Problem-solving attitude & ability to work toward multiple deadlines simultaneously 👋 About us Equativ is the new single name for Smart Adserver, DynAdmic and LiquidM — three proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication. Headquartered in Paris and New York, Equativ operates globally with a team of more than 450 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com . The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies. Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment. Come and lead the charge with us in building a transparent ecosystem based on quality! ---------------------- Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com","Equativ, the French AdTech company, is seeking a Data Engineer to join its growing Business Process Automation team. The role will focus on expanding and optimizing the company's data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. Candidates should hold a bachelor's degree in computer science, informatics, or another quantitative field, and have at least three years of experience as a data engineer or in a similar role. Technical skills required include knowledge of programming languages, experience with data pipeline and workflow management tools, and strong project management and organizational skills.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
375,57121,https://www.welcometothejungle.com/fr/companies/the-product-crew/jobs/data-engineer_paris,Data engineer,The Product Crew,{scale},Télétravail partiel possible,"11 Rue Greneta, Paris, 75003",Recrutement,CDI,2023-03-26,"Chez The Product Crew, ils cherchent à inventer le Futur du recrutement. Ils animent pour cela une communauté de membres sélectionnés pour leur talent en Product, Design, Data et Tech, avec pour vocation de leur apporter du soutien tout au long de leur vie professionnelle. Leur mission est d’aider les membres de cette communauté à libérer leur potentiel. Mais également de permettre aux entreprises de construire et commercialiser les plus meilleurs produits technologiques. Pour cela, ils organisent du partage de connaissance (webinars, ateliers, meetups, masterclass, contenus exclusifs…) et des sessions intensives de recrutement en ligne. Fort d’une communauté de plus de 7500 talents et de plus de 400 entreprises technologiques partenaires; The Product Crew s’adresse spécifiquement aux métiers du Product, du Design, de la Data et de la Tech. Nous travaillons avec +400 startups et scale ups de la scène tech française et européenne, à la recherche de devs, ops, data engineers, scientists expérimentés de Confirmés à C-Level : Heetch, Scaleway, Skello, Blablacar, Sendinblue, Mirakl, Partoo, Frichti, Swan, Jellysmack, MangoPay, Coinhouse… mais aussi les startups d’eFounders comme Collective Work, Numeral, ou Folk… et bien d’autres. Nous développons une communauté de hauts talents avec pour vocation d’apporter du soutien à leur carrière tout au long de leur vie professionnelle. Événements, ressources, sessions de recrutement… 🤜 Décroche ton prochain rôle de Data Engineer avec l’aide de la communauté The Product Crew 🤛 👉 Comme chaque 1er du mois, nous lançons une nouvelle session de recrutement pour les Data Engineers expérimentés . Les inscriptions sont ouvertes pour quelques jours seulement : Tu as la possibilité de rendre ton profil visible auprès de nos startups partenaires, Celles qui sont intéressées rentrent directement en contact avec toi, Nous t’accompagnons tout au long du process. On sera ravis de t’accompagner ton prochain objectif 🚀 L’inscription prend 5min. Pas besoin de CV, et c’est 100% gratuit 😊 Voici le lien pour t’inscrire 👉 https://bit.ly/jobs-wttj En t’inscrivant 1 seule fois, tu pourras décrocher : 💎 Des mises en relation directes avec les équipes de ces startups 💎 Jusqu’à 10 opportunités concrètes en quelques jours 💎 Que des équipes qui ont flashé sur ton profil ⚡️ Tu peux postuler pour devenir membre de The Product Crew et participer à cette session de recrutement (ou à une prochaine). L’inscription prend 5min. Pas besoin de CV 😊 En prenant ton café ☕️ Inscription ici 👉 https://bit.ly/jobs-wttj","Looking for experienced Data Engineers, The Product Crew organizes online recruitment sessions to help members of their community achieve their career goals. They work with more than 400 French and European startups and technology companies, offering events, resources, and recruitment sessions to high-talented professionals in Product, Design, Data, and Tech. They provide direct connections to interested startups, support throughout the recruitment process, and opportunities to network and advance within their careers.",Non spécifié,< 15 salariés,Non spécifié,2,1,0.04154662416233763
369,56688,https://www.welcometothejungle.com/fr/companies/alptis-assurances/jobs/data-engineer-h-f_lyon-3e,Data Engineer,Alptis Prévoyance & Santé,"{Talend,Snowflake,via,TALEND,Qlik}",Télétravail partiel possible,"Lyon 3e, 69003",Assurance,CDI,2023-03-26,"L’ambition d’Alptis ? Permettre à chacun d’être acteur de sa santé ! Créé à Lyon en 1976, Alptis est un groupement de protection sociale, indépendant, associatif et entrepreneurial au modèle singulier dans le monde de l’assurance. Il s’inscrit dans le mouvement de l’entrepreneuriat sociétal porteur de valeurs et de convictions fortes : gouvernance participative et rentabilité raisonnée. Le Groupe Alptis intervient dans les domaines de l’assurance santé, de la prévoyance, de l’assurance de prêts, de l’épargne retraite et du financement, pour les particuliers, les travailleurs non salariés et les entreprises. Nous sommes forts de : 600 collaborateurs engagés 475 000 adhérents 7 900 courtiers et conseillers en gestion de patrimoine indépendants Rejoindre Alptis, c’est intégrer un groupe qui conjugue bienveillance et performance, où l’on joue collectif, dans lequel on peut grandir et vivre des projets enrichissants. Nous recrutons pour notre siège à Lyon un Data Engineer (H/F) en CDI au sein de la Direction Digitale et Transformation. Notre objectif : renforcer l’équipe DATA du groupe Alptis pour mener à bien l’ensemble des projets permettant à Alptis de devenir DATA Driven. Au sein de notre équipe, en tant que Data Engineer, vous avez la charge d’accompagner les différents projets et certaines activités de maintenance sur la nouvelle plateforme. Notre stack techno : Talend / Snowflake / Qlik / BO. Votre rôle est d’intervenir sur des missions diversifiées : Conception/réalisation des flux d’alimentations de notre Datawarehouse en provenance de nombreuses sources de données au moyen de l’outil TALEND, Participation avec nos architectes DATA à la modélisation de notre Datawarehouse Collaboration avec nos Data analyst pour exposer les données aux meilleurs formats via les outils BO et Qlik ou aux Data Scientists. Vous agissez en tant qu’expert Data et partagez vos connaissances avec d’autres data engineers, les parties prenantes de l’entreprise et avec les experts de la plateforme. Savoirs et savoirs faire : Vous êtes de formation bac+5 en école d’ingénieur ou cursus informatique, Vous avez une expérience de 3ans minimum en tant que Data Engineer, Vous avez une très bonne connaissance des ETL et de plateformes BIG DATA ainsi que des outils de data visualisation comme BO ou Qliksense, Idéalement, vous maitrisez Talend, Modéliser des données, Vous procédez à l’implémentation d’architectures de flux de données, Savoirs Etre : Autonome, rigoureux et force de proposition. Vous possédez d’excellentes capacités d’analyse et de synthèse. Rejoindre ALPTIS c’est bénéficier des avantages suivants : 10 jours de télétravail possible par mois, Mutuelle prise en charge à 100% par l’employeur, 14 RTT/an, Carte tickets-restaurant, Indemnités kilométrique vélo, Contrat retraite complémentaire. Un parking à disposition des collaborateurs. Idéalement situés dans le quartier de la manufacture des tabacs, nos locaux sont à quelques minutes à pied du métro D “Sans Souci” et du tramway “Manufacture Montluc”.","Alptis, an independent and entrepreneurial social protection group, is looking for a Data Engineer to reinforce its data team in Lyon. The ideal candidate should have a bachelor's degree in engineering, at least three years of experience in data engineering, and expertise in ETL and BIG DATA platforms. Collaboration skills, autonomy, rigor, and proposal force are also essential to the role. The company offers benefits such as telework, 100% employer-paid health insurance, 14 RTT per year, restaurant tickets, and retirement contract.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
367,56809,https://www.welcometothejungle.com/fr/companies/datadog/jobs/engineering-manager-1-data-science-core-models_paris,Engineering Manager 1 (Data Science) - Core Models,Datadog,"{Java,Go,color,Scala,Anomaly,scale,Datadog,Python}",Télétravail partiel possible,"21 Rue de Châteaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. The Team The Core Models team owns time series algorithms that power features across the Datadog application. We are responsible for the implementation and performance of the algorithms, as well as the internal tooling to evaluate and iterate on them. Our models power features such as Watchdog Alerts and Log Anomaly Detection . As the Engineering Manager of the Core Models team, you will lead and grow a team of Data Scientists and Software Engineers that own the implementation and development of our core time series models. These models are at the heart of Data Science efforts and are driving an increasing number of use cases. At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them. What you'll do: Lead and develop an amazing team of data scientists and software engineers. Develop a strategy to build common services and components encapsulating data science capabilities for other products and teams to leverage. Ensure that our data science-driven features continue to scale well as Datadog adds more customers and ingests more data per customer. Collaborate with stakeholder teams to develop joint roadmaps that provide the underlying primitives required to execute the vision of the product. Ensure the development and continuous improvement of a scalable and reliable architecture that can keep up with the growth of the product in a sustainable manner. Who you are: You have 1+ years experience managing software engineers or data scientists. You have 5+ years of experience designing and building machine learning systems. You have experience in working and communicating effectively in a fast-paced, high-growth, distributed organization. You have partnered with product management in the past to set the vision and strategy for your projects. You value simplicity and getting the right things done. Nice to Haves: You have experience working with Data Science algorithms (Statistics, AI/ML). You have experience working with microservices and/or distributed systems. You have experience working with time series data. You have experience working in Python, Java, Scala or Go. You have experience working on big data / analytical systems. Datadog values people from all walks of life. We know not everyone will meet all the above qualifications on day one. That’s okay. If you’re passionate about technology and want to grow your experience, we encourage you to apply. Benefits & Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more #DatadogLife on Instagram , LinkedIn and Datadog Learning Center . #LI-AA5 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice .","Datadog is seeking an Engineering Manager for its Core Models team responsible for implementing and developing the algorithms that power features across the Datadog application such as Watchdog Alerts and Log Anomaly Detection. The successful candidate should have experience managing software engineers or data scientists, and designing and building machine learning systems. They should also be able to work and communicate effectively in a fast-paced, high-growth, distributed organization, and partner with product management to set the vision and strategy for their projects. Experience in Data Science algorithms, microservices and/or distributed systems, time series data, and working in Python, Java, Scala or Go is a plus.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
366,37418,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-h-f_aix-en-provence,Data Engineer,Thales,"{Couchbase,MapR,Mongo,Nifi,HBase,Kafka,Spark,Marklogic,NoSQL,Hadoop,Python,Cloudera}",Télétravail partiel possible,N,"Logiciels, Cybersécurité, Aéronautique / Spatiale",CDI,2022-10-18,"Ceux qui font avancer le monde s’appuient sur Thales. Dans un monde en constante mutation, à la fois imprévisible et riche d’opportunités, ils sont aux côtés de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus sûr. Riches de la diversité de leurs expertises, de leurs talents, de leurs cultures, leurs équipes d’architectes conçoivent un éventail unique de solutions technologiques d’exception, qui rendent demain possible dès aujourd’hui. Du fond des océans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients à maîtriser des environnements toujours plus complexes pour prendre des décisions rapides, efficaces, à chaque moment décisif. Quel que soit l’enjeu. QUI SOMMES-NOUS ? Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES VOUS ? Vous aimez le travail en équipe? Vous êtes reconnu/e pour votre dynamisme et votre rigueur ? Si vous vous reconnaissez, vous avez alors toutes les qualités pour rejoindre nos équipes ! CE QUE NOUS POUVONS FAIRE ENSEMBLE Rattaché(e) à la direction d’ingénierie du logiciel d’Aix-En-Provence, votre mission sera de faire du développement en environnement Big Data tout en gardant une vue globale du besoin. Vos missions principales sont les suivantes : Concevoir, développer et déployer des pipelines de transformations de données en environnement Big Data Maintenir et paramétrer des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, …) Réaliser des prototypes sur des technologies et de la veille technologique sur le Big Data Compétences techniques autour des produits Data / Big Data: Solution Hadoop Spark, Python Bases NoSQL (Mongo, HBase, Couchbase, Marklogic…) Capacité à travailler en équipe, et dans une organisation Agile type Srcum ou SAFE Apportez votre créativité, nous saurons vous accueillir dans une équipe passionnée et dynamique pour bâtir le nouveau monde du digital ! Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is seeking a Big Data Engineer with experience designing, developing, and deploying data transformation pipelines in a Big Data environment. The candidate must have experience with Hadoop, Spark, Python, and NoSQL databases, as well as working in an Agile organization. The role involves maintaining and configuring Big Data clusters and conducting research on new Big Data technologies. The ideal candidate is a team player with strong attention to detail and a passion for innovation.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
364,49687,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-paris-or-remote-france_paris_DATAI_Lz5KM9M,Software Engineer Data Preparation - Paris or Remote France,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",Télétravail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working 'œunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is looking for a full-stack software engineer with experience in software development and an interest in data processing. The ideal candidate will be customer-oriented and interested in solving actual customer problems. They should have experience building a real product, be curious about working ""under the hood,"" and have firsthand experience in data preparation. Dataiku values autonomy, work-life balance, camaraderie, and giving back to the community. The company is an equal opportunity employer.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
361,49717,https://www.welcometothejungle.com/fr/companies/carboat-media/jobs/data-engineer_paris,Data Engineer,Groupe La Centrale,"{Jupyter,Athena,Scala,Pandas,Redshift,Numpy,Glue,AWS,S3,Lambda,Scipy,Spark,Sagemaker,Python,Elastic,Tableau}",Télétravail partiel possible,"37, Rue du Rocher, Paris, 75008","Économie collaborative, Média",CDI,2023-02-07,"Le Groupe La Centrale est le groupe spécialiste des marketplaces auto (La Centrale, Promoneuve et maVoitureCash) et du contenu éditorial (Caradisiac et Forum Auto). Avec plus de 50 millions de visites par mois, nous sommes la référence pour acheter, vendre et consulter un maximum d’informations sur un véhicule. Nous sommes aujourd’hui plus de 200 collaborateurs qui participent à l’évolution de notre entreprise en générant un chiffre d’affaires de 70 millions d’euros. Notre mission est de rendre la démarche d’achat et de vente la plus simple et sereine possible, à l’occasion d’une décision de vie engageante (le changement de voiture). Faciliter la recherche, exposer et décrypter toutes les informations utiles sur un véhicule, apporter davantage de transparence sont au cœur de notre stratégie. Le Groupe dispose d’un écosystème unique de marques complémentaires, qui nous positionnent sur toutes les démarches digitales : • L’achat de véhicules d’occasion avec La Centrale • L’achat de véhicules neufs avec Promoneuve • La vente de véhicules auprès de Professionnels partenaires avec mavoiturecash • Toute l’actualité automobile enfin (essais, guides, comparatifs et avis) avec Caradisiac Sa vision stratégique ? Avoir toujours une longueur d’avance Chez le Groupe La Centrale la Data est au centre du business pour accompagner au mieux l’entreprise et les décideurs ! Dans l’objectif de faire de Groupe La Centrale une entreprise Data-Driven nous souhaitons renforcer notre équipe Data. Membre de la feature team Data composée de 8 personnes dont 2 OPS; L’équipe DATA gère et construit la plateforme data BI, en supervisant notamment la construction d’un datalakehouse, au service de nos utilisateurs Tableau. Elle assure également le développement de l’algorithme de cotation des véhicules d’occasion (machine learning) En endossant le rôle de Data Engineer au sein de la feature team Data, tu auras pour rôle de participer aux développement de la plateforme BI et de l’application “la cote” Voici les missions qui te seront confiées : Développer et assurer la mise production de nouvelles applications de prédictions ou de nouveaux pipelines de données (ingestion, traitement, exposition) Contribuer aux choix de conception avec l’équipe, participer aux développements et déployer des infrastructures cloud AWS orienté BigData Identifier les axes d’amélioration et de consolidation de notre plateforme Travailler en collaboration avec les data scientists ou les data analysts pour leur fournir un support Participer aux évènements (Workshop Group, Tableau Conférence, AWS Summit…) Profil expérimenté, tu as un fort intérêt pour la data et tu as déjà travaillé sur des systèmes conséquents. Les bonnes pratiques et leur partage font partie de ton quotidien et tu es un référent pour ton équipe. Scala et Spark n’ont pas de secrets pour toi. Une expérience cloud serait un vrai plus. Un niveau d’anglais technique est requis et le poste implique de pouvoir collaborer ponctuellement avec les équipes de notre groupe Axel Springer. hardskills : Scala sur AWS Glue (Spark) AWS Redshift, Spectrum, AWS S3, Athena Python, Pandas, Jupyter Notebook, Scikit-learn, Numpy, Scipy AWS Sagemaker, AWS Lambda, AWS Codebuild, AWS ECR Tableau, Elastic Search Pourquoi GLC ? Intégrer Groupe La Centrale c’est développer sa passion pour les technologies innovantes au sein d’une société web dynamique et de taille humaine avec des développeurs ayant à cœur le partage de leur savoir-faire technique et agile. Nos petits plus : Mac ou PC, c’est toi qui choisis ! Participation à des conférences Petits déjeuner gratuits et Friday Pub Séminaire annuel Participation attractive CE Quartier sympa (Saint-Lazare) Déroulement des entretiens • Un call de 30 min avec Dalila, RH, et Chritophe, Deputy CTO • un Test • Une rencontre avec l’équipe et le futur Manager Christophe à Paris","The Groupe La Centrale is seeking an experienced Data Engineer to join its Data team. The candidate must have experience with Scala on AWS Glue (Spark), AWS Redshift, AWS Sagemaker, and be knowledgeable in Python, Pandas, Jupyter Notebook, Scikit-learn, Numpy, Scipy, AWS Lambda, AWS Codebuild, AWS ECR, Tableau, and Elastic Search. The role will involve developing and deploying cloud infrastructure, working with data scientists and analysts, and participating in company events. The successful candidate will share the company's focus on simplifying and transparently communicating information to customers looking to buy or sell a car. The company offers a dynamic and collaborative work culture in a web-focused and growing business.",N,N,N,2,1,0.04154662416233763
360,49670,https://www.welcometothejungle.com/fr/companies/helexia/jobs/data-manager-f-h,Data Engineer,Helexia,{},Télétravail partiel possible,La Madeleine,"Bureau d'études et d'ingénierie, Energie, Accompagnement d'entreprises",CDI,2023-02-07,"Fondée en 2010 avec la volonté d’allier économies & écologie, Helexia est expert de la transition énergétique au service des organisations. Ils offrent à leurs clients la possibilité de s’inscrire dans une démarche RSE tout en réalisant des économies et ce, quel que soit leur niveau de maturité sur le sujet. Avec +250 collaborateurs présents dans 6 pays et avec la première famille industrielle et commerciale de France comme principal actionnaire, Helexia est un acteur majeur du marché de la transition énergétique. Aujourd’hui, seul acteur du marché à ne dépendre ni d’une technologie ni d’un producteur d’énergies classiques/fossiles, Helexia travaille donc en toute indépendance. Helexia accompagne durablement et dans la totalité votre démarche de transition énergétique. Au sein de l’équipe DAO (Digital Asset & Operation), le (la) Data Engineer F/H contribue à la cohérence des systèmes d’acquisitions des données métiers (Production & suivi d’énergies/ressources) afin d’assurer la double mission de disponibilité de flux de données pour les Business Units (+ de 6 localités internationales à ce jour) & l’agrégation de KPI consistants pour le compte du Groupe. Le (la) Data Engineer F/H se verra confier les responsabilités suivantes, sans que cette liste ne soit exhaustive : ➡ Administration et Maitrise d’Ouvrage de l’Energy Monitoring System groupe & solutions monitoring locales ; ➡ Intégration au projet stratégique “Group Data Architecture 2.0” ; ➡ Développement d’automatisations métier (API / Power Automate / Script…) ; ➡ Assistance au déploiement d’outils métiers groupe. Le rôle du (de la) Data Engineer F/H est de : ➡ Développer des solutions d’acquisition de données répondant aux impératifs divers des assets d’Helexia (centrales photovoltaïques, groupes froids, bornes de mobilité…) ; ➡ Manager l’intégralité de l’outil EMS groupe et de son infrastructure ; ➡ Assurer le support de niveau 2 : Gérer l’ensemble des demandes de support interne sur les outils mis en place ; ➡ Stratégie : Aligner les outils avec la stratégie groupe DTO. Helexia est certifiée ISO 9001. Dans ce cadre chaque collaborateur s’engage à respecter les procédures en place et à contribuer à l’amélioration continue du système. Pour mener à bien ces missions, vous êtes diplômé Bac +4 ou +5 et justifiez d’une expérience de 2 ans minimum. Vous êtes capable de maîtriser un EMS ainsi que des protocoles d’acquisition de données. Vous avez un bon niveau d’anglais qui vous permet de collaborer de façon efficace à l’écrit comme à l’oral. Techniquement curieux et pragmatique, orienté résolution de problèmes, vous exercez votre métier avec enthousiasme. Polyvalent(e) et doté(e) d’un excellent relationnel, vous aimez travaillez en équipe et savez vous adapter à des situations variées ainsi qu’à vos différents interlocuteurs. Enfin, vous êtes convaincu.e que les énergies renouvelables ont un rôle majeur à jouer dans l’avenir et souhaitez être acteur de ce changement, vous avez envie de vous investir dans une structure en plein développement, porteuse d’un projet ambitieux et passionnant. Helexia reconnaît et recrute tous les talents. Tous nos postes sont ouverts aux personnes en situation de handicap.","The Data Engineer at Helexia will ensure consistency in business data acquisition systems to provide consistent KPIs for the company. Responsibilities include administration of the Energy Monitoring System (EMS) group, integration into the Group Data Architecture 2.0 project, developing automation scripts, ensuring availability of data flows, and aligning tools with the DTO group's strategy. The ideal candidate is technically curious, pragmatic, has an excellent relationship building, and has a good level of English. They must have a Bachelor's or Master's degree and at least two years of relevant experience in handling EMS and data acquisition protocols.",Bac +4,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
353,34884,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-h-f_paris,Data Engineer -,Kisio Digital > Hove,"{OpenStreetMap,python,Jenkins,Go,Git,GitHub,Kubernetes,AWS,Docker,github,Linux,Spark,kafka,RabbitMQ,kinesis,Github,Python}",Télétravail partiel possible,Paris,"Application mobile, Mobilité, SaaS / Cloud Services",CDI,2022-08-08,"Avec plus de 15 milliards de requêtes par an, Kisio Digital business unit de Kisio et filiale numérique du Groupe Keolis est un acteur majeur de la mobilité. Les trois grands domaines d’intervention de Kisio Digital portent sur les systèmes d’information-voyageur (recherche d’itinéraire multimodal, porte-à-porte et temps-réel) ; l’achat de titres de transport dématérialisés et le mobile-ticketing. Sa vision de la mobilité : permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’emprise possible sur la planète. C’est ce qu’on appelle la « responsive locomotion » ! Kisio Digital travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire en tenant compte du contexte et des préférences du voyageur. Pour répondre aux enjeux d’une mobilité plus intelligente, plus ouverte et plus écologique, Kisio Digital réalise des applications mobiles, des sites web et des SDK basés sur notre API www.navitia.io. Cette plateforme propose des services numériques de mobilité dans le monde entier. Elle rassemble une communauté de 20 000 développeurs et participe à leur stratégie d’innovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, vélomanes, bussophiles, et autres passionnés de montgolfière ou de transports pas toujours très communs. Curieux et ouverts d’esprit, ils sont passionnés par la mobilité au sens large, les nouvelles technologies et les communs numériques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communauté Open transport. Si vous souhaitez vous épanouir dans un environnement multiculturel, sachez que Kisio Digital va désormais lancer des services à l’étranger. Rejoignez-les ! En tant que Data engineer Navitia, vous êtes intégré à une équipe pluridisciplinaire mêlant développeurs, Product Owner et Architectes dont l’objectif est de mettre en place un système de collecte, agrégation, mise en qualité de données pour les services d’information voyageur (itinéraires, horaires à l’arrêt, perturbations, etc.). Les données manipulées sont très variées (OpenStreetMap, GTFS de Paris, de New-York ou d’Accra, vélo en libre services, etc.) et nécessitent des contrôles et des traitements très spécifiques ; et de mélanger ces données avec des centaines de flux temps réel par seconde pour finalement les intégrer dans nos systèmes et ainsi répondre aux 15 milliards de requêtes annuelles. Et surtout, ne jamais avoir pas peur ™. Avec cette équipe, vous assurerez les missions suivantes : Participer à la création et à l’évolution du moteur d’ingestion et de mise en qualité des donné Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Concevoir techniquement la solution en collaboration avec les architectes, SRE, métier… Superviser et monitorer le déploiement et la robustesse des composants mis en production Participer activement à la qualité de l’ingénierie logicielle (Relecture de code, test, intégration continue, déploiement, etc.) Chiffrage des demandes d’évolution Le Rust vous passionne, python ne vous fait pas peur, et le Go vous inspire Vous êtes familier avec les problématiques liées au contexte multi-threads Vous avez déjà travaillé avec un pubSub (kafka/kinesis) et un système de Queue tel que RabbitMQ Vous êtes curieux des nouvelles technos et aimez partager ce que vous découvrez, tout en sachant que tout réécrire n’est pas toujours une bonne idée Vous êtes motivé à partager votre code source sur GitHub et à participer à l’aventure Open Source Navitia Vous avez une certaine culture de la mesure, de la métrologie du code et de son fonctionnement Anglais professionnel Vous êtes pragmatique : la bonne techno pour répondre au besoin, ni plus, ni moins. Vous êtes responsable : Vous vous engagez sur un chiffrage, vous le respectez Vous justifiez d’une expérience d’au moins. 2 ans sur un poste similaire Vous maîtrisez : Linux Rust, Go, Python Apache Spark, PubSub & Queue… Cloud Public (AWS…) Git, SonarQube, Jenkins Docker, Kubernetes Partagez avec nous votre Github, nous vous donnons le nôtre : https://github.com/CanalTP/navitia pour l’information voyageur, et https://github.com/CanalTP/transit_model / pour la manipulation du modèle de données !","Kisio Digital, a major player in mobility, is seeking a Data Engineer Navitia to develop a system for collecting, aggregating and ensuring the data quality of travel information services such as itineraries, stop schedules and disruptions, integrating that into its systems and responding to the 15 billion annual queries. Applicants should be familiar with Rust, Python and Go, have worked with pubSub (kafka/kinesis) and Queue systems such as RabbitMQ, be curious about new tech and have a culture of measurement, and must have at least two years of experience on a similar post.",N,N,N,2,1,0.04154662416233763
470,57106,https://www.welcometothejungle.com/fr/companies/mytraffic/jobs/engineering-manager-data-team_paris,Engineering Manager - Data Team,MYTRAFFIC,"{scale,via}",Télétravail partiel possible,"37, Avenue Trudaine, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, SaaS / Cloud Services",CDI,2023-03-26,"Mytraffic, created in 2016, aims to boost the performance of commercial real estate players (Retail, Real Estate, Local Authorities, Consultancy) thanks to an innovative Saas solution raising the real world to the level of the digital world in terms of data analytics. We have already convinced more than 420 clients (Nhood, Nuveen, H&M, Dyson, Amorino, Carrefour, Klepierre, American Express, BNP) to work with us across Europe to help them expand their business, analyze and predict the performance of their investments, understand their customers’ habits and benchmark themselves against their competitors. Mytraffic is a hyper growing scale up (+110%/year) supported by 30 Millions € Series B fundraising round with Axa Venture Partners, Alven and Kernel Investissements in November 2022 to finance its European expansion. Their ambition is to quickly become the European leader in data solutions for commercial real estate. Their values are: Believe in DATA Only MERIT prevails Be AMBITIOUS Work together with EMPATHY See things ANOTHER WAY Get it DONE You’ll be focused on people and delivery execution. Reporting to the CTO. The Engineering Manager is in charge of the Data Team. Within this feature team: - is responsible for keeping people happy and motivated to work at Mytraffic (KR = employee retention rate, internal satisfaction surveys).
- is responsible for ensuring that pace of delivery stays high (KR = delivery results of the team) After building solid statistics on pedestrian and vehicle data geolocation, we continue to improve the performance of our algorithms. We plan to explore other data sources (social network data, banking transactions…) to integrate into our platform. The goal is to use these new datasets with existing ones to provide metrics to our customers to drive even better decisions. The Engineering Manager must have a technical background to understand the team’s blockers, to be able to evaluate individual contributions and to recruit effectively for the team (technical skills will be evaluated during the recruitment process). The Engineering Manager is not responsible for taking technical decisions within the team (but may have good insights), this is the scope of the tech lead. The Engineering Manager should take only 0-20% of its time in the code, to be familiar with the stack and understand the blockers, without slowing down the team as a whole. Tech Team Philosophy → test, test, test. At Mytraffic, every line of code in production is a tested one, whether in the back or in the front end. → constantly improve and help others. Whether on a daily basis via code reviews, or occasionally via workshops. Our goal is to progress together towards exemplary technical quality. → questioning our processes and technical choices, proposing solutions and bringing up existing problems. Critical thinking is a guarantee of excellence. → evolve according to your inclinations, we offer to help you grow by joining other teams during your career, or to specialise in the technology of your choice → Participate in design thinking with the Product Manager, Designer and other stakeholders This job was meant for you if… You have at least 7 years of experience in technologies similar to ours with operational constraints. Background in mentoring / leading a development team You have a good attitude towards change and uncertainty about the future, which is common in young, fast-growing start-ups. You are able to provide constructive and reasoned criticism of architectural and design decisions. You have the ability to give a relevant opinion on important business decisions such as hiring, implementing new processes, changing methods when necessary. Your written and verbal communication is good and concise so that you can easily convey your thoughts, opinions and feelings to other team members, teammates, clients or founders. You are open to feedback in order to continue to improve. What we offer Competitive salary: our demand for excellence pushes us to recruit the best profiles Possibility to dedicate 4 days a year to an association during your working time because Mytraffic’s values also lie in having a positive impact around us Frequent team building activities such as renting a house in the countryside to spend a week together because team spirit is at the heart of our values at Mytraffic Development opportunities for all our employees through workshops such as “Feedback culture”, “Non Violent Communication”, “Women in leadership” (at Mytraffic, half of our managers are women) And as a bonus, we have great offices in the centre of Paris (75002) Interview process (2 weeks long) Call with our Talent Acquisition Manager First meeting with our CTO Meeting with Tech Leads Onsite Meeting with our CTO + the team Interview with our CEO","Mytraffic, a hyper-growing scale-up, is seeking an Engineering Manager to lead its data team responsible for data analytics for commercial real estate. The individual must have at least seven years of experience in similar technologies with a background in mentoring/leading a development team. The Engineering Manager is expected to help people and deliver results while keeping pace high at Mytraffic. The company values critical thinking, questioning processes and technical choices, and evolving the team members. The firm is currently preparing for European expansion, aiming to become the leader in data solutions for commercial real estate.",Bac +5 / Master,Entre 50 et 250 salariés,> 7 ans,2,1,0.04154662416233763
225,56393,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_lyon,Data Engineer,ASI,"{Oracle,SAS,Talend,SAP,QlikView,Qlik}",Télétravail partiel possible,Lyon,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 VOS MISSIONS Analyser et comprendre les besoins client Participer aux différentes phases : - Conception d’architecture décisionnelle et technique - Rédaction des spécifications fonctionnelles et techniques - Traitement de la donnée, concevoir et spécifier les jobs d’alimentation - Construction de cubes de données - Développement des rapports - Tests et recette - Mise en production PARLONS DE VOUS Vous êtes prêt à monter en compétences sur de nouvelles solutions, l’envie d’élargir votre spectre technologique. Vous êtes curieux, rigoureux, analytique, dynamique et doté d'une grande capacité d'adaptation. Vous avez de l'appétence et/ou connaissance des nouveaux concepts de la data (Data Mining, Data Visualisation, Data Lake, …) De formation supérieure avec une expérience réussie sur un poste similaire avec les compétences suivantes : - Travailler sur des projets de Data Intelligence, de façon autonome ou au sein d’une équipe - Maîtrise d’une ou plusieurs solutions du marché - Alimentation et stockage de données : SSIS, Talend, Oracle Data Integrator, SAP Data Services, … - Analyse : SSAS, SAS, … - Restitution : SSRS, SAP BO, QlikView, Qlik Sense, Power BI Ensemble, nous saurons développer vos compétences et enrichir votre expérience ! Alors rejoignez-notre Team ASI !","ASI, a digital expertise firm, is seeking a Data Intelligence Consultant with experience in data mining, data visualization, and data lakes. The candidate must be curious, rigorous, analytical, dynamic, and adaptable. The role involves analyzing client needs and participating in various project phases, including developing reports, constructing data cubes, and testing. The company values a responsible digital world for humans and encourages employees to develop new skills and expand their technological horizons.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
78,56726,https://www.welcometothejungle.com/fr/companies/psl-1/jobs/data-engineer_paris,Aqemia - Data Engineer,Deeptech @ PSL,"{regard,python,color,Kubernetes,AWS,K8s,instrumental,SQL}",Télétravail partiel possible,"33, Rue Censier, Paris, 75005","Formation, Incubateur / Accélérateur",CDI,2023-03-26,"This job offer is for Aqemia, a start-up issued from PSL University Ecosystem, with the following description: At Aqemia you will work in a multi-disciplinary team of passionate drug hunters, AI engineers and developers who are committed to our mission of finding many drugs, at high pace, to cure diseases. As part of our growing team, you will enjoy a fast-paced, challenging, science-driven and creative environment, working at the very forefront of AI & Deep physics-powered drug discovery. This is a tremendous opportunity to bring your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team. We are looking for highly skilled and collaborative individuals who are naturally curious, have a passion for learning and solving complex problems with a “can-do” mindset. If this sounds exciting to you, come and join us! The difference you’ll make As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia’s engineering teams. You will also support engineering Teams to build their Data pipeline and assets. This way, you will be instrumental in all engineering teams’ success. Our Workplace Environment Fast-paced, intellectually and scientifically demanding, results-driven. Our Founders boast: 10+ years experience in research at Ecole Normale Supérieure in Paris, not to mention a stint in Oxford and Cambridge. 10+ years experience in strategy consulting at BCG. Aqemia has a rapidly growing team of +40 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale Supérieure, Ecole Polytechnique, BCG) Our premises are conveniently located in center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work. Working language: English Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law. What you’ll do Contribute in defining the relevant Data Architecture and stack for Aqemia. Contribute to build the relevant Data infrastructure for Aqemia in AWS. In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets. Support engineering team in designing their Data pipelines and assets. Bring the Data Engineering expertise in engineering projects from design to delivery. Your profile 2+ years experience as a Data or Software engineer in an engineering team of 4+ engineers. Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus). Good knowledge of Data Engineering building blocks (storage, orchestrator). Fluent in object-oriented language development (ideally python). Experience in delivering technical projects from start to finish. Preferred skills Proficient in SQL. Experience in backend engineering. Experience in infrastructure-as-code techniques (ideally Terraform). Knowledge in ML Ops and DevOps. Knowledge of Kubernetes, K8s administration. You know how to interact with technical stakeholders. Who you are You are eager to play an active role in contributing to Aqemia’s strategy to develop drugs for patients. You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds. You are keen to solve tough problems on issues that truly matter. You are inquisitive, and proactive with a can-do attitude. You are excited to join a small team and make your mark on drug discovery. You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track.","Aqemia, a start-up focused on drug discovery, is hiring a Data Engineer to join the team in Paris. The successful candidate will design and build a modern, scalable Data Platform and support engineering teams to build their data pipeline and assets. Applicants should have at least two years' experience as a Data or Software engineer, knowledge of cloud infrastructure and products, and experience delivering technical projects from start to finish. Proficiency in SQL and experience in backend engineering are preferred. Aqemia is an equal employment opportunity employer.",Bac +5 / Master,N,> 2 ans,2,1,0.04154662416233763
103,72838,https://www.welcometothejungle.com/fr/companies/elmy/jobs/junior-data-engineer_lyon_ELMY_0RjkJAK,Data Engineer,elmy,"{GCS,Github,Node,Python,Jenkins,Datadog,PostgreSQL,Beam,GCP,OpenTelemetry,Kubernetes,Docker,Prometheus,Airflow,Grafana,Julia,TypeScript}",Télétravail partiel possible,"23, Boulevard Jules Favre, Lyon, 69006","Environnement / Développement durable, Energie",CDI,2023-04-22,"elmy est le 1er énergéticien 100% français et 100 % vert 🌱. elmy, c’est une équipe d’une centaine de personnes engagées pour une transition énergétique, écologique et solidaire. Ils maîtrisent l’énergie de A à Z en interne et ça, ça fait toute la différence ! En étant présent sur l’ensemble de la chaîne de valeur de l’électricité, de la production à la consommation, ils permettent à chacun d’avoir l’impact le plus concret sur la transition énergétique. Une nécessité compte tenu des enjeux climatiques ! Leurs ambitions ? 1/ Participer à la transformation du modèle énergétique 💡 2/ Reconnecter les consommateurs à l’énergie ⚡️ 3/ Tout faire pour encourager un maximum de monde à passer au vert 🌱 4/ Construire l’entreprise contributive de demain, car l’entreprise a un rôle sociétal à tenir 🤝 Toi aussi, tu as l’énergie d’agir pour la transition énergétique ? Rejoins-les ! Data Engineer En tant que Data Engineer, tu intègres notre équipe métier « Trading et analyse marché » afin de contribuer à construire une logique data au sein de l’équipe. En collaboration avec l’équipe Tech, tu développeras des outils de collecte et de traitement de la donnée en travaillant étroitement avec des analystes et des traders avec pour ambition de mieux comprendre et modéliser les marchés de l’électricité de gros au cœur de nos problématiques actuelles. Nous portons beaucoup d’attention sur la qualité du code, donc les tests et relectures de code sont des étapes clés du cycle de vie du produit. Nous privilégions le développement continu ainsi que le contact permanent avec les autres métiers de l’équipe. Tes challenges Tu intègres l’équipe Trading et analyse marché et participes pleinement à la construction de notre approche data : Tu es responsable du développement de nos pipelines data ; Tu interviens, en lien avec l’équipe Tech, sur les sujets de découvrabilité, de qualité et de visibilité de la donnée; Tu prends une part active à la refonte de certains processus de nos pipelines data; Tu participes, avec l’équipe Tech, au développement de la culture data de l’entreprise Tu participes à la définition de l’architecture de nos applications ; Tu as voix au chapitre sur la priorisation des chantiers de l’équipe ; Tu es garant.e des bonnes pratiques de développement, notamment au niveau de la qualité et de la sécurité. Notre stack technique Data : PostgreSQL , Stockage objet (GCS) , Apache Beam, Cloud Pub/Sub … Languages : Node/TypeScript, Python , Julia… Orchestration : Kubernetes , Airflow … Devops : Docker, GCP … CI/CD : Github, Jenkins, SonarQube, … Monitoring : Datadog, Prometheus , Grafana, OpenTelemetry, … Ce qui t’attend si tu nous rejoins 💡 Ce poste est ouvert dans nos locaux lyonnais avec du télétravail partiel possible. Nous proposons sur ce poste une rémunération annuelle à partir de 35.000 euros annuels en fonction de ton expérience + un variable de 10% indexé sur objectifs. 🚀 semaine de 4 jours 🌱un travail qui a du sens : avoir un impact positif sur l’environnement en œuvrant pour la transition énergétique 🤝 de la flexibilité sur les horaires et le télétravail 🧗‍♀️ un pack sport de 200 euros par an 🎵 un abonnement Deezer 👨‍👩‍👦 une mutuelle Alan prise en charge à 100% pour toi et ta famille 🐝 une organisation horizontale inspirée de l’holacratie favorisant l’autonomie et la créativité ❤️ un quotidien avec une équipe conviviale, bienveillante et optimiste 💆‍♀️ des locaux où il fait bon vivre : cours de yoga, paniers de fruits, coin piano et salle de sieste Tu es notre candidat.e idéal.e si tu… 🤩 👉 Impliqué.e et concerné.e par les problématiques environnementales, tu souhaites mettre ta passion pour le domaine technique au service de tes valeurs. 👉 Enthousiaste et social.e tu possèdes un réel esprit d’équipe et une volonté d’intégrer un groupe convivial et multiculturel. Plus techniquement 👉 Tu justifies d’une première expérience ou d’un stage sur un poste similaire. Rigoureux.se, tu portes un intérêt majeur à la qualité de ton travail / code / data. Passionné.e, tu es plus attiré.e par la technologie que par un langage spécifique. 👉 Autonome et créatif.ve, tu montres une appétence pour le travail « from scratch » et es enthousiasmé.e par l’idée de rejoindre des projets techniques dès leurs débuts. 👉 Curieux.se tu es capable d’intervenir sur plusieurs technologies. 👉 Orienté.e data, tu as à cœur de comprendre les enjeux métier derrière les données. Tu interagiras au quotidien avec les autres membres de l’équipe (analystes, traders). Ladies Les études montrent que les femmes ont moins tendance à postuler à une offre d’emploi lorsqu’elles n’ont pas toutes les qualifications requises. Ladies, ne vous mettez pas de barrière et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d’échanger avec vous ! 👉 Premier call de présentation 👉 Entretien avec Lilia, Talent Acquisition Manager. Le but est, d’un côté, d’en savoir plus sur toi, et de l’autre, que nous puissions t’en dire plus sur ce que l’on fait ici. 👉Entretien avec Erwan, Analyste marché, pour rentrer dans le vif du sujet et parler métier 👉 Test technique suivi d’un debrief avec l’équipe 👉 Bienvenue :)",,Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,2,1,0.04154662416233763
102,72818,https://www.welcometothejungle.com/fr/companies/publicis-media/jobs/analytics-engineer-h-f-cdi_paris,Analytics Engineer  - CDI,Publicis Media,"{GCS,Python,Spark,NoSQL,AWS,SQL,bigquery,GCP}",Télétravail partiel possible,"30-34 Rue du Chemin Vert, Paris, 75011","Design, Marketing / Communication, Publicité",CDI,2023-04-22,"Publicis Media c’est une équipe de près de 1000 talents répartis sur 5 sites en France : Paris, Lille, Lyon, Rennes et Montpellier. Passionnés ‍🔥 par les métiers du conseil media et du trading, férus d’innovation 🤟 et engagés à délivrer les meilleures performances business, Publicis Media accompagne ses clients dans l’univers complexe des médias d’aujourd’hui et décline ses expertises sur tous les leviers et points de contact. Qu’ils construisent la stratégie ou déploient les campagnes de leurs clients, les talents testent, développent et challengent les dernières technologies et participent à faire bouger les lignes du secteur des agences média pour que nos métiers évoluent constamment. Publicis Media, c’est avant tout une aventure humaine, un collectif soudé ✊, des projets avant-gardistes pour développer toujours plus la montée en compétences de ses talents et une ambiance de travail qui ne connait pas l’ennui. C’est à la fois des agences au service de ses clients : Zenith, Starcom, Blue 449, Performics, Spark Foundry, Publicis Sport, Publicis Media Connect et des centres d’expertises au service de l’innovation : Social media, Data, Content, Search, Performance marketing et digitale, Tech, Commerce. Intégrer Publicis Media, c’est intégrer le leader des media en France et un groupe mondial présent dans 115 pays. C’est aussi décider d’apprendre tous les jours et de créer des liens qui comptent. Vous êtes rattaché.e au Lead Data & Analytics de Publicis Media et serez en charge de la structuration et de la livraison des projets Analytics (ingestion de sources de données, traitement, transformation, modélisation et restitution), entre autre associés aux équipes Data Science & Data Engineering, mais également structurants pour poursuivre les travaux de transformation de l’entreprise et de ses usages. L’Analytics Engineer occupe un rôle central dans notre stratégie Data, en sa capacité à pouvoir contribuer à convertir la donnée en connaissance, tout en s’appuyant sur la technologie, à poursuivre la conception de la prochaine génération d’algorithmes. Ce que vous ferez La construction de pipelines Data depuis la collecte jusqu’à la restitution Le rapatriement et l’ingestion de données de multiples sources (Cloud – GCS, AWS… – SFTP, API…) L’utilisation des Best Practices pour la création des data models L’automatisation de l’analyse au travers des mécanismes de monitoring et d’alerting, en post-déploiement La gestion du suivi et livraison des projets associés – depuis la conception, au développement, testing, et opérations associées Les défis associés Richesse des environnements : de multiples sources, de multiples environnements dans un écosystème en perpétuel mouvement impliquent une grande capacité à pouvoir les aborder pour rassembler les données attenantes Media, Marketing, CRM… : des données de nature différentes (First, Third…), en grande quantité, à forte granularité, réunies pour en déduire les meilleurs insights Scalabilité : la quantité de donnée de chaque Client peut être conséquente, mais le travail de transformation et processing peut l’être davantage Respect de la vie privée, gestion des données personnelles : nous pouvons être amenés à traiter de la donnée Media mise à disposition sur des “Clean Rooms” (Google, Facebook, Amazon…) Gestion des coûts : méthode & rigueur sont essentielles pour optimiser les dépenses de stockage et computing de la donnée (en interne ou pour le compte de nos clients) Viva La Différence ! Cette philosophie de Publicis Groupe témoigne depuis toujours de notre engagement pour la diversité et de la conviction que nos talents sont notre plus grande richesse et notre meilleur atout . Nous valorisons ainsi toutes les singularités, sans distinction d’âge, de sexe, de couleur de peau, d’origine sociale, de religion, ou d’orientation sexuelle… seules la compétence et l’énergie comptent ! Nous encourageons toutes les candidatures qualifiées et seront ravis d’accompagner tout au long du processus de recrutement, de manière personnalisée un.e candidat.e en situation de handicap qui en ferait la demande. Publicis France est engagée pour l’égalité des chances et l’équité d’opportunités pour tous et toutes. Qualifications Formation d’ingénieur.e en informatique (ou assimilé.e), méthodes Agile ; vous disposez de 2 ans minimum d’expérience dans l’administration, configuration, monitoring, débogage et mise en oeuvre d’une solution Cloud (GCP idéalement), ainsi que dans les mécanismes d’intégration (fichiers, messages, data…).
La certification Google Cloud Engineer est recommandée, ainsi que la pratique de l’anglais. Expertises & compétences Langages de développement : Python, SQL, Basch Compétences : manipulation de données en SQL / NoSQL Expertise : Google Cloud Platform (Cloud Functions, Cloud Run, Cloud Pub/Sub, Cloud Workflow, Dataplex, CI/CD…), Amazon Web Services… Connaissance des mécanismes de constitution d’ETL, technologies d’orchestration (Workflow, cloud scheduler, …). Des connaissances en Terraform et en bigquery est un plus Phases de testing ; documentation du code",,Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
101,34055,https://www.welcometothejungle.com/fr/companies/m13h/jobs/dataviz-engineer-france-europe-f-h_bordeaux,DataViz Engineer - Bordeaux -,M13h,"{OneTrust,DataStudio,Looker,PowerBI,Fivetran,dbt,Contentsquare,via,Adverity,SQL,Qlik,Tableau}",Télétravail partiel possible,Bordeaux,"Digital Marketing / Data Marketing, Stratégie, Big Data",CDI,2022-08-08,"A propos de M13h 👋 M13h est une équipe de consultant·e·s passionné·e·s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Stratégique et expertises Data, Marketing & Technologies pour accélérer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous maîtrisons toute la chaîne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, … à accroître leurs performances, au travers de missions variées : Stratégie Data : définir sa stratégie, ses cas d’usage data et le socle technologique pour la déployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donnée pour créer de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et améliorer les taux de conversion Privacy : s’adapter aux évolutions technologiques et règlementaires tout en développant ses performances marketing Modern Data Platforms : construire des plateformes de données sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des données pour prendre des décisions éclairées (dashboards, data analyse, data science, modélisation avancée, …) M13h est membre du Groupe Labelium et met ses compétences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure à taille humaine où il fait bon travailler ! En plein mouvement de régionalisation et d’internationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l’Europe (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N’hésitez pas à en discuter en entretien. Description du poste 📢 En tant que DataViz Engineer, tu interviens sur les problématiques relatives à la mise en place de dashboards et autres outils de pilotage d’activité pour les clients de M13h. Pour cela, tu interviens à différents stades des projets : Compréhension des besoins métiers et définition des indicateurs pour les représenter de manière efficace Création des indicateurs de suivi Mise en place des dashboards Maintenance et évolution des dashboards Veille sur les évolutions du marché Définition des bonnes pratiques de développement de visualisation efficientes Quelques exemples de missions à titre d’illustration : Création de dashboard centralisant la donnée média issue des principales plateformes d’activation Construction de rapport de suivi de performances marketing Mise en place d’un outil de pilotage de l’attribution média Création de dashboard omnicanaux avec notamment les données issus de Google My Business et Facebook pages Mise en place de dashboards à destination des franchisés Création de templates de dashboards dans le cadre d’une industrialisation du pilotage media Rigoureux·se, tu as à cœur de comprendre les besoins de tes interlocuteurs puis les traduire et les matérialiser via des dashboards pertinents . En tant que Junior , tu seras encadré·e par des profils plus seniors te permettant de progresser rapidement dans notre environnement et sur des outils modernes. Profil recherché 👨👩 Issu·e d’une grande école de commerce, d’ingénieurs ou équivalent , tu souhaites t’orienter vers les métiers de la business intelligence. Tu connais certains outils de marché (Tableau, PowerBI, DataStudio, Qlik, Looker, …) et tu as des bases dans la gestion et la structuration de données notamment en SQL, ainsi que sur la meilleure manière de restituer des données de façon visuelle. Tu souhaites travailler sur des environnements cloud et découvrir les outils ELTs. Au-delà des compétences techniques, tu fais preuve de rigueur, de créativité et d’autonomie. Tu as également une forte capacité de formalisation et fait preuve de pédagogie. Pourquoi nous rejoindre ❓ M13h, c’est avant tout une équipe qui aime les challenges et porte des valeurs de bienveillance et de progrès collectif . Tu as déjà lu ça ailleurs ? Contactes nos consultant·e·s sur LinkedIn pour vérifier directement :) Démarrer chez M13h, c’est aussi une belle opportunité de développer tes compétences conseil et ton expertise rapidement sur des missions variées, au sein d’une structure à taille humaine tout en profitant des avantages d’un groupe international. Tu es accompagné par un parrain ou une marraine dès ton arrivée en plus de ton manager, profites de formations, accèdes à de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, … Et puis M13h, c’est aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d’arrivée pour s’équiper pour le télétravail Une politique souple de télétravail Un abonnement gratuit à des salles de sport 2 séminaires par an et de nombreux moments de cohésion d’équipe Des locaux au coeur de grandes villes françaises (Paris, Bordeaux, Lyon) et européennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge à 100% et bien d’autres… Comment postuler 🙋 Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontanée à recrutement@m13h.com","M13h, a consulting firm specializing in business and marketing performance, is seeking a DataViz Engineer with experience in dashboard implementation and maintenance. The ideal candidate should have a degree in engineering, commerce, or equivalent, and knowledge of market tools like Tableau, PowerBI, DataStudio, Qlik, and Looker. Besides technical expertise, the candidate must have attention to detail, creativity, autonomy, and excellent communication skills. M13h offers opportunities to work on diverse assignments and provide a learning platform through mentorship, training, flexible policies, and recreational events.",Bac +5 / Master,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
100,34072,https://www.welcometothejungle.com/fr/companies/bouygues-telecom/jobs/data-engineer-sre-h-f_meudon,Data Engineer / SRE -,Bouygues Telecom,"{MongoDB,ElasticSearch,Tensorflow,Anaconda,Kubernetes,HDFS,S3,Kafka,Hive,Spark,Superset,Docker,Java,Python,Tableau}",Télétravail partiel possible,Meudon,"IT / Digital, Objets connectés, Electronique / Télécommunications",CDI,2022-08-08,"Depuis notre création en 1996, toutes nos collaboratrices et tous nos collaborateurs ont la même ambition: être l’opérateur qui fait grandir les relations humaines. Nous innovons au service de technologies qui font grandir les amitiés, les liens de famille, les histoires d’amour, les engagements solidaires, les projets collectifs. Nous avons créé le premier forfait illimité, nous avons lancé l’internet mobile. Chaque jour, nous redoublons d’efforts pour fournir un réseau encore plus puissant et étendu pour connecter tous les territoires. Nous sommes 9 500 artisans des liens humains, passionnés, au service de 25 millions de personnes partout en France. Nous sommes 9 500 engagés pour l’inclusion, tous différents : par notre parcours, notre métier, nos idées. Alors si pour vous faire grandir les relations humaines est un métier, on est fait pour être ensemble. Bouygues Telecom recherche des futurs talents dans la tech en CDI ! Si le développement Java, la CI/CD, la gestion de gros volumes de Data, les problématiques de scalabilité et de distribution de charge ou encore Kubernetes vous parlent, rencontrons-nous ! Des postes de Data Engineer, Lead Technique et SRE sont à pourvoir. L’un d’eux est peut-être pour vous ! La Direction des Systèmes d’information Réseau (IT RES) s’inscrit au cœur du business de Bouygues Telecom. Elle fournit l’ensemble des SI qui pilotent les processus clés de la direction SI. Au sein de cette direction se trouve la structure Architecture Développement Opérations. Elle a pour vocation d’assurer la gestion des données du Réseau de Bouygues Telecom entrant dans les processus d’amélioration de la qualité de l’expérience utilisateur. Cette plateforme Big Data fournit également un environnement de machine learning et d’analytique aux ingénieurs réseaux de Bouygues Telecom. Vous serez immergé dans une équipe aux multiples savoir-faire (architecture technique, développement, data science, product manager, SRE …). C’est donc au sein de cette structure, et dans nos équipes composées de collaborateurs internes et de prestataires, que peut s’inscrire votre avenir ! Vous travaillerez sur la chaîne complète de nos projets, sur du Build comme du Run. Profil recherché : Notre environnement technique riche et varié : Big Data - Supervision et analyses de performances du réseau, métrologie applicative : Kubernetes, HDFS, S3, Hive, Kafka, Spark, PrestoDB, MongoDB, Tableau, Superset, ElasticSearch, Docker, … Détection d’anomalies liées à la supervision du réseau, corrélation d’alarme, … : Tensorflow, DNN, VAE, Anaconda, Docker, … * Notre socle de développement se fait principalement sous Java et Python. Localisation et Rémunération : Vous serez basé au Technopôle, situé à deux pas de Vélizy 2. Avantages & rémunération : Selon expérience, rémunération fixe annuelle brute sur 13,1 mois + participation/intéressement + avantages groupe variés + télétravail régulier.","Bouygues Telecom, an operator of telecommunication services in France, is seeking talented individuals for various tech roles such as Data Engineer, Lead Technique, and SRE. The company is looking for individuals with skills in Java development, CI/CD, large data management, scalability and load distribution, and Kubernetes. The roles are based in the Architecture Development Operations structure of the company and require knowledge of technologies such as HDFS, S3, Hive, Kafka, Spark, PrestoDB, MongoDB, Tableau, Superset, ElasticSearch, and more. The position offers a competitive salary, benefits package, and regular telecommuting opportunities.",Bac +5 / Master,> 2000 salariés,> 4 ans,2,1,0.04154662416233763
98,73701,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/manager-data-engineering-h-f_paris_EF_4Rr7q6,Manager Data Engineering,EPSILON France,"{Python,EPSILON,Microsoft,Cloudera,Azure,marquez,Kafka,Hadoop,Spark,Kubernetes,Docker,Gitlab,MongoDB}",Télétravail partiel possible,"17 Rue Bréguet, Paris, 75011","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-04-22,"EPSILON France est l’entité Datamarketing de Publicis Groupe avec 700 experts data, marketing et technologiques et plus de 40 métiers représentés. Avec pour claim « Every Interaction Counts », la mission d’EPSILON est de conjuguer les pouvoirs de la data, du marketing et de la technologie pour rendre les interactions entre les marques et leurs clients toujours plus justes et pertinentes. EPSILON intervient sur l’ensemble des étapes-clé d’un projet de transformation data-driven, de la définition de la stratégie à l’exécution opérationnelle. EPSILON compte plus de 300 clients actifs et pilote quotidiennement plus de 100 plateformes datamarketing. Le Pôle Data & Analytics Platform est composé de 140 experts spécialisés sur la transformation Data des entreprises : Cadrage fonctionnel et technique, Définition de use-cases, Conception d’architecture cloud ou hybride, Mise en œuvre et run de plateformes data, Implémentation de solutions Dataviz et Analytics, Accompagnement du changement, Cadrage et déploiement de Data Gouvernance, Mise en œuvre de Data Office. Au sein du Pôle Data & Analytics Platform, le centre de compétences des technologies Big Data et Cloud intervient sur l’ensemble de la chaîne Data : Architecture, Développement de plateforme Data (ingestion, traitement, stockage, exposition des données), industrialisation et opérationnalisation des solutions développées (essentiellement en mode cloud). Rattaché à ce centre de compétences en tant que Manager Data Engineering, vous avez 4 grandes missions : Management : - Vous managez et animez votre équipe (8 à 10 personnes) dans un esprit de formation, d’innovation et de satisfaction client. Projet : Garant de la qualité du delivery de vos projets - Vous assumez le rôle de chef de projet ou de directeur de projets sur des missions et des clients variés, de la conception à l’implémentation, sans oublier l’optimisation de la performance et la scalabilité de vos développements. Innovate & Train : développement du capital connaissance et de l’innovation - Vous animez nos réseaux de compétences et êtes un support méthodologique et technique pour les consultants - Vous développez des points de vue, des ""assets"", des bonnes pratiques et contribuez à la croissance de l'équipe, - Vous êtes source de conseils tout en participant à la réalisation effective des projets. Sell : - Vous animez la relation client et contribuez activement aux activités d’avant-vente. - Vous animez la relation avec certains partenaires éditeurs d’EPSILON (Google, Microsoft, …) Vous marquez des points si Vous évoluez depuis au moins 6 ans dans des environnements Data Agile et Cloud. La mise en œuvre de plateformes Data n’a pas de secret pour vous. Vous êtes un fan de Scrum, SAFE ou DevOps… et vous avez appliqué ces méthodes avec succès à vos projets ! Vous avez la maitrise d’une stack technique de référence Hadoop (Cloudera/HortonWorks), Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, … et une réelle expérience des environnements cloud (en particulier Google Cloud Platform et Azure ). Vous avez déjà encadré, managé, fait évoluer des consultants à travers une première expérience significative de management ? Le partage de connaissance et la curiosité sont des pré-requis dans votre quotidien ? Dynamique et réactif, vous démontrez un réel leadership. La qualité de votre communication écrite et orale ainsi que votre aisance relationnelle vous permettent d’être reconnu comme un interlocuteur exigeant et fiable tant en interne qu’en externe.",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
97,73696,https://www.welcometothejungle.com/fr/companies/evaneos/jobs/data-engineer_paris_EVANE_1p2gxJ0,Data Engineer,Evaneos,"{Looker,BigQuery,Python,durable,dbt,Dbt,via,airflow,Kubernetes,Git,Airflow,SQL,Amplitude,bigquery,GCP}",Télétravail partiel possible,"27 rue de Mogador, Paris, 75009","Tourisme, SocialTech / GreenTech",CDI,2023-04-22,"Des voyages meilleurs pour les voyageuses et voyageurs, meilleurs pour la planète 🌍 Depuis sa création en 2009, Evaneos n’a cessé d’œuvrer pour que le voyage de demain devienne plus juste et plus durable. En connectant les voyageuses et les voyageurs avec la crème des experts et expertes locales à travers le monde, l’expérience n’en est que meilleure pour nos voyageurs‧euses et meilleure pour les lieux visités. Selon nous, tout est une question de qualité de service et d’impact. Cela se traduit par une lutte permanente contre le tourisme de masse et toute forme d’expériences désincarnées effectuées au détriment des communautés locales et de l’environnement. Grâce à notre réseau de plus de 1 000 partenaires locaux, nous avons pu aider près de 500 000 voyageurs et voyageuses à organiser des séjours exceptionnels dans plus de 160 pays à travers le monde. L’aventure ne s’arrête pas là. Nous sommes sur le point de rendre chaque voyage vendu par Evaneos 100% neutre en carbone et nous allons ajouter à notre réseau 200 nouvelles agences dirigées par des femmes. Nos valeurs sont tout aussi présentes au sein d’Evaneos . Nous puisons notre force dans notre diversité, constituée d’une multitude de langues, d’origines et d’expériences. Nous pensons que les meilleures équipes se construisent dans un environnement où chaque personne peut être elle-même, où l’on peut se faire confiance et s’épanouir. Nous espérons que vous nous rejoindrez pour contribuer à cette mission ! 🚀 Team Data 📊 L’équipe Data chez Evaneos existe depuis plus de 4 ans et est composée d’une douzaine de personnes (Data Analysts, Product Analysts, Analytic Engineers, and Data Engineer). En tant que plateforme de mise en relation, Evaneos collecte chaque jour des données de différentes sources, et la vocation de l’équipe data consiste à valoriser ces données pour accompagner la croissance de l’entreprise, notamment grâce à : L’aide à la décision : Nous accompagnons l’ensemble des métiers à prendre les meilleures décisions possibles en utilisant au mieux la donnée. L’ensemble des méthodologies métiers reposent sur des démarches scientifiques et data-driven, à travers l’émission d’hypothèses et leur validation (ou invalidation) par la donnée. L’innovation : Notre objectif 2024 est de lancer notre plateforme de Datascience et d’innover, avec un fort accent sur l’industrialisation à travers les pratiques MLOps notamment. Tes missions 🔭 Au quotidien tu te sens à l’aise avec l’une ou plusieurs de ces missions : Ingérer les nouvelles sources de données dans le datalake (airflow) Monitorer et maintenir les flux de données en production (airflow + dbt + bigquery) Maintenir l’infrastructure cloud (Pulumi + GCP + Kubernetes) Améliorer l’environnement de travail des data analystes (VSCode + Notebooks) Construire la future plateforme datascience (Vertex AI ? À définir ensemble 🔍) Devenir le référent de l’architecture côté Data Et évidemment , tu as envie de participer également à l’essor de la Team Data en t’impliquant dans la vie d’équipe dans un but d’amélioration collective 🙂 📢 Note : n’hésite pas à postuler même si tu ne coches pas toutes les cases, nous serons ravi·e·s de t’accompagner dans ton apprentissage. Notre stack 📈 Airflow Dbt BigQuery Looker Amplitude Git GCP (GKE, Vertex AI) Pulumi Nos outils de collaboration 📌 Notion Slack Miro Figma Gather.town qui reproduit nos locaux sur internet Cadre de travail ✔️ Nous plaçons le bien-être des “Evaneosien·nes” au centre de nos valeurs : Budget voyage via le CSE pour découvrir les services Evaneos Télétravail à temps plein ou télétravail ponctuel possible + Travelling TT pour travailler plusieurs fois par an dans d’autres pays/régions Une flexibilité du temps de travail : en accord avec ton équipe, tu peux aménager tes horaires grâce aux “Flexi-Fridays” Bureaux proches de Saint-Lazare avec une superbe cour intérieure permettant d’échanger avec tous les collègues le soir et de faire des afterworks Cours de yoga, méditation, sports en partie pris en charge par Evaneos grâce au partenariat avec Gymlib Différents groupes de loisirs : Groupe de musique, team jeu de sociétés, groupes de sports, etc. Des événements internes pour se connaître, découvrir et échanger : déjeuners culturels, afterworks, daily, sprint planning, rétro, café, etc. PC ou MacBook Pro fourni au choix Des BSPCE pour être lié.e au succès de l’entreprise Tu as un bon sens du business, tu es pragmatique, organisé·e et rigoureux·euse. Tu es prêt·e à challenger et à être challengé·e par nos équipes data et produit. Tu es curieux·euse, et tu as envie d’apprendre et de partager tes connaissances sur différents sujets (techniques comme business). Tu es pédagogue et bon·ne communiquant·e. Tu maitrises le Python et le SQL. Rémunération 💳 Notre politique de rémunération nous permet de définir une fourchette de salaire selon l’expérience professionnelle et le niveau d’impact d’une personne. Cela correspond, chez nous, à une fourchette entre 43 et 55k€. La communauté tech d’Evaneos étant en complète transparence de ses salaires, ta rémunération sera définie en comparant ton niveau à celui de tes collègues, afin de te proposer une rémunération cohérente avec le reste de la communauté. 1 entretien avec Nicolas (Head of Data) et Ludovic (Data Engineer) 1 test technique ( à réaliser chez toi ) 1 échange “team fit” pour rencontrer d’autres membres de l’équipe Data : Camille, Victor, Agnes, Quentin, selon leurs disponibilités.",,Non spécifié,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
96,73677,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/data-engineer-cloud-confirme-e-pau-f-h_pau_CAPGE_7Z1pp7A,Data Engineer-Cloud Confirmé.e PAU,Capgemini,"{TensorFlow,React,Python,Azure,PostgreSQL,Docker,AWS,Git,Java}",Télétravail partiel possible,"Pau, 64000","IT / Digital, Organisation / Management, Stratégie, Transformation",CDI,2023-04-22,""" Get the future you want"" Telle est notre promesse chez Capgemini : Evoluer dans un environnement où le développement des compétences et les perspectives d'avenir sont à portée de main ! Nous recherchons des femmes et des hommes passionné.e.s par l'IT pour intégrer nos équipes techniques et accompagner nos clients dans leurs projets de transformation numérique. Nos équipes Data sur Pau c'est : Une équipe jeune et dynamique construite autour de 3 piliers : la data, l’expertise et le fun ! Des data scientistes, des data ingénieur.e.s, des data analystes et des data architectes, Des projets Agiles et innovants dans le Cloud, Des personnes intégrées à un réseau de plus de 1000 consultants Data en France et plus de 10000 de par le monde ! Notre Practice PER s’appuie sur l’excellence technologique, la gestion des données, ainsi que l’expertise propre aux activités métiers et aux secteurs. Notre quotidien est d’aider les entreprises aux enjeux de demain comme le green IT. Afin de répondre aux besoins de nos clients du secteur Pétrolier/Gazier, nous recrutons un.e Data Engineer Cloud au sein de l'équipe de Ridha CHELGHAF . Intégré.e au sein de l’équipe Data ton rôle sera de : CONCEVOIR des modélisations statistiques et des algorithmes pour exploiter les données DEVELOPPER les pipelines de collecte, stockage et transformation des données dans un contexte DevOps MODELISER les résultats des analyses de données pour les rendre lisibles, accessibles et exploitables par les data analystes et data scientistes (PostgreSQL, Flask…) INDUSTRIALISER les solutions dans un contexte Cloud DevOps (AWS, Azure, Docker…) COLLABORER lors de la mise en place des stratégies « Data Driven » de l’entreprise ACCOMPAGNER de jeunes développeur.euse.s dans leur montée en compétence au sein de notre entité PARTICIPER à la vie de notre équipe Data (proposer / organiser / assister à nos évènements et nos ateliers) Description du profil : Quels sont les prérequis ? Tu maitrises : Python, Panda, DevOps, Scikit Learn, TensorFlow, Git, Docker, Sonar, Flask, Angular, AWS ou Azure Tu maitrises également Angular, React, Spring, Java ? N’hésite pas, rejoins-nous ! Nous proposons : Tu intégreras une équipe ambitieuse, fun et dynamique ! Une culture forte et bienveillante, et une grande place laissée à la liberté Des projets innovants autour de la Data et du Cloud Des clients variés, leaders de leur secteur Un véritable accompagnement dans l’évolution de votre carrière Une équipe à taille humaine, en renouvellement et en hyper croissance Côté rémunération : ton salaire mais aussi de la participation, de l’intéressement, un PERCO, une mutuelle, une carte restaurants, des congés supplémentaires proportionnels à ton ancienneté, un CE très dynamique, un accord de télétravail et de parentalité et des horaires modulables.",,Bac +5 / Master,> 2000 salariés,> 4 ans,2,1,0.04154662416233763
95,56759,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-sante-social-emploi-nantes_nantes_SS_84zVa21,Data Engineer - Big Data - Santé Social Emploi - Nantes,Sopra Steria,"{Iceberg,SAS,Python,MongoDB,Grafana,Trino,Airflow,PostgreSQL,Gitlab,Prometheus,Parquet,Ceph,R,Spark,Java,Jupyter}",Télétravail partiel possible,"5-7 impasse Claude Reggiani 44800 Saint Herblain, Nantes","IT / Digital, Organisation / Management",CDI,2023-03-26,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Santé Social Emploi » regroupe l'ensemble des acteurs qui exercent une mission de service public dans ces domaines. Nos clients sont notamment les organismes de protection sociale de la santé, de la retraite et de la famille, et également de grands acteurs du secteur de l'emploi. Notre présence globale dans l'écosystème et la connaissance approfondie des métiers de nos clients sont un atout majeur pour répondre aux grands enjeux de transformation impliqués par les réformes de l'Etat. Votre rôle et missions Votre futur environnement de travail : Si vous êtes passionné(e) par les grands projets Data, rejoignez notre équipe d'ingénieurs du centre d'expertise Data de Nantes. Y sont présents des experts de la mise en ?uvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée. Vous êtes accompagné(e) au développement de vos connaissances et de vos compétences à travers nos programmes de formations Sopra Academy, vous bénéficiez du support des Directions Techniques et Fonctionnelles, ainsi que de la communauté Data. Rejoindre la communauté Data Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée! Votre rôle et missions : Dans le cadre de la mise en place de plateforme Data pour un de nos grands clients et selon votre expérience, vous participez à : - La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analyste - La mise en oeuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming au sein d'un Cloud privé. - Le traitement de la donnée jusqu'à l'exposition au métier. - La mise en place de la chaine CI/CD et de sa supervision. - Le déploiement de la sécurité sur la plateforme. Environnement technique : - Spark, Trino, Jupyter, SAS - Openshift, Keycloack, Bastion, Vault, Wallix - Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB - Prometheus, Grafana, ELK, Gitlab CI - Java, Python, R Ce que nous proposons : - Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. - Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation. - Un accompagnement individualisé avec un mentor. - Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore?). Votre profil : Diplômé(e) d'une école d'Ingénieurs ou équivalent universitaire, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 2 ans. Vous accordez une importance particulière à : - Au développement de vos compétences sur plusieurs technologies. - L'opportunité d'évolution réelle de carrière au travers de l'expérience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir auprès de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le développement de leur carrière. - A la bienveillance et à la diversité. Chez Sopra Steria, nous sommes engagés pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les différences. Tous nos postes sont ouverts aux personnes en situation de handicap . En savoir plus ici","Sopra Steria seeks a Data Engineer to join its Nantes Data Expertise Center. The ideal candidate will have at least two years of experience in Big Data or BI projects, and will be responsible for understanding business needs, implementing data ingestion solutions, processing data, supervising CI/CD chains, and deploying security on data platforms. Technical skills required include Spark, Trino, Jupyter, SAS, Openshift, Keycloack, Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB, Prometheus, Grafana, ELK, Gitlab CI, Java, Python, and R. Sopra Steria offers teleworking options, mentoring, career advancement opportunities, individualized training, and a diverse and inclusive work environment.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
93,73651,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/data-engineer_paris_WEWYS_YxbkxZx,Data Engineer,Wewyse,"{Python,Jenkins,Scala,Azure,Hadoop,Spark,Docker,Kubernetes,NoSQL,AWS,Git,SQL,Java,GCP}",Télétravail partiel possible,"48 Rue du Château d'Eau, Paris, 75010","Digital Marketing / Data Marketing, IT / Digital, Transformation",CDI,2023-04-22,"Wewyse est un cabinet de conseil spécialisé en Data et en Intelligence Artificielle . C’est aussi et surtout une communauté de passionnés partageant l’ambition de grandir ensemble et d’ouvrir le champ des possibles dans leurs domaines. Si vous pensez que la Data et l’Intelligence Artificielle ont beaucoup à offrir au monde de demain, et si vous souhaitez apporter votre contribution à ce monde, avec humilité et enthousiasme, alors vous êtes un Wyser en puissance. Être Data Engineer chez Wewyse c’est : intégrer une communauté d’experts Data passionnés, recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements, intervenir chez des clients pour y porter l’expertise Wewyse dans des contextes et des secteurs variés, participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up, viser l’excellence des développement en s’appuyant sur le Software craftsmanship, concevoir des architectures logicielles modernes, penser DevOps pour l’automatisation des déploiements et la continuité des services. être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles, faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière. Ce que nous aimons chez Wewyse : les personnalités ouvertes, curieuses, ambitieuses les langages Scala, Python et Java le cloud : AWS, GCP, Azure les écosystèmes : Hadoop et Spark la conteneurisation : Docker et Kubernetes les méthodes Agiles le SQL et le NoSQL l’approche DevOps : Jenkins, Ansible et Terraform le versionning : Git l’anglais",,Bac +5 / Master,Entre 15 et 50 salariés,> 1 an,2,1,0.04154662416233763
92,73623,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-sante-social-emploi-nantes_nantes_SS_yrjr019,Data Engineer - Big Data - Santé Social Emploi - Nantes,Sopra Steria,"{Python,Iceberg,Ceph,SAS,Parquet,Jupyter,PostgreSQL,Java,Spark,MongoDB,Prometheus,Gitlab,Airflow,Grafana,R,Trino}",Télétravail partiel possible,"5-7 impasse Serge Reggiani, Nantes","IT / Digital, Organisation / Management",CDI,2023-04-22,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Santé Social Emploi » regroupe l'ensemble des acteurs qui exercent une mission de service public dans ces domaines. Nos clients sont notamment les organismes de protection sociale de la santé, de la retraite et de la famille, et également de grands acteurs du secteur de l'emploi. Notre présence globale dans l'écosystème et la connaissance approfondie des métiers de nos clients sont un atout majeur pour répondre aux grands enjeux de transformation impliqués par les réformes de l'Etat. Votre rôle et missions Votre futur environnement de travail : Si vous êtes passionné(e) par les grands projets Data, rejoignez notre équipe d'ingénieurs du centre d'expertise Data de Nantes. Y sont présents des experts de la mise en ?uvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée. Vous êtes accompagné(e) au développement de vos connaissances et de vos compétences à travers nos programmes de formations Sopra Academy, vous bénéficiez du support des Directions Techniques et Fonctionnelles, ainsi que de la communauté Data. Rejoindre la communauté Data Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée! Votre rôle et missions : Dans le cadre de la mise en place de plateforme Data pour un de nos grands clients et selon votre expérience, vous participez à : - La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analyste - La mise en oeuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming au sein d'un Cloud privé. - Le traitement de la donnée jusqu'à l'exposition au métier. - La mise en place de la chaine CI/CD et de sa supervision. - Le déploiement de la sécurité sur la plateforme. Environnement technique : - Spark, Trino, Jupyter, SAS - Openshift, Keycloack, Bastion, Vault, Wallix - Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB - Prometheus, Grafana, ELK, Gitlab CI - Java, Python, R Ce que nous proposons : - Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. - Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation. - Un accompagnement individualisé avec un mentor. - Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore?). Votre profil : Diplômé(e) d'une école d'Ingénieurs ou équivalent universitaire, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 2 ans. Vous accordez une importance particulière à : - Au développement de vos compétences sur plusieurs technologies. - L'opportunité d'évolution réelle de carrière au travers de l'expérience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir auprès de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le développement de leur carrière. - A la bienveillance et à la diversité. Chez Sopra Steria, nous sommes engagés pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les différences. Tous nos postes sont ouverts aux personnes en situation de handicap . En savoir plus ici",,Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
91,58093,https://www.welcometothejungle.com/fr/companies/cleyrop/jobs/support-engineer-data-platform_paris,Support Engineer Data Platform,Cleyrop,"{Databricks,Snowflake,via,Datahub,Hadoop,DataHub}",Télétravail partiel possible,"16, Rue Washington, Paris, 75008","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data",CDI,2023-03-26,"Cleyrop a été créé fin 2020 avec pour objectif de créer le premier DataHub européen. Pourquoi ? Car aujourd’hui, c’est encore trop complexe. Car aujourd’hui, on se tourne vers des acteurs américains qui ne font qu’une partie du chemin. Car aujourd’hui, le pouvoir de la data doit être à la portée de chacun Now what ? Chez Cleyrop, nous sommes convaincus d’un monde où chacun pourrait prendre le contrôle de ses données afin d’en démultiplier l’usage. C’est pourquoi nous avons créé le premier DataHub européen industriel, sécurisé et modulaire qui embarque les meilleures solutions européennes dans une plateforme consistante et prête à déployer. Les enjeux sont importants, les ambitions aussi (CA 2021 3M€ et CA 2022 10M€) Nous avons déjà levé fin 2021 4 Millions en Seed auprès de business angels et de la BPI ce qui nous permet de se lancer dans ce défi. Notre mission : Simplifier et démocratiser l’accès à la donnée Les premiers projets d’exploitation des données dans des domaines tels que Santé, Recherche, Energie, … ont dès leurs premières étapes obtenu des résultats fantastiques. Que ce soient les partages collaboratifs, les corrélations inattendues, ou simplement la pertinence des analyses effectuées, la data commence seulement à révéler tout son potentiel. Et le meilleur est à venir ! La data doit rentrer dans les usages courants de chacun pour que chaque entreprise ou organisation, puisse mettre l’intelligence de la donnée au coeur de ses décisions et de ses opérations. Données brutes, sensibles, complexes… notre mission est de rendre la Data accessible au plus grand nombre pour en démultiplier les usages. Notre ambition : Devenir le partenaire Data européen de référence​ Face à la croissance exponentielle des données et ses usages, un point d’entrée unique et complet est une nécessité pour que les organisations puissent s’adapter à leur environnement en constante évolution. Pour cela, nous voulons offrir une solution simple, clé en main et souveraine avec un haut niveau de services. Cleyrop est fière de constituer la 1ère alternative européenne et industrielle permettant aux organisations de devenir data driven dans un cadre de confiance. TLDR : Too long Didn’t read Participer pleinement à la création du premier Datahub européen , avec une architecture et des technos les plus modernes possibles, tout ça au sein d’une équipe en pleine structuration , c’est ce qu’on te propose, tenté.e ? Ce poste est en CDI // Localisation : Ile De France , Tu peux travailler depuis chez toi de manière hybride et/ou depuis nos bureaux à Paris 8ème . Le salaire est compris entre 55k€ et 65k€ annuel brut en fonction du niveau qui te sera attribué à l’issue du process de recrutement // Si tu as l’esprit doer , on est prêts à te recruter dès que tu veux en être ! Pour ce poste une première expérience similaire de 4 à 6 ans est attendue. L’aventure que tu pourrais rejoindre : Nous avons créé Cleyrop fin 2020 avec pour objectif de créer le premier DataHub européen. 🤔 Pourquoi ? Car aujourd’hui, c’est encore trop complexe. Car aujourd’hui, on se tourne vers des acteurs américains qui ne font qu’une partie du chemin. Car aujourd’hui, le pouvoir de la data doit être à la portée de chacun.e. 👀 Now what ? Chez Cleyrop, nous sommes convaincus.es d’un monde où chacun pourrait prendre le contrôle de ses données afin d’en démultiplier l’usage. C’est pourquoi nous avons créé le premier DataHub européen industriel, sécurisé et modulaire qui embarque les meilleures solutions européennes dans une plateforme consistante et prête à déployer. Les enjeux sont importants, les ambitions aussi ! Notre contexte : Actuellement en plein déploiement, nous ouvrons pour cette année une soixantaine de postes, il faut donc s’attendre à rejoindre une équipe en pleine construction. Les ambitions sont fortes, collectivement nous portons à bras le corps le projet Cleyrop pour qu’il réussisse. Pourquoi ce recrutement ? Aujourd’hui le service support est à construire , nous devons donc monter en compétences sur le support L2 pour le rendre plus efficace. Nous devons également être capable de lire le code/log pour se retrouver dans notre produit. Nous devons également être garant de l’efficacité opérationnelle . Tu travailleras aux côtés des équipes ops, produit et service , tu seras ainsi au coeur de la machine ! Tu travailleras également aux côtés de Leang qui intervient sur la partie support. Ce qui t’attend si tu nous rejoins Si tu nous rejoins, tes principaux objectifs seront les suivants : 🎯 A court terme : Être à l’aise avec notre produit Être l’aise avec la plateforme sous jacente Réaliser les premiers tickets bien classifiés 🚀 A long terme : Le support L2 est en place Assurer le bon fonctionnement du support L2 Occuper le rôle de head of support si cette perspective d’évolution te convient Plus techniquement, les objectifs attendus sont la qualité ops du service monitoré depuis le ticketing system, la base de connaissance support est initiée, prise en main du produit de la data plateforme cleyrop d’un point de vue fonctionnelle et technique, service opérationnel. Notre process de recrutement : Ces compétences et ces expertises seront vérifiées au cours de notre process de recrutement, défini spécialement pour ce job. 1/ D’abord un premier entretien avec Jennifer, notre Chief Recruitment Officer, pour échanger autour de tes expériences, répondre à tes questions concernant Cleyrop et le poste et définir si le match s’opère entre tes attentes professionnelles et ce que nous pouvons te proposer. 2/ La deuxième étape : un usecase pour comprendre ta méthode et tes compétences. Il s’agit d’un cas concret qui te mettra aussitôt dans le bain de ce à quoi tu pourrais être confronté.e chez Cleyrop. 3/ Le second entretien avec Jean, notre Directeur Technique afin d’échanger autour de ton usecase, l’opérationnel sera de mise ! 4/ Le troisième entretien avec Franck, notre VP Engineer, via cet échange tu auras plus de visibilité concernant notre organisation il pourra également te questionner sur la partie hard skill. 4/ La dernière étape sera un échange avec Lauren, co-fondatrice et CPO pour t’exposer la vision long terme de Cleyrop. N’hésite plus et envoie nous ta candidature, Jennifer t’attend déjà pour le premier échange !!! 😊 C’est pour toi si : Si ce défi t’attire, voici ce que l’on attend de toi. Les premières compétences sont requises et cruciales mais si tu ne les coches pas toutes parfaitement postules quand même, nous sommes ouverts aux potentiels ! 🦾 Les compétences requises sont les suivantes : Connaissance ITIL incident VS problem management Connaissance data plateforme : 5 couches usual suspectes de la data plateforme Tu es Focus client et ton niveau de communication te permet d’échanger avec tout type d’interlocuteur, tu es également orienté.e problem solver Tu disposes d’une connaissance des métiers tech pour naviguer facilement au sein de Cleyrop. C’est un vrai plus si tu es passionné.e de la DATA et si tu as déjà travaillé sur un/ou plusieurs de ces environnements : Databricks ; Datiku ; Snowflake ; Hadoop. Ce que nous pouvons t’apporter : Apporter sa pierre à l’édifice sur un projet à impact ; Collaborer aux côtés de passionné.es te permettant de monter en compétences sur l’environnement de la data ; Partager dans un cadre collectif ; Ces compétences et ces expertises seront vérifiées au cours de notre process de recrutement, défini spécialement pour ce job. 1/ D’abord un premier entretien avec Jennifer, notre Chief Recruitment Officer, pour échanger autour de tes expériences, répondre à tes questions concernant Cleyrop et le poste et définir si le match s’opère entre tes attentes professionnelles et ce que nous pouvons te proposer. 2/ La deuxième étape : un usecase pour comprendre ta méthode et tes compétences. Il s’agit d’un cas concret qui te mettra aussitôt dans le bain de ce à quoi tu pourrais être confronté.e chez Cleyrop. 3/ Le second entretien avec Jean , notre Directeur Technique afin d’échanger autour de ton usecase, l’opérationnel sera de mise ! 4/ Le troisième entretien avec Franck, notre VP Engineer, via cet échange tu auras plus de visibilité concernant notre organisation il pourra également te questionner sur la partie hard skill. 4/ La dernière étape sera un échange avec Lauren , co-fondatrice et CPO pour t’exposer la vision long terme de Cleyrop. N’hésite plus et envoie nous ta candidature, Jennifer t’attend déjà pour le premier échange !!! 😊","Cleyrop is seeking a Support Engineer to join their team and participate in creating the first industrial, modular, and secure European DataHub. This role requires experience in ITIL incident and problem management, along with knowledge of data platform technology. The successful candidate will have strong communication skills, be customer-focused, and have a passion for data. The job involves troubleshooting code and logs, ensuring operational efficiency, and being comfortable with the Cleyrop platform. The ideal candidate will work alongside the ops, product, and service teams and contribute towards creating a platform that simplifies and democratizes data access. Cleyrop offers a salary of 55k€ to 65k€ annually and provides an opportunity to work from home or Paris 8th office.",Non spécifié,Entre 15 et 50 salariés,> 4 ans,2,1,0.04154662416233763
90,73583,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-aerospatial-toulon-f-h_toulon,Data Engineer - Aérospatial - Toulon -,Sopra Steria,"{Hadoop,Spark,Tableau,Nifi}",Télétravail partiel possible,"Toulon, 13100","IT / Digital, Organisation / Management",CDI,2023-04-22,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Aeroline » regroupe nos activités auprès de grands acteurs de l'Aéronautique et du Spatial avec une couverture internationale. Nos expertises principales : le manufacturing 4.0, la maintenance et les services qui englobent nos expertises autour de l'ingénierie et du « Product Lifecycle Management ». Sopra Steria est un acteur incontournable de la transformation et de la performance de la chaîne de valeur de nos clients. Votre futur environnement de travail Environnement technologique : Architecture Spark, Hadoop, Nifi, Qlick/Tableau, Environnement fonctionnel : Au sein d'une plateforme Big Data, l'équipe projet intervient, pour le compte d'un grand constructeur de la défense de la région, sur le traitement et la mise à disposition au client d'un grand volume de données dans le cadre d'une stratégie de transformation numérique. Votre rôle et vos missions : Vous rejoindrez une équipe dynamique et serez amené(e) à contribuer de la construction au déploiement de solutions permettant de traiter des enjeux comme : - Le remplacement d'outils clients par des solutions plus adaptées et plus efficaces, - Le développement d'outils d'aide à la décision, - La digitalisation de chaines de traitement, - La mise en place d'indicateurs sur des équipements spécifiques, - Etc. Vous aurez également l'occasion de participer à différents ateliers directement au contact du client afin de mieux cibler ses enjeux et ses attentes. Les apports du poste : - Spécifier, développer des solutions techniques et les déployer dans un contexte opérationnel - Participer à des cycles courts favorisant le retour d'expérience et la progression ; - Baigner dans un écosystème Big Data à forte valeur ; - Participer à l'ensemble des activités prises en charge par votre équipe (de l'ingestion jusqu'à l'exposition data) ; - Être accompagné(e) au quotidien par un(e) responsable technique expérimenté(e) et reconnu(e). Ce que nous proposons - Un package d'avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation. - Un accompagnement individualisé avec un mentor. - Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore). - Vous êtes également formé(e) au contexte de nos clients et à leurs métiers, ainsi qu'à nos processus qualité et méthodes. Vous êtes diplômé(e) d'une école d'Ingénieur ou d'un Master 2 Informatique. Vous êtes curieux(se), logique et vous appréciez le travail collaboratif. Vous êtes passionné(e) par les enjeux induits par la transformation digitale en cours et à venir et vous voulez en être un acteur / une actrice. Vous avez un bon relationnel et adhérez à l'idée que le développement de la société s'appuie sur la veille technologique et l'esprit d'innovation des collaborateurs. Vous avez envie d'évoluer au sein d'une équipe, dans un contexte d'innovation. Rejoignez-nous ! Employeur inclusif et engagé, Sopra Steria oeuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils Tous nos postes sont ouverts aux personnes en situation de handicap",,Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
89,57088,https://www.welcometothejungle.com/fr/companies/railwai/jobs/software-and-data-engineer-f-h_montpellier,Software and Data Engineer,RAILwAI,"{Git,AWS,R,kubernetes,BigQuery,GCP,SQL,Python,docker}",Télétravail partiel possible,"Rond-Point Benjamin Franklin, Montpellier, 34000","Logiciels, Intelligence artificielle / Machine Learning, Ferroviaire",CDI,2023-03-26,"RAILwAI est une jeune entreprise innovante créée en octobre 2021. Elle combine les expertises de deux domaines très spécifiques, à haute technicité et à forte valeur ajoutée : La maintenance et l’exploitation d’infrastructures de transport (lignes ferroviaires, métros, tramways) La data science ou science des données RAILwAI propose des solutions logicielles, qui s’interfacent avec tout type de capteurs ou sources de data, pour traiter et analyser les données brutes afin de constituer un panel d’outils d’aide à la décision pour le client en fonction de ses besoins (e.g., tableaux de bord, data analytics ou maintenance prédictive). Missions principales Participe à la conception, au développement et à la maintenance des applications, modules ou services (back end, Cloud) qui permettent de traiter, visualiser, éditer et valider des données, en prenant en compte les besoins des utilisateurs ainsi que les contraintes techniques (faisabilité au développement) et celles liées à l’offre logicielle de la société. Activités et Tâches Analyser / Concevoir : ∝ Participer à l’analyse des besoins fonctionnels et techniques ∝ Participer à la définition des spécifications générales de la solution et de son environnement ∝ Concevoir des solutions nécessitant l’utilisation de technologies Cloud, Data et Machine Learning pour répondre à des cas d’usages métiers et à la feuille de route Produit ∝ Travailler en collaboration pour soutenir le développement de nouvelles fonctionnalités Développer : ∝ Développer et tester des flux d’ingestion de données de Data Lake et de traitement des données ∝ Déployer, optimiser et industrialiser au quotidien des pipelines de données dans le Cloud ∝ Développer la solution (API, logiciel Web, application, système) en conformité avec les bonnes pratiques de développement ∝ Documenter le code source ∝ Assurer la qualité du code, le respect des délais, et les processus de mise en production Tester / Déployer : ∝ Tester et valider les développements : mettre en place des tests unitaires et d’intégration sur les fonctionnalités développées ∝ Participer aux ateliers de recettes utilisateurs ∝ Contribuer aux corrections nécessaires ∝ Participer à l’amélioration de la qualité du code ∝ Participer à la phase de mise en production des outils et solutions logicielles Maintenir : ∝ Participer aux actions de maintenance des outils et solutions logicielles ∝ Prendre en charge les demandes de corrections, petites évolutions dans le cadre de cette maintenance ∝ Participer au maintien en condition opérationnelle des solutions logicielles Tâches transverses : ∝ Participer à la documentation technique et globale du produit ∝ Accompagner des équipes métiers dans leurs travaux d’identification et d’expression des besoins sur la data ∝ Contribuer à la définition, à la réalisation et à l’amélioration de la solution Produit de la société ∝ Participer à l’élaboration des solutions logicielles, tant du point de vue d’architecture que du choix des différentes briques techniques (langages, frameworks, librairies, etc.) ∝ Collaborer étroitement avec les services de R&D et Innovation, de la Direction de la Stratégie et des Opérations, mais aussi au sein de l’équipe de la Direction Technique avec les différents profils à venir ∝ Collaborer auprès des clients, fournisseurs, sous-traitants, notamment dans le cadre des différents projets, mais aussi en phase d’avant-vente avec l’équipe commerciale ∝ Contribuer activement à l’évaluation des charges et de la planification ∝ Pourra avoir la charge de la gestion et du suivi d’équipe au sein de la Direction Technique ∝ Pourra encadrer des collaborateurs futurs (employés, stagiaires, etc.) Environnement de travail Outils Google cloud platform (BigQuery, Cloud Run, etc.) Outils Atlassian (JIRA, BitBucket, SourceTree, Confluence) Python, Visual Studio Code Office 365, Teams, Outlook, etc. Compétences requises Goût pour l’innovation et les nouvelles technologies Ouvert et curieux, aime travailler en mode agile Maitrise des langages SQL, R, Python Expérience des environnements Cloud et Serverless : GCP/AWS Connaissances autour des processus d’industrialisation et d’infrastructure as code (Terraform), et des outils d’orchestration (docker, kubernetes, etc.) Pratique des outils de travail collaboratif (Git, Jira, etc.) Une expérience en Machine Learning et Deep Learning et Développement Full Stack serait un atout. La maîtrise de l’anglais technique serait un plus. Entretiens avec le Directeur Technique et le Directeur Général.","RAILwAI seeks a software developer to participate in the design, development, and maintenance of software applications that process, analyze, and visualize data for clients in the transportation industry. The ideal candidate has experience in Cloud environments, data processing, and machine learning, as well as familiarity with collaborative work tools and agile methodologies. Additional qualifications include expertise in SQL, R, and Python, and experience with infrastructure as code and orchestration tools such as Kubernetes. Fluency in technical English is desirable.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
88,57080,https://www.welcometothejungle.com/fr/companies/valtech/jobs/data-engineer-h-f-paris_paris,Data Engineer h/f - Paris,Valtech,"{DynamoDB,DBT,Snowflake,Synapse,Cassandra,Neo4J,Docker,Azure,MongoDB,Databricks,Kafka,Git,NoSQL,Qlik,Jenkins,Kubernetes,AWS,SQL,Airflow,Redshift,BigQuery,GCP,Python,Tableau}",Télétravail partiel possible,"38 Rue des Jeuneurs, Paris, 75002","IT / Digital, Transformation",CDI,2023-03-26,"Valtech est une agence digitale dédiée à la transformation des entreprises. Valtech réunit plus de 5000 experts (dont 400 chez Valtech France) en technologies, design, développement, création, marketing et data, dans 61 bureaux répartis dans 22 pays (Allemagne, Argentine, Brésil, Bulgarie, Canada, Chine, Danemark, Émirats arabes unis, États-Unis, France, Inde, Macédoine, Mexique, Pays-Bas, Pologne, Portugal, Roumanie, Royaume-Uni, Singapour, Suède, Suisse, Ukraine). Ensemble, nous concevons et déployons des stratégies digitales pour accompagner la transformation de grandes marques. Contexte Rejoignez le département dédié à la data « stratégie et données » de Valtech, qui aide les plus grandes marques et entreprises mondiales à atteindre une croissance ambitieuse dans différents secteurs (luxe, retail, médias, etc.). Nos clients nous choisissent en raison de la qualité de nos livrables et de notre engagement à produire des résultats commerciaux clairs et mesurables. Notre expertise s'exprime dans les domaines de l’ingénierie et de la science des données, de l’analyse de celles-ci, de l’optimisation continue, de la technologie MarTech. Notre passion est de relever les défis où nous réinventons le parcours client et construisons de nouvelles expériences connectées et où nous orchestrons les données afin d'aider nos clients à transformer leur mode de fonctionnement et optimiser les plateformes numériques pour le commerce et le marketing omnicanal. Rôle / Mission Consultant Data Engineer En association avec des contributeurs et des gestionnaires individuels de haut niveau, vos principales fonctions et responsabilités seront les suivantes : Améliorer la conception, mettre à jour et modifier la programmation pour des parties et des sous-systèmes de pipelines de données, de référentiels et de modèles pour les données structurées/non structurées ; Travailler en tant qu’ingénieur Big Data, contributeur individuel et joueur d’équipe ; Exploiter les données à l’aide d’outils et de langages de programmation modernes ; Analyser, concevoir et déterminer les activités de codage, de programmation et d’intégration requises en fonction des objectifs spécifiques et des lignes directrices établies du projet ; Exécuter et écrire des parties de plans de test, de protocoles et de documentation pour la partie affectée de l’application ; Identifier et débogguer les problèmes liés au code et suggérer des modifications et/ou des améliorations ; Participer avec d’autres professionnels de la science des données pour développer des solutions fiables, rentables et de haute qualité pour les systèmes, modèles ou composants de données ; Collaborer et communiquer avec l’équipe de projet concernant l’avancement du projet et la résolution des problèmes. Profil Vous justifiez de 5 ans d'expérience dans un rôle d’ingénierie de données, d’analyse commerciale, d’intelligence d’affaires ou d’ingénierie de données comparable, y compris les outils d’entreposage de données et d’intelligence d’affaires. Hardskills Tableau, Qlik, Power BI, Data Studio ; Python, Tables delta, SGBDR traditionnel (SQL), NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan), Jenkins, Git, Apache, Kafka, AWS, Docker, Kubernetes, Apache Airflow, API Rest, Snowflake, DBT, BigQuery, AWS Redshift, Azure Synapse Analytics, Databricks ; Azure, AWS ou GCP sont des plus ; Softskills Direction de projets et d’équipes d’ingénierie de data dans un cadre agile ; Être capable de transformer des données structurées, semi-structurées et non structurées, selon les meilleurs modèles de conception ETL / ELT ; Solide compréhension des principes de sécurité de l’information pour assurer un traitement et une gestion conformes des données ; Une expérience dans le secteur du luxe est un must ; Anglais ET Français impératifs. Nos valeurs : Share - Dare - Care Share : Nous partageons les uns et les autres nos idées pour aller toujours plus loin - nous investissons dans la constitution d'équipes diversifiées et inclusives et dans une culture du travail et de l'excellence. Dare : Nous osons aller dans les territoires inconnus. Échouer, recommencer, fait partie de notre métier. Ce n'est ni un secret, ni un tabou, c'est une façon de penser, indissociable de l'exploration et de l'innovation. Care : Nous nous soucions de la qualité de ce que nous produisons. Nous souhaitons contribuer à faire du monde un endroit meilleur grâce à ce que nous créons. Diversité & Inclusion À Valtech, nous concevons des expériences fortes qui touchent chaque personne. Nous sommes donc proactifs en créant des lieux de travail qui conviennent à chaque personne. Notre objectif est de créer un lieu de travail équitable qui offre aux personnes de tous horizons le soutien dont elles ont besoin pour s'épanouir, grandir et atteindre leurs objectifs (quels qu'ils soient). Si vous ne répondez pas à tous les critères ou si vous avez des lacunes dans votre CV, nous serons heureux d’en savoir plus sur vous et qui sait ? Vous serez peut-être le prochain Valtech ! L’agence Valtech est une agence digitale axée sur la transformation des entreprises et nourrie par l'innovation. Avec +5500 experts en technologies, design, développement, création, marketing et data, dans 62 bureaux répartis dans 22 pays, nous sommes parfaitement positionnés pour soutenir la transformation globale de nos clients et leur permettre d'anticiper les défis de demain, de stimuler leur croissance et d'obtenir un retour sur investissement rapide. Les clients font confiance à Valtech pour éliminer la complexité et fournir des solutions innovantes et sans friction comblant ainsi l'écart entre les attentes des clients et l’expérience réelle. www.valtech.com Transform by Doing","Valtech seeks a Data Engineer Consultant to join their team dedicated to the ""strategy and data"" department. The role involves improving the design and modifying programming for data pipelines, repositories, and models while analyzing data using modern programming languages and tools, and collaborating with project teams to develop reliable, cost-effective, and high-quality solutions for data systems. The ideal candidate should have five years of experience in data engineering or a comparable role and possess technical skills in various data tools, languages, and platforms such as Python, Tableau, and AWS. Additionally, the candidate must have excellent project management and team leadership capabilities while understanding data security principles to ensure compliant data processing and management. Fluency in English and French is necessary for the role, and experience in the luxury sector is a must.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
87,73534,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_lyon_EXTIA_MgrzxmR,Data engineer,EXTIA,"{Python,Scala,Linux,SAS,HDFS,R,AWS,S3,Java,GCP}",Télétravail partiel possible,"129 rue Servient, Lyon, 69003","Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-04-22,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Ensuite quoi Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse… Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes. Vous serez en charge de : Participer à la définition des besoins et à la rédaction des User Stories, Collaborer avec les Data Scientists au développement des modules d’analyse de donnée, Concevoir et construire des architectures de données, Intégrer des sources de données, Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives, Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux. Profil : Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple, Vous maitrisez les bases de l’analyse statistique, Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous êtes familiarisé avec l’environnement Linux, Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts. #LI-EB3 Curieux , vous adorez partager les dernières idées innovantes que vous avez découvertes, Analytique , vous avez une âme d’enquêteur et les énigmes n’ont aucun secret pour vous , Proactif , vous aimez les projets qui avancent vite et bien.",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
82,56944,https://www.welcometothejungle.com/fr/companies/margo/jobs/data-engineer-h-f_paris_MARGO_r7xy5gZ,Data Engineer -,Margo,"{Scala,Hbase,via,Spark,Azure,Java,Hadoop,Python,Cloudera}",Télétravail partiel possible,"1, Rue de Saint-Pétersbourg, Paris, 75008","Logiciels, IT / Digital, FinTech / InsurTech",CDI,2023-03-26,"La mission de Margo ? Accélérer la transformation digitale de ses clients en les accompagnant dans le déploiement de projets IT complexes. Margo, c’est un cabinet de consulting à taille humaine dont l’objectif depuis 15 ans est d’assurer la satisfaction de ses consultants autant que celle de ses clients. Pour cela la recette est simple : ils sélectionnent avec attention leurs projets pour que chacun de leurs collaborateurs se sente stimulé et progresse rapidement. Ils interviennent aujourd’hui principalement sur des sujets de coding et data, et sur des problématiques métiers dans la finance, la banque, l’assurance et l’énergie. Notre mission chez Margo ? Accélérer la transformation digitale de nos clients en les accompagnant dans le déploiement de projets IT complexes . Nous sommes un cabinet de conseil à taille humaine dont l’objectif depuis 15 ans est d’assurer la satisfaction de nos consultants autant que celle de nos clients. Pour cela la recette est simple : nous sélectionnons avec attention nos projets pour que chacun de nos collaborateurs se sente stimulé et progresse rapidement . C’est pourquoi nous avons développé une expertise dans les secteurs d’activité où l’on retrouve des contraintes techniques fortes : multithreading, temps réel, performance, volumétrie de données,... Nos consultants interviennent ainsi chez des clients prestigieux en finance de marché, assurance ou énergie, dans des grands groupes ou startups à succès. L’aventure Margo, c’est aussi intégrer une communauté de 350 experts, tous passionnés par la tech, répartis entre Paris, Londres et Varsovie. A leurs côtés, vous pourrez évoluer rapidement et développer de nouvelles compétences. Prêt à nous rejoindre ? 🎯 Exemple de projet proposé par Margo : En intégrant Margo, vous aurez le choix des missions sur lesquelles vous souhaitez travailler. Vous serez accompagné par notre équipe de Business Managers, dont le rôle est de rechercher le projet client qui correspondra le plus à vos attentes. Ainsi, vous pourrez par exemple intervenir sur l’un de nos projets de refonte from scratch d’un datalake au sein d’un grand acteur de l’Asset Management. L’objectif est d'assurer la distribution de la donnée de la manière optimisée pour créer une couche de distribution et permettre aux Data Scientists d’implémenter les use cases. Vous aurez ainsi l’opportunité d’évoluer dans un environnement exigeant , en méthodologie agile et au sein d’une équipe d’experts , composée de 4 développeurs Spark / Scala, 1 architecte data, 1 Ops et 1 tech lead. En tant que Data Engineer, vos missions seront : - Développer en mode agile les usages métier reposant sur le Datalake Hadoop - Identifier et modéliser des données nécessaires à l'usage - Sélectionner le stockage le plus adapté à l'usage parmi les technologies de l'écosystème Hadoop - Développer en Spark et Scala des traitements de transformation et de production de données - Développer des API RESTful (Scala / Play) permettant l'accès aux données produites - Participer à l’amélioration continue et au refactoring de code Stack techno : Hadoop/Cloudera Spark / Scala / Python / Java Cloud Azure Impala / Hbase ✨ La vie interne chez Margo Les projets que nous proposons chez Margo sont des missions longues (2 à 3 ans) qui vous permettront d’évoluer vers une expertise technique. Vous aurez également l’opportunité de vous impliquer dans la vie interne de Margo et contribuer à faire grandir notre communauté. Les possibilités sont nombreuses, vous pourrez devenir : - Recruteur , pour tester techniquement les candidats pendant leur processus de recrutement, représenter Margo lors de forums écoles ou proposer des cooptations de personnes de votre réseau. - Formateur , pour partager votre expertise et vos connaissances au sein de la communauté Margo. - Manager, pour suivre en mission et être garant de l’évolution de carrière de consultants juniors. - Rédacteur , pour mettre en lumière votre expertise et celle de Margo en rédigeant des articles techniques publiés sur notre blog et dans la presse spécialisée. 🔍 Vous êtes un(e) futur(e) Margo si : Must-Have - Vous êtes issu(e) d’une école d’ingénieur ou d’un cursus universitaire équivalent niveau Bac + 5 / Master. - Vous aimez coder et vous êtes passionné(e) d’informatique. - Vous êtes curieux(se) et vous vous intéressez aux dernières technologies du marché. - Vous justifiez d’une première expérience en tant que Data Engineer. Nice to Have - Vous êtes ambitieux et n’avez pas peur de travailler sur des projets challengeants dans des environnements à fortes contraintes techniques, notamment de forte volumétrie de données. - Vous aimez travailler en équipe et êtes attaché au respect des bonnes pratiques de code. - Vous parlez et comprenez l’anglais. 🤝Notre processus de recrutement : 1. Postulez en ligne ! L’équipe RH étudie avec attention votre candidature et vous contacte si votre profil est en adéquation avec l’un de nos postes. 2. Première rencontre ! Vous échangez avec un RH et un Business Manager sur votre parcours, vos aspirations professionnelles ainsi que sur Margo et les opportunités que nous proposons. 3. Challengez-vous dans le cadre d’un entretien technique avec l’un de nos experts. C’est également l’occasion pour vous d’avoir son retour d’expérience. 4. Dernier entretien de motivation : pour finir, vous rencontrez un membre du comité de direction de Margo pour confirmer notre fit culturel. Pendant tout le processus de recrutement, vous avez la possibilité de participer à des événements organisés par Margo et d’échanger avec des collaborateurs afin d’en apprendre plus sur nous ! PS : Si vous étudiez ou travaillez loin de Paris, nous vous proposons de suivre ce processus en full visio via le système Hangout Meets de Google. 🏊 Plongez dans la culture d’entreprise de Margo : - Rencontrez nos équipes à travers notre page WelcomeToTheJungle - Découvrez des retours d’expériences de consultants Margo sur notre page YouTube - N’hésitez pas à prendre connaissance des avis de nos collaborateurs sur GlassDoor Si vous ne vous reconnaissez pas dans cette offre, n’hésitez pas à prendre connaissance de nos autres opportunités 👉 nos offres d'emploi Engagée en faveur de l'égalité des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap.","Margo is a human-sized consulting firm that aims to accelerate the digital transformation of its clients by accompanying them in complex IT projects. They are looking for a Data Engineer with a Bac + 5 degree, a passion for coding and a strong interest in the latest technologies, with previous experience in the field. The successful candidate will work on a project to revamp a datalake and will have the opportunity to develop new skills and progress quickly. Margo values the satisfaction of its consultants and clients and has developed expertise in the finance, banking, insurance, and energy sectors. The company offers long-term missions and opportunities for internal growth, such as becoming a recruiter, trainer, manager, or writer. The hiring process includes online application, interviews with the HR and business managers, a technical interview, and a meeting with a member of Margo's management team to confirm cultural fit.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
80,56818,https://www.welcometothejungle.com/fr/companies/stime/jobs/data-engineer-h-f_chatillon_STIME_0o7rxkK,Data Engineer,Stime,"{Microsoft,Databricks,Scala,Parquet,Spark,Azure,SQL,Python}",Télétravail partiel possible,"117 Avenue de la République, Châtillon, 92320","Grande distribution, IT / Digital",CDI,2023-03-26,"La Stime répond au mieux et au plus vite aux enjeux de business, de performance et de transformation du Groupement Les Mousquetaires et particulièrement de ses points de vente. Elle propose des services, conçoit et délivre des solutions informatiques simples, innovantes et adaptées aux besoins et aux usages. La Stime s’appuie sur des relations de partenariat et de confiance avec les pôles de performance et les services d’appui ainsi que sur les compétences et l’engagement de ses collaborateurs. La Stime, DSI du Groupement Les Mousquetaires , est le moteur de la transformation informatique du Groupement Les Mousquetaires. Rejoindre la Stime c’est l’assurance de contribuer à des projets à fort enjeu et d’être challengé dans ses missions. Contexte Au sein de la Direction Digital & Data, l’équipe Data Lab intervient sur les périmètres Data et Analytics, dans le cadre du programme de transformation du SI du Groupement Les Mousquetaires. Vous aurez l’opportunité de rejoindre la Data Factory(STIME et Direction Data desenseignes Intermarché et Netto) dont la mission première est de déployer des produits Analytics innovants à destination des fonctions support et logistique, des magasins, et surtout des consommateurs. Après les premiers succès et des attentes de plus en plus fortes, nous passons désormais à l’échelle avec une nouvelle organisation Agile en Domaine/Tribu/Squad et la nécessité d’industrialiser nos pratiques pour accélérer la livraison des produits, tout en capitalisant mieux sur le patrimoine de données constitué. Vous aurez l’occasion d’intégrer une de nos squad dont la principale mission est de développer des cas d’usage BI, Analytics et Data Science déployés sur notre plateforme Data hébergée sur le Cloud Azure. Partant(e) pour l’aventure ? Concrètement quelles seront vos missions : Participation à des ateliers de définition de besoin avec le PO ou le métier Etude de besoin et proposition de solutions d’architecture sous la supervision d’un architecte solution Construction des pipelines de données pour collecter, transformer et traiter des données dans notre Data Lake sur Azure Développement de notebooks de traitement avancé des données sur Databricks (langage Scala ou PySpark) Conception et modélisation des données au niveau du Data Lake (format Parquet, Delta) Conception et modélisation de données pour alimentation d’une base de données SQL sur le cloud Azure Réalisation des tests unitaires, d’assemblage et d’intégration Rédaction de documentation technique (Dossier d'Analyse Technique, release delivery note, ….) Préparation de package pour livraison en CI/CD avec les équipes DevOps Réalisation des activités de maintenance corrective et évolutive Participation aux cérémonies agiles (Sprint Planning, Daily Scrum, Spring Review, Demo, Daily …) Participation aux animations proposées régulièrement par la communauté de Data (groupe de travail, meetup avec des partenaires tels que Microsoft, Databricks …) 💪 Les qualités indispensables à votre réussite : Excellent relationnel et capacités d’analyse. Réactif et force de proposition. Rigueur Curiosité et challenge Capacité à travailler en équipe Autonomie 👊 Nos forces : Un management qui favorise le travail collaboratif et s’appuie sur la co-construction Un environnement dynamique et stimulant Une excellente ambiance d’équipe. Vous aurez l’occasion d’intégrer une Data Factory composée de près de 120 compétences travaillant en mode agile. Vous serez intégré à une communauté active composée de plus 40 Data Engineer ou Data Scientist. Possibilité de participer à des hackathon avec d’autres Data Engineer ou Tech lead Accès à de nombreux e-learning proposés par nos partenaires (Microsoft, Databricks, …) Diplômé(e) d’un Bac+2 avec une expérience d'au moins 2 ans en data. Vous avez une appétence pour la Data, et possédez au moins une expérience dans la BI, Big Data et Analystics, avec une expérience dans le développement et l’implémentation de solutions Big Data, idéalement sur le Cloud et des compétences en développement informatique (langages : Spark, Scala, SQL, Python). Bonne maitrise des concepts DevOps, CI/CD et outils associés. Vous avez des capacités d’analyse, de présentation et de vulgarisation de votre travail et une bonne capacité d’écoute et de recueil d’informations en n’ayant pas peur d’entrer dans les détails d’un sujet technique ou métier. Les plus : Une certification sur Spark, Azure ou Databricks sont un plus. Connaissance des outils Agile (JIRA) et ayant déjà travaillé en mode Agile Envie d’une expérience enrichissante au sein d’une entreprise dynamique ? Rejoins-nous dans nos locaux à Châtillon (92).","The Data Engineer position at Les Mousquetaires Group involves collaborating with the Data Lab team in developing BI, analytics, and data science use cases for the Group's support, logistics, stores, and customers. The successful candidate must have at least two years of experience in data, strong technical skills in Big Data development and implementation, and proficiency in Spark, Scala, SQL, and Python. They must also have an understanding of DevOps and CI/CD concepts, be able to work independently and in teams, and possess excellent analytical, presentation, and communication skills. Certification in Spark, Azure, or Databricks is desirable.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
104,72845,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-integration-de-flux_paris,Data Engineer - Intégration de Flux,Assistance Publique - Hôpitaux de Paris - DSI,"{Linux,java,MySQL,Jupyter,Kafka,Jenkins,Scala,python,Nvidia,Talend,bash,via,Spark,SQL,Java,Python,Oracle,sql,Hadoop,Elastic,Docker,Kubernetes,NoSQL,Postgresql}",Télétravail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Santé",CDI,2023-04-22,"L’ Assistance Publique - Hôpitaux de Paris (AP - HP) est un établissement public de santé et le centre hospitalier universitaire - CHU - de la région Ile-de-France, reconnu mondialement pour sa recherche. Le département Web Innovation Données (WIND) s’inscrit au sein de sa Direction des Systèmes d’Information. Sa mission ? 🎯Réaliser les projets numériques innovants au contact du monde hospitalier. Ses projets phares ? 🚀 Construire le plus gros entrepôt public de données de santé en Europe ! Le projet vise à valoriser les données produites à l’AP-HP pour la recherche, l’innovation et le pilotage des soins, tout en protégeant les données patient. L’Entrepôt de Données de Santé, c’est déjà +10 millions de patients dont les données sont structurées et référencées sur une plateforme Big Data dédiée. 🙋‍♀️🙋‍♂Faciliter le quotidien des patients! Le domaine gère notamment toutes les applications mobiles et tous les téléservices de l’AP-HP. 🔬Monter une plateforme Bio-Informatique centrale pour assister les pôles de biologie de l’ AP-HP dans leurs besoins informatiques (gestion du séquençage, déploiement de ressources de calcul). 🌼Développer et déployer au niveau national les outils de collecte et d’analyse épidémiologique des données relatives aux maladies rares. La mission de votre équipe Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP. ​ L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision. ​ La Plateforme Big Data de l’AP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives. ​ Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP. ​ Vos missions Au sein de l’équipe en charge de la réalisation et du suivi des pipelines d’intégration de données, vous aurez pour missions de proposer et de développer de nouveaux flux de type ETL, de même que des outils ou composants spécifiques, adaptés à la typologie des sources (données structurées ou non structurées). Ces développements s’inscrivent dans un contexte exceptionnel de très grandes volumétries de données de santé avec des objectifs d’industrialisation des flux d’intégration et de standardisation des données selon le modèle de données commun OMOP et d’interopérabilité sur la base du standard d’échange HL7-FHIR. En tant que data engineer - intégration de flux, sous la responsabilité du chef d’équipe intégration de flux, vous contribuez aux activités transversales d’exploitation et collaborez avec les acteurs internes de l’infrastructure et de DevOps pour bâtir le socle de nos projets de recherche sur données médicales. Vos missions comportent typiquement des facettes suivantes : ​ Contribuez à la définition des besoins techniques et à l’accompagnement des chercheurs/médecins lors de la réalisation de projets de recherche impliquant de nouvelles sources de données Analyserez les différents sources de données d’un point de vue technique (acquisition, stockage, transformation, exploitation, …) Développerez, industrialiserez et maintiendrez les flux d’intégration de données (extraction, sélection, collecte et intégration) soit avec l’utilisation de l’ETL Talend + connecteurs spécifiques, soit via des développements en Spark/Scala Contribuerez à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en java, python ou d’autres langages Industrialiserez le code de génération du flux de données et assurer sa performance globale Aiderez à l’implémentation de standards et normes de mise à disposition des données (OMOP/FHIR) Développerez des méthodologies standardisées pour l’intégration de nouvelles données Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des données Travaillerez en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche Idéalement, vous.. Avez un diplôme d’ingénieur ou équivalent (bac+4/5, master2) en informatique ou sciences avec formation complémentaire en informatique Avez une expérience de développement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, …) et ETL (Talend ou autre) Avez une expérience dans la manipulation de données avec le langage SQL Connaissez les standards en informatique de santé (HL7 v2, DICOM, HL7-FHIR, OMOP, …) Avez le goût de l’intégration de systèmes informatiques hétérogènes Avez des connaissances des bonnes pratiques de sécurité informatique et de la réglementation informatique et libertés Adhérez aux valeurs du service public et vous avez un intérêt prononcé pour le domaine de la santé Avez un niveau d’anglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise du langage Python et de bash Bonnes connaissance des bases de données Oracle, Postgresql ou MySQL et langages associés (sql) Bonne maitrise en méthode de conduite de projet (planification, reporting, analyse de risques, …) Connaissance des outils ETL (Talend, …), d’informatique décisionnelle et des méthodes de data warehouse (OLTP, RDBMS…) Connaissance du traitement des données massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en méthodes de développement logiciel (dont cycle en V, méthodes agile), méthodes d’analyse et de modélisation (Merise, UML …) Connaissance en administration d’environnements Linux Connaissance des méthodologies devops et des outils associés (Docker, Kubernetes, Jenkins…) Et humainement ? Capacité à appréhender des enjeux liés à la recherche, à l’analyse de données et aux technologies de machine learning/deep learning, notamment dans le domaine de la santé (santé publique, imagerie médicale, épidémiologie, …) Esprit d’équipe et la volonté de prendre part à une aventure collective Sens de l’écoute, du résultat et de la qualité Des qualités d’autonomie, de flexibilité et de responsabilité Curieux, dynamique et créatif, avec un réel envie de faire preuve d’innovation 2-3 Entretiens Tél/Visio + Présentiel",,Bac +4,Entre 250 et 2000 salariés,> 1 an,2,1,0.04154662416233763
108,72949,https://www.welcometothejungle.com/fr/companies/schneider-electric/jobs/cloud-data-engineer-f-h_rueil-malmaison,Cloud Data Engineer,Schneider Electric,"{Github,Python,Presto,Scala,Microsoft,Azure,durable,Databricks,Spark,Kubernetes,Docker,R,AWS,Flink,Java}",Télétravail partiel possible,Rueil Malmaison,"Ingénieries Spécialisées, Objets connectés, Energie",CDI,2023-04-22,"Schneider Electric est leader mondial de la gestion de l’énergie et des automatismes. Nous concevons, réalisons et mettons en œuvre des solutions innovantes pour une gestion de l’énergie sûre, efficace, fiable et durable. La raison d’être de Schneider Electric est de permettre à chacun de tirer le meilleur de son énergie et de ses ressources, afin de concilier progrès et développement durable pour tous. Nous nommons cette ambition : Life is On. Notre mission est d’être le partenaire digital du développement durable et de l’efficacité de nos clients. Nous menons la transformation numérique en intégrant les technologies de l’énergie et des automatismes les plus avancées. Nous connectons jusqu’au cloud, produits, plateformes de contrôle, logiciels et services sur l’ensemble du cycle de vie de vos activités pour une gestion intégrée de l’habitat résidentiel, des bâtiments tertiaires, des data centers, des infrastructures et des industries. Chez Schneider Electric , nous nous engageons à résoudre des problèmes concrets pour créer un avenir électrique durable et numérisé. L' Intelligence Artificielle a le potentiel de transformer les industries et d'aider à débloquer l'efficacité et la durabilité.Au sein de notre Global AI Hub , nous combinons notre expertise de longue date en matière de fabrication et de domaine avec une innovation de pointe en matière d'IA, d'apprentissage automatique et d'apprentissage profond pour favoriser une prise de décision plus intelligente, l'agilité et la décarbonisation.Au sein de l'équipe AI Technology, nous recrutons un.e Cloud Data Engineer. Le groupe AI Technology (70 personnes) développe 2 plateformes d'IA s'appuyant sur Azure et AWS pour répondre aux besoins externes et internes. Vos responsabilités : Ingénierie de pipelines de données efficaces, évolutifs et adaptables pour traiter des données structurées, semi-structurées et non structurées. Maintenir et repenser les ensembles de données et les pipelines existants pour servir une grande variété de cas d'utilisation. Mettre en œuvre l'observabilité des données et surveiller les pipelines de données en production afin d'en assurer le bon fonctionnement. Agir en tant que partenaire de l'équipe d'ingénierie de la plateforme et de l'équipe d'apprentissage automatique, comprendre leurs défis et faire des recommandations avisées qui leur permettent d'avoir des solutions de données. Ecrire de l'infrastructure en tant que code pour déployer notre infrastructure de données Rédiger des travaux ETL pour collecter et agréger des données. Construire des modèles de données de haute qualité. Identification, mise en œuvre de composants et de bibliothèques partagés à réutiliser d'un contexte à l'autre. Spécification, conception, mise en œuvre, test, validation et industrialisation de fonctions avancées de gestion des données à intégrer dans les produits, systèmes et solutions. Collaboration avec des experts en données et en domaines afin d'identifier les méthodes, les outils et les technologies de transformation des données en vue d'élaborer des plateformes et des offres de produits. Contribution à l'identification et à l'évaluation de partenaires externes potentiels. Contribution à la protection de la propriété intellectuelle, à la capitalisation des connaissances et à la communication interne et externe. Votre profil : Master ou doctorat ou diplôme équivalent en traitement de données, informatique avec minimum 2 ans d'expérience. Expert en ingénierie de pipeline de données utilisant des technologies telles que Presto, Spark ou Flink et ou les services gérés équivalents des fournisseurs de cloud public. Compétences/expérience en génie logiciel : capacité à coder, déboguer, tester (y compris les tests unitaires, les tests fonctionnels et les tests d'intégration) et dépanner tout au long du processus de développement de l'application et en mode agile. Idéalement, connaissance du marché de la gestion et de l'automatisation de l'énergie. Orientation vers la résolution de problèmes, l'obtention de résultats et l'application de la technologie à des cas concrets. Compétences de communication efficaces, y compris une aptitude à raconter des histoires basées sur des données : convaincre avec des mots, avoir un impact avec des données et influencer avec des images. Autonomie ET capacité à coopérer. Ouverture d'esprit ET rigueur scientifique. Anglais courant. Technologies : Langages : Python, Java, Scala Plateformes cloud : Microsoft Azure, AWS Outils : Kubernetes, Databricks, Docker, Spark, OpenDataSoft, Github, Terraform.Notre offre comprend une rémunération attractive et va bien au-delà. Nous offrons des avantages compétitifs, un environnement de travail qui encourage le développement professionnel, un onboarding qualitatif et un accompagnement tout au long des différentes étapes de votre vie (formation, opportunités de carrière, parentalité, flexibilité…), dans un lieu de travail formidable.Pourquoi nous? Schneider Electric est le chef de file de la transformation numérique de la gestion et de l'automatisation énergétique. Nos technologies permettent au monde d'utiliser l'énergie de manière sûre, efficace et durable. Nous nous efforçons de promouvoir une économie mondiale à la fois viable sur le plan écologique et hautement productive. 25,7 milliards d'euros de chiffre d'affaires global 137 000+ employés dans plus de 100 pays 45 % du chiffre d'affaires de l'IdO 5 % du chiffre d'affaires consacré à la R&D Vous devez soumettre une demande en ligne pour être pris en considération pour ce poste. Ce poste sera posté jusqu'à ce qu'il soit rempli.",,Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
109,72959,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/analytics-engineer-h-f-cdi_paris,Analytics Engineer  - CDI,Publicis France,"{GCS,Python,Epsilon,Spark,NoSQL,AWS,SQL,bigquery,GCP}",Télétravail partiel possible,"30-34 Rue du Chemin Vert, Paris, 75011","Marketing / Communication, Publicité, Digital, Relations publiques, AdTech  / MarTech, Evénementiel, Design",CDI,2023-04-22,"Leader français du marketing, de la communication et de la transformation digitale des entreprises, le groupe Publicis s’appuie sur un modèle unique qui allie créativité, technologie, médias avec au cœur la data. Présidé par Agathe Bousquet, Publicis Groupe en France est une Talent company riche de plus de 5 000 collaborateurs, répartis dans 26 agences, qui accompagnent près de 600 clients. En France, le groupe est organisé autour des activités de création avec les agences Publicis Conseil, Marcel, Leo Burnett Paris, Saatchi & Saatchi, Publicis Consultants, PublicisLive, Carré noir, Publicis Luxe, Prodigious, Razorfish. Le groupe est également un acteur puissant des medias avec ses agences Publicis Media, Starcom, Zenith, Spark Foundry, Blue449, Performics. Enfin il intervient dans la transformation numérique avec Publicis Sapient, et dans la data avec Epsilon. Ainsi grâce à une puissante alchimie, de la créativité et de la technologie, Publicis pilote la transformation des entreprises sur toute la chaine de valeur. La responsabilité sociétale de l’entreprise (RSE) irrigue tous ces métiers et fait partie intégrante de la stratégie globale de Publicis. Le groupe est par ailleurs le premier réseau en nombre d’agences à avoir obtenu le label RSE Agences Actives délivré par l’AACC avec 12 agences labellisées. Publicis, c’est aussi « Viva la différence ! ». Persuadé que la diversité est un puissant moteur de créativité et de performance, Publicis s’engage sur de nombreux sujets pour promouvoir l’égalité des chances et renforcer l’égalité des origines. Le groupe est convaincu que la somme de ses différences fait sa richesse. Vous êtes rattaché.e au Lead Data & Analytics de Publicis Media et serez en charge de la structuration et de la livraison des projets Analytics (ingestion de sources de données, traitement, transformation, modélisation et restitution), entre autre associés aux équipes Data Science & Data Engineering, mais également structurants pour poursuivre les travaux de transformation de l’entreprise et de ses usages. L’Analytics Engineer occupe un rôle central dans notre stratégie Data, en sa capacité à pouvoir contribuer à convertir la donnée en connaissance, tout en s’appuyant sur la technologie, à poursuivre la conception de la prochaine génération d’algorithmes. Ce que vous ferez La construction de pipelines Data depuis la collecte jusqu’à la restitution Le rapatriement et l’ingestion de données de multiples sources (Cloud – GCS, AWS… – SFTP, API…) L’utilisation des Best Practices pour la création des data models L’automatisation de l’analyse au travers des mécanismes de monitoring et d’alerting, en post-déploiement La gestion du suivi et livraison des projets associés – depuis la conception, au développement, testing, et opérations associées Les défis associés Richesse des environnements : de multiples sources, de multiples environnements dans un écosystème en perpétuel mouvement impliquent une grande capacité à pouvoir les aborder pour rassembler les données attenantes Media, Marketing, CRM… : des données de nature différentes (First, Third…), en grande quantité, à forte granularité, réunies pour en déduire les meilleurs insights Scalabilité : la quantité de donnée de chaque Client peut être conséquente, mais le travail de transformation et processing peut l’être davantage Respect de la vie privée, gestion des données personnelles : nous pouvons être amenés à traiter de la donnée Media mise à disposition sur des “Clean Rooms” (Google, Facebook, Amazon…) Gestion des coûts : méthode & rigueur sont essentielles pour optimiser les dépenses de stockage et computing de la donnée (en interne ou pour le compte de nos clients) Qualifications Formation d’ingénieur.e en informatique (ou assimilé.e), méthodes Agile ; vous disposez de 2 ans minimum d’expérience dans l’administration, configuration, monitoring, débogage et mise en oeuvre d’une solution Cloud (GCP idéalement), ainsi que dans les mécanismes d’intégration (fichiers, messages, data…).
La certification Google Cloud Engineer est recommandée, ainsi que la pratique de l’anglais. Expertises & compétences Langages de développement : Python, SQL, Basch Compétences : manipulation de données en SQL / NoSQL Expertise : Google Cloud Platform (Cloud Functions, Cloud Run, Cloud Pub/Sub, Cloud Workflow, Dataplex, CI/CD…), Amazon Web Services… Connaissance des mécanismes de constitution d’ETL, technologies d’orchestration (Workflow, cloud scheduler, …). Des connaissances en Terraform et en bigquery est un plus Phases de testing ; documentation du code",,Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
128,73414,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/cloud-engineer_paris_WEWYS_dmjMkk,Cloud Engineer,Wewyse,"{Python,Jenkins,Azure,Shell,unix,Docker,Kubernetes,AWS,Java,GCP}",Télétravail partiel possible,"48 Rue du Château d'Eau, Paris, 75010","Digital Marketing / Data Marketing, IT / Digital, Transformation",CDI,2023-04-22,"Wewyse est le cabinet de conseil de Wemanity, spécialisé en Data et en Intelligence Artificielle. C’est aussi et surtout une communauté de passionnés partageant l’ambition de grandir ensemble et d’ouvrir le champ des possibles dans leurs domaines. Nous apportons conseil et expertise technique pour définir avec nos clients les stratégies et solutions adaptées à leurs enjeux, puis nous les accompagnons dans les phases de conception et de déploiement. Être Cloud Engineer chez Wewyse, c’est : planifier, designer et développer des applications sur le cloud, maintenir et réaliser le support des architectures cloud, migrer des applications on-premise vers le cloud, intervenir chez des clients pour y porter l’expertise Wewyse dans des contextes et des secteurs variés, recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements, participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up, être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière. Chez Wewyse, nous aimons : Les providers cloud : AWS, GCP, Azure Les langages Java, Python, Shell unix Les API La conteneurisation : Docker et Kubernetes Les outils DevOps : Jenkins, Ansible , Terraform La sécurité : VaultLes méthodes Agiles Les personnalités ouvertes, curieuses, ambitieuses L’anglais",,Bac +5 / Master,Entre 15 et 50 salariés,> 1 an,2,1,0.04154662416233763
148,56344,https://www.welcometothejungle.com/fr/companies/lectra/jobs/ingenieur-data-data-engineer-h-f_cestas,Ingénieur Data / Data Engineer,Lectra,"{Microsoft,Jenkins,Git,Scala,Kubernetes,Snowflake,Docker,Kafka,Linux,via,Spark,RabbitMQ,Azure,Java,SQL,Python}",Télétravail partiel possible,"23, Chemin de Marticot, Cestas, 33610","Logiciels, SaaS / Cloud Services",CDI,2023-03-26,"Acteur majeur sur les marchés de la mode, de l’automobile et de l’ameublement, Lectra contribue au développement de l’industrie 4.0 avec audace et passion. Le groupe propose des solutions d’intelligence industrielle à la pointe de la technologie qui facilitent la transformation digitale des entreprises. Grâce à ses logiciels, équipements, données et services, Lectra aide ses clients à repousser les frontières et à libérer pleinement leur potentiel. Ses 2 400 collaborateurs sont guidés par trois valeurs fondamentales, qui font la fierté du groupe : faire preuve d’ouverture d’esprit, être des partenaires de confiance et innover avec ardeur. Fondée en 1973, Lectra a réalisé un chiffre d’affaires de 521 millions d’euros en 2022 et est cotée sur Euronext (LSS). Pour plus d’informations, visitez lectra.com. Tu recherches une nouvelle expérience de Data Engineer (H/F) alors on a un job pour toi ! Tes missions : • Tu participeras aux études et phases exploratoires des projets Data, • Tu réaliseras en équipe la conception et l’implémentation des solutions en gardant un haut niveau de qualité, • Tu livreras régulièrement de la valeur en production et tu sauras mettre les outils nécessaires à la supervision de ton développement, • Tu participeras à l’amélioration continue de l’équipe (pratiques de développement, organisation d’équipe, etc) • Tu rechercheras la techno la plus adaptée pour garantir la sécurité, la scalabilité des solutions et l’expérience utilisateur la plus optimale Environnement technique • Linux préféré ou Windows • Snowflake, Apache Spark, Azure Datalake, Apache Kafka, RabbitMQ • SQL, Scala, Kotlin, Python, Java • Cloud : Microsoft Azure, Docker, Kubernetes • Outillage : Git, Jenkins • Méthodologie : Agile (Kanban), pair/mob programming, code review. Tes formations / compétences : Tu as une formation Bac+5 souhaitée en développement logiciel ou équivalent, Tu as une expérience significative déjà en tant qu’Ingénieur Data ou dans le développement logiciel orientée vers la donnée, Tu recherches le sens et la valeur des fonctionnalités qui te sont demandées, Tu aimes développer en suivant les bonnes pratiques dans un environnement en intégration continue, Tu as l’habitude de travailler en équipe et de partager ton point de vue, Tu connais au moins un de ces composants des Data Platforms modernes (Snowflake, Azure Datalake, Apache Spark, Apache Kafka, …) et tu maîtrises un langage de développement (idéalement Scala ou Kotlin, Python, Java) en sus du SQL, Tu sais structurer la donnée (relationnel, dimensionnel ou document) pour la rendre le plus facilement exploitable. Tu es sensible aux problématiques de qualité (de la donnée et des livrables), tests et Architecture As Code. Tu es ouvert(e) à l’agilité et au travail en équipe. Ce que l’on te propose chez Lectra ? • De faire émerger une architecture en équipe dans la bonne humeur et le partage, • De travailler sur des projets Data avec une stack de traitement et des langages et frameworks modernes, • De déployer en continu ton code avec une culture intégrée des tests, • Travailler sur des problématiques d’une plateforme donnée, et de traitements par lot ou temps réel des données, • De travailler dans un environnement Agile, • De fortement collaborer avec les autres membres de l’équipe à travers le pair-programming, le mob-programming et les revues de code fréquentes, • De bénéficier de la souplesse du travail dans le Cloud Azure, • D’aller à des conventions et conférences à travers le monde (Devoxx, Dataquitaine, AgileFrance, MixIT, BDX I/O, Kafka SUMMIT et bien d’autres), • De bénéficier de nos nombreuses formations internes et externes, • De conserver un équilibre vie pro/vie perso (70 jours de télétravail par an, CSE, restaurant d’entreprise, …), • Des activités sportives et ludiques entre midi et 2 (club de jeux, badminton, running, cross training, …). Le poste est basé à Cestas (23 chemin de Marticot) - pour nous rejoindre : avec possibilité de télétravail : 1 jour et demi par semaine. • Accessible par l’autoroute sortie 25 de l’A63 (parking voiture et deux-roues sur place) • Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de vélo/trottinette pour accéder au campus sur piste cyclable hors route. • Depuis Pessac - Arrêt Unitec via le Transgironde 602 : arrêt Marticot : 20min.","Lectra, a major player in fashion, automotive, and furniture markets, is looking for a Data Engineer with experience in software development and data orientation. The successful candidate will work on data projects, participate in the design and implementation of solutions while ensuring high quality and supervising the development. Skills required include experience in at least one component of modern data platforms and proficiency in one or more programming languages. The role is based in Cestas, with the possibility of teleworking. Lectra offers benefits that include 70 working days of telecommuting per year, sports and leisure activities, and international conventions and conferences.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
140,50015,https://www.welcometothejungle.com/fr/companies/itera-cz/jobs/middle-data-integration-application-support-engineer_brno,Middle Data Integration Application Support Engineer,Itera Czechia,"{Microsoft,Oracle,SAS,Denodo,PostgreSQL,Informatica,Linux,Azure,SQL,Python,Bash}",Télétravail partiel possible,"Vlněna, Brno, 602 00",Logiciels,CDI,2023-02-07,"Itera is a Norwegian IT consulting company, which spreaded thoughout the whole Europe during its nearly 30 years existence and recently opened a brand new office in the most modern co-working space in Brno, Czechia. People in Itera work on various projects in the banking and insurance sector explicitely for Scandinavian clients, mostly Norwegian companies. It’s the Norwegian origin which makes Itera so special and imprints into its atmosphere, culture and values. The most important aspects are: Equality and trust: Itera gives every consultant a space for self-realisation and stands as an equal partner to its clients, where proactivity, open and honest feedback and clear communication are the basic essence. Work-life balance: Instead of overtimes and pressure from upcoming deadlines, consultants in Itera have an opportunity to adjust work according to their time possibilities. The biggest priority is to deliver high-quality solutions. “Itera fit”: Itera carefully chooses new colleagues not only according to their technical skills and experience, but complex communication skills are similarly important. They also love to spend time together not only at work, but also on a teambuilding, sports activities or playing games. Itera is looking for a Middle Application (Data Integration) Support Engineer with a wide experience within IT operations, system engineering, client-server Data Analytics and Reporting applications support, for one of Itera customers which provides services in financial sector. Strong technical background, problem analysis skills, and good communication skills are essential. Tasks and responsibilities: Client-server application support: maintenance, troubleshooting, consultancy etc. Data ETL (Extract, Transform, Load) tasks development, deployment, and support Routines automation, reports development Code performance improvements Work with a global team spread across tech hubs in multiple geographies and time zones Perform root-cause incident analysis to gather findings and identify follow-up actions that lead to more reliable products 1+ year experience with systems/applications support, preferably Data Integration, Analytics & Reporting systems Microsoft stack: Windows 10/11, Servers Experience with database administration (e.g., MS SQL Server, PostgreSQL, Oracle) T-SQL basic knowledge Network and AD basics Familiarity with logging, monitoring and metric collection systems Experience in configuration, deployment and maintenance of cloud-based infrastructure (Azure) Scripting languages: PowerShell (Python, Bash, SAS be a plus) Hands-on experience with Azure DevOps Understanding of L1-L3 support chain Excellent troubleshooting skills Experience with ServiceNow or similar tracking system Passion for continuously striving to improve the customer experience Strong desire to current on technical trends in order to suggest innovative tools and approaches to interesting problems Will be a plus if you have: SAS Analytics support experience and basic programming skills Denodo Platform support experience Any Data integration system support experience (Informatica, HP Connect-IT etc.) DevOps skills and experience Linux administration Data Engineer skills – Cloud (Azure)/On-prem Step 1: prescreen with our recruiter (phone/MS Teams/etc.) Step 2: 1st round ITW (online/f2f) * part 1 with Recruiter & People manager will give you more info about how we operate * part 2 with our technical colleague will provide you a chance to discuss tech details and your competence Step 3: 2nd round ITW with our Director of Itera Czechia (online/f2f) Step 4: offer :)","Itera is seeking a Middle Application (Data Integration) Support Engineer with experience in IT operations, system engineering, data analytics, and reporting applications support in the financial sector. Strong technical and communication skills, as well as problem analysis skills, are necessary for the role. The ideal candidate will have experience with Microsoft stack, database administration, network and AD basics, and cloud-based infrastructure. The company values work-life balance, teamwork, and communication skills.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
139,56572,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-modelisation-standardisation_paris,Data Engineer - Big Data,Assistance Publique - Hôpitaux de Paris - DSI,"{Oracle,python,bash,Nvidia,Docker,Postgresql,MySQL,scala,Talend,Kafka,Linux,NoSQL,Elastic,java,Jenkins,Kubernetes,Java,SQL,Hadoop,Jupyter,Scala,via,Spark,sql,Python}",Télétravail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Santé",CDD / Temporaire,2023-03-26,"L’ Assistance Publique - Hôpitaux de Paris (AP - HP) est un établissement public de santé et le centre hospitalier universitaire - CHU - de la région Ile-de-France, reconnu mondialement pour sa recherche. Le pôle Innovation& Données (ID) s’inscrit au sein de sa Direction des Services Numériques. Sa mission ? 🎯Réaliser les projets numériques innovants au contact du monde hospitalier. Ses projets phares ? 🚀 Construire le plus gros entrepôt public de données de santé en Europe ! Le projet vise à valoriser les données produites à l’AP-HP pour la recherche, l’innovation et le pilotage des soins, tout en protégeant les données patient. L’Entrepôt de Données de Santé, c’est déjà +12 millions de patients dont les données sont intégrées, structurées et référencées sur une plateforme Big Data dédiée. 🙋‍♀️🙋‍♂Faciliter le quotidien des patients! Le domaine gère notamment toutes les applications mobiles et tous les téléservices de l’AP-HP. 🔬Monter une plateforme Bio-Informatique centrale pour assister les pôles de biologie de l’ AP-HP dans leurs besoins informatiques (gestion du séquençage, déploiement de ressources de calcul). 🌼Développer et déployer au niveau national les outils de collecte et d’analyse épidémiologique des données relatives aux maladies rares. La mission de votre équipe Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP. ​ L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision. ​ La Plateforme Big Data de l’AP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives. ​ Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP. ​ Vos missions Au sein de l’équipe en charge de la Plateforme Big Data de l’APHP, vous aurez pour missions de proposer et de développer des outils ou composants répondant aux attentes des médecins et chercheurs pour l’exploitation des données collectées dans le cadre de leurs projets de recherche. Ces développements s’inscrivent dans un contexte de standardisation des données selon le modèle de données commun OMOP et d’interopérabilité sur la base du standard d’échange HL7-FHIR. En tant que data engineer - données massives, sous la responsabilité du chef d’équipe développement données massives, il s’agira de contribuer à la création d’outils d’intégration, de visualisation, d’exploration et d’enrichissement de données médicales pour la recherche, souvent en lien direct avec des personnels médicaux. Outre l’intégration technique des données cliniques, les développements relèvent globalement de la pseudonymisation des données pour assurer la confidentialité des dossiers médicaux, de la standardisation des modèles de données, de la mise en place de moteurs de recherche performant incluant des notions sémantiques et de l’analyse qualitative et statistique des données collectées. Selon la typologie des données (données structurés, imagerie, voix, signaux physiologiques, etc.) des outils plus spécifiques sont également mise en œuvre. Vos missions comportent typiquement des facettes suivantes : ​ Contribuez à la définition des besoins techniques et à l’accompagnement des datascientists, chercheurs, et médecins lors de la réalisation de projets de recherche impliquant de nouvelles sources de données Analyserez les différents sources de données d’un point de vue technique (acquisition, stockage, transformation, exploitation, …) Développerez, industrialiserez et maintiendrez des traitements de données (extraction, sélection, collecte et intégration) dans un contexte big data (développements en Spark/Scala) Contribuerez à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en java/scala, python ou d’autres langages Aiderez à l’implémentation de standards et normes de mise à disposition des données (OMOP/FHIR) Industrialiserez le code de génération du flux de données et assurer sa performance globale Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark) Développerez des méthodologies standardisées pour l’intégration de nouvelles données Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des données Travaillerez en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche Idéalement, vous.. Avez un diplôme d’ingénieur ou équivalent (bac+4/5, master2) en informatique ou sciences avec formation complémentaire en informatique Avez une expérience de développement sous Linux, des langagage Java/Scala et si possible Python Avez une expérience dans la manipulation de données avec le langage SQL Connaissez les standards en informatique de santé (HL7 v2, DICOM, HL7-FHIR, OMOP, …) Avez le goût de l’intégration de systèmes informatiques hétérogènes Avez des connaissances des bonnes pratiques de sécurité informatique et de la réglementation informatique et libertés Adhérez aux valeurs du service public et vous avez un intérêt prononcé pour le domaine de la santé Avez un niveau d’anglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise des langages Java/Scala (Spark), Python et de bash Bonnes connaissance des bases de données Oracle, Postgresql ou MySQL et langages associés (sql) Bonne maitrise en méthode de conduite de projet (planification, reporting, analyse de risques, …) Connaissance des outils ETL (Talend, …) et des méthodes de data warehouse (OLTP, RDBMS…) Connaissance du traitement des données massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en méthodes de développement logiciel (dont cycle en V, méthodes agile), méthodes d’analyse et de modélisation (Merise, UML …) Connaissance en administration d’environnements Linux Connaissance des méthodologies devops et des outils associés (Docker, Kubernetes, Jenkins…) Et humainement ? Curieux, dynamique et créatif, avec un réel envie de faire preuve d’innovation Esprit d’équipe et la volonté de prendre part à une aventure collective Sens de l’écoute, du résultat et de la qualité Capacité à appréhender des enjeux liés à la recherche, à l’analyse de données et aux technologies de machine learning/deep learning dans le domaine de la santé (santé publique, imagerie médicale, épidémiologie, …) Des qualités d’autonomie, de flexibilité et de responsabilité 2-3 Entretiens Tél/Visio + Présentiel","The AP-HP is seeking a data engineer with experience in developing big data tools to join their Plateforme Big Data team. The successful candidate will contribute to the integration, visualization, exploration, and enrichment of medical data for research, as well as developing methodologies for the integration of new data. Candidates must have experience with Java/Scala, SQL, and HL7-FHIR, as well as an understanding of data security and privacy regulations. Strong teamwork skills, curiosity, and creativity are also desirable qualities.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
138,50060,https://www.welcometothejungle.com/fr/companies/april/jobs/data-analytics-engineer_lyon,DATA Analytics Engineer,APRIL,"{Dataiku,Mongo,Snowflake,R,SQL,Python}",Télétravail partiel possible,"114 Bd Marius Vivier Merle, Lyon, 69003","Logiciels, Assurance, Big Data",CDI,2023-02-07,"Les 2 300 collaborateurs d’APRIL dessinent au quotidien le futur de l’assurance en proposant à leurs clients et partenaires – particuliers, professionnels et entreprises – une expérience remarquable alliant le meilleur des relations humaines et de la technologie. APRIL est le créateur et le leader du courtage grossiste en assurance en France avec un réseau de plus de 15 000 courtiers partenaires. Nous sommes aujourd’hui un acteur reconnu en France, en Europe, en Asie et en Amérique du Nord pour nos savoir-faire en santé et prévoyance des particuliers, professionnels et TPE, en assurance des emprunteurs, en santé internationale et en dommages de niches. Rejoindre APRIL et prendre soin du futur c’est : • choisir un métier dont vous pourrez être fier : «accompagner et protéger à chaque moment qui compte, simplement» telle est la mission et la raison d’être partagée par l’ensemble de nos collaborateurs, • développer votre expertise dans un environnement en pleine transformation, au carrefour de l’innovation et de l’expérience client : notre ambition à horizon 2023, être un acteur digital, omnicanal et agile, champion de l’expérience client, • vous engager au sein d’une entreprise engagée : nous rejoindre, c’est faire partie d’un groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de 4 axes (santé, aidants, éducation et environnement) avec un impact sociétal positif et réel. APRIL a obtenu la médaille d’argent EcoVadis pour la 2ème année consécutive Véritable industrie de la donnée, rejoignez le monde de
l’assurance et mettez votre expertise au service de la valorisation de notre
patrimoine informationnel ! Votre objectif :
éclairer et objectiver les prises de décisions des différentes parties
prenantes de l'entreprise. Et si être « DATA Analytics Engineer » chez APRIL vous permettait … de choisir un métier dont vous pourrez être fier : «accompagner et protéger à chaque moment qui compte, simplement» telle est la mission et la raison d’être partagée par l’ensemble de nos collaborateurs, de développer votre expertise dans un environnement en pleine transformation, au carrefour de l’innovation et de l’expérience client : notre ambition à horizon 2023, être un acteur digital, omnicanal et agile, champion de l'expérience client, de vous engager au sein d'une entreprise engagée : nous rejoindre, c’est faire partie d’un Groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de 4 axes (santé, aidants, éducation et environnement) avec un impact sociétal positif et réel. Nous nous engageons à promouvoir des emplois respectant la diversité et la différence, ouverts à chacun. VOS FUTURES MISSIONS : Gestion des données et support à la décision Participer aux ateliers d'expression des besoins internes métiers comprendre leurs problématiques et les traduire de manière analytique, Extraire les données nécessaires à l'analyse, Analyser les données (modèles et tests statistiques) Restituer les résultats des analyses sous forme de tableaux de bord Echanger sur les résultats et les solutions avec les équipes métiers, Participer au contrôle de la qualité des données tout au long de leurs traitements Veille et développement de l'activité Contribuer à la promotion de la culture data au sein de l'entreprise, Assurer une veille technologique sur les outils d'analyse de la donnée. Cette opportunité est à pourvoir dans le cadre d'une création de poste Directement rattaché.e à Samuel , Chief Data Officer , vous rejoindrez l'équipe DIAG (Data Innovation & Analytics group) basée à Lyon. Dès votre arrivée, vous bénéficierez d'un parcours d'intégration pour favoriser votre prise de poste. Vous disposez au minimum d'un Bac +3en statistique et traitement de l'information ou Datamining ou économétrie ou informatique décisionnelle . NOTRE COLLÈGUE IDÉAL : ·Est curieux et passionné : Il fait grandir son équipe en partageant son savoir et sa veille ·Est autonome et proactif : Il challenge l’existant et est force de proposition pour améliorer les produits logiciels et les pratiques. ·Travaille en équipe agile : Il est orienté création de valeur et est soucieux de la pertinence et de la qualité des produits délivrés. Vous pourrez également mettre à profit : vos compétences techniques : langages de programmation (Python, R, SQL), création d'applications data (Dataiku, Streanlit), Base de données (Snowflake, SQL Server, Mongo), Maitrise de l'anglais. vos compétences transverses : Orientation client, Capacité d'analyse et esprit critique, travail collaboratif Cette opportunité est faite pour vous ? N'attendez plus pour postuler en nous adressant votre CV accompagné de quelques lignes sur votre projet professionnel et ce qui pourrait vous épanouir aujourd'hui. Ce sera la première étape de notre processus de recrutement. Si vous n’êtes pas sûr(e) que cette offre soit LA bonne, d’autres postes sont à pourvoir , alors n’hésitez pas à consulter notre site carrière et/ou notre page Linkedin !","APRIL, a leading wholesale insurance brokerage firm in France, is seeking a Data Analytics Engineer to join its Data Innovation and Analytics group in Lyon. The ideal candidate should have a minimum of a bachelor's degree in statistics, data mining, econometrics, or decision-making informatics. The job responsibilities include extracting and analyzing data, ensuring data quality control, participating in technology watch activities, contributing to increasing data culture, and promoting the company's corporate social responsibility initiatives. The candidate should be curious, passionate, autonomous, proactive, and capable of working in an agile team-oriented environment. Technical skills required include knowledge of programming languages (Python, R, SQL), data application design (Dataiku, Streamlit), database management (Snowflake, SQL Server, Mongo), and proficiency in English.",Bac +2,> 2000 salariés,> 4 ans,2,1,0.04154662416233763
135,39848,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-confirme-h-f_lyon,Data Engineer  Confirmé,ASI,"{UNIX,GitHub,Cassandra,Elasticsearch,Docker,Azure,Microsoft,GitLab,SAP,MySql,Kafka,Linux,NoSQL,SAS,Jenkins,Kubernetes,AWS,HBase,Teradata,Java,Hadoop,SQL,Javascript,Scala,Redshift,Spark,GCP,Python}",Télétravail partiel possible,Lyon,"IT / Digital, Transformation, Big Data",CDI,2022-11-29,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Et si vous développiez votre expérience Data avec ASI ? Vous avez un parcours professionnel sur l’ensemble de la chaine de traitement de la data ou bien vous venez du monde du développement d’application/web avec une appétence particulière à l’exploitation de la donnée … N’attendez plus Rejoignez une équipe en plein développement et participez à l'enrichissement de notre expertise de la DATA En tant que Data Engineer , vous intervenez pour nos principaux clients en expertise ou sur des projets à fort enjeux : - Vous apporterez une expertise en Big Data , - Vous serez amené à travailler avec des systèmes de bases de données, - Vous concevez des plateformes permettant de traiter des volumes importants de données, des API et des outils pour les process ETL , - Vous faites de la modélisation de données, - Vous veillez à la sécurisation des pipelines de données, - Vous réalisez une veille technologique constante. Leader technique, vous pourrez être amené à encadrer techniquement et à coacher une équipe de développement. Le poste est à pourvoir dès que possible ! A compétences égales, ce poste est ouvert aux personnes en situation de handicap. Qui êtes-vous ? Créateur de systèmes, vous êtes celui qui développe, teste, met en place des architectures data. Vous créez des bases de données, gérez des gros volumes et organisez les flux de données entre les sources et les bases de stockage. Passionné(e) par la technologie et ses différents cas d'usage, vous disposez de plusieurs expériences significatives. Compétences clés du Data Engineer : - Maîtrise des langages structurés : Scala, Java, Javascript, Python, - Maîtrise de divers systèmes d’exploitation : UNIX, Linux, Windows, - Connaissances en solutions de bases de données : SQL, MySql, Teradata, Microsoft SQL Server, SAS Base, SAP Hana, - Connaissances des systèmes NoSQL : Elasticsearch, HBase, Cassandra, Redshift - Forte expertise le stockage de données et les outils ETL, - Maîtrise des technologies du Big Data permettant le traitement et la manipulation de données (Hadoop, Spark, Kafka…), - Outils DevOps, intégration et déploiement continu : Jenkins, Ansible, GitHub, GitLab, création de CI/CD, Docker, Kubernetes… - Être à l’aise dans des environnements cloud : Azure, AWS, GCP, - La maitrise de l’anglais est un plus. Le profil aura une expérience supérieure à 2 ans sur ce type d'environnement. Qualités du Data Engineer attendues : - Sens de la qualité, - Réactivité, - Esprit analytique et de synthèse, - Esprit d’équipe et excellent relationnel. Curieux(se) et disposé(e) à élargir votre champ de compétences à de nouvelles technologies, vous faites preuve de rigueur et êtes force de proposition sur l'amélioration des pratiques et les sujets à étudier. Vous souhaitez rejoindre une équipe dynamique ? Rejoignez-nous","ASI, a digital expertise firm, is seeking a Data Engineer with expertise in Big Data, databases, ETL, data modeling, and data security. The successful candidate should have experience with programming languages such as Scala, Java, Javascript, and Python, as well as operating systems such as UNIX, Linux, and Windows. Experience in cloud environments, DevOps, continuous integration and deployment, and Big Data technologies such as Hadoop, Spark, Kafka, Elasticsearch, HBase, Cassandra, and Redshift are required. The position requires at least two years of experience, analytical and synthetic thinking, and teamwork skills.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
134,39691,https://www.welcometothejungle.com/fr/companies/efounders/jobs/backend-data-engineer-delteer_paris,Backend Data Engineer @Delteer,eFounders,"{React,go,DynamoDB,ElasticSearch,Django,Typescript,Gitlab,PostgreSQL,AWS,Lambda,Elasticsearch,Sentry,Docker,Datadog,NoSQL,Python}",Télétravail partiel possible,"9, Rue Ambroise Thomas, Paris, 75009","Incubateur / Accélérateur, Accompagnement d'entreprises",CDI,2022-11-29,"About eFounders Together with entrepreneurs, we turn unique ideas into successful companies. We build businesses that create the tools of tomorrow and inspire new ways of working , in short, we build the future of work! Startup studio eFounders was the first to pioneer the model in 2011 and has since launched over 32 companies (7 of them have made exits) with $700M in funding and now reaching a valuation of over $3 billion - including unicorns Aircall & Spendesk. Our companies : Front • Mailjet • Aircall • Spendesk • Forest • Upflow • Collective • Numeral • and +28 other startups and many more to come 🚀 👋 Who we are We’re reinventing the old-shool loyalty programs of brands ! Today’s consumers have changed. They support brands which are aligned with their identity & their values. They want to be contributors, to feel part of a community. But brands are unequipped to federate their community in such a way. That’s why we’ve built Delteer. Delteer is the new way for brands to engage their customers and turn them into active stakeholders. With our mobile app, brands can offer engaging activities to their customers, and reward them for their participation. It’s a win-win for brands and consumers : consumers get a more engaging & rewarding experience from their favorite brands, and brands turn their consumers into loyal advocates ! Things are moving fast ! We just closed a Pre-Seed round and joined eFounders Web3 startup studio, 3Founders. We’re looking for motivated and talented people to join the adventure! The Team Delteer was co-founded by two brothers: Pierre , CEO - ex Project Leader @ Boston Consulting Group (6 years) Louis , CTO - ex Lead Data Scientist @ Mazars (4 years) 💼 What you’ll do We are looking for a Backend Data Engineer. This is a unique opportunity to join the latest eFounders project as one of the first Engineer and have a huge impact on the product and technical stack. You will work closely with Louis , our CTO, and Delteer’s Engineering team to build a world class data pipeline. Responsibilities: Contribute to design, implementation and documentation of the Delteer’s core data pipeline Work closely with the founders and product team to shape data pipeline new components to feed future application features Leverage open-source and in-house technologies to improve the stack Design indexing schemas to foster query efficiency Keep Delteer’s technical stack up-to-date with industry standards and technology developments. 3+ years in Data Engineering : experience working with Python (Django is a plus), NoSQL databases (Elasticsearch / Opensearch - DynamoDB) Ownership mentality : you are a doer and have a bias for action, no task is below you. You like to own projects from start to finish Long-term vision : you know how to set best practices to ensure code quality, reusability and maintenance in the long run Entrepreneurial mindset : you thrive in fast-paced environments where you have broad responsibilities. You are ambitious and want to take a part in the development of a world-class product and company Problem solver : you know how to deconstruct complex problems to use appropriate technologies to meet requirements Team player : you perform well in a group and enjoy sharing knowledge with your peers 🛠️ Technical stack Backend: Python, Django, PostgreSQL, ElasticSearch, OpenSearch, DynamoDB, Thirds party APIs (Discord, etc.) Frontend: React, React Native, Typescript, Chart.js / Detroit.js Infra: AWS Serverless (Lambda, Eventbridge, Fargate - CDK Python), Docker Monitoring: Datadog, Sentry Version control: Gitlab ⭐ What we offer! Competitive compensation and equity package Great working environment surrounded by very cool and talented people in the center of Paris (75009) - we are looking for people committed to building a great team, but we are remote flexible ! Challenging work experience building and owning an ambitious product Quality-driven environment A strong product and technical culture *eFounders is committed to creating a diverse environment. All qualified applicants will receive consideration for employment irrespective of gender, origins, identity, background and sexual orientations. We are aware there’s a long way to go with regards to diversity in our industry, which is why we encourage all applicants- and especially those listed above- to apply to our open positions.*","Delteer, a loyalty scheme start-up that enables brands to engage with customers and turn them into ""active stakeholders"" is looking for a back-end data engineer to join its engineering team in Paris. Founded by the CEO, Pierre, a former project leader at the Boston Consulting Group, and CTO Louis, an ex-lead data scientist at Mazars, Delteer offers mobile clients to allow brands to offer engaging activities, rewards and opportunities to their customers. The startup was created in 2021 and is part of eFounders Web3 start-up studio, 3Founders.
",N,N,N,2,1,0.04154662416233763
129,73476,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-h-f_bordeaux_NEXTO_lwk0NeX,Data engineer,NEXTON,"{Talend,Python,SQL}",Télétravail partiel possible,"Marine Clauzade, Bordeaux","Design, IT / Digital, Digital",CDI,2023-04-22,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, Nexton connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, professionnalisme et performance. Et pour vous ? Notre politique de développement des compétences dynamique saura vous séduire avec un programme de suivi de carrière sur-mesure. NEXTON recrute un DATA Engineer H/F , en CDI , à Bordeaux ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, NEXTON connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance. Et pour toi ? Notre politique de développement des compétences dynamique saura te séduire avec un programme de suivi de carrière sur-mesure. Le contexte : En tant que Data Engineer, tu es garant de l'accès aux sources de données, et aux données, et travailles sur l'ensemble des activités liées à la banque. Les missions : Tu es responsable de : Construire des pipelines scalables de données structurées et non structurées Définir la stratégie des stacks techniques et garantir la CI/CD Maintenir et repenser les datasets et pipelines existants pour servir une plus large variété de use cases Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ; Contribuer activement à notre communauté de data engineers. Tu es issu d'une formation supérieure d'ingénieur en informatique ou équivalent, tu as plus de 3 ans d'expériences en tant que data engineer.Tu as un bon niveau sur SQL et idéalement sur les ETL (Talend ou équivalent) ainsi qu'en programmation sur Python. Tu es rigoureux, avec un esprit analytique et de synthèse. Enfin, tu aimes travailler en équipe. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'année : - Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'année - Des moments privilégiés avec ton manager Prêts à nous rejoindre ? Rencontrons-nous !",,Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
127,73324,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech-paris_paris,DataOps Engineer - Big Data & Analytics Fintech PARIS,Opensee,"{go,kubernetes,aws,golang,pandas,python,numpy,scale,Unix,AWS,lambda,bash,azure,SQL,docker,Python,Bash,Docker,Kubernetes,linux}",Télétravail partiel possible,"28, Rue de Madrid, Paris, 75008","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee’s commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What’s in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client’s internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Multiple full-time positions Duration : permanent contract Salary : Competitive, profile based Location : Paris (near Saint-Lazare) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!",,Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
112,34675,https://www.welcometothejungle.com/fr/companies/adevinta-fr/jobs/data-analytics-engineer_barcelona,Data Analytics Engineer,Adevinta,"{Cassandra,Hive,Docker,Azure,Zeppelin,go,Kinesis,Athena,Beam,Databricks,Kafka,Luigi,Presto,Git,NoSQL,Flink,Kubernetes,Akka,Argo,SQL,Jupyter,Scala,Airflow,Redshift,via,Spark,BigQuery,Python,Tableau}",Télétravail partiel possible,Barcelona,"Intelligence artificielle / Machine Learning, Big Data, E-commerce",CDI,2022-08-08,"Adevinta is a global classifieds specialist, with +40 online marketplaces in 14 countries. Through their trusted brands, including leboncoin in France, mobile.de in Germany and 2dehands in The Netherlands, they create perfect matches. They connect house-hunters to new homes, jobseekers to new careers and buyers and sellers to give previously-owned products a new life, all helping to create brighter futures for millions of people. By making these connections, they’re creating positive change for the world and helping to build a more sustainable future. You will work in the Corporate data Team by providing data products which allow teams, managers and the entire B2B Organisation to access the data easily to solve their analytical needs, and providing high-level analyses and recommendations to help them make data-driven decisions. You will definitely make an analytical impact in Adevinta Spain. Main responsabilities: Lead a Data Analytics Project end-to-end: From detecting opportunities and understanding needs, data capture and transformation, visualisation, analysis and analytical training. Set, prioritise and coordinate implementation of data requirements and data-quality standards. Requirements analysis in systems engineering Understand business needs and produce insightful analyses for internal teams and leaders/managers to make the right decisions. Design, create and evolve data products via programming data pipelines and using models of structured/unstructured raw data. Ensure best experience of data product users through measurement of SLO and satisfaction levels and implementation of learning. Provide real time solutions using modern tools and programming languages. Maintain, develop and orchestrate the pipelines that build curated datasets Ensure that quality standards and data governance are being achieved Develop comprehensive data capture, transformation, and visualizations for self service analytics. Guarantee definitions of dimensions and indicators across the company. Assist colleagues in gaining access to the right data, train them and eliminate the barriers that exist in order to facilitate the analytical autonomy of the teams. Provide accurate data, insights, analysis and forecasts for decision makers and stakeholders Work with the technical team to translate business requirements into detailed technical design Communicate results in a clear and concise manner, with an understanding of data visualization and the importance of drawing accurate conclusions from multiple data sources Coach colleagues and users on how to access the right data helping eliminate barriers for self service and autonomy of the teams. Additional Information At Adevinta Spain, we believe in the power of a fair and equitable benefits policy. And we do everything we can to make it so. Therefore, we pay special attention to all aspects that are key in your day-to-day life: Ever since COVID-19 hit, we've all been working remotely following the health recommendations, but the offices are open and you can go in whenever you'd like with all the necessary health measures in place. Now, we are shaping our new post-COVID-19 working model. It will be based on a hybrid formula that will have a significant remote work component. Every year we engage into benchmarking against the external market in order to create competitive compensation packages. Moreover, we do have plans that allow you to ""flex your gross salary"" in order to purchase benefits such as meal vouchers, commuters card, training and child care. All Adevintans have in common the passion for innovation and technology. You can choose whether to have a Macbook or Dell XPS laptop and you can opt for an Iphone or a Samsung. We subsidize your parking up to a maximum of 90€/ month. Your well-being is our priority. We cover fully for your medical insurance and we allow family members to be added to the policy for a discounted price. We have a doctor in our facilities and we do offer extra wellness initiatives such as Yoga at the office in Madrid and physiotherapy in Barcelona. Do you like going to the gym? We sponsor 70% of the monthly fee of your chosen centre/ studio and we have agreements with both Andjoy and McFit for discounted membership prices. We enjoy 23 days of paid-time-off a year. In Barcelona offices we offer free breakfast and beverages🥐 You can choose the daily menu freshly prepared in our canteen. Last but not least, you have 5 extra days to attend conferences and we offer one entrance ticket per year Must: 3 years experience in a similar position. Nice to have a 3 years experience in a similar position Knowledge of Tableau. Storytelling skills Extensive experience with SQL Extensive experience with Python and Pyspark. Clouds Azure and Amazon Experience working with data processing frameworks like Spark, Flink, Kafka Streams or Beam. Familiarity developing data pipelines with scheduling tools like: Airflow, Luigi, Cloud Componer, Argo. Proficiency in building well-tested code. Querying tools: Hive, Athena, Presto, BigQuery… Good development practices (SOLID, testing) and data care (rigor for data quality). Self-starter and detail-oriented . You can complete projects with minimal supervision Excellent communication skills and ability to interact with multidisciplinary teams Intermediate knowledge of Git Experience with Agile methodologies Fluent in English Nice to have knowledge: Experience with Docker and container orchestration tools like Kubernetes, ECS, Docker Swarm. Experience with streaming processing tools like Kafka / Kinesis, Structured Streaming, Akka Streams, Flink, Spark Streaming… Notebooks: Jupyter, Zeppelin, Databricks, , Scala NoSQL databases: Redshift, Cassandra Fluent in English","Adevinta is hiring a Senior Data Analytics Project Leader in Spain to lead end-to-end data analytics projects, set and coordinate data requirements and quality standards, produce insightful analyses for internal teams and leaders, and design, create and evolve data products via programming data pipelines. The ideal candidate will have experience with Tableau, SQL, Python, Pyspark, and cloud services like Azure and Amazon, as well as good development and data quality practices. Fluency in English is required. Adevinta offers a competitive compensation package, remote work options, medical insurance, wellness initiatives, gym subsidies, and more.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
124,57139,https://www.welcometothejungle.com/fr/companies/neolynk/jobs/data-engineer-3-ans-d-experiences-h-f_paris,Data Engineer 3 ans d'expériences,NeoLynk,"{Python,SQL,Spark,AWS}",Télétravail partiel possible,"91 rue du faubourg saint honore, Paris, 75008",IT / Digital,CDI,2023-03-26,"Une manière innovante de répondre aux challenges digitaux de nos clients, une manière différente de valoriser nos consultants. Depuis plus de 6 ans, NeoLynk évolue dans le domaine de l’Open Source, passionnément ! Au travers de notre Tribu JVM et de nos projets innovants, nous conduisons nos consultants vers une maturité technologique toujours plus forte ! Passionné(e) par le Big Data ? Intègre notre Tribu et participe à son évolution, le tout en contribuant à des projets clients challengeants au sein d’équipes expérimentées ! Quelques clients : Rakuten, Société Générale, Saint Gobain, Kering … Vous évoluez au quotidien au sein de la tribe transverse Data Tools and Services, constituée de 7 pôles : Data Science, Data Engineering, BI/DATAVIZ, Data Analysis, Product Analysis, Data Quality, Data discovery. Vous aurez le soutien de l’entreprise qui a une ambition de révolutionner l’usage et le business model grâce aux nouvelles technologies. Vous travaillerez conjointement avec l’équipe Data Science et l’équipe data engineering. Vos missions: Vous travaillerez sous la responsabilité conjointe des deux managers Data Engineer & Data Science. Vous participerez à la mise en place d’un important chantier data au sein du client “la Data Plateform (DP)” qui permettra la centralisation, la creation et la mise à disposition de segments d’utilisateurs. Cette DP permettra d’alimenter différents use cases produit du client (Pub, CRM,Premium, Service Client, …). Vous serez en charge d’apporter votre expertise et votre support sur 3 principaux composants de cette DP :  La librairie de création de segment existante : qui permet l’intégration et la gestion des tables de référencement et d’archivage de segments. Des modifications seront apportées à cette librairie pour s’adapter à la DP  La table de référencement des segments : Changement de la table permettant de répertorier les segments disponibles dans la DP.  Les notebooks permettant de créer les segments existants : o Refactoring de ces notebooks en tenant compte des nouveaux changements de la librairie et des nouvelles bases de données (Xiti) • Vous justifiez d’une expérience d’au moins 3 ans dans le domaine de la data • Une expérience dans des environnements cloud avec des connaissances en Spark et AWS est très souhaitée. • Une bonne maitrise du langage Python et du SQL. • Capacité de synthèse, de vulgarisation de communication. • Être force de proposition. • Sens du partage et esprit d’équipe. • Prise d’initiative. Entretien téléphonique Test technique Entretien physique","NeoLynk, an Open Source technology company, seeks a Big Data expert to join their transverse Data Tools and Services tribe. The successful candidate will work closely with the Data Science and Data Engineering teams to support the Data Platform (DP) project for a client by bringing expertise on three key components. A minimum of three years of data experience and knowledge of cloud environments, Spark, AWS, Python, and SQL is required, with good communication skills, team spirit, and initiative.",Bac +5 / Master,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
122,57086,https://www.welcometothejungle.com/fr/companies/ekkiden/jobs/data-engineer,Data Engineer,Ekkiden Technologies,"{GCP,R,Python,Git}",Télétravail partiel possible,Lille,"IT / Digital, Transformation",CDI,2023-03-26,"The consulting world needs a new, more human, more modern, and more agile actor. This is the ambition that gave birth to Ekkiden in 2019. Today, this international consulting group is challenging traditions and bringing a large dose of innovation to its sector. Through its ecosystem of passionate, enthusiastic, and committed consultants, Ekkiden leads organizational, operational, and technological transformation projects in three areas, IT/Digital, Industry/R&D and Pharma/Biotech, mainly with large accounts and SMEs. Vous serez en charge de l’alimentation du datalake par des données Vous réaliserez les calculs d’agrégats Vous participerez à la conception générale et à l’analyse technique Vous développerez des programmes et les tests unitaires associés Vous participerez à la recette fonctionnelle et à la préparation de la mise en production Vous serez en charge du support aux utilisateurs Vous réaliserez des compte rendu des avancées et des points d’alerte Vous participerez à la migration du cluster bigdata on premise vers GCP Vous êtes issu d’une formation Bac+ 5 en informatique Vous justifiez de bonnes connaissances sur GCP Vous avez idéalement une expérience concrète sur Python et son framework Pyspark Des connaissance sur Git et Jira sont un véritable plus Vous êtes curieux, ouvert d’esprit et possédez un un bon esprit d’investigation et d’analyse Premier échange : téléphonique avec un membre de l’équipe recrutement Deuxième échange : visio avec un Business Manager Troisième échange (optionnel) : visio avec le Directeur commercial du périmètre","Ekkiden, an international consulting group, seeks a data engineer to feed data into the datalake, perform aggregate calculations, participate in technical analysis and design, develop programs and associated unit tests, participate in functional testing, support users, and participate in the migration of the big data cluster to GCP. The ideal candidate should have a degree in computer science, good knowledge of GCP, practical experience in Python and its framework Pyspark, knowledge of Git and Jira, curiosity, an open mind, and analytical skills. The hiring process includes a phone interview, a video conference with a business manager, and an optional video conference with the commercial director of the perimeter.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
120,73546,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/front-software-engineer-f-m-d-data-observability_croix,Front Software Engineer  - Data Observability,Decathlon Digital,"{NodeJS,Github,AWS,GraphQL,via,Kafka,Javascript,Docker,Kubernetes,React,Git,GitHub,GCP,TypeScript}",Télétravail partiel possible,"4 Rue du Professeur Langevin, Croix, 59170","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES DATA DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour accompagner cette transformation digitale internationale de Decathlon, les équipes Data évoluent et mettent au cœur de leurs enjeux : La qualité et l’accessibilité de la donnée La scalabilité des processus associés au cycle de vie de la donnée (ingest, store, transform, expose) L’élasticité des infrastructures et des services Intégré au cœur de la data platform votre rôle sera de servir ces deux enjeux majeurs Garantir l'accès et l'usage de la donnée pour tous nos utilisateurs data en délivrant outils et guidelines La scalabilité REJOINS L'ÉQUIPE DATA OBSERVABILITY En fournissant la capacité à identifier, diagnostiquer, tracer et résoudre les évènements de transformation de la donnée dans le SI de Decathlon, nous donnons le pouvoir aux équipes data de fiabiliser leurs produits et d'en mesurer la qualité. En tant que Software Engineer Frontend tu auras pour mission de créer les meilleures expériences possibles et unifiées via des interfaces pour nos équipes internes. Dans le cadre de l’ouverture d’un poste en CDI, nous recrutons un-e Software Engineer, basé-e, au choix à Paris où à Lille. Périmètre d’action Tu prendras part de bout en bout au développement d'un portail complet et de nouvelles fonctionnalités (React/ Svelte) en lien avec le Product Manager. Tu évolueras également au contact des autres coéquipières et coéquipiers : l’amélioration continue et l’autonomie sont particulièrement valorisées chez Decathlon ! Ton exigence technique (qualité du code, pratiques, patterns, outils…) et tes qualités relationnelles permettent de diffuser les bonnes pratiques dans l’équipe, en collaboration avec le Tech Lead. TES RESPONSABILITES Construire une plateforme front pour rendre l'observabilité accessible à tous intervenir sur toute la chaîne de livraison des fonctionnalités : conception, implémentation, tests, documentation technique, exemples, API, SDK… être moteur dans le processus d'intégration et de livraison continue se montrer force de proposition dans les choix techniques mais aussi aussi dans nos moyens de collaboration Le périmètre technique : HTML / CSS : accessibilité, standards W3C, web performance… Svelte / Vue JS / ReactJS / GraphQL / Material UI Javascript / TypeScript, NodeJS Git (Github Actions) Tests unitaires et fonctionnels Outils collaboratifs : Confluence, Slack, Jira… Infrastructure : AWS, Kafka, Docker, Kubernetes… CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience (minimum 3-5 ans) du développement web frontend (Svelte / Vue JS / React), des architectures micro services / micro frontend, et de déploiement continu et tu as déjà effectué de l'UX design Tu as un bon niveau d’anglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu as un état d'esprit agile tourné vers l'amélioration continue, l'intelligence collective, l’entraide et la solidarité Tu aimes travailler dans un environnement collaboratif (Pair Prog, Code Review, et écosystème GitHub) Tu as une passion de la technique que tu aimes partager Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style relationnel et la vie en équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon à Lille où à Paris (prévoir un déplacement régulier sur Lille, à un rythme d'1 ou 2 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Digital, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantés notamment à Paris, Lille et Amsterdam. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .",,Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
119,73511,https://www.welcometothejungle.com/fr/companies/voyage-prive/jobs/data-engineer-f-h_aix-en-provence_VP_5y1d2xD,Data Engineer,Voyage Privé,"{GitLab,BigQuery,Elasticsearch,Python,Scala,SQL,scale,Hadoop,Spark,Tableau,Docker,NoSQL,GitHub,Airflow,YARN,Dataiku,moderne}",Télétravail partiel possible,"330 Rue Pascal Duverger, Aix-En-Provence, 13090","Luxe, Loisirs, E-commerce",CDI,2023-04-22,"Aventure entrepreneuriale lancée en France en 2004, Voyage Privé est le leader européen de la vente éphémère de voyage en ligne. Ils font voyager 56 millions de membre en dénichant partout dans le monde des produits haut de gamme négociés au meilleur prix. Présents sur 9 marchés (France, Allemagne, Espagne, Italie, Angleterre, Belgique, Suisse, Pays-Bas, Autriche) et ne comptent pas s’arrêter là ! Le groupe a connu une croissance dynamique à deux chiffres depuis sa création avant d’être ralenti en 2020 par la crise covid. Nous poursuivons aujourd’hui notre phase de scale amorcée en 2020. Ils se préparent pour un nouveau cycle de croissance très soutenue et recrutent les talents qui participeront à la reprise explosive du voyage ! Voyage Privé, c’est aussi un groupe qui a l’ambition de faire éclore une nouvelle façon d’entreprendre, conciliant réussite économique et initiatives sociales, le tout porté par le dynamisme et l’engagement de ses collaborateurs. Leur Campus rassemble salariés, sportifs de haut niveau et éducateurs. Chacun apprenant des autres pour développer le meilleur de lui-même et impacter positivement. Pourquoi nous rejoindre ? L'univers du voyage est un terrain de jeu magique en termes de data : données clients, marketing, fournisseurs, navigation, CRM, service client... Notre activité génère un important volume de données (+80 To) dont l'analyse a un impact direct sur l'expérience utilisateur, la conversion, les relations fournisseurs. En tant que Data Engineer, vous accompagnez le déploiement de notre architecture vers le cloud et les projets (data warehouse, CI/CD, hébergement des modèles de machine learning) Vous participerez à la consolidation d'une plateforme robuste, performante, aux coûts optimisés, facile d’exploitation et offrant la capacité à l’ensemble de l’équipe data de travailler dans les meilleures conditions (reporting, ad-hoc analysis, A/B tests, industrialisation de modèles de data science) Vos missions Développement de l’architecture data Challenger l’architecture actuelle et l’optimiser pour en faciliter l’exploitation Intégrer de nouvelles données par les équipes de développement (back-end et front-end, APIs externes) Améliorer le modèle de données en collaboration étroite avec les ingénieurs BI Proposer et mettre en place des améliorations dans le processus de développement (CI/CD, monitoring, optimisation des coûts, best practices, etc.) Créer l’architecture adaptée à l’industrialisation d’algorithme de machine learning Maintenance de la plateforme Maintenir un pipeline de traitement capable de traiter un volume important de données tout en garantissant leur sécurité Monitorer et améliorer les métriques du data pipeline (disponibilité, taux d’erreur, latency, etc.) Prendre en compte le contexte réglementaire de récolte et d’accès aux données (RGPD) Notre environnement technique : Tableau, Dataiku DSS, BigQuery, Elasticsearch, ETL interne, Apache Spark on YARN, Google Cloud Storage, Google Cloud Dataproc, Google Cloud Pub/Sub Développement en Python et Scala avec Docker, GitHub/GitLab Vous allez prendre plaisir à nous rejoindre … S’impliquer pleinement dans l’aventure entrepreneuriale Voyage Privé et devenir acteur de la réussite du Groupe. Vivre dans le Sud de la France dans un environnement naturel, économique et culturel exceptionnel et dans un campus moderne, numérique et éco-responsable. Découvrir un écosystème unique et porteur de sens, créateur de ponts entre des univers souvent éloignés : l’économique, le sportif, l’académique, le social et participer à l’un des projets Vision (Ecole des XV - Provence Rugby - VP Green- Les Tremplins – Chez Pierre). Faire du sport sur le campus, assister aux matchs de rugby du Provence-Rugby ou danser sur les sons du Dalida Institute ! Découvrir le monde en bénéficiant de remises complémentaires sur vos évasions Voyage Privé pour vous, votre famille et vos amis. Vivre au rythme des différents temps forts Business & fun de Voyage-Privé (Company Breaks, Carnaval, Convention annuelle …) et participer à des meet-up et des talks être en permanence ouvert au monde qui nous entoure … Nous sommes faits pour nous rencontrer et grandir ensemble si …. Vous êtes de formation bac+5 école d'ingénieur ou universitaire, vous avez une expérience d’au moins 4 ans en tant que data ingénieur Vous maîtrisez SQL, les concepts et le déploiement des bases de données relationnelles et NoSQL ainsi que le langage Python Vous êtes habitué à travailler dans un environnement dynamique et capable de prioriser vos projets Vous avez déjà conçu, déployé et maintenu une architecture complexe en production : spécifications, conception, monitoring, alerting, gestion des incidents, recherche des root causes Vous avez développé une expertise dans au moins une des technologies big data (Hadoop, process ETL, Spark, Airflow, etc.) Une expérience sur Google Cloud Platform serait un plus",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
118,73400,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-scientist-data-engineer,Data scientist / Data engineer,MP DATA,"{Postgres,GCS,Python,Azure,Django,SQL,Kafka,Spark,MongoDB,AWS,Git,S3,Snowflake,Java,GCP}",Télétravail partiel possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-04-22,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur données. Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français. MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences. Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort. Le dataLab entité de la Direction Technique a pour mission de développer des solutions d’Intelligence Artificielle (IA) dans le groupe, sur toute la chaine de valeur. Le dataLab possède une expertise en data science et dans les technologies d’IA (Jumeaux, numériques, Machine Learning, Computer Vision ou encore de Speech to Text….). Ses travaux sont déployés à la demande des directions métiers dans le but d’apporter une valeur ajoutée à l’entreprise. Ingénieur d’une grande école (Centrale, Mines, Supaero, Supelec, …), vous avez des connaissances en modélisation et machine learning (deep learning, random forest, svm…) acquises lors de votre scolarité ou de vos expériences passées (stage ou césure) vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite à votre cursus ingénieur ou vos expériences professionnelles, vous disposez de connaissances métiers dans les domaines de l’aéronautique, énergie, transport, etc… Vous êtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacité à être force de proposition. Vous êtes intéressés pour vous dépasser en data science & data engineering et vous avez des premières expériences dans ce domaine, comme par exemple : C/C++ / Java / Rust Spark Kafka Cloud : AWS / GCP / Azure Technologies de stockage : Snowflake / S3 / GCS / Azure Blob Django / Flask Git SQL : Postgres / MongoDB CI/CD.",,Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
224,57008,https://www.welcometothejungle.com/fr/companies/deepreach/jobs/data-engineer_paris,Data Engineer,DeepReach,"{count,JavaScript,SQL,Python}",Télétravail partiel possible,"40, Rue du Colisée, Paris, 75008","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-03-26,"Who are we ? 1DeepReach is the leading AI SaaS-based multi-channel platform disrupting digital local advertising. Our company was born in France in 2018 to bring brands closer to their local consumers. At a time when all brands are refining their local strategies, DeepReach technology increases agencies’ capacity to better address local ads. 1We shape another approach of digital advertising: more local, more multi-channel, more business-driven, thus more efficient, with the power of data. Boosted by +11M€ fundraising, we are proud to count +55 Adtech talents working across France, +250 clients of all sizes from international groups (WPP, Publicis…) to local agencies and +20 000 local campaigns operated through our platform. Our success story in France was built on a continuous search of innovation, excellence, and customer-centric approach, fueled by a teamwork and entrepreneurial mindset. Aiming the ambition of becoming a worldwide digital local platform leader at its very beginning, DeepReach is actively undertaking its global expansion in Europe in 2022, rolling out its presence and business in several countries such as UK, Germany, Spain, Italy, Belgium, and Switzerland. What you will be doing As a Data Engineer you will be working alongside the Data team liaising with various stakeholders internally and externally, handling large quantities of data from multiple sources, working on multiple tasks & projects simultaneously and dealing with any queries. The focus on your work will be to find hidden patterns and correlations in raw data, build prototypes and find data-driven ways to improve our offer. 🚀Analyze and organize raw data 🚀Evaluate business needs and objectives 🚀Interpret trends and patterns 🚀Conduct complex data analysis and report on results 🚀Prepare data for prescriptive and predictive modelling 🚀Build algorithms and prototypes 🚀Combine raw information from different sources 🚀Explore ways to enhance data quality and reliability 🚀Develop analytical tools and programs Your profile 🚀Previous experience as a data engineer or in a similar role (2-5 years) 🚀Technical expertise with data models, data mining, and segmentation techniques 🚀Knowledge of programming languages (e.g. Python, JavaScript) 🚀Hands-on experience with SQL database design 🚀Great numerical and analytical skills 🚀Degree in Computer Science, IT, or similar field 🚀Previous experience in AdTech or Digital Marketing is a big plus 🚀Previous experience with GIS and/or time series data is a big plus Interview process HR screening Interview with our Data Product Manager Interview with our VP Product Interview with our CTO An informal conversation with our data developers to get to know the team and the tech stack","1DeepReach, an AI SaaS-based multi-channel platform disrupting digital local advertising, is seeking a Data Engineer with previous experience and technical expertise in data models, data mining, and segmentation techniques. The successful candidate will analyze and organize raw data, evaluate business needs and objectives, interpret trends and patterns, conduct complex data analysis, build algorithms and prototypes, and develop analytical tools and programs. Previous experience in AdTech or Digital Marketing is a plus. The company is expanding globally and is looking for someone to join its team of 55 Adtech talents working across France. The interview process includes HR screening, interviews with Data Product Manager, VP Product, CTO, and an informal conversation with the data developers.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
115,73196,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-h-f_bezons_ATOS_0Kw7a1D,Data engineer confirmé,Atos,"{SnowFlake,Kafka,Dataflow,Hive,Redshift,Kibana,CouchBase,HDFS,Beam,BigQuery,Spark,Redis,Logstash,ElasticSearch,MongoDB,Java,Python,Cassandra,Teradata,Hadoop,Docker,Kubernetes,NoSQL}",Télétravail partiel possible,"80 quai Voltaire, Bezons, 95870",IT / Digital,CDI,2023-04-22,"Atos est un leader international de la transformation digitale avec plus de 110 000 collaborateurs dans 73 pays et un chiffre d’affaires annuel de plus de 11 milliards d’euros. Numéro un européen du Cloud, de la cybersécurité et des supercalculateurs, le groupe fournit des solutions intégrées de Cloud Hybride Orchestré, Big Data, Applications Métiers et Environnement de Travail Connecté. Partenaire informatique mondial des Jeux Olympiques et Paralympiques, le Groupe exerce ses activités sous les marques Atos, Atos Syntel, et Unify. Atos est une SE (Société Européenne) cotée sur Euronext Paris et fait partie de l’indice CAC 40. La raison d’être d’Atos est de contribuer à façonner l’espace informationnel. Avec ses compétences et ses services, le groupe supporte le développement de la connaissance, de l’éducation et de la recherche dans une approche pluriculturelle et contribue au développement de l’excellence scientifique et technologique. Partout dans le monde, Atos permet à ses clients et à ses collaborateurs, et plus généralement au plus grand nombre, de vivre, travailler et progresser durablement et en toute confiance dans l’espace informationnel. Atos est responsable de la définition, de la conception et de la construction de plateformes et de solutions sécurisées Big Data. Vous interviendrez au sein d’une équipe dynamique d’expertise Big Data en forte croissance réalisant des activités allant du conseil en architecture et gouvernance de la donnée aux aspects Data Ingestion, Data Analytiques et DataScience / IA , en passant par la mise en place, l’intégration, le développement et l’optimisation de solutions Big Data pour les projets stratégiques de nos clients. Notre valeur ajoutée repose sur une forte expertise technique et business de la data renforcée par de nombreux partenariats avec les éditeurs actifs dans les domaines des architectures applicatives distribuées et du Big Data & Analytics. Dans le cadre de notre croissance et pour répondre aux nouveaux besoins de nos clients, nous recherchons à étoffer nos équipes Big Data en recrutant un(e) Data Engineer Expérimenté(e). Description du profil : Expertise en développement Python ou Java Spring Boot, Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam, …, Connaissance des écosystèmes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana) , MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS, … Connaissance des architectures conteneurs : Docker, Kubernetes, …., La connaissance des services managés BigData de Google Cloud Platform (Dataflow, BigQuery, Pub/Sub, ML Engine,…) est appréciée, La connaissance des approches Agile & DevOps est appréciée. Nous proposons : Ce domaine technologique étant très dynamique, plus que des connaissances et des compétences techniques, vous devrez démontrer une réelle envie d’apprendre, de progresser et de se tenir à jour sur toutes les technologies et architectures.",,Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
79,56821,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes_EDF_k5RgOpe,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",Télétravail partiel possible,"Tour EDF La Défense, Colombes, 92400","Environnement / Développement durable, Energie",CDI,2023-03-26,"Chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez EDF même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez EDF même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf La DSIN est en charge de développer le SI et les outils numériques de la Direction Commerce pour faire face aux défis que doit affronter EDF dans le cadre de la concurrence accrue du marché de l'énergie et des services. Elle contribue à la performance des métiers, à leur évolution et à la transformation de la Direction à travers ses activités SI et Data Science. Au sein de la DSIN, le Centre de Solutions et de Compétences DataScience & IA (CSC DS & IA), a pour mission de réaliser les travaux d'analyse et de valorisation des données de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux métiers du Marché d'Affaires et du Marché des Clients Particuliers pour répondre à des enjeux variés comme les départs à la concurrence, la conquête de nouveaux clients, la satisfaction client, la détection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de données conséquentes (~26 millions de clients, B2C+B2B). Afin de répondre à ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une équipe de Data Engineer, et en appui d'une équipe de plus de 20 Data Scientists, votre mission consistera à : - Mettre en place des pipelines de traitements de données - avec des volumes importants de données (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de données distribuées (Spark …) - Extraire massivement des données (Hadoop - Hive, Oracle - SQL, …) - vous-même ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de données (compréhension des problématiques Yarn, JVM, tablespace temp…) - Accompagner les Data Scientists dans le maintien et l'évolution des outils de requêtage développés en interne (dnquery pour requeter Oracle et Hive), extension à une nouvelle technologie de stockage des données (PostGre, SQL Server…) - Accompagner les déploiements de modèles de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des chaînes récurrentes de type traitement de la donnée ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer à la construction des stratégies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer à l'évolution de l'environnement technique des Data Scientists Votre Profil ? - Vous êtes titulaire d'un Bac +5 (Master, diplôme d'ingénieur) dans le domaine informatique, des mathématiques / statistiques, de la Data Science ou du Big Data - Vous bénéficiez d'une expérience d'au moins 3 ans en tant que Data Engineer - Vous avez déjà travaillé dans un contexte de Datascience et automatisé des traitements de type Datascience - Vous maîtrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez déjà manipulé des données stockées sous S3 - Vous êtes à l'aise avec les outils collaboratifs de développement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous bénéficiez d'une ou plusieurs expériences de travail en mode Agile - Vous êtes curieux et les projets innovants vous passionnent - Vous êtes force de proposition et proactif - Vous aimez transmettre et travailler en équipe Méthodologie de travail : Vous collaborerez étroitement avec les Référents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'équipe en charge des lacs de données au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark…). Le poste est situé à Colombes, proche de La Défense Ouest, avec une possibilité de télétravail partiel. Rémunération : Fourchette estimative : entre 50k et 57k€, la rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is seeking a Data Engineer to join its Centre de Solutions et de Compétences DataScience & IA (CSC DS & IA) in Colombes, France. The successful candidate will work closely with the team of Data Engineers, as well as assist and support more than 20 Data Scientists in developing and maintaining internal tools. The candidate should have a Master's or Engineer's degree in computer science, mathematics/statistics, data science or big data, at least three years of experience as a Data Engineer, and expertise in Python, SQL, R, Docker, Airflow, Hadoop, and Git. The position is open to all applicants, and telecommuting is available.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
72,73470,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-engineer_paris_NUMBE_e8AR0gm,Data Engineer,Numberly,"{RabbitMQ,Linux,MySQL,HBase,Kafka,Hive,Cube,Tabular,Scala,HDFS,Airflow,AWS,hadoop,Druid,Spark,SQL,ElasticSearch,MongoDB,Java,Python,ScyllaDB,Hadoop,Docker,Kubernetes,Celery,NoSQL,Git,GCP}",Télétravail partiel possible,"28 rue de Châteaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Numberly is looking for a Data Engineer to join its dedicated team Data. As a Data Engineer you will: Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MS SQL Server, MongoDB, ScyllaDB). Participate in a huge migration from CRM to CDP (SQL Server to hadoop, relational DB to NoSQL) Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage. Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly. Work alongside Data Analytics, Data Scientists, DevOps, and many other talented techs. Suggest your own technological solutions and try them out (our latest POCs include Apache Druid and Tabular) . Join a great multicultural team filled with wonderful people At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (“Live my life” in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Positions available in Paris, Lyon, Bordeaux, Marseille, Nantes, Lille You : Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused… Like work well done and pay attention to detail Dream of being able to develop and manage website databases with strong traffic Want to work with various, prestigious clients on different problems Are on the lookout for new languages/technologies and test the latest open source trends before others You love the following stack ? Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...) SQL Databases (MySQL, SQLServer) Apache Spark ETL (Apache Airflow or equivalent) NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...) Apache Kafka Python, Java, Scala Git Linux Even better if you know : Cube OLAP and SSRS Cloud Solutions (AWS, GCP, …) API REST, WebServices Docker Kubernetes Apache Druid Data Science and Machine Learning Message Queuing (RabbitMQ, Celery, …)",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
155,56495,https://www.welcometothejungle.com/fr/companies/margo/jobs/margo-analytics-data-engineer-h-f_paris,Margo Analytics - Data Engineer -,Margo,"{Databricks,Scala,via,Spark,Azure,Hadoop,Python}",Télétravail partiel possible,"1, Rue de Saint-Pétersbourg, Paris, 75008","Logiciels, IT / Digital, FinTech / InsurTech",CDI,2023-03-26,"La mission de Margo ? Accélérer la transformation digitale de ses clients en les accompagnant dans le déploiement de projets IT complexes. Margo, c’est un cabinet de consulting à taille humaine dont l’objectif depuis 15 ans est d’assurer la satisfaction de ses consultants autant que celle de ses clients. Pour cela la recette est simple : ils sélectionnent avec attention leurs projets pour que chacun de leurs collaborateurs se sente stimulé et progresse rapidement. Ils interviennent aujourd’hui principalement sur des sujets de coding et data, et sur des problématiques métiers dans la finance, la banque, l’assurance et l’énergie. Margo Analytics - Data Engineer – H/F CDI. Paris. Notre mission chez Margo Analytics? Accompagner la transformation Data et Cloud de nos clients en combinant ROI et Innovation technologique. Nous sommes un cabinet de conseil à taille humaine dont l’objectif est d’assurer la satisfaction de nos consultants autant que celle de nos clients. Pour cela la recette est simple : nous sélectionnons avec attention nos projets pour que chacun de nos collaborateurs se sente stimulé et progresse rapidement . C’est pourquoi nous avons développé une expertise sur les dernières technologies Data et Cloud dans les secteurs d’activité où l’on retrouve des contraintes techniques fortes (Banque, Assurance, Industrie, Énergie et Retail). L’aventure Margo Analytics, c’est aussi intégrer une communauté de 350 experts du groupe Margo, tous passionnés par la tech, répartis entre Paris, Londres et Varsovie. A leurs côtés, vous pourrez évoluer rapidement et développer de nouvelles compétences. Prêt à nous rejoindre ? 🎯 Exemple de projet proposé par Margo Analytics : En intégrant Margo Analytics, vous aurez le choix des missions sur lesquelles vous souhaitez travailler. Vous serez accompagné par les 2 fondateurs de l’entreprise, dont le rôle est de rechercher le projet client qui correspondra le plus à vos attentes et de vous accompagner dans votre carrière. Ainsi, vous pourrez par exemple intervenir sur l’un de nos projets de refonte from scratch d’un datalake au sein d’un grand acteur de l’Industrie et de sa migration vers le Cloud Azure.L’objectif est d'assurer la distribution de la donnée de manière optimisée pour créer une couche de distribution et permettre aux entités métiers d’implémenter les use cases.Vous aurez ainsi l’opportunité d’évoluer dans un environnement très exigeant, en méthodologie agile et au sein d’une équipe d’experts. En tant que Data Engineer, vos missions seront : Développer en mode agile les usages métier reposant sur le Datalake HadoopParticiper au projet de MoveToCloud vers Azure Identifier et modéliser des données nécessaires à l'usage Sélectionner le stockage le plus adapté à l'usage parmi les technologies de l'écosystème Databricks Développer en Python et en Scala des traitements de transformation et de production de données Participer à l’amélioration continue et au refactoring de code Stack techno : Hadoop/Spark / KafkaScala / Python Databricks Cloud Azure ✨ La vie interne chez Margo Analytics Les projets que nous proposons chez Margo Analytics sont des missions longues (2 à 3 ans) qui vous permettront d’évoluer vers une expertise technique. Vous aurez également l’opportunité de vous impliquer dans le développement et la stratégie de Margo Analytics et contribuer à faire grandir notre communauté. Les possibilités sont nombreuses et très rapidement nous vous proposons d’avoir un 2ème rôle au sein de la structure : Recruteur , pour échanger techniquement avec les candidats pendant leur processus de recrutement, représenter Margo Analytics lors de forums écoles ou proposer des cooptations de personnes de votre ré seau. Formateur , pour partager votre expertise et vos connaissances au sein de la communauté Margo Analytics. Manager , pour suivre en mission et être garant de l’évolution de carrière de consultants juniors. Rédacteur , pour mettre en lumière votre expertise et celle de Margo Analytics en rédigeant des articles techniques publiés sur notre blog et dans la presse spécialisé e. Speaker , pour prendre la parole et proposer des débats lors de conférences internes ou externes 🔍 Vous êtes un(e) futur(e) Margo Analytics si : Must-Have Vous êtes issu(e) d’une école d’ingénieur ou d’un cursus universitaire équivalent niveau Bac + 5 / Master.Vous aimez coder et vous êtes passionné(e) d’informatique et de Data.Vous êtes curieux(se) et vous vous intéressez aux dernières technologies du marché.Vous justifiez d’une première expérience en tant que Data Engineer. Nice to Have Vous êtes ambitieux(se) et n’avez pas peur de travailler sur des projets challengeants dans des environnements à fortes contraintes techniques (forte volumétrie de données, temps réel, optimisation de la performance). Vous aimez travailler en équipe et êtes attaché(e) au respect des bonnes pratiques de code.Vous parlez et comprenez l’anglais. 🙌 Les avantages : 🤝Notre processus de recrutement : Postulez en ligne ! L’équipe RH étudie avec attention votre candidature et vous contacte si votre profil est en adéquation avec l’un de nos postes. Première rencontre ! Vous échangez avec un RH et un des associés de Margo Analytics sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunités que nous proposons. Challengez-vous dans le cadre d’un entretien technique avec l’un de nos experts. C’est également l’occasion pour vous d’avoir son retour d’expérience. Dernier entretien de motivation : pour finir, vous rencontrez un membre du comité de direction de Margo Analytics pour confirmer notre motivation commune. Pendant tout le processus de recrutement, vous avez la possibilité de participer à des événements organisés par Margo Analytics et d’échanger avec des collaborateurs afin d’en apprendre plus sur nous ! PS : Si vous étudiez ou travaillez loin de Paris, nous vous proposons de suivre ce processus en full visio via le système Hangout Meets de Google. 🏊 Plongez dans la culture d’entreprise du groupe Margo : Rencontrez nos équipes à travers notre page WelcomeToTheJungle Découvrez des retours d’expériences de consultants Margo sur notre page YouTube N’hésitez pas à prendre connaissance des avis de nos collaborateurs sur GlassDoor Si vous ne vous reconnaissez pas dans cette offre, n’hésitez pas à prendre connaissance de nos autres opportunités 👉 nos offres d'emploi Engagée en faveur de l'égalité des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap.","Margo Analytics is seeking a Data Engineer to join their team in Paris, France. The company aims to combine ROI and technological innovation to help clients transform their data and cloud technologies. The ideal candidate should have a Bachelor's or Master's degree in engineering or a related field, experience working as a Data Engineer, and be passionate about technology and data. They should also be willing to work on challenging projects and adhere to code best practices. The company offers long-term missions, opportunities for growth and development, and the chance to contribute to the company's development and strategy. The recruitment process includes interviews with HR, company associates, and technical experts.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
71,56418,https://www.welcometothejungle.com/fr/companies/withings/jobs/data-engineer-h-f_issy-les-moulineaux_WITHI_bJ6kDAw,Data Engineer,Withings,"{ElasticSearch,dbt,Dagster,via,Linux,Unix,ClickHouse,SQL,Python}",Télétravail partiel possible,"2 rue Maurice Hartmann, Issy-Les-Moulineaux, 92130",Objets connectés,CDI,2023-03-26,"Chez Withings, ils souhaitent redonner aux individus le contrôle de leur santé. Ils ont l’obsession de créer des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; leurs balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de leur gamme sont aujourd’hui utilisés par des millions d’utilisateurs. Leur objectif : permettre la prévention, le dépistage et l’accompagnement d’un certain nombre de maladies chroniques via des produits et des services innovants, afin de révolutionner la manière dont on prend soin de notre santé. Chez Withings, nous souhaitons redonner aux individus le contrôle de leur santé. Nous avons l’obsession de créer des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd’hui utilisés par des millions d’utilisateurs. Notre objectif : permettre la prévention, le dépistage et l’accompagnement d’un certain nombre de maladies chroniques via des produits et des services innovants, afin de révolutionner la manière dont on prend soin de notre santé . Au sein de Withings, l’équipe Data Analytics facilite le traitement et l’usage de gros volumes de données afin de permettre à toutes les équipes de Withings de prendre des décisions basées sur la réalité. Dans ce cadre, tu auras les responsabilités suivantes: Maintenance et administration de base de données (ClickHouse / PostgresSQL / ElasticSearch) Modélisation de données en SQL (SQL - dbt) Développement de connexions API (Python / Rust) Développement de pipelines de données complexes (Python - Dagster) Maintenance et administration de machines virtuelles (Unix) Soutien technique au reste de l’équipe Former les équipes métiers aux bases de SQL Requirements Fortes compétences informatiques : SQL, Python, Linux, développement de connexions API… Appétence forte pour les challenges techniques : stack on-premise, outils open-source, contraintes physiques des serveurs, sécurité forte liée à l’utilisation de données de santé… Rigueur, autonomie, prise d'initiatives, curiosité... Maîtrise parfaite de la communication en français et en anglais, aussi bien à l’écrit qu’à l’oral Benefits Rejoindre l’aventure Withings, c’est : Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen Participer à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues Bénéficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, réductions pour des activités culturelles et sportives, restaurant d’entreprise, et bien plus encore Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites ! Toutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.","Withings is seeking a Data Analyst to maintain and administer databases, model data in SQL, develop API connections and complex data pipelines, and provide technical support in an agile and constantly evolving environment. The ideal candidate should have strong technical skills in SQL, Python, Linux, and API development, as well as a strong interest in technical challenges related to on-premise stacks, open-source tools, server physical constraints, and data security. Withings offers various benefits, including contributing to innovative and ambitious health projects, teleworking, stock options, a choice of smartphone and computer, and more.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
28,67470,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont_NATIX_V4xO2LW,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"Charenton le Pont, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-04-07,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de votre âge, origine, orientation sexuelle, handicap... Au sein du département CIO CIB, vous rejoignez l'équipe de Sensitivities, au sein de l'IT Risks, composée de 10 personnes. En nous rejoignant, vous prenez part à plusieurs programmes de transformation de notre système d'information afin de répondre aux besoins du département des risques, des régulateurs, tout en accompagnant les front offices dans leurs nouvelles activités. L'équipe est en charge de la maintenance et des évolutions de deux applications clés pour la gestion des risques de marchés : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities répondant à la réglementation FRTB). Nos principaux interlocuteurs sont le département des risques de marchés (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk), les équipes support/production à Porto et les équipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques à mettre en œuvre et estimer le coût avec l'équipe ; Développer de nouvelles fonctionnalités de la phase de conception aux tests, dans une démarche durable (haute qualité du code, respect des principes d'architecture et de sécurité informatique, documentation, automatisation des tests, utilisation maitrisée de l'infrastructure) ; Travailler sur des problématiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et améliorer la Software Factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 et les développements nécessaires pour maintenir une production ponctuelle, de qualité et maîtrisée. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Paris et à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en informatique avec une spécialisation en big data, vous avez au moins 3 ans d'expérience en tant que data engineer. Vous maîtrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La préconisation de solutions techniques. Vous êtes : - Reconnu pour votre leadership ; - Capable de proposer des améliorations continues ; - Rigoureux, autonome et pédagogue. Vous maîtrisez l'anglais avec un niveau minimum B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.",,Bac +4,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
27,67387,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont_NATIX_OQAO6RD,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"30 AVENUE PIERRE MENDES-FRANCE, Charenton-Le-Pont, 75013","Banque, Transformation, Assurance",CDI,2023-04-07,"Au sein de la direction CIO CIB Risks, dans le département Data Processing and Metrics, vous rejoignez l'équipe Metric Services P&L Explain qui est composée de 5 personnes. Dans cette équipe nous travaillons à calculer l'explication du P&L (profit and loss) par les sensibilités. Notre application est également partie prenante des calculs de Stress Tests et IPV (indépendance price validation). Nous intervenons donc sur plusieurs chaînes de valeurs, auprès de notre client : le département des risques de marché. Au quotidien vous avez pour missions de : Contribuer aux spécifications techniques et fonctionnelles ; Intervenir de la phase de concéption aux tests : développement de nouvelles fonctionnalités, revue de code, documentation, ... ; Travailler sur des problématiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et améliorer la software factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 pour avoir une production ponctuelle, de qualité et maîtrisée. Nos principaux interlocuteurs sont : le département des risques de marché (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk) et les équipes support et production à Porto. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Vous travaillez dans un environnement international, au sein d'une communauté d'experts qui place l'excellence, l'impact et l'action collective au cœur de tout ce qu'elle entreprend. Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en finance et/ou en informatique avec une spécialisation en big data, vous avez une expérience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous maîtrisez : * La finance de marché, et plus précisément le marché des risques et PNL (méthode d'explication du PNL) ; * Les spécifications des besoins de l'équipe et vous êtes capable de proposer des maquettes aux utilisateurs en autonomie. Vous êtes : * Pédagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des améliorations continues. Vous maîtrisez l'anglais avec un niveau B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.",,Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
26,56945,https://www.welcometothejungle.com/fr/companies/cgi/jobs/ingenieur-data-big-data-tips-h-f_paris,Ingénieur DATA - BIG DATA / TIPS,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",Télétravail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. - Conseil, Audit et Maitrise d’œuvre, * Etudes d’opportunité, cadrage de projet d’intégration de données et aide au Choix de solution, * Accompagnement à la mise en place de DataLake/Big Data * Conception et développement de flux d’intégration des données (ETL,ELT, streaming ,API … ) * Conception et mise en œuvre de plates-formes On Premise ou Cloud de stockage des données dans un Data Lake (Big Data) - Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.) * Migration des données - Move to Cloud Profil de consultant Data Ingénieur: * Animation d’ateliers Métier/ IT de définition des processus d’intégration des données, * Animation d’atelier de définition de plateforme d’intégration et de stockage des données * Proposition de type d’architecture de gouvernance (Centrale, décentralisée, etc.) - Capacité à intégrer une équipe d’intégration des données - Capacité à proposer des solutions & architectures de données * Capacité à configurer des outils d’intégration et de Reporting des données * Formation et pratique d’outils de Data Intégration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. )","CGI, a global leader in digital consulting and services, is seeking a Data Engineer consultant to work on a variety of projects in industries such as banking, retail, energy, and transport. The ideal candidate should have experience in data integration, cloud platforms, data architecture, and tools such as Informatica and Talend. The role involves leading workshops, proposing solutions, and configuring data integration and reporting tools.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
25,67290,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-h-f-nwm_paris_NATIX_xmqzm5r,Data Engineer  - NWM,Natixis,"{Microsoft,via,SQL}",Télétravail partiel possible,"paris, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-04-07,"Avec plus de 450 collaborateurs, Natixis Wealth Management est implantée en France et intervient également au Luxembourg. Natixis Wealth Management fait partie du Groupe BPCE, 2ème acteur bancaire en France qui lui offre solidité et sécurité. Elle entretient des liens étroits avec les réseaux qui le composent (Banque Populaire, Caisse d'Epargne et BPCE IOM) pour servir ses clients. Naturellement, elle s'appuie sur les talents et les expertises de Natixis pour proposer des solutions financières se situant hors de son périmètre d'activité. « En tant qu'entreprise socialement responsable, Natixis Wealth Management s'engage à favoriser l'insertion professionnelle et le maintien dans l'emploi des personnes en situation de handicap. Nous sommes tous mobilisés pour que chaque collaborateur puisse exprimer tout son potentiel. » L'équipe activités et projets transverses, que vous rejoignez en tant que Data Engineer, est composée d'une quinzaine de personnes au sein de la DSI. Dans cette équipe, nous travaillons notamment à la refonte de la plateforme data et participons à l'ensemble des enjeux data de la banque. Au quotidien, vous avez pour missions : D'assurer, dans un premier temps, un rôle de tech lead sur le programme de rénovation de la plateforme data ; De mettre en oeuvre les bonnes pratiques concernant le socle data du SI de Natixis Wealth Management (NWM) ; De participer à la fiabilisation du SI et d'apporter un support de niveau 2 sur certains incidents ou demandes d'assistance ; D'assurer une veille technologique ; D'analyser les demande d'évolution ou de maintenance corrective. Les stacks techniques utilisées sont les suivantes : SQL, SQL Server, SSIS, Microsoft. Nos équipes travaillent en mode Agile. Vous intégrez une communauté d'experts qui place l'excellence, l'impact et l'action collective au cœur de tout ce qu'elle entreprend. #MuchMoreThanJustAJob Le poste est basé à Paris et chez nous, vous bénéficierez de 10 jours de télétravail par mois, de 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, de développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté.e par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier) Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait.e pour travailler avec nous : De formation supérieure en école d'ingénieur ou équivalent, vous disposez d'au moins cinq ans d'expérience sur des fonctions similaires. Vous maîtrisez : * Les méthodes agiles ; * Le langage SQL, les bases de données SQL Server, le SSIS et la stack technique Microsoft ; * Les techniques de modélisation des données et les problématiques de stockage des données ; * L'ETL et le big data ; * Les outils DevOps. Vous êtes : * Capable de vous adapter rapidement au contexte de Natixis Wealth Management (NWM) ; * Adaptable ; * Reconnu pour votre leadership. Vous maîtrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé.e en répondant à cette annonce.",,Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
24,56896,https://www.welcometothejungle.com/fr/companies/advanced-schema/jobs/data-engineer_paris,Data Engineer,ADVANCED SCHEMA,"{NoSQL,Java,BASH,SQL,Python}",Télétravail partiel possible,"19, Rue Galilée, Paris, 75116","IT / Digital, SaaS / Cloud Services, Big Data",CDI,2023-03-26,"ADVANCED SCHEMA, spécialiste des problématiques data, accompagne ses clients depuis plus de 20 ans dans la réussite de leurs projets stratégiques. Nous concevons des solutions data centrées sur les usages et la performance. Notre positionnement : une expertise de pointe, des projets à fort enjeux métiers et technologiques, toujours menés à bien dans le respect de notre ADN. Nos valeurs et notre mode de fonctionnement font d’ADVANCED SCHEMA une entreprise unique, guidée par ses fortes convictions technologiques. Chaque collaborateur apporte son expertise et son savoir-faire pour participer à l’engagement collectif de son équipe. Prenez part à l’expérience ADVANCED SCHEMA portée par la diversité des projets dans lesquels vous pourrez exprimer pleinement votre potentiel. En tant que Data Engineer, vous aurez les missions suivantes : -Concevoir des modélisations physiques -Construire des mappings techniques et rédaction de spécifications d’alimentation. -Développer des flux des données -Contribuer au pilotage de projets, de proof of concepts -Participer à des missions d’expertise N’hésitez pas à postuler même si vous ne répondez pas à toutes les exigences. Nous accordons autant d’importance à la capacité d’apprendre qu’à la maîtrise d’une technologie. Ce poste est à pourvoir en stage et CDI Compétences professionnelles & niveau d’études requis : -Vous êtes titulaire d’un diplôme Bac +3 minimum dans le domaine de la data -Vous possédez minimum 1 an d’expérience dans le métier -Être enthousiaste à l’idée d’apprendre de nouvelles technologies -Expérience de la méthodologie Agile / Scrum -Capacité à planifier et à prioriser les tâches et les activités confiées en autonomie -Maîtrise de l’anglais oral et technique obligatoire -Expérience avérée dans l’écriture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL Etape 1 : Rapide échange téléphonique, dont le but est d’échanger sur ce que vous recherchez, et d’apprendre à se connaître. Etape 2 : Entretien en visioconférence afin d’échanger sur votre parcours et votre motivation Etape 3 : Entretien physique au sein des locaux d’ADVANCED SCHEMA pour finaliser le processus de recrutement.","Advanced Schema is seeking a Data Engineer with expertise in Advanced Schema and data-related issues to join their team. The ideal candidate will possess a minimum of a bachelor's degree in data-related fields with at least one year of experience in the field. The candidate should also have a strong ability to learn new technologies and experience with Agile/Scrum methodologies. They should also possess excellent problem-solving skills and be proficient in at least two of the following languages: BASH, SQL, Java, Python, or NoSQL.",Bac +3,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
22,61959,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_rennes_ASI_61x8rWj,Data Ingénieur  - Manipulation et valorisation des big-datas,ASI,"{Oracle,Snowflake,Cassandra,Azure,Cloudera,MySQL,MongoDB,Databricks,Kafka,NoSQL,ElasticSearch,RabbitMQ,Java,SQL,Hadoop,Scala,Flume,PostGreSQL,Spark,Python}",Télétravail partiel possible,Rennes,"IT / Digital, Transformation, Big Data",CDI,2023-03-30,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Vous aurez pour mission de : Concevoir et réaliser un sourcing de données Big Data Temps réels ou non Maîtriser les formats de données non structurés et savoir les manipuler Concevoir et réaliser une chaîne de traitement dans un environnement Big Data Concevoir et réaliser des applications et API utilisant les données valorisées Gérer et administrer les bases de données filesystem et NoSQL Ecosystème en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra. Langages de développement : Python, Java, Scala. Compétences principales : Hadoop (Cloudera)et/ou une solution de base de données NoSQL Le requêtage SQL, HiveQL Le développement Spark avec SQL, Python et/ou Scala Le développement Java (API en particulier) Les bases de données relationnelles (PostGreSQL, Oracle, SQLServer, MySQL…) Compétences spécialisées : Base de données NoSQL​ (ElasticSearch, MongoDB, Cassandra…​) Solutions Cloud​ (Azure Data (Datalake Store, Databricks), Snowflake…​) Message broker​ (Kafka, Flume, RabbitMQ…)","ASI is a French digital expertise firm that supports public and private organizations in their digital transformation by developing digital services for their employees, partners, and clients. They are looking for a Big Data Consultant who can design and implement data sourcing, processing and application development using Hadoop, Spark, Kafka, Elasticsearch, MongoDB and Cassandra among other tools. Candidates should have expertise in SQL querying, HiveQL, Spark development using SQL, Python, and Scala, as well as experience working with NoSQL databases like ElasticSearch, MongoDB, and Cassandra, as well as Cloud solutions like Azure Data and message brokers like Kafka, Flume, and RabbitMQ.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
21,66884,https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f_paris_EL_q5RNw31,Data Engineer,Eleven Labs,"{Jupyter,SnowFlake,GO,Node,Spark,BigQuery,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"102, Rue du Faubourg Saint-Honoré, Paris, 75008","Logiciels, IT / Digital, Audit",CDI,2023-04-07,"Eleven Labs est une société de conseil, spécialisée en création et réalisation de projets Web agiles de qualité. Les astronautes interviennent sur des missions qu’ils choisissent, et elles sont axées sur du développement, de l’architecture, de la conduite de projet Agile, de l’audit et du conseil. Au quotidien, tout est fait pour encourager la progression et l’épanouissement technique, à travers des plateformes dédiées à l’apprentissage ( le blog , le codelabs , des accès à Udemy et egghead.io …), ou grâce à des événements internes (workshops, meetups, formations…) réguliers. Seras-tu notre furtur.e Data Engineer ! Un peu de contexte ☝️ De plus en plus de nos consultants s’intéressent de près au sujet de la Data, ce qui nous a poussé à explorer ces problématiques chez nos clients et de constater un besoin fort d’accompagnement de leur part. Nous recherchons donc la personne qui ouvrira la voie à cette expertise chez Eleven Labs et qui accompagnera la création de l’escouade Data ! Nos attentes 🧠 Nous recherchons quelqu’un d’expérimenté/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de répondre au mieux aux problématiques qui lui seront soumises, pour qui les requêtes SQL, NoSQL sur BDD n’ont aucun secret, et qui maîtrise déjà une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake). 🍒 Cerise sur le gâteau : on cherche aussi un profil maîtrisant les langages type Python, Java, GO et Node.JS pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribué. Des connaissances dans l’utilisation d’outils ML et d’environnement Cloud en général sont un vrai plus. 🎭 Côté personnalité, et outre cet aspect expérimenté et “ouvreur de voie”, on cherche quelqu’un de moteur, avec un réel enthousiasme à transmettre ses connaissances, former et échanger. Les missions 🕵️ Les missions proposées te feront intervenir dans des secteurs divers, avec des cas d’usage variés souvent en lien avec le marketing et impliqueront principalement : d’être force de proposition quant au choix des outils et pratiques ; faire de la data visualisation (B.I.) d’assurer l’extraction de données et leur transformation de gérer la mise en place from scratch de pipelines et data lakes. Nos engagements 💪 Tu participeras activement au développement de l’escouade Data chez Eleven Labs pour laquelle nous avons de véritables ambitions de production de contenu externe (talks, articles, implication dans le recrutement…), et interne (workshops, animation de la communauté Data, mentorat de profils juniors…). 🔥 Nos clients sont des sites grand publics principalement des secteurs médias/presse et e-commerce, avec pour points communs un fort accent mis sur la qualité, et un fonctionnement en méthodologie Agile. 💖 Tu travailleras avec une équipe de passionné(e)s qui aime partager, remettre en question ses façons de faire, et trouver de nouvelles idées pour gagner en efficacité. 🤝 Tu évolueras dans une culture d’entreprise qui valorise le collectif : nous restons même à 100 salariés une entreprise où les gens se connaissent et échangent quotidiennement (pour parler de leur job mais aussi du dernier meme ou d’un compte Twitter improbable). Si tu es intéressé(e), comment ça se passe ? 🗨️ Tout commence par un entretien d’introduction Tu t’entretiendras avec une recruteuse tech qui te suivra tout le long de ton parcours chez nous. Vous parlerez de tes attentes et de ce que tu aimes dans ton job, et elle te présentera Eleven Labs. 👋 Ensuite il y a un entretien de cas pratique Pour avoir une idée de ce qui t’attend, on te propose de rencontrer Rémy (Data Architect) ainsi que Charles-Éric (Directeur Technique). 🏠 On conclut par une visite des locaux On t’invite dans les locaux ! Tu pourras y rencontrer d’autres membres de la fusée pour échanger sur leurs parcours et le tien autour d’un café.",,Non spécifié,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
19,49633,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris-or-remote-france_paris_DATAI_M5g1m4J,Software Engineer Data Presentation - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",Télétravail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with frontend and backend development skills to create usable, intuitive, and beautiful interfaces and scalable engines for its Dataiku DSS platform. The ideal candidate has experience in software development and is interested in data visualization tools, is customer-oriented, and has firsthand experience building a real product. The role involves building components to allow users to create and display charts, dashboards, and ad-hoc web applications in a scalable way, prototyping and creating new ways to interact with data, and working with product managers and UX designers to refine solutions. The company values autonomy, work-life balance, and a diverse and inclusive culture.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
18,39694,https://www.welcometothejungle.com/fr/companies/wakam/jobs/data-engineer-python_paris,Data Engineer Python,Wakam,"{GIT,databricks,python,Django,Snowflake,magic,R,snowflake,Azure,SQL,Python}",Télétravail partiel possible,"120-122 rue Réaumur, Paris, 75002","Assurance, FinTech / InsurTech, Blockchain",CDI,2022-11-29,"Wakam (qu’on prononce Ouakam pas Vakam) est un assureur B2B qui conçoit, en marque blanche, des produits d’assurance sur-mesure pour ses partenaires distributeurs (des courtiers en assurance mais cela peut aussi être des acteurs du e-retail, des néo-banques, des compagnies aériennes). Nos produits d’assurances ont la particularité d’être embarqués dans les produits ou services proposés au client final (par exemple, tu prends une trottinette en libre-service 🛴, tu es assuré automatiquement). Wakam est présent dans 32 pays européens (point bonus si tu arrives à les citer en entretien) ça commence à faire beaucoup et on risque de ne pas s’arrêter là car notre part du chiffre d’affaires en dehors de France est en forte progression (58% à la fin de l’année 2020). C’est pour cette raison que l’on recrute de futurs Wakamees qui parlent bien anglais (mieux que Brian in the kitchen hein !). Chez Wakam nous croyons à la formule « for profit & for good ». Depuis mars 2021, nous sommes une Société à mission, ça veut dire que notre raison d’être « Rendre l’assurance transparente et impactante » est inscrite dans nos statuts. Nous avons défini 9 engagements concrets pour donner corps à cette mission comme par exemple, rédiger les contrats d’assurance en langage clair (fini les formules alambiquées et les petites lignes illisibles). Nous créons aussi pour des associations, des produits d’assurance sur lesquels nous ne faisons aucune marge. Notre culture ? Free to impact. Une culture où tout est possible, où toutes les idées sont considérées, où chacun a un impact sur la transformation de l’assurance ! Quête de liberté ? Soif d’autonomie ? Si tu es intrépide et aimes le challenge (ouai ouai je sais ce mot que toutes les startups ont à la bouche) Wakam devrait être fait pour toi. Nos 11 marqueurs culturels en disent long sur qui nous sommes, à découvrir sur notre site web ! Au sein de l’équipe Project Data du Data Office, le Data Engineer/Developpeur Python participera aux développements de produits data sur notre asset End To End Data Factory. Ces produits sont autour de la qualité de données, des flux d’intégration de données et de moteur de calculs de KPIs, construits à l’aide du langage Python. Les produits sont mis en œuvre dans une approche product management et des pratiques DevOps. Nous travaillons d’un écosystème technique Azure et Snowflake. Description du poste au sein de l’équipe projet du Data Office : Développer en python des features/US pour construire nos produits data : Industrialisation de contrôles de données techniques et fonctionnelles, sur plusieurs types de formats : fichiers dans Azure Datalake : csv, json, xml, xlsx, tables parquets databricks, tables BDD snowflake, logger les résultats dans snowflake. Interfacer ces produits en construisant des APIs, créer des IHMs pour la mise à jour des paramétrages et les process de validations. Créer des flux de collecte de données en requêtant des APIs. Réaliser un moteur de calculs de KPIs de réassurances. Travailler en méthodologie Agile, en collaboration avec les Products Owner et les Business Analyst, détailler les US en tâches, estimer la complexité et les efforts d’implémentations Garantir la qualité et les performances de ces développements en mettant en place des stratégies de test automatique et de déploiement continu Accompagner le Product Owner et les Business Analysts lors des recettes des nouvelles features/Users Stories Rédiger des spécifications techniques et documenter les développements réalisés Être force de proposition et proposer des solutions pour améliorer de façon continue les produits data (E2E DataFactory) Participer au maquettage ou à la mise en place de Proof of concept dans le cadre de l’activité de R&D Veille technologique ✯ Le profil recherché Vous avez au minimum 5 ans d’expérience sur un poste similaire, Vous êtes un Master sur Python (Exemple de librairies : standard (os, time, date), panda, json, regex, yaml, magic, requests…) et les frameworks Python tels que Flask, Django,... pour créer des APIs et IHMs n'ont plus de secret pour vous DevOps (Azure DevOps, VS Code, GIT, CI/CD …) SQL Etre force de proposition, créatif et innovant, Porter un grand soin à la qualité et à la performance de ses développements Process de recrutement Echange avec Danny, Talent Acquisition Expert Echange technique avec Cédric, BI Project Manager Echange avec l'équipe Echange avec Raphaël, Chief Data Officer Echange RH avec Amandine - Chief People Officer et/ou Laura - Head of Talent => Welcome @Wakam 🙌 Positive energy, agility, and team spirit are essential to support Wakam in its hyper-growth! You have the Wakam mindset? Join us! More about us Our culture? Free to impact . A culture where everything is possible, where all ideas are taken into consideration, where everyone has an impact on the transformation of insurance! Hungry for freedom? Thirsty for autonomy? If you are bold and like challenges (yeah yeah! That one word that all startups have at the tip of their tongues), then the Wakam adventure might be made for you! Discover -on our website- who we really are with the 11 cultural markers that so well describe us! Mindset compatibility with our ‘Free to Impact’ culture: Think big Biased for action Curious and eager to learn Can say no and find solutions Aims for the moon (but please don’t stick on the moon) And above all: have fun working together 🤜🤛 ! Wakam is not based on a hierarchy but on a methodology where everyone finds his role and knows his objectives. With a flat hierarchical system and a highly collaborative operating model, Wakam is an extremely agile and transparent company. Every last Friday of the month, it's Free.day at Wakam, a day without meetings to take a step aside and dedicate ourselves to skills sponsorship or other activities (because we are curious, I remind you). Full-remote is a reality at Wakam (there is even one Wakamee who works from his sailing boat ⛵) Last but not least : we are nice and we have fun! (you'll find out by yourself 😉) What happened in 2021 @Wakam?","Wakam is hiring an experienced Data Engineer/Python Developer to join their Project Data team and develop data products related to data quality, data integration, and KPIs using Python. The candidate should be proficient in Python libraries and frameworks, have a DevOps mindset, and possess strong problem-solving and collaboration skills. Wakam is a B2B insurer that creates customized insurance products for its partner distributors, and its mission is to make insurance transparent and impactful. They operate in 32 European countries and believe in a culture of freedom to impact, where everyone's ideas are valued, and every employee has a hand in transforming insurance. The company is a Société à mission, which means that its raison d'être (reason for being) is ingrained in its statutes.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
17,37362,https://www.welcometothejungle.com/fr/companies/addixware/jobs/data-engineer-h-f_sophia-antipolis,Data Engineer,AddixGroup,"{Azure,explosion,Python,DataBricks}",Télétravail partiel possible,N,Logiciels,CDI,2022-10-18,"AddixData (ADD) fait partie du premier groupe français d’ingénierie informatique spécialisé dans la transformation digitale. ADD constitue l’un des 2 hub technologiques et B2B d’AddixGroup. Il fournit des solutions et des services aux entreprises qui veulent apporter de l’intelligence à leurs données informatiques. L’offre Data est née de l’explosion du volume des données informatiques et du fait que nous considérons qu’une donnée informatique dénuée d’intelligence n’a aucune valeur. Il est devenu essentiel d’en faire le tri et d’apporter de l’intelligence humaine à toutes ces données afin de construire un monde qui soit plus vertueux. Composé d’Ingénieurs et Docteurs en Data Science, ADD répond à l’ensemble des problématiques liées à la Data : Analyse des données, nettoyage et traitement, machine learning, business Intelligence, déploiement de bases de données et intégration de solutions data. Nous sommes présents sur Paris, Aix-en-Provence et Sophia-Antipolis. AddixData a remporté un projet innovant pour son partenaire spécialiste de la valorisation immobilière. Notre client recupère, traite et valorise beaucoup de données provenantes de différentes sources, afin de proposer à leurs clients des informations clés des biens immobiliers, les points d’intérêts et les risques permettant à l’acheteur de se positionner en sécurité sur l’achat d’un bien. Dans ce contexte, vous intervenez en temps que Data Engineer pour piloter ce projet. Profil: Vous maîtrisez DataBricks Vous connaissez Azure Python n’a pas de secret pour vous? Vous souhaitez rejoindre une équipe dynamique et agile ? Ce projet est fait pour vous !","AddixData is seeking a Data Engineer with expertise in DataBricks, Azure, and Python to lead an innovative project focused on real estate data processing and analysis. The ideal candidate will have experience in data cleaning, machine learning, business intelligence, and database deployment. A strong commitment to building a more virtuous world through intelligent data analysis is a must.",Bac +5 / Master,Entre 50 et 250 salariés,> 4 ans,2,1,0.04154662416233763
13,72980,https://www.welcometothejungle.com/fr/companies/opteven/jobs/data-engineer-f-h_villeurbanne,Data Engineer,Opteven,"{Tableau,PostgreSQL,Jenkins,SQL}",Télétravail partiel possible,"Rue Olympe de Gouges, Villeurbanne, 69100","Mobilité, Assurance",CDI,2023-04-22,"Société indépendante comprenant 950 collaborateurs et représentant 278 millions d’euros de chiffre d’affaires, OPTEVEN (www.opteven.com) est un des acteurs majeurs en France et en Europe de l’Assistance et de la Garantie Panne Mécanique. Notre croissance depuis plus de 10 ans sur ces deux métiers démontre que la qualité de nos prestations est plébiscitée par nos clients, professionnels de l’automobile et de l’assurance. Rejoindre OPTEVEN, c’est rejoindre une entreprise innovante, engagée dans la RSE et convaincue que le succès d’une entreprise se fait grâce aux talents qui la composent. Pour accompagner sa croissance et son évolution technologique, Opteven renforce sa DSI et recherche des Data Engineer F/H, rattaché(e) au responsable du Pôle Data/BI. Vous prenez en charge les spécifications et conceptions techniques, puis la mise en oeuvre de traitements de données (échanges, intégration, extraction) dans ou depuis nos systèmes et vous serez le référent sur les sujets de flux d’échanges avec nos clients (entrants et sortants). Vous serez également amené à travailler ponctuellement sur l’alimentation de nos entrepôts de données statistiques. Missions principales du poste : Vous concevez et développez les flux d’échanges inter-applicatifs au sein du SI OPTEVEN et avec les SI de ses clients/partenaires Vous analysez les impacts sur le SI, notamment sur les traitements existants, vous préconisez des modalités techniques d’intégration performantes, à l’état de l’art, et dans le respect des règles de sécurité d’OPTEVEN Vous analysez les besoins en lien avec les pôles métiers demandeurs Vous apportez une expertise technique auprès des interlocuteurs internes de la DSI, vous identifiez les traitements portant des risques potentiels de performances. Vous êtes force de proposition dans la re-engineering des chaînes de traitement Vous réalisez des tests unitaires et recette des développements effectués Vous êtes garant du bon fonctionnement des flux d’échanges et assurez la supervision, le support et le maintien en condition opérationnelle. Vous rédigez et enrichissez les documentations nécessaires à la base de connaissance : référentiels, procédures d’exploitation, spécifications techniques, gestion d’incident. Vous êtes en contact avec les équipes techniques de nos clients pour la gestion, la mise en place de flux entrants et sortants Vous êtes en relation avec les services métier internes pour répondre à leurs besoins en termes de données Vous travaillez en collaboration avec les équipes fonctionnelles et techniques dans le cadre de projets (lancements clients, mise en place de nouveaux référentiels…) Master en informatique avec une spécialisation en gestion de données. Une première expérience sur un poste équivalent est fortement appréciée. Compétences recherchées : Connaissances avancées en SQL Expérience de 2 à 3 ans minimum dans le domaine du traitement et de l’intégration de données, avec utilisation d’un ETL Vous avez des expériences d’utilisation de solutions d’ordonnancement, d’outils de ticketing Anglais professionnel à minima Qualités requises : Passionné(e) par la technique Adaptabilité Sens de la communication Rigueur Autonomie Organisation Environnement technique : ETL : Pentaho (version 5.2 et 9) Jenkins Base de données : PostgreSQL Tableau Poste en CDI OPTEVEN assure une prise en charge à hauteur de 60% de l’abonnement des transports en commun (ou une prime de transport) Participation aux contrats mutuelle et prévoyance Participation et intéressement Carte restaurant Télétravail : possibilité de faire jusqu’à 2 jours/semaine une fois la période d’essai validée Poste localisé à Lyon Villeurbanne (69) Rejoignez-nous !",,Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
12,72953,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer_bucharest,Data Engineer,EXTIA,"{go,GCS,Python,Scala,Hadoop,Spark,SQL,Git,GCP}",Télétravail partiel possible,Bucharest,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-04-22,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. ⚡Then what: Mastery in Spark-SQL API (ability to use the Spark-SQL API to design optimized Spark-SQL queries for big data environments); Mastery writing Spark UDF functions using optimized algorithms designed in Scala; Mastery writing Scala/Spark-SQL applications and debuggin code written in Scala/Spark SQL; Advanced or Mastery in SQL, preffered Big Query dialect (ability to write SQL optimised queries); Experience in writing stored procedures; Advanced knowledge of the Hadoop cluster architecture and Hadoop ecosystem; Basic Python programming skills to debug CI/CD pipeline processes; Experience with Git, InteliJ or an IDE equivalent; Expertise in JSON files manipulation; Basic knowledge of the GCP infrastructure(like GCP dataproc, Big Query SQL dialect, GCS, gsutils API). 🚀 You recognize yourself in the ""Who"" and you represent the ""What""? Apply and let's talk! ⚡First who: Flexible, you can adapt to different people and tools, ways of working and new ideas; Passionate and thirsty to learn, you like to keep up with the IT trends; Team player, you are convinced that “alone, we go faster, but together, we go further”;",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
11,56793,https://www.welcometothejungle.com/fr/companies/teleparis-galaxie/jobs/data-engineer_neuilly-sur-seine,Data engineer,Téléparis Galaxie,"{pandas,JavaScript,SQL,Python}",Télétravail partiel possible,"9, Rue du Commandant Pilot, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Edition, Presse écrite, Télévision / Production audiovisuelle",CDI,2023-03-26,"Teleparis Galaxie est une fabrique de contenus « signature » innovants et originaux. Développement web, production et diffusion, Téléparis Galaxie est un content producer à 360° travaillant avec les groupes audiovisuels, de grandes marques, et des médias digitaux indépendants. Fondé par Stéphane Simon en 1999, Téléparis a commencé par produire des émissions cultes pour la télévision. Depuis sa création, Téléparis Galaxie n’a eu de cesse de se réinventer, d’explorer de nouveaux territoires et d’innover en tenant compte des nouveaux médias et des nouveaux usages. Ainsi, Téléparis s’est diversifié depuis 10 ans dans le digital (développement de sites web et de médias indépendants en lignes, accompagnement digital et social etc.). Aujourd’hui, Téléparis c’est aussi une factory de près de 1000 m2 proposant à ses clients toutes les solutions de production : studios de tournage, de podcasts, montage et mixage, équipes de production et de réalisation, rédactions et pôles journalistes, teams développement web, Social Media Management et Data analysis, fonctions supports, bureaux et co-working… Toute la production de contenus est regroupée dans un lieu unique, Téléparis studio, à l’attention de grands comptes et de co-workers. Description : Rattaché au pôle innovations mais aussi en étroite collaboration la rédaction et la direction, vous serez responsable du développement et de la maintenance de l’en- semble des projets data du média. Vos principales missions : • Concevoir et développer des pipelines de données pour collecter, stocker, traiter et analyser les données à partir de diférentes sources (API, bases de données, fchiers, etc.). • Maintenir et optimiser les infrastructures de stockage et de traitement de données, y compris les bases de données SQL et les outils cloud (Google Cloud Platform, Big Query, Cloud Run, Vertex AI, etc.). • Collaborer avec les équipes éditoriales et commerciales pour comprendre leurs besoins en matière de données et concevoir des solutions de reporting, de visualisation et d’analyse adaptées. • Participer à la conception de nouveaux outils pour l’entreprise en utilisant des données pour informer les décisions. • Études statistiques ponctuelles sur des données propriétaires ou scrapées par vos soins. • Vous avez un diplôme d’ingénieur en informatique, en mathématiques, en statistiques ou dans un domaine connexe. • Vous avez une première expérience acquise au sein d’un environnement exi- geant où vous avez mené à bien des projets techniques. • Vous avez d’excellentes compétences en programmation en Python, y com- pris l’utilisation de pandas et d’autres bibliothèques pour l’analyse de don- nées. • Vous avez de l’expérience dans l’utilisation d’API pour collecter des données et dans le web scraping. • Vous avez des compétences en technologies cloud, des connaissances de SQL et des bases de données relationnelles, et des notions de JavaScript et de ReactJS. • Vous savez travailler de manière autonome et gérer plusieurs projets simulta- nément. • Vous avez un intérêt pour les réseaux sociaux, les média et l’audiovisuel. Type de contrat : CDI Salaire : selon profil Localisation : Paris","Teleparis Galaxie, a content producer, is seeking a data engineer to develop and maintain data projects across the media. The candidate should have experience with Python programming, API usage for data collection and web scraping, cloud technologies, SQL, and relational databases, as well as be able to manage multiple projects simultaneously. A degree in engineering, mathematics, statistics, or related fields is required, as well as experience working in a demanding environment. The position is a full-time contract in Paris.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
8,72905,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_a7WPg97,Data Engineer,FACILECOMM (SHIPPINGBO),"{Pandas,PostgreSQL,R,Airflow,AWS,Redis,SQL,MongoDB,Redshift}",Télétravail partiel possible,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-04-22,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait mené(e) jusqu’à cette annonce ! Peut-être est-ce toi, le/la futur(e) Data Engineer que nous attendons… En tout cas, nous l’espérons. Dans un premier temps, permets nous de nous présenter. Qui est Shippingbo ? La première chose que tu dois te demander c’est “qui est Shippingbo” et c’est une très bonne question ! Shippingbo est une technologie logistique e-commerce fondée en 2016, par la société facilecomm. Nous mettons à disposition des vendeurs en ligne une technologie qui leur permet d’optimiser toute leur chaîne logistique : depuis la récupération des commandes, jusqu’à leur expédition, en passant par la préparation. Pour la faire très simple, on est la technologie de l’ombre qui permet à ton site favori de te livrer dans les meilleurs délais, tout en te notifiant de l’avancée de ta commande. Pas mal, non ? Notre ambition : permettre à nos clients de proposer aux consommateurs un parcours d’achat au top, digne des géants du e-commerce ! Aujourd’hui, nous comptons pas moins de 1000 clients aux activités e-commerce assez variées : e-commerçants, retailers, fournisseurs, grossistes…. mais dont le point commun reste la vente en ligne ! Avec près de 72% de croissance en 2021 et plus d’1 milliard d’euros de GMV, nous sommes bien décidés à poursuivre sur cette lancée pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage européen d’ici 3 ans ! Shippingbo cherche aujourd’hui à développer les outils d’analyse qu’elle met à disposition de ses clients ainsi qu’à développer de nouvelles fonctionnalités se fondant sur l’analyse des données. En tant que data engineer, votre rôle sera de construire et maintenir les entrepôts et pipelines de données. Vos missions principales consisteront à : Participer à la définition des schémas de données et aux choix d’architecture ; Définir et optimiser les requêtes faîtes par l’API et celles au cœur des pipelines ; Préparer des datasets exploitables à des fins d’analyse ; Identifier de facon plus générale les moyens optimaux de répondre à l’ensemble des requêtes de données ; Optimiser également le fonctionnement des pipelines et maintenir les systèmes surveillant leur bon fonctionnement et la qualité des données ; Participer à l’administration, la configuration et le paramétrage des bases de données. - Vous avez au moins 2 ans d’expérience comme data engineer (ou des rôles similaires) et dans la construction et la maintenance de pipelines de données ; - Vous avez une connaissance approfondie de SQL , de l’optimisation de requêtes et des entrepôts de données ; - Vous avez une expérience avec au moins une base de donnée orientée colonnes ; - Idéalement vous avez également une expérience avec une base de donnée orientée documents et une base de donnée clé-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en métro, arrêt Ramonville) Rattaché au département R&D de l'entreprise Mise à disposition d’outils informatiques Tickets restaurant >>> Venez découvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversité occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'égalité professionnelle et l'emploi des travailleurs en situation de handicap. A compétences équivalentes, ce poste est ouvert à tous.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
7,56972,https://www.welcometothejungle.com/fr/companies/yassir/jobs/data-science_paris,Data Science Engineer (f/m/x),Yassir,"{color,Shell,SQL,Python}",Télétravail partiel possible,"128, Rue La Boétie, Paris, 75008","Application mobile, Intelligence artificielle / Machine Learning, Mobilité",CDI,2023-03-26,"Yassir is the leading super App for on demand, ride-hailing, last-mile delivery, payment services and more, set to change the way daily services are provided. It currently operates in 45 cities across multiple countries. It has raised $150 million in Series B funding, five times what it raised in its previous priced round last November with world class investors such as BOND and Y Combinator, which is the precursor of the likes of Airbnb, Stripe, Dropbox, Doordash, among others. We offer on-demand services such as ride-hailing and last-mile delivery. Building on this infrastructure, we are now introducing financial services to help our users pay, save and borrow digitally. Helping usher the continent into a digital economy era. We’re not just about serving people - we’re about creating a marketplace to bring people what they need while infusing social values. About Yassir Yassir is the leading super App for on demand, ride-hailing, last-mile delivery, payment services and more, set to change the way daily services are provided. It currently operates in 45 cities across multiple countries. It has raised $150 million in Series B funding, five times what it raised in its previous priced round last November with world class investors such as BOND and Y Combinator, which is the precursor of the likes of Airbnb, Stripe, Dropbox, Doordash, among others. We’re not just about serving people - we’re about creating a marketplace to bring people what they need while infusing social values. Global context and problematic of the subject Recent progress in the field of deep learning has led to major advances in Natural Language Processing (NLP). Among its most complex tasks, sentiment analysis has also made great progress thanks to the possibility of training efficient neural models for understanding languages using dialogue data collected from different outlets (emails, SMS, comments, question answering, booking an event, etc.). However, these models are still very limited when it comes to providing accurate results when analysing the Arabic language [1]. Arabic is a category IV language in parameters of complexity and difficulty to learn [2] and has a high ability for new word formations with rich semantic meanings [3]. Progress is being made regarding this when it comes to standard arabic, some dialects that are more or less formal (Gulf Peninsular, Levantine, and Egyptian) [4]. However, none are made when it comes to Maghreb dialect (Morocco, Algeria, Tunisia)[4]. Scientific objective - results and obstacles to be overcome The objective of the thesis is to propose solutions to mutualise natural language understanding and sentiment analysis, that is to study the progressive fusion of various tasks mixing language diarization and language transliteration for Arabic representation or manipulation. The context of application will first be that of dialect written only in Arabic, then that of full form dialect with both latin and arabic characters and word from different languages. The focus will be on the development of original and efficient learning strategies for the construction of these multi-task neural models, rather than testing existing models blindly. Among these strategies, the use of prompting techniques as well as attention models is highly anticipated [5-7]. The work will be based on local corpora developed using comments extracted from the different apps of YASSIR. In this respect, one of the main obstacles is labeling this data in meaningful way within the learning process, both in terms of the given sentiment and transliteration. About your experience Deep learning, machine learning Natural language processing Python, Shell SQL Optionally, knowledge extraction and management or graph databases Google Cloud Platform Good communication in English, both oral and written Education required (Master's degree, engineering degree, PhD, scientific and technical field, etc.) Degree: Master's degree or engineering degree Field: Computer science or apple math with a focus on machine learning Interested candidate need to send their transcripts from the last year of study (Master 2) and at least 3 reference contacts (e-mail and phone number) preferably of teacher/supervisor who are experts in the fields of machine learning, artificial intelligence or natural language processing. References M. Al-Ayyoub, A. A. Khamaiseh, Y. Jararweh, and M. N. Al-Kabi, “A comprehensive survey of arabic sentiment analysis,” Information Processing & Management, vol. 56, no. 2. Elsevier BV, pp. 320–342, Mar. 2019. doi: 10.1016/j.ipm.2018.07.006. Foreign Service Institute (FSI). 2021. Foreign Language Training. URL https://www.state.gov/foreign-language-training/ . K. Shaalan, S. Siddiqui, M. Alkhatib, and A. Abdel Monem, “Challenges in Arabic Natural Language Processing,” Computational Linguistics, Speech and Image Processing for Arabic Language. WORLD SCIENTIFIC, pp. 59–83, Sep. 19, 2018. doi: 10.1142/9789813229396_0003. K. Meftouh, K. Smaili, and Nadjette Bouchemal, “A study of non-resourced language: the case of an Algerian dialect,” The third International Workshop on Spoken Languages Tech-nologies for Under-resourced Languages , vol12. 1-7. 2012, doi: 10.13140/RG.2.1.4881.1041. Liu, H., Paola Garcia Perera, L., Zhang, X., Dauwels, J., H Khong, A. W., Khudanpur, S., & Styles, S. J. (2021). End-to-End Language Diarization for Bilingual Code-Switching Speech . https://doi.org/10.21437/Interspeech.2021-82 Chowdhury, S. A., Hussein, A., Abdelali, A., & Ali, A. (2021). Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR . https://doi.org/10.21437/Interspeech.2021-1809 Jia, Y., Zen, H., Shen, J., Zhang, Y., & Wu, Y. (2021). PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS . https://doi.org/10.21437/Interspeech.2021-1757 Process Candidates will be evaluated in 4 steps (no expectations are made) Phone interview/screening Technical interview with our applied researcher Programming assignment, candidates need to read a paper and implement it. Reviewing the programming assignment. *As a company, we are passionate about diversity and inclusion, 40% of our team are women leaders in the tech sector. Research shows that women do not apply for jobs if they do not meet all of the requirements. We would like to hear from you if you feel you would be a good fit for us! Do you want to become part of our first-class team? Then you absolutely have to send us your application. 🚀 PS: And if you want to stand out in your application, just let us know in your cover letter why we should have in our team. 💡 Diversity & Inclusion & Engagement: We celebrate diversity and are committed to creating an inclusive environment for all employees, as we believe diverse teams are more successful in the long term. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, and we encourage all people equally to apply for jobs with us.","Yassir, a super app for on-demand services, is seeking a candidate with experience in deep learning, machine learning, natural language processing, Python, Shell, and SQL for a thesis project focused on sentiment analysis and natural language understanding in Arabic. The objective is to build multi-task neural models for Arabic representation and manipulation using local corpora collected from Yassir's apps. The company highlights its commitment to diversity and inclusion and encourages all qualified candidates to apply.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.04154662416233763
5,57012,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_z7WGAV0,Data Engineer,EXTIA,"{Microsoft,Jenkins,Git,Scala,Airflow,Kubernetes,Spark,Azure,SQL,Python}",Télétravail partiel possible,Paris,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-03-26,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Maitrise de l’écosystème Microsoft Azure Data Factory, Azure Data Lake est un plus Maitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala… Maitrise des bonnes pratiques de développement et méthodes agiles Base de données : SQL, Postgré SQL (Paas) et modélisation de la donnée Connaissance des systèmes de gestionnaire de conteneur (Kubernetes,…) Connaissance des outils de déploiements : Jenkins, Git, maven, Ansible Qualités relationnelles et capacité à gérer nombreuses interactions Dynamisme, autonomie et envie de découvrir des manières différentes/innovantes de faire #LI-MV2 Rigoureux , vous ne laissez rien au hasard, Efficace , vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui, Autonome , vous savez mener vos missions à bien sans aide","Extia, an IT, digital, and engineering consulting firm, is looking for a candidate proficient in Microsoft Azure Data Factory, Azure Data Lake, and IT technologies such as Power BI, Spark, Airflow, Python, and Scala. The ideal candidate should also have adequate knowledge about Kubernetes, Jenkins, Git, maven, and Ansible. The skills required for this role include good communication skills, the ability to manage multiple interactions, rigor, efficiency, and autonomy.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
2,57011,https://www.welcometothejungle.com/fr/companies/devoteam-revolve/jobs/data-engineer-experimente-h-f,Data Engineer expérimenté,Devoteam Revolve,"{UNIX,DynamoDB,Glue,Lambda,Snowflake,Azure,Docker,MLlib,EC2,Kinesis,Athena,Databricks,GitLab,PowerBI,QlikView,Kafka,Linux,Git,PyTorch,linux,ElasticSearch,Jenkins,Keras,Kubernetes,AWS,Java,D3,SQL,Hadoop,Tensorflow,EMR,Scala,Redshift,Airflow,S3,Spark,GCP,Python,Tableau}",Télétravail partiel possible,Paris,"IT / Digital, SaaS / Cloud Services",CDI,2023-03-26,"Nous sommes une communauté d’explorateurs et d’exploratrices en constant apprentissage ! Le savoir et le partage sont au cœur de notre raison d’être. Une carrière chez Devoteam Revolve, c’est tracer une trajectoire qui vous permet de donner le meilleur de vous-même et de révéler vos singularités. Nous pensons notre organisation au quotidien pour permettre à nos collaboratrices et collaborateurs de produire du savoir sur les nouvelles pratiques et les nouveaux usages apportés par la technologie. Le débat et la curiosité intellectuelle qui nous caractérisent nous permettent de toujours repenser nos actions et d’améliorer notre savoir-faire et savoir-être. Nous sommes convaincus que la technologie n’est pas neutre et qu’il est vital d’apporter du sens et de l’éthique dans notre façon de travailler en prenant en compte les enjeux sociétaux et environnementaux auxquels nous devons faire face. En constant mouvement, nous gravitons dans des écosystèmes hyper technologiques toujours en évolution. Notre projet concrétise les réflexions sur le sens que nous souhaitons donner à la technologie et notre volonté de lutter contre les raccourcis intellectuels et de proposer des alternatives. Et pour cela, nous avons besoin de vous ! Si vous êtes intéressé·e d’intégrer une équipe qui challenge ses pratiques et révèle les singularités de chaque membre de notre collectif, alors cette annonce est faite pour vous ! Envie de rejoindre une équipe de “builders” qui travaillent sur de vrais projets de Data en production et à l’échelle ? Vous êtes au bon endroit ! Vous avez au moins 2 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…) dans un context agile Vous disposez de solides connaissances sur les architectures de données et les environnements cloud (GCP, Azure, AWS…) Vous disposez d’une expérience en visualisation de données (PowerBI, Tableau, QlikView, D3.js…) Vous maîtrisez au moins un langage de programmation spécifique (Spark, Scala, Python, Java, SQL) Vous maîtrisez des systèmes d’exploitation (UNIX, Linux, Solaris ) avec une expertise dans le stockage de données et les outils ETL. Vous avez une bonne culture DevOps, une bonne communication opérationnelle et une forte capacité d’adaptation. Vous êtes conscient·e de la valeur que peut apporter l’automatisation. Vous êtes convaincue par la culture Data, Cloud, tech et souhaitez affirmer vos convictions. Vous cultivez votre savoir faire, et cherchez constamment de meilleures manières de faire et votre volonté de la partager avec les autres n’a pas de limite. L’organisation, la rigueur, l’autonomie font partie de vos qualités tout comme l’écoute et le partage. Vous maîtrisez également l’anglais à l’oral comme à l’écrit. Voici une liste non exhaustive de vos missions au quotidien, nous vous faisons confiance pour les prendre en main et les enrichir à votre façon : Participer à des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions hébergées sur une architecture AWS (Snowflake, Databricks, etc.) Développer et automatiser des pipelines d’ingestion de données avec des layers de traitement dans les technologies adéquates ( Python,, Spark, Kafka) Industrialiser des algorithmes de Data Science Concevoir des schémas de données extensibles et génériques pour répondre à des besoins de reporting ou autre (SQL) Développer des applications custom sur la base de composants génériques existants pour répondre à des besoins client (scénarisation, suivi d’entraînement de modèles prédictifs et d’IA, reporting, etc. Encadrer et superviser les consultant(es) juniors i.e., peer code review, application des best practices. Accompagner notre équipe commerciale sur la rédaction de propositions et des réunions d’avant-vente. Participer au développement de notre communauté interne (REX, workshops, articles, hackerspace. Participer au recrutement de nos futurs talents. Compétences techniques requises : La liste des technologies sur lesquelles vous seriez amené à travailler est la suivante : Python, PySpark ou Scala Spark. Scikit-learn, MLlib, Tensorflow, Keras, PyTorch ,LightGBM, XGBoost, Scikit-Learn et Spark (pour ne citer qu’eux) Les architectures Data et les environnements Hadoop, ElasticSearch, Kafka notamment. La stack AWS Big Data (Step Function, Lambda, ECR, S3, EC2, Code Build, Glue, outils d’automatisation et Devops, EMR, Redshift, Athena) Mise en place des environnements DevOps et Infra As Code Une bonne partie des outils Git, GitLab CI, Jenkins, Ansible, Terraform, Docker, Kubernetes, ML Flow, Airflow ou leurs équivalents dans les environnements Cloud. Bon à savoir : Revolve training est notre centre de formation permettant à toutes et tous de pouvoir suivre des formations et monter en compétence. Les Revolvers peuvent, au-delà de leurs missions, contribuer à Gravity, notre centre de recherche contributive qui explore les sujets liés à la sobriété numérique, l’éthique de la technologie, la souveraineté numérique, le machine learning au service de l’écologie, ou tout autre projet susceptible de faire progresser la communauté et ses pratiques. Flexibilité : Le télétravail fait partie du quotidien des collaboratrices et collaborateurs. Une mutuelle attractive La possibilité de choisir son matériel (mac, windows, linux, smartphone…). Une participation annuelle aux frais de transports Une carte ticket restaurant Offre exclusive Meyclub Ce qui fait la différence chez Devoteam Revolve, c’est notre façon de : Partager ouvertement, largement et délibérément les informations. Encourager les prises de décision autonomes de la part des collaborateurs et collaboratrices. Ne collaborer sur le long terme qu’avec des collaborateurs et collaboratrices hautement compétent·es et ayant un impact positif sur le collectif. Toujours rechercher une “meilleure façon” de faire les choses. Être ouvert·e d’esprit aux idées changeantes et aux approches nouvelles. Le processus de recrutement se déroule en trois étapes : Entretien RH pour apprendre à vous connaitre et comprendre votre projet professionnel ainsi que pour vous présenter l’entreprise et notre vision. Entretien Technique pour faire le bilan sur vos compétences et votre cohérence sur le poste. Entretien avec la direction pour se projeter ensemble sur votre trajectoire professionnelle au sein de Devoteam Revolve. Devoteam Revolve s’engage à promouvoir la diversité et est fier de favoriser l’égalité des chances au sein de l’entreprise. Chaque candidature est considérée sans tenir compte de l’origine, de la couleur de peau, de la religion, du genre, de l’identité de genre, de l’orientation sexuelle, du handicap, des caractéristiques génétiques ou de l’âge. Parce que nous voulons que le savoir soit utile au plus grand nombre, nous croyons à l’inclusion de toutes et tous.","Devoteam Revolve seeks a data engineer with a minimum of two years of experience in data engineering, solid knowledge of data architectures and cloud environments such as GCP, Azure, and AWS, and experience in data visualization with PowerBI, Tableau, QlikView, or D3.js. The company values DevOps culture, automation, and ethical considerations and expects the candidate to have expertise in programming languages such as Spark, Scala, Python, Java, or SQL, as well as storage and ETL tools. The ideal candidate must also have strong communication skills, autonomy, problem-solving aptitude, and a willingness to develop new skills and share knowledge. The company offers online training programs and grants access to research projects centered around digital sobriety, ethical technology, digital sovereignty, and machine learning for ecology. Devoteam Revolve is committed to promoting diversity, equity, and inclusion in its recruitment practices.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
31,67534,https://www.welcometothejungle.com/fr/companies/amazon-operations/jobs/data-center-engineering-operations-intern-m-f-d_paris,Data Center Engineering Operations Intern,Amazon Operations,{AWS},Télétravail partiel possible,Paris,"Ingénieries Spécialisées, Supply Chain, E-commerce",CDI,2023-04-07,"Vous connaissez sûrement Amazon, mais connaissez-vous Amazon Opérations ? C’est la branche opérationnelle d’Amazon, le cœur de son activité logistique. Amazon Opérations, c’est des procédés parmi les plus avancés au monde, des technologies toujours plus novatrices et une excellence opérationnelle qui permet de livrer efficacement les clients. Chez Amazon Opérations, les équipes sont engagées et guidées par des valeurs communes. C’est ce que vous retrouverez sur l’ensemble de leurs sites en France. Job summary Amazon Web Services (AWS) is growing rapidly, and we are looking for Data Center Engineering Operations Technician Interns to join our expanding Infrastructure Operations team in a 3 months' Fulltime internship program in our Data Center in Paris. This internship covers mandatory as well as voluntary university internships, please inform us which of the two you are aiming to pursue. As an AWS Intern, you will collaborate with experienced Amazon Technicians to ensure that the Data Center's mechanical, electrical and plumbing operates at 100% availability while maintaining first-class customer service to the teams and groups within the data centers. You will be tasked with driving innovation while reducing operational costs in the facilities. The Engineering Operations team is Amazon’s front-line responders for hands-on electrical and mechanical equipment troubleshooting and operations. you will work with equipment that supports mission-critical servers and must maintain better than 99.999% uptime. This equipment includes, but is not limited to, stand-by diesel generators, switchgear, UPS’s, PDU’s, AHU’s, chillers, cooling towers, chemical treatment systems, pumps, motors, VFD’s, and building automation systems. Upon successful completion of the internship program, you will receive an offer as a permanent EOT. Are you ready to embrace the challenge? Come build the future with us. Key job responsibilities Maintain mechanical and electrical equipment Assist root cause analysis of equipment failures Assist in troubleshooting of facility and rack-level events within internal SLA Take daily operational readings of all mechanical and electrical equipment Utilize internal CMMS to manage building workflows Previous facilities or data center operations experience Amazon est un employeur engagé pour l'égalité des chances. Nous sommes convaincus qu'une main d'oeuvre diversifée est essentielle à notre réussite. Nous prenons nos décisions de recrutement en fonction de votre expérience et de vos compétences. Nous apprécions votre envie de découvrir, d'inventer, de simplifier et de construire. La protection de votre vie privée et la sécurité de vos données constituent depuis longtemps une priorité absolue pour Amazon. Veuillez consulter notre Politique de Confidentialité pour en savoir plus sur la façon dont nous collectons, utilisons et traitons les données personnelles de nos candidats.",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
32,67595,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-f-h-cio-cib_paris_NATIX_rw4gg9,Data Engineer Risks  CIO CIB,Natixis,"{scala,java,Jenkins,spark,Scala,via,Spark,Java,Hadoop}",Télétravail partiel possible,"CHARENTON-LE-PONT, Paris, 94220","Banque, Transformation, Assurance",CDI,2023-04-07,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de votre âge, origine, orientation sexuelle, handicap... Au sein du pôle CIO CIB (Corporate & Investment Banking), dans le département Risks, vous rejoignez l'équipe DPM/Metrics Services, en tant que data engineer. Vous reportez directement au responsable de l'équipe Metrics Services, des évolutions du composant de l'application « golden data » et des PV de Stress Tests. Ce composant est la clef de voûte d'une chaine applicative FO to Risk pilotée par le programme SUNRISE. Au quotidien, vous avez pour missions de : Assurer l'évolution de l'application développée en spark/scala/java sur plateforme Hadoop dans un contexte projet ; Piloter des sujets multi-systèmes (référentiel market data, référentiel instrument, pricers front) ; Gérer l'industrialisation et la mise en qualité des données ; Faire la coordination avec : les business analyst de l'équipe, les autres équipes de développeurs du programme et les autres équipes IT (production applicative, infrastructure, support Hadoop) ; Assurer le support de niveau 2. La stack technique utilisée est la suivante : Java, Spark/Scala et Hadoop dans un environnement DevOps. Nous travaillons en méthode Agile (SAFe) et vous serez intégré à notre communauté de data engineers. #MuchMoreThanJustAJob Ce poste est basé à Paris avec la possibilité de télétravailler. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de leur âge, origine, orientation sexuelle, handicap... A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure, vous avez au moins 10 ans d'expérience en tant que data engineer dans le domaine fonctionnel de la finance de marché (type DSI). Vous maitrisez : * les problématiques d'optimisation de performance et vous proposez des solutions innovantes ; * la mise en place des protocoles de sécurité dans des environnements de développement ; * les langages Java et Hadoop ; * les bases du DevOps (intégration continue/automatisation, Jenkins, Sonar, XLDeploy, XLRelease …) ; * la méthode Agile (SAFe). Vous êtes : * passionné d'IT et data centric, vous souhaitez développer une véritable expertise technique sur des projets innovants. Vous maitrisez l'anglais avec un niveau B2 minimum. Dites-nous que vous êtes intéressé en répondant à cette annonce.",,Bac +5 / Master,> 2000 salariés,> 7 ans,2,1,0.04154662416233763
34,56721,https://www.welcometothejungle.com/fr/companies/directfamily/jobs/datovy-analytik-data-engineer_brnopraha-7_DF_4LoWXL0,Datový analytik/Data Engineer,Direct Family,"{Python,Kubernetes,AWS,postgreSQL,Argo,GIT}",Télétravail partiel possible,Brnopraha 7,"Application mobile, Mobilité, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Direct family je prostor, jehož součástí jsou firmy Direct pojišťovna, Direct Fidoo, Direct auto a Direct nadace, které vznikly, aby měnily svět kolem sebe k lepšímu. Je to místo, kde mohou svobodně tvořit, pracovat a posouvat věci, které mají pozitivní dopad na prostor, ve kterém žijeme. Zajímá tě, jak probíhá analýza hlasových služeb, obrazových dat nebo analýza chovaní uživatelů pomocí umělé inteligence? Budovaní datových pipelines v cloudu? Sleduješ novinky v oblasti zpracování dat? Baví tě tvořit nové věci a přemýšlet out-of-the-box? Chceš zanechat stopu a změnit fungování v nejrychleji rostoucí pojišťovně na českém trhu. Pak hledáme právě tebe! Co tě u nás čeká? Aktivní spolupráce s týmem Advanced Analytics a budování datových pipelines. Vývoj a správa orchestrace datových toků. Práce se zajímavými daty a spolupráce nad projekty nejen z oblasti pojišťovnictví. Integrace externích dat, práce s REST API. Jak si tě představujeme?​ Máš za sebou alespoň rok vývoje v jazyce Python a rozumíš základům programování. Verzováním kódu pomocí GIT nástrojů pro tebe není žádný problém. Máš nadšení pro data a umíš samostatně a systematicky plnit úkoly. Rád se učíš nové technologie a chceš tvořit prostě to nejlepší. CI/CD nejsou pro tebe zkratky hudební skupiny. Zkušenosti s Kubernetes, Argo, TeamCity výhodou. Rozumíš datovým typům, umíš si transformovat data, práce s relačními databázemi je tvůj denní chléb. Znalost MSSQL, postgreSQL výhodou. Znalost AWS výhodou. Máš rád výzvy a rád se rozvíjíš.","Direct family is seeking a Data Engineer with at least one year of experience in Python development and basic programming skills to work with the Advanced Analytics team in building data pipelines in the cloud, integrating external data, and working with REST APIs. The ideal candidate should have a passion for data and be able to work independently and systematically on tasks, as well as continuously learn new technologies. Experience with Kubernetes, Argo, and TeamCity is a plus, as is familiarity with MSSQL, postgreSQL, and AWS.",Sans diplôme,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
56,73347,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-engineer-cloud-f-h_toulouse_CG_eV3RDoQ,Data Engineer Cloud -,CS GROUP,"{IAM,Python,Cassandra,AWS,dynamoDB,Scala,Grafana,EC2,HBase,Java,Hadoop,Spark,Docker,Kubernetes,Airflow,SQL,S3,MongoDB}",Télétravail partiel possible,"6 Rue Emmanuel Arin, Toulouse, 31300","Ingénieries Spécialisées, Aéronautique / Spatiale, Energie",CDI,2023-04-22,"La mission de CS GROUP : être à la pointe des technologies pour garantir la sécurité de tous dans un monde en pleine mutation. L’expertise reconnue de CS GROUP lui permet d’intervenir là où les enjeux de sécurité sont les plus sensibles : défense, spatial, aéronautique, énergie… Et, aussi, là où les réponses sont à inventer ou à réinventer: lutte anti-drone, cybersécurité, traitement de données satellitaire… Le positionnement de CS GROUP en fait un acteur unique sur son marché : son expertise technique se combine avec une forte affinité avec les métiers de ses clients. À la clé, un capital confiance qui lui ouvre les portes d’un fort développement partout dans le monde pour des interventions tout au long de la chaîne de valeur. Conseil, conception, développement, intégration, maintenance et support aux opérations… Nous recrutons un.e Ingénieur Data Engineer Cloud pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data & Process Intelligence . Elle accompagne nos clients dans leurs problématiques associées à la transformation digitale. Nos offres se déclinent autour de la data intelligence & de la maintenance prédictive, de la digitalisation des processus industriels et du SI Métiers. Votre mission : Dans le cadre de projets, vous rejoindrez notre équipe et participerez aux missions suivantes : Concevoir et développer des outils de traitements et processing de données - Déploiement, industrialisation et tests de solutions développées, - Monitoring et analyse de flux de données. - Rédiger les rapports d’analyse de données, et assurer la présentation au client - Savoir utiliser les outils d'analyse et de visualisation de données - Environnement cloud L’environnement technique : Bases de Données : AWS RDS, No SQL, MongoDB, Apache Cassandra, HBase et Amazon dynamoDB Framework : Hadoop, Hortonworks, Spark, Airflow Outils de containerisation : Docker / Kubernetes Cloud computing: AWS (IAM, S3, EC2, etc.) ou équivalent chez un autre fournisseur de services cloud Langages: Java, Python, Scala Visualisation : Dash, Grafana, Python Qui êtes-vous ? De formation Bac+5, vous avez une première expérience en Data Engineering , idéalement dans le secteur aéronautique. La connaissance des techniques et outils de traitement de la donnée en Python , Spark/Hadoop dans un environnement cloud vous sera demandé dans l’exercice de votre fonction. L'utilisation d'outil de data mining et analyse de données serait un plus. Un niveau d’anglais courant est requis. Vous êtes autonome et vous savez faire preuve de capacité d’analyse ? Vous êtes bon communiquant et créatif ? Alors vous êtes la pépite que nous recherchons ! A compétences égales, ce poste est ouvert aux personnes en situation de handicap.",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
70,56369,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineering-manager-data-solutions-f-m-d_paris,Data Engineering Manager - Data Solutions,Decathlon Digital,"{GCP,AWS}",Télétravail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOINS LES EQUIPES DATA DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Au sein de cette entité Data, nous recherchons un·e Data Engineering Manager en CDI. Tu piloteras les compétences de l'équipe et seras responsable de la bonne délivrabilité des solutions techniques liées à vos Data domains (ex : supply chain, sport et process, retail, sustainability ...) Le poste est basé, au choix à Paris, Lille, Lyon ou Nantes (prévoir des déplacements réguliers sur Lille) TES RESPONSABILITES Comprendre les besoins remontés pas les différents utilisateurs des solution de ton data domaine En collaboration avec les autres équipes de Décathlon, concevoir et proposer les solutions data répondant à ces besoins Mettre en place ces solutions Assurer la délivrabilité, la maintenance, l’évolution et le maintien en condition opérationnel des solutions data sous ta responsabilité TA MISSION : Tu es responsable de l’architecture et l'opérabilité des solutions data de ton domaine d’activité. Tu es responsable des engagements de délivrabilité de ton équipe En tant que responsable de l'ingénierie data de ton domaine, tu construis, coaches et soutiens ton équipe pour qu'elle grandisse et soit performante. Tu alignes ton équipe et les autres équipes data autour des choix techniques et des bonnes pratiques applicables aux fonctionnalités sur lesquelles elle travaille. Tu t’assures que ton équipe comprenne et suive les directives de l'entreprise (outils, langues, sécurité, etc.) Tu recrutes les meilleurs Talents en fonction des besoins de notre écosystème. Tu gères l‘évolution professionnelle et le bien être au travail de tes collaborateurs. Tu mènes des revues de talents et les entretiens réguliers pour assurer la performance de l'équipe et les aider à atteindre l'excellence. Tu co-construis avec les autres leaders notre data Factory Tu es responsable du maintien en condition opérationnelle des solutions mises en place. Tu challenges les stratégies techniques transversales et partages la vision dans ton domaine d'expertise. Tu connais les techniques de conduite de projets et d’animation de produit en mode agile, et tu pilotes ton équipe au travers de cette méthode. CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu es hands on et reconnu-e en tant que data ingénieur-e ; Tu as 2 ans d'expérience minimum dans l’encadrement direct d’ingénieur-e-s ( Data engineer/Ops/DevOps/ DataOps). Tu as une solide expérience dans l’environnement agile et tu es capable d’accompagner des collaborateurs dans ce contexte. Tu as un expérience éprouvée dans le run d’un ou plusieurs produits data. Tu aimes développer et faire grandir tes collaborateurs·trices. Tu as un intérêt pour le pilotage économique. Tu comprends le cycle de vie de la donnée et tu es à l’aise avec les concepts de data lineage, data gouvernance et data privacy. Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et l’animation de tes équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien","Decathlon is seeking a Data Engineering Manager to lead and manage the team responsible for delivering technical solutions related to various data domains. The ideal candidate should have a minimum of two years of experience mentoring direct engineering teams, a solid background in agile environments, and proven experience in running one or more data products. Other requirements include a passion for developing and mentoring team members, a strong interest in economic management, and familiarity with data governance, lineage, and privacy. This position is available in Paris, Lille, Lyon, or Nantes, with regular travel to Lille. Decathlon offers two days of remote work per week, international exposure, and opportunities for professional growth and certification.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
69,56411,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-engineer_paris_NUMBE_7zVVerd,Data Engineer,Numberly,"{Hive,Docker,Celery,MySQL,MongoDB,Cube,Kafka,Linux,Git,Tabular,ScyllaDB,NoSQL,hadoop,ElasticSearch,Kubernetes,AWS,HBase,RabbitMQ,Java,Hadoop,SQL,Scala,Airflow,HDFS,Druid,Spark,GCP,Python}",Télétravail partiel possible,"28 rue de Châteaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-03-26,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Numberly is looking for a Data Engineer to join its dedicated team Data. As a Data Engineer you will: Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MS SQL Server, MongoDB, ScyllaDB). Participate in a huge migration from CRM to CDP (SQL Server to hadoop, relational DB to NoSQL) Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage. Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly. Work alongside Data Analytics, Data Scientists, DevOps, and many other talented techs. Suggest your own technological solutions and try them out (our latest POCs include Apache Druid and Tabular) . Join a great multicultural team filled with wonderful people At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (“Live my life” in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Positions available in Paris, Lyon, Bordeaux, Marseille, Nantes, Lille You : Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused… Like work well done and pay attention to detail Dream of being able to develop and manage website databases with strong traffic Want to work with various, prestigious clients on different problems Are on the lookout for new languages/technologies and test the latest open source trends before others You love the following stack ? Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...) SQL Databases (MySQL, SQLServer) Apache Spark ETL (Apache Airflow or equivalent) NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...) Apache Kafka Python, Java, Scala Git Linux Even better if you know : Cube OLAP and SSRS Cloud Solutions (AWS, GCP, …) API REST, WebServices Docker Kubernetes Apache Druid Data Science and Machine Learning Message Queuing (RabbitMQ, Celery, …)","Numberly, a marketing technologist company with a people-based approach, is seeking a Data Engineer to join its dedicated team. The role requires creating and maintaining pipeline jobs, participating in a migration from CRM to CDP, optimizing data operations and storage, and suggesting technological solutions. The company offers an international environment, delivers diversity by design, and enables remote work up to 50% of the time. The ideal candidate should have expertise in Hadoop ecosystem, SQL databases, Apache Spark, ETL, and NoSQL databases, along with knowledge of cloud solutions and data science.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
67,73407,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret_MICRO_DjqwlKX,Data Engineer / GCP,Micropole,"{Python,Scala,Microsoft,durable,Spark,R,AWS,Java,GCP}",Télétravail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-04-22,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer / GCP Localité : Levallois-Perret Type de contrat : CDI Niveau d’expérience : au moins 2 ans Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services. Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus ! Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes, vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP. Vos compétences techniques : Vous avez un minimum de 2 années d’expérience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou à défaut une certification GCP avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ; Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visio Etape 3 – Vous rencontrez un manager technique avec l’un de nos experts. En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) LA VIE CHEZ MICROPOLE, C’est : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; Participation à des projets internes sur la base du volontariat. #LI-DM1 Compétences GCP",,Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
65,73390,https://www.welcometothejungle.com/fr/companies/veolia/jobs/data-engineer-h-f_aubervilliers,Data Engineer,Veolia,"{Python,durable,Dataflow,Java,GCP}",Télétravail partiel possible,"30 Rue Madeleine Vionnet, Aubervilliers, 93300","Environnement / Développement durable, Bâtiment / Travaux publics, Energie",CDI,2023-04-22,"Vous voulez donner du sens à votre activité professionnelle ? Vous ressentez le besoin d’être utile ? Vous voulez agir en faveur de la planète et pour un avenir meilleur et durable ? Vous vous sentez l’âme d’un “Ressourceur” ? …. Chez Veolia, 84% des collaborateurs et 92% des managers se sentent engagés dans leur travail. Les équipes trouvent un sens et une utilité à leur activité, dans les métiers de l’eau, l’énergie ou les déchets. Chez Veolia, nous recrutons plusieurs centaines de jeunes diplômés chaque année : issus d’écoles d’ingénieurs, d’écoles de commerce et d’universités, ils nous rejoignent pour un stage, un contrat d’alternance ou un premier job. Nous leur proposons aussi des V.I.E. grâce à notre programme Pangeo, qui leur est dédié. Au travers de notre réseau des Campus, nous accueillons aussi des apprentis, et nous les formons du CAP au master… Chez Veolia, nos 178 894 collaborateurs ont une mission : Ressourcer le monde. C’est pourquoi nous les appelons “Ressourceurs”. Tous, nous œuvrons ensemble pour atteindre l’ambition de Veolia : être l’entreprise de référence de la transformation écologique. Présent sur les cinq continents, dans 51 pays, avec plus de 178 894 salariés , Veolia conçoit et déploie des solutions qui participent au développement durable des villes et des industries, dans les domaines de la gestion de l’eau, des déchets et de l’énergie. Spécialiste des métiers de l’environnement, Veolia s’attache tous les jours, sur tous les continents, à développer l’accès aux ressources , les préserver et les renouveler. Le Groupe veille au strict respect des lois et des traités internationaux garantissant les droits humains et sociaux de chacun, à la fois au sein de l’entreprise, et auprès de ses parties prenantes. Ces valeurs et règles de conduite intègrent les diversités culturelles du Groupe. En 2020, le groupe Veolia a servi 95 millions d’habitants en eau potable et 62 millions en assainissement, produit près de 43 millions de mégawattheures et valorisé 47 millions de tonnes de déchets. L’objectif du poste de Data Engineer est de contribuer aux activités de build et de run de l’équipe Data Factory Définir les architectures ▪ Définir les services GCP adéquats pour la mise en place de flux streaming et batch ▪ Participer à la définition de l’implémentation / architecture lors de la mise en place de nouveaux pipelines ▪ Définir et suivre les droits d’accès en fonction des caractéristiques des utilisateurs ou des services ▪ Suivre et actualiser la configuration et l’architecture des systèmes d’information et des données en fonction des évolutions Monitorer / exploiter les solutions ▪ S’appuyer sur les outils de monitoring et les enrichir ▪ Analyser les performances du système d’information et préconiser des mesures d’amélioration de la qualité, la sécurité, la productivité ▪ Identifier et diagnostiquer les dysfonctionnements, incidents, non-conformités et mettre en œuvre les mesures correctives ▪ Intégrer les données dans l’environnement GCP de la Data Factory Améliorer ▪ Participer à la compréhension des problématiques métiers et opérationnelles pour implémenter les pipelines de façon optimale (tous métiers : fonctions supports et opérationnels) ▪ Faire évoluer les flux de données en fonctions des contraintes opérationnelles (coût, volumétrie) ▪ Comprendre la modélisation des résultats dans Big Query afin de fournir des conseils pertinents et/ou détecter la cause d’anomalies dans les résultats. Communiquer - travailler en équipe ▪ Maintenir la documentation et particulièrement les documents d'architecture technique ▪ Être capable d'apporter des modifications sur des éléments développés par d’autres. ▪ Participer aux rituels agiles de l’équipe Data Factory (SCRUM). Informations supplémentaires En tant qu'entreprise inclusive, Veolia s’engage pour la diversité et accorde la même considération à toutes les candidatures, sans discrimination. Bac + 4/5 - École d’ingénieur ou équivalent et 5 à 10 ans d’expérience équivalente Maîtrise du build (mode projet) et de l'exploitation (run) en environnement “Big Data” / ETL Maîtrise de Python et des services Data Google Cloud Platform (Big Query, Composer, Dataflow, ...) Java est un plus. Au-delà de solides compétences techniques, ce poste requiert une culture informatique large (développement, ETL, data, API, réseau...), une capacité d’écoute et un bon relationnel pour accompagner les clients, et une capacité à prendre du recul pour adopter les meilleures solutions. La maîtrise de l'anglais est exigée pour ce poste.",,Bac +4,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
59,73331,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/cloud-data-engineer-h-f_wasquehal_EF_ky6dJwo,Cloud Data Engineer,EPSILON France,"{Python,EPSILON,Azure,Microsoft,HDFS,Hadoop,Hive,GCP}",Télétravail partiel possible,"29 Avenue de la Marne, Wasquehal, 59290","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-04-22,"EPSILON France est l’entité Datamarketing de Publicis Groupe avec 700 experts data, marketing et technologiques et plus de 40 métiers représentés. Avec pour claim « Every Interaction Counts », la mission d’EPSILON est de conjuguer les pouvoirs de la data, du marketing et de la technologie pour rendre les interactions entre les marques et leurs clients toujours plus justes et pertinentes. EPSILON intervient sur l’ensemble des étapes-clé d’un projet de transformation data-driven, de la définition de la stratégie à l’exécution opérationnelle. EPSILON compte plus de 300 clients actifs et pilote quotidiennement plus de 100 plateformes datamarketing. L’ambition du Pôle Data Management est d'offrir la meilleure expérience à nos clients grâce à des solutions data-driven et cloud. Nous les accompagnons sur des projets innovants et la création de modèles s'appuyant sur les nouvelles technologies. En tant que Cloud Data Engineer Azure et/ou Google voici vos missions : Contribuer à la réalisation de projets Data Client, Data Lake, Data services dans un contexte de plus en plus DevOps et Agile, Assurer la veille technologique sur les composants d’une plateforme Data, Datalake, Cloud, Rédiger des documents projets (design, réalisation, déploiement, …), Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA, Participer aux initiatives projets et à l’évolution de nos assets data internes. C'est un travail passionnant et enrichissant pour nos collaborateurs qui sont amenés à collaborer avec le marketing, le digital et la création. H/F, vous avez 2 ans d'expérience minimum sur des projets data en environnement cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des méthodes agiles, voire du DataOps. Vous souhaitez évoluer sur les technologies Big Data Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, ...). Votre expérience dans le traitement de la data, sa valorisation et sa production est un atout considérable. Une connaissance d’un ETL est un plus. CHOISISSEZ… - Notre expertise reconnue dans le domaine du décisionnel et du Big Data depuis 30 ans, un cadre méthodologique et une organisation des compétences animées constamment dans un souci de veille et de progression, - Nos projets innovants et nos missions de conseil en cours de réalisation ou réalisés autour des solutions BI, Big Data et DMP, nos projets transverses Data et Marketing à la fois. - Notre diversité de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale…) ainsi que des clients internationaux. - Notre organisation en communautés technologiques est un atout pour votre intégration et le travail en équipe. - Notre partenariat privilégié et avancé avec Google, Microsoft et Salesforce est une force qui vous permettra de monter en compétence rapidement sur les solutions cloud. - Notre management de proximité et notre souci de développement des compétences",,Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
58,73351,https://www.welcometothejungle.com/fr/companies/opensee/jobs/analytics-and-ai-engineer_paris_OPENS_WrV53YA,Analytics and AI Engineer,Opensee,"{Python,SQL}",Télétravail partiel possible,"28, Rue de Madrid, Paris, 75008","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"A propos d’Opensee Opensee est un fournisseur de solutions d’analyse de données instantanées, illimitées et en libre-service, ouvrant la valeur du big data en permettant aux institutions financières de transformer les défis du big data en opportunités compétitives et vitales pour les utilisateurs professionnels. Fondée en 2015 par une équipe de banquiers seniors et d’experts en technologie big data, Opensee se déploie désormais dans plusieurs grandes institutions financières de premier plan sur des cas d’utilisation critiques. Pour soutenir cette croissance, nous avons doublé nos effectifs et nous nous développons désormais depuis 2020 à Londres, New York et Singapour. Pourquoi nous rejoindre ? Rejoignez une Fintech française pour découvrir et contribuer à notre solution Big Data innovante destinée au secteur financier. Évoluez dans un environnement dynamique et international dans lequel créativité et innovation sont fortement encouragées : toutes vos bonnes idées seront étudiées. Bénéficier d’une multitude d’opportunités de développement, au travers de notre croissance en France et à l’international Description du poste En tant qu’ingénieur au sein de l’équipe Solutions, vous devrez aider à la création et à la maintenance de la couche Solutions, et également assister dans les services Solutions aux clients. Ces solutions peuvent utiliser des algorithmes calculatoires simples ou plus complexes, type Machine Learning ou Deep Learning. En détails : Recueillir les besoins des clients pour définir au mieux les outils nécessaires à notre couche Solutions. Développer ces outils de Solutions en Python, que ce soit des solutions spécifiques pour certains clients ou des solutions plus génériques qui seront proposées à tout client. Contribuer à tous les aspects des améliorations des solutions, que cela soit l’amélioration de la performance, plateforme de tests et documentation. Contribuer au support et à l’analyse des incidents sur les solutions. A propos de vous Compétences professionnelles : Diplôme d’ingénieur ou master en mathématiques/informatique Vous avez une première expérience (stage inclus) dans le secteur financier Bonnes compétences en communication français/anglais obligatoires Compétences en Data Science, IA Compétences en technologies Big Data, SQL et Python. Qualités personnelles : Vous savez analyser rapidement un problème technique. Autonome, vous êtes à l’aise pour interagir avec différents interlocuteurs pour résoudre un problème et progresser sur votre développement de produits Vous êtes capable de comprendre à la fois les besoins des utilisateurs, les outils théoriques et les contraintes techniques liés aux outils Détails pratiques : Date de début : immédiate Lieu : Paris (quartier Saint-Lazare) Qu’en dites-vous ? Si vous vous retrouvez dans cette annonce et que vous répondez aux critères de sélection alors n’hésitez pas, postulez! Nous serons ravis d’échanger avec vous.",,Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
57,73349,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineer-confirme-scala_paris,Data Engineer Confirmé - Scala,Groupe SeLoger,"{Redshift,Jenkins,Scala,Datadog,CircleCI,Athena,AWS,Argo,Grafana,Airflow,Spark,Glue,SQL,S3,Java,Python,Kubernetes,Git,EMR}",Télétravail partiel possible,"65 Rue Ordener, Paris, 75018","Application mobile, IT / Digital, Média",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Français dans la réalisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d’offrir à chacun de nos utilisateurs, une expérience immobilière simple et efficace afin qu’ils concrétisent leurs projets d’achat, de vente ou de location en toute sérénité. Nous mettons à disposition des Français le plus large choix d’annonces afin de leur faciliter la recherche d’un bien selon leurs critères propres, et répondre à toutes les questions soulevées par la réalisation d’un projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque préférée des Français pour se repérer et se lancer dans leur projet immobilier. Ce poste est à pourvoir en CDI uniquement. Rejoignez l’équipe Marketplace Design AVIV La marketplace AVIV est le lieu de rencontre privilégié de tous les acteurs de l’annonce immobilière: potentiels acquéreurs ou locataires, propriétaires ou agents, … Afin de garder notre position, nous devons fournir la meilleure qualité de service possible en termes de sécurité, de confiance, d’efficacité et de pertinence des échanges entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualité et sérieux des prospects et des agents ainsi que la qualité des informations affichées. Le rôle de l’équipe Marketplace design est de concevoir et exécuter toutes les actions nécessaires pour assurer la satisfaction de nos utilisateurs : qualité et correction des données, scoring, matching, gamification, et amélioration continue. Ces actions requièrent un usage important des données, l’équipe Data Operations est responsable de la gouvernance, la modélisation et la qualité des données ainsi que de fournir les data-sets clés et maintenir une data platform robuste et efficace pour tout le groupe AVIV. Vos responsabilités : En tant que Data Engineer au sein de l’équipe Data Operations, vous travaillez en étroite collaboration avec un Product Manager et votre Engineering Manager. Vos développements respectent les bonnes pratiques en place et sont alignés avec l’architecture d’entreprise AVIV. Vous apportez votre expertise technique à votre équipe, vous créez, adaptez et améliorez la qualité des data-sets largement utilisés chez AVIV. L’équipe Data Operations L’équipe est constituée d’environ 40 personnes, avec notamment: coach Agile Data Engineers Data Quality Engineers Data Analysts & Modelers Devops Engineers Enterprise & Solution Architects Product Managers Les projets Décentraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv Fournir les insights sur les usages des différents sites et apps mobiles européens Notre Stack Technique data AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS) Spark Git, CircleCI, Datadog Scala, Java Vous avez idéalement des connaissances complémentaires telles que : Python Apache Airflow, Kubernetes Jenkins, Argo CD, Grafana, VictoriaMetrics Nous recherchons une personne capable de: Créer et maintenir des datasets complexes et à gros volumes selon des spécifications fonctionnelles précises. Participer à la création d’une infrastructure solide et optimale pour l’extraction, la transformation et le chargement (ETL) de données à partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud. Identifier, concevoir et implémenter les processus internes d’amélioration: automatisation, optimisation du delivery, scalabilité, etc… Travailler avec des experts data et données analytiques au développement de nouvelles fonctionnalités Maitriser la méthodologie Agile: communication directe, adaptation, fail fast, amélioration continue et Software Craftsman Maîtriser le produit et le business, impactant l’amélioration du service aux clients, du produit et de l’architecture Rigueur, curiosité, autonomie et état d’esprit positif Partager des connaissances et ouvert aux nouveautés Maîtriser les sujets RGPD, sécurité et respect de la vie privée Expérience recherchée Expérience réussie de data engineering, dans différents environnements, notamment Spark. Maîtrise des design patterns actuels et des architectures développements courants. Maîtrise de l’anglais professionnel.",,Non spécifié,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
52,73319,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineer-confirme-python_paris,Data Engineer Confirmé - Python,Groupe SeLoger,"{PostgresQL,Github,Python,Jenkins,Grafana,Spark,Docker,R,Kubernetes,Airflow,AWS,SQL,GCP}",Télétravail partiel possible,"65 Rue Ordener, Paris, 75018","Application mobile, IT / Digital, Média",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Français dans la réalisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d’offrir à chacun de nos utilisateurs, une expérience immobilière simple et efficace afin qu’ils concrétisent leurs projets d’achat, de vente ou de location en toute sérénité. Nous mettons à disposition des Français le plus large choix d’annonces afin de leur faciliter la recherche d’un bien selon leurs critères propres, et répondre à toutes les questions soulevées par la réalisation d’un projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque préférée des Français pour se repérer et se lancer dans leur projet immobilier. Le poste : Nous recherchons un Data Engineer Confirmé pour rejoindre l’équipe chargée des relations entre vendeur et agent au sein de l’entité Data, Science, Geo & Property Team du groupe. L'équipe Data Science est chargée de produire et d'exposer les insights les plus pertinents sur le marché du logement (cartes de prix, outils d'estimation, ...) et les analyses data-driven à un large public : particuliers, agents immobiliers, institutions privées et publiques. Composé d'une quarantaine de personnes, nous adoptons une approche scientifique pour modéliser le marché de l'immobilier résidentiel et développer des produits à fortes valeurs ajoutées. Au sein de ce pôle, notre équipe Data Engineering est composée de 14 profils ayant des compétences en extraction et traitement de l'information, architecture système, traitement du signal et gestion de bases de données. Nous travaillons en étroite collaboration avec des doctorants et des docteurs en mathématiques, économie, finance et statistiques, ingénieurs en Machine Learning et GIS. Vos missions seront : Internationalisation d'une plateforme de données Moderniser et harmoniser notre architecture et la faire évoluer Fournir à l'équipe Data Science un environnement R&D stable Construire un pipeline de traitement de données robuste et efficace Développer des processus de contrôle de la qualité et identifier les améliorations Concevoir des API et des systèmes de livraison de données Outils : GCP, AWS Python, Spark, Docker, Airflow, PostgresQL, Kubernetes Github, Jenkins, ArgoCD, Grafana, VictoriaMetrics A propos de vous : MS/PhD en informatique, statistiques, mathématiques ou similaire Expérience de développement Python Maîtrise le langage SQL et idéalement une expérience de Postgis Rigoureux, curieux, autonome, force de proposition Grand intérêt pour la visualisation et la cartographie des données",,Non spécifié,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
35,67656,https://www.welcometothejungle.com/fr/companies/edenred/jobs/lead-azure-data-engineer-architect-w-m_malakoff,Lead Azure Data engineer/Architect (w/m),Edenred France,"{Amplitude,MongoDB,Databricks,PowerBI,Synapse,scale,via,Spark,Azure,NoSQL,SQL}",Télétravail partiel possible,"178 Boulevard Gabriel Péri, Malakoff, 92240","Application mobile, Restauration, FoodTech",CDI,2023-04-07,"Edenred France est la plateforme de services et de paiements qui accompagne au quotidien les acteurs du monde du travail. Elle connecte 6 millions de salariés utilisateurs et 380 000 commerçants partenaires via 150 000 entreprises clientes en France. En 2019, grâce à ses actifs technologiques globaux, le Groupe Edenred a géré dans le monde 2,5 milliards de transactions de paiement à usages spécifiques, représentant un volume d’affaires de 31 milliards d’euros réalisé principalement via applications mobiles, plateformes en ligne et cartes. Edenred France propose des solutions de paiement à usages spécifiques dédiées à l’alimentation (Ticket Restaurant®), à la mobilité (Ticket Fleet Pro, Ticket Mobilité), à la motivation et à la qualité de vie (Kadéos, ProwebCE, CleanWay, Ticket CESU, Ticket Service), et aux paiements professionnels (cartes virtuelles). Ces solutions améliorent le bien-être et le pouvoir d’achat des salariés, renforcent l’attractivité et l’efficacité des entreprises, et vitalisent l’emploi et l’économie locale. Les 1 200 collaborateurs d’Edenred France s’engagent au quotidien pour faire du monde du travail un monde connecté, simple, sûr et efficace. OUR CONTEXT For a very ambitious agile-at-scale program (Feature Teams organization), we are seeking talented and ambitious professionals to join our team based primarily in Paris and Bucharest as we accelerate our transformative digital and product journey. We are fully embracing Cloud Native capabilities and best practices and operating as a multi-tribe Product team to better serve our customers (Clients, Merchants and Users) and our Edenred employees. We are leveraging Agility at scale principles and are leading the charge in establishing “FinTech Product” ways of working for Edenred. We are also embracing data mesh principles. This means that we are empowering our domain teams to own their data products and encouraging a culture of collaboration and innovation across our entire organization. We want to foster a data-driven culture that enables us to unlock the full potential of our data assets and drive business value for our customers. With data mesh, we are transforming the way we work with data and revolutionizing the employee benefits industry. Our main focus areas to drive value from our Data products : Product excellence: ensure the product team is equipped with Analytics to monitor UX, usage, adoption & performance of the product, both for Front-end and Process aspects Business Performance: ensure the Business Units using our platform can access the data from the different domains for their own BI and propose “ready to use” dashboard to help driving convergence across the Business line for Business performance reporting Value for our Customers & monetization: leverage a 360 view of our Customers and relevant external data sources - through partnerships when relevant - to bring personalized value to our Customers and differentiate from our competition Some critical success factors : Data privacy: protect the data of our customers and fully integrate GDPR regulation principles across our architecture - including consent management and right to be forgotten Data quality: drive a “quality by design” engineering mindset and establish best in class Data observability Data democratization : ensure data is available and easily accessible to who need them, with clear definition, usage guidelines and lineage collaboratively maintained in a catalog Data UX: adopt a persona approach for our Data consumption use cases and promote a superior UX in our visualizations Our Technology stack for Data : Azure Data Platform including Event hub and Synapse Databricks Data Cataloguing - TBD PowerBI and PowerApps for visualization MongoDB/NoSQL for User and Customer domains Vertabelo for data modelling and “Data as code” Amplitude for Front-end analytics Didomi for Consent management YOU WILL VIBE WITH US At Edenred, we believe that data is the key to unlocking business value and driving positive change for our customers. As a Data Engineering Leader, you will play a critical role in this mission, leading a team of data engineers to design, build, and maintain our data platform and pipelines using cutting-edge technologies such as Azure Cloud data technology and Databricks. In this role, you will have a strong focus on technical excellence and innovation, leveraging your deep expertise in data engineering and cloud data architecture to design and implement scalable data solutions that meet the needs of our business and customers. You will be a driving force for implementing data mesh principles, empowering domain teams to own their data products and creating a culture of collaboration and innovation across the organization. You will collaborate with domain owners, data product managers, and other stakeholders to define the data product architecture and ensure that it aligns with data mesh principles. Your main responsibilities: Lead a team of data engineers responsible for designing, building, and maintaining our data platform and pipelines. Design and implement scalable data solutions that leverage Azure Cloud data technology and Databricks to their full potential, including data ingestion, processing, storage, and consumption. Collaborate closely with cross-functional teams, including business stakeholders, product managers, and domain owners, to define and execute the data strategy and ensure that our data solutions meet business objectives and customer needs. Implement data mesh principles and empower domain teams to own their data products, creating a culture of collaboration and innovation across the organization. Define the data product architecture and ensure that it aligns with data mesh principles, collaborating with domain owners, data product managers, and other stakeholders to develop and execute the architecture roadmap. Implement best practices for data observability, data quality, data governance, and data security across all data solutions and pipelines. Develop and maintain documentation and technical specifications for all data solutions and pipelines, ensuring that they are up to date and accessible to all relevant stakeholders. Stay up to date with the latest trends and technologies in the data engineering field, and apply this knowledge to continuously improve our data solutions and pipelines. WE WILL VIBE WITH YOU You could be our next teammate if you have : Bachelor’s degree in Computer Science, Engineering, or a related field. 10+ years of experience in data engineering or architecture roles, with a strong focus on Azure Cloud data technology and Databricks. Good understanding of data mesh principles and domain designed data products. Experience leading and managing high-performing data engineering teams, with a focus on developing team members and creating a culture of collaboration and innovation. Strong technical skills in data ingestion, processing, storage, and consumption, using technologies such as Azure Data Factory, Azure Databricks, SQL Server, NoSQL databases, and Spark. Strong knowledge of data quality, data governance, and data security best practices, and experience implementing these practices in a production environment. Strong communication and collaboration skills, with the ability to work closely with cross-functional teams and stakeholders to define and execute the data strategy.",,Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
50,73289,https://www.welcometothejungle.com/fr/companies/dynatrace/jobs/systems-engineer-m-f-x-observability-devops-and-cloud-engineering_linz,"Systems Engineer (m/f/x)  - Observability, DevOps, and Cloud Engineering",Dynatrace,"{Jenkins,bash,scale,Dynatrace,Kubernetes,Docker,dynatrace,Java}",Télétravail partiel possible,Linz,"Logiciels, IT / Digital, SaaS / Cloud Services",CDI,2023-04-22,"Dynatrace exists to make the world’s software work perfectly. Our unified software intelligence platform combines broad and deep observability and continuous runtime application security with the most advanced AIOps to provide answers and intelligent automation from data at an enormous scale. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences. That is why the world’s largest organizations trust Dynatrace® to accelerate digital transformation. Job Description Build and maintain demo applications to showcase Dynatrace features with various technologies and languages Deploy and manage applications using tools like Kubernetes and Docker Develop and maintain team-internal Kubernetes environments Automate deployments and infrastructure using Terraform and Jenkins Collaborate and assist your colleagues in international development teams Continuously research and evaluate new technologies and tools to optimize the team’s workflows Qualifications A strong interest in technology and a willingness to continuously learn new things Technical studies related to Computer Science or similar experience Fluent in Java, and open to other programming languages and frameworks Working knowledge of containerization technologies (Docker, Kubernetes) Interest in infrastructure-as-code tools like Terraform Admin experience (bash scripting, system maintenance) is a plus Hands-on team player with high quality standards Curious and innovative mindset with a bias towards action Additional Information What's in it for you? A one-product software company creating real value for the largest enterprises and millions of end customers globally, striving for a world where software works perfectly . Working with the latest technologies and at the forefront of innovation in tech on scale; but also, in other areas like marketing, design, or research. Working models that offer you the flexibility you need, ranging from full remote options to hybrid ones combining home and in-office work. A team that thinks outside the box, welcomes unconventional ideas, and pushes boundaries . An environment that fosters innovation, enables creative collaboration, and allows you to grow . A globally unique and tailor-made career development program recognizing your potential, promoting your strengths, and supporting you in achieving your career goals. A truly international mindset that is being shaped by the diverse personalities, expertise, and backgrounds of our global team. A relocation team that is eager to help you start your journey to a new country , always there to support and by your side. Attractive compensation packages and stock purchase options with numerous benefits and advantages . Compensation and rewards We offer attractive compensation packages and stock purchase options with numerous benefits and advantages. Due to legal reasons, we are obliged to disclose the minimum salary for this position, which is € 39,200 gross per year based on full-time employment. We offer a higher salary in line with qualifications and experience. Discover more perks & benefits Growth opportunities - find out how Dynatrace supports your career development and personal growth journey: https://careers.dynatrace.com/grow-with-us/career-development/ Flexible working - our flexible and trusting work environment fits your current life situation: https://careers.dynatrace.com/ways-of-work/ Relocation Support - discover how we can support you if you wish to join us at one of our global locations: https://careers.dynatrace.com/relocation/ Company Description Dynatrace exists to make software work perfectly. Our platform combines broad and deep observability and continuous runtime application security with advanced AIOps to provide answers and intelligent automation from data. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences.",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
48,34671,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_paris-la-defense,Data Engineer,Société Générale,"{Kafka,Spark,Java}",Télétravail partiel possible,Paris La Défense,"Banque, Finance",CDI,2022-08-08,"Au sein de Société Générale : Pour vous, l'utilisation des données représente l'avenir ? Vous avez envie de rejoindre une équipe agile, dynamique, engagée et qui travaille en forte proximité avec le business ? Rejoiniez une équipe de passionné, dans un environnement international pour contribuez aux développements des outils d'analyse de l'activité du périmètre Fixed Income. Concrètement, vous serez amené(e) à : * Travailler en étroite collaboration avec les Products Owner métiers du périmètre fixed income * Proposer des solutions basées sur la stack Big Data pour l'analyse et la restitution de l'activité, historique comme temps réel * Inover et imaginer les solutions du future * Vous êtes diplômé(e) d'un Bac +5 en informatique / école d'ingénieur * Passionné(e) de data, vous proposez des améliorations et partagez avec votre équipe * Incollable sur la stack big data: Spark,Kafka en langage Java,Pytoh vous avez également la fibre DevOps et FinOps * You're fluent in English!","Join an agile team at Société Générale as a Big Data Engineer to work closely with Fixed Income business owners, propose data-driven solutions for analysis and visualization, develop innovative solutions, have a strong knowledge of big data stack, and possess a degree in computer science or engineering. Fluency in English is required.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
45,56672,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-equipements-biomedicaux-connectes_paris,Data Engineer - Equipements Biomédicaux connectés,Assistance Publique - Hôpitaux de Paris - DSI,"{Oracle,python,bash,Nvidia,Docker,Postgresql,MySQL,Talend,Kafka,Linux,NoSQL,Elastic,java,Jenkins,Kubernetes,Java,SQL,Hadoop,Jupyter,via,Spark,sql,Python}",Télétravail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Santé",CDD / Temporaire,2023-03-26,"L’ Assistance Publique - Hôpitaux de Paris (AP - HP) est un établissement public de santé et le centre hospitalier universitaire - CHU - de la région Ile-de-France, reconnu mondialement pour sa recherche. Le département Web Innovation Données (WIND) s’inscrit au sein de sa Direction des Systèmes d’Information. Sa mission ? 🎯Réaliser les projets numériques innovants au contact du monde hospitalier. Ses projets phares ? 🚀 Construire le plus large entrepôt public de données de santé en Europe ! Le projet vise à valoriser les données produites à l’AP-HP pour la recherche, l’innovation et le pilotage des soins, tout en protégeant les données patient. L’Entrepôt de Données de Santé, c’est déjà +12 millions de patients dont les données sont structurées et référencées sur une plateforme Big Data dédiée. 🙋‍♀️🙋‍♂Faciliter le quotidien des patients! Le domaine gère notamment toutes les applications mobiles et tous les téléservices de l’AP-HP. 🔬Monter une plateforme Bio-Informatique centrale pour assister les pôles de biologie de l’ AP-HP dans leurs besoins informatiques (gestion du séquençage, déploiement de ressources de calcul). 🌼Développer et déployer au niveau national les outils de collecte et d’analyse épidémiologique des données relatives aux maladies rares. La mission de votre équipe Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP. ​ L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision. ​ La Plateforme Big Data de l’AP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (48 Nvidia P40 / V100), de 20 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives. ​ Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP. Les données issues des équipements biomédicaux connectés proviennent globalement de l’ensemble des services de l’APHP et en particulier dans les services de soins intensifs. Selon le contexte, la fréquence d’acquisition et la durée d’enregistrement des signaux varient dans des proportoins importantes (de quelques secondes à plusieurs jours et de 0.02Hz à 3kHz). Vos missions Au sein de l’équipe en charge de la Plateforme Big Data de l’APHP, vous prenez en charge le développement des outils ou composants répondant aux attentes des médecins et chercheurs pour le stockage et l’exploitation des données de type signaux physiologiques (ECG, EEG, EMG, courbes respiratoires, …) collectées dans le cadre de leurs projets de recherche. La plateforme big data cherche a se doter d’une solution technique spécifique pour le stockage, le traitement et l’exploitation de ces données sous forme de séries temporelles. Vous serez amené à analyser, à proposer et à mettre en oeuvre une architecture et des solutions adaptées aux différents besoins des projets de recherche et vous participerez également à la mise en place d’un certain nombre d’outils de base (visualisation, annotation, etc.) pour faciliter l’exploitation et l’enrichissement des données physiologiques par les utilisateurs de la plateforme. En tant que data engineer spécialisé en traitement du signal et idéalement en systèmes biomédicaux, vous : Réaliserez la définition des besoins et l’accompagnement des médecins pour la réalisation d’un projet de recherche Analyserez les différents équipements biomédicaux, signaux et protocoles de communication Développerez, industrialiserez et maintiendrez les flux d’intégration des signaux physiologiques pour permettre leur collecte au sein de la plateforme big data Contribuerez à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en java, python ou d’autres langages Industrialiserez le code de génération du flux de données et assurer sa performance globale Aiderez à l’implémentation de standards et normes de mise à disposition des données Mettrez en place des outils permettant l’enrichissement des données (analyse, annotation, etc) Travaillerez en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche Idéalement, vous.. Avez un diplôme d’ingénieur ou équivalent (bac+4/5, master2) en informatique ou sciences avec formation complémentaire en informatique Avez une expérience de développement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, …) et ETL (Talend ou autre) Avez une expérience dans la manipulation de données avec le langage SQL Connaissez les standards en informatique de santé (HL7 v2, DICOM, HL7-FHIR, OMOP, …) Avez le goût de l’intégration de systèmes informatiques hétérogènes Avez des connaissances des bonnes pratiques de sécurité informatique et de la réglementation informatique et libertés Adhérez aux valeurs du service public et vous avez un intérêt prononcé pour le domaine de la santé Avez un niveau d’anglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise du langage Python et de bash Bonnes connaissance des bases de données Oracle, Postgresql ou MySQL et langages associés (sql) Bonne maitrise en méthode de conduite de projet (planification, reporting, analyse de risques, …) Connaissance des outils ETL (Talend, …), d’informatique décisionnelle et des méthodes de data warehouse (OLTP, RDBMS…) Connaissance du traitement des données massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en méthodes de développement logiciel (dont cycle en V, méthodes agile), méthodes d’analyse et de modélisation (Merise, UML …) Connaissance en administration d’environnements Linux Connaissance des méthodologies devops et des outils associés (Docker, Kubernetes, Jenkins…) Et humainement ? Capacité à appréhender des enjeux liés à la recherche, à l’analyse de données et aux technologies de machine learning/deep learning, notamment dans le domaine de la santé (santé publique, imagerie médicale, épidémiologie, …) Esprit d’équipe et la volonté de prendre part à une aventure collective Sens de l’écoute, du résultat et de la qualité Des qualités d’autonomie, de flexibilité et de responsabilité Curieux, dynamique et créatif, avec un réel envie de faire preuve d’innovation Au cours de 2 à 3 entretiens vous échangerez avec différents chefs de projets et le directeur de la plateforme","AP-HP is looking for a data engineer with expertise in signal processing and ideally in biomedical systems. The successful candidate will be responsible for developing tools and components for the storage and exploitation of physiological signals such as ECG, EEG, EMG, and respiratory curves collected as part of research projects. They will work with doctors to define project requirements, analyze biomedical equipment and communication protocols, develop and maintain integration flows, and implement standards and data provisioning tools. The ideal candidate holds a degree in computer science or a related field, has experience with Java and/or Python, and is familiar with EAI and ETL tools. They should also have knowledge of SQL, health informatics standards, and data security regulations, as well as expertise in project management, software development, and DevOps methodologies.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
42,73153,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_34O3aKb,Data engineer,EXTIA,"{Python,Scala,Linux,SAS,HDFS,Hadoop,Spark,R,AWS,S3,Java,GCP}",Télétravail partiel possible,Paris,"Ingénieries Spécialisées, IT / Digital, Stratégie",CDI,2023-04-22,"Société de conseil spécialisée dans les métiers de l’IT, du digital et de l’ingénierie , nous privilégions depuis notre création en 2007 une approche qui allie performance et bien-être au travail. Récompensée depuis 2012 par le label Great Place to Work®, cette conviction s’incarne au quotidien dans notre marque de fabrique : « D’abord qui, ensuite quoi » ! Nous partons du « Qui », de la personne, de ses aspirations et ses talents, pour ensuite co-construire le « Quoi », un projet porteur de sens et de valeur ajoutée pour elle et pour Extia. 🎯 Cette vision de l’entreprise est aujourd’hui partagée par plus de 2500 Extien·ne·s en France et à l’international qui accompagnent nos 250 clients dans la réalisation de leurs projets. Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse… Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes. Vous serez en charge de : ● Participer à la définition des besoins et à la rédaction des User Stories, ● Collaborer avec les Data Scientists au développement des modules d’analyse de donnée, ● Concevoir et construire des architectures de données, ● Intégrer des sources de données, ● Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives, ● Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux #LI-GG1 ● Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple, ● Vous maitrisez les bases de l’analyse statistique, ● Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, ● Vous maitrisez Spark et Hadoop ● Vous êtes familiarisé avec l’environnement Linux, ● Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.",,Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
39,73085,https://www.welcometothejungle.com/fr/companies/cdiscount/jobs/dataops-engineer-h-f_bordeaux-33,DATAOPS ENGINEER,Cdiscount,{},Télétravail partiel possible,"Bordeaux (33), 33000","Logistique, SaaS / Cloud Services, E-commerce",CDI,2023-04-22,"Cdiscount est une aventure du numérique français. Passée en 20 ans d’une start-up bordelaise au leader français du e-commerce, l’entreprise n’a eu de cesse de répondre aux attentes de ses clients. L’objectif ? Rendre possible l’accès aux biens (high-tech, électroménager, vins, décorations ou encore les jouets) et aux services (énergie, offres de voyages ou forfaits téléphoniques) au plus grand nombre en construisant une économique numérique, européenne, inclusive et responsable. Avec audace et engagement, les collaborateurs de Cdiscount œuvrent tous les jours pour proposer grâce à la technologie et l’innovation, une expérience client riche, humaine et fluide. Depuis 2011, l’entreprise offre une vitrine aux PME/TPE en France et à l’étranger et accompagne leur digitalisation grâce à sa marketplace. Ce qui lui permet de proposer plus de 60 millions de produits à ses 9 millions de clients. Conservant l’agilité de son modèle et forte de son positionnement de leader français, Cdiscount construit chaque jour le e-commerce d’aujourd’hui et de demain. Cdiscount en chiffres : • 4 Mds € de Volume d’affaires en 2019 • 20 millions de visiteurs uniques par mois • 60 millions de références • 2 000 collaborateurs • 560 000 m² d’entrepôt logistique • 70% de trafic sur mobile • Plus de 60 métiers représentés REJOIGNEZ UN COLLECTIF ANIME PAR LE GOUT DU DEFI Chez Peaksys , filiale Tech de Cdiscount, nous sommes plus de 650 passionné(e)s de Tech, mobilisé(e)s chaque jour pour accélérer les développements BtoB et BtoC de Cdiscount et ses filiales. Rejoignez Peaksys, venez faire du hors norme votre norme. Notre mission : Fabriquer et opérer des solutions digitales à l’échelle pour tout l’écosystème Cdiscount (Cdiscount.com, Octopia, C-Logistics, Cdiscount Advertising), en assurant à nos utilisateurs une qualité d’expérience sans compromis. Notre terrain de jeu : nos systèmes traitent 1 Md de requêtes par an sur le moteur de recherche/ Jusqu’à 1001 commandes clients par minute/ 3000 mises à jour d’offres vendeurs par seconde/ 1 changement en production toutes les 7 minutes. Ce qui nous caractérise : nous visons l’excellence et une vitesse d’exécution toujours plus rapide pour chacun de nos produits. Notre conviction : nous croyons en l’équipe et en la puissance du collectif comme moteur de notre performance. Vous avez soif de défis ? Venez prendre part à une aventure humaine et technologique exceptionnelle sur un terrain de jeu Tech hors norme. Description du profil : Peaksys est un employeur investi en faveur de la diversité : du recrutement à l’évolution professionnelle, nous garantissons l’égalité des chances à tous nos collaborateurs. Vous êtes persuadé que l’avenir appartient à celles et ceux qui osent faire bouger les lignes ? Nous aussi. Alors, Inventez-tout, Révélez-vous ! Venez développer vos compétences et votre employabilité dans un environnement de travail unique : 🏡 : Un accord télétravail pouvant aller jusqu’à 3 jours par semaine, 🌉 : Des locaux modernes et situés au bord de la Garonne en plein cœur des Bassins à Flots, hub de la tech Bordelaise, 🎤 : Des animations, conférences, et temps d’échanges dédiés avec la Direction, 🎓 : Une offre de formation innovante et à la pointe des nouvelles technologies, 🏆 : De nombreux labels obtenus (Great Place To Work, Happy Trainees, AFNOR “Diversité” et “Egalité F/H”), 🛒 : Un abonnement Cdiscount à volonté (CDAV) offert et des réductions toute l’année, 🎢 : Des offres avantageuses grâce au CSE (cinéma, parcs de loisirs, concerts), 🌍 : L’opportunité d’être acteur d’initiatives RSE et liées à la Diversité : (HandiTeam, GreenTeam), 👶🏽 : Des places en crèches et un dispositif de garde d’enfant en urgence, 💰 : Des plans d’épargnes (PEE, PERCOL, abondement employeur sur versements volontaires), Et les indispensables : 🍔 cartes restaurants, 🌅 chèques vacances, 🩹mutuelle adaptée à tous, 🚎 remboursement à hauteur de 50% des titres de transport. Les prochaines étapes : Un entretien téléphonique RH avec Hélène , votre contact RH durant votre processus de recrutement, Un entretien avec votre future manager, Fabien et Hélène, Un entretien technique avec votre N+2, Julien, Notre proposition d’embauche ! Informations complémentaires Type de mobilité: Mobilité définitive Localisation: Bordeaux (33) Référence: 10688",,Bac +5 / Master,> 2000 salariés,> 4 ans,2,1,0.04154662416233763
38,56703,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/manager-data-engineering-h-f_paris_PF_zNkwZlM,Manager Data Engineering,Publicis France,"{Microsoft,Azure,MongoDB,Gitlab,Kubernetes,EPSILON,Cloudera,Kafka,Spark,Epsilon,Docker,Hadoop,Python,marquez}",Télétravail partiel possible,"17 Rue Bréguet, Paris, 75011","Marketing / Communication, Publicité, Digital, Relations publiques, AdTech  / MarTech, Evénementiel, Design",CDI,2023-03-26,"Leader français du marketing, de la communication et de la transformation digitale des entreprises, le groupe Publicis s’appuie sur un modèle unique qui allie créativité, technologie, médias avec au cœur la data. Présidé par Agathe Bousquet, Publicis Groupe en France est une Talent company riche de plus de 5 000 collaborateurs, répartis dans 26 agences, qui accompagnent près de 600 clients. En France, le groupe est organisé autour des activités de création avec les agences Publicis Conseil, Marcel, Leo Burnett Paris, Saatchi & Saatchi, Publicis Consultants, PublicisLive, Carré noir, Publicis Luxe, Prodigious, Razorfish. Le groupe est également un acteur puissant des medias avec ses agences Publicis Media, Starcom, Zenith, Spark Foundry, Blue449, Performics. Enfin il intervient dans la transformation numérique avec Publicis Sapient, et dans la data avec Epsilon. Ainsi grâce à une puissante alchimie, de la créativité et de la technologie, Publicis pilote la transformation des entreprises sur toute la chaine de valeur. La responsabilité sociétale de l’entreprise (RSE) irrigue tous ces métiers et fait partie intégrante de la stratégie globale de Publicis. Le groupe est par ailleurs le premier réseau en nombre d’agences à avoir obtenu le label RSE Agences Actives délivré par l’AACC avec 12 agences labellisées. Publicis, c’est aussi « Viva la différence ! ». Persuadé que la diversité est un puissant moteur de créativité et de performance, Publicis s’engage sur de nombreux sujets pour promouvoir l’égalité des chances et renforcer l’égalité des origines. Le groupe est convaincu que la somme de ses différences fait sa richesse. Le Pôle Data & Analytics Platform est composé de 140 experts spécialisés sur la transformation Data des entreprises : Cadrage fonctionnel et technique, Définition de use-cases, Conception d’architecture cloud ou hybride, Mise en œuvre et run de plateformes data, Implémentation de solutions Dataviz et Analytics, Accompagnement du changement, Cadrage et déploiement de Data Gouvernance, Mise en œuvre de Data Office. Au sein du Pôle Data & Analytics Platform, le centre de compétences des technologies Big Data et Cloud intervient sur l’ensemble de la chaîne Data : Architecture, Développement de plateforme Data (ingestion, traitement, stockage, exposition des données), industrialisation et opérationnalisation des solutions développées (essentiellement en mode cloud). Rattaché à ce centre de compétences en tant que Manager Data Engineering, vous avez 4 grandes missions : Management : - Vous managez et animez votre équipe (8 à 10 personnes) dans un esprit de formation, d’innovation et de satisfaction client. Projet : Garant de la qualité du delivery de vos projets - Vous assumez le rôle de chef de projet ou de directeur de projets sur des missions et des clients variés, de la conception à l’implémentation, sans oublier l’optimisation de la performance et la scalabilité de vos développements. Innovate & Train : développement du capital connaissance et de l’innovation - Vous animez nos réseaux de compétences et êtes un support méthodologique et technique pour les consultants - Vous développez des points de vue, des ""assets"", des bonnes pratiques et contribuez à la croissance de l'équipe, - Vous êtes source de conseils tout en participant à la réalisation effective des projets. Sell : - Vous animez la relation client et contribuez activement aux activités d’avant-vente. - Vous animez la relation avec certains partenaires éditeurs d’EPSILON (Google, Microsoft, …) Vous marquez des points si Vous évoluez depuis au moins 6 ans dans des environnements Data Agile et Cloud. La mise en œuvre de plateformes Data n’a pas de secret pour vous. Vous êtes un fan de Scrum, SAFE ou DevOps… et vous avez appliqué ces méthodes avec succès à vos projets ! Vous avez la maitrise d’une stack technique de référence Hadoop (Cloudera/HortonWorks), Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, … et une réelle expérience des environnements cloud (en particulier Google Cloud Platform et Azure ). Vous avez déjà encadré, managé, fait évoluer des consultants à travers une première expérience significative de management ? Le partage de connaissance et la curiosité sont des pré-requis dans votre quotidien ? Dynamique et réactif, vous démontrez un réel leadership. La qualité de votre communication écrite et orale ainsi que votre aisance relationnelle vous permettent d’être reconnu comme un interlocuteur exigeant et fiable tant en interne qu’en externe.","Publicis Groupe is seeking a Manager for its Data Engineering team to drive the transformation of companies across the entire value chain. The candidate must have at least six years of experience in agile data and cloud environments and must be skilled in Scrum, SAFE, or DevOps methodologies. They should have expertise in developing data platforms using Hadoop, Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, and cloud environments particularly Google Cloud Platform and Azure. The Manager Data Engineering will be responsible for managing and leading a team of 8-10 employees, project quality, innovation, and client satisfaction. They will also lead client relations and support the team's development and growth by contributing points of view, assets, and best practices.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
36,34114,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_puteaux_SG_RaReRwz,Data Engineer,Société Générale,"{Nifi,Scala,Kibana,lambda,Kafka,KAFKA,Hive,Spark,NIFI,Hadoop,Python,Elastic}",NaN,Puteaux,"Banque, Finance",CDI,2022-08-08,"Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer ! Dans le cadre d'une équipe agile, en tant que Data Engineer, vous garantissez l'accès aux données liées à l'activité de la banque. Vous implémentez et industrialisez des traitements pour collecter, nettoyer et synthétiser des données afin de les rendre accessibles tout en veillant à leur qualité. Concrètement, vous serez amené(e) à : Concevoir des solutions pour collecter, transformer et exploiter des gros volumes de données Participer à l'industrialisation des traitements et à leur amélioration continue pour qu'ils soient fiables, robustes, performants et résilients afin de répondre aux exigences des partenaires métiers Assurer la maintenance et l'évolution des différents pipelines de traitement Assurer une veille technologique afin d'être à la pointe des connaissances en matière de data Vous êtes curieux(se) avec un bon esprit d'analyse et de synthèse Passionné(e) de data, vous proposez des améliorations et partagez avec votre équipe You're fluent in English! Vous êtes diplômé(e) d'un Bac +5 en informatique / école d'ingénieur et avez une première expérience dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc. Vous disposez des compétences techniques suivantes : Connaissances des outils Big data : Spark, Hive, Hadoop, NIFI, KAFKA, Elastic, Kibana. Langage de développement : Scala, Python, Devops, outils CI/CD, microservice, API. Connaissances des architectures Big Data : Résilience, architecture Kappa et lambda, couplage, event driven.","As a Data Engineer at Société Générale, you will be responsible for implementing and industrializing processes to collect, clean, and summarize data to ensure its accessibility and quality. You will design solutions for collecting and exploiting large volumes of data, participate in the industrialization and continuous improvement of processes, ensure maintenance and evolution of processing pipelines, and stay up-to-date with the latest data technologies. This role requires a strong analytical and synthetic mindset, a passion for data, and proficiency in English. Technical skills in big data tools, development languages, and architectures are also necessary, with a Bachelor's or Master's degree in IT or engineering and previous experience in a tech environment.",Bac +5 / Master,> 2000 salariés,< 6 mois,0,3,0.04154662416233763
154,56970,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/data-engineer-ingenieur-e-big-data_paris,Data Engineer / Ingénieur·e Big Data - CDI - Caen ou Paris,SoyHuCe,"{python,PostgreSQL,Cassandra,noSQL,Azure,JAVA,MySQL,MongoDB,Dataiku,Shell,github,Kafka,NoSQL,PyTorch,ElasticSearch,Kubernetes,Golang,AWS,CouchDB,Hadoop,SQL,Redis,regard,Minio,Tensorflow,Scala,Kibana,HDFS,MXNet,R,Spark,GCP,Python}",Télétravail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Transformation",CDI,2023-03-26,"Tech Lab spécialisé en algorithmes et en IA, SOYHUCE accompagne ses clients en proposant une offre adéquate et complète avec ses équipes Parisienne et Caennaise. La démarche de SOYHUCE se décline en 3 expertises : Une usine digitale ; Un laboratoire R&D en algorithmie & IA ; La data factory SOYHUCE se positionne sur le marché du digital et de la Data comme un « valorisateur de données ». Elle se repose sur des logiciels et des algorithmes personnalisables, centrés sur les métiers, et sur sa capacité à faire ressortir les besoins au-delà de ceux exprimés au travers d’une approche analytique fine. Créée en 2013, SOYHUCE souhaite apporter un nouveau regard dans les innovations. Tout en plaçant l’humain au cœur des entreprises, nos solutions sont adaptées aux enjeux économiques, sociales et sociétales d’aujourd’hui. Leurs produits : OctoData : La plateforme d’orchestration de technologies Big Data, prête à l’emploi et dédiée au traitement et à la valorisation de vos données massives. iStoryPath : La webapp de génération de parcours touristiques et événementiels personnalisés. AlgoRH : L’outil de gestion de planning intelligent à destination des Centres de Relation Clients. Vous souhaitez mettre en oeuvre vos talents au sein d’une jeune entreprise innovante, où bonne ambiance et défis techniques rythment votre quotidien ? Dans le cadre du développement de ses activités de R&D et de ses missions de conseil, SoyHuCe est à la recherche d’un·e Data Engineer pour consolider son équipe infrastructure et développement Big Data. À propos Studio R&D en algorithmie et data science, SoyHuCe accompagne les entreprises, et les collectivités dans leurs réflexions et projets numériques et métiers. Les solutions que conçoit et développe SoyHuCe sont centrées sur les utilisateurs, mettant l’humain au cœur des organisations. Descriptif du poste Vous travaillerez conjointement avec les Data Scientists et le Data Architect déjà en poste et vous serez impliqué(e) dans la prise de décisions liée à notre solution Big Data et à son évolution. Vous participerez également à la construction d’un pôle Data au sein de l’entreprise. Vos missions au quotidien : Contribuer au développement de notre offre Big Data; Comprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets des BUs ; Définir l’architecture logiciel de votre solution en collaboration avec vos pairs ; Travailler la donnée sous toutes ses formes (stockage, élaboration du modèle, structuration, nettoyage) ; Rédiger la documentation sous confluence / github ; Mettre en œuvre les standards de l’usine logiciel (intégration continue, livraison continue, test driven…) ; Partager votre savoir-faire entre les différents membres de l’équipe ; Concevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateforme ; Concevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data ; Assurer une veille technologique. Compétences techniques attendues : Expérience en développement : Fournisseur cloud , R, python. JAVA, C++ ; Connaissance en bases de données : SQL et noSQL ; Expérience dans le traitement de données à grande échelle en utilisant les systèmes traditionnels et distribués tels que Hadoop ou Spark ; Sensibilité à la culture devops et au software craftmanship ; Data Analysis ; Data Engineering ; Data Visualisation ; Gestion de projets Data ; Déploiement d’architecture cloud. Notre stack (en constante évolution) : Stockage de données: PostgreSQL, Cassandra, Kafka, ElasticSearch, MongoDB, Minio, Redis; Cloud: AWS, GCP, Azure, OVH; Orchestrateurs: Kubernetes; Technologies Big Data : Spark; Cassandra, HDFS, Kafka Bases de données : PostgreSQL, MySQL, CouchDB Machine learning: Tensorflow, PyTorch, MXNet, Scikit-Learn; Langages: Scala, Python, Golang, Shell ; Outils : Kibana, Dataiku, Power BI. Diplômé·e d’études supérieures dans le système d’information, computer sciences, big data (école d’ingénieurs, école spécialisée, école de commerce ou équivalent universitaire), vous justifiez d’une première expérience en BI et/ou Data engineering, ainsi qu’une expérience confirmée en conseil ou en gestion de projet. Vous avez une expérience concrète sur la mise en place de pipelines complets de valorisation de données massives, de la collecte à la mise à disposition d’applications en passant par le traitement. Vous êtes orienté code quality, pair programming ou encore Test driven development. Pro-actif, vous savez travailler en autonomie. Côté technique, vous possédez de solides bases en traitement de données avec Spark, Spark Streaming et Kafka dans un environnement Cloud ainsi qu’en base de données NoSQL. Vous êtes rigoureux·euse, ouvert·e, très curieux·euse et adorez explorer et éprouver des nouvelles technologies. Un pré-qualification avec notre Talent Acquisition Senior Un entretien avec un Référent Technique Métier Un challenge technique Un entretien avec notre CEO","SoyHuCe, a tech lab specializing in algorithms and AI, is seeking a data engineer to develop their Big Data offering, working collaboratively with their existing team of Data Scientists and Data Architects, contributing to the construction of an in-house Data department. Candidates must have experience in BI and/or data engineering, with a solid understanding of data processing, Spark, Spark Streaming, Kafka, NoSQL databases, and cloud deployment. Technical proficiency with R, Python, Java, C++, SQL, MongoDB, and Redis is essential.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
116,35595,https://www.welcometothejungle.com/fr/companies/tinyclues/jobs/data-engineer_paris_TINYC_z7QQOmy,Data Engineer,Tinyclues,"{Kubeflow,Airflow,TensorFlow,S3,GCS,BigQuery,SQL,DataFlow,Python}",Télétravail partiel possible,N,"SaaS / Cloud Services, Big Data",CDI,2022-09-28,"Tinyclues est une entreprise de tech focalisée sur le marketing CRM. Nous pensons que la construction d’une stratégie CRM solide n’a pas à être coûteuse et difficile. C’est pourquoi nous avons conçu une technologie extrêmement simple pour que nos clients BtoC atteignent toujours les bonnes personnes avec chacune de leurs campagnes. Permettre à chacun de nos clients de satisfaire chaque personne de sa base CRM, en leur proposant les bons produits, est l’objectif que l’on souhaite atteindre avec chacun de nos clients. Nous travaillons avec plus de 250 entreprises B to C, principalement dans les secteurs du Retail et du Travel. Plus de 100 000 campagnes marketing ont déjà été crées grâce Tinyclues, sur la base le plus de 100 milliards de dollars de transactions ! Last but not least, nos clients nous aiment - NPS en 2021 de 80 (et nous leur rendons bien). Tinyclues AI-first marketing platform is built with the latest technologies including ML frameworks like TensorFlow, Vertex, Kubeflow but also BigQuery, DataFlow. Our software stack is based on the Python ecosystem, natively designed for the cloud and deployed on Google Cloud Platform. We focus on using those technologies for what they do best. The solution processes and analyzes hundreds of terabytes of data every day from our 100+ enterprise clients across 13 countries. It runs dozens of powerful and carefully designed Deep Learning algorithms to find the “tiny clues” in our clients’ first-party databases. We believe empowering people is the most efficient way to build the best product together. The teams are organized in small & autonomous feature teams working on different business needs with agile methodologies. Our innovative technology has led Tinyclues to be identified by leading IT analyst firm Gartner as a Vendor to Watch for digital marketing analytics and a Cool Vendor in multichannel marketing. By joining Tinyclues, you will have an impact on one of top fast-growing start-ups with a unique AI-first vision, breakthrough predictive technology and proven global success. Learn more about building successful predictive systems by reading our two articles on Medium.com: How we tamed our multi-tenancy model in less than a week and Beyond Cold-Start. What you will do You will join the Data team whom: Build, manage & improve several hundred data pipelines Design, Organize & Optimize our BQ data warehouse Power our Deep Learning technologies, gather critical data from our clients using various means (Data Cloud/ GCS/ S3/ SFTP/API), build easily consumable insights & deliver audiences to our marketing cloud partners. Our challenges: Multi-Tenant: every client has its own data schema, ability to build flexible and configurable KPIs. Scalability: client data can be big but the computation and scoring we process for our client are even bigger. Cost efficiency: linked to the amount of data to process for each client, we maintain the cost low to make a profit. Requirements: You are an engineer: given an issue, you search for the best and easiest way to tackle it and provide a reliable simple solution. You always try to reuse the existing stacks when possible. You propose an enhancement of the architecture only if it simplifies or prepares the future.( KISS : KeepItSimpleStupid) You understand the power and limitations of different data technologies and know how to turn them into accelerators to deliver client value. You handle and share the global vision of the solution and you propose options to make the best choice with the stakeholders of the product and engineering and are able to define the right plan to tackle things in a sequence of incremental value. You have been working in an Agile environment and are able to manage sprints, velocity, etc… You are fluent in English. French is a plus. Technical skills: You have strong SQL skills You know orchestration technologies (Airflow, Kubeflow ). You are Python fluent. Knowledge of Google Cloud Platform would be appreciated. Experience of BigQuery is a plus.","Tinyclues is seeking a Data Engineer to join their team and help build, manage, and improve several hundred data pipelines while designing, organizing, and optimizing their BQ data warehouse. The ideal candidate should have strong SQL skills, be fluent in Python, understand the power and limitations of different data technologies, and have experience in an Agile environment. The company utilizes ML frameworks such as TensorFlow, Vertex, and Kubeflow, as well as the Google Cloud Platform, making knowledge in these areas a plus.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
156,56516,https://www.welcometothejungle.com/fr/companies/promovacances/jobs/data-engineer-h-f_paris,DATA ENGINEER,Promovacances,"{cube,Azure,Microsoft,Snowflake,BigQuery,AZURE,SQL,SnowFlake}",Télétravail partiel possible,"17, Rue de l'Échiquier, Paris, 75010",Tourisme,CDI,2023-03-26,"N°1 de la vente de séjours en ligne avec plus de 7 millions de visiteurs uniques par mois sur ses différents sites, le groupe Karavel connait une croissance dynamique et continue avec un CA de 400 millions d euros. En tant que Data Engineer, vous interviendrez sur la totalité de la chaine décisionnelle au sein du pôle DATA, et serez chargé, entre autres de : La maintenance corrective et évolutive de l'existant implémenté sur la suite MS BI en collaboration avec le reste de l'équipe DATA . La participation au projet de refonte de notre BI actuelle (MS BI, Access, BigQuery) vers AZURE / SnowFlake / Power BI. Analyse de l'existant et des nouveaux besoins métiers ; Réalisation des spécifications fonctionnelles et techniques ; Modélisation ; Création de package sous SSIS ; Implémentation des chargements de données vers SnowFlake ; Développement sous cube Tabulaire (service AS Azure) ; Réalisation de rapports sous Power BI / Excel Recette et mise en production ; Vous disposez d'au moins 5 années d'expérience sur la suite Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS) avec une solide compétence en SQL De compétences sur Snowflake (architecture, développement, administration) d'au moins 2 ans d'expérience sur Power BI Une première expérience réussie dans le machine learning serait un plus Vous avez démontré un forte capacité d'adaptation et d'autonomie à travailler au sein d'environnements complexes et hétérogènes en termes de systèmes d'information et de domaines fonctionnels couverts. Vous êtes doté d'une forte culture de l'engagement et du résultat, vous êtes autonome, réactif et aimez relever les challenges. Vous avez déjà une expérience dans le secteur du digital et vous avez été confrontés aux problèmes de qualité de données et de volumétries.","Karavel Group, a leading online travel agency, is seeking a Data Engineer with at least 5 years of experience in Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS), Snowflake, and Power BI. The role involves maintaining and developing their existing BI system, as well as participating in a project to move to Azure/Snowflake/Power BI. The ideal candidate should have a strong ability to adapt to complex and heterogeneous environments and have a culture of engagement and result-orientation. Experience in the digital sector and dealing with data quality and volume issues is also preferred.",Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
200,56823,https://www.welcometothejungle.com/fr/companies/witco/jobs/data-engineer_paris,Data Analytics Engineer,Witco (Ex-MonBuilding),"{MongoDB,Athena,PowerBI,Lambda,S3,AWS,Nodejs,SQL,Python}",Télétravail partiel possible,"7, Rue de Magdebourg, Paris, 75116","Application mobile, SaaS / Cloud Services, Immobilier commercial",CDI,2023-03-26,"Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life… Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi… After raising a €12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who is Witco? Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life… Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi… After raising a €12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who is Witco? Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life… Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi… After raising a €12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who we are looking for 70% Data engineer 50% analytics Able to develop and maintain our data platform: support and enhance data architecture & instrumentation, define database schema, create datamarts and pipelining Your mission in the team Work with the team to analyze needs of data and work the the solutions to collect the data Prepare (collect, clean, transform, enrich, …), publish and test datasets Build and maintain general data architecture, data lake and derived data marts Work on the data pipelines, scheduling, orchestration Put in place automated tests for the data pipelines Implement monitoring and alert solutions for the data pipelines Create the necessary API endpoints to provide access to statistic data to 3rd party consumers Who are you? You have solid experience in a similar role with a proven track record of building, maintaining and optimizing data pipelines You have strong analytical skills and you are data-driven thinking You are result-oriented and focus on the value created by your development You have the ability to take ownership and be a technical lead to potentially lead the data engineering team in the future Fluent in English Experience Handling of large datasets with SQL Monitoring and improving the scalability & reliability of data pipelines Business-oriented data models & schemas Database programming Cloud computing (AWS S3, Athena, Terraform, etc) Main Technologies used AWS technologies: Athena S3 Lambda functions Python SQL Other technologies used: Terraform - Used to configure the infrastructure Nodejs - used for exports of MongoDB and communication with client app MongoDB - Main app data is stored on MongoDB Power BI - Create PowerBI dashboards with internal performance indicators. Benefits 🏠 2 days remote per week ☀️ Beautiful and spacious offices in the centre of Paris with a rooftop view on the Eiffel tower! 👥 A diverse, international, and friendly team of talented people 📚 Access to training programs 🏥 Alan health mutual (covered 50% by witco) 🍽 Restaurant tickets with Swile 🎉 Bi-annual off-sites and regular Afterworks At Witco, we are committed to an inclusive recruitment process and to fostering diversity within our teams.","Witco, a Worktech solution, is seeking a data engineer with a proven track record in building, maintaining, and optimizing data pipelines. The successful candidate must have strong analytical skills and be result-oriented, with the ability to take ownership and potentially lead the data engineering team in the future. Witco offers remote work opportunities, beautiful offices in the centre of Paris, access to training programs, health benefits, restaurant tickets with Swile, and regular social events. The company values diversity and promotes an inclusive recruitment process.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
208,34881,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/software-engineer-data-collection_paris_CONTE_r48OXPZ,Software Engineer - Data Collection,Contentsquare,"{React,regard,Jenkins,ContentSquare,Javascript,color,Contentsquare,TypeScript}",Télétravail partiel possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We’ve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we’re not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! This position is open to several locations: Paris, Lyon, Rennes, Barcelona ContentSquare's Data Collection team is looking for a talented Software Engineer! The main role of the Data Collection team is the collection of raw data application and web in an innovative way without impacting the performance of our customers (the largest digital companies in France, US, and UK). For this, we develop an universal web and application tag and we are willing to integrate the most modern frameworks such as React, Angular, Vue.js, Polymer, etc.This team faces the permanent technical challenge of constantly improving our technology to make it more innovative and more efficient. Our web collector is executed over 100 millions times daily on a large numbers of browsers and devices, so compatibility and stability is mission critical for the team. Technology wise, our web collector is developed in TypeScript with as few dependencies as possible. Our unit tests are launched on every browser we support and our codebase has 60+% test coverage at all times. We pride ourselves with automation of building, shippings, testing, validation and automate basically anything we can get our hands on. With our focus on automating the mundane, engineers have only to focus on the task at hand. Our codebase and processes baked in our CI can guarantee that when Jenkins shows green it really is green. This all means our product owners can ship by themselves on a Friday afternoon and can have the confidence to do so. We are building our own progressive rollout flow, so that we can do progressively and safely rollout our code to clients. If all of the above sounds like something you believe in and would like to be a part of, please see if you also like the following requirements. What you will do: - Participate in all phases of development lifecycle, from inception to deployment monitoring - Diagnose intricately complex issues, evaluate, recommend and execute the best resolution - Write regression free code, with unit tests and documentation - Implement code design, execute project deliverables and estimate scope of work - Work in an Agile SCRUM environment and having a TDD mindset What you will need: - Enthusiastic follower of good practices of development - You have some experience with TypeScript / Javascript - Fluent in English Why joining our Data Collection team - You are interested in contributing to open source projects as well as investing yourself on the tech scene by participating in meetups and presenting topics in conferences - You are looking for an environment where you'll have the possibility to have responsibilities and learn from more experienced developers - You share our ""quality focused"" vision: code reviews, coverage of unit and functional tests, ... Why you should join Contentsquare - We’re humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we’d like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company’s success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is a digital experience analytics company seeking a Software Engineer for their Data Collection team. The team develops an innovative way to collect raw data application and web, without impacting customers' performance. They are looking for someone with experience in TypeScript/Javascript, enthusiastic about development practices, and fluent in English. The company offers various benefits like stock options, parental leave, and a wellbeing allowance. They're an equal opportunity employer and welcome everyone to apply.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
167,56447,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-database-reliability_paris,Software Engineer - Global Data Platform,Datadog,"{Redis,color,Golang,Kafka,scale,Cassandra,Elasticsearch,Datadog,Python,Postgres}",Télétravail total possible,"21 Rue de Châteaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. Database Reliability Engineers (DRE) build production-ready solutions that our product engineers can use to build developer tools and automation that quickly scale up for use by thousands of customers. This team ensures that our databases are scalable and cost-efficient, giving our engineers the platform they need to operate in a high-volume, low-latency environment that is continuing to double in size. The DRE team works collaboratively with engineers across the company, using their deep systems understanding to respond to infrastructure failures and reduce operational toil for all. What You’ll Do: Keep our datastores reliable, available and fast. Respond to, investigate and fix issues, whether it’s deep in the database code or in the client application. Build tooling to minimize customer-facing downtime, and scale up resources on short notice Protect and ensure the consistency of customer data. Work with developers to design data models, and choose the correct datastores, to support orders of magnitude more customer data and traffic. Who You Are: 3+ years of experience in software engineering You value correctness and efficiency; you leave no stone unturned when diagnosing production issues You handle infrastructure with code because automation lets you focus on the more difficult and rewarding problems You have production experience with distributed datastores, e.g. Cassandra, Postgres, Kafka, Elasticsearch, Redis, You have created tooling for, or submitted contributions to, an open-source datastore You are fluent in Python or Golang Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our Internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-AD1 #LI-Remote This is a remote position About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice .","The Database Reliability Engineers (DRE) at Datadog are responsible for building and maintaining scalable, cost-efficient databases that enable the company's product engineers to develop tools and automation used by thousands of customers. Candidates must have at least three years of experience in software engineering and knowledge of distributed datastores such as Cassandra, Postgres, Kafka, Elasticsearch, and Redis. Fluency in Python or Golang is also required. Datadog values inclusivity and offers a range of benefits, including professional development opportunities, global mental health benefits, and an inclusive company culture. This is a remote position.",Non spécifié,> 2000 salariés,> 3 ans,3,0,0.04154662416233763
169,56372,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-h-f-cdi_puteaux_DATAS_ZMLPerq,Data Engineer  | CDI,Datascientest,"{Microsoft,GCP,Scala,Kubernetes,Airflow,AWS,Docker,R,Spark,Azure,Python,Bash}",Télétravail ponctuel autorisé,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"🤝🏻DataScientest ? DataScientest, est le leader de la formation aux métiers de la Data, en Europe La pluralité des formations proposées et la disponibilité de ses équipes talentueuses permet à tous les apprenants (B2B, B2C), quels que soient leurs besoins (reconversion professionnelle, développement de compétences, professionnalisation), et leur niveau, de se perfectionner, de progresser, d’être coachés et de booster leur carrière dans le monde de la Tech. De plus, DataScientest propose des formations adaptées aux objectifs de ses entreprises partenaires, notamment à travers son étroite collaboration avec pôle emploi, mais également des particuliers qui bénéficient d’un accompagnement personnalisé (équipes career & customer care). Enfin, DataScientest œuvre pour l’employabilité et le développement des compétences de ses apprenants, notamment à travers les dispositifs de POEI et l’ouverture de son centre de formation en apprentissage (CFA). 📈En quelques chiffres : Plus de 7000 apprenants inscrits et satisfaits, 70 groupes partenaires, dont 30 du CAC40, 2 partenaires académiques prestigieux : Mines Paris Executive Education et l’Université Panthéon La Sorbonne, Des partenaires éditeurs majeurs : AWS, Microsoft Azure 🏆Ses ambitions : D’ici 3 ans, DataScientest a pour objectif de devenir un champion mondial en continuant à proposer des produits de formation qui répondent aux besoins du marché et en poursuivant son expansion géographique, Afin d’appuyer son statut de leader, DataScientest continue de se développer à l’international et de créer ses propres écoles en Cybersécurité et DevOps adaptées aux besoins du marché (CyberUniversity, DevUniversity) ! Comment ? Avec un format pédgogique hybride unique, un studio R&D et surtout les équipes de DataScientest qui donnent le meilleur d’eux même au quotidien pour délivrer des formations de qualité ! En tant que Data Engineer, vous maîtrisez les technologies d’acquisition, de traitement, et d’extraction de données et avez des connaisisances scientifiques qui vous permettent de dialoguer avec des équipes Data. Missions et activités principales : Création et développement de contenus Création environnement de formation et contribution au développement de notre plateforme de formation Accompagnement et mentorat sur des sujet d’engineering Participation et organisation d’évènements data Participation à la stratégie R&D du département Tech Compétences requises : Excellente maitrise de Python Bonne maitrise de la programmation orienté objet La maitrise de Scala (Spark) est un + Attrait pour l’actualité relative au machine learning, l’engineering et à l’open-source. Bon niveau en Anglais. La connaissance d’un provider cloud est très appréciée (AWS, Azure, GCP) ETL Bonne connaissance des différents Systèmes de Gestion de Bases de Données Bonnes connaissances en script Bash Attrait pour l’actualité relative au machine learning Outils de mise en production: Docker, Kubernetes, FastAPI, Airflow Savoir faire S’adapter rapidement aux nouvelles technos de Data Engineering Aimer transmettre ses connaissances et accompagner des profils sur des thématiques de Data Engineering Travailler en équipe Savoir gérer son temps et hiérarchiser les priorités, Capable de supporter des charges de travail parfois élevées Résoudre des problématiques complexes Savoir être Être autonome, rigoureux(se), organisé(e) Avoir un bon esprit d’analyse, et une capacité à explorer de nouvelles stratégies Preneur(se) d’initiatives Avoir un gout prononcé pour l’apprentissage de nouvelles technologies Disposer d’un bon niveau rédactionnel en français/anglais. Niveau d’étude et expérience : Bac +5 en maths/informatique minimum, et au moins 1 stage en entreprise sur des problématiques de Data Engineering Vous avez une appétence pour la formation et votre état d’esprit start-up vous permettra d’évoluer rapidement et de tirer l’entreprise vers le haut ? Rejoignez-nous ! 1 - Appel de cadrage 2 - Entretien(s) avec l’équipe technique 3 - Evaluation technique 4 - Entretien avec un co-fondateur","DataScientest is a leader in data training in Europe, offering a variety of courses to both individuals and businesses. The organization aims to become a global champion in the next three years by continuing to offer relevant training and expanding geographically. The Data Engineer will be responsible for creating content, contributing to the development of the training environment, mentoring, and participating in data engineering events. Required skills include Python proficiency, object-oriented programming, ETL, database management systems, and a knowledge of cloud providers like AWS and Azure. Candidates should also be adaptable, able to work collaboratively, and able to manage competing priorities. A minimum of a bachelor's degree in math or computer science and experience working with data engineering problems is also required.",Bac +5 / Master,Entre 50 et 250 salariés,> 6 mois,1,2,0.04154662416233763
206,65925,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/database-reliability-engineer-f-m-d_paris,Database Reliability Engineer,Decathlon Digital,"{Redis,MongoDB,Dynatrace,Github,NoSQL,ElasticSearch,Mysql,Aiven,AWS,via,Kafka,GCP,Datadog,SQL,CouchBase,Python}",Télétravail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-05,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES CLOUD PLATFORM ENGINEERING Ses objectifs principaux sont de rationaliser le catalogue de produits techniques référencés au sein du groupe ET de fournir des services “clé en main” pour les équipes IT, qui pourront ainsi se concentrer sur le développement de services à valeur ajoutée. Le fait d’avoir moins d’outils va permettre de mettre plus de monde sur chacun et d’approfondir l’usage de ceux-ci. Il sera aussi plus simple de basculer d’équipe en équipe grâce à des compétences communes. Aujourd’hui, la CPE est une Business Unit de près de 150 personnes qui continuent à se renforcer et travailler main dans la main avec les équipes de chaque domain. REJOINS L'ÉQUIPE DATA BASE RELIABILITY ENGINEERING L’équipe Database Reliability Engineering que tu intégreras s’occupe de fournir des solutions de base de données les plus innovantes, les plus performantes et les plus packagées possibles afin d’accélérer la mise à disposition des applications pour nos clients finaux. Une partie du travail de l’équipe est d’ industrialiser et d'automatiser les solutions référencées afin de toujours donner plus de moyens et d’autonomie aux développeurs pour améliorer les performances de leurs applications. Un des objectifs est également de tester les dernières solutions du marché pour les intégrer à notre catalogue si un bénéfice pour les équipes est identifié. L’équipe a également une mission de conseil en architecture, d’audit auprès des applications et domaines afin de toujours coller au mieux aux besoins des équipes de développement. Tu pourras i ntervenir sur des problématiques de performances complexes sur des applications de l'ensemble de nos BUs à l'international (60 pays). Tous nos hébergements sont déjà sur le Cloud. Nous nous appuyons donc beaucoup sur des solutions managées des Cloud Providers ou de tiers via les Marketplaces ou services agnostiques (#CloudNative). L'équipe doit s'assurer que chacune de ces offres soit en conformité avec notre Cloud Security Policy et adopter l'approche Security By Design. Le périmètre technique : Databases : PgSQL, Mysql, MongoDB, Redis, CouchBase, OpenSearch Managed Databases : Aiven (avec Kafka, PgSQL, OpenSearch) Managed Databases : Amazon RDS, Cloud SQL Cloud Service Providers : GCP, AWS Infra-as-Code : Terraform / Python Observabilité / monitoring : Dynatrace, Datadog Gestion de code : Github CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience d' au moins 2 ans en bases de données et sur des solutions Cloud Tu es à l’aise dans l’ étude de performances des bases de données relationnelles et/ou NoSQL Tu as déjà installé et administré des bases de données et tu capitalises maintenant sur des connaissances plus larges à propos des infrastructures Tu aimes découvrir, tester les nouvelles solutions du marché afin de faire des propositions pertinentes sur les produits et optimiser les services dont tu as la charge Tu es coutumier des bonnes pratiques DevOps et tu as à cœur de les mettre en oeuvre et des les partager avec le reste des équipes Tu es reconnu pour ton sens du service, tes capacités d’écoute et ta pédagogie Tu pratiques régulièrement l’anglais dans un contexte professionnel Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et la vie d'équipe ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) Tu possèdes les hard skills suivantes : Databases : PgSQL, Mysql, MongoDB, Redis, CouchBase, OpenSearch - Niveau intermédiaire sur une de ces technologies Managed Databases : Aiven (avec Kafka, PgSQL, ElasticSearch) - Niveau débutant Managed Databases : Amazon RDS, Cloud SQL - Niveau débutant Cloud Service Providers : GCP, AWS - Niveau débutant Infra-as-Code : Terraform / Python - Niveau intermédiaire Observabilité/Monitoring : Dynatrace, Datadog - Niveau débutant Gestion de code : Github - Niveau intermédiaire CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon à Lille ou Paris (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon, the leading sportswear company, is seeking a Database Reliability Engineer to join their Cloud Platform Engineering team. The role involves providing innovative and high-quality database solutions, improving the performance of applications, and delivering automation and industrialization of the reference solutions. The ideal candidate should have a minimum of 2 years of experience in databases and cloud solutions, excellent knowledge of databases and cloud infrastructure, and proficiency in DevOps practices. Decathlon offers a flexible work environment, opportunities for professional growth, and a mission to make the benefits of sports accessible to everyone.",Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
204,65924,https://www.welcometothejungle.com/fr/companies/relyens/jobs/developpeur-etl-talend-h-f_lyon,DEVELOPPEUR ETL - TALEND,Relyens,"{SQL,Qlik,Talend}",Télétravail partiel possible,"20 Rue Edouard Rochet, Lyon, 69008","Assurance, FinTech / InsurTech, Santé",CDI,2023-04-05,"Relyens est le Groupe mutualiste européen de référence en Assurance et Management des risques spécialiste des acteurs du soin (hôpitaux, cliniques, Ehpad, professionnels de santé…) et des territoires (régions, mairies, élus locaux, centres de gestion…). Pour sécuriser leur activité et garantir la qualité des services délivrés aux patients et citoyens, nous les accompagnons dans la maîtrise des risques liés à la délivrance du soin, à la gestion du capital humain ou à la cybersécurité. Nous déployons une approche globale et unique combinant des solutions de pilotage, de prévention des risques et d'assurance. Créé à Lyon il y a près de 100 ans par et pour des hospitaliers, Relyens est Entreprise à Mission depuis 2021 . « Agir et innover, aux côtés de celles et ceux qui œuvrent à l'intérêt général, pour construire un monde de confiance .», telle est la raison d'être qui anime nos 1100 collaborateurs en France, en Espagne, en Italie et en Allemagne. À votre tour, rejoignez-nous et impliquons-nous ensemble pour ceux qui s'engagent. Pour en savoir plus, rendez-vous sur Relyens.eu Restons connectés : LinkedIn , Twitter , Youtube Au sein de notre DSI et en interaction forte avec les Services Finance & RH, vous intervenez sur la mise en œuvre des évolutions majeures du Système d'Information financier et RH (en mode projet), sur les activités de maintenance évolutive et corrective et le support de niveau 3 (support technique) auprès des utilisateurs. Vos missions : Au sein d'une équipe de 5 personnes, vos missions principales sont les suivantes : - Analyser les spécifications fonctionnelles et assurer la conception technique et le développement des flux de données ETL sous Talend sur le domaine SIFI/SIRH - Contribuer à l'assistance aux phases de recette technique et fonctionnelle - Préparer et accompagner les mises en production dans le respect des processus internes - Contribuer activement à l'optimisation constante des flux de données sur le domaine SIFI/SIRH - Contribuer à la rédaction de la documentation (SFD, STD, CR d'atelier, cahier de tests, supports de formation…) - Assurer une bonne coordination avec les experts internes Talend afin de garantir la conformité avec les normes et standards de développements IT Groupe - Assurer une assistance technique à l'équipe en charge de l'exploitation du SI - Intervenir dans le cadre du support Assurer le bon fonctionnement du SIFI et du SIRH en assurant la supervision quotidienne des flux et batchs, et mener les actions correctives en respect des contraintes opérationnelles des équipes Finances et RH - Contribuer au développement et au maintien en conditions opérationnelles des applications de pilotage financier et RH. Votre profil : De formation supérieure type école d'ingénieur ou équivalent en informatique, vous justifiez d'une expérience d'au moins 3 ans dans la mise en en œuvre de flux ETL et maîtrisez les bonnes pratiques de développement et d'exploitation d'une plateforme. Vous possédez les compétences suivantes : ETL (Talend), langage SQL et manipulation de requêtes complexes, la sécurisation des échanges de données. Idéalement vous avez des notions de comptabilité générale et technique (schémas comptables, CRE / CRI…, développement BI (Qlik)). Autonome, rigoureux, force de proposition et doté d'un très bon sens du service et du collectif, vous avez plaisir à travailler en équipe dans des organisations matricielles et multisites, vous aimez intervenir en mode projet et sur des activités de maintenance évolutive et corrective. Vous faites preuve d'Agilité et êtes à l'aise avec les process et outils correspondants (orientation client, user stories, gestion du backlog, Kanban, JIRA, Confluence…). Un niveau d'anglais à l'écrit et à l'oral de niveau B2 minimum est requis. Mission basée à Lyon, des déplacements peuvent avoir lieu de façon très ponctuelle sur nos différents sites (France et International). Relyens est un Groupe handi-accueillant et handi-bienveillant. Tous nos postes sont ouverts aux personnes en situation de handicap.","Relyens, a European mutual insurance and risk management group specializing in healthcare and territory actors, is seeking a Financial and HR Information System Developer with at least 3 years of experience in ETL flow implementation, SQL, and data exchange security. The successful candidate will join a team of 5 people in Lyon and have a good understanding of accounting, BI development, and agile processes. The position requires occasional travel to Relyens' various sites in France and internationally. Relyens is a disability-friendly group, and all its positions are open to people with disabilities.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
202,57135,https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f_paris_EL_7z5xOwg,Data Engineer,Eleven Labs,"{Jupyter,SnowFlake,GO,Node,Spark,BigQuery,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"102, Rue du Faubourg Saint-Honoré, Paris, 75008","Logiciels, IT / Digital, Audit",CDI,2023-03-26,"Eleven Labs est une société de conseil, spécialisée en création et réalisation de projets Web agiles de qualité. Les astronautes interviennent sur des missions qu’ils choisissent, et elles sont axées sur du développement, de l’architecture, de la conduite de projet Agile, de l’audit et du conseil. Au quotidien, tout est fait pour encourager la progression et l’épanouissement technique, à travers des plateformes dédiées à l’apprentissage ( le blog , le codelabs , des accès à Udemy et egghead.io …), ou grâce à des événements internes (workshops, meetups, formations…) réguliers. Seras-tu notre furtur.e Data Engineer ! Un peu de contexte ☝️ De plus en plus de nos consultants s’intéressent de près au sujet de la Data, ce qui nous a poussé à explorer ces problématiques chez nos clients et de constater un besoin fort d’accompagnement de leur part. Nous recherchons donc la personne qui ouvrira la voie à cette expertise chez Eleven Labs et qui accompagnera la création de l’escouade Data ! Nos attentes 🧠 Nous recherchons quelqu’un d’expérimenté/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de répondre au mieux aux problématiques qui lui seront soumises, pour qui les requêtes SQL, NoSQL sur BDD n’ont aucun secret, et qui maîtrise déjà une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake). 🍒 Cerise sur le gâteau : on cherche aussi un profil maîtrisant les langages type Python, Java, GO et Node.JS pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribué. Des connaissances dans l’utilisation d’outils ML et d’environnement Cloud en général sont un vrai plus. 🎭 Côté personnalité, et outre cet aspect expérimenté et “ouvreur de voie”, on cherche quelqu’un de moteur, avec un réel enthousiasme à transmettre ses connaissances, former et échanger. Les missions 🕵️ Les missions proposées te feront intervenir dans des secteurs divers, avec des cas d’usage variés souvent en lien avec le marketing et impliqueront principalement : d’être force de proposition quant au choix des outils et pratiques ; faire de la data visualisation (B.I.) d’assurer l’extraction de données et leur transformation de gérer la mise en place from scratch de pipelines et data lakes. Nos engagements 💪 Tu participeras activement au développement de l’escouade Data chez Eleven Labs pour laquelle nous avons de véritables ambitions de production de contenu externe (talks, articles, implication dans le recrutement…), et interne (workshops, animation de la communauté Data, mentorat de profils juniors…). 🔥 Nos clients sont des sites grand publics principalement des secteurs médias/presse et e-commerce, avec pour points communs un fort accent mis sur la qualité, et un fonctionnement en méthodologie Agile. 💖 Tu travailleras avec une équipe de passionné(e)s qui aime partager, remettre en question ses façons de faire, et trouver de nouvelles idées pour gagner en efficacité. 🤝 Tu évolueras dans une culture d’entreprise qui valorise le collectif : nous restons même à 100 salariés une entreprise où les gens se connaissent et échangent quotidiennement (pour parler de leur job mais aussi du dernier meme ou d’un compte Twitter improbable). Si tu es intéressé(e), comment ça se passe ? 🗨️ Tout commence par un entretien d’introduction Tu t’entretiendras avec une recruteuse tech qui te suivra tout le long de ton parcours chez nous. Vous parlerez de tes attentes et de ce que tu aimes dans ton job, et elle te présentera Eleven Labs. 👋 Ensuite il y a un entretien de cas pratique Pour avoir une idée de ce qui t’attend, on te propose de rencontrer Rémy (Data Architect) ainsi que Charles-Éric (Directeur Technique). 🏠 On conclut par une visite des locaux On t’invite dans les locaux ! Tu pourras y rencontrer d’autres membres de la fusée pour échanger sur leurs parcours et le tien autour d’un café.","Eleven Labs is seeking an experienced Data Engineer with expertise in ETL/ELT pipeline and data lake/hub, SQL and NoSQL databases, and one or more Data Warehouse solutions. Proficiency in languages like Python, Java, GO, and Node.JS is preferable with knowledge in tools like Spark, Jupyter, and Cloud Run for distributed computing. The successful candidate should have a genuine enthusiasm for mentoring, sharing knowledge, and exchanging expertise with the team. The missions will involve data visualization, data extraction, transformation, and management for various sectors, with emphasis on marketing.",Non spécifié,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
172,57020,https://www.welcometothejungle.com/fr/companies/greenflex/jobs/data-engineer_paris,Data Engineer,GreenFlex,"{durable,InfluxDB,Databricks,Gitlab,AWS,DataDog,MLflow,Spark,SQL,Qlik,Python}",Télétravail partiel possible,"7-11 boulevard Haussmann, Paris, 75009","Environnement / Développement durable, Energie",CDI,2023-03-26,"Nous aidons les organisations à changer de trajectoire en se transformant sur le plan environnemental, énergétique et sociétal. Notre raison d’être ? Construire une économie qui crée et préserve plus qu’elle ne détruit. Notre modèle est basé sur la multi expertise : Conseil-environnemental et sociétal Mise en œuvre de projets de performance énergétique et bas-carbone Financement de la transition Plateforme digitale de pilotage des plans d’actions Face aux urgences environnementales et sociétales, ce modèle nous permet aujourd’hui d’accélérer la transition de nos 800 clients et plus encore demain. GreenFlex recherche un Data Engineer pour participer à l’accompagnement des clients internes et grands comptes dans la réduction de leur empreinte énergétique et environnementale à travers des projets analytics. MISSIONS ET RESPONSABILITÉS : Au sein d’une équipe digitale organisée en squads « agile » avec une forte culture devops, membre du Chapter Data Analytics, vous travaillerez sur l’industrialisation des modèles de Machine Learning sur la plateforme Greenflex IQ, plateforme dédiée à l’accélération de la transition environnementale de ses clients (énergie, développement durable, RSE, financement, …). Vous aurez la possibilité de travailler sur un environnement à haut niveau technique (AWS, Databricks, MLflow, Qlik, DataDog, Gitlab, librairies Python notamment de Data Science). Vous serez principalement amené(e) à travailler sur des sujets orientés analyse de données et modélisation qui consisteront à : • Participer à la poursuite de la mise en place et à la maintenance des outils MLOps de la plateforme (model registry, model serving, model monitoring, automatisation, metadata handling, features store, etc.) • Contribuer à la conception et aux développements des nouveaux produits analytics de la plateforme, en appliquant les « best practices » du génie logiciel • Assurer la maintenance des produits analytics • Alimenter et maintenir les documentations techniques Vous participerez à l’élaboration d’algorithmes de traitement, d’analyses de données et modèles d’apprentissage automatique avancés : réseaux de neurones, clustering, régression logistique, PCA… Vous serez immergé dans les problématiques métiers des équipes de management de l’énergie sur des secteurs d’activité tel que le retail, l’industrie ou encore sur des problématiques d’ENR − Grandes écoles d’ingénieur ou université avec une majeur ou spécialisation en mathématiques appliquées, statistiques ou big data analytics. − Expérience professionnelle exigée : 4 ans en tant qu’ingénieur de données, et ayant participer à l’architecture et la réalisation de flux d’acquisition, d’ingestion, de préparation et de traitements de données (distribués ou non) COMPETENCES TECHNIQUES : − Maitrise d’un langage de programmation, tel que Python, Pyspark est obligatoire − Maitrise développement en Spark sur l’environnement Databricks / module Delta est obligatoire − Connaissances DevOps et GitOps − Connaissances en base de données tels que : SQL, InfluxDB, Spark, RDBMS − Maitrise d’API tel que Graph QL serait appréciable − Bonne maitrise d’Excel et de PowerPoint − Bonne connaissance des enjeux environnementaux et IT − Une connaissance des méthodes d’explicabilité des modèles de Machine Learning (XAI) serait un plus APTITUDES : • Esprit Engineering et Génie logiciel • Bon niveau d’anglais • Méthodologies Agile • Une connaissance du secteur du développement durable et/ou de l’énergie serait un plus SAVOIR ETRE : − Communication orale et écrite claire − Sens du service − Qualité d’écoute et de pédagogie − Esprit de collaboration − Autonomie − Rigueur","GreenFlex is seeking a data engineer with a degree in applied mathematics, statistics, or big data analytics and a minimum of 4 years' experience in data engineering. The candidate must have skills in programming languages like Python and Pyspark, DevOps, GitOps, database management, and a good understanding of environmental and IT issues. The role involves working on Machine Learning models, designing, and implementing new analytics products and maintaining existing analytics products. The candidate should have an engineering and software engineering mindset with good communication, collaboration, and listening skills.",Bac +5 / Master,Entre 250 et 2000 salariés,> 4 ans,2,1,0.04154662416233763
173,58074,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_montpellier,Expert technique ETL Semarchy xDI / Stambia,CGI,{},Télétravail total possible,"Montpellier, 34000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Semarchy xDI / Stambia • Participer aux échanges avec l’éditeur Semarchy • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné.e d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert.e technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI is seeking a passionate and ambitious Data ETL Expert with at least 3 years of experience in technical integration of data within digital services or consulting firms. The candidate would join the Digital Innovation Center and work collaboratively in teams to support clients' digital transformation through the efficient delivery of data solutions. The role includes analyzing and improving solution efficacy, collaborating with experts on technical queries, facilitating training, participating in pre-sales as a technical expert, and supporting clients and teams on a daily basis. The ideal candidate has experience with Semarchy xDI / Stambia ETL and a desire to diversify their skill set. CGI is an inclusive employer committed to supporting diverse candidates and their career development.",Non spécifié,> 2000 salariés,> 3 ans,3,0,0.04154662416233763
174,56315,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont_NATIX_yRRpMQO,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",Télétravail partiel possible,"avenue de la liberté , Charenton-Le-Pont, 94018","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engagé à construire un environnement de travail inclusif, nous offrons les mêmes opportunités aux talents de tous horizons, indépendamment de votre âge, origine, orientation sexuelle, handicap... Au sein du département CIO CIB, vous rejoignez l'équipe de Sensitivities, au sein de l'IT Risks, composée de 10 personnes. En nous rejoignant, vous prenez part à plusieurs programmes de transformation de notre système d'information afin de répondre aux besoins du département des risques, des régulateurs, tout en accompagnant les front offices dans leurs nouvelles activités. L'équipe est en charge de la maintenance et des évolutions de deux applications clés pour la gestion des risques de marchés : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities répondant à la réglementation FRTB). Nos principaux interlocuteurs sont le département des risques de marchés (équipe de transformation et équipes de production du P&L), les équipes IT Natixis Paris (IT Front, et IT Risk), les équipes support/production à Porto et les équipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques à mettre en œuvre et estimer le coût avec l'équipe ; Développer de nouvelles fonctionnalités de la phase de conception aux tests, dans une démarche durable (haute qualité du code, respect des principes d'architecture et de sécurité informatique, documentation, automatisation des tests, utilisation maitrisée de l'infrastructure) ; Travailler sur des problématiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et améliorer la Software Factory et les environnements de développement ; Assurer, avec l'équipe, le support de niveau 3 et les développements nécessaires pour maintenir une production ponctuelle, de qualité et maîtrisée. La stack technique utilisée est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en méthode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est basé à Paris et à Charenton-le-Pont et chez nous c'est 10 jours de télétravail par mois, 15 à 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos rémunérations sont composées d'un fixe, d'un bonus annuel, d'un dispositif d'épargne entreprise incluant l'intéressement, la participation et l'abondement. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : De formation supérieure en informatique avec une spécialisation en big data, vous avez au moins 3 ans d'expérience en tant que data engineer. Vous maîtrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La préconisation de solutions techniques. Vous êtes : - Reconnu pour votre leadership ; - Capable de proposer des améliorations continues ; - Rigoureux, autonome et pédagogue. Vous maîtrisez l'anglais avec un niveau minimum B2. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis Corporate & Investment Banking is looking for a Data Engineer with at least 3 years of experience in big data who is proficient in Spark, Scala, and Hadoop. The role involves developing sustainable solutions, optimizing performance, and maintaining and improving the Software Factory and development environments. The successful candidate will be autonomous, rigorous, and able to propose continuous improvements while working in an agile framework. Natixis offers flexible working arrangements, career development and training opportunities, and the chance to make a positive impact on society.",Bac +4,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
175,56367,https://www.welcometothejungle.com/fr/companies/gojob/jobs/staff-ml-engineer-datascientist-aix-en-provence_aix-en-provence,Staff ML Engineer (DataScientist) - Aix en Provence,Gojob,"{Kubeflow,GCP,Azure,MongoDB,regard,Go,Gitlab,PostgreSQL,AWS,dbt,scale,R,BigQuery,Docker,SQL,Python,Elastic}",Télétravail partiel possible,"220 Rue de la tramontane, Aix-En-Provence, 13090",Recrutement,CDI,2023-03-26,"Qui sommes-nous ? Implantée en France et aux USA, Gojob est une plateforme de service pour l’emploi qui s’appuie sur ses propres technologies et données pour rendre le marché du travail plus fluide et accessible, et accompagner chaque individu avec dignité. Chez Gojob, “We staff instantly, at scale and with care”. Membre trois années consécutives de la promotion French Tech FT120, deux fois saluée par le prestigieux classement du Financial Times, élue n°1 des Champions de la Croissance 2021 des Echos, Gojob continue son ascension sur le marché de l’emploi pour un impact social concret. Notre ambition “Proposer un accompagnement personnalisé à nos intérimaires quelque soit leur formation et leur expérience et permettre à nos clients de trouver instantanément les meilleurs profils répondant à leurs exigences. “ Pour faire la différence et offrir un modèle 100% tech intégré sur un marché de l’intérim traditionnel, nous avons créé et investi 12M€ en R&D dans notre laboratoire dédié à l’Intelligence Artificielle afin de développer notre technologie propriétaire. Fruit de 6 ans de recherche, nous avons aujourd’hui un écosystème tech et data qui révolutionne les process de recrutement et réinvente l’accompagnement de l’individu. Sourcing, matching, gestion, onboarding, suivi, formation… chez Gojob, la technologie est partout. Avec une IA et des flux d’automatisation basés sur des données exclusives, notre stack tech nous permet de sourcer, sélectionner et valider des candidats : 32x plus rapidement qu’une agence traditionnelle Plus qualitativement : 95% des profils recommandés automatiquement par l’IA sont embauchés et présents le premier jour. Tout en favorisant l’impact social : notre algorithme matche les candidats les plus pertinents au regard de + 100 dimensions observées, en prenant en compte les soft-skills et sans aucune discrimination. Cet algorithme est monitoré par notre comité d’éthique qui veille à son intégrité. Il fait l’objet d’un brevet et nous avons publié plusieurs articles scientifiques sur le sujet. Reconnu pour son savoir-faire et souvent présenté dans les médias, le lab a su attirer des talents et des ingénieurs issus des meilleures formations en intelligence artificielle. Présentation du poste : La data est au coeur de la stratégie de Gojob. Notre équipe travaille quotidiennement sur du delivery avec un impact immédiat sur l’offre de service Gojob. La Data science est partie prenante de l’activité et en interaction régulière avec les équipes produits, business et le Comex. Nous renforçons l’équipe Data de notre labo d’intelligence artificielle avec un poste de Staff ML engineer (Data-Scientist) en CDI sur Aix-en-Provence. Vous aurez l’opportunité unique de travailler avec un groupe de passionnés pour une innovation continue qui révolutionne le marché de l’emploi avec un impact social concret et réel. Détail des missions : Identifier, modéliser et développer des projets data science de bout en bout Vous travaillez en collaboration avec le Produit dans l’identification de sujets sur lesquels la data science peut avoir de l’impact au service du business et de la stratégie. Vous allez sur le terrain à la rencontre des différentes parties prenantes de Gojob (métiers en interne, clients, Gojobbers). Vous modélisez les problèmes métiers puis construisez avec pragmatisme, déployez et maintenez les produits data science de bout en bout : scoring, matching, recommandation, sequence modelling, NLP. Vous améliorez continuellement les produits data science existants, entre autres, AGLAE : notre algorithme de matching au service des recruteurs de Gojob. Vous mesurez l’impact de vos travaux et vous assurez de la pérennité de la performance des modèles mis en production. Faire progresser l’équipe Data Vous êtes un élément moteur dans la vie de l’équipe Data : daily, upskilling, partage de connaissance, Coproj avec le C-level.. Vous êtes un mentor et réalisez le coaching technique des data scientists. Vous les aider à monter en compétence techniquement et à gagner en ownership sur les projets data que vous avez initiés. Porter la voix de la data science chez Gojob Vous êtes un vrai référent en data science auprès de Gojob : vous réalisez une veille techno et scientifique constante, vous identifiez les prochains sujets “game changer” en lien avec le Head of Data, vous êtes force de proposition pour faire évoluer la stack Data de Gojob en lien avec le Data Engineer Vous avez la capacité à expliquer et vulgariser des concepts complexes au business et aux utilisateurs. Valoriser les actifs tech de Gojob auprès des investisseurs et de la communauté scientifique vous encadrez la rédaction des brevets et d’articles scientifiques vous gérez les relations avec les laboratoires et les universités pour faire avancer notre recherche Quelle est notre stack technique ? Python, SQL Google Cloud Platform Docker, Gitlab CI/CD PostgreSQL, BigQuery, MongoDB, Elastic Search Poetry, VertexAI, Kubeflow Feature store, precompute, fast API dbt Êtes-vous notre futur(e) Staff ML engineer ? Vous avez au moins 5 ans d’expérience en tant que ML Engineer-Data Scientist. Vous avez un cursus BAC+5 ou ingénieur dans un de ces domaines: informatique, stats, mathématiques et/ou data science. L’obtention d’un PhD est un plus. Vous avez une réelle appétence pour les enjeux business et stratégiques. Vous avez la capacité et le relationnel nécessaires pour échanger avec les différentes parties prenantes de Gojob et faire évoluer notre produit. Vous avez une expérience consistante en modélisation, et êtes ainsi très à l’aise pour faire le lien entre les besoins business et les solutions techniques possibles. Vous êtes de nature entreprenante, vous savez porter des initiatives et être un réel moteur de la stratégie data. Vous avez une excellente maîtrise de Python et SQL et une expérience professionnelle sur des projets NLP. Vous êtes familier avec le déploiement de solutions Data Science dans des infrastructures Cloud (type GCP, AWS, Azure ou autre). Vous savez travailler avec Gitlab, et une maîtrise de la CI/CD est un plus. Ce que nous vous offrons : Une rémunération attractive selon votre profil Une politique de télétravail flexible (2 jours/semaine et plus de flexibilité ponctuellement) La carte Swile (équivalent ticket resto) d’une valeur de 8€/jour pris en charge à 55% par Gojob 6 semaines de Congés Payés Une excellente mutuelle/prévoyance 50% du titre de transport en commun remboursé Des cours hebdomadaires de yoga Un forfait sport à 150€/an Les avantages de Gojob: Si vous travaillez sur Aix-en-Provence : 300 jours de soleil par an dans un cadre de travail inspirant avec jardin avec vue sur les vignes et la lavande :) à 30 minutes de la mer et juste à côté de la célèbre Sainte Victoire propice à de superbes randonnées les week-ends ! Et pour tous… Le “Go Community program”, c’est à dire une team dédiée, chargée d’animer la vie de l’entreprise tous les mois en proposant des activités culturelles, solidaires, sportives, sans oublier festives ! Quel est le processus de recrutement ? Un entretien avec Oliver (Head of data) Un échange technique avec l’équipe Data Un entretien avec Guillaume (Head of product) Un entretien avec Nicolas (CTO)","Gojob, a job services platform with a focus on using technology and data to make the job market more accessible, is seeking a Staff ML Engineer (Data Scientist) to join its team in Aix-en-Provence, France. The successful candidate will work on identifying, modeling, and developing data science projects in collaboration with the product team, and is expected to have at least five years of experience as an ML engineer or data scientist. The role also involves mentoring and coaching data scientists, and promoting the voice of data science at Gojob. An excellent understanding of Python and SQL, and experience with NLP, are required for the role.",Bac +5 / Master,Entre 50 et 250 salariés,> 5 ans,2,1,0.04154662416233763
164,65899,https://www.welcometothejungle.com/fr/companies/ekkiden/jobs/data-engineer-f-h_paris,Data engineer,Ekkiden Technologies,"{Cassandra,R}",Télétravail partiel possible,"Paris, 75001","IT / Digital, Transformation",CDI,2023-04-05,"The consulting world needs a new, more human, more modern, and more agile actor. This is the ambition that gave birth to Ekkiden in 2019. Today, this international consulting group is challenging traditions and bringing a large dose of innovation to its sector. Through its ecosystem of passionate, enthusiastic, and committed consultants, Ekkiden leads organizational, operational, and technological transformation projects in three areas, IT/Digital, Industry/R&D and Pharma/Biotech, mainly with large accounts and SMEs. Le rôle: Data Engineer Responsabilités: Vous alimenterez le datalake par des données Vous réaliserez les calculs d’agrégats Vous participerez à la conception générale et à l'analyse technique Vous développerez des programmes et les tests unitaires associés Vous participerez à la recette fonctionnelle et à la préparation de la mise en production Vous serez en charge du support aux utilisateurs Vous réaliserez des compte rendu des avancées et des points d’alerte Ce que nous recherchons : Vous êtes issu d'une formation Bac+ 5 en informatique Vous justifiez de bonnes connaissances sur Cassandra Vous êtes curieux, ouvert d'esprit et possédez un bon esprit d'investigation et d'analyse Ce que nous proposons: 🤝 Nous rejoindre au bon moment pour faire ta place au sein d’une organisation en très forte croissance 🚀 Des missions variées dans un environnement challengeant qui te permettront d’avoir un réel impact sur la boîte 💪 La possibilité de travailler de façon autonome et d’être force de proposition pour grandir ensemble ✨ Un parcours de carrière adapté à ta personnalité, aussi bien au niveau du rôle que de la localité 🤓 Une formation exigeante en continu pour libérer tout ton potentiel 👍 Des conditions de travail flexibles (horaires, télétravail, …) 💸 Une culture de la performance avec de belles primes de résultats ❤️ Une mutuelle très complète (Alan) et des titres-restaurant (carte Swile)","Ekkiden, an international consulting group, is seeking a Data Engineer with knowledge of Cassandra to contribute to its data lake, perform aggregation calculations, develop programs and participate in functional testing, among other responsibilities. The role offers the opportunity to work with a fast-growing organization, have a real impact, work autonomously, and receive continuous training and flexible work conditions.",Bac +5 / Master,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
176,56436,https://www.welcometothejungle.com/fr/companies/hove/jobs/data-engineer-paris-h-f_paris,Data Engineer - Paris -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",Télétravail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilité, SaaS / Cloud Services",CDI,2023-03-26,"Hove est un acteur incontournable de la data-mobilité, en plus d’être une filiale de Keolis. Depuis sa création il y a 24 ans, Hove est un acteur clé dans ce domaine et l’un des premiers experts. Il occupe une place considérable dans l’écosystème de la mobilité et fait partie d’une communauté de 20 000 développeurs, qui participent à leur stratégie d’innovation ouverte et collaborative. Acteur de la Greentech, Hove porte une vision évolutive des mobilités douces, pour un impact plus positif et plus responsable de notre environnement grâce à ses 2 produits et métiers : Avec Navitia , Hove travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire, tout en tenant compte du contexte et des préférences du voyageur. L’objectif ? permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’impact possible sur la planète. Avec Patterns , Hove analyse les motifs que dessinent les mobilités sur un territoire ciblé. L’objectif ? Suivre la fréquentation, à travers des matrices origine – destination, les parts modales… À partir du recueil et de l’analyse des traces GPS et WiFi, entre autres. En tant que Data engineer Hove, vous êtes intégré à une équipe pluridisciplinaire mêlant développeurs, Product Owner, Architectes dont l’objectif est de créer des services à fortes valeur ajouté dans le domaine du transport. Vous avez la charge de définir et mettre en œuvre le pipeline d’acquisition des données (datahub) global pour Hove, d’organiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Créer et faire évoluer le moteur d’ingestion des données (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilité des flux de données Travailler en collaboration avec les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégrations continues, scalabilité des modèles, craftsmanship, etc…) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Déployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des données Superviser et monitorer le déploiement et la robustesse des composants mis en production Participer activement à la qualité de l’ingénierie logicielle (Relecture de code, test, intégration continue, déploiement, etc.) Participer aux évènements internes à la communauté data interne et externes (AWS Summit, workshops, meetups…) Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.* Vous justifiez d’une expérience d’au moins 2 ans en tant que Data engineer Vous opérez dans le conseil et pouvez justifier de vos missions Vous maitrisez l’anglais professionnel Vous maitrisez au moins : Un framework de calcul distribué tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala…). Différents systèmes de base de données (SQL et NoSQL) et le langage SQL. Un framework de streaming de données tel que Kafka, Kinesis, … Une expérience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks… Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez être capable de livrer du code de qualité dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l’équipe tech Un entretien avec notre CTO","Hove, a subsidiary of Keolis, is seeking a Data Engineer with at least two years of experience in the field. The ideal candidate will have proficiency in distributed computing frameworks such as Spark, Storm, and Flink, programming languages including Python, Java, C/C++, and Scala, and streaming data frameworks like Kafka and Kinesis. They will also have experience with AWS technologies, including Terraform and CloudFormation, and knowledge of SQL and NoSQL databases. The role involves working in a multidisciplinary team to develop high-value services in the transport sector, including designing and implementing a global data acquisition pipeline, managing data storage, and providing support to data scientists and analysts.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,2,1,0.04154662416233763
198,56696,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-engineering-manager-f-h_evry_CARRE_aPXyR8o,Data Engineering Manager,Carrefour,"{durable,Looker,dbt,Node,scale,BigQuery,Python}",Télétravail partiel possible,Évry,"Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux défis de notre époque, Carrefour a pour ambition de rendre le meilleur accessible à tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos équipes. Nous nous épanouissons en équipe : Métiers du commerce, métiers d'expertise, entrepreneurs unissent leurs compétences et leurs efforts pour construire ensemble une chaîne de valeur au service des consommateurs. Au plus près de nos clients ou en coulisses, chacun a un rôle à jouer mais peut compter sur les autres pour réussir. Nous veillons à ce que chacun puisse aller loin : L'envie et le mérite sont les seuls pré-requis pour nous rejoindre, accéder à une formation, changer de métier, être promu ou créer son entreprise. Nous partageons la victoire : nos collaborateurs sont engagés et nous nous engageons en retour. En offrant des rémunérations et des avantages parmi les meilleurs de notre secteur, en permettant à chacun d'être associé aux résultats, en veillant à la santé de tous. Carrefour capitalise sur la richesse de ses données pour développer de nouvelles solutions à destination de ses partenaires, incluant le partage d'insights à forte valeur ajoutée, le ciblage et l'activation marketing au travers de campagnes de dernière génération, la publicité digitale ciblée, etc. L'ensemble de ces solutions sont développées et déployées dans le cadre d'un programme de valorisation de la donnée appelé ""Carrefour Links"". Porteur de cette ambition, la Direction Links Operations, recrute un(e) : Data Engineering Manager F/H BON À SAVOIR : ASAP / CDI / CADRE / MASSY Missions Rattaché(e) au CTO Carrefour Links, vous êtes responsable des équipes d'ingénierie des produits Carrefour Links. Dans ce cadre, vous incarnez la stratégie technique et la déclinez au sein de vos équipes. Vous vous assurez du recrutement et de l'accompagnement des nouveaux profils, du suivi et du coaching des équipes en place, de la mise en place et de l'optimisation des bonnes pratiques ainsi que de la coordination avec les autres parties prenantes du périmètre. Responsabilités : ● Participe activement au processus de recrutement des nouveaux profils ● Suit les prestations de service sur le périmètre ● Met en place un parcours de ramp-up afin de garantir aux nouveaux arrivants une intégration optimale au sein des équipes ● Assure le développement des équipes grâce à une communication ouverte, un coaching continu et la mise en place de bonnes pratiques ● Identifie les problèmes existants et travaille avec les équipes pour les résoudre ● Collabore étroitement avec le CTO et est force de proposition sur l'évolution de la stack technique et le choix des outils ● Se synchronise avec l'ensemble des parties prenantes du programme Links (produits, business, plateforme, RUN, pôle agile…) ● S'assure auprès des équipes du delivery des produits avec le bon niveau de qualité Exemples de profils dans les équipes : Tech Lead, Data &amp; Analytics Engineers, QA Engineers, Développeurs Cloud Exemples de technologies utilisées sur le périmètre Carrefour Links : BigQuery, dbt, Looker, Data Studio, Cloud Functions, Cloud Workflows, Node.js, Vue.js, Python. Informations complémentaires En rejoignant Carrefour Links au sein du Groupe Carrefour, vous bénéficiez d'avantages sociaux élaborés pour vous fournir un cadre de travail des plus attractifs et flexibles : ● Le télétravail à votre rythme : jusqu'à 3 jours de télétravail par semaine et 2 jours de présence sur le site de Massy en flex office ● Une activité en plein scale-up avec des équipes qui s'agrandissent ; ● Des avantages sociaux et financiers attractifs : Primes, intéressement, Participation, Avantages collaborateurs sur achats Carrefour, Régime de retraite, Mutuelle avantageuse, Comité d'Entreprise généreux pour vos Loisirs, Voyages et Équipements, etc. ● L'accès à des services exclusifs à Massy : salle de sport, crèche, plusieurs options de restauration au sein du siège avec participation CE, infirmerie, téléconsultation médicale, conciergerie, coiffeur, etc. ● Carrefour s'engage pour la santé et le bien-être de ses collaborateurs en leur proposant une solution gratuite pour faire du sport : Gymlib ● Un accès à un large choix de restauration (dont Paul et Starbucks au sein du campus) ● Des opportunités de formation continue (l'Université Carrefour, la Digital Academy) ; ● La mobilité internationale : des plans de mobilité pour nos collaborateurs qui souhaitent rejoindre l'une de nos neuf filiales ; Chez Carrefour, nous avons à cœur de ne passer à côté d'aucun talent et sommes fiers de compter des équipes représentatives de la société dans son ensemble. Nous encourageons ainsi tous types de profils à postuler à cette offre et garantissons un processus de recrutement dénué de toutes formes de discriminations. Profil : ● Vous êtes diplômé(e) d'une école d'ingénieur ou équivalent Bac+5 minimum. ● Vous avez une expérience d'au moins 5 ans dans le développement logiciel (idéalement sur des produits Data) dont 2 sur un poste équivalent. ● Vous avez un anglais professionnel à l'oral comme à l'écrit. Compétences : ● Vous êtes passionné(e) par la Data et faisant preuve à la fois d'expertise technique et d'appétence fonctionnelle. ● Vous aimez construire et animer des équipes d'ingénierie logicielle. ● Vous avez une expérience avérée dans la mise en place de pipeline d'analytics de bout-en-bout dans un contexte industriel et sur des volumétries importantes. ● Vous avez de bonnes compétences dans l'architecture des systèmes, bases de données, méthodologies d'analyse. ● Vous appréciez le travail en équipe dans un contexte Agile (Scrum, SAFe) ● Vous faites preuve de leadership et êtes capable de fédérer les différentes parties prenantes autour de vos initiatives. ● Vous êtes curieux/se et menez régulièrement de la veille technologique autour des thématiques Cloud, Data, IA et Devops.","Carrefour is seeking a Data Engineering Manager to be responsible for the engineering teams of Carrefour Links products. The ideal candidate should have experience in software development, a passion for data, and hands-on expertise in analytics pipelines. The role involves coaching, hiring, and improving teams, proposing ideas on technical stacks, and coordinating with various stakeholders such as business, platform, and run. The candidate should also have good skills in system architecture, data analysis methodologies, and agile practices. Carrefour offers a flexible work environment with attractive social and financial benefits.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
196,56515,https://www.welcometothejungle.com/fr/companies/echosens/jobs/ingenieur-data-h-f_paris,Ingénieur Data,Echosens,"{Java,SQL,Python,Talend}",Télétravail partiel possible,"6, Rue Ferrus, Paris, 75014","Logiciels, SaaS / Cloud Services, Objets connectés, Intelligence artificielle / Machine Learning, Santé, Pharmaceutique / Biotechnologique",CDI,2023-03-26,"Echosens, entreprise française innovante de haute technologie créée en 2001, est le leader mondial des dispositifs médicaux non invasifs dans le domaine de l’hépatologie. Forte d’un rythme ambitieux de développement de ses produits, Echosens est également présente dans les activités d’E-santé (système de diagnostic avancé). Echosens poursuit sa stratégie d’expansion internationale au travers de ses filiales en Chine, aux Etats-Unis et en Europe (Allemagne, Espagne, Angleterre et Italie) et commercialise ses produits et ses services dans plus de 100 pays. Rejoindre Echosens , c’est faire le choix d’un parcours professionnel dynamique, enrichissant et valorisant. Dans le cadre de son fort développement, Echosens recrute en CDI un : Ingénieur Data (H/F) Poste basé Paris 14ième Intégré(e) au sein de la Direction des Systèmes d’Information (7 personnes) et rattaché(e) au Responsable Pôle Projets, vous concevez, mettez en œuvre, faites évoluer et opérer les flux d’échange de données entre les applications de l’entreprise tout en s’assurant de la cohérence des données de l’entreprise (gestion, stockage, sécurité). Votre rôle central vous amène à la conception des interfaces, la modélisation des données, leur mise en œuvre et la définition des attentes d’intégrité, de sécurité et de disponibilité des données au sein de l’entreprise. Vous serez également en charge de gérer le portefeuille d’interfaces (Webservices, ETL) et leur cycle de vie, ainsi que contribuer au design de ces interfaces en lien avec les applications métier de l’entreprise. Enfin, vous gérerez la surveillance des flux de données et serez garant de la résolution d’incidents qui pourraient en découler. Vous êtes garant de l’intégrité, de la sécurité et de la disponibilité des données d’Echosens et proposerez des améliorations de modèles de données, de flux et de technologies associées. Environnement technique du poste : · SQL , Java , Python. · ETL (Talend) · API Webservices Rest/Soap. Titulaire d’un diplôme Bac+3 en informatique (ou expérience équivalente), vous disposez d’une expérience réussie de 3 ans minimum dans l’intégration de flux de données d’ERP/CRM. Vous possédez de réelles qualités relationnelles. Rigoureu(x/se), organisé(e) et méthodique, vous savez analyser et synthétiser les situations. Votre curiosité technique vous permet d’appréhender de nouvelles technologies et d’être force de proposition. Enfin, votre esprit d’équipe sera un atout majeur pour mener à bien ce challenge ambitieux. 1 entretien RH par Teams 1 entretien en présentiel Manager/DSI 1 entretien avec un autre manager opérationnel","Echosens, a French innovative high-technology company that focuses on non-invasive medical devices in hepatology and e-health, is seeking a Data Engineer to design, implement, and operate data exchange flows between the company's applications while ensuring the integrity, security, and availability of data. The ideal candidate will have a minimum of three years of experience in integrating ERP/CRM data flows and possess excellent analytical, organizational, and technical skills with knowledge of SQL, Java, Python, ETL (Talend), and API Webservices Rest/Soap. The position is based in Paris, and the company offers a dynamic and rewarding professional career path.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
157,56648,https://www.welcometothejungle.com/fr/companies/raedy/jobs/data-engineer_neuilly-sur-seine,Data Engineer,Rædy,"{durable,Scala,Atscale,Presto,Hive,Spark,scale,moderne,Hadoop,Python,Tableau}",Télétravail partiel possible,"89, Boulevard Pereire, Paris, 75017","Digital Marketing / Data Marketing, IT / Digital, Audit",CDI,2023-03-26,"Rædy est une jeune entreprise innovante qui a pour ambition de redéfinir les codes du service numérique en créant « l’Artisanat au Service du Numérique ». A l’instar des artisans, Rædy tend vers l’Excellence du service afin d’accompagner ses clients sur l’ensemble du cycle de vie de leur Accélération Digitale : Acquisition et valorisation du savoir-faire Ajout constant de valeur Animation d’une communauté d’experts Développement de partenariats productifs Être Data Engineer chez Rædy, ça consiste à quoi ? Développer des solutions techniques de stockages Concevoir l’architecture technique nécessaire pour la valorisation des données Prioriser les besoins métiers Modéliser, développer et effectuer la maintenance du Datawarehouse Assurer la clarté et la sécurité des données Déceler les dysfonctionnements éventuels Consolider les données à des fins analytiques ou de Datascience Explorer et effecteur la fouille des données Réaliser des tests unitaires et d’intégration Suivre le RUN Participer à des POC Mettre à jour les technologies et langages utilisés Assurer le suivi de production et la maintenance Compétences requises Tu fais de la veille informatique et technologique pour compléter ton expertise L’esprit d’équipe est essentiel pour toi Tu maîtrises les langages Scala, Spark et Python Tu as des connaissances dans la gestion volume de donnée et d’applications Big Data sur Hadoop Tu as des connaissances sur les nouvelles techniques analytiques Big Data : Apache Kylin, Atscale, Hive, Presto DB Tu utilises les techniques de visualisation de données : Tableau Software Tu maîtrise la méthode agile Petit + : tu as des connaissances en modélisation datalake C’est pour toi si : Ce rôle est pour toi si tu aimes créer, concevoir et travailler en équipe ! Fort de ta curiosité data et tech, tu es capable d’intervenir en totale autonomie et d’être force de proposition sur des solutions respectant les contraintes internes. Tu es passionné.e, organisé.e et curieux.se avec un bon état d’esprit Tu as une formation d’ingénieur en informatique ou équivalent (Bac +5) Tu as minimum 3 à 5 ans d’expérience significative Tu maîtrises l’environnement data à la perfection 1/ Tout commencera avec un premier entretien avec nos Talents Acquisition Recruiters. Tu pourras parler de toi, tes expériences, tes attentes et nos équipes t’éclaiciront sur la mission. 2/ Un échange technique sera alors effectué pour analyser tes compétences. 3/ Si le feeling passe et que la mission te convient, un deuxième entretien sera organisé avec notre client. L’occasion d’échanger sur tes motivations et expertises métier. Vous allez pouvoir partager vos passions pour la data avant que l’aventure ne commence 🤞🏼 Pourquoi rejoindre Rædy ? ## Notre devise, « l’Artisanat au Service du Numérique » prend tout son sens quand il s’agit de recruter. Notre approche permet de répondre à vos attentes, vos ambitions d’évolution et de les faire correspondre aux exigences de nos clients. CDI ou freelance, pas de différence pour nous, votre bien être et votre épanouissement seront notre priorité. En nous rejoignant, vous travaillerez aux côtés des acteurs du SBF120, des ETI, des scale-up et des licornes. Les + : Salaire en fonction de ton expérience Télétravail autorisé Swile : titres-restaurant 12,50€ / jour (participation à 60€) et forfait mobilité durable (50€/ mois) Alan : la meilleure mutuelle et prévoyance prise en charge à 100% Beaucoup de travail et beaucoup de fun Afterworks et évènements réguliers Si tu as lu jusqu’ici, n’hésite plus ! Rejoins une entreprise moderne, disruptive et en plein développement. On attend ton CV 🤗","Rædy is looking for a data engineer to develop technical storage solutions and design the necessary architecture for data optimization. The ideal candidate should have expertise in Scala, Spark, and Python, as well as knowledge of Hadoop and Big Data analytical techniques such as Apache Kylin and Presto DB. The role requires strong teamwork skills and the ability to work autonomously. The company offers a flexible work environment and opportunities for career development.",Bac +5 / Master,Entre 15 et 50 salariés,> 4 ans,2,1,0.04154662416233763
178,34327,https://www.welcometothejungle.com/fr/companies/disneyland-paris/jobs/data-engineer-f-h-cdi_chessy,Data Engineer  - CDI,Disneyland® Paris,"{GCP,Redshift,Kubernetes,Glue,AWS,S3,Snowflake,Docker,SageMaker,Spark,Git,Sagemaker,SQL,Python,EC2,Tableau}",Télétravail partiel possible,Chessy,"Cinéma, Tourisme, Loisirs",CDI,2022-08-08,"Pour faire vivre la magie, Disneyland® Paris peut compter sur l’engagement et l’expertise de multiples talents nommés Cast Members, qui font vivre le parc Disneyland®, le parc Walt Disney Studios®, le centre de divertissements Disney Village® ainsi que nos hôtels à thème. Disneyland® Paris est une société où les rêves deviennent vraiment réalité. Nos Cast Members travaillent dans des centaines de professions liées aux opérations et au soutien, sur scène ou en coulisses. Leur mission : offrir à chaque client une expérience Disney inoubliable. La passion et l’enthousiasme de nos équipes ont fait de notre société la destination touristique numéro un en Europe ! Faire rêver implique de grandes responsabilités. Pour notre destination, la performance sur le long terme doit s’appuyer sur un modèle de tourisme responsable. Nous avons pris des engagements socio-environnementaux très importants, que nous nous attachons à concrétiser avec l’implication constante de nos collaborateurs et parties prenantes. Disneyland Paris est une filiale de la Walt Disney Company, leader international du secteur du divertissement et des médias. Voici votre chance de vivre une aventure professionnelle unique ! Votre environnement ? Disneyland Paris vit actuellement une transformation data en se dotant d’une équipe centralisée (Data Office) et d’une data platform sur AWS pour exploiter ses données riches et variées : digital, billetterie, hébergement, opérations, maintenance, finance, boutiques, restaurants, supply chain, costumes, flux, ressources humaines… Le Disneyland Paris Data Office est au cœur de ce projet de transformation et pilote : La maintenance et l’évolution de notre data platform, la centralisation de la donnée au sein d’un datalake, la production de la valeur à partir de nos données ; La promotion de l’utilisation de la data et l’accélération du self-BI pour réduire les temps d’analyse et de prise de décision ; L’animation des communautés d’utilisateurs ; La définition et le développement des produits data-driven basés sur l’intelligence artificielle. Nous mettons ainsi la data au cœur des décisions stratégiques et facilitons l’accès à la data pour tous. Nous encourageons nos équipes à réaliser le potentiel qu’apporte la data, à se rendre compte de sa puissance et les aidons à innover. Dans ce contexte, nous recrutons un(e) Data Engineer qui interviendra dans le déploiement de cas d’usage data au service des métiers, par les méthodes de collecte de la donnée jusqu’à son exposition et en contribuant à la mise en place de pipeline de machine learning. Vous rejoindrez l’équipe Data composée d’une trentaine de personnes et reporterez au Senior Manager Decisions. Vous contribuerez aux avancées de nos squad, en collaboration avec les autres membres de l’équipe data (Product Owner, Data Engineer, BI Developer, Data Steward, Tester), dans un environnement stimulant, où l’esprit d’équipe et la volonté continue d’amélioration & d’apprentissage sont clé ! Chacun des membres de l’équipe a l’opportunité d’être acteur de ce que nous mettons en place. Vous aurez ainsi la possibilité d’apporter vos connaissances, remettre en question l’existant, innover, mettre en place de nouvelles choses constamment et rapidement ! Vos missions ? Vous participerez activement à la construction de notre data platform et aux choix des outils , aiderez à la prise de décision et à développer la croissance de Disneyland Paris. Vos missions consistent, en particulier, à : Etudier et mettre en place les meilleures solutions techniques pour gérer de grands volumes de données, de la collecte de données d’entrainement jusqu’au déploiement en production ; Maitriser la qualité du code mis en production pour assurer le run (Git, évaluation de performance de modèle) ; Travailler en collaboration avec le Data Engineer, le Data Scientist et le Product Owner pour intégrer des modèles machine learning en tant que livrables dans un produit ; Développer et maintenir notre stack data à l’état de l’art ; Contribuer par de nouveaux data pipelines : Collecter sur notre datalake (S3), développer et maintenir les flux d’entrée et de sortie de la DP, sur des données internes et externes, en batch et realtime, jusqu’à l’activation des données (Snowflake / Redshift / Tableau, APIs…) Transformer la donnée collectée, enrichir et maintenir notre data warehouse (Snowflake) Assurer l’intégrité du cycle de vie de la donnée Dessiner, mettre en place et maintenir tout le pipeline de production pour déployer des modèles de machine learning avec les Data Scientists Proposer, mettre en place et accompagner les best practices au sein de l’organisation data (agile, code review, …) ; Pratiquer de la veille technologique sur le cloud et le data engineering. Vous aurez l’opportunité de travailler sur des technologies variées. Notre environnement technique actuel, en cours de construction donc non exhaustif, se base sur AWS Glue / S3 / EC2 / Sagemaker, Snowflake, Python, Spark, SQL, Git . Nous rejoindre, c’est la garantie de participer à la naissance du projet data platform et d’avoir de l’impact dans sa structuration et ses choix technologiques ! Vous aurez l’opportunité de travailler sur des sujets très diversifiés , avec le support des équipes Data Science & Engineering de The Walt Disney Company aux États-Unis. La différence Disneyland Paris ? Un environnement exceptionnel, international et multiculturel, concentré sur un site unique ; Un environnement où les valeurs d’inclusion et de diversité sont clé, dans lequel tous les collaborateurs sont encouragés à être authentiques ; Une session d’intégration complète et un large éventail d’options de formation pour le développement des compétences ; De nombreuses possibilités de carrière (promotion interne ou mobilité horizontale). Prêt(e) à participer à une formidable aventure humaine ? A rejoindre nos collaborateurs (Cast Members) partageant la même ambition professionnelle : celle de faire vivre la magie Disneyland Paris pour les millions de visiteurs qui viennent dans nos parcs tous les ans ? Il ne vous reste plus qu’à postuler car nous sommes prêts à vous donner les moyens de faire rayonner vos talents ! Disneyland Paris est soucieux d’offrir à ses Cast Members les conditions de travail les plus favorables à leur épanouissement professionnel. Dans ce cadre et pour garantir une flexibilité optimale, les emplois qui ne nécessitent pas une intervention ou l’accès à des installations ou applications sur site et/ou des interactions physiques peuvent s’exercer en télétravail, avec un minimum de présence requis de cinq jours par mois sur site. Nos bureaux sont situés à 5 minutes à pieds de la gare de Val d’Europe. Vous êtes le/la candidat(e) idéal(e) pour ce poste si : Vous êtes issu(e) d’une formation supérieure type école d’ingénieur ou master spécialisé en data engineering/big data/cloud engineering/data science et avez acquis une expérience de 5 ans minimum dans des projets data , au sein d’un environnement international et agile ; Vous connaissez au moins un environnement cloud (AWS ou GCP) et avez déjà déployé du code sur ce dernier ; Vous avez déjà participé à un projet de datawarehouse ; Vous maîtrisez un langage de programmation ( Python et SQL en priorité) ou de configuration YAML, connaissez les concepts DevOps (Docker, Kubernetes) et les services managés (AWS) ; Vous avez une expérience dans l’industrialisation de modèles de machine learning (AWS SageMaker) ; Vous savez vous exprimer en anglais couramment (niveau C1) pour une utilisation quotidienne à l’écrit comme à l’oral, ainsi qu’en français (niveau B2). Vous réussirez dans ce rôle si : Vous faites preuve de curiosité et êtes capable de proposer, tester de nouvelles choses, remettre en question l’existant et faire des recommandations ; Votre leadership vous permet d’être à l’aise pour porter un sujet, le défendre, le vendre auprès de vos interlocuteurs techniques comme fonctionnels ; vous savez vulgariser les sujets techniques pour convaincre ; Vous appréciez collaborer avec des interlocuteurs pluridisciplinaires, travailler en équipe et partager votre savoir ; Vous êtes particulièrement sensible à la qualité des déploiements et mettez tout en œuvre pour délivrer un produit de qualité. C’est le bon moment pour avoir un fort impact sur nos activités et contribuer à la montée en puissance de la culture data au sein d’un environnement incroyablement spécial ! Premier échange avec notre recruteur pour faire connaissance et voir si nous pouvons aller plus loin ensemble Entretien avec notre recruteur et évaluer l’adéquation entre votre personnalité, vos attentes et ce que nous pouvons vous offrir Entretien avec notre data engineer pour vous donner une vision élargie du poste et évaluer vos capacités techniques Entretien avec nos product owners pour vous donner une vision fonctionnelle et évaluer vos capacités fonctionnelles Entretien final avec vos futurs manager et N+2 pour vous envisager au sein de notre environnement. Bien sûr, l’ensemble de ces échanges peut se faire à distance, dans un délai que nous nous efforçons de raccourcir un maximum. Les candidatures sont étudiées au fur et à mesure de leur arrivée ; ne passez pas à côté, postulez dès maintenant !","Disneyland Paris is looking for a Data Engineer to join their Data Office team, participating in the development of their data platform by deploying data use cases for the business. The successful candidate will work alongside Data Scientists and Product Owners to integrate machine learning models and ensure optimal data engineering practices. The role requires a minimum of 5 years of experience in data engineering, with a deep knowledge of at least one cloud environment such as AWS or GCP, and proficiency in Python and SQL. Strong communication skills in English and French are also necessary. Disneyland Paris offers a unique and international environment, with training options and career development opportunities.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
182,36576,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-tableau-dataviz-bi-factory-f-m-d_nantes,BI Engineer Tableau / DataViz - BI Factory,Decathlon Technology,"{AWS,dataset,github,GCP,SQL,Tableau}",Télétravail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-10-12,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour répondre aux mieux a son ambition de pilotage par la data, Decathlon a organisé une DATA UNIT à laquelle la BI Factory est rattachée. TA RESPONSABILITE : Ta mission principale consiste à : Répondre à des demandes d’analyses récurrentes de KPIs en mettant à disposition des métiers, de manière automatique et régulière, des outils de data visualisation performants. Intervenir dès la finalisation du cadrage projet par le Project Manager jusqu’à la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : Project Manager, les autres BI Engineers, les métiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e BI Engineer, basé-e, au choix à Paris, Lille, Lyon ou Nantes. Le périmètre technique : maîtrise du SQL maîtrise d’une BDD maîtrise d’un ETL maîtrise d’un outil de datavisualisation (idéalement Tableau software) Rédaction de documentation dans github et/ou wiki Méthodologie AGILE CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience d’au moins 3 ans en développement BI et parle un Anglais courant (relation avec des équipes à l'international). Tu as déjà produit de la data visualisation performant avec Tableau Software ; Pour réussir, tu dois savoir: Comprendre le besoin métier / interagir avec les interlocuteurs fonctionnels Comprendre un modèle de données et t'en servir. Modéliser un dataset afin de développer des visualisations en assurant les performances techniques Développer le flux d’extraction des data nécessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages métiers exprimés lors du cadrage Maîtriser les technologies utilisées et les bonnes pratiques de développement Partager ton avancement et les difficultés rencontrées lors des instances AGILE dédiées. Rédiger la documentation technique permettant d’assurer un run efficace Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et la vie en équipes ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a BI Engineer with three years of experience in BI development, data visualization, and expertise in SQL, ETL, and data visualization tools such as Tableau. The selected candidate will be responsible for developing data extraction flow, modeling datasets, and providing technical expertise on visualizing KPIs. Additionally, the candidate will coordinate with the data team, project managers, and other BI Engineers, and contribute to agile instances to ensure efficient deliveries. Decathlon Technology offers opportunities for mentoring, diverse projects, and certifications, with the possibility of teleworking two days a week and working from any Decathlon office in Lille, Paris, Nantes, or Lyon.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
192,50457,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",Télétravail partiel possible,"Tour EDF La Défense, Colombes, 92400","Environnement / Développement durable, Energie",CDI,2023-02-07,"Chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez EDF même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Au sein de la DSIN, le Centre de Solutions et de Compétences DataScience & IA (CSC DS & IA), a pour mission de réaliser les travaux d'analyse et de valorisation des données de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux métiers du Marché d'Affaires et du Marché des Clients Particuliers pour répondre à des enjeux variés comme les départs à la concurrence, la conquête de nouveaux clients, la satisfaction client, la détection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de données conséquentes (~26 millions de clients, B2C+B2B). Afin de répondre à ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une équipe de Data Engineer, et en appui d'une équipe de plus de 20 Data Scientists, votre mission consistera à : - Mettre en place des pipelines de traitements de données - avec des volumes importants de données (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de données distribuées (Spark …) - Extraire massivement des données (Hadoop - Hive, Oracle - SQL, …) - vous-même ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de données (compréhension des problématiques Yarn, JVM, tablespace temp…) - Accompagner les Data Scientists dans le maintien et l'évolution des outils de requêtage développés en interne (dnquery pour requeter Oracle et Hive), extension à une nouvelle technologie de stockage des données (PostGre, SQL Server…) - Accompagner les déploiements de modèles de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des chaînes récurrentes de type traitement de la donnée ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer à la construction des stratégies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer à l'évolution de l'environnement technique des Data Scientists Votre Profil ? - Vous êtes titulaire d'un Bac +5 (Master, diplôme d'ingénieur) dans le domaine informatique, des mathématiques / statistiques, de la Data Science ou du Big Data - Vous bénéficiez d'une expérience d'au moins 3 ans en tant que Data Engineer - Vous avez déjà travaillé dans un contexte de Datascience et automatisé des traitements de type Datascience - Vous maîtrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez déjà manipulé des données stockées sous S3 - Vous êtes à l'aise avec les outils collaboratifs de développement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous bénéficiez d'une ou plusieurs expériences de travail en mode Agile - Vous êtes curieux et les projets innovants vous passionnent - Vous êtes force de proposition et proactif - Vous aimez transmettre et travailler en équipe Méthodologie de travail : Vous collaborerez étroitement avec les Référents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'équipe en charge des lacs de données au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark…). Le poste est situé à Colombes, proche de La Défense Ouest, avec une possibilité de télétravail partiel. Rémunération : Fourchette estimative : entre 50k et 57k€, la rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is seeking a Data Engineer to join its Center of Solutions and Competences Data Science & AI (CSC DS & IA) team. The role involves setting up data processing pipelines, helping data scientists in debugging and data extraction, deploying machine learning models, and contributing to the evolution of the technical environment for data scientists. Candidates must have at least three years of experience as a data engineer and hold a Master's degree, engineering diploma or equivalent in computer science, mathematics/statistics, data science or big data. Proficiency in Python, SQL, Docker, and Airflow, and experience with Hadoop and S3 storage systems are must-haves. The position is located in Colombes, France, near La Défense Ouest, with the possibility of partial teleworking. The salary ranges from €50k to €57k and is commensurate with experience and market trends.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
184,36687,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/engineering-manager_paris,Engineering Manager Data,Contentsquare,"{go,regard,ContentSquare,color,Aerospike,Akka,Contentsquare,Kafka,scale,Spark,ClickHouse}",Télétravail partiel possible,N,SaaS / Cloud Services,CDI,2022-10-12,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We’ve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, we raised $600M in Series F funding, doubling our valuation to $5.6B. But we’re not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! As an Engineering Manager, you will join and lead a team of passionate and talented Data Engineers. Do not hesitate to check on our YouTube video to see what it's like to be a Data Engineer at ContentSquare! We collect several billions of events per day and query hundreds of terabytes in real-time. The role of the Data Team is to: • Design robust and efficient architectures to store and analyze petabytes of data • Select, along with the product team, valuable functionalities for Contentsquare users • Develop, test, and deploy corresponding features to best serve the functionalities • Constantly maintain and improve the underlying infrastructure and services leveraging state of the art technologies such as Kafka, Spark, Akka, ClickHouse, Aerospike… • Integrate the best technologies and innovate to optimize accuracy, speed, and cost • Contribute to advance and share tech knowledge by contributing to open source projects, publishing articles, and participating in events As an Engineering Manager, you will be one of the leaders of the Data Team, with a responsibility to: • Collaborate with Product to determine the tech roadmap and priorities for your team • Ensure your team makes the right technical choices • Lead the timely and efficient delivery of multiple large scale projects by your team • Identify & address risks, determine the team staffing needs • Manage your team (rituals, career path, recruitment) and mentor Senior team members • Interact with other stakeholders (other Data Engineering Teams, Data Science, QA, Front End, & Platform Teams, Product, Program Management, HR…) to collectively succeed Why join ContentSquare’s Data Engineering team? •You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data •You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences •You are looking for an environment where you’ll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategic corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross-team innovation days, we are committed to innovating towards tomorrow’s user experience. You’ll also have flexible working hours, remote days; soccer, handball, yoga, and many other activities; after-work beers provided every Friday, monthly parties…and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare - We’re humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we’d like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company’s success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is looking for an Engineering Manager to lead and collaborate with their passionate and talented Data Engineers team. The ideal candidate is responsible for leading the team in delivering multiple large-scale projects, identifying risks, determining team staffing needs and making the right technical choices. Contentsquare aims to double its global workforce in the next two years and values innovation, diversity, and flexibility. They offer a generous paid time-off policy, home office allowance, and wellbeing allowance, among other benefits. They are looking for individuals who are committed to innovating the user experience and want to join their awesome adventure.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,2,1,0.04154662416233763
185,65908,https://www.welcometothejungle.com/fr/companies/3dsoutscale/jobs/data-engineer-f-h_saint-cloud,Data Engineer,3DS OUTSCALE,"{scala,matplotlib,pandas,tableau,R,Spark,kafka,bokeh,Python,numpy}",Télétravail partiel possible,"1 rue royale , Saint-Cloud, 92210 ","SaaS / Cloud Services, Big Data",CDI,2023-04-05,"L’histoire de 3DS OUTSCALE a débuté en 2010 avec un objectif : assurer la souveraineté des données et garantir leur sécurité au quotidien. Filiale et partenaire stratégique de Dassault Systèmes, 3DS OUTSCALE s’est imposé comme le Cloud d’hyper-confiance auprès des OIV, du secteur public et des éditeurs de logiciel en proposant des services Cloud d’Infrastructure hautement qualifiés : ISO 27001, HDS, SecNumCloud, RSE Lucie 26000… Pour assurer la qualité de nos services et en maîtriser le cœur technologique, nous avons développé notre propre orchestrateur de IaaS : TINA OS, qui évolue continuellement par l’innovation de notre département R&D. Vous rejoindrez une entreprise humaine, composée d’Outscaliennes et d’Outscaliens passionné.es par la technologie, motivé.es d’apprendre en continu dans une ambiance agréable. Nous sommes fier.ères de voir grandir nos équipes dans un contexte de perpétuelle croissance. Nous recherchons des talents aux valeurs fortes, passionné.es par les challenges que représentent le Cloud ! Nos valeurs : L’Excellence L’Expertise L’Humain Étant une entreprise en perpétuelle croissance, et toujours à la recherche de nouveaux talents, nous recrutons un·e Data Engineer afin de renforcer notre SU Billing . Vos missions Rattaché·e au sein de la Service Unit Billing, le collaborateur·trice contribuera aux projets relatifs aux traitements des données de facturation des ressources du Cloud. Les applications de facturation génèrent les différents rapports de consommation (à la demande et réguliers), les tableaux de bord et les factures destinés aux clients externes et internes (autres SU). Vos missions seront les suivantes : La préparation, l’implémentation et le contrôle des données nécessaires dans les différents projets La définition et la conception des indicateurs de performance La préparation de rapports et des autres livrables L’automatisation et pérennisation des tableau de bords La diffusion de la culture de la data auprès des équipes métiers La veille technologique Stack technique Données machines de test et de production : consommation, événements, etc. Time series analysis, donnés catégoriques, Machine learning (clustering, classification, etc.) Python (numpy, pandas, scikits, matplotlib, bokeh) et/or scala Spark (rdd, stream, ml), kafka Titulaire d’un BAC+5 d’une grande école ou d’un master avec une spécialisation en traitement de données, vous êtes rigoureux, organisé(e) et méthodique. Vous possédez un fort intérêt pour le monde de l’IT Vous appréciez le travail en équipe Vous êtes force de proposition, persévérant·e et proactif·ve Vous parlez anglais couramment La Diversité de 3DS OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.","3DS OUTSCALE, a cloud infrastructure provider, is seeking a Data Engineer to join its Service Unit Billing team. The candidate will be responsible for contributing to billing data processing and generating consumption reports, dashboards, and invoices. The ideal candidate should possess a Bachelor's or Master's degree with a specialization in data processing and have expertise in time series analysis, categorical data, machine learning, Python, Scala, Spark, Kafka, and English proficiency. The company values excellence, expertise, and a human touch while encouraging diversity and equal opportunities.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,2,1,0.04154662416233763
210,65913,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/data-engineer-f-h_la-defense_INGNI_g5AxQwL,Data Engineer -,Ingéniance,"{GCP,Redis,Scala,Kubernetes,AWS,Storm,Cassandra,Hadoop,Azure,Java,NoSQL,SQL,Python,Cloudera,docker}",Télétravail partiel possible,La Defense,IT / Digital,CDI,2023-04-05,"Ingéniance, est une société de conseil spécialisée dans des projets liés aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajoutée en associant innovation technologique, transformation digitale, expertise métier (Banque, Finance et Assurance) & méthodes agiles. Technology-oriented, elle offre une réelle expertise à ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l’Agilité. Son projet d’entreprise s’appuie aussi sur des valeurs humaines, sociétales et environnementales (Label EcoVadis Gold). La proximité, la performance, la convivialité et le progrès sont des atouts sur lesquels elle bâtit sonévolution collective au quotidien. Quelles seront vos missions ? Vos missions s'inscrivent dans un contexte de travail Agile, au sein du centre d'expertise Data en charge du développement et de la gestion des systèmes de collecte, normalisation croisement et restitution des données. Dans ce cadre, vous contribuerez à : Développer de nouveaux pipelines de données (ingestion, traitement, stockage) Développer des moyens de restitution de la donnée (APIs, génération fichier, autres...) Industrialiser et automatiser les tests des APIs (Swagger, Postman, ...) Développer des moyens de parallèlisation des processus (Apache Storm, Multithreading, ...) Définir les bonnes pratiques de développements sur le cloud (AWS, Azure, GCP, ...) Rédiger la documentation nécessaire au partage et à la maintenance du code Faire partie d'une équipe agile et suivre la méthodologie Scrum Qui êtes-vous ? Entre 5 et 10 ans d'expérience en développement dont au moins 3 sur un programme DATA Vous maîtriser un langage de programmation (Java, C#, Scala, Python) Vous êtes à l'aise avec les architectures distribuées ou sur le cloud et leur mise en place. Vous avez de solides connaissances en SQL ainsi que sur des bases de données NoSQL (Mango, Redis, Cassandra) Vous avez déjà travaillé avec des outils de conteneurisation comme docker et d'orchestration tel que Kubernetes Enfin vous avez déjà implémenté des solutions dans le cloud (AWS, Azure, GCP...) Les compétences que vous renforcerez : Vous interviendrez sur la conception et le déploiement d'environnements « clusturisés » de type Datalake (Hadoop/Cloud & distributions Hortonworks, Cloudera) Vous pourrez vous confronter et contribuer à une communauté d'experts Vous accompagnerez les équipes de Datascientist, d'experts du Machine Learning et des approches statistiques, sur des projets de mise en oeuvre de ces approche s et du traitement des données associées. Vous évoluerez dans un environnement fonctionnel riche","Ingéniance, a technology-oriented consulting company specializing in finance, seeks a Senior Data Engineer with at least five years of development experience, three of which are in a data program. The candidate should be skilled in programming languages such as Java, C#, Scala, or Python, as well as having experience in distributed or cloud architectures, SQL, and NoSQL databases. The candidate should also have experience with tools such as Docker and Kubernetes, and implementing solutions in AWS, Azure, or GCP. The candidate will work in an Agile environment and follow Scrum methodology, contributing to the development and management of data collection, normalization, cross-referencing, and restitution systems.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,2,1,0.04154662416233763
166,64475,https://www.welcometothejungle.com/fr/companies/mckinsey-digital/jobs/data-engineer,Data Engineer,McKinsey Digital,"{intrinsic,iterative,Scala,modular,scale,R,Python}",Télétravail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Stratégie, SaaS / Cloud Services, Big Data",CDI,2023-04-03,"McKinsey Digital accompagne les organisations dans l’exploitation de la puissance de la technologie et de la donnée pour concevoir de nouvelles expériences, optimiser leurs opérations et créer de nouveaux business. Pour cela, le pôle met à leur disposition le meilleur de ses compétences (combinaison de talents tech et de talents métiers), ses approches innovantes (telles que Leap by McKinsey, activité de création de nouveaux business numériques), un large écosystème de partenaires, ainsi que de nombreuses solutions propriétaires utilisées au quotidien. Le Digital est en très forte croissance et concerne déjà la moitié des projets réalisés par McKinsey & Company. McKinsey Digital s’appuie sur l’expertise et la richesse exceptionnelle des 6 000 talents qui constituent le pôle à l’échelle mondiale, parmi lesquels des data scientists, designers, ingénieurs, architectes IT, développeurs, responsables technologiques, coaches agiles, designers reconnus et experts en cybersécurité. McKinsey Digital France compte une centaine de personnes. McKinsey Digital met au service de ses clients le meilleur de ses expertises digitales à travers le monde, dans plus de 60 pays, de manière transparente et flexible. WHO YOU’LL WORK WITH Based in Paris and working across the region, as a consultant data engineer you will work closely with our clients, data scientists and all types of McKinsey consultants to curate problem specific datasets that feed directly into our machine learning and modelling approach. This hybrid client-facing/technical role will allow you to use state of the art technologies to solve highly impactful business problems, whilst also leveraging your strong communication skills to convey complex intractable ideas to non-technical audiences. Who you are This position is for a data engineer (all seniority levels) with strong intrinsic technical ability and an aptitude to solving complex problems using technology. A core value at QuantumBlack is fusion and at the heart of our multi-disciplinary teams is the belief that the sum of individual parts will always be less than the impact of the entire team. You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly. Trust between colleagues is paramount here – you are an individual who can always be trusted to work in the best interests of all colleagues and to achieve the best outcome for QuantumBlack and our clients. You are naturally enthusiastic and enjoy sharing your passion with others. WHAT YOU’LL DO As a Data Engineer with the Paris office… You will work in multi-disciplinary environments harnessing data to provide real-world impact for organizations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance. See our video: A Day in the Life of a Data Engineer Role responsibilities Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches Acquire, ingest, and process data from multiple sources and systems into Big Data platforms Understanding, assessing and mapping the data landscape. Maintaining our Information Security standards on the engagement. Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models. Defining the technology stack to be provisioned by our infrastructure team. Building modular pipeline to construct features and modelling tables. Use new and creative techniques to deliver impact for our clients as well as internal R&D projects. What you’ll learn _No project is ever the same – we work across multiple sectors, providing unique learning and development opportunities across the region._ How successful projects on real world problems across a variety of industries are completed through referencing past deliveries of end to end pipelines. Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations. Be focused on the wrangling, clean-up and transformation of data by working alongside the Data Science team which focuses on modelling the data. Using new technologies and problem-solving skills in a multicultural and creative environment. You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport. Master’s degree in quantitative field like computer science, engineering, statistics, mathematics or related field required; advanced degree advantageous Experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data Ability to write clean, maintainable, and robust code in Python, Scala, or similar languages Familiarity with the latest OSS, cloud, container, query languages and database technologies Ability to work collaboratively in a team environment Commercial client-facing or senior stakeholder management experience a plus Fluency in both English and French Willingness to travel up to 60% Interviewing is a two-way process—it gives us the opportunity to learn about you as a potential colleague, and allows you to learn about McKinsey and what you could do here. Overall, we look for personal impact, entrepreneurial drive, inclusive leadership and problem solving, as well as your technical skills. As a Data Engineer, the process will assess your technical skills during Pair programming and technical interviews as well as your business sense.","McKinsey Digital, which helps organizations optimize operations, create new business opportunities, and design new customer experiences, is seeking a consultant data engineer in Paris. The successful candidate will work with clients and data scientists to create problem-specific datasets for use in machine learning and modeling projects. The role is client-facing and requires strong communication skills, alongside demonstrable technical competence in building data pipelines in production. Fluency in French and English, as well as availability for up to 60% travel, is also required.",Non spécifié,> 2000 salariés,Non spécifié,2,1,0.04154662416233763
190,39763,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-data-scientist-h-f-cdi-paris_puteaux,Data Engineer/ Data scientist  - CDI - Paris,AXA,"{Microsoft,GCP,AZURE,Databricks,Git,Scala,AWS,R,Spark,Azure,SQL,Python}",Télétravail partiel possible,"VILLE DE PUTEAUX, Puteaux, 92400","Banque, Assurance, FinTech / InsurTech",CDI,2022-11-29,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l’assurance et de la gestion d’actifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous protéger en donnant à chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! 1. AXA GROUP The AXA Group, world leader in Financial Protection, supports and advises its individual and corporate customers at every life stage, providing them with the products and services that meet their insurance, personal protection, savings and wealth management needs. Our areas of expertise are reflected in a range of products and services adapted to the needs of each client in three major business lines: property-casualty insurance, life & savings, and asset management. In 2022, present in 64 countries, the 153,000 employees and distributors of AXA were committed to serving 105 million clients. AXA Corporate Center’s main missions are to: Steer the entities in order to ensure the coherence of the strategies, the consistency of the commercial approaches as well as the optimization of the risks and results; Defining and coordinating Group policies, different transversal projects and standards, identifying and sharing best practices; Supporting the entities in order to help them to grow, to develop their offer, their management and steering standards as well as their risk management. The head office of AXA Group (GIE AXA), based in La Défense, gathers the Group's corporate activities. It coordinates the various entities according to the Group's strategy and is responsible for managing international projects. The headquarters is composed with over 1000 employees and is distinguished by its strong international culture (45 nationalities). 2. PRESENTATION OF THE DIRECTION Group Performance Management (GPM) is responsible for performance monitoring within the Group. Its objective is to coordinate a regular dialogue with the entities in order to deliver to the Group Management Committee of AXA information on the financial, operational and strategic performance of the entities and to be the Gatekeeper for Group requests vis a vis the entities. Information Management team is part of Group Performance Management Department within Group Finance. Led by the Corporate Center Chief Data Officer, Information Management team setup and deploy the Data strategy though (i) Data Governance and Data Quality Programs, (ii) efficient Data Architecture design, (iii) Data Operation services and (iv) Data Culture fostering. 3. PRIMARY MISSION: Within the Information Management team, you will be responsible for (i) organizing, optimizing, and operating the collection of transversal data, either external or internal (ii) optimizing their distribution, (iii) ensuring their quality and (iv) controlling the entire data lifecycle, from collection to operational use. You will work hand in hand with Business Data Analysts and Data Transformation teams prioritizing and implementing use cases to create value for the overall organization. 4. KEY ACCOUNTABILITIES: We are looking for a Data Engineer to take part in the scaling of our data platform and support the team’s and company’s growth. Within the Data Operation services team, you will work with the following objectives: Design, implement, and maintain our Data Lake that collects, stores, and processes external and internal data, focusing on scalability and reliability Designing, developing, and maintaining pipeline to integrate data Controlling and managing their entire lifecycle, from collection to operational use considering Group Security and GDPR policies Ensuring the scalability, security, and availability of platform data Carrying out a technological watch to be at the forefront of cloud & Data solutions Distribute data to final users ensuring expected data quality Modelling and analyzing data Industrialising and automating data cleansing aligned with final users’ specifications Managing, maintaining, and documenting the several data bases Create and automatise dashboards for final users Design and build machine-learning algorithms and tooling to explore and visualize data. Proposing technical solutions answering business needs and simplifying process through automation Designing, developing, testing, and industrializing “Big Data” processing in different business and application contexts in collaboration with data architects and devOps Developing automation, integration, and continuous deployment tools Ensuring the proper application of the Group's security and confidentiality rules within data processing Work hand in hand with Data Transformation team to create value for AXA accompanying Corporate Center’s departments and entities in their project, or new needs: Contributing to implement, new use cases of Business Intelligence, or Data Visualization Contributing to business specifications, build and tests phases, as well as data migration. Supporting clients in training sessions to end users. Participate in maintaining consistency and good practices with other data engineers Contribute to the Group's technical expertise communities Embody and relay product and data-driven methodologies </li></ul></li></ul> 5. TECHNICAL AND PROFESSIONAL SKILLS: Fluency in English is mandatory Programming Languages: Spark, Scala, Python, R, SQL Cloud Platforms: Microsoft Azure, or AWS, or GCP Tools: Azure Data Factory (ADF), Databricks, Azure DevOps, Git, JIRA, etc. Microsoft AZURE Data engineer certification (DP 203) is a plus 6. SOFT SKILLS AND COMPETENCIES: Team player who can break the silos with tact and diplomacy Leadership, influence, and conflict resolution Able to adapt to changing requirements, to deal with competing priorities and pressure Proactive, able to change things and to lead projects while being customer centric Comfortable working in a complex and multidisciplinary international environment 7. BACKGROUND & EXPERIENCE: Graduate degree in information systems, informatics, statistics, computer science or another quantitative field 3-5 years’ experience working as a developer/Engineer with ideally operational experience in Data platforms among which Master Data Management, BI & Analytics (data warehousing, big data, data science), integration services, Data storage solutions Experience within insurance, bank, or investment management sectors is a plus Project Management experience is a plus </li></ul>","AXA, a world leader in financial protection and management, is seeking a Data Engineer to join their Information Management team. The successful candidate will be responsible for organizing, optimizing, and operating the collection of transversal data, designing and implementing data pipelines, ensuring data quality, and managing data lifecycles, as well as contributing to the development and implementation of new use cases for business intelligence and data visualization. Proficiency in programming languages such as Spark, Scala, Python, R, and SQL, as well as cloud platforms such as Microsoft Azure, AWS, or GCP, is required. The ideal candidate should also possess strong soft skills such as the ability to work in a complex and multidisciplinary international environment, adaptability, and customer-centricity. A graduate degree in a quantitative field and 3-5 years of experience in Data platforms, BI & Analytics, and integration services are preferred. A Microsoft AZURE Data Engineer certification (DP 203) is also a plus.",Non spécifié,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
160,59920,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad_barcelone,Data Engineering Manager - Customer squad,Back Market,"{color,dynamodb,Scala,Lambda,AWS,via,Spark,GCP,Datadog,Python}",Télétravail partiel possible,"Barcelone, 08007","Environnement / Développement durable, Économie collaborative, E-commerce",CDI,2023-03-28,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world’s leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of 963,226 tons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: “be a coach not a dictator” is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc… - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We’re here to SABOTAGE: It’s our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team.","BackMarket seeks an Engineering Manager with expertise in building reliable, high-performing, and secure data infrastructures and tools to manage its Customer data team. The candidate must align the tech vision with the objectives of the company, build and execute a growth plan, identify and improve the processes, practices, and products of the company. The ideal candidate must have great communication skills in English, be knowledgeable in Lambda, dynamaodb, Big Query, and possess leadership qualities. Additionally, the role comes with great benefits such as flexible hours, equity, health insurance, parental benefits, and other personal and career development schemes.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
218,65922,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/big-data-engineer-f-h_la-defense_INGNI_VGLdzo9,BIG DATA ENGINEER-,Ingéniance,"{Jenkins,Git,HDFS,Linux,Hive,Spark,Docker,Java,Hadoop,Python}",Télétravail partiel possible,La Défense,IT / Digital,CDI,2023-04-05,"Ingéniance, est une société de conseil spécialisée dans des projets liés aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajoutée en associant innovation technologique, transformation digitale, expertise métier (Banque, Finance et Assurance) & méthodes agiles. Technology-oriented, elle offre une réelle expertise à ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l’Agilité. Son projet d’entreprise s’appuie aussi sur des valeurs humaines, sociétales et environnementales (Label EcoVadis Gold). La proximité, la performance, la convivialité et le progrès sont des atouts sur lesquels elle bâtit sonévolution collective au quotidien. Missions : Rattaché à nos experts, au sein de notre lab « Big Data » , vous : aurez en chargela réalisation d'un prototype Big Data(technologies Hadoop HDFS, Hive, Spark, etc) participerez aux activités de veille technologique sur le domaine du Big Data (recherches, expérimentations, etc) participerez à la rédaction d'articles et à l'animation de nos réseaux sociaux sur le domaine du Big Data évoluerez dans des équipes fonctionnant en méthode Agile utiliserez les outilsDevOpsdéployés sur nos chaînes d'intégration continue (Jenkins, Docker, Git, etc) Ce poste sera l'occasion d'intégrer notre programme de formation interne avec pour objectif d'acquérir les compétences fonctionnelles de base sur nos secteurs d'activité (finance de marché, banque et assurances) mais aussi de solides connaissances techniques. Profil recherché : Vous êtes diplômé d'une école d'ingénieurs ou équivalent. Une spécialisation dans le génie logiciel sera vivement appréciée. Réactif, avec le sens du service, vous justifiez de bonnes capacités d'écoute, d'un bon relationnel et une bonne gestion du stress. Curieux, autonome, et proactif, vous avez les qualités nécessaires à ce projet. Vous êtes intéressé par le conseil , les systèmes d'informations et le secteur de la Banque/ Finance/ Assurance Compétences requises : Des compétences en développement : Java ou Python. Des compétences des OS Linux et Windows ; Des compétences sur le framework Hadoop ; Une connaissance théorique et idéalement pratique de la gestion d'un projet informatique; A minima une connaissance théorique des méthodes Agile (Scrum par exemple).","Ingéniance is seeking an engineer for the Big Data lab to work on building a prototype, conduct technology watch activities, and contribute to social media posts. The ideal candidate holds an engineering degree with software engineering specialization, has good listening and stress management skills, is curious, independent, proactive, has knowledge of Java/Python, Linux/Windows, Hadoop, and Scrum. The role offers an opportunity to develop consulting and technical expertise via the company’s internal training program.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,2,1,0.04154662416233763
163,57137,https://www.welcometothejungle.com/fr/companies/oris/jobs/data-engineer-permanent-contract_saint-quentin-fallavier,Data Engineer - Permanent Contract,ORIS,"{GitLab,modular,PowerBI,AWS,S3,Lambda,scale,via,Docker,Sagemaker,SQL,Python,Tableau}",Télétravail partiel possible,"Rue du Montmûrier, Saint-Quentin-Fallavier, 38070","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Bâtiment / Travaux publics",CDI,2023-03-26,"Join us! Innovation, adventure, agile environment, start-up context… A dynamic team spirit and a company on a human scale aiming for excellence, that’s what defines us. ORIS is the first digital platform for sustainable infrastructure materials. Supported by high-level artificial intelligence, ORIS evaluates road designs from a global perspective to improve the sustainability of road construction. This solution can reduce the cost of road construction projects by a third and carbon dioxide emissions by half, while tripling the durability and service life of roads. Through intelligent design, ORIS helps managers, road authorities and investors to increase sustainability and reduce inefficiencies in road construction. ORIS also helps material suppliers to present and manage their product catalogue and identify road project opportunities. website: www.oris-connect.com Main tasks: Develop and maintain data integration pipelines from internal and external data sources to a datalake Develop data flows from the datalake, allowing their explotation (Datamart, reinjection in ORIS, manual verification reporting, …) Ensure automatic verification and continuous improvement of data quality Ensure data security, accessibility and integrity within the framework of ISO 27001 certification You may also be required to work on related data analysis or machine learning topics : Implementing machine learning models from geo-spatial data with AWS Sagemaker or text recognition Develop AI solutions to assess climate change resilience of infrastructure Create interactive dashboards for internal and external users with AWS Quicksight Knowledge of the Python language for the creation of ETL and machine learning solutions Knowledge of the AWS cloud environment and services such as S3, Lambda functions and Step functions, Sagemaker, … Good knowledge of GitLab versioning Knowledge of SQL databases Ability to extract data via APIs Knowledge of Docker containers Knowledge of a BI tool ideally AWS Quicksight, or such as Tableau, Qliksense, PowerBI A good command of English is essential Mastery of algorithms and the development of structured, modular and reusable code Ability to develop solutions iteratively in an agile environment (Kanban, Scrum) Good knowledge of data modelling and business intelligence concepts Ability to document well the codes or methodologies used. Desire to work in a start-up structure, focused on innovation and sustainable development Enjoy teamwork and knowledge sharing Have a great technical curiosity and a capacity to learn and adapt quickly Good communication skills and an entrepreneurial spirit Requirements : Master degree with an IS background and ideally a Data specialisation Have previous experience in data management and development of data integration solutions in Python, ideally in the AWS environment 2 interviews with HR Manager and CDO, and then with the COO.","ORIS is seeking a data integration specialist with experience developing and maintaining data integration pipelines and data flows from internal and external sources to a datalake. The ideal candidate should have a Master's degree in IS with a data specialisation, experience in data management and development of data integration solutions in Python, and knowledge of AWS environment and services. Additionally, experience in implementing machine learning models, using AWS Quicksight, GitLab versioning, and SQL databases is also preferred. A good command of English, good communication skills, and a desire to work in a start-up structure focused on innovation and sustainable development are essential.",Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,2,1,0.04154662416233763
217,65944,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes_EDF_2gLPzM5,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",Télétravail partiel possible,"Rue d'Estiennes D'Orves, Colombes, 92050","Environnement / Développement durable, Energie",CDI,2023-04-05,"Chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez EDF même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez EDF même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf La DSIN est en charge de développer le SI et les outils numériques de la Direction Commerce pour faire face aux défis que doit affronter EDF dans le cadre de la concurrence accrue du marché de l'énergie et des services. Elle contribue à la performance des métiers, à leur évolution et à la transformation de la Direction à travers ses activités SI et Data Science. Au sein de la DSIN, le Centre de Solutions et de Compétences DataScience & IA (CSC DS & IA), a pour mission de réaliser les travaux d'analyse et de valorisation des données de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux métiers du Marché d'Affaires et du Marché des Clients Particuliers pour répondre à des enjeux variés comme les départs à la concurrence, la conquête de nouveaux clients, la satisfaction client, la détection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de données conséquentes (~26 millions de clients, B2C+B2B). Afin de répondre à ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une équipe de Data Engineer, et en appui d'une équipe de plus de 20 Data Scientists, votre mission consistera à : - Mettre en place des pipelines de traitements de données - avec des volumes importants de données (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de données distribuées (Spark …) - Extraire massivement des données (Hadoop - Hive, Oracle - SQL, …) - vous-même ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de données (compréhension des problématiques Yarn, JVM, tablespace temp…) - Accompagner les Data Scientists dans le maintien et l'évolution des outils de requêtage développés en interne (dnquery pour requeter Oracle et Hive), extension à une nouvelle technologie de stockage des données (PostGre, SQL Server…) - Accompagner les déploiements de modèles de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des chaînes récurrentes de type traitement de la donnée ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer à la construction des stratégies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer à l'évolution de l'environnement technique des Data Scientists Votre Profil ? - Vous êtes titulaire d'un Bac +5 (Master, diplôme d'ingénieur) dans le domaine informatique, des mathématiques / statistiques, de la Data Science ou du Big Data - Vous bénéficiez d'une expérience d'au moins 3 ans en tant que Data Engineer - Vous avez déjà travaillé dans un contexte de Datascience et automatisé des traitements de type Datascience - Vous maîtrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez déjà manipulé des données stockées sous S3 - Vous êtes à l'aise avec les outils collaboratifs de développement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous bénéficiez d'une ou plusieurs expériences de travail en mode Agile - Vous êtes curieux et les projets innovants vous passionnent - Vous êtes force de proposition et proactif - Vous aimez transmettre et travailler en équipe Méthodologie de travail : Vous collaborerez étroitement avec les Référents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'équipe en charge des lacs de données au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark…). Le poste est situé à Colombes, proche de La Défense Ouest, avec une possibilité de télétravail partiel. Rémunération : Fourchette estimative : entre 50k et 57k€, la rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is hiring a Data Engineer to work in its Center of Solutions and Competences DataScience & AI. The position requires knowledge of Python, SQL, R, Docker, Airflow, and Hadoop, among other tools, as well as experience in automating Data Science-type treatments. The salary range is between €50k and €57k. The data engineer will be based in Colombes, France, and teleworking is possible. The role will involve working closely with technical, run, and DevSecOps contacts within EDF. The position is open to all, including people with disabilities.",Bac +5 / Master,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
220,66096,https://www.welcometothejungle.com/fr/companies/aviv-group/jobs/data-quality-engineer-m-w-d_hamburg,Data Quality Engineer,AVIV Group,"{scala,java,python,javascript,AZURE,AWS,GCP,sql}",Télétravail total possible,Hamburg,"Immobilier commercial, Immobilier particulier",CDI,2023-04-06,"Aviv Group is one of the world’s largest, privately owned real estate tech companies and a subsidiary of Axel Springer. Its mission is to unlock everyone’s perfect place! Some of Europe’s best known digital real estate marketplaces and brands form part of the Group, they are: 🇫🇷Meilleurs Agents 🇫🇷Group SeLoger 🇧🇪Immoweb 🇬🇧Real estate world 🇪🇸Housell 🇮🇱Yad2 Aviv Group also invest in innovative business models which shape the future of how people buy, sell, rent or lend properties and hold minority participations in companies such as: 🇬🇧 PurpleBricks 🇩🇪 Homeday 🇺🇸 Zumper 🇺🇸 Parcel The ambition is to be the leading employer in proptech across Europe. Join us on our exciting journey and become an AVIVer 🤩 WHAT WE DO IN Marketplace Design– Product and Tech at AVIV The Marketplace Design Domain at AVIV group is part of the Product & Tech organization and its objective is to deliver the internal services that powers Actor teams to brings safety, trustworthiness and remove opacity from the experience. Building on local expertise from Immowelt (Germany & Austria), Immoweb (Belgium), Groupe SeLoger and Meilleurs Agents (France), we deliver fraud / cheat / information reliability assessment services to raise marketplace safety and reliability in the interactions between Seekers and Owner / Agent. WE ARE LOOKING FOR AN INDIVIDUAL WHO CAN: Will be part of an agile, multidisciplinary, international team and work closely with them to Identify data quality issues, and implement solutions to verify, validate, and monitor data quality. Contributes to analysis of data issues and help identifying business processes and technical improvements that contribute to higher quality data. Work with the product team to establish data quality standards within the sprints, develop a test plan and deliver high quality builds on time. Work with product owners and data engineers to improve the overall experience by suggesting improvements and changes. Design and maintain QA reports for the internal data systems. Align and collaborate with the rest of the data quality team to improve the overall quality, assess risks, promote consistency, identify common needs. Develop test strategies for automation both for backend and data. Write and execute both functional and non-functional data tests. You convince with your analytical way of thinking. WHAT WE OFFER YOU: We are one of the leading PropTech platforms in Europe. If you’ve ever rented or purchased a property then you may have used one of our classified portals. This is a great time to join us to help elevate our AVIV brand. You'll experience a good work-life balance with 30 days holiday per year, flexible working hours, mobile working options and openness to sabbaticals You have the autonomy to work in a style which suits you to be the most productive. You are part of a great team with an exceptionally positive spirit that turns employee events into very special experiences. INDIVIDUAL WHO HAS: Solid experience (at least 3 Years) as Data Quality Engineer. Practical experience working with agile methodologies. Degree in Computer Science or other relevant qualifications. ISTQB Certification is a plus. Practical experience creating and maintaining ETL and API tests. Experience in automating data tests with frameworks like Deequ or other. Experience in automating APIs tests with javascript or java libraries like fetch, superAgent, restAssured... You are comfortable reading and writing code in at least one programming language, ideally java, scala, python. Basic understanding of sql. Experience with CI/CD Tools. Basics in cloud experience like AWS, GCP, AZURE is plus. A proactive team player that analyses the risk and impact of issues and is working with the team to prioritise and resolve them. Any experience with performance, GDPR, accessibility, interoperability and security testing is a plus. Excellent communication skills, with fluency in English. Willingness to travel from time to time is available.",,Non spécifié,Entre 250 et 2000 salariés,> 3 ans,3,0,0.04154662416233763
216,65928,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-banque-bordeaux_bordeaux_SS_VXqZ4xe,Data Engineer - Big Data - Banque - Bordeaux,Sopra Steria,"{Hdfs,Jenkins,spark,Scala,Shell,hive,GitLab}",Télétravail partiel possible,"18 avenue de Pythagore, Bordeaux, 33700","IT / Digital, Organisation / Management",CDI,2023-04-05,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Banque » s'est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement. Votre futur environnement de travail : Intégré(e) au sein d'une équipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participez à un projet Big Data, en mode Agile, et intervenez en tant que référent(e) technique au sein de votre équipe. Votre rôle et vos missions : A cette occasion vous êtes amené(e) à : - Apporter votre expertise et votre expérience à vos collègues lors des phases de conception et développement - Accompagner vos collègues dans leur montée en compétence technique au sein du projet - Définir et implémenter des solutions au sein d'un périmètre applicatif existant - Proposer des idées d'amélioration continue à votre client et à votre équipe (revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie) - Concevoir et développer des sujets complexes. Environnement du projet : - Méthodologie projet : Mode Agile (Scrum). Environnement technique : - Hdfs, hive, spark, oozie - Scala, HQL, Shell - GitLab, Nexus, Maven, Jenkins, Sonar Environnement fonctionnel : - Alimentation d'un DataLake jusqu'au build d'un moteur de calcul ; - Intervention sur la mise en place de règle relatives aux normes Bâloise. Votre profil : De formation Bac+5, vous avez au moins 5 ans d'expérience dans la data dont 3 ans en Big Data, notamment sur les technologies mentionnées ci-dessus. Vous aimez travailler en équipe, relever les défis techniques, conseiller et apporter votre valeur ajoutée à une équipe. Vous savez être challengeant et leader envers le client et l'équipe de Dev en ce qui concerne l'amélioration continue (process de livraison, automatisation du testing/validation, maintenance des bonnes pratiques et performance des runs). Vous aimez vous tenir informé(e) des nouveautés technologiques et êtes à la recherche d'évolution de carrière réelle basées sur l'expérience projet et l'acquisition de nouvelles compétences. Employeur inclusif et engagé, Sopra Steria oeuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils. Tous nos postes sont ouverts aux personnes en situation de handicap. https://www.soprasteria.fr/carrieres/decouvrez-sopra-steria/nos-engagements-rse","Sopra Steria, a European leader in digital transformation, is looking for a Big Data expert to join their team and work on a project with a major banking client. The ideal candidate should have at least five years of experience in data, with three years in Big Data, as well as a strong technical background in Hdfs, hive, spark, oozie, Scala, HQL, and Shell. The successful candidate will work in an Agile environment and be responsible for providing technical expertise and support to their team, as well as implementing solutions and proposing improvements. Diversity and inclusion are encouraged, and all candidates, including those with disabilities, are welcome to apply.",Bac +5 / Master,> 2000 salariés,> 5 ans,2,1,0.04154662416233763
213,65898,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-nantes-f-h_nantes_SS_AAy3xXD,Data Engineer - Big Data - Nantes -,Sopra Steria,"{Hive,datahub,Azure,Cloudera,DataBricks,Talend,SAP,Informatica,Kafka,Qlik,Elastic,SAS,Java,Hadoop,DataIku,Scala,R,Spark,Python}",Télétravail partiel possible,"impasse claude nougaro, Nantes, 44000","IT / Digital, Organisation / Management",CDI,2023-04-05,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Banque » s'est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement. Votre futur environnement de travail : Si vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Nantes et les quelques 100 Data Ingénieurs qui la composent. Vous y rencontrerez des experts de la mise en oeuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée. Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition. Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée. Votre rôle et vos missions : Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence pour l'un de nos chapitres Data ci-dessous, vous participez à : - La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis. - La mise en oeuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud. - La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données. - Le traitement de la donnée jusqu'à l'exposition au métier. - La mise en place de la chaine CI/CD et de sa supervision. - La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients. Environnement technique : - Spark, Hadoop, Hive, Kafka, Elastic - Cloudera, Azure HD Insight - Informatica, Talend, Stambia, DataStage, - SAS, DataIku, DataBricks - Qlik, SAP BI (BO), Power BI - Java, Scala, Python, R Votre profil : Diplômé(e) d'une école d'Ingénieurs ou équivalent universitaire, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 2 ans. Vous accordez une importance particulière à : - Au développement de vos compétences sur plusieurs technologies. - L'opportunité d'évolution réelle de carrière au travers de l'expérience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir auprès de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le développement de leur carrière. - A la bienveillance et à la diversité. Les avantages à nous rejoindre : - Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. - Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation. - Un accompagnement individualisé avec un mentor. - Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore). Chez Sopra Steria, nous sommes engagés pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les différences. Tous nos postes sont ouverts aux personnes en situation de handicap.","Sopra Steria is seeking a Data Engineer to join their Data Factory team in Nantes, France. Candidates should have a degree in engineering or a related field, as well as a minimum of two years of experience working in Big Data or BI projects. The role involves participating in the implementation of data platform solutions for clients, such as ingestion, structuring, processing, and visualization of data, and collaborating with Data Architects and other experts to provide solutions for data-related challenges. Candidates must be passionate about data and interested in developing their knowledge and skills in areas such as automation of processes, big data, AI, and cloud computing. Sopra Steria is committed to inclusivity and encourages applications from individuals with disabilities. The company offers its employees various benefits and opportunities for career growth, such as telecommuting, mentoring programs, training, and social engagement initiatives.",Bac +5 / Master,> 2000 salariés,> 1 an,2,1,0.04154662416233763
221,66225,https://www.welcometothejungle.com/fr/companies/adevinta-fr/jobs/data-engineer-team-data-platform-f-m_paris,Data Engineer team Data Platform,Adevinta,"{DynamoDB,Glue,Elasticsearch,Docker,Hudi,durable,Athena,Kafka,Kubernetes,AWS,Java,Github,Jupyter,SQL,Airflow,Redshift,S3,R,Spark,Unix,Python,MLFlow}",Télétravail partiel possible,"22 Rue des Jeûneurs, Paris, 75002","Intelligence artificielle / Machine Learning, Big Data, E-commerce",CDI,2023-04-06,"Adevinta est un leader mondial des petites annonces en ligne, avec plus de 40 marketplaces dans 13 pays, regroupant 8 100 collaborateurs. C’est au travers de ces marketplaces, qui incluent leboncoin en France, mobile.de en Allemagne et 2dehands au Pays-Bas, que se font des connexions et des rencontres. Ainsi, Adevinta met en relation des acheteurs avec des vendeurs pour l’achat d’une nouvelle maison ou d’une voiture, des personnes à la recherche d’un emploi avec les annonces correspondantes et plus généralement des personnes qui vendent avec des personnes qui achètent pour donner une seconde vie à des produits. Établir ces connexions contribue à créer un changement positif et à construire un avenir plus durable pour des millions de personnes. Vous êtes rattaché.e à l’équipe Data Engineering , composée de data engineers et de SRE. Cette équipe vous accompagne sur la stack technique data, vous permet d’échanger sur des sujets transverses et de participer aux rituels data engineering (guilde, rétro…). Cette équipe appartient à la tribe “Data Tools & Services“, qui regroupe les services data centraux La stack : Développement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm Dans un environnement à la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi Ce que vous ferez : Développer des applicatifs complexes assurant une circulation optimale des données, et assurer leur fiabilité : API d’exposition de données, applications de streaming, industrialisation de modèles de machine learning Optimiser notre architecture et notre environnement AWS : stockage, sécurité, automatisation, scalabilité Assurer la sécurité des données de nos utilisateurs sur la data platform, dans le respect de la réglementation en vigueur (GDPR, e-privacy) Participer activement à la veille technologique et à l'effort de R&D Garantir le bon fonctionnement, la disponibilité, l’évolution et la performance des outils Assurer l’interface avec les équipes techniques du produit Informations supplémentaires Poste basé à Paris 10 Les étapes : Premier échange avec Simon (RH) Entretien managérial avec Thomas (Engineering Manager) Entretien technique avec deux membres de l'équipe (Data Eng) Entretien Fit/RH avec Julien (directeur data) et Simon (RH) Vous avez au moins 5 ans en tant que Data Engineer Vous connaissez les environnements Unix, et possédez un niveau avancé en Java / Python . Vous êtes familier avec l'environnement cloud AWS , et avez de solides notions d’architecture distribuée et de gestion de data platform à forte volumétrie. Vous êtes à l’aise en anglais tant à l’écrit qu’à l’oral.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
219,66090,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-middleware-h-f-services_paris,Data Engineer Middleware  - Services,CGI,"{Azure,Numpy,Pandas,Python}",Télétravail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-04-06,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Fonctions et responsabilités - Savoir identifier et présenter les avantages/inconvénients de solutions techniques afin de répondre aux besoins métiers - Participer aux phases de réalisation, d'évolution et de maintenance à l'application ainsi qu'aux phases de test des fonctionnalités développées - Echanger avec les métiers et comprendre l'expression de besoin fonctionnel - Concevoir et développer des nouvelles fonctionnalités from scratch ou des évolutions - Rédaction de la documentation technique et fonctionnel - Mise en place de tests unitaires - Diagnostiquer les incidents et développer les correctifs tout en s'inscrivant dans un processus d'amélioration continue - Effectuer de la veille technologique et proposer des évolutions Qualités requises pour réussir dans ce rôle De formation bac +4/5 dans le domaine de l'IT ou de l'ingénierie, tu possèdes une expérience significative de minimum 2 ans en analyse et développement Python. - Compétences techniques : Python, Azure Devops, Jira, ESB, middleware, Pandas, Numpy, Petl librairies : aiflow - Compétences métier : Capacité orale et rédactionnelle, Méthodologie Agile Anglais requis Mobilité en Ile-de-France A compétences égales, ce poste est ouvert aux personnes en situation de handicap, à l'évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Allier savoir et faire Alors que la technologie s’inscrit au cœur de la transformation numérique de nos clients, nous savons que les individus sont au cœur du succès en affaires. Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos collègues et clients pour proposer des idées exploitables qui produisent des résultats concrets et durables. Nous appelons nos employés ""membres"" parce qu’ils sont actionnaires et propriétaires de CGI. Ils ont du plaisir à travailler et à grandir ensemble pour bâtir une entreprise dont nous sommes fiers. C’est notre rêve depuis 1976. Il nous a menés là où nous sommes aujourd’hui – l’une des plus importantes entreprises indépendantes de conseil en technologie de l’information (TI) et en management au monde. Chez CGI, nous reconnaissons la richesse que la diversité nous apporte. Nous aspirons à créer une culture à laquelle nous appartenons tous et collaborons avec nos clients pour créer des communautés plus inclusives. En tant qu’employeur qui prône l’égalité des chances pour tous, nous voulons donner à tous nos membres les moyens de réussir et de s’épanouir. Si vous avez besoin d’un accompagnement spécifique durant le processus de recrutement et d’intégration, veuillez nous en informer. Nous serons heureux de vous aider. Prêt à faire partie d’une entreprise qui est gage d’excellence? Rejoignez CGI – où vos idées et vos actions changent la donne.",,Non spécifié,> 2000 salariés,> 2 ans,2,1,0.04154662416233763
223,56833,https://www.welcometothejungle.com/fr/companies/trend-it/jobs/data-engineer-azure-data-factory-msbi-stack_paris,DATA ENGINEER  (Azure Data Factory/MSBI Stack),TREND-IT,"{Microsoft,Azure,SQL}",Télétravail partiel possible,"277, Rue Saint-Honoré, Paris, 75008",Logiciels,CDI,2023-03-26,"TREND-IT est un cabinet de conseil IT, d’expertise technique et de transformation digitale. Nous sommes une ESN pure player Microsoft. Nous accompagnons nos clients tout au long de leurs processus de transformation digitale : Analyse, Conception, Réalisation, Déploiement et Audit, spécialisés sur les prestations intellectuelles dans les technologies Microsoft. TREND-IT évolue dans une activité B to B. Elle propose les services suivants : le conseil (en système d’information, en conduite de changement…), l’intégration de système (architecture de systèmes d’information, intégration de progiciels, ERP…). TA TEAM TREND-IT met l accent sur l esprit d’équipe et collaboratif. En plus de faire partie d’une équipe, tu feras partie de la famille TREND-IT ! Pour renforcer ses équipes TREND-IT recrute dans l’immédiat un Data Engineer pour travailler sur un projet de grande envergure avec des intervenants hautement qualifiés. Nous sommes à la recherche d’un profil confirmé sur la suite Microsoft BI pour un poste en CDI. Nous recherchons une personne justifiant d’au moins 5 ans d’expériences, dans un environnement Microsoft. Les compétences/appétences suivantes sont requises pour le poste: MSBI( SSIS, SSAS, SSRS) Power BI SQL Server : Suivi performance(Charge serveur/Optimisation/Log…) Azure Data Factory Autonome et rigoureux(se) Bon(ne) communicant(e) Maitrise de l’anglais","TREND-IT is hiring a Data Engineer with at least 5 years of experience in Microsoft environment, for a CDI position, to work on a large-scale project. The ideal candidate should have expertise in MSBI (SSIS, SSAS, SSRS), Power BI, SQL Server, Azure Data Factory, be autonomous, rigorous, a good communicator, and have a command of English. TREND-IT is an IT consulting firm specialized in Microsoft technologies, offering consulting and system integration services.",Bac +5 / Master,< 15 salariés,> 5 ans,2,1,0.04154662416233763
222,56782,https://www.welcometothejungle.com/fr/companies/octopus-energy/jobs/ingenieur-data_saint-denis,Data Engineer expérimenté·e,Octopus Energy France,"{durable,AWS,dbt,SparkSQL,Python}",Télétravail partiel possible,"6, Boulevard Haussmann, Paris, 75009","Environnement / Développement durable, Energie",CDI,2023-03-26,"Octopus Energy France (anciennement Plüm énergie), est un fournisseur d’électricité verte. Sa mission est d’accélérer la transition écologique auprès des particuliers, des entreprises et des collectivités. C’est une entreprise reconnue d’utilité sociale par le gouvernement (ESUS). Créée en 2016 et après plusieurs tours de financement, la start-up a rejoint début 2023 le groupe innovant et engagé Octopus Energy, afin de lutter contre le réchauffement climatique à grande échelle. Octopus Energy est un fournisseur et producteur d’énergie verte Britannique, déjà plusieurs fois “licorne”, qui fournit plusieurs millions de client·e·s à travers le monde. Leur technologie, Kraken, révolutionne le marché de l’énergie et permet de garantir aux client·e·s de réaliser des économies, tout en bénéficiant de la meilleure expérience du marché. La filiale française a déjà rencontré de beaux succès, en gagnant par exemple trois fois consécutives l’appel d’offre de la ville de Paris. Parcs, écoles, musées, éclairage public… Près de 8 000 bâtiments et équipements publics parisiens sont aujourd’hui chez Octopus. Et la Canebière à Marseille, c’est également Octopus qui l’éclaire ! Toujours en continuant d’enrichir le nouveau système énergétique durable que le groupe a su construire, le prochain challenge d’Octopus Groupe est d’atteindre 100 millions de client·e·s dans le monde d’ici 10 ans. Nous recherchons un·e ingénieur·e data expérimenté·e pour rejoindre notre équipe data en France. Chez Octopus, nous avons développé une plateforme de données qui fournit des services à toutes les parties de notre entreprise au Royaume-Uni et dans le monde entier. Cette plateforme permet à des centaines d’utilisateurs/trices d’effectuer des analyses de données en libre-service et d’automatiser tous nos flux de données. Dans ce rôle, tu seras responsable de la construction et de la maintenance de nouvelles pipelines de données et d’applications de données pour permettre à l’équipe de production de développer, gérer et optimiser efficacement ses actifs renouvelables. Ce que tu feras Construire et maintenir des pipelines de data qui fournissent des informations clés à l’entreprise. Intégrer de nouvelles sources de données dans la plateforme de données par le biais d’API ou de transferts de données en masse. Travailler en étroite collaboration avec les équipes data. Créer et maintenir des cadres de test et de documentation pour nos sources de données. Travailler avec l’entreprise pour définir la portée et la réalisation de nouveaux projets et des exigences en matière d’ingénierie des données. Maintenir et développer notre infrastructure de données et nos outils existants. Soutenir l’internationalisation de notre infrastructure de données dans le cadre de notre croissance mondiale. Avant tout, nous voulons que nos ingénieur·e·s data soient d’excellent·es ingénieur·e·s en logiciels, passionnés par l’écriture de code de haute qualité. Il serait utile d’avoir de l’expérience/expertise dans les domaines suivants (par ordre de priorité approximatif) : Python / SparkSQL Expérience dans la modélisation des données pour l’analyse - idéalement, expérience dans l’utilisation de dbt comme outil de modélisation. Expérience dans l’assurance de la qualité des données Expérience dans le déploiement de services de données dans un environnement cloud (idéalement AWS). Les projets seront variés et nous recherchons une personne capable de travailler de manière autonome et proactive pour définir les problématiques, les résoudre et fournir des solutions pragmatiques. Pourquoi tu vas adorer ce poste Tu te demandes quel est le salaire pour ce poste ? Demande-le nous ! Lors de notre premier contact, c’est un point que nous abordons toujours, car nous souhaitons réellement faire correspondre ton expérience avec le bon salaire. La raison pour laquelle nous n’en parlons pas ici est que nous avons un certain degré de flexibilité et que nous ne voudrions jamais que le salaire soit une raison pour laquelle quelqu’un.e ne postule pas chez Octopus - ce qui est plus important pour nous est de trouver le bon octofit ! Octopus Energy a une culture unique : nous avons gagné le prix de la meilleure entreprise pour laquelle travailler en 2022, sur Glassdoor UK nous avons été élus parmi les 50 meilleurs endroits où travailler en 2022 et notre PDG, Greg, a enregistré un podcast sur notre culture et la façon dont nous donnons du pouvoir à nos employés - c’est la même chose ici en France. Nous sommes une organisation où les gens apprennent, décident et construisent plus rapidement. Où ils travaillent de manière autonome, avec des gens extraordinaires, sur des projets qui innovent. Intéressement au capital, flex-office, excellente mutuelle, forfait mobilité douce, remboursement du pass navigo au delà du minimum légal, et même des jours de congés spéciaux pour mener des projets associatifs qui te tiennent à coeur… nous voulons que ton dur labeur soit récompensé par des avantages auxquels vous tenez vraiment ! Nous recherchons une personne qui aime résoudre des problèmes difficiles. Quelqu’un qui peut challenger ceux qui l’entourent et être challengé, tout en offrant une expérience agréable à nos clients internes et externes. Si tout cela te passionne, postule dès maintenant.","Octopus Energy France is seeking an experienced data engineer to join their team in building and maintaining new data pipelines and applications for effective renewable asset management. The candidate should have expertise in Python, SparkSQL, data quality assurance, and AWS cloud deployment. Octopus Energy is a socially responsible energy provider and producer, aiming to accelerate the ecological transition for individuals, businesses, and communities. The company offers flexible working hours and a unique culture where individuals learn and innovate autonomously.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.04154662416233763
397,35714,https://www.welcometothejungle.com/fr/companies/retailmenot/jobs/data-engineer-h-f_paris,Data Engineer,RetailMeNot,"{Qlikview,Looker,Airflow,Braze,S3,Snowflake,SQL,Python,Tableau}",Télétravail partiel possible,N,"Application mobile, E-commerce, Marketing / Communication",CDI,2022-09-28,"RetailMeNot France fait partie de Ziff Media Group, un groupe au rayonnement mondial, leader dans les secteurs Shopping, Média et Technologie. Ziff Media est connu en France sous les marques grand public Poulpeo, le service shopping qui accompagne les consommateurs tout au long de leur parcours d’achat avec des solutions de cashback, de codes promos, de bons plans et des guides d’achat, et Ma Reduc, la référence des consommateurs français pour profiter des meilleures offres promotionnelles. Reprise de la génération de tous les flux de données Business Analytics Maintenance et optimisation des jobs SQL existants, Possibilité de créer / corriger le développement d’une API, Capacité à optimiser / corriger un dashboard mis en place, Suivi des données envoyées quotidiennement à notre outil Marketing “Braze”, Création de nouveaux flux de données from scratch: capacité à modéliser et créer des données agrégées à ingérer quotidiennement Créer de la valeur business à partir d’un ensemble de données Travailler en collaboration avec notre équipe Marketing afin de segmenter notre base utilisateurs et leur adresser des messages pertinents (scoring algorithmiques, système de fidélité, etc.), Appréhender et améliorer nos algorithmes de recommandations d’offres et marchands automatisés, Travailler avec les ingénieurs front pour pousser du contenu segmenté en temps réel sur nos produits afin d’améliorer l’engagement, Suivre les performances des différents AB tests lancés par nos équipes produits, Travailler de paire avec nos analystes de données et réaliser des dashboards à destination des équipes métiers. Manager et accompagner un alternant Transmission de vos compétences à un alternant lui permettant d’acquérir une autonomie sur le long terme, Création d’une roadmap data en adéquation avec la stratégie de l’entreprise, Suivi des compétences et délégation des tâches. Management de Snowflake, notre “Cloud Data Platform” Création des utilisateurs et gestion des rôles pour la sécurité, Comprendre les routines d’imports et d’ingestion de données stockées de nos dépôts Amazon S3 vers Snowflake, Manager et suivre mensuellement les dépenses Snowflake pour respecter le budget annuel. Formation de type école d’ingénieurs, Une première expérience réussie en tant que Data Engineer, Expertise SQL requise (des tests seront effectués), Maîtrise avancée d’un langage de programmation comme Python, Maîtrise de la suite Office, Connaissance requise d’un outil de data visualisation type Tableau / Looker / Qlikview, La manipulation d’un outil d’ETL type SSIS / Airflow est un plus, La connaissance business du milieu e-commerce / digital est un plus, Très bonne communication nécessaire, La maîtrise de l’anglais est obligatoire. Ce que nous offrons De l’autonomie, des responsabilités, de la confiance Des avantages classiques (carte Swile tickets restaurants, remboursement de l’abonnement transport, mutuelle…) Et aussi, le remboursement de votre abonnement à la salle, pour vous maintenir en forme et aérer l’esprit ! Des horaires flexibles & du télétravail Des évènements réguliers (même si c’était plus facile avant) Des collègues un peu fous, mais hyper disponibles et toujours bienveillants Un visio avec notre RH pour présenter votre parcours & vos attentes (20-30 mins) Un entretien avec notre Business Analytics Manager incluant un cas pratique et test technique (1h30) Un dernier échange avec notre DG (1h)","RetailMeNot France seeks a Data Engineer to manage, maintain, and optimize existing SQL jobs, create new data flows, and improve algorithms for customer segmentation, recommendations, and promotions. The candidate should have a degree in engineering, expertise in SQL, advanced programming skills in Python, and proficiency in data visualization tools such as Tableau. The ability to communicate effectively, prioritize tasks, and manage an apprentice is also required. Fluency in English is mandatory. The company offers flexible schedules, remote work, gym reimbursement, and regular team-building events.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
84,57003,https://www.welcometothejungle.com/fr/companies/jow/jobs/data-engineer_paris,Data Engineer,JOW,"{Looker,Redshift,Airflow,magic,scale,NoSQL,SQL,Python}",Télétravail partiel possible,"17, Rue de Lancry, Paris, 75010","E-commerce, Grande consommation, FoodTech",CDI,2023-03-26,"Jow is a new way to eat better, smarter and healthier every day. Jow’s app automatically creates a customized menu, just for you, with simple and delicious recipes, and automatically fills your cart with all the ingredients you need, magic! Your grocery is then delivered to your door by your favorite merchant, and you can enjoy our video tutorials to cook our simple and delicious recipes every day. We are strengthening our Data team and we’re looking for an experimented Data Engineer profile to develop, maintain and operate Jow’s data stack. As Jow’s Data Engineer, you’ll be responsible for Jow’s Data Warehouse and ETL tools, helping Jow teams make the most of their data. Reporting to Jow’s Head of Data within Jow Platform Team (a cross-disciplinary team in charge of all tech & products challenges at Jow), you’ll make an immediate impact on Jow’s business and strategy and play a central role, working with both technical and business teams. What you’ll do: Develop, maintain and build evolutions to Jow’s data stack and tools: warehouse databases, ETL process, scripts & tools… Maintain and enhance the existing data infrastructure Optimize the performance and scalability of the data pipelines that ingest, transform, and load data from a variety of sources into our data warehouse Collaborate with the technical, product and business teams to identify and prioritize data needs Implement data quality controls and monitoring processes Stay up-to-date with the latest data engineering technologies and best practices Our current stack: Data Warehouse: Redshift ETL: Airflow BI platform: Looker Master’s degree in Computer Science, Data Engineering, Software Development or a related field 3-5 years building/developing data architectures and/or working on data issues, ideally in a fast growing data-driven start-up company Experience with the core toolkit of Data Engineering: Python SQL & NoSQL databases Data modeling Large-scale data sets manipulation Data warehousing ETL development Able to work in French and in English Strong problem-solving and communication skills Basic full-stack dev & DevOps knowledge is a plus Call: to know about each other and check if the stars are aligned 2 to 3 more formal/classic interviews with the team, including some tech tests to assess your hard skills Breakfast or coffee with some members of the team: we want you to be happy to see our teammates every morning, so one of the very first things we check is the cultural fit. We have a “no brilliant jerk” rule. Being nice, cool and humble is as mandatory as being good at what you do ;-)","Jow is seeking an experienced Data Engineer to develop, maintain, and operate Jow’s data stack. The role involves optimizing the performance and scalability of data pipelines, collaborating with technical, product, and business teams to identify and prioritize data needs, implementing data quality controls and monitoring processes, and staying updated with the latest data engineering technologies and best practices. The ideal candidate should have a Master's degree in Computer Science, Data Engineering, Software Development, or related fields, 3-5 years of experience building/developing data architectures and/or working on data issues, and expertise in Python, SQL & NoSQL databases, data modeling, large-scale data sets manipulation, data warehousing, and ETL development.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
468,56729,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-cdi-scala-spark_paris,Data Engineer - CDI - Scala & Spark,Assistance Publique - Hôpitaux de Paris - DSI,"{UNIX,bash,Hive,Nvidia,Docker,portable,Kafka,NoSQL,Postgres,Elastic,Kubernetes,Java,SQL,Hadoop,Jupyter,Scala,via,Spark,Python}",Télétravail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Santé",CDI,2023-03-26,"L’ Assistance Publique - Hôpitaux de Paris (AP-HP) est un établissement public de santé et le centre hospitalier universitaire - CHU - de la région Ile-de-France, reconnu mondialement pour sa recherche. Le département Innovation & Données (I&D) s’inscrit au sein de sa Direction des Systèmes d’Information . 🎯 Sa mission ? Réaliser les projets numériques innovants au contact du monde hospitalier. 🚀 Ses projets phares ? Construire le plus large entrepôt public de données de santé en Europe ! Le projet vise à valoriser les données produites à l’AP-HP pour la recherche, l’innovation et le pilotage des soins, tout en protégeant les données patient. L’ Entrepôt de Données de Santé , c’est déjà +13 millions de patients dont les données sont structurées et référencées sur une plateforme Big Data dédiée. Notre objectif est de créer une base de données standardisée et centralisée à partir d’une multitude de sources de données ( données textuelles, images, radiographies, examens, analyses biologiques, signaux physiologiques, etc.. ). Faciliter le quotidien des patients! Le domaine gère notamment toutes les applications mobiles et tous les téléservices de l’AP-HP, dont par exemple le “Portail Patient”. Monter une plateforme Bio-Informatique centrale pour assister les pôles de biologie de l’AP-HP dans leurs besoins informatiques (gestion du séquençage, déploiement de ressources de calcul). Développer et déployer au niveau national les outils de collecte et d’analyse épidémiologique des données relatives aux maladies rares. 📊 Quelles statistiques : L’ Entrepôt de Données de Santé (EDS) de l’AP-HP accueille aujourd’hui plus de 170 projets de recherche médicale sur données : https://eds.aphp.fr/recherches-en-cours L’EDS intègre des données administratives et médicales de plus de 13 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (40 millions de dossiers médicaux, plus de 45 millions de diagnostics, 2.5 milliards de résultats de laboratoires…) . Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision. L’EDS de l’AP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 2Po d’espace disque) , de machines GPU (80 Nvidia P40, V100 et A100) , plus de 20 machines dédiées aux environnements Jupyter pour l’analyse de données , et de nombreuses autres machines applicatives. En tant que Data Engineer , vous serez intégré au sein de l’équipe Big Data de l’ Entrepôt de Données de Santé (EDS) de l’AP-HP . Cette équipe est composée d’une dizaine de Data Engineer travaillant à la conception et au développement de la base de données standardisée et centralisée de l’EDS. Cette base contient des données aggrégées provenant de divers applicatifs de l’AP-HP avec des typologies très différentes (données structurées, non-structurées, imagerie, voix, signaux physiologiques, etc.) qui nécessitera la mise en oeuvre d’outils spécifiques à leur intégration et leurs traitements. Contribuer à la définition des besoins techniques et à l’accompagnement des Datas Scientists, chercheurs, et médecins lors de la réalisation de projets de recherche impliquant de nouvelles sources de données Analyser les différents sources de données d’un point de vue technique (acquisition, stockage, transformation, exploitation, …) Développer, industrialiserez et maintiendrez des traitements de données (extraction, sélection, collecte, intégration et aggrégation) dans un contexte Big Data (développements en Spark/Scala/Python) Intégration d’algorithmes spécifiques (ML, NLP, etc.) co-développés avec l’équipe Data Science de l’EDS Contribuer à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en Java/Scala & Python Aider à l’implémentation de standards et normes de mise à disposition des données (OMOP/FHIR) Industrialiser le code de génération du flux de données et assurer sa performance globale Optimiser la performance des outils dans un contexte Big Data (Hadoop / Spark) Développer des méthodologies standardisées pour l’intégration de nouvelles données Metter en place des outils les processus de tests unitaires, de recette et de qualification des données Développer des solutions permettant la mise à disposition des données dans les espaces des projets de recherche Développer des solutions pour monitorer les différents processus en production ainsi que la qualité des données Travailler en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche Vous serez force de proposition pour améliorer la qualité des développements, notamment en réalisant une veille continue sur les outils et technologies, en proposant des algorithmes pouvant resoudre des problématiques fonctionnelles et techniques. Avantages Technique : un cluster Hadoop de +30 serveurs une infrastructure Kubernetisée conséquente (+100 serveurs) opérée par une équipe voisine un ordinateur portable i7/32Go Quotidien : Cantine Télétravail (max 3 jours par semaine) 25 Congés payés et environ 22 RTT Salaire de cadre dans la fonction publique (40 000,00€ à 60 000,00€ par an) imposé à 15% contre 25% dans le privé N’hésitez pas à vous envoyer votre CV pour un premier entretien pour en découvrir + sur le poste, et peut-être par la suite venir nous rencontrer dans le 12e arrondissement ! Bac+5/Master 3 ans d’expériences en tant que Data Engineer Technologies et compétences requises : Environnement UNIX (ou Windows selon préférence) Scala / Java & Python Traitement des données massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Bases de données SQL (Postgres, Apache Hive, LevelDB, etc.) DevOps (CI/CD, Docker, scripting, bash, etc.) Qualité de code (Tests, veille, code reviews, etc.) Excellent relationnel et expression personnelle Au moins un des points suivants : Industrialisation d’application ou de flux de traitement de données massives de manière distribuée Administration de cluster Hadoop Pipelines CI/CD | Kubernetes / Helm charts Connaissance des standards d’interopérabilité du domaine de la santé (FHIR, OMOP, CDA, HL7, CIM, Snomed, LOINC, etc.) Déroulé des entretiens (susceptible de varier en fonction du profil du candidat) : 1 premier entretien en visio avec des membres de l’équipe 1 second entretien sur place (75012 - Campus Picpus) avec possibilité d’échanges avec les membres de l’équipe (recommandé) 1 dernier entretien avec le directeur de la Plateforme Big Data (N+2)","The Assistance Publique - Hôpitaux de Paris (AP-HP), the largest hospital center in the Paris region, is seeking a Data Engineer to join its Big Data team within its Department of Innovation & Data. The role involves contributing to the development of a public health data warehouse, integrating and processing diverse data types including structured and unstructured, imaging, voice, and physiological signals. The successful candidate will have at least three years of experience in data engineering and be proficient in Scala/Java and Python, Hadoop/Spark/Kafka as well as working in DevOps and CI/CD environments. Knowledge of health interoperability standards such as FHIR and OMOP is also desirable.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
234,58100,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/bi-analyst-analytics-engineer-h-f_paris,BI Analyst / Analytics Engineer,NEXTON,"{dbt,SQL,Tableau}",Télétravail partiel possible,"5, Rue Saint-Fiacre, Paris, 75002","Design, IT / Digital, Digital",CDI,2023-03-26,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, Nexton connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, professionnalisme et performance. Et pour vous ? Notre politique de développement des compétences dynamique saura vous séduire avec un programme de suivi de carrière sur-mesure. NEXTON recrute un BI Analyst / Analytics Engineer H/F , en CDI , à Paris ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…). Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel. Fort du succès, Nexton connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance. Et pour vous ? Notre politique de développement des compétences dynamique saura vous séduire avec un programme de suivi de carrière sur-mesure. Le contexte : En tant qu'Analyste BI / Ingénieur Analytics, vous faites partie d'une équipe multi-compétence Data et vous agissez en tant qu'expert BI et data warehousing. Vos missions : Recueillir et comprendre les exigences des produits commerciaux et de données (de manière autonome ou en équipe avec des analystes de données ; suivis par les PO/PM) Concevoir et développer des actifs BI & Datawarehouse robustes, évolutifs et industrialisés (flux d'intégration de données / ETL / pipelines ; tables de dimension et de faits ; datamarts ; métriques ; KPI,…) visant à faciliter et rendre cohérente la consommation de données en soutenant les équipes métiers dans le suivi de leurs performances et de l'atteinte des objectifs et également dans le partage de données avec d'autres systèmes Développer des approches de support (documentation, communication, outillage, formation, etc.) vers les équipes techniques & métiers pour assurer une accélération progressive de l'organisation vers une utilisation plus facile et plus systématique des actifs BI dans leurs activités quotidiennes De formation supérieure, vous justifiez 4 à 8 ans d'expérience dans le domaine de la data. Vous travaillez de manière autonome, proactive, responsable et orientée vers les solutions : vous n'attendez pas qu'on vous dise quoi faire. Vous fournissez des ressources approfondies et fiables dans un environnement en évolution rapide, avec une excellente organisation et une excellente gestion du temps. Vous maîtrisez les modèles de transformation de données (ETL/ELT) ainsi que le SQL (dbt) et Tableau. Vous avez une connaissance pointue des pratiques d'intégration et de modélisation de données : conception ETL, techniques de modélisation des données dimensionnelles et techniques de reporting / visualisation de données Vous savez travailler en méthode agile et gérer plusieurs sujets en parallèle, avec différents acteurs impliqués. Des excellentes compétences en communication orale et écrite en anglais sont obligatoires. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'année : - Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'année - Des moments privilégiés avec votre manager Prêts à nous rejoindre ? Rencontrons-nous !","NEXTON, a digital transformation company, is seeking a BI Analyst/Analytics Engineer with 4-8 years' experience and expertise in data warehousing, ETL/ELT, SQL, Tableau, and data integration and modeling. The successful candidate will have excellent communication skills, work autonomously and proactively, and be able to manage multiple projects simultaneously.NEXTON offers a dynamic skills development program and a supportive work environment.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
232,56848,https://www.welcometothejungle.com/fr/companies/thelio/jobs/data-engineer-experimente_lyon,Data Engineer,Thélio,"{Oracle,Databricks,Talend,Qlik,Scala,Snowflake,Kafka,Hadoop,Spark,Azure,NoSQL,SQL,Tableau}",Télétravail partiel possible,"21, Quai Antoine Riboud, Lyon, 69002","IT / Digital, Stratégie, Big Data",CDI,2023-03-26,"Thélio est né pour relever un défi : démystifier le monde de la Data pour la rendre accessible à toutes les entreprises Sa raison d’être ? : des entreprises et organisations plus performantes, innovantes et humaines, grâce à l’intelligence de la donnée Né à Bordeaux et continuant sa croissance à Lyon et Aix-en-Provence , Thélio intervient sur toute la chaîne de valeur de la donnée : Stratégie & Gouvernance Data Data Visualisation Modern Data Platform Intégration Data Master Data Management Qualité & Conformité de la Donnée Selon vos expériences, votre mission, si vous l’acceptez, sera de : Définir les architectures data de nos clients : challenger l’existant et proposer de nouvelles solutions, Effectuer des analyses fonctionnelles et de rédiger les spécifications, retranscrire les besoins métiers en solutions techniques, Concevoir et développer des pipelines de données, Garantir la sécurité et l’intégrité des données, Encadrer vos collègues dans le respect de la charge et du planning projet et transmettre votre expertise, Être garant des solutions techniques mises en œuvre, D’une manière générale, être force de proposition sur les projets de la conception à la mise en production. En fonction de votre expérience, vous serez également amené(e) à intervenir sur les sujets tels que : participation aux avant-ventes, mise en place de POC, accompagnement à la gestion de projet, missions de conseil et d’audit, d’expertise technique et d’optimisation sur tous nos clients Auvergne-Rhônes-Alpes. Pour relever ce défi, il vous faut : Avoir au moins 3 ans d’expérience : o Sur des problématiques de modélisation, d’organisation de données, mise en place de pipelines de données, optimisations techniques o Sur des problématiques d’ingénierie de données : temps-réel, gestion de schémas, résilience, redondance, scalabilité, ordonnancement… Être aguerri(e) à la maitrise du SQL, Posséder une réelle appétence pour la donnée, et être toujours en veille sur le domaine, Maîtriser une ou plusieurs technologies suivantes : o Azure Data Factory, Azure Databricks o Stockage : SQL Server, Oracle, Azure Datalake, Google Big Query, Snowflake o Big Data : Kafka, Spark, Scala, Hadoop, Google Big Query, HortonWorks, NoSQL o Grand avantage : Posséder une ou des certifications sur les outils maitrisés Sensibilité au cloud (gestion des coûts, scalabilités, flexibilité…) En bonus, expériences en décisionnel : modélisation BI et/ou ETL (Talend, SSIS) et/ou outil de dataviz (Power BI, Tableau, Qlik, Cognos) Être force de proposition et aimer transmettre votre savoir On vous aide dans la recherche de votre nouveau logement sur Lyon, afin de faciliter votre démarrage chez nous !","Thélio is seeking for a Data Engineer to define data architectures for clients, develop data pipelines, ensure data security, and lead project teams. The ideal candidate should have at least 3 years of experience in data modeling, pipeline development, and knowledge of SQL, Azure Data Factory, Azure Databricks, and other relevant technologies. Certification in relevant tools and experience in data visualization and BI are a plus.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
199,56766,https://www.welcometothejungle.com/fr/companies/thelio/jobs/data-engineer-experimente-bordeaux_begles,Data Engineer,Thélio,"{Oracle,Databricks,Talend,Qlik,Scala,Snowflake,Kafka,Hadoop,Spark,Azure,NoSQL,SQL,Microstrategy,Tableau}",Télétravail partiel possible,"Boulevard Jean-Jacques Bosc, Bordeaux, 33800","IT / Digital, Stratégie, Big Data",CDI,2023-03-26,"Thélio est né pour relever un défi : démystifier le monde de la Data pour la rendre accessible à toutes les entreprises Sa raison d’être ? : des entreprises et organisations plus performantes, innovantes et humaines, grâce à l’intelligence de la donnée Né à Bordeaux et continuant sa croissance à Lyon et Aix-en-Provence , Thélio intervient sur toute la chaîne de valeur de la donnée : Stratégie & Gouvernance Data Data Visualisation Modern Data Platform Intégration Data Master Data Management Qualité & Conformité de la Donnée Selon vos expériences, votre mission, si vous l’acceptez, sera de : Définir les architectures data de nos clients : challenger l’existant et proposer de nouvelles solutions, Effectuer des analyses fonctionnelles et de rédiger les spécifications, retranscrire les besoins métiers en solutions techniques, Concevoir et développer des pipelines de données, Garantir la sécurité et l’intégrité des données, Encadrer vos collègues dans le respect de la charge et du planning projet et transmettre votre expertise, Être garant des solutions techniques mises en œuvre, D’une manière générale, être force de proposition sur les projets de la conception à la mise en production. En fonction de votre expérience, vous serez également amené(e) à intervenir sur les sujets tels que : participation aux avant-ventes, mise en place de POC, accompagnement à la gestion de projet, missions de conseil et d’audit, d’expertise technique et d’optimisation sur tous nos clients Sud-Ouest. Pour relever ce défi, il vous faut : Avoir au moins 3 ans d’expérience : sur des problématiques de modélisation, mise en place de pipelines de données, optimisation techniques, sur des problématiques d’ingénierie de données : temps-réel, gestion de schémas, résilience, redondance, scalabilité, ordonnancement…, Être aguerri(e) à la maitrise du SQL, Posséder une réelle appétence pour la donnée, et être toujours en veille sur le domaine, Maîtriser une ou plusieurs technologies suivantes : Azure Data Factory, Azure Databricks Stockage : SQL Server, Oracle, Azure Datalake, Google Big Query, Snowflake Big Data : Kafka, Spark, Scala, Hadoop, Google Big Query, HortonWorks, NoSQL Grand avantage : Posséder une ou des certifications sur les outils maitrisés Sensibilité au cloud (gestion des coûts, scalabilités, flexibilité…) En bonus, expériences en décisionnel : modélisation BI et/ou ETL (Talend, SSIS) et/ou outil de dataviz (Power BI, Tableau, Qlik, Microstrategy) Être force de proposition et aimer transmettre votre savoir On vous aide dans la recherche de votre nouveau logement sur Bordeaux, afin de faciliter votre démarrage chez nous !","Thélio is seeking a Data Architect with at least 3 years of experience in data modeling, pipeline development, and technical optimization. The ideal candidate should have strong SQL skills and be knowledgeable in Azure Data Factory, Azure Databricks, and various storage and big data technologies. They must also possess excellent problem-solving skills and be able to propose and transmit their ideas effectively. A certification in any of the relevant tools is a plus, along with experience in BI modeling or ETL tools. Applicants should be proactive and enjoy sharing their expertise. As a bonus, Thélio helps with housing in Bordeaux for a smooth transition into the company.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
463,56506,https://www.welcometothejungle.com/fr/companies/quanticfy/jobs/data-software-engineer_tunis_TQF_Jj3m1dV,Data Software Engineer,THE QUANTIC FACTORY,"{MySQL,PHP,Linux,GIT}",Télétravail partiel possible,Tunis,Big Data,CDI,2023-03-26,"Quanticfy est une solution SaaS d’analyse de données disponible pour les boutiques utilisant la plate-forme eCommerce Shopify. Elle propose de centraliser leurs data puis de les traiter à des fins d’attribution marketing et d’analyses clients. A propos de Shopify : il s’agit du CMS le plus populaire du moment, il réunit environ 2 millions de boutiques eCommerce du monde entier, le volume d’affaires que représente l’ensemble de ces boutiques se situe entre celui d’Amazon et celui d’EBay. L’ambition de Quanticfy est de démocratiser l’usage de la data auprès de tous les eCommerçants de cet écosystème, en leur apportant des solutions technologiques à haute valeur ajoutée, le tout dans un contexte où l’usage de la donnée se doit d’être exemplaire en matière de respect de la vie privée. Le Data Software Engineer prend en charge, spécifie, développe, documente et déploie des services applicatifs utilisés 24h/24 dans le monde entier. Rattaché.e à la DIRECTION TECHNIQUE, vous aurez à charge des missions telles que : Développer de nouveaux algorithmes pour toute la chaîne de traitement, notamment le traitement des données par Data Science ; Concevoir l’évolution des systèmes pour mieux répondre aux besoins de nos clients (devops) ; Rédiger des spécifications. Soutenu.e par notre Directeur technique vous développerez vos compétences techniques au sein d’une entreprise tournée vers l’excellence technologique. Vous vous verrez confier rapidement des responsabilités importantes et vous aurez l’occasion d’utiliser des technologies de pointe. The Quantic Factory développe des logiciels SaaS de synchronisation de données à destination des e-commerçants. VOTRE PROFIL Autonomie, responsabilité, créativité, forte dose d’apprentissage… sont pour vous des aspirations ! Nous recherchons un développeur doublé d’un chef de projet compétent, motivé, consciencieux, impliqué, capable d’imaginer rapidement des solutions simples à des problèmes parfois complexes. L’usage de méthodologies de travail dérivées des méthodes Agile (ex : Scrum) est déjà appréhendé. Vous êtes un bon communiquant ce qui vous permet d’évoluer dans des projets dont le contexte est collaboratif. Les qualités que nous recherchons avant tout : le pragmatisme et la rigueur, l’implication, la créativité, capacité de communication, et la soif d’apprendre. VOTRE FORMATION, VOTRE EXPERIENCE Issu(e) d’une formation technique (Ingénieur ou équivalent), vous : avez une expérience dans le développement de logiciels utilisant de la donnée de manière intensive avez déjà mené des projets techniques de A à Z (depuis les spécifications jusqu’à la livraison) COMPETENCES RECHERCHEES Indispensables : Programmation objet/système, Maîtrise d’au moins un langage backend Versionning sous GIT, Base de données : MySQL Linux. Appréciées : Devops, Anglais Environnement Google Cloud Platform, Architecture orientée service (SOA). PHP 7 Un à deux entretiens sont prévus (avec le CEO et le CTO) ainsi qu’un test technique.","Quanticfy seeks a data software engineer who will develop new algorithms for data processing, design system evolution, and write specifications for a SaaS data analysis solution. The ideal candidate should be autonomous, reliable, creative, and a good communicator with experience in developing software and leading technical projects. Proficiency in programming and system object, MySQL, Git, and Linux is a must, while experience in DevOps, SOA, and fluency in English is favourable. Quanticfy offers a collaborative environment that values pragmatism, diligence, creativity, communication, and continuous learning.",Bac +5 / Master,< 15 salariés,> 3 ans,2,0,0.027697749441558416
462,56304,https://www.welcometothejungle.com/fr/companies/d-edge/jobs/database-reliability-engineer-m-f-nb_paris,Database Reliability Engineer NB,D-EDGE Hospitality Solutions,"{Microsoft,GCP,Couchbase,MongoDB,Redis,color,MariaDB,Mysql,AWS,R,Elasticsearch,noSQL,Linux,Azure,NoSQL,SQL}",Télétravail partiel possible,Paris,"Digital Marketing / Data Marketing, SaaS / Cloud Services, Tourisme",CDI,2023-03-26,"Have you ever booked a hotel online? Then you’ve probably used D-EDGE without knowing it. Every day, we help more than 17,000 hotels worldwide to develop their online visibility and sales through a range of SaaS and digital marketing solutions. Amongst the 500+ D-EDGERS, the Tech and Product team is made up of a hundred or so enthusiasts who are reinventing hotel booking for both the traveller and the hotelier. As a subsidiary of the Accor group, D-EDGE simplifies the life of independent hotels and hotel chains alike. ABOUT THE TEAM: You will be joining the “Engineering Infrastructure Team” alongside Guillaume DEFENDINI , Skander REDJEL , Philippe BECHU , Gabriel GARCIA , Jeremy BOUCHET . You will be reporting to Julien SCHERER , Engineering Team Leader. The team focuses on the deployment of new infrastructure architectures and softwares to answer the business needs in accordance with the standards defined by the architecture team. Designing, Testing and Referencing solutions for the infrastructure of Tomorrow is the main goal accross all team members. Team conceives infrastructure for production team, for itself and for the business in a devops mindset and by discussing with the R&D department, mainly with the development tech leads and the software architects. ABOUT THE ROLE : As a DBRE, you will design, optimize, supervise and participate in the maintenance in operational conditions of the databases within our global Cloud infrastructure in order to meet the business requirements in terms of performance, availability, security and sustainability for our external customers and our internal uses. You will be the technical referent of the Database domain of the data architecture enabling a transformation to the Cloud by qualifying the health of the databases, their capacities, their performance, the debugging of the queries, the training of the internal development teams. MISSIONS: Maintain databases in optimal conditions (performance, availability). Automation of deployments / updates (Infrastructure as a Code) Risk and security management (DRP, How do we recover data? Does our backup granularity meet RPO requirements) Performance optimization of SQL/noSQL processing performed by our platforms in close collaboration with our development and architecture teams Supporting developers in the design of data structures and SQL/NoSQL development Develop the DEVOPS culture through the Dev / Ops teams Participation in the production releases of the components we develop and operate Supervision and analysis of Database activity, monitoring of jobs, incident management Security management in accordance with the internal PSSI and the standards in force, user management Management and supervision of data archiving and data structure cleaning Technical watch WHAT WE ARE LOOKING FOR: Bac+5 in IT 3 years experience minimum as DBRE (or similar) Very good knowledge of NoSQL/SQL databases (MongoDB, AWS Aurora, Couchbase, SQL Server, Mysql, MariaDB, …) Good knowledge of Cloud environments (AWS, Microsoft Azure, GCP or OVH) Good knowledge of distributed data storage (Elasticsearch, Redis..) Good knowledge of automation tools (Ansible, Terraform..) Competence on Linux technologies (Ubuntu / CentOS environment) and Microsoft Server Knowledge of the Agile / DevOps environment (Scrum - Kanban).Very good level of English (read / spoken / written). Good interpersonal skills, sense of service, analytical and synthesis skills, autonomy, versatility, dynamism and you have the ability to generate confidence in our business Communication skills, team spirit, intellectual curiosity, strength of proposal, reactivity, rigor, sense of responsibility and commitment WHAT WE OFFER: Attractive salary according to your profile D-Edge is Remote Friendly 50% of transport costs from home to work Meal Allowance (Swile : 9,48€/day, paid at 60%) Accor Employee Card : Discount on hotel bookings Incentives plans, bonuses and wage savings CSE: Sports and cultural activities, gift cards and various discounts Vendredi : Access a network of certified nonprofits to get involved in You will participate to our great internal invents: D-Convention: This is THE event that D-EDGERS are looking forward to D-Coffee roulette: Informal meetings between colleagues from all over the world. D-Summer Party: Annual meeting to spend a fun and friendly moment with all D-EDGERS 1) Telephone interview with Talent Acquisition 2) First interview with Infrastructure Team Lead 3) On-line Technical Test 4) Technical interview with team members 5) Interview with the Head of Infrastructure … and welcome to D-EDGE ! :) Please be aware that we will be asking for work references. D-EDGE is an equal opportunity employer. We do not discriminate based on : race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status.","D-EDGE is seeking a DBRE with a minimum of three years of experience and good knowledge of SQL and NoSQL databases, automation tools like Ansible and Terraform, cloud environments like AWS, Microsoft Azure, GCP, and OVH, and Linux technologies. The candidate should also have knowledge of the Agile/DevOps environment, strong analytical and synthesis skills, and be able to generate confidence for the company. The company offers an attractive salary, remote working, meal allowance, and discounted hotel bookings, among other incentives. The interview process comprises a telephone interview, technical tests, and multiple interviews with team members and the Head of Infrastructure.",Non spécifié,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
10,56410,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-cloud-poei_puteaux_DATAS_5xMkPLa,Data Engineer  | POEI,Datascientest,"{Microsoft,GCP,AWS,Azure,Java,Python}",Télétravail ponctuel autorisé,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"Vous êtes demandeur d’emploi et vivement intéressé(e) par les métiers de la Data ? Rejoignez DataScientest en intégrant une formation 100% financée par Pôle Emploi afin d’acquérir les compétences clés qui vous permettront de booster votre carrière en tant que Data Engineer Cloud, un métier en tension et en plein essor. Cette formation est certifiée par l’Ecole des Mines ParisTech, et inclut le passage de certifications éditeurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilité. Après avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire. Les candidats retenus bénéficieront d’une formation intensive, entièrement prise en charge par le dispositif POEI (Préparation Opérationnelle à l’Emploi Individuel) avec Pôle-Emploi. En tant que Cloud Data Engineer, vous aurez pour missions de proposer les meilleures solutions aux entreprises afin d’optimiser leur activité, à travers les missions suivantes : Développement de solutions permettant de traiter des volumes importants de données, Conception, collection et fabrication des données brutes, Création d’outils et algorithmes pour le traitement des données, Préparation des données pour le Data Analyst, Sécurisation des Pipelines données pour les Data Analysts et Data Scientists, Organisation de l’architecture du cloud Ce que nous vous offrons : Une certification de l’Ecole des Mines ParisTech Un CDI auprès de notre partenaire JEMS Group, expert européen dans le traitement et l’exploitation des données Un salaire attractif à la clé : 35 000€ à 48 000€ selon le profil Votre profil : Issu(e) d’une filière scientifique ou informatique vous disposez d’un bac+5 ou d’un diplôme d’ingénieur, Vous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la Data, Vous maîtrisez un langage objet type Java, Python, C++, etc. Vous êtes inscrit(e) à Pôle Emploi","DataScientest is seeking job seekers with scientific or computer science backgrounds to join their 100% funded training program to become a Cloud Data Engineer. The program is certified by the École des Mines ParisTech and includes certifications from AWS, Microsoft Azure, or GCP to increase employability. Graduates of the program will be offered a permanent contract to join JEMS Group as a Cloud Data Engineer with a salary ranging from €35,000 to €48,000. Ideal candidates have experience in computer development or data architecture and knowledge of object-oriented programming languages such as Java or Python. Applicants must be registered with Pôle Emploi.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,1,1,0.027697749441558416
81,73486,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-quality-engineer_paris,Data Quality Engineer,Groupe SeLoger,"{AZURE,python,java,scala,sql,javascript,AWS,GCP}",Télétravail partiel possible,"7 Boulevard Haussmann, Paris, 75009","Application mobile, IT / Digital, Média",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Français dans la réalisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d’offrir à chacun de nos utilisateurs, une expérience immobilière simple et efficace afin qu’ils concrétisent leurs projets d’achat, de vente ou de location en toute sérénité. Nous mettons à disposition des Français le plus large choix d’annonces afin de leur faciliter la recherche d’un bien selon leurs critères propres, et répondre à toutes les questions soulevées par la réalisation d’un projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque préférée des Français pour se repérer et se lancer dans leur projet immobilier. Ce que nous faisons dans le domaine Marketplace Design- Product and Tech à l'AVIV Le domaine Marketplace Design du groupe AVIV fait partie de l'organisation Product & Tech et son objectif est de fournir les services internes qui permettent aux équipes d'Acteurs d'apporter la sécurité, la fiabilité et de supprimer l'opacité de l'expérience. En s'appuyant sur l'expertise locale d'Immowelt (Allemagne et Autriche), Immoweb (Belgique), Groupe SeLoger et Meilleurs Agents (France), nous fournissons des services d'évaluation de la fraude, de la tricherie et de la fiabilité de l'information afin d'améliorer la sécurité et la fiabilité de la place de marché dans les interactions entre les chercheurs et les propriétaires/agents. Nous recherchons une personne qui: Fera partie d'une équipe agile, multidisciplinaire et internationale et travaillera en étroite collaboration avec elle pour Identifier les problèmes de qualité des données, et mettre en œuvre des solutions pour vérifier, valider et surveiller la qualité des données. Contribuer à l'analyse des problèmes de données et aider à identifier les processus opérationnels et les améliorations techniques qui contribuent à une meilleure qualité des données Travailler avec l'équipe produit pour établir des normes de qualité des données au sein des sprints, développer un plan de test et livrer des builds de haute qualité dans les délais. Travailler avec les propriétaires de produits et les ingénieurs de données pour améliorer l'expérience globale en suggérant des améliorations et des changements Concevoir et maintenir des rapports d'assurance qualité pour les systèmes de données internes Aligner et collaborer avec le reste de l'équipe de qualité des données pour améliorer la qualité globale, évaluer les risques, promouvoir la cohérence, identifier les besoins communs. Développer des stratégies de test pour l'automatisation à la fois pour le backend et les données Rédiger et exécuter des tests de données fonctionnels et non fonctionnels. Vous convainquez par votre esprit d'analyse Une personne qui a: Une solide expérience (au moins 3 ans) en tant qu'ingénieur en qualité des données Une expérience pratique de travail avec les méthodologies agiles Diplôme en informatique ou autres qualifications pertinentes La certification ISTQB est un plus Expérience pratique de la création et de la maintenance de tests ETL et API Expérience dans l'automatisation de tests de données avec des frameworks comme Deequ ou autres Expérience dans l'automatisation de tests d'API avec javascript ou des bibliothèques java comme fetch, superAgent, restAssured... Vous êtes à l'aise pour lire et écrire du code dans au moins un langage de programmation, idéalement java, scala, python Compréhension de base de sql Expérience avec les outils CI/CD Les bases de l'expérience du cloud comme AWS, GCP, AZURE sont un plus Un joueur d'équipe proactif qui analyse le risque et l'impact des problèmes et travaille avec l'équipe pour les prioriser et les résoudre Toute expérience en matière de tests de performance, GDPR, accessibilité, interopérabilité et sécurité est un plus Excellentes compétences en communication, avec une maîtrise de l'anglais. La volonté de voyager de temps en temps est disponible",,Non spécifié,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
194,56473,https://www.welcometothejungle.com/fr/companies/pass-culture/jobs/data-engineer_paris_PC_N4R853W,Data Engineer,pass Culture,"{Algolia,React,ElasticSearch,Tensorflow,Metabase,CloudSQL,Looker,Airflow,Kubernetes,Docker,github,GCS,K8s,Bigquery,GCP,Python}",Télétravail partiel possible,"89, Rue La Boétie, Paris, 75008","Application mobile, Musées / Institutions culturelles, Théâtre, Cinéma, Musique, Art / Marché de l'art",CDI,2023-03-26,"Le pass Culture est l’une des réformes prioritaires du gouvernement en matière culturelle. Il s’appuie sur une application gratuite et géolocalisée destinée à favoriser l’accès des jeunes aux arts et à la culture, encourager et diversifier leurs pratiques culturelles et artistiques. Le dispositif permet aux jeunes de bénéficier d’un crédit en fonction de leur âge (20 € à 15 ans, 30 € à 16 et 17 ans, 300 € à 18 ans), qu’ils peuvent dépenser dans une variété d’offres physiques ou numériques pour approfondir ou s’initier à une pratique artistique. En parallèle, un volet collectif, inscrit dans la politique d’Éducation Artistique et Culturelle (EAC) est directement attribué aux établissements scolaires. Chaque classe, de la 4ème à la Terminale, se voit allouer un crédit de 20, 25 ou 30 euros par élève, destiné à financer des activités effectuées en groupes et encadrées par les professeurs. Le pôle data est composé à la fois de data analysts, data scientists et data engineers qui travaillent en collaboration avec les différentes équipes du pass Culture (tech, produit, développement, programmation). Son rôle est de collecter et de transformer la donnée afin de créer de nouveaux services et de proposer des solutions aux différentes problématiques rencontrées. Le pôle est notamment en charge de la mise en place d’algorithmes ML (recommandation d’offres au utilisateurs, segmentation, alerting, …), de la mise en place d’AB tests sur le produit (utilisation de la recherche, la performance de la page d’accueil de l’application mobile, retention des utilisateurs et des acteurs culturels…), d’analyses sur les pratiques culturelles , de la mise à disposition de tableaux de bords pour les équipes interne ainsi que de la valorisation de la donnée à l’externe (institutions, partenaires et conférences). Cette équipe, au cœur du pass Culture, accompagne ainsi l’ensemble de l’organisation au coeur d’une politique publique qui cherche à intensifier et diversifier les pratiques culturelles des jeunes de 15 à 20 ans. Tu peux trouver plus d’information sur l’organisation produit sur cette fiche Notion . Au sein de l’équipe Data, tes missions seront : 💫 Conception, développement et responsabilité du datalake 🧠 Développement, supervision et amélioration des services data ML internes (API, Recommandation) 👷 Automatisation des pipelines et création de nouveaux modèles de données 🗺️ Participation à la stratégie data et aux rituels de notre pôle : stand-ups, démo, team building, etc 💫 Accompagnagment et coaching des data analysts & scientists sur leur problèmatiques engineering 🫶 Et surtout… tu souhaites relever le défi de porter la culture vers tous ! Notre stack : Data Visualisation : Metabase, Looker Infrastructure : GCP (Airflow, K8s, CloudSQL, VertexAI) Data Warehouse : Bigquery / GCS ML : Python / Tensorflow Cloud Management : Terraform Autres équipes : Python & React Native Autres services : Contentful, Algolia, ElasticSearch, GA Une bonne partie est open source, tu peux trouver les repos ici : https://github.com/pass-culture 👴 Tu as 4 ans d’expérience en tant que Data Engineer / ML Engineer 🧱 Tu as de solides compétences en ingénierie et en data science 🔮 Capacité à comprendre et à expliquer des architectures complexes 🌇 Expérience dans la construction et la maintenance de systèmes en production 💻 Maîtrise de Python, Docker, Airflow. Kubernetes est un plus 🤝 Esprit d’équipe et intérêt pour la mission du pass Culture entretien découverte avec le Lead Data entretien technique avec l’équipe entretien de motivation avec un Product Manager","The Pass Culture program is seeking a Data Engineer/ML Engineer to work with their data analysts, data scientists, and data engineers to collect, transform and analyze data to improve their services and address different challenges. The ideal candidate should have at least 4 years of experience, strong engineering and data science skills, and expertise in Python, Docker, and Airflow. They should also have an interest in the Pass Culture program's mission of intensifying and diversifying cultural experiences for 15-20-year-olds.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
68,57120,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_5N1XgoR,Data Engineer - Madonne Core,Natixis,"{SingleStore,Scala,via,Spark,SQL,Hadoop}",Télétravail partiel possible,"rue de montmartre, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking , financements, banque commerciale et sur les marchés de capitaux. Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050. Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne. Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque). Au quotidien vous avez pour missions de : Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ; Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ; Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ; Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk. #MuchMoreThanJustAJob Ce poste est basé à Paris avec la possibilité de télétravailler. En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours. Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier). Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala. Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data. Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé en répondant à cette annonce.","Natixis Corporate & Investment Banking, a top international financial actor, is seeking a developer proficient in Spark and Scala, with knowledge of Agile methodologies, C#, SQL, and an interest in market finance. The successful candidate will join the Core team responsible for maintaining and improving the Madonne and BOP applications, and will participate in modernizing the tools and processes. Fluency in English at the B1 level is required. Natixis is committed to environmental transition and offers an inclusive, hybrid work environment with opportunities for internal mobility, career development, and social engagement.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
73,56678,https://www.welcometothejungle.com/fr/companies/illuin-tech/jobs/data-engineer_neuilly-sur-seine,Data Engineer,ILLUIN Technology,"{UNIX,Scala,Kubernetes,AWS,Docker,R,Git,Java,NoSQL,SQL,Python,Bash,MLFlow}",Télétravail partiel possible,"183, Avenue Charles de Gaulle, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"ILLUIN Technology, c’est LA référence pour le développement de solutions technologiques de pointe en France. En à peine 6 ans, ILLUIN Technology est passée de 11 à 80+ Illuiners et a atteint un chiffre d’affaires de 7,2 M€ en 2022 en réalisant des projets sur mesure aussi diversifiés - IA, web, mobile, AR/VR, IoT, etc. - que bluffants sur le plan technique et UX. Le secret ? Leurs quelques 50+ clients grands comptes, startups, asso, etc. vous le disent : “ILLUIN, ce sont des personnes agréables, dotées d’un très haut niveau technique, polyvalentes et toujours engagées.” Et ce n’est pas tout ! Depuis 2 ans, la société propulse aussi ses propres produits utilisant l’état de l’art du NLU dans le domaine de l’IA conversationnelle et du traitement intelligent de document (parsing, search…). - Pourquoi nous rejoindre ? 🏅 Nous sommes certifiés HappyAtWork 2022 et avec le 2ème meilleur score des startups françaises 🌍 Nous donnons 1500€ à une association pour chaque cooptation et autant au cooptant 🚀 Nous avons un framework d’évolution clair et transparent qui permet de se projeter 💸 Nous proposons un package de rémunération des plus attractifs du marché et une évolution rapide 🌿 Nous donnons du sens au travail : coaching d’étudiants, Tech4Good, unité Data x Santé, startup studio… 😍 Nous valorisons plus que tout la bienveillance, la stimulation intellectuelle et l’équilibre pro-perso 💻 Nous travaillons sur du matériel haut de gamme (Macbook Pro / DELL XPS, écran QHD) → Votre mission En tant que Data Engineer, votre rôle sera d’industrialiser des solutions d’IA scalables à grande échelle, de développer des pipelines de transformation de données à gros volume ainsi que de mettre en place des solutions de stockage centralisé (data warehouses, data lakes). Ces solutions s’inscrivent dans le cadre de projets sur-mesure pour nos clients ou pour répondre aux besoins en data engineering de nos produits ILLUIN Technology. → Vos responsabilités Participer à la conception et l’optimisation de solutions technologiques traitant un gros volume de données à grande échelle et répondant aux besoins des utilisateurs/clients Réaliser des projets en équipe, encadré.e par des profils expérimentés qui vous feront monter en compétences Perfectionner ses compétences et chercher constamment à améliorer les outils et les méthodes employées (veille technologique, R&D, échanges de bonnes pratiques, hackathons) Participer à des code reviews avec les membres de votre équipe, challenger les implémentations, partager votre expertise et faire grandir les illuiners juniors autour de vous Prendre part aux cérémonies et sprint reviews en lien direct avec le client / nos équipes produits Participer au développement de projets internes transverses : recherche, OPS, sécurité, formations, … Participer à l’évolution de notre offre de Data Engineering en épaulant ponctuellement l’équipe commerciale grâce à votre expertise technique Nous cherchons le match parfait 💓 …mais nous croyons à la richesse des rencontres ! Alors si vous n’êtes pas certain.e de matcher notre recherche nous vous encourageons à nous contacter quand même ✉️ ✅ Must have Expérience avec un langage de programmation (Java / Kotlin / Scala / Python) Bonne compréhension des solutions de processing de données (queueing, streaming, batch processing, caching) Bonne compréhension des solutions de stockage données (bases de données SQL / NoSQL, data warehouse, data lake) Expérience avec Git et des outils d’intégration continue Expérience avec Docker 🌈 Nice to have Bonne compréhension du fonctionnement du Web Tests unitaires et d’intégration Expérience en OPS (Kubernetes, Terraform, Ansible, …) Expérience avec un framework back-end (Spring, Symfony, …) Utilisation de framework de MLOps / ML Engineering (Zen ML, ClearML, MLFlow, …) Connaissances de base UNIX & Bash Expérience sur des outils cloud (Google Cloud, AWS, OpenStack, …) Connaissances en IA / data science (machine learning, deep learning, NLP) 🤩 Les gens disent de vous que… Vous êtes engagé.e et prêt.e à donner le meilleur de vous-mêmes Vous êtes curieux.se, flexible, empathique, autonome Vous avez le sens du partage et le sens du travail en équipe Vous partagez nos valeurs : confiance, empowerment, excellence, innovation Après un 1er contact par téléphone, voici le processus : Test technique à distance (1h) Entretien Tech Live Entretien Human Fit Entretien Head of Software Engineering Entretien CEO","ILLUIN Technology is seeking a Data Engineer with programming experience in Java/Kotlin/Scala/Python and a good understanding of data processing, storage solutions, and Git. The role involves industrializing scalable AI solutions, developing pipelines for data processing, and centralizing storage solutions. The company values collaboration, personal development, and diversity. The recruitment process includes a technical test, two technical interviews, a Human Fit interview, and a final interview with the Head of Software Engineering and CEO. The company offers competitive compensations, promotes work-life balance, and supports various charitable causes. Nice-to-have skills include experience in OPS, web testing, cloud platforms, and AI/data science.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
75,56695,https://www.welcometothejungle.com/fr/companies/scalapay/jobs/data-engineer_barcelona,Data Engineer,Scalapay,"{Athena,Kubernetes,Glue,AWS,magic,S3,scale,Linux,Git,SQL,Python}",Télétravail partiel possible,"Barcelona, 08007","FinTech / InsurTech, Mode, Art de vivre",CDI,2023-03-26,"Scalapay transforme la façon dont les consommateurs réalisent leurs achats online et en magasin, en permettant aux commerçants d’offrir à leurs clients des expériences magiques. Avec plus de 4 000 détaillants dans les secteurs de la mode, de la beauté, de la maison et du voyage qui nous font confiance (Moschino, Calzedonia, Gérard Darel, Nike, Shein, pour n’en citer que quelques-uns), nous avons plus d’un million de clients qui utilisent Scalapay aujourd’hui en Europe. Après une série B de 497M$ en février 2022 menée par Tencent et Willoughby Capital, nous avons obtenu le statut de licorne ! Grâce à cela, nos équipes grandissent rapidement et nous recherchons des talents extraordinaires pour venir rejoindre l’aventure et nous aider à façonner l’avenir du paiement et des produits checkout dans l’écosystème eCommerce. Travailler avec nous signifie un quotidien où tout va très vite, où chacun a l’opportunité de mener des projets passionnants et stimulants, et de faire partie d’une équipe animée par 4 valeurs très fortes : #createmagic #staycurious #beimpactful #playasateam. Nous sommes fiers d’être l’une des 10 meilleures startups pour lesquelles travailler selon LinkedIn, et la startup de l’année 2021 en Italie. This is where your magic happens. If you love it, Scalapay it 🖤 Thanks to our innovative BuyNow PayLater payment solution, Scalapay is transforming the way more than 3.5 million customers buy online and in-store, empowering 5,000+ merchants to give their customers magical shopping experiences. Being only 3 years old didn’t stop us from becoming a unicorn 🦄 We have raised over $700mln and we did this thanks to a team built around our 4 core values: #createmagic #staycurious #beimpactful #playasateam. This is where your magic happens. If you love it, Scalapay it ♥ THE MISSION Data-driven decisions are the centre of our efforts to automate processes and support decisions across the business. As Data Engineer , your role will focus on developing distributed software for large-scale heterogeneous data processing, the development of ETL and reverse ETL pipeline. You will be responsible for: - Data modelling - Data lineage - Data quality / Data observability - SLA, performance and scalability You’ll be required to discuss requirements for data access and integrations with colleagues across the business, design solutions to the company’s problems and implement these using modern software processes in the cloud. The role gives a large amount of autonomy and the chance to work with a top-notch team of experienced data experts. Who we are looking for: - Strong Python and SQL experience - Experience building and deploying ETL pipelines - Experience with API integration - Ability to scope projects and decompose work into tasks - Familiarity with Linux-like development stacks, including Git, Kubernetes, etc - Familiarity with AWS infrastructure (such as S3, Athena, Glue, etc) - Knowledge of Data Modeling / Data Observability is a plus - Ability to engage with colleagues on business processes - A Bachelor's degree in computer science or a related field Why you should join Scalapay: - Attractive packages based on skills and experience - International environment with significant challenges to be met every day - Lots of opportunities to work with a team of industry tech leaders who are focused on delivering products that offer exceptional user experiences - Personalised support to accelerate your professional growth and take ownership of the products you deliver: we want to help you grow! - Latest technologies and being encouraged to bring your flair to the role Recruitment Process: 1) A quick chat with one of our Talent Acquisition team members 2) The first interview with the Hiring Manager to deep dive into your experiences and better understand your motivation 3) A case study to test your hard skills 4) A Meet The Team session where you’ll get to meet different people at Scalapay and see if you’ll fit into our culture _________________________________________________________________________ Want to learn more? Don't hesitate to explore our Careers website and Careers website, and our LinkedIn, WTTJ, Meritocracy and Glassdoor pages. Pro tip: send your CV in English 😉 Super Pro tip: we know that application processes can be scary and frustrating but… we look for talent, not people that tick all our boxes. We believe in the power of diversity: Scalapay is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation.","Scalapay, an innovative BuyNow PayLater payment solution transforming online and in-store shopping experiences, is seeking a Data Engineer to build and develop software for large-scale heterogeneous data processing, ETL and reverse ETL pipeline. The role requires strong Python and SQL skills, experience with API integration and Linux-like development stacks, among others. The ideal candidate will have a Bachelor's degree in computer science or a related field, and be able to engage with colleagues on business processes. Scalapay provides an international working environment, attractive packages, and personalized support for professional growth.",Bac +3,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
76,73482,https://www.welcometothejungle.com/fr/companies/neoxia/jobs/data-engineer-confirme-h-f,Data Engineer confirmé,Neoxia,"{Kafka,Kinesis,Snowflake,Redshift,Scala,Dask,Beam,Airflow,AWS,Pandas,Prefect,BigQuery,Azure,via,Spark,Java,Synapse,Python,Teradata,Hadoop,GCP}",Télétravail partiel possible,Paris,"Logiciels, IT / Digital",CDI,2023-04-22,"A chacun son domaine d’excellence, sa source d’expression ! Qu’ils soient Cloud-Native développeur, ou Product Designer, les Neoxiens de la Tribe Digital participent à la réalisation de projets ambitieux en s’appuyant sur les meilleurs écosystèmes Cloud (AWS, GCP, Azure) pour leurs Clients grands comptes ou Start-Up (comme Veolia, Free2Move, BlaBlaCar, JC Decaux, Eurosport, Pernod-Ricard, le Ministère de l’Éducation Nationale, Safran, Intermarché, Routard.com, PlayPlay…). Du coté de la Tribe Data, personne ne fait semblant. De la partie Engineering jusqu’à la partie Ops en passant par le Machine Learning, leur équipe de spécialistes en pleine croissance adresse tous les challenges autour des Datas qui les entourent. Cloud, Infra as Code et DevOps raisonnent comme un Eldorado ? Bienvenue chez SKALE-5, société du Groupe NEOXIA pure player du secteur ! Google Cloud, Amazon Web Service et Azure n’ont pas de secret pour eux. Être Neoxien ou Skaleur c’est être exigeant, c’est vouloir une maîtrise concrète des technologies car leurs métiers impliquent une réalisation sérieuse et soignée. Par ailleurs, ils sont convaincus que la réalisation de soi passe aussi par la satisfaction que l’on tire de son travail. C’est ici, dans un contexte bienveillant que vous trouverez la solidarité et l’entraide pour vous exprimer pleinement. Au sein de notre Tribe Data Participer à l’élaboration d’architectures cibles pour la collecte, le stockage, le traitement et l’analyse de données sur les plateformes cloud de nos partenaires AWS, Google, Azure Concevoir, développer et déployer des flux de données complexes sur des environnements cloud Assurer le suivi de la qualité des données collectées et traitées à travers la mise en place de tests automatisés Suivre la bonne application des règles de gouvernance des données à travers la mise en place d’outils dédiés Participer à la mise en place de plateformes data sur le cloud et au déploiement des outils nécessaires pour le traitement et l’analyse des données. Concevoir et déployer les outils nécessaires pour la mise à disposition des données pour les data scientists et pour les utilisateurs finaux des données Accompagner les data engineers / ops des squads projet par la formation, le coaching et la mise en place des bonnes pratiques Assurer une veille technologique et diffuser les connaissances via l’organisation d’ateliers au sein de neoxia ou de meetup ouverts à la communauté (ex Azure UG ) Tu interviendras également dans l’animation interne autour des différents sujets Data Engineering et Data Ops. Ainsi, tu devras : Assurer une veille technologique et diffuser tes connaissances via l’organisation d’ateliers au sein de neoxia ou de meetup ouverts à la communauté Intervenir au sein des guildes internes “Data Engineering” et “Data Ops / ML Ops” pour consolider les convictions de Neoxia et créer les supports nécessaires pour pouvoir partager ces convictions Accompagner les data scientists, data engineers et data ops des squads projet par la formation, le coaching et la mise en place des bonnes pratiques Diplômé(e) en ingénierie informatique Plusieurs expériences 100% Data à minima pendant 3 ans. Dynamique et rigoureux (se), tu as un bon relationnel. Tu es à la fois autonome et à l’écoute des autres. Tu es passionné(e) de technologie et curieux(se) au sujet de l’évolution des pratiques d’ingénierie logicielle (Continuous Delivery, DevOps, …) Compétences Expertise sur des technologies Cloud Data : GCP, AWS, Azure Expertise sur une solution de Data Warehousing : Teradata, BigQuery, Redshift, Synapse, Snowflake…. Expertise sur un outil d’orchestration de flux : Airflow, Prefect, Dragster…. Expertise de développement sur un framework de traitement de données : Pandas, Spark (Python, Scala, Java), Apache Beam ou Dask Connaissances autour de technologies de “event/stream processing” : Kafka, Kinesis, Pub/sub,… Connaissances liées à l’écosystème Hadoop serait un plus Connaissances en machine learning serait un plus Entretien téléphonique RH Test technique en ligne pour valider des pré-requis nécessaire pour nous rejoindre Un “use case” d’1h30 avec l’ un de nos lead tech Une dernière étape avec un manager ou un associé pour parler de tes motivations / envies et de la compatibilité de tout cela avec la culture neoxienne et le parcours",,Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
464,57076,https://www.welcometothejungle.com/fr/companies/health-data-hub/jobs/referent-donnees-dataops-h-f_paris,Référent données / data engineer,Health Data Hub,"{Jupyter,Microsoft,regard,Git,spark,GitLab,pandas,Gitlab,dask,GitHub,via,R,Spark,Azure,SQL,Python}",Télétravail partiel possible,"9 Rue Georges Pitard, Paris, 75015","Intelligence artificielle / Machine Learning, Santé",CDI,2023-03-26,"Comment améliorer les dépistages et faire en sorte que les patients soient pris en charge le plus tôt possible ? Comment leur proposer les meilleurs traitements sur le long cours ? Comment appuyer les professionnels de santé dans un contexte clinique qui se complexifie ou en cas de crise sanitaire ? L’Intelligence Artificielle et les données de santé font partie de la réponse. Elles sont incontournables pour la recherche et l’innovation en santé. Par exemple, pour prévenir des insuffisances cardiaques à partir de données issues d’appareils connectés, ou pour accélérer le dépistage du cancer du sein à partir d’analyses automatiques des examens de mammographies. Ou même pour réunir assez d’informations afin d’améliorer la prise en charge des maladies rares. Et pour ça, la France a la chance de disposer de bases de données extrêmement riches ! Mais ces données sont souvent sous exploitées car dispersées. Grâce à des solutions innovantes telles que l’IA, l’objectif du Health Data Hub est justement de permettre d’accéder de manière facilitée; unifiée, transparente et sécurisée à un catalogue de bases de données de santé françaises. Comment ? Le Health Data Hub a mis en place une plateforme technologique qui met à disposition des porteurs de projets d’intérêt public, dans un environnement technologique sécurisé et à l’état de l’art, les données de santé pseudonymisées des français. Ces porteurs de projets vont mobiliser des sources de données très volumineuses, les croiser entre elles, et utiliser une puissance de calcul pour faire tourner des algorithmes de recherche complexes. Il s’agit par exemple de projets de start-up pour améliorer des logiciels d’aide au professionnel de santé, de projets permettant d’améliorer la prise en charge des patients en comparant l’efficacité de prise en charge, de projets portés par les administrations pour éclairer les politiques publiques. Notre offre technologique, en constante évolution, peut être consultée ici. Les défis sont de taille pour traiter ces données de santé sensibles, volumineuses de natures et formats variables. La plateforme doit être un levier d’innovation dans l’écosystème de la donnée de santé français. En résumé, avec le Hub, nous accompagnons des porteurs de projets innovants qui contribuent à trouver les solutions de demain pour améliorer la santé de tous les citoyens. Direction des données : Pour mener à bien les missions qui lui ont été confiées, le Health Data Hub a formé la direction des données dont les objectifs principaux sont de : Définir des stratégies novatrices sur la gestion, l’exploitation et le partage de données de santé, permettant de réaliser la vision du HDH ; Partager et mutualiser les outils et les connaissances nécessaires à l’analyse des données de santé, dans le cadre d’une démarche open source. Gérer et mettre à disposition les données qui lui sont confiées aux porteurs de projet au sein de la plateforme technologique du Health Data Hub ; Soutenir les projets d’intérêt public que le HDH accompagne, aussi bien sur la compréhension des données de santé que sur leur exploitation via des experts des données de santé, des data scientists et des data engineers. Pôle “Gestion des données” : Pour répondre à la troisième mission qui lui a été conférée et définir une approche claire pour l’écosystème de la santé, la direction des données s’est dotée d’un pôle “Gestion des données”. Ce pôle est responsable de l’intégralité du cycle de vie des données, et se structure autour des chantiers suivants : Traitement des données de santé massives et diverses transmises par les porteurs de projet à la plateforme technologique du Health Data Hub ; Gestion et mise en qualité des données de santé stockées dans la plateforme technologique du Health Data Hub ; Développement de librairies en Python ou R pour faciliter, automatiser et systématiser les traitements des données cités précédemment ; Analyses exploratoires de nouvelles fonctionnalités et applications (e.g., cluster spark, lecteur d’images spécifiques au secteur de la santé) à intégrer à la plateforme technologique du Health Data Hub. Ces missions sont essentielles pour garantir la fiabilité des recherches menées sur la plateforme technologique et présentent d’importants défis au regard du caractère hétérogène des données manipulées (e.g., données médico-administratives, imagerie médicale, compte-rendus médicaux) et des efforts nécessaires pour les rendre utilisables. Activités du poste : En tant que data engineer ayant le rôle de “référent des données”, au sein du pôle “Gestion des données”, vous aurez pour missions de : réaliser les traitements nécessaires pour la bonne gestion du parcours des données présentes sur la plateforme technologique du Health Data Hub : collaborer conjointement avec la Direction Projets et Services utilisateurs et prendre connaissance du protocole scientifique et des buts premiers de chacun des projets accompagner. Cette phase s’accompagne d’une découverte du ou des jeu(x) de données complet(s) tant au niveau fonctionnel qu’au niveau technique; documenter et définir les conditions d’import des données sur la plateforme, en relation avec des acteurs externes (producteurs de données, porteurs de projets de recherche) ; travailler dans la plateforme technologique du Health Data Hub ; utiliser les librairies existantes et les compléter pour développer des scripts Python et PySpark permettant de manipuler des grande quantite de données (~To) sous différentes formats (e.g., tabulaires, texte libre, images, JSON) reçues sur la plateforme technologique. vérifier l’intégrité, confidentialité et conformité à certains critères de qualité définis en amont ainsi que de de les préparer pour leur mise à disposition (e.g., reformatage, jointure, transformation) ; contribuer à la documentation de ces opérations. développer et gérer les outils logiciels internes à la direction des données : définir l’architecture des librairies logicielles servant à automatiser les étapes de traitement des données ; développer, documenter, tester et maintenir ces librairies ; optimiser le traitement de jeux de données de grande taille (plusieurs téraoctets) pour minimiser les coûts et délais de traitement ; adapter les librairies pour permettre de traitement de données diverses (comptes-rendus médicaux, images d’IRM, bases hospitalières, bases nationales) ; collaborer avec le reste du pôle en suivant la méthodologie Agile-scrum (gestion d’un backlog, rituels scrum, etc.) en s’appuyant sur des pratiques de développement à l’état de l’art (notamment, intégration continue via GitLab). développer et gérer les outils à destination des utilisateurs de la plateforme : accompagner l’équipe produit dans l’identification ou l’étude de nouvelles fonctionnalités à intégrer à la plateforme technologique auprès des utilisateurs (e.g., producteurs de données, porteurs de projets, équipe des référents des données) pour garantir un service adapté, et inscrire les demandes de nouveaux développements ou rapports de bugs dans le backlog produit ; tester, via le développement de prototypes, de nouvelles technologies à intégrer à l’offre technologique de la plateforme pour répondre aux mieux aux besoins des utilisateurs, en collaboration avec les équipes Produit et Plateforme du Health Data Hub ; configurer, une fois le prototype validé, la technologie avant son intégration dans la plateforme technologique par la Direction technique du Health Data Hub. La tech stack (pile de technologies) utilisée pour ces missions sera principalement : Python comme langage de programmation généraliste notebooks Jupyter pour accéder à la plateforme et organiser la documentation d’utilisation (tutoriels) pandas pour l’analyse des données CSV de petite taille et Spark / pyspark pour les données volumineuses pytest pour les tests de librairies Gitlab pour la gestion du développement et l’intégration continue Microsoft Azure pour le stockage et le requêtage de données volumineuses Suite Google pour la bureautique (Google Docs, Google Sheets, etc.) Pour les besoins des utilisateurs externes, certaines librairies sont également développées et maintenues en R / sparklyR. Dans le cadre des projets d’accompagnement du HDH auprès de nos partenaires, vous pourrez être amené(e) à vous rendre disponible et vous mettre à disposition selon les besoins auprès d’institutions du domaine de la recherche médicale en région parisienne. Compétences indispensables Excellente maîtrise du langage Python Bonne maîtrise de SQL et de gestion de bases de données Bonne maîtrise des librairies de traitement de données (e.g., pandas, dask, dplyr) Connaissance des différents paradigmes de développement de librairies et applicatif (e.g., orienté objet, fonctionnel) Connaissance des outils en ligne de travail collaboratif type Git (GitHub ou GitLab) Capacités rédactionnelles Bon relationnel : capacité à interagir avec les partenaires externes du HDH (startups, institutions publiques, etc.) Compétences additionnelles recherchées Maîtrise des frameworks de calcul distribué (Spark) Maîtrise de R Maîtrise d’environnements cloud (notamment Azure) Expérience avec des formats de données complexes (par exemple : images DICOM, JSON complexes, CSV de très grande taille etc.) Connaissance des approches de développement (notamment CI/CD et DevOps) Connaissance de la méthodologie Agile/scrum Une expérience dans le domaine de la recherche médicale est un plus. POURQUOI CHOISIR LE HEALTH DATA HUB ? Vous êtes motivé(e) à rejoindre une équipe impliquée dans un projet ambitieux, qui a du sens et une finalité d’intérêt public ? Rejoignez-nous ! Notre récente structure a besoin de talents créatifs, autonomes et proactifs pour continuer de grandir ! Ensemble, nous nous sommes engagés à : Accompagner les porteurs de projet visant à analyser les données de santé pour le bien commun. Construire et opérer une plateforme technologique pour leur offrir les meilleurs outils avec un très haut niveau de sécurité à respecter. Réunir et mettre en forme les données au plus grand potentiel pour la recherche et l’innovation. Promouvoir le partage des connaissances, des expertises et du savoir et diffuser une culture de la donnée de santé auprès de tous. Bon à savoir: 💪 Rejoindre le HDH c’est surtout participer à un projet enrichissant humainement qui a du sens, avec un fort impact sociétal 🏆 Au HDH on favorise la prise d’initiative, dans une ambiance de challenge perpétuel 😎 Ici la bonne humeur et l’esprit d’équipe règnent Après avoir postulé, voilà comment se déroulera le recrutement: Un premier entretien avec un membre de l’équipe Une mise en situation à préparer chez soi Un entretien technique, basé sur la mise en situation, avec un membre de l’équipe et le Directeur Data Un entretien avec la directrice du Health Data Hub Un entretien de formalité RH","The Health Data Hub is seeking a Data Engineer to work within the Data Management team to manage and manipulate large sets of health data. The role involves working with Python, notebooks Jupyter, Pandas, Spark, and SQL to develop and manage libraries and software tools to handle, process and store large amounts of data. The engineer will also work with stakeholders to communicate project requirements and ensure data quality. The ideal candidate will have experience in Agile and Scrum methodology, and experience with healthcare data formats, cloud environments, and dev-ops approaches would be helpful. The Health Data Hub is looking for a candidate who is proactive, autonomous, and driven to join a team working on an ambitious project with a strong social impact.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
212,65937,https://www.welcometothejungle.com/fr/companies/gleamer/jobs/data-engineer_paris,Medical Data Engineer,GLEAMER,"{Java,regard,Python}",Télétravail ponctuel autorisé,"117, Quai de Valmy, Paris, 75010","Logiciels, Intelligence artificielle / Machine Learning, Santé",CDI,2023-04-05,"GLEAMER met l’intelligence artificielle au service des médecins en développant des solutions capables de sécuriser leurs diagnostics et d’améliorer leur environnement de travail. Plus que des logiciels, ses produits sont de véritables compagnons de travail pour les médecins utilisateurs. Ils agissent comme une seconde lecture automatisée et transparente. Actuellement en pleine croissance, GLEAMER a l’ambition de révolutionner le monde de l’imagerie médicale grâce à une technologie de pointe. 🚀 Mission L’interdisciplinarité est un des piliers de GLEAMER. Chaque Data Engineer collabore avec les membres de l’équipe Data, permettant le partage d’expériences et de bonnes pratiques, mais est aussi associé à une Squad, en charge du développement et/ou de l’amélioration d’un produit et inclut des membres des équipes Médicale, Produit, IA, Data, Clinique et QARA. Responsable de la partie Data au sein de la Squad que tu intégreras, tu auras un rôle décisif dans la conception et l’amélioration de dispositifs médicaux innovants et ambitieux. Ta mission principale sera de participer activement au développement de nos produits futurs en imagerie 3D et à l’amélioration continue de nos produits existants BoneView et ChestView à travers les différentes tâches qui te seront confiées. 💻 Responsabilités Participer à la définition de la stratégie d’annotation et des besoins en données en collaboration avec les membres de ta Squad et de l’équipe Data Assurer en binôme avec le radiologue référent la qualité et le suivi des annotations Participer aux formations des annotateurs en collaboration avec l’équipe Médicale Participer à la réflexion sur les outils utilisés, à l’amélioration des outils internes, et notamment assurer l’enrichissement des méthodes de traitement du langage pour l’optimisation de l’annotation Participer au processus d’import de données en assurant le bon déroulement des exports en court, en aidant à la mise en place de nouveaux exports et en prenant part au contrôle qualité des données récupérées En tant que membre de l’équipe Data, tu pourras aussi être amené(e) à : Participer à des tâches en lien avec nos autres produits, existants ou à venir Assurer l’intégrité de la base de données ; Participer à des tâches en lien avec les études cliniques. 📌 Hard skills Connaissances en Python et/ou Java Connaissances en base de données Bon niveau d’Anglais 📌 Soft skills Fort intérêt pour le domaine médical (des connaissances en imagerie médicale/norme Dicom sont un plus) Rigueur scientifique et regard critique indispensables Bonnes capacités de communication 🎓 Profil recherché Niveau d’étude Bac +5/Master, profils junior acceptés 💵 Salaire 40 000€ - 50 000€ selon profil et expérience","Data Engineer role at GLEAMER involves working with interdisciplinary teams to develop innovative medical imaging products that use artificial intelligence to enhance the medical diagnosis process. The main responsibility involves participating in the development of future 3D imaging products and enhancing existing products' BoneView and ChestView continuous improvement. The ideal candidate's hard skills include knowledge of Python, Java, and database with a good level of English. The candidate must also possess a strong interest in the medical field, scientific rigor, critical thinking, and excellent communication skills. Candidates with Bac+5/Master's degree and junior profiles are welcome to apply with a salary range of €40k-€50k commensurate with experience.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,1,1,0.027697749441558416
201,57146,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_paris,Expert.e technique ETL Semarchy xDI / Stambia,CGI,{},Télétravail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Semarchy xDI / Stambia • Participer aux échanges avec l’éditeur Semarchy • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné.e d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert.e technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a leader in digital consulting and services, is seeking a Data Integration Expert with experience in ETL Semarchy xDI/Stambia to work on national and international projects across various industries. Responsibilities include analysis, collaboration with engineers, developing technical documentation, and providing technical support to clients. The successful candidate must have at least three years of experience as a technical expert in data integration and be a team player with an ambitious and proactive mindset. Knowledge of data quality and governance is a plus. CGI is an inclusive employer committed to diversity, work-life balance, and career advancement for all employees.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
243,56562,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_85eO0j8,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",Télétravail partiel possible,"Courbevoie, 92014",Energie,CDI,2023-03-26,"Enedis est une entreprise de service public, gestionnaire du réseau de distribution d'électricité. Elle développe, exploite, modernise le réseau électrique et gère les données associées. Elle facilite la transition énergétique des territoires en les accompagnant dans le développement et la planification de leur production d'électricité d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le dépannage 24h/24, le relevé des compteurs et toutes les interventions techniques. Indépendante, Enedis délivre la même qualité de service aux fournisseurs d'énergie. Comme le prévoit la loi, elle a établi un code de bonne conduite auquel ses collaborateurs sont formés afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des métiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilité du Système d'information dans un contexte de forte numérisation des métiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engagée notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Système d'Information à la transformation numérique ou dans le positionnement d'Enedis comme opérateur de données, la DSI met en oeuvre de nombreux projets majeurs en lien avec les métiers concernés. Chez Enedis comme chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez Enedis même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Le monde de l'IT et des nouvelles technologies vous intéresse ? Contribuer à la réussite de la transformation digitale et numérique du Groupe EDF vous plairait ? Et travailler en mode collaboratif dans des espaces de travail innovants, inspirants et épanouissants ? C'est ce que nous vous proposons en rejoignant une équipe dynamique, agile et passionnée ! Un des enjeux majeurs d'Enedis est de devenir un opérateur de confiance de Données énergétiques. Afin de répondre à cet enjeu, Enedis a mis en place une plateforme de données pour l'entreprise. Cette plateforme est composée d'une infrastructure de données centralisée construite sur Hadoop et d'outils à destination des équipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'améliorer cette plateforme sur plusieurs axes : migration vers le cloud, évolution de l'architecture avec en cible une plateforme modulaire composant des services managés, automatisation et montée en gamme de l'offre de services internes permettant aux équipes de gagner en autonomie dans la création de véritables produits de données. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des équipes du train SAFe DataServices4U - équipe SPHINX, en charge de l'infrastructure data des activités exploratoires (big data, big mem, GPU) - définira, développera, mettra en place et maintiendra les outils et infrastructures adéquats aux opérations du reste du train (équipes data scientists et data engineers). - veillera à garantir les opérations des solutions permettant le traitement de volumes importants de données tout en garantissant la sécurité de celles-ci - définira les enablers à prendre en compte dans l'équipe - sera Tech. Lead d'une équipe d'une dizaine de personnes - testera les réalisations de l'équipe - contribuera aux démonstrations faites aux équipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous êtes issu d'une formation de type Bac +5 dans le domaine de l'IT / système d'information / Numérique et DATA - Vous disposez d'une expérience d'au moins 4 ans dans des activités équivalentes, au cours desquelles vous avec avez développé de solides compétences techniques - Vous avez un profil Ingénieur Big Data disposant de compétences d'analyse, de synthèse, de créativité et d'une appétence pour l'innovation. - Vous avez de bonnes connaissances de l'administration système UNIX : maîtrise de Linux (Redhat), Bash - ainsi que composants sécurité et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacités de communication (orales et écrites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacités de coordination - Vous faites preuve de curiosité, d'esprit de synthèse, de méthodologie et de rigueur dans un environnement complexe Le poste est situé à Courbevoie, avec une possibilité de télétravail partiel. La rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","Enedis is seeking a System Team Engineer DataOps with a background in IT or data to become a technical leader of one of their teams to define, develop, implement, and maintain the tools and infrastructure needed to operate the big data, along with ensuring the safety of the data. The ideal candidate should have knowledge of UNIX system administration, Hadoop, Spark, Teradata, Kafka, and Python, along with excellent coordination and communication skills. The position offers competitive compensation and benefits and is located in Courbevoie, with the possibility of partial telecommuting.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
211,65931,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-f-h_toulouse_MERIT_Lgr6GVy,Data Engineer,Meritis,{Java},Télétravail ponctuel autorisé,"Place du Capitole, Toulouse, 31000","IT / Digital, Finance",CDI,2023-04-05,"Meritis est une société de conseil en transformation des Systèmes d’Information et Organisations. Notre mission : associer les meilleurs talents à l’élaboration de transformations créatrices de valeur. Nous sommes une entreprise où il fait bon travailler ! Régulièrement labellisée Great Place To Work ® : N°3 GPTW en 2020, N°1 GPTW en 2017, N°7 GPTW en 2015, N°5 GPTW en 2013. En 2021 Meritis est classée 11e du Palmarès Européen des Best Work Places. 👉 GPTW Au sein du pôle Data IA, vous intégrerez les équipes qui sont responsables de la collecte des données, vous serez en charge de : Récupérer, organiser et mettre en forme la donnée Développer de nouvelles fonctionnalités Réaliser les tests techniques Faire évoluer l'architecture Produire la documentation Encadrer une équipe de développeur Prêt.e à démarrer de nouveaux challenges dans une entreprise où il fait bon vivre ? Meritis offre à ses collaborateurs : • Un accompagnement personnalisé tout au long de leur carrière, • Des parcours professionnels sur mesure : choix des projets, évolution de carrière, formations adaptées et mentoring. Mais aussi de : • Bénéficier d’un réseau de clients riche et varié, • Travailler dans un environnement convivial avec de nombreux événements festifs et techniques, • Envisager des mobilités géographiques internes grâce au maillage régional du groupe. Nos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Vous avez un diplôme d’ingénieur (Bac+5), une spécialisation dans l'ingénierie informatique est un plus Vous disposez de plus de 7 ans d'expérience en développement Java Vous êtes autonome, rigoureux.se et organisé.e Vous êtes bilingue Anglais","Meritis, a consultancy firm in Information Systems and Organizational transformation, seeks a Java Developer with over 7 years of experience in Java development to join its Data IA team. The successful candidate will be responsible for collecting data, developing new features, testing technical aspects, evolving architecture, documentation, and leading a team of developers. Meritis encourages diversity and non-discrimination, and all their jobs are accessible to people with disabilities. The ideal candidate must have a master's in engineering, a specialization in IT engineering is desirable, be autonomous, organized, and bilingual in English. Meritis offers customized career paths, variety in clients, and internal geographical mobility.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,1,1,0.027697749441558416
248,56621,https://www.welcometothejungle.com/fr/companies/airbus-1/jobs/engineering-data-custodian-f-m_toulouse,Engineering Data Custodian (f/m),AIRBUS,"{via,GO}",Télétravail ponctuel autorisé,Toulouse,"Cybersécurité, Aéronautique / Spatiale",CDI,2023-03-26,"Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world’s leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. About us Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world’s leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. Job description Airbus Commercial Aircraft is looking for an **Engineering Data Custodian (f/m) to join our Architecture and Integration department based in ** Toulouse, France. ** You will be part of a team developing processes and methodologies for the Systems engineering domain. As part of the Systems Engineering Office team, you will support the Systems Engineering process, culture, competency and discipline, on day-to-day business activities, enabled by adequate Methods & Tools (M&T) products and services. This support spans all aspects of the Systems life cycle. Your working environment: Global capital of aeronautics and European capital for space research, Toulouse is a dynamic city in the southwest of France served by an international airport. Ideally located between the Mediterranean sea and the Atlantic ocean and close to the Pyrenees mountains, it offers plenty of options for outdoor activities! How we care for you: **Financial rewards: **Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis. **Work / Life Balance: **Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services. **Wellbeing / Health: **Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application. Individual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking. Your challenges: Contribute to the engineering global picture in data/digital asset development and in the equipped framework blueprint. Under engineering common blueprint constraints, develop, execute, and supervise plans, policies, programs and practices that deliver, control, protect, and enhance the value of data and information assets throughout their life cycles. Improve existing, or implement new, processes/methodologies to support the business needs and the current challenges. Support team to help them adopt change. As part of the assessment board of the data/digital asset development quality package, provide the GO/NOGO of the data/digital asset deployment and commissioning based on Accountable for the well application and respect of data management frameworks used in data/digital asset development. Your boarding pass: Min 5 years of professional experience in an engineering business, ideally in aeronautics Strong process-minded approach. Prior experience in Functional Data of business processes and related processes. Good understanding of Data Architecture, Data Design and Modelling, Data Intelligence, Science and Analysis Ability to understand business needs and challenges in order to convey them via processes/methodologie. Leadership skills to carry change and to ensure adhesion or team members. Ideally a prior experience in change management. Comfortable working within an unclear/unidentified workframe Good communication skills, including strong competence in English language Many of our staff work flexibly in many different ways, including part-time. Please talk to us about the flexibility you need during the interview and we’ll always do our best to accommodate your request. Salary range: Salary range based on the required profile: 55,000 to 65,000 €/year (including a variable part based on your performance). Information provided as an indication. Not a 100% match? No worries! Airbus supports your personal growth with customized development solutions. Take your career to a new level and apply online now! #LI-AS1 This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company’s success, reputation and sustainable growth By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus. Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.","Airbus is seeking an Engineering Data Custodian to join their Architecture and Integration department in Toulouse, France. The role involves supporting the Systems Engineering process and improving processes and methodologies for the Systems engineering domain. The ideal candidate should have experience in engineering, strong process-minded approach, and leadership skills. Airbus offers financial rewards, work/life balance, wellbeing/health benefits, individual development opportunities, and flexible working arrangements. The salary range for the position is €55,000 to €65,000 per year. Airbus is committed to achieving workforce diversity and an inclusive working environment.",Bac +5 / Master,> 2000 salariés,> 4 ans,1,1,0.027697749441558416
434,49780,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",Télétravail partiel possible,"Courbevoie, 92014",Energie,CDI,2023-02-07,"Enedis est une entreprise de service public, gestionnaire du réseau de distribution d'électricité. Elle développe, exploite, modernise le réseau électrique et gère les données associées. Elle facilite la transition énergétique des territoires en les accompagnant dans le développement et la planification de leur production d'électricité d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le dépannage 24h/24, le relevé des compteurs et toutes les interventions techniques. Indépendante, Enedis délivre la même qualité de service aux fournisseurs d'énergie. Comme le prévoit la loi, elle a établi un code de bonne conduite auquel ses collaborateurs sont formés afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des métiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilité du Système d'information dans un contexte de forte numérisation des métiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engagée notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Système d'Information à la transformation numérique ou dans le positionnement d'Enedis comme opérateur de données, la DSI met en oeuvre de nombreux projets majeurs en lien avec les métiers concernés. Chez Enedis comme chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez Enedis même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Un des enjeux majeurs d'Enedis est de devenir un opérateur de confiance de Données énergétiques. Afin de répondre à cet enjeu, Enedis a mis en place une plateforme de données pour l'entreprise. Cette plateforme est composée d'une infrastructure de données centralisée construite sur Hadoop et d'outils à destination des équipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'améliorer cette plateforme sur plusieurs axes : migration vers le cloud, évolution de l'architecture avec en cible une plateforme modulaire composant des services managés, automatisation et montée en gamme de l'offre de services internes permettant aux équipes de gagner en autonomie dans la création de véritables produits de données. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des équipes du train SAFe DataServices4U - équipe SPHINX, en charge de l'infrastructure data des activités exploratoires (big data, big mem, GPU) - définira, développera, mettra en place et maintiendra les outils et infrastructures adéquats aux opérations du reste du train (équipes data scientists et data engineers). - veillera à garantir les opérations des solutions permettant le traitement de volumes importants de données tout en garantissant la sécurité de celles-ci - définira les enablers à prendre en compte dans l'équipe - sera Tech. Lead d'une équipe d'une dizaine de personnes - testera les réalisations de l'équipe - contribuera aux démonstrations faites aux équipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous êtes issu d'une formation de type Bac +5 dans le domaine de l'IT / système d'information / Numérique et DATA - Vous disposez d'une expérience d'au moins 4 ans dans des activités équivalentes, au cours desquelles vous avec avez développé de solides compétences techniques - Vous avez un profil Ingénieur Big Data disposant de compétences d'analyse, de synthèse, de créativité et d'une appétence pour l'innovation. - Vous avez de bonnes connaissances de l'administration système UNIX : maîtrise de Linux (Redhat), Bash - ainsi que composants sécurité et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacités de communication (orales et écrites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacités de coordination - Vous faites preuve de curiosité, d'esprit de synthèse, de méthodologie et de rigueur dans un environnement complexe Le poste est situé à Courbevoie, avec une possibilité de télétravail partiel. La rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","Enedis is seeking a System Team Engineer DataOps with a Bachelor's in IT, digital and data, and a minimum of four years related experience. The successful candidate will be responsible for the technical leadership of an Enedis team in charge of the infrastructure data of exploratory activities, developing and maintaining appropriate tools and infrastructures, ensuring data security, testing team achievements, and working with an agile team of over 10 other tech leaders. The position is based in Courbevoie and offers the possibility of partial remote work.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
245,56949,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-f-h_nanterre_AXA_V4Ra50p,Data Engineer,AXA,"{Microsoft,Databricks,Git,PowerBI,Spark,Azure,NoSQL,Python}",Télétravail partiel possible,"313 Terrasses de l'Arche , Nanterre, 92727","Banque, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l’assurance et de la gestion d’actifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous protéger en donnant à chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! Le Développeur Big Data contribue directement aux projets des directions métier d’AXA France (ex : fraude santé, multiéquipements, pricing IARD, optimisation du lead management, fragilité auto, …) & à la construction du socle technique Big Data. Il a pour missions principales de développer les projets Big Data demandés par le métier, et notamment : a. Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requetables dans le datalake (inférer les schémas de données, nettoyer et normaliser les données, publier les données)b. Consolider ces données au fur et à mesure de leur alimentation récurrente dans le data lakec. Les exploiter pour atteindre la finalité business (exposition de business view, réintégration des résultats dans le SI, service de scoring, …)d. De travailler à la création du socle technique Big Data (librairies de fonctions, features communément utilisées avec les data scientists…) et industrialiser le cycle de développement de l'équipee. De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)f. D’accompagner les développeurs plus juniors de l’équipe (coaching, code review, pair programming…) De Formation scientifique (école d’ingénieur, école d’informatique), vous justifiez de: - Au moins 3 ans d’expérience professionnelle tous langages confondus - Au moins 1 an d’expérience professionnelle en développement Big Data avec PySpark (Spark en Python) Dans l’idéal vous avez eu une expérience professionnelle sur le cloud Microsoft Azure avec des outils comme Azure Databricks Azure Data Lake Storage et Azure Data Factory. Vous avez l'habitude des cycles de développements courts en mode Agile ainsi que des outils associés: - Gestion de sources Git sur Azure DevOps - Intégration & déploiement continue avec Azure Pipelines - Gestion des artefacts avec Azure Artifact Ces connaissances supplémentaires seraient un plus : - Cloud Microsoft Azure - Traitements Big Data en mode Streaming - Bases de données relationnelles et NoSQL - Outils de BI (PowerBI, Spotfire) De nature pragmatique, vous êtes capable de travailler en autonomie pour livrer du code de qualité satisfaisant des besoins métiers. Vous avez de bonnes aptitudes relationnelles, et vous faites preuve d’une grande curiosité et de capacité d’innovation et d'adaptation.","AXA is looking for a Big Data Developer to work on projects requested by AXA France business units and to contribute to the construction of their Big Data technical base. The developer will be responsible for developing Big Data projects, consolidating data, analyzing data, creating technical tools and functions, providing coaching and support to junior developers, and ensuring quality throughout the development cycle. The ideal candidate should have at least 3 years of professional experience, 1 year of experience in Big Data development using PySpark, and knowledge of Azure cloud and associated tools, Git, Azure Pipelines, Azure Artifact, and BI tools. Good communication and innovation skills, pragmatic work style and ability to work autonomously are essential.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
37,60592,https://www.welcometothejungle.com/fr/companies/extracadabra/jobs/data-engineer-f-h_paris_EXTRA_7lP8NMM,Data Engineer,Extracadabra,"{PowerBI,Redash,SQL,Zeppelin,Tableau}",Télétravail partiel possible,"82, rue d'Hauteville, Paris, 75010 ","Application mobile, FoodTech",CDI,2023-03-28,"Extracadabra c’est une mission : simplifier l’emploi dans le domaine de l’hôtellerie-restauration, du retail et de la logistique. Créé en 2015 par Frédéric Nardon et Rémi Boisson Extracadabra est l’app qui met en relation des candidats Extra ou CDI avec des établissements grâce à un système de matching hors du commun avec son équipe de maintenant 40 personnes. Elle a notamment été élue meilleure plateforme spécialisée en hôtellerie-Restauration dans le palmarès 2021 des plateformes de travail réalisée par Mounir Mahjoubi, député et ex-Secrétaire d’État au Numérique. Extracadabra a levé près de 3 Millions € auprès de BPI Tourisme, Side Capital, Sowefund et des fondateurs de La Fourchette et Doctolib et compte bien consolider sa position de leader dans le secteur de l’hôtellerie-restauration. Bien plus qu’une application ou un site c’est une relation privilégiée avec 10 000 établissements partenaires en France ( Big Mamma Group, Anne Sophie Pic, Le Perchoir, Potel & Chabot, Ducasse, Paris Society, Echo, Cali Sisters …) et une communauté de 150 000 candidats. Depuis 2019, Extracadabra s’étend sur de nouvelles verticales (vente et logistique) avec des clients comme Bergamotte, Cabaïa, Maison Landemaine, Selency, Pierre Hermé, Moncler… Nos Valeurs qui allient perfomance et valeurs humaines fortes dans un contexte où nous avons un impact fort sur la société sur un sujet central, l’emploi pour tous : CCLAP ! Confiance Créativité Lien Ambition Performance Au sein de l’équipe tech et produit, tu as un rôle clé dans la valorisation et le partage de la donnée business et produit en interne. En effet, Extracadabra cherche un profil confirmé Data Engineer pour piloter l’évangélisation de la data. Tu devras consolider la data en faisant évoluer le datawarehouse actuel, avant de construire des reports avec les outils de visualisation (PowerBI, Redash, Zeppelin). Tu encadreras 1 alternant et 1 stagiaire pour t’accompagner dans la mise en place de solutions pérennes. Tes missions Participer à la prise en compte des besoins internes en matière de Data (équipes business et produit) Analyser l’architecture et les flux de data existants Participer au renforcement du datawarehouse existant pour le rendre plus scalable Construire des reports pour placer la data au cœur de la stratégie des différentes équipes de l’entreprise Construire des pipelines de data pour notamment alimenter des outils business comme Salesforce Partager les prérequis data aux équipes de dev pour les features à venir Ton profil Tu as une expérience d’au moins 2 ans dans une entreprise où la data est clé dans sa stratégie et dans le quotidien des équipes. Tu possèdes des connaissances techniques pour manipuler des données (ETL). Le langage SQL n’a pas de secret pour toi. Tu maîtrises un outil de Data Visualisation (PowerBI, Tableau). Tu as une bonne capacité d’analyse, de synthèse et de priorisation. Tu es curieux(se) et force de proposition. Tu es débrouillard(e) et aime relever des défis en dehors de ta zone de confort. Entretien avec la RH Entretien + Test technique (Echange avec un membre de l’équipe) Entretien co fondateur","Extracadabra is seeking an experienced Data Engineer to evangelize data within the company's tech and product team. The selected candidate will consolidate the data by evolving the existing data warehouse and creating reports using visualizing tools, manage data pipelines to feed business tools such as Salesforce, and share data requisites with dev teams for upcoming features. The ideal candidate should have a minimum of 2 years of experience, knowledge of technical data manipulation, SQL proficiency, proficiency in data visualization tools, good analytical and prioritization skills, and be curious and solution-oriented.",Non spécifié,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
429,44506,https://www.welcometothejungle.com/fr/companies/gorgias/jobs/data-analytics-engineer_paris,Data & Analytics Engineer,Gorgias,"{Datafold,go,python,Go,color,Airbyte,GitLab,DBT,GitHub,Fivetran,AWS,dbt,Hightouch,scale,Metaplane,BigQuery,GCP,SQL}",Télétravail partiel possible,"Paris, 75001",SaaS / Cloud Services,CDI,2023-02-01,"Meet Gorgias, the customer service platform that’s designed for eCommerce merchants, and built to provide an amazing experience to shoppers. Our product empowers merchants to manage all their customer service in one place support over email, live chat, voice, Facebook, Instagram, Twitter, and SMS in one feed to help our merchants provide exceptional customer experiences at scale on Shopify, BigCommerce, and Magento. Everything we do is for our customers, and we’re currently serving over 10,000+ e-commerce merchants, including Steve Madden (linked case study), Timbuk2, Decathlon, and Sports Illustrated. They love us for our innovative product, our focus on their eCommerce needs, and, of course, our lightning-fast customer service response times. We raised a total of including x this year our $25 million Series B round in December 2020 and our $30 million Series C round this year. In between, share growth we more than doubled in size in every meaningful way: annual recurring revenue, the size of our customer base, and the size of our Gorgias team, for starters. We’re still growing fast and looking for new teammates who want to grow with us. Join our team for the opportunity to: 👩🏼‍💻Work with smart, passionate people every day 💪 Get extreme ownership over your work and results 🧠 Be treated like the expert you are About the Growth Operations team Growth Ops is a cross-functional team that works hand-in-hand with all of the other Growth teams (Go-to-market Marketing, Sales, Success & Support, and Product) and also interacts with the dev teams. Our core role is to ensure that data flows accurately and efficiently across all of these teams and the tools they use to maintain and improve our data stack. In addition to this, we build complex data models and perform data analysis to provide insights. The Growth Ops team is also in charge of building data products that maximize each team’s efficiency: lead qualification models, optimizing deal routing, predicting churn, automated lead enrichment & prospecting, etc. The team itself is composed of three main squads: Business Intelligence , split into 2 squads, Go-to-market & Customer Operations, these teams help the rest of the company by providing insights on performance and by giving them the resources needed to achieve their goals. This includes things like providing or editing data marts, helping build dashboards, automating processes, researching new tools, and more. Core Ops is responsible for the management and maintenance of the Data Platform, including all data pipelines and assets. Their primary goal is to ensure that accurate and easily accessible data is provided at scale to end users. They also play a key role in advising and training Ops Analysts on analytics engineering best practices and maintaining up-to-date documentation and knowledge sharing. If you are naturally data curious, excited by data stack architecture, experienced in improving the availability and usability of datasets, and motivated by having an impact on the business where you work, we want to hear from you. What You’ll Do We are looking for a Data & Analytics Engineer who is passionate about applying their analytical and engineering skills to democratize data, metrics, and insights to drive decision-making and analytics across Gorgias. You will join our Core Ops section and will be integral to building out our world-class data platform and enabling all teams across the company to move faster and smarter. You will work on the analytics infrastructure end-to-end - from data ingestion to reporting - ensuring high data quality, availability, and performance to support Data/Ops Analysts. Build and maintain efficient and scalable data pipelines, leveraging ETL tools and protocols. Full-stack analytics engineering development, designing, implementing, and documenting data models that deliver clean, well-structured data for visualization, exploration, and activation. Develop and maintain reliable cloud-based applications to automate processes for our teams and unlock their full potential. Help the team to maintain an overall position of strong data governance with great data observability (data monitoring & alerting, CI/CD pipelines). Develop and maintain documentation that increases the understanding and utilization of our data assets. Develop and communicate strong opinions about best practices in Analytics Engineering. As a member of the Core Ops team, you will also promote strong standards throughout the organization and help level-up team members through the adoption of software engineering best practices (testing, version control, documentation, etc). Who You Are You have 3+ years of hands-on experience as an analytics engineer, data engineer, or equivalent. 3+ years of experience in data modeling and data warehouse architecture, with solid SQL experience. You care about writing good and clean SQL, with an emphasis on readability and performance. 2+ years of experience with a general-purpose programming language (preferably python), including testing, deployment, and codebase refactoring. 2+ years of experience with the modern data stack (Segment / ETL / Warehouse / dbt / BI / Activation tool), creating data products within a data warehouse environment to meet business goals. You have experience working in a cloud-based environment (GCP or AWS), managing and monitoring resources. You have strong knowledge of software development best practices applied to data and analytics (DataOps), primarily related to version control, CI/CD, automation, and testing. You have a natural fit for both technical and business challenges. We are building technical solutions to solve business-oriented challenges, so strong business acumen is needed for the role. You are always learning and staying informed about new tools and practices. At the speed at which the ecosystem is evolving, it is essential to stay on top of things and always look for new ways to improve our work. You love working with a wide range of data sources and stakeholders from operational and product teams. You pay attention to detail, with strong organization and prioritization skills, comfortable switching gears and moving between projects seamlessly. Our current data analytics stack mainly includes: Data ingestion: Airbyte, Segment, Fivetran Storage: BigQuery Transformation: DBT BI tools: Periscope, push.ai Data Activation: Hightouch, Segment, Airplane Data Monitoring: Datafold, Metaplane GCP products (Compute Engine, Cloud Functions, Cloud Run, PubSub …) CI/CD: GitHub Action & GitLab Project management: Linear, Notion Perks and Benefits 🏖 5 weeks of vacation 🍼Paid parental leave 💻Latest MacBook Pro or equivalent 🚊50% of public transportation reimbursed (Vélib, Navigo, etc.) 🍽️ Personal credit card to buy lunches (we use Swile ) 🏥 We provide private health insurance (we use Alan ) 💆🏻‍♀️ Get up to $700 to set up your workstation at home (working from home should feel breezy) 🥰 Every quarter, we organize an online company-wide summit to discuss where we’re going and strengthen social bonds. Once per year we organize offsite team retreats and company retreats! ( Here is the photo album from our last company retreat in Mexico in 2022, when we were a total of 200 people!) The position’s Interviewing Process Initial call with a recruiter that will present Gorgias, the team, and the position in more detail - ask all the questions you need Meet your manager, Elliot, Data Analytics Manager: get to know each other and set yourself up for success in this process Do a take-home case study where we don’t ask you to solve our problems, but we look for your creative insights. It’s the perfect time to show off what you know Case study review with Elliot, brainstorm and elaborate on key points Meet Axelle, Head of Growth at Gorgias. This is a good time to ask difficult questions and see if we are a good match for you! Why join us? 🚀 We’re among the fastest-growing startups in the eCommerce ecosystem 🦄 We’ve built an extremely efficient go-to-market engine 🥇 Work with a talented team you’ll learn a lot from 🙏 Join a company where automation and good & clean data are core beliefs shared by all 🎥 Here is an interview with one of our team member’s experiences from our most recent company retreat to Cancun! More cool things to know about Gorgias… 😁 Raised our Series C for $30M in 2022: TechCrunch Article ⬅️ We went from 0 to 10,000+ merchants using our platform since 2016 We have a 4.7 rating on Glassdoor & 4.7 Comparably culture score What our customers are saying: apps.shopify.com/helpdesk#reviews Other positions: gorgias.com/about-us/jobs Discover the Gorgias Platform” HERE Learn about our Compensation Policy: HERE Gorgias ensures equal employment opportunity without discrimination or harassment based on race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, veteran status, or any other characteristic protected by law.","Gorgias is seeking a Data and Analytics Engineer to join their Core Ops team. The successful candidate will have experience in data modeling, data warehouse architecture, general-purpose programming languages, and cloud-based environments. They will build and maintain data pipelines, design data models, and develop cloud-based applications. Additionally, they will maintain documentation and ensure data governance and strong data observability. The position offers benefits such as parental leave, private health insurance, and equipment reimbursement.",Non spécifié,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
428,44176,https://www.welcometothejungle.com/fr/companies/pretto/jobs/data-engineer_paris_PRETT_mg9OP0Y,Data Engineer,Pretto,"{python,Airflow,scale,via,R,BigQuery,SQL}",Télétravail partiel possible,"42, Rue de Paradis, Paris, 75010","FinTech / InsurTech, Immobilier particulier",CDI,2023-02-01,"Qui sommes-nous chez Pretto ? L’achat immobilier est l’un des moments les plus importants d’une vie. Mais c’est aussi une étape stressante et complexe, surtout quand il s’agit de trouver le prêt immobilier qui valide son projet. Pretto, c’est la fintech qui rend simple, efficace et équitable la recherche de crédit immobilier. Notre secret sauce ? Le meilleur simulateur du marché qui permet de savoir en 3 min si on peut acheter, combien et à quel taux, Un expert dédié qui accompagne des premières recherches de bien jusqu’à la signature et négocie pour ses clients auprès des banques, Une UX aux petits oignons pour supprimer la paperasse et suivre son projet depuis son canapé. Le résultat : des acheteurs qui obtiennent facilement leur prêt et découvrent la joie d’être propriétaire. Et ça, ça n’a pas de prix ! Depuis 2017, Pretto c’est 150 000 clients conseillés, 1 Milliard € de prêt financés par an, une note de 4,8/5 sur Trustpilot, 220 collaborateurs entre Paris et Nantes, une récente série B de 30 Millions d’€… et ce n’est que le début ! 3 raisons de nous rejoindre ? on a un vrai impact sur la vie de nos clients, c’est pourquoi on met toute notre énergie et notre exigence pour proposer la meilleure expérience à tous les niveaux nos équipes sont engagées et aux profils très variés, on cultive la collaboration dans une atmosphère bienveillante et positive on aide chacun à bien grandir avec des rituels de feedback ainsi qu’une formation continue via la Pretto Academy, notre super école de vente. Pour aller plus loin, on vous présente sur notre site Inside Pretto tout ce qu’il faut savoir sur Pretto, ce qu’on y fait, pourquoi, comment on y travaille, grandit… et s’épanouit ! 🎯 Nous rejoindre en tant que Data Engineer chez Pretto Chez Pretto, la data est au cœur de notre stratégie. Nous sommes en train de changer le marché de l'immobilier en apportant de la transparence et de la prévisibilité grâce aux données que nous collectons et analysons. Nous avons décidé très tôt d'investir sur la construction d'une stack data afin de centraliser dans une warehouse la source de vérité sur toutes nos métriques, et de construire les outils de pilotage et de mesure des différents pôles sur cette source de vérité. Cette data nous permet de suivre nos KPI business, d'améliorer en continu notre produit, mais également de travailler sur des projets long terme, par exemple : - suivre et anticiper les évolutions de taux - catégoriser nos utilisateurs pour nous adapter à leurs besoins - scorer de manière plus fine et efficace la finançabilité de nos utilisateurs C'est dans ce cadre que nous cherchons un•e data engineer qui prendra la responsabilité de la partie infra de notre stack data. 🌟 Tes missions Ta mission est donc de scale up l'infrastructure data d'une plateforme amenée à accompagner des centaines de milliers de projets immobiliers complexes et riches en données et évènements. Pour cela, tu devras : - Prendre le lead sur notre infrastructure de collecte de données. - Mettre en place et maintenir la collecte depuis tous nos sources : CRM / Bases de données / Tracking utilisateur / Outils tiers - Faire scaler notre infrastructure afin que les flux de données puissent y transiter en temps réel - En collaboration avec nos data scientists, mettre en place une infrastructure leur permettant de déployer en production leur travail d'analyse de donnée - En collaboration avec nos ingénieurs R&D, augmenter notre flux de données brutes de signaux de scoring - Optimiser l'utilisation et la structuration de notre data warehouse BigQuery - En collaboration avec les directeurs des différents pôles de Pretto, mettre en place une infrastructure leur permettant d'accéder et d'utiliser au quotidien des datamarts métier (dashboards, synchronisations avec outils d'analyse de donnée, alerting, ...) 👫 Ton profil - Diplômé•e d'une école d'ingénieur, avec au moins 3 ans d'expérience de développement, dont une sur des sujets de data engineering. - Connaissance solide des bases de données relationnelles, et maîtrise du langage SQL. - Bonnes pratiques de développement en équipe : versioning, code review, intégration continue, tests automatisés ... - Niveau solide en développement python dans un contexte d'ETL - Bonus : expérience avec Apache Airflow - Bonus : expérience avec la stack Google Cloud 🔥 Rejoins la team Tech parce que : - On t’offre un accompagnement en interne avec les meilleurs standards (formation coaching, culture de l’entraide et transmission de bonnes pratiques) - On te propose un plan de carrière qui te permettra de grandir chez nous - La culture du feedback : chez Pretto tout le monde a droit de donner son avis et proposer des solutions, c'est même recommandé ! 🎁 Les avantages à travailler chez Pretto 💰 Un package salarial avantageux : carte ticket restaurant Swile, mutuelle prise en charge à 50% et remboursement de la moitié de ton abonnement de transport en commun 🌟 Des primes attractives : vacances, cooptation pouvant aller jusqu'à 2000€, intéressement, naissance 🏡 Une charte de télétravail te permettant de télétravailler 3 jours par semaine, avec une indemnité de 2€ par jour 🍻 Des moments partagés entre collègues : onboarding avec ta promo, rituels d’équipe, séances de sport, tournois de Smash Bros, organisation de Happylunch, offsite 🧑‍🤝‍🧑 Un parrain ou marraine référent(e) pour te permettre de t’intégrer et de t’épanouir chez Pretto","Pretto, a real estate fintech, is seeking a data engineer to lead the infrastructure of their data stack. The ideal candidate should have at least three years of experience in data engineering, strong knowledge of SQL and Python, and experience with Apache Airflow and the Google Cloud stack. The successful candidate will be responsible for managing data collection, maintaining data sources, optimizing data warehouses, and collaborating with data scientists and R&D engineers to develop data analysis tools. Pretto offers attractive compensation packages, career growth opportunities, and a telecommuting policy.",Non spécifié,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
209,56988,https://www.welcometothejungle.com/fr/companies/beamy/jobs/data-engineer_paris,Data Engineer,Beamy,"{airbyte,precisely,airflow,Airbyte,Airflow,Looker,grid,AWS,Snowflake,dbt,Airtable,scale,BigQuery,GCP,SQL,Python}",Télétravail partiel possible,"6, Rue Auber, Paris, 75009","Intelligence artificielle / Machine Learning, SaaS / Cloud Services",CDI,2023-03-26,"SaaS apps are now everywhere to make our working life easier. Who hasn’t used Notion, Airtable, Atlassian, Adobe or Zoom at least once? Easily accessible, innovative and less expensive, this massive and widespread use is part of an underlying trend that is accelerating continuously. It offers employees new ways of working. This is what we call Business Led-IT. Beamy centralises SaaS knowledge on a single platform to master usage, optimise contracts and mitigate associated risks. Beamy helps to build an effective SaaS governance between all key stakeholders (Business Units, CIOs, CISOs, DPOs etc.) by using powerful automated workflows. In this way, Beamy re-establishes communication between the business teams (Marketing, HR, Finance, etc.) and the IT department. The entire company can then orchestrate their digitalisation through a single platform in a secured, compliant and transparent way. The successful use of Beamy by our customers is based on data. Without the Data Team, it would be impossible to fulfil Beamy's first promise : Shadow IT detection. For 2023 we have decided to reinforce this stream and grow our Data team. We are looking for Data Engineers. We need to build the best and most scalable infrastructure that will allow us to collect, store and transform our client's data. Your responsibilities : - Take part of the definition of the architecture and data flows between different data sources - Design, implement, test, deploy and maintain data pipelines - Be responsible for the monitoring and the data consistency throughout the data cycle - Create and maintain integrations with partner applications - Ensure that our data practices are always in line with the best trends of the industry - Actively share knowledge and document insights to support continuous team improvement and collaboration Stack : GCP, Airbyte, Airflow, ETL, BigQuery/Snowflake, Looker, PySpark… What we offer: - 50K to 65K + stock options 💰(Our salary grid focuses on two variables : your level of impact in the organisation and your job expertise observed during our interviews)(We frequently Benchmark with Radford ) - A strong transparency culture (salaries and financial situation of the company shared internally, transparent career tracks...) coupled to an excellent and healthy atmosphere (no micromanagement, strong autonomy...) - Office in the heart of Paris, at Opera, (9th district) - A key position in our organisation and the opportunity to be a fundamental player in Beamy's acceleration and international scale - The best health mutual and lunch vouchers available (Alan & Swile), 5 weeks of holidays + RTT About you: As we're growing fast, new challenges arise, requiring creativity and a willingness to take responsibility. - You have at least 3 years of experience as a Data Engineer - You have a strong knowledge of programming languages: Python and PySpark, SQL - You have a strong knowledge of cloud architecture: GCP or AWS - You have already managed a stack with modern data engineering tools (airbyte, airflow, dbt, BigQuery/Snowflake, Looker, …) - You can communicate clearly in both written and oral form in English and French - You have interest in understanding and solving Business data challenges Application & Hiring process: We are looking for an overview of your background (either a resume or a Linkedin profile) and a short note to tell us why we're a great fit for each other and how you envision your future @Beamy We'll review your application and we'll get back to you within a week. Be sure you will hear from us 🙃 Our hiring process for this role: - A 30min Introduction call with Leslye - Senior Talent Acquisition Specialist to make sure our expectations are aligned. - A 30min video call with Tahir - CTO to deep dive into the role and to check that your skillset and mindset fit for the job. - A Case study - 1h of Who Interview with the HR team, to make sure we're a great fit in terms of culture - On-site session to get a feel of the work atmosphere during a lunch + reference check Research shows that while men apply to jobs where they meet an average of 60% of the criteria, women and other underrepresented groups tend to only apply when they meet 100% of the qualifications. At Beamy, we value respectful debate and people who aren't afraid to challenge assumptions, so we are looking for diverse perspectives as long as you meet our minimum criteria. You are encouraged to apply even if your experience doesn't precisely match the job description!","Beamy is seeking a Data Engineer to reinforce its data team in Paris. Candidates must have at least three years of experience in data engineering, strong knowledge of programming languages, cloud architecture, and modern data engineering tools. The role involves designing, implementing, testing, deploying, and maintaining data pipelines, among other responsibilities. Beamy offers a salary of €50k-€65k, stock options, a healthy working environment, and an opportunity to be a fundamental player in the company's acceleration and international scale. Women and underrepresented groups are encouraged to apply.",Non spécifié,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
43,56861,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-cdi-f-h_grenoble,Data Engineer (Confirmé) - CDI -,Atos,"{Cassandra,Hive,Docker,Azure,Microsoft,MongoDB,Beam,Logstash,Kafka,NoSQL,SnowFlake,ElasticSearch,Kubernetes,AWS,Teradata,Java,CouchBase,Hadoop,Redis,Redshift,Kibana,HDFS,Spark,BigQuery,Python}",Télétravail partiel possible,"28 Rue Gustave Eiffel, Grenoble, 38000",IT / Digital,CDI,2023-03-26,"Bienvenue chez Atos, où nous imaginons le futur de la tech. Leader international du numérique sécurisé et décarboné, Atos contribue à façonner les nouvelles technologies avec ses clients. Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carrière valorisants basés sur des programmes de formation, de certification et de mobilité. C’est pourquoi chez Atos, la diversité des compétences et des expériences de nos équipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l’avenir de notre entreprise et de la société. LA MISSION QUE L’ON VOUS CONFIE : Au sein d'équipes dynamiques, vous aurez pour missions principales : Conseiller en architecture en gouvernance de la donnée. Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA. Mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud pour les projets stratégiques de nos clients. VOTRE PROFIL POUR REUSSIR : De formation supérieure BAC +5 en Informatique d`une Ecole d’Ingénieur ou d’un Mastère universitaire dans le domaine des sciences informatiques que vous avez complété par une expérience significative en Data Science / Data Engineering. Votre stack technique : Requis : Connaissance des écosystèmes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS … ; Expertise en développement Python ou Java Spring Boot ; Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam… ; Connaissance des architectures conteneurs : Docker, Kubernetes. Apprécié : Connaissance d’un des services managés BigData de Google Cloud Platform / AWS / Microsoft Azure ; Connaissance des approches Agile & DevOps. Soft skills : Passionné(e) d’informatique en progressant et en vous tenant à jour sur toutes les technologies et architectures, vous êtes créatif(ve), autonome, rigoureux(se), curieux(se), motivé(e) et avez le sens du travail en équipe et du relationnel alors rejoignez-nous ! Niveau de langue : Anglais : niveau intermédiaire minimum recommandé et Français exigé. Description du profil : POUR VOUS CONVAINCRE DE NOUS REJOINDRE : Travailler à Grenoble dans une ambiance et cadre de travail agréable avec nos clients en direct . Un accompagnement personnalisé avec montée en compétences, formation et évolution sur des projets long terme. Un employeur attentif à votre épanouissement avec des possibilités de télétravail pouvant aller jusqu’à 50% du temps Un package d’avantages avec régime de santé très favorable, RTT disponibles dès votre arrivée et un CE très dynamique, remboursement des déplacements en transport en commun. NOTRE PROCESSUS DE RECRUTEMENT : Prise de contact avec un recruteur pour une préqualification Evaluation technique en fonction du profil Entretien avec nos ingénieurs commerciaux / managers Vous voulez en découvrir plus ? N’hésitez plus et postulez dès à présent ! #TheFutureIsOurChoice","Atos is seeking a Data Engineer/Architect with experience in data governance, data ingestion, analytics, and data science/AI, and knowledge of various ecosystems and frameworks such as ELK, Spark, and Docker. The successful candidate should have a BAC+5 in Computer Science and significant experience in data engineering/science. They should be passionate, creative, curious, motivated, and a team player with good communication skills. The position offers personalized skills development, telecommuting up to 50% of the time, a comprehensive benefits package, and a dynamic work environment. Fluency in English (intermediate) and French (required) is necessary.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
53,73310,https://www.welcometothejungle.com/fr/companies/sicara/jobs/lead-data-software-engineer-cdi-paris_paris,Lead Data Software Engineer - CDI - Paris,Sicara,"{Hadoop,Spark,Python,Airflow}",Télétravail ponctuel autorisé,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-04-22,"Sicara est une startup experte en data, basée à Paris : nous révolutionnons les projets data en combinant notre savoir-faire dans l’agilité, la data science et le data engineering afin d’accélérer la transformation digitale de nos clients. Pourquoi on recrute un Lead Data Software Engineer ? Pour continuer à renforcer les équipes Data Software Engineering de Sicara. En tant que Lead Data Engineer , et auprès de tes clients, tu auras pour missions de : Analyser les données sources et échanger avec les experts métier afin d’identifier et évaluer des cas d’usage métier Leader une équipe de 2 à 5 data software engineers dans le delivery de la solution à implémenter au quotidien Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels) Définir les méthodologies de déploiement et plans de migration Construire et déployer les pipelines de données (ETL et ELT) Assurer la migration des données vers les nouveaux environnements Choisir et mettre en oeuvre des outils de data analyse et/ou data visualisation Mettre en place des outils de contrôle de la qualité de la donnée Accompagner et former les équipes clients Au sein de Sicara, dans ton rôle interne tu pourras : Accompagner et former les équipes au data software engineering Assurer une veille technologique continue sur les solutions de l’état de l’art Intervenir dans la réflexion sur la stratégie technique à proposer en phases d’avant-vente de nos projets Générer de la connaissance technique sur des sujets d’expertises , pour les propager au sein de Sicara, et ce grâce à l’encadrement de l’équipe dirigeante En fonction de tes envies et de tes compétences, tu auras la possibilité de : Devenir un(e) expert(e) sur les sujets techniques qui te passionnent. Devenir un(e) leader grâce au développement de compétences transverses : coaching, recrutement, commercial, management, marketing, etc. Monter une tribe ou une guilde pour développer un nouvelle offre et améliorer nos pratiques. Tu as entre 2 et 4 ans d’expérience sur des sujets de Data Software Engineering Tu es diplômé(e) d’une école d’ingénieur en Bac+5 Tu as une bonne connaissance de Python et tu as déjà utilisé des technologies Big Data ( Spark, Hadoop, Airflow, Terraform ) Tu souhaites participer à la conception de produits à fort impact business Tu recherches à être accompagné(e) par une équipe d’experts pour exploiter à fond ton potentiel et réaliser ton ambition sur des sujets data qui te passionnent ! 1 entretien RH + 1 test + 1 entretien technique + 2 entretiens dirigeants",,Bac +5 / Master,Entre 15 et 50 salariés,> 2 ans,1,1,0.027697749441558416
420,40487,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-banque-f-h_paris,Data Engineer - banque,CGI,"{Couchbase,NoSQL,MapR,Mongo,Nifi,HDFS,HBase,Kafka,Linux,Hive,Spark,Marklogic,YARN,Hadoop,Python,Cloudera}",Télétravail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-01-29,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Principales missions: -Concevoir, développer et déployer des pipelines de transformations de données en environnement Big Data -Définir des solutions globales permettant de répondre aux besoins métiers en prenant en compte les problématiques de performances, d’industrialisation, d’exploitation et de sécurité. -Paramétrer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, …) -Faire des prototypes sur des technologies et de la veille technologique sur le Big Data -Accompagner & supporter les équipes projet en coaching et expertise -Animer et faire progresser des juniors et stagiaires -Assurer le rôle de Lead Tech dans une équipe Vous disposez d’au moins 3 ans d’expérience sur des fonctions IT de conception / développement en environnement Big Data. Vous vous définissez comme un ‘Data Engineer’ capable de faire du développement tout en conservant une vue globale du besoin et des finalités de clients. Vous avez acquis les compétences suivantes au cours de votre expérience: -Compétences techniques autour des produits Data / Big Data: o Solution Hadoop (HDFS, YARN, Hive, Hue, Oozie…) et outillage associé o Spark, Python o Bases NoSQL (Mongo, HBase, Couchbase, Marklogic…) -Expérience avérée de développements Big Data dans des environnements complexes avec des contraintes techniques identifiés (sécurité, performances, fonctionnel complexe…) -Connaissance de la stack standard Linux -Capacité à travailler en équipe, et dans une organisation Agile type Srcum ou SAFE -Capacité à coacher des juniors voire d’encadrer une équipe -Compétences de tech lead appréciées CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap.","CGI is seeking a Senior Big Data Engineer who will be responsible for designing and deploying data transformation pipelines, defining global solutions to meet business needs, configuring and maintaining Big Data clusters, coaching and supporting project teams, and leading a team. The ideal candidate should have at least 3 years of IT experience in Big Data environments, technical skills in Hadoop, Spark, Python and NoSQL databases, and the ability to work in a team and coach juniors. CGI is an inclusive employer and welcomes applications from candidates with disabilities.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
85,73539,https://www.welcometothejungle.com/fr/companies/airbus-1/jobs/engineering-data-custodian-f-m_toulouse_AIRBU_RzGrLNy,Engineering Data Custodian (f/m),AIRBUS,"{via,GO}",Télétravail ponctuel autorisé,"Toulouse, 31000","Cybersécurité, Aéronautique / Spatiale",CDI,2023-04-22,"Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world’s leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. About us Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world’s leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. Job description Airbus Commercial Aircraft is looking for an **Engineering Data Custodian (f/m) to join our Architecture and Integration department based in ** Toulouse, France. ** You will be part of a team developing processes and methodologies for the Systems engineering domain. As part of the Systems Engineering Office team, you will support the Systems Engineering process, culture, competency and discipline, on day-to-day business activities, enabled by adequate Methods & Tools (M&T) products and services. This support spans all aspects of the Systems life cycle. Your working environment: Global capital of aeronautics and European capital for space research, Toulouse is a dynamic city in the southwest of France served by an international airport. Ideally located between the Mediterranean sea and the Atlantic ocean and close to the Pyrenees mountains, it offers plenty of options for outdoor activities! How we care for you: **Financial rewards: **Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis. **Work / Life Balance: **Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services. **Wellbeing / Health: **Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application. Individual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking. Your challenges: Contribute to the engineering global picture in data/digital asset development and in the equipped framework blueprint. Under engineering common blueprint constraints, develop, execute, and supervise plans, policies, programs and practices that deliver, control, protect, and enhance the value of data and information assets throughout their life cycles. Improve existing, or implement new, processes/methodologies to support the business needs and the current challenges. Support team to help them adopt change. As part of the assessment board of the data/digital asset development quality package, provide the GO/NOGO of the data/digital asset deployment and commissioning based on Accountable for the well application and respect of data management frameworks used in data/digital asset development. Your boarding pass: Min 5 years of professional experience in an engineering business, ideally in aeronautics Strong process-minded approach. Prior experience in Functional Data of business processes and related processes. Good understanding of Data Architecture, Data Design and Modelling, Data Intelligence, Science and Analysis Ability to understand business needs and challenges in order to convey them via processes/methodologie. Leadership skills to carry change and to ensure adhesion or team members. Ideally a prior experience in change management. Comfortable working within an unclear/unidentified workframe Good communication skills, including strong competence in English language Many of our staff work flexibly in many different ways, including part-time. Please talk to us about the flexibility you need during the interview and we’ll always do our best to accommodate your request. Salary range: Salary range based on the required profile: 55,000 to 65,000 €/year (including a variable part based on your performance). Information provided as an indication. Not a 100% match? No worries! Airbus supports your personal growth with customized development solutions. Take your career to a new level and apply online now! #LI-AS1 This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company’s success, reputation and sustainable growth By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus. Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.",,Bac +5 / Master,> 2000 salariés,> 5 ans,1,1,0.027697749441558416
442,53117,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_6Vowm79,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",Télétravail partiel possible,"à définir, Courbevoie, 92026",Energie,CDI,2023-03-20,"Enedis est une entreprise de service public, gestionnaire du réseau de distribution d'électricité. Elle développe, exploite, modernise le réseau électrique et gère les données associées. Elle facilite la transition énergétique des territoires en les accompagnant dans le développement et la planification de leur production d'électricité d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le dépannage 24h/24, le relevé des compteurs et toutes les interventions techniques. Indépendante, Enedis délivre la même qualité de service aux fournisseurs d'énergie. Comme le prévoit la loi, elle a établi un code de bonne conduite auquel ses collaborateurs sont formés afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des métiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilité du Système d'information dans un contexte de forte numérisation des métiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engagée notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Système d'Information à la transformation numérique ou dans le positionnement d'Enedis comme opérateur de données, la DSI met en oeuvre de nombreux projets majeurs en lien avec les métiers concernés. Un des enjeux majeurs d'Enedis est de devenir un opérateur de confiance de Données énergétiques. Afin de répondre à cet enjeu, Enedis a mis en place une plateforme de données pour l'entreprise. Cette plateforme est composée d'une infrastructure de données centralisée construite sur Hadoop et d'outils à destination des équipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'améliorer cette plateforme sur plusieurs axes : migration vers le cloud, évolution de l'architecture avec en cible une plateforme modulaire composant des services managés, automatisation et montée en gamme de l'offre de services internes permettant aux équipes de gagner en autonomie dans la création de véritables produits de données. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des équipes du train SAFe DataServices4U - équipe SPHINX, en charge de l'infrastructure data des activités exploratoires (big data, big mem, GPU) - définira, développera, mettra en place et maintiendra les outils et infrastructures adéquats aux opérations du reste du train (équipes data scientists et data engineers). - veillera à garantir les opérations des solutions permettant le traitement de volumes importants de données tout en garantissant la sécurité de celles-ci - définira les enablers à prendre en compte dans l'équipe - sera Tech. Lead d'une équipe d'une dizaine de personnes - testera les réalisations de l'équipe - contribuera aux démonstrations faites aux équipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous êtes issu d'une formation de type Bac +5 dans le domaine de l'IT / système d'information / Numérique et DATA - Vous disposez d'une expérience d'au moins 4 ans dans des activités équivalentes, au cours desquelles vous avec avez développé de solides compétences techniques - Vous avez un profil Ingénieur Big Data disposant de compétences d'analyse, de synthèse, de créativité et d'une appétence pour l'innovation. - Vous avez de bonnes connaissances de l'administration système UNIX : maîtrise de Linux (Redhat), Bash - ainsi que composants sécurité et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacités de communication (orales et écrites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacités de coordination - Vous faites preuve de curiosité, d'esprit de synthèse, de méthodologie et de rigueur dans un environnement complexe Le poste est situé à Courbevoie, avec une possibilité de télétravail partiel. La rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Chez Enedis, accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous.","Enedis seeks a System Team Engineer DataOps with a background in IT/system information/Numérique and DATA, and at least four years of experience with a strong technical skill set. The engineer will lead a team and be responsible for defining, developing, implementing, and maintaining the appropriate tools and infrastructure for the operations of a platform of centralized data infrastructure based on Hadoop. Additionally, the engineer will test the team's achievements, contribute to demonstrations, and stay synchronized with other technical leaders and architecture.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
419,40397,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-ingenieur-f-h_nanterre,Data Ingénieur,EDF,"{UNIX,PowerBI,Linux,Hadoop,SQL,Python}",Télétravail partiel possible,"Avenue Pablo Picasso , Nanterre, 92200","Environnement / Développement durable, Energie",CDI,2023-01-29,"Le groupe EDF est l’un des premiers électriciens mondiaux, à la pointe de l’innovation technologique. Le respect de la personne et celui de l’environnement, l’intégrité, la solidarité sont au cœur de nos actions. Face à l’urgence climatique, notre rôle est d’inventer un modèle énergétique qui respecte notre planète. Nous voulons construire un monde où il sera possible de produire une électricité neutre en CO2, grâce au nucléaire et aux énergies renouvelables, conciliant préservation de la planète, bien-être et développement, grâce à l’électricité et à des solutions et services innovants. Notre ambition est de toujours innover, pour permettre à notre société de continuer à grandir. Depuis notre création, c’est notre responsabilité de rendre l’énergie accessible à tous, à tout moment, en toutes circonstances, en proposant de nouvelles manières de moins consommer, de mieux consommer. C’est à nous, femmes et hommes d’EDF, fiers de nos missions de service public, de transformer demain. Vous aussi vous souhaitez construire un avenir énergétique neutre en CO2 ? En 2022, le groupe EDF recrutera plus de 15 000 nouveaux collaborateurs en CDI, alternance ou stage. Rejoignez-nous ! EDF, électricien performant et responsable, champion de la croissance bas carbone recrute dans ses nombreux métiers. Rejoignez nos équipes et relevez de nouveaux défis au service de 38.5 millions de clients. Au sein d'EDF, la Direction Services Informatique et Télécoms (DSIT) du groupe EDF propose aux métiers du groupe des moyens d'exploitation des applications, infrastructures, et moyens collaboratifs communs. En tant que Data Ingénieur, vous intégrez un collectif organisé en Agile, et reposant sur 3 équipes Scrum pour un total de 20 personnes : 2 équipes de DataAnalysts 1 équipe de DataIngénieurs sur laquelle est publiée cette offre Les méthodologies Scrum et SAFe pour l'agilité à l'échelle seront utilisées. Les services rendus par ce collectif sont de valoriser les données IT de toute l'entité et de tous nos coeurs d'activités IT Des infrastructure (télécoms, système, IoT …) A nos applicatifs (cloud privé, public …) Afin de mieux piloter notre production et nos actifs. Vous aurez ainsi pour mission de fournir aux équipes de DataAnalyse une infrastructure de données fiable et performante, avec des données de qualité. Vos missions Au quotidien, les activités du Data Ingénieur sont les suivantes : Infrastructures de données : Cartographie et documente les sources de données. Assure la maintenance des différentes applications données (Data) déployées en production et des infrastructures. Structure les bases de données (sémantique, format, etc.). Contribue à la gestion des référentiels de données. Intégration des données : Capte et stocke, en toute sécurité, les données (structurées ou non) produites dans les différentes applications ou venant de l'extérieur de l'entreprise. Assure la supervision et l'intégration des données de diverses nature qui proviennent de sources multiples. Vérifie la qualité des données qui entrent dans le Datawarehouse et s'assure de leur sécurité. Nettoie la donnée (élimination des doublons...) et la valide pour une utilisation aval. Maintien en condition opérationnelle S'assure de la maintenance de l'infrastructure de données. Maintien de la performance de l'infrastructure de données. Optimise l'infrastructure de données. Pour en savoir plus sur la culture numérique au sein d'EDF, cliquez ici. Vous souhaitez appliquer vos connaissances techniques autour des briques de stockage, traitement et restitution de la donnée . Vous avez une expérience significative dans les domaines techniques de la Data en tant que Data Ingénieur, afin d'être à l'aise dans les environnements techniques suivants : Stockage des données : Bases SGBD traditionnelles :Administration et requêtage SQL Modélisation de bases de données Traitement des donnéesDéveloppements Python Outils d'ETL Visualisation de données : Outils de Dataviz type PowerBI Connaissances système : Linux/UNIX Vous faites preuve d'autonomie, et êtes force de proposition sur les choix techniques, de réactivité dans la gestion des demandes et incidents, d''une capacité d'écoute et de compréhension des besoins. Vous avez une culture sur les environnements et technologies du BigData (Hadoop, ELK …). Vous êtes à l'aise dans une organisation Agile du travail. Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous.","EDF, a global electricity leader, is seeking a data engineer to provide reliable and high-performing data infrastructure to data analysis teams. The ideal candidate should have significant experience in data management and be familiar with SQL administration, database modeling, Python development, ETL tools, data visualization tools, and Unix/Linux systems. The position is part of an Agile team using Scrum and SAFe methodologies to support the IT activities of EDF. Applicants should be proactive, technically savvy, and comfortable working in an Agile environment. EDF welcomes candidates with disabilities and strives to offer equal opportunities to all.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
207,56583,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_toulouse,Expert technique ETL Semarchy xDI / Stambia,CGI,{},Télétravail partiel possible,"Toulouse, 31000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Semarchy xDI / Stambia • Participer aux échanges avec l’éditeur Semarchy • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné.e d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert.e technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, seeks a candidate with at least three years of experience as an ETL Semarchy xDI/Stambia technical expert to join its Digital Innovation Center. The role involves improving the efficiency and effectiveness of implemented solutions, collaborating with engineers and other experts on data integration issues, developing technical standards, providing internal and external training, and providing daily technical support. The ideal candidate is ambitious, a team player, and has experience as a technical consultant in fixed-price projects. Knowledge of data quality and governance is a plus. CGI is a proponent of workplace diversity and welcomes applications from candidates with disabilities and members of the LGBT community.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
205,56584,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/concepteur-developpeur-talend-f-h_nantes,Consultant ETL Talend -,Micropole,"{Microsoft,durable,Talend,AWS,R,TALEND,GCP}",Télétravail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. Comme nous, vous êtes passionné(e) par la donnée etconvaincus que l’optimisation du patrimoine data des entreprises est laclé de leur performance ? Vous voulez rendre les entreprises dataintelligentes et les aider à se transformer pour préparer dès à présentleur futur ? Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitales , au sein d’uneagence à taille humaine où règnent entraide et convivialité, engagée en faveurd’un numérique plus responsable au service de clients principalement implantésrégionalement ? Si vous avez répondu favorablement àchacune de ces questions, qu'attendez-vous ? Rejoignez l'aventure Micropole ! EN TANT QUE CONSULTANT TALEND (F/H) : Micropole s’appuie sur l'expertise deses collaborateurs spécialistes de la donnée pour accompagner les clients dansleurs projets de business intelligence, gouvernance de la donnée et pilotage de laperformance visant à apporter de la valeur aux métiers. L’un des Managers du Pôle BI composéd'une trentaine de personnes sur l'Ouest recrute un Consultant ETL Talend (F/H) pour compléter ses équipes spécialistes de l’alimentation desystèmes d’informations décisionnels. Dans vos missions quotidiennes , vous serez amené(e) : - Comprendre le besoinexprimé par les métiers - Concevoir le modèle conceptuelde données et le modèle physique de données - Rédiger les spécificationsdétaillées - Développer les jobs d’alimentationTalend - Tester, déployer, industrialiseret optimiser les performances des jobs - Documenter vos travaux Le mot du Manager: Fort de nos valeurs d’engagement et de collectif, nous accompagnons les transformations data et digitale vers un numérique plus responsable. Vos compétences techniques : - Vouspossédez au moins 3 ans d’expérience sur Talend - Vousêtes idéalement certifié(e) Talend Data Integration Vos atouts : - De formation en informatiquedécisionnelle ou équivalente, vous êtes à l’aise dans le traitement de la donnée, - Vous possédez descapacités relationnelles qui vous permettent de vous adapter et de communiqueravec l'ensemble des interlocuteurs d'un projet, - Votre rigueur etvos capacités d'organisation sont souvent reconnues et particulièrementappréciées, Devenir #INNOVATIVE PEOPLE C’est : - Intégrer une communauté de1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg,la Suisse, l’Espagne et la Chine. - Construire ensemble lessolutions stratégiques et innovantes de demain pour accompagner nos clientsdans leur transformation data et digitale. - Participer au développementde nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement autravers de formations et de certifications sur les plus grandes technologiesgrâce à Micropole Campus. - S’assurer d’une innovationcontinue grâce à : o Notre écosystème de partenaires technologiques o Notre accélérateur de start’up databoost’R o Nos lieux d’innovations « innovativeSpaces » et deco-construction avec les clients o Notre management par les talents naturels Processus de recrutement : Chez Micropole, le processus de recrutement estréactif et transparent. - Etape 1 – Si votre profil correspond à nos attentes, vous êtesrecontacté(e)s dans les 72 heures qui suivent votre candidature par Céline ouMikaël nos Talent Specialist pour la région ouest pour un premier échangetéléphonique ; - Etape 2 – Un premier entretien est programmé avec l’un d’entre euxsur site ou à distance - Etape 3 – Vous rencontrez Stéphanie ou Camille les manager del’équipe Data de l’Ouest en second entretien En fonction du poste, vous pouvez passer des étapessupplémentaires (entretien supplémentaire ou test technique) LAVIE CHEZ MICROPOLE, C’EST : - Une vie interne rythméepour se familiariser à la culture d’entreprise et aux valeurs deMicropole ; - Des évènements internesréguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; - Une politique de formationattractive et éclectique (certifications prises en charge) ; - Un travail en équipevalorisé pour une meilleure cohésion ; - La participation à desprojets internes sur la base du volontariat. À PROPOS DE MICROPOLE GRAND-OUEST Micropole GrandOuest regroupe les agences de Nantes, Niort, Rennes.Avec un développement rapide sur le Data, leDigital et Cloud, les équipes portent l’ensemble de la proposition de valeur duGroupe. Présent au plusprès de l’écosystème de partenaires, de réseaux professionnels et d’acteurs dudéveloppement économique, nous accompagnons nos clients des secteurs del’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et dupublic dans leur transformation data et digitale, notamment au travers deméthodologies innovantes comme le Datathinking® ou Lego Serious Play®. L’agence GrandOuest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit etmet en place des méthodes, compétences et expertises pour le développement d’unnumérique responsable au sein des organisations. À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. Pour en avoir plus : https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Compétences ETL Talend","Micropole is seeking a Talend ETL Consultant to support clients in their business intelligence, data governance and performance management projects. The successful candidate should possess at least 3 years of experience in Talend and be comfortable with data processing. They should also have strong communication and organizational skills. Micropole is a group of 1200 consultants in Europe and China, dedicated to helping clients transform their businesses through data.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
239,56900,https://www.welcometothejungle.com/fr/companies/visian/jobs/data-engineer-h-f_levallois-perret_VISIA_MP6apl8,DATA ENGINEER,Visian,"{NiFi,Tensorflow,Beam,MXNet,Kafka,Spark,Keras,NoSQL,Hadoop}",Télétravail partiel possible,"22, Rue du Président Wilson, Levallois-Perret, 92300","Intelligence artificielle / Machine Learning, IT / Digital, Stratégie",CDI,2023-03-26,"De la définition d’une roadmap digitale au lancement de produits et services innovants, Visian concrétise les ambitions de ses clients en veillant à intégrer durabilité et sobriété numérique. Visian est spécialisé dans l’innovation, le product design et la data. Ses consultants technophiles allient compréhension des enjeux digitaux et vision produit. Visian, cabinet de conseil spécialisé en Innovation, Design Produit, et Data, recherche pour son client, grand acteur du secteur de l’énergie, un Data Engineer pour rejoindre ses équipes sur un projet innovant. Contexte: La mission se déroule au sein de l’entité responsable du développement de méthodologies et d’outils d’IA/d’apprentissage automatique pour des solutions intelligentes et basées sur les données qui prennent en charge des modèles commerciaux nouveaux et innovants pour les chaînes de valeur existantes et futures. L’ingénieur sera responsable de l’expansion et de l’optimisation de l’architecture d’IA, en mettant des modèles d’apprentissage automatique. Il agira en soutien des développeurs de logiciels, architectes de bases de données, Data Analyst, et Data Scientist pour garantir l’architecture de prestation de services d’IA optimale Missions : Développer et maintenir un système de traitement de données à grande échelle Déployer des modèles ML (fournis par des scientifiques des données) S’assurer que les pipelines ETL construites prendront en charge les flux de données à volume élevé Détecter les opportunités d’acquisition, de stockage et d’interrogation de données de manière performante Utiliser une variété de langages et d’outils (sensibilisation aux données opensource apache/ML cadres connexes est une compétence indispensable) Comprendre, personnaliser et maintenir des projets open source et contribuer au développement de nouveaux cadres 3 à 5 ans en tant que Data Engineer sur des sujets d’IA Pratiques des Outils BIG DATA: Hadoop, Spark, Kafka, NoSQL, NiFi, Beam, Zookeeper,etc… Savoir Construire des pipelines ETL de données évolutifs et tolérants aux pannes basées sur les technologies du Big Data Expériences en implémentation d’inférences basées sur des modèles d’apprentissage profond avec des frameworks comme Apache MXNet, Tensorflow, Keras etc Mise en production des modèles ML suite à MLOps Expériences avec les langages de programmation orientés objet Compréhension du web sémantique / des Données liées Approches agiles (SCRUM, SAFE) Expériences de soutien et de travail avec des équipes interfonctionnelles dans un environnement dynamique Anglais courant","Visian, an Innovation, Product Design, and Data consultancy, is seeking a Data Engineer for its client in the energy sector. The engineer will be responsible for expanding and optimizing AI architecture, deploying ML models, and detecting opportunities for acquisition, storage, and effective data querying. The ideal candidate should have 3-5 years' experience in AI, familiarity with big data tools such as Hadoop, Spark, Kafka, among others, and proficiency in programming languages. The position requires excellent communication skills and the ability to collaboratively work in an agile environment.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
412,37324,https://www.welcometothejungle.com/fr/companies/gens-de-confiance/jobs/data-engineer-platform-f-m_nantes,"Data Engineer, Platform",Gens de Confiance,"{Amplitude,Ruby,Go,Metabase,JavaScript,Redshift,Glue,Lambda,AWS,scale,PHP,NoSQL,SQL,Python}",Télétravail partiel possible,N,"Big Data, Économie collaborative, Immobilier particulier",CDI,2022-10-18,"Gens de Confiance est un service de petites annonces accessible sur recommandation pour les particuliers et les professionnels, qui permet à ses 1.500.000 membres d’acheter, de vendre et de louer en ligne, en toute sécurité. Les catégories disponibles vont de l’immobilier à l’électroménager, en passant par le babysitting et l’automobile. Vous êtes aussi à la recherche d’un artisan ou d’un professeur particulier ? La plateforme vous permet également de trouver le professionnel de confiance ! Comment ça marche ? Tout le monde peut s’inscrire gratuitement sur Gens de Confiance, mais il faut être membre pour répondre aux annonces. Les inscrits qui souhaitent devenir membres doivent obtenir le parrainage de trois membres existants. Et le jeu en vaut la chandelle, car 70 % des annonces publiées sur Gens de Confiance sont introuvables ailleurs. Depuis 2014 nous avons compris qu’avec Gens de Confiance il est possible d’apporter un niveau de confiance radicalement supérieur à l’existant — et à grande échelle — en offrant un cadre simple, un service de qualité et un produit au meilleur niveau. Pour autant, nous n’en sommes qu’au début de nos découvertes et un boulevard s’offre à nous à condition de savoir nous faire connaître au plus grand nombre ! Notre mission, est à la fois simple et ambitieuse : remettre un peu plus de confiance dans notre société et contribuer au développement de l’économie circulaire. Et l’actualité nous confirme hélas chaque semaine que ce n’est pas du luxe. Aujourd’hui, Gens de Confiance est disponible en français et en anglais, sur le web comme sur mobile. L’entreprise compte 65 personnes, à Nantes et en remote. Pour révéler la confiance, l’équipe Tech / Produit adopte une culture qui repose sur l’intelligence collective, la soif d’apprendre, le partage de connaissances et un esprit “doer”. Et si le langage est un moyen, notre priorité reste le produit ! Le poste : Nous avons un réseau de près d’ 1.400.000 membres et nos équipes répondent à de forts enjeux de scalabilité, de refonte d’architecture, et de recherche de performance accrue. Nous recherchons des personnes avec une réelle valeur-ajoutée; l’expérience nous prouve que la diversité et l’inclusion font la richesse de notre startup. Notre équipe Tech / Produit de plus de 30 personnes est notamment répartie au sein de différentes squads dont 3 feature teams autonomes et une team transverse: Team Classifieds Team Members Team Services & Pro Team Platform Chaque feature team est constituée d’un Engineering Manager, d’un Product Manager, d’un Product Designer et de développeurs back et front. Chaque team a ses objectifs (OKRs) et est autonome sur son mode de fonctionnement. La Team Platform compte 7 personnes. La data se trouve au cœur de la stratégie de Gens de Confiance, afin d’améliorer l’expérience utilisateur et pour proposer de nouveaux services et produits liés à la confiance. Nous avons entamé la mise en place d’une architecture de collecte, de traitement et d’analyse des données. Notre équipe cherche des profils pour venir accélérer le déploiement de cette architecture, en développer les pans manquants (data warehouse, hébergement des modèles de machine learning, etc.) et créer des fonctionnalités produits exploitant nos données. Pourquoi ? Parce que la satisfaction de nos membres et de nos feature teams, coeur de notre métier, passe par une architecture de données robuste et performante. Ton rôle : Fournir un accès stable à la donnée de GDC et enrichir l’expérience utilisateur grâce à des fonctionnalités enrichie par la donnée. Pour ce faire tes principales missions seront de : Déployer et maintenir un pipeline de traitement capable de traiter un volume important de données tout en garantissant leur sécurité. Monitorer et améliorer les métriques du data pipeline (disponibilité, taux d’erreur, latency, etc.) Rassembler et participer à la priorisation des besoins data des équipes marketing, produit et des cofondateurs. Prendre en compte le contexte réglementaire quant à la récolte et à l’accès aux données (RGPD) Faciliter l’intégration de nouvelles données par les équipes de développement (back-end et front-end) Proposer et mettre en place des améliorations dans le processus de développement (CI, tests, monitoring, déploiement, etc.) Développer des outils d’accès et de visualisation de la données (Amplitude, Redshift, etc.) Bâtir des nouveaux produits et fonctionnalités basées sur la donnée, par exemple dans la création et la recherche d’annonce, l’inscription et la recommandation de parrainages, la détection automatique d’anomalies et d’erreurs. Stack: Python AWS: Lambda Redshift Glue Neptune Terraform Serverless Metabase Avantages : Des horaires flexibles, une organisation agile et un environnement propice au télétravail Programme d’évolution de carrière Accompagnement aux side projects et formations allouées (budgets et temps) Locaux agréables, spacieux et idéalement situés dans le centre de Nantes Budget pour des abonnements de cours en ligne Complémentaire santé familiale (mutuelle) prise en charge à 85% par Gens de Confiance Cours d’anglais BSPCE Welcome Pack : budget d’équipement de l’entreprise de 4 k€ : écran panoramique incurvé de 34” + fauteuil Herman Miller Aeron + ordinateur de ton choix) Qui es-tu ? Tu es de formation ingénieur ou équivalent. Tu disposes d’au moins 3 ans d’expérience, idéalement au sein d’une startup avec des contraintes de scale et product first Tu excelles dans au moins un langage de programmation (Python, JavaScript, PHP, Ruby, Go, Rust…). Tu maîtrises le SQL, les concepts et le déploiement des bases de données relationnelles et NoSQL. Tu es à l’aise à travailler dans un environnement de startup dynamique, avec de multiples priorités à gérer Bref, tu aimes la gestion de projet et l’amélioration continue. Seraient un plus : Tu as conçu, déployé et maintenu une architecture complexe en production : spécifications, conception, monitoring, alerting, gestion des incidents, recherche des root causes. Tu as de l’expérience Cloud (de préférence AWS) Pourquoi devrais-tu postuler ? Tu crois comme nous que… le succès passe par le collectif pas d’impact sans delivery faire preuve d’audace et tenir ses engagements est primordial en donnant on reçoit beaucoup ! Les étapes clés : Entretien avec notre équipe RH Réalisation d’un test technique chez toi Entretiens avec tes futurs collègues et un manager Entretien avec un co-fondateur","Gens de Confiance is a French online platform that allows its 1.5 million members to buy, sell and rent securely. They are looking for a Data Engineer to deploy and maintain a data pipeline that handles a large volume of data while ensuring its security, monitor and improve data pipeline metrics, prioritize the data needs of marketing and product teams, and propose improvements to the development process. The ideal candidate should have at least 3 years of experience in a startup environment and be comfortable working in a fast-paced, dynamic environment. AWS experience is preferred. The company offers flexible working hours, career development programs, and healthcare benefits.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
260,62900,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-f-h_toulouse,Data Engineer,Meritis,{Java},Télétravail ponctuel autorisé,"Place du Capitole, Toulouse, 31000","IT / Digital, Finance",CDI,2023-03-31,"Meritis est une société de conseil en transformation des Systèmes d’Information et Organisations. Notre mission : associer les meilleurs talents à l’élaboration de transformations créatrices de valeur. Nous sommes une entreprise où il fait bon travailler ! Régulièrement labellisée Great Place To Work ® : N°3 GPTW en 2020, N°1 GPTW en 2017, N°7 GPTW en 2015, N°5 GPTW en 2013. En 2021 Meritis est classée 11e du Palmarès Européen des Best Work Places. 👉 GPTW Au sein du pôle Data IA, vous intégrerez les équipes qui sont responsables de la collecte des données, vous serez en charge de : Récupérer, organiser et mettre en forme la donnée Développer de nouvelles fonctionnalités Réaliser les tests techniques Faire évoluer l'architecture Produire la documentation Encadrer une équipe de développeur Prêt.e à démarrer de nouveaux challenges dans une entreprise où il fait bon vivre ? Meritis offre à ses collaborateurs : • Un accompagnement personnalisé tout au long de leur carrière, • Des parcours professionnels sur mesure : choix des projets, évolution de carrière, formations adaptées et mentoring. Mais aussi de : • Bénéficier d’un réseau de clients riche et varié, • Travailler dans un environnement convivial avec de nombreux événements festifs et techniques, • Envisager des mobilités géographiques internes grâce au maillage régional du groupe. Nos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Vous avez un diplôme d’ingénieur (Bac+5), une spécialisation dans l'ingénierie informatique est un plus Vous disposez de plus de 7 ans d'expérience en développement Java Vous êtes autonome, rigoureux.se et organisé.e Vous êtes bilingue Anglais","Meritis, a consulting firm for information system and organizational transformation, is seeking a Java Developer with over 7 years of experience. The role involves data collection, organizing and formatting data, developing new functionalities, testing, and architecture evolution. The position also includes managing a team of developers. Meritis offers personalized career paths, diverse client network, friendly work environment, and regional mobility opportunities. They are committed to diversity and equal opportunity for people with disabilities. A degree in engineering is required, and proficiency in English is mandatory.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,1,1,0.027697749441558416
389,34697,https://www.welcometothejungle.com/fr/companies/apgar/jobs/data-engineer-confirme_neuilly-sur-seine,Data Engineer Confirmé(e),Apgar Consulting,{portable},Télétravail ponctuel autorisé,Neuilly-Sur-Seine,"IT / Digital, SaaS / Cloud Services, Big Data",CDI,2022-08-08,"Apgar Consulting est un cabinet de Conseil spécialiste de la Data. Apgar concilie son expertise « Data » avec une vision plus générale du fonctionnement de L’Entreprise afin de concevoir des solutions organisationnelles et technologiques sur-mesure pour améliorer l’usage et le partage des informations capitales. L’expertise d’Apgar s’articule autour de 4 axes suivant : Le Meta Data Management : Décrire et piloter les données de l’entreprise pour mieux les valoriser. Le Master Data Management : Maitriser la création, l’usage, le partage et la qualité des données capitales au fonctionnement des processus de l’entreprise La Data Integration : Implémenter les solutions d’échanges inter-applicatifs La Data Preparation : Appliquer la connaissance des données pour les nettoyer et les classer, avant de les entreposer et de les analyser. Pour chacune de ces offres, Apgar porte une attention particulière à l’expérience utilisateur et à la réussite de son intégration dans le système d’information, en adoptant une méthodologie projet pragmatique, adaptée aux solutions implémentées. En qualité de Data Engineer confirmé(e), vous travaillez au sein d’une équipe intervenant directement sur un projet Client. Vous êtes encadré(e) par un Data Engineer sénior ou un manager. Vous prenez la responsabilité d’un chantier qui vous aura été confié par votre chef de projet Vous êtes impliqué(e) sur l’ensemble du projet dès son démarrage et serez en interaction avec le client / métier et les consultants techniques Vous participez à toutes les phases de mise en œuvre de solutions de Data Management Vous participez à l’analyse des besoins, rédigez les spécifications fonctionnelles et assurez l’adéquation de la solution avec le besoin du client Vous assurez un reporting fiable et pertinent de votre activité auprès de votre responsable Vous animez les ateliers de conception fonctionnelles et rédigez les comptes-rendus Vous accompagnez le client dans la recette et la mise en service de la solution Vous êtes responsable de la qualité des livrables et des prestations fournis et contribuez à la qualité globale des projets et missions auxquels vous participez De formation supérieure BAC+4/5, vous disposez de minimum 3 années d’expérience en cabinet de conseil ou ESN · Vous avez des appétences relationnelles et avez des facilités à rédiger et à vous exprimer · Vous avez la capacité de comprendre et de rédiger des spécifications fonctionnelles · Vous souhaitez acquérir des compétences en gestion de projet et management d’équipe · Une expérience en lien avec l’une de nos offres (MDM, Méta data, Data Integration et Data Preparation) serait un réel plus Vos Avantages : Une rémunération attrayante avec une part fixe et une part variable 75% de prise en charge du titre de transport (Navigo) Un téléphone portable et son forfait associé Des tickets restaurant avec participation de l’entreprise Des avantages sociaux et fiscaux (Mutuelle entreprise, PEE et PERCO) La possibilité de télétravailler 2 jours par semaine Alors si vous êtes dynamique, enthousiaste et curieux n’hésitez pas à postuler pour rejoindre un cadre de travail agréable, bienveillant et fraternel …. Futur(e)s Apgariens, Apgariennes nous vous attendons !","Apgar Consulting, a data consulting firm, is seeking an experienced Data Engineer to work on client projects. The ideal candidate should have expertise in meta data management, master data management, data integration, and data preparation. The role involves working within a team, taking responsibility for a project, participating in all phases of data management solutions, and ensuring the quality of deliverables. The candidate should have strong communication skills and be able to write functional specifications. A minimum of three years of experience in consulting or ESN is required, with knowledge of one of Apgar's areas of expertise being a plus. The company offers attractive benefits, including a fixed and variable salary, transportation subsidies, and social and tax benefits.",N,N,N,1,1,0.027697749441558416
320,56424,https://www.welcometothejungle.com/fr/companies/chronotruck/jobs/data-engineer_puteaux,Data engineer,Chronotruck,"{Git,Metabase,PostgreSQL,Airflow,Docker,SQL,Python,MLFlow}",Télétravail partiel possible,"Puteaux, 92800","Transports maritime et routier, Big Data",CDI,2023-03-26,"Chronotruck, c’est une boite tech’ qui veut transformer le transport routier de marchandises à coups d’algorithmes et de Data ! En quelques mots : une plateforme web et mobile B2B de mise en relation d’expéditeurs et de transporteurs professionnels géolocalisés, qui facilite les transactions entre les deux parties. Pionnier dans son domaine (même avant les US !), Chronotruck est un des leaders français du fret routier 2.0. Racheté en 2019 par le géant du transport GEFCO, lui-même racheté en 2022 par CEVA Logistics, l’ambition est de devenir le leader européen du transport routier de marchandises digital. Chronotruck a été retenu dans les 20 entreprises mondiales qui vont révolutionner l’industrie du fret routier par le cabinet Frost & Sullivan. Côté tech, l’équipe est composée d’une dizaine de personnes qui travaillent ensemble pour proposer à nos utilisateurs la meilleure expérience possible. Nos valeurs : autonomie, implication, rigueur, désir de progresser. Si tu veux en savoir plus on a un site développeurs Au sein de l’équipe tech (10 personnes), tu viendras renforcer l’équipe data (3 personnes avec toi) sur les sujets de data engineering. Tu seras en charge de gérer les pipelines de données, l’intégration de données, la qualité des données et également le bon fonctionnement de nos algos en prod. Tu reporteras au head of data. Tes missions Tu es LE (LA) responsable technique de la stack data. Aujourd’hui nous utilisons Python, Airflow comme ETL et pour faire tourner certains algos, fastAPI, MLFlow et Metabase pour la data analyse. Nos db sont en PostgreSQL et tout tourne sur Digital Ocean. Tu t’occupes du déploiement et de la maintenance des pipelines de prod, pour l’ingestion de données et les algos. Tu participes au développement des nouveaux algos en apportant notamment ton aisance technique. Tu fais grandir l’équipe sur les sujets de data engineering. Tu fais de la veille techno sur le data engineering. Idéalement tu as déjà de l’expérience en tant que data engineer, à défaut en tant que dev/devops/software engineer et intéressé par les problématiques data! Tu maitrîses Python, SQL, Docker et Git. Tu as déjà mis en prod des algos de ML et des pipelines de données dans des contextes réels. Soft skills Tu es soucieux(se) de l’expérience utilisateur, tu détestes voir un bug en prod. Tu es data-driven et orienté(e) business. Tu as le souci du détail, mais tu sais aussi être pragmatique. Tu es prêt(e) à t’intéresser au secteur du transport de marchandises. Pourquoi nous rejoindre Tu feras partie d’une petite équipe data composée aujourd’hui d’un head of data et d’un data scientist passionnés, dynamiques, talentueux et impliqués. Tu bénéficieras d’une grande autonomie et tes prises d’initiatives seront encouragées. Tu participeras aux décisions techniques stratégiques. Tu travailleras sur des données riches et spécifiques au transport ainsi que sur des algorithmes originaux. Tu auras 3 jours de télétravail par semaine. Call de présentation. Test technique. Entretien physique ou visio.","Chronotruck is a technology company that uses algorithms and data to transform freight transport. They are searching for a data engineer to manage data pipelines, data integration, and data quality, as well as develop new algorithms and grow the data engineering team. The ideal candidate should have experience with Python, SQL, Docker, Git, and ML algorithms, and be data-driven, business-oriented, and detail-oriented. The company offers a small, dynamic, and talented data team, autonomy, and the opportunity to work on rich and specific transport data and original algorithms. Remote work is available three days a week.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
290,56994,https://www.welcometothejungle.com/fr/companies/fulll/jobs/data-scientist-ingenieur-h-f_aix-en-provence,Data Engineer,Fulll,"{React,python,AWS,tableau,SQL}",Télétravail ponctuel autorisé,"12, Allée des Informaticiens, Aix-en-Provence, Aix-En-Provence, 13290",Logiciels,CDI,2023-03-26,"Parlons bien, parlons fulll ! L’histoire commence en 2021, quand trois éditeurs de logiciels historiques décident d’unir leurs forces et donner naissance à fulll. Aujourd’hui, fulll c’est la seule solution 100% web dédiée à la production comptable et sociale collaborative . Notre mission est d’accompagner les experts-comptables dans le pilotage de leur activité, en mettant à leur disposition des outils innovants, complets, agiles et évolutifs pour simplifier la collaboration avec leurs clients (TPE/PME), les accompagner dans la mise en place de leur méthode de travail. C’est le sens de notre engagement quotidien : les aider à relever leurs défis de transformations, ils sont nombreux. Gestion documentaire, tableau de bord, agenda professionnel partagé, collecte des variables de paie, analyse de la performance, suivi des dépenses et des recettes,… Nous proposons un panel de solutions performantes, et notre projet est d’en développer bien d’autres ! Notre ambition ? Devenir l’acteur incontournable du monde de l’expertise comptable. En 2022, nous avons accompagné plus de 1000 cabinets et plus de 200 000 entreprises sont connectées à notre portail. Pour ce qui est de l’équipe, nous sommes aujourd’hui 225 fulllers répartis sur 4 sites (Lyon, Aix-en-Provence, Rouen et Bordeaux), dont plus de 75% des métiers sont des profils techniques (développeurs, architectes, testeur QA, etc.). Esprit collectif, engagement personnel et dépassement de soi, responsabilité sociétale, bienveillance sont autant de caractéristiques de nos collaboratrices et collaborateurs. Pour l’année 2023, une cinquantaine de postes sont à pourvoir. Et si c’était toi, notre prochain fulller ? Qui cherchons-nous ? En tant que Data Engineer, vous avez la charge de la mise en place des pipelines d’intégration et de traitement de données pour pouvoir développer de nouveaux algorithmes de machine learning. Vous avez aussi la charge du maintien et de la mise à jour de notre data lake et de nos nombreux ETL (Extract-Transform-Load). Vous travaillez main dans la main avec nos architectes et data scientists pour mettre en place la gestion des données pour nos futurs produits. Vous avez pour objectif de rendre nos outils proactifs, de guider le chef d’entreprise dans ses décisions, grâce à l’analyse d’un ensemble de données (non) structurées et multisources. Vous pourrez voir l’impact de votre travail sur des centaines de milliers de clients et contribuer de façon agile à l’ensemble de notre portfolio de services. Quel sera votre quotidien ? Concevoir et développer des preuves de concepts en réponse à des besoins clients Appuyer les équipes techniques dans l’implémentation de nouvelles fonctionnalités Traduire des problèmes business en schéma de données efficaces et scalables Mise en place de stack de transport et traitement de données comme source pour nos nouvelles applications Mise en production de ces pipelines et monitoring pour un impact direct sur des milliers de clients Explorer et donner du sens aux nombreuses sources de données que nous traitons sur les entreprises clientes de Fulll Participation au rayonnement technique de l’équipe Quels seront vos avantages ? Toutes les 5 semaines : des workshops Du bon café gratuit pour bien travailler Des corbeilles de fruits pour faire le plein de vitamines Des participations aux conférences qui comptent (React Europe, Devoxxx, …) Des horaires aménagés et du remote (3 jours par semaine) Une carte Swile Quelles sont les qualités requises ? En tant que Data Engineer, vous avez un minimum de deux ans d’expérience de développement data ops et Big Data, et de mise en production des pipelines. Vous avez de l’expérience dans la création d’API et le datamining. Vous avez même peut-être contribué à améliorer un ou plusieurs projets open source. Vous maîtrisez SQL et python et vous avez de l’expérience de la gestion de données non structurées comme structurées à grande échelle. Vous prenez soin de créer un code propre et performant, utilisant de façon efficace les concepts de data structure/pattern. Vous êtes capable d’expliquer avec des mots simples vos choix techniques. Vous maîtrisez l’anglais et pouvez lire des articles scientifiques en anglais. Une expérience avec les services AWS et infrastructures As code (Terraform) serait un atout. Bref, vous l’aurez sûrement compris, nous ne sommes pas des inconditionnels du CV et des process lourds, on préfère avant tout les humains qui peuvent contribuer à faire grandir notre équipe. Ainsi, le process se compose en 3 étapes : 1er entretien avec notre chargée de recrutement Tests techniques 2e entretien avec deux personnes de l’équipe Data","Fulll is seeking a Data Engineer to set up integration and data processing pipelines for creating new machine learning algorithms. The role involves maintaining and updating the data lake and ETL tools, building data management systems for future products, and collaborating with architects and data scientists. Candidates must have at least two years of experience in data ops, Big Data development, and pipeline production while having expertise in SQL, Python, and managing structured and unstructured data at scale. The position comes with a range of benefits like flexible hours and work from home, English fluency, and experience with AWS and infrastructure as code (Terraform).",Bac +3,Entre 50 et 250 salariés,> 2 ans,1,1,0.027697749441558416
107,72939,https://www.welcometothejungle.com/fr/companies/orange-1/jobs/cloud-data-engineer-confirme-f-h_lyon-6eme-arrondissement,Cloud Data Engineer - Confirmé(e),Orange,"{Python,Scala,QlikView,Azure,durable,PowerBi,Tableau,JAVA,AWS,GCP}",Télétravail ponctuel autorisé,"Lyon - 6ème Arrondissement, 69006","Objets connectés, Big Data, Electronique / Télécommunications",CDI,2023-04-22,"Nous sommes une entreprise de services digitaux née du réseau, reconnue en France et à l’international pour notre capacité à transformer les infrastructures digitales de nos clients. En tant qu’entreprise de services numériques, les compétences et l’expertise de nos 29 000 collaborateurs sont au coeur de notre modèle économique, éthique, responsable et inclusif. Nous offrons des opportunités passionnantes grâce à des projets innovants et valorisants dans les domaines de l’IoT, du cloud, du digital, du big data, de l’intelligence artificielle, de la cybersécurité et du digital workspace. En travaillant ensemble dans une culture où chaque voix est entendue, nous aidons les individus à créer un impact positif et à offrir une croissance durable à nos clients. Au sein de Business & Decision, vous interviendrez sur différentes missions en tant que Consultant(e) : - L’étude, l’analyse et le cadrage des besoins métiers - Analyse des données sources afin d’identifier les cas d’usages métiers - Conception et mise en place de solutions résilientes et sécurisées (Data Lake, pipeline, systèmes temps-réels, base de données…) - Migration fiable et maitrisée des données vers les nouveaux environnements Cloud - Veille technologique pour être à la pointe sur les solutions cloud & Data Diplômé(e) d’une école d’ingénieurs ou d’un Master 2 en Informatique ou équivalent, vous avez une expérience significative sur des projets Data : architecture, modélisation, traitement ou analyse de données, automatisation et outillage DevOps. Vous maitrisez au moins un des langages de programmation suivants : Python, JAVA, Scala. Vous êtes passionné(e) par le Cloud. Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale. L’obtention de la certi_cation Data Engineer (Azure, AWS, GCP), est un vrai plus ! La connaissance d’au moins un outil de suivi et visualisation (PowerBi, Tableau, QlikView…) est également un plus !",,Bac +5 / Master,> 2000 salariés,> 2 ans,1,1,0.027697749441558416
319,56371,https://www.welcometothejungle.com/fr/companies/gatewatcher/jobs/developpeur-data-engineer-h-f_puteaux,Data Engineer,Gatewatcher,"{Go,Kibana,Linux,SQL,Python}",Télétravail ponctuel autorisé,"5, Rue Bellini, Puteaux, 92800",Cybersécurité,CDI,2023-03-26,"Leader technologique de la détection d’intrusions et de menaces avancées, Gatewatcher protège depuis 2015 les réseaux critiques des plus grandes entreprises comme des institutions publiques, en France et à l’international. Fort d’un réseau de partenaires certifiés pour accompagner nos clients les plus exigeants, Gatewatcher se déploie en Europe, mais aussi au Moyen Orient, en Asie et en Afrique Francophone. Notre vision est d’offrir une approche flexible (cloud, sur site, hybride), innovante et ouverte à l’IA, sans perturber l’architecture en place pour permettre aux équipes cybersécurité une meilleure efficacité dans la priorisation de leurs actions de remédiation. Nos solutions apportent une amélioration immédiate aux enjeux actuels et futurs de cybersécurité par une réponse adaptée aux nouveaux besoins de détection des organisations. Elles combinent des algorithmes d’apprentissage automatique avec différentes méthodes d’analyse du trafic réseau et sont conçues pour être évolutives et immédiatement opérationnelles pour une intégration facilitée dans les SOC (Security Operations Center). Chez Gatewatcher, nous vous proposons d’évoluer dans un environnement stimulant au sein d’une équipe pluridisciplinaire de haut niveau d’experts en sécurité, système, réseau, chiffrement et machine learning. Nos collaborateurs sont des passionnés et aiment partager leurs connaissances au quotidien. Nos bureaux sont situés au Campus Cyber au cœur du quartier de la Défense, soit l’endroit idéal pour s’épanouir et prendre part à un écosystème dynamique autour de la cybersécurité. Nous recherchons actuellement Data Engineer en CDI , pour accompagner l’hyper-croissance de nos produits en France et à l’international. Vos missions : Amélioration des pipelines de données et optimisation des BDD Mise en place d’outils de benchmark Dashboarding Kibana Environnement technique : Linux Python 3 SQL Go Diplômé(e) d’un Master en informatique Expérience de 2 ans minimum en tant que Ingénieur Data Compétent sur un environnement Linux Maîtrise de SQL, Python 3, ELK ou une techno similaire Maîtrise de Go apprécié Passionné(e), force de proposition et autonome Pourquoi nous rejoindre ? Société en hyper-croissance Découvrir ou peaufiner ses compétences en cybersécurité au contact d’une expertise pluridisciplinaire reconnue Afterwork, team building et baby-foot avec des équipes de passionnés Flexibilité sur le sujet du télétravail Entretien RH en visio (test) Entretien Technique en visio Entretien avec la Direction dans nos locaux","Gatewatcher, a technology leader in intrusion detection and advanced threat protection, is seeking a Data Engineer with minimum of 2 years experience working with Linux, Python 3, SQL and ELK or similar technologies. They are looking for someone who is passionate, independent, and a proposal force to join their highly skilled security experts team. With an emphasis on flexible, innovative, AI-driven approaches maintaining pre-existing architecture, the company works to provide immediate and lasting solutions for cyber-security challenges ranging from database optimization to bench-marking, all in the context of a highly collaborative work environment.",Bac +5 / Master,Entre 50 et 250 salariés,> 2 ans,1,1,0.027697749441558416
165,63013,https://www.welcometothejungle.com/fr/companies/le-pont/jobs/data-engineer-poei_levallois-perret,Data Engineer - POEI,Le Pont,"{Java,Scala,Python,SPARK}",Télétravail ponctuel autorisé,Levallois-Perret,N,CDI,2023-03-31,"Acteur multi-spécialiste en transformation digitale avec 960 collaborateurs, conseil métier et conseil en technologies, Audensiel accompagne ses clients de tout secteur d’activité en France et à l’international dans les domaines suivants : Digital : projets de transformation digitale, de la direction de projets en méthode Agile en passant par l’AMOA et le développement d’applications jusqu’à la recette/test. Conseil : conseil IT au sein des DSI et conseil métier au sein des directions fonctionnelles spécifiquement pour la Banque, l’Assurance et l’Industrie pharmaceutique dans leurs problématiques de gouvernance, de conformité réglementaire, de gestion des risques et de transformation des directions financières. Data/IA : Architecture et développement de solutions Big Data avec des consultants Data Engineer et Data Scientists. Développement projets innovants d’intelligence artificielle de nos clients sous forme de POC. IoT : Exploitation des données des objets connectés et leurs traitements au sein de systèmes complexes interconnectés. Conception de l’ensemble de la chaîne de valeur qui permet d’offrir la meilleure expérience utilisateur pour ces nouveaux services et d’optimiser les gains de productivité. Cybersécurité : Accompagnement sur la gouvernance des problématiques de cybersécurité de nos clients. Audit et gestion de projets pour la défense et la sécurité de données. - Cloud/DevOps : Accompagnement à différents niveaux de votre projet, stratégie et gouvernance, architecture, développement ou encore DevOps. Rejoignez AUDENSIEL en intégrant la formation POEI “Data Engineer” avec l’organisme LePont 100% financée par Pôle Emploi afin d’acquérir les compétences clés qui vous permettront d’accompagner nos clients dans leur projet de transformation digitale et booster votre carrière en tant que Data Engineer. En tant que Data Engineer, vous intervenez sur différentes missions transverses : Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données Création de pipelines de données, traitement et transformation de la donnée. Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles Assurer le suivi de la production 15 POSTES OUVERTS en CDI Villes : Lille, Evreux, Paris, Strasbourg, Rennes, Nantes, Tours, Niort, Bordeaux, Biarritz, Toulouse, Lyon, Aix en Provence, Sophia Antipolis **Vous êtes inscrit(e) à Pôle Emploi. ** Issu(e) d’une filière scientifique ou informatique vous disposez d’un Bac+4/5 ou diplôme d’ingénieur, vous disposez d’une expérience significative en développement informatique minimum. Hard Skills : Vous maitrisez un langage objet :Java/Python Notions complémentaire en SPARK et ou Scala seraient un + Niveau d’anglais requis Soft Skills : Des qualités d’autonomie, de flexibilité et de responsabilité L’esprit d’équipe et la volonté de prendre part à une aventure collective Vous passez un premier entretien avec LePont Vous passez un second entretien avec l’entreprise partenaire Votre dossier passe en commission d’admission Si vous êtes validés par l’entreprise, vous débutez votre formation avec LePont Une fois la formation validée, vous débutez votre CDI chez l’entreprise partenaire. Pour postuler : https://www.lepont-learning.com/fr/contact/inscription-poei/","Audensiel, a digital transformation company with 960 employees, is looking for Data Engineers to support diverse projects such as Digital, Consultancy, Data/IA, IoT, Cybersecurity, and Cloud/DevOps. The ideal candidate must have experience in Java/Python, and the knowledge of languages such as Spark and Scala is a plus. Candidates will need to attend an interview with LePont and the second interview with the hiring company before starting the training with LePont. Once the training is completed, candidates are eligible for a full-time position at the partnering company.",Bac +4,Entre 50 et 250 salariés,> 2 ans,1,1,0.027697749441558416
162,57091,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/engineer-analytics-h-f-poei_puteaux,Analytics Engineer  | POEI,Datascientest,"{UNIX,Python,LINUX}",Télétravail ponctuel autorisé,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"Vous cherchez la bonne opportunité pour booster votre carrière ? Cette offre d’emploi vous permet de démarrer votre carrière en tant que Analytique ingénieur, un métier en tension et en plein essor. Une fois sélectionné(e), vous bénéficierez d’une formation 100% financée par Pôle Emploi d’une durée de 3 mois afin de développer les compétences d’un véritable expert. Cette formation sera certifiée par l’Université Paris 1 Panthéon-Sorbonne. En tant que Analytics Engineer vous serez responsable des missions suivantes : Définir, mettre en place et exécuter l’ensemble des techniques en vue de la réalisation expérimentale des projets. Traiter, analyser, interpréter les données et valider les résultats. Rédiger ou vérifier les protocoles et rapports en lien avec l’activité Développement analytique. Communiquer avec le client sur les résultats obtenues et les avancés Développer, optimiser et valider les méthodes d’analyse des produits Rédiger ou vérifier les protocoles et rapports en lien avec l’activité analytique Mener et/ou participer à la résolution des problèmes afin d’y parvenir. Participer à la veille technologique Dynamique, autonome et rigoureux(se), vous avez le sens du serviceclient ? Issue d’un Bac +3/5 en systèmes et réseaux ou Bac + 3/5 en Informatique Connaissance des systèmes d’exploitation Windows et/ou UNIX/LINUX Vous avez un bon niveau d’anglais Un plus : Vous avez des notions en Python. Vous êtes inscrit(e) à Pôle Emploi. N’hésitez pas à postuler ! Step 1 : Premier échange avec DataScientest Step 2 : Entretien d’embauche avec notre entreprise partenaire, spécialisée dans le conseil Step 3 : Si step 2 validé : Formation de 3 mois chez DataScientest Step 4 : Début des missions en CDI","This job offers a training opportunity to become an Analytics Engineer with skills in experimental project execution, data analysis, and communication with clients. Applicants should have a degree in systems and networks or computer science, knowledge of Windows and/or UNIX/LINUX, and a good level of English. Python skills are a plus. The position is open to candidates registered with Pôle Emploi. The hiring process involves three steps: an initial conversation with DataScientest, an interview with the company's partner, a consulting firm, and a three-month training program at DataScientest before starting full-time employment.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,1,1,0.027697749441558416
352,56586,https://www.welcometothejungle.com/fr/companies/cenisis/jobs/data-engineer_lille,Data Engineer,CENISIS - Data Agency,"{NoSql,R,Cassandra,SQL,Python}",Télétravail partiel possible,"149, Avenue de Bretagne, Lille, 59000","IT / Digital, Transformation",CDI,2023-03-26,"CENISIS, expert français en Data Management, aide les entreprises à tirer profit de leur Data, patrimoine précieux et à en exploiter toute la richesse. Grâce à ses collaborateur.rice.s, Cenisis a pour but d’inspirer l’innovation de la Data. Rejoindre Cenisis, c’est rejoindre une entreprise qui place l’ambition et le développement national au cœur de ses objectifs dans un environnement riche et stimulant. Nos équipes nous poussent à l’exigence pour progresser dans la bienveillance ! L’entreprise incarne les valeurs portées par ses collaborateur.rice.s : 👉 L’audace : Oser des choix inspirants et singuliers. Savoir prendre des risques et des initiatives au quotidien. 👉 L’authenticité : Rester cohérent avec nos engagements. Favoriser la transparence et l’honnêteté. 👉 La cohésion : Partager nos richesses individuelles et collectives. Créer une unicité. 👉 La responsabilité : Porter et assumer des ambitions durables. 🎓 Cenisis Academy, école du Data Management en France, propose des formations adaptées à la fois en interne et en externe à tous les publics de l’entreprise. Tu souhaites rejoindre une communauté Data Addict à taille humaine ? Nous recherchons un Data Engineer F/H qui aura un rôle à part entière dans la communauté CENISIS. Nous t’apportons l’opportunité d’intervenir sur un large choix de projets mais également de faire partie de la CENISIS Academy. Tes missions ? Gérer et mettre en place les structures nécessaires ainsi que les données de type big data pour permettre l’exploitabilité par les data scientists Permettre la collecte, le stockage et l’exploitabilité fluide des données Constuire les outils de collecte et d’analyse de données (structurées et non structurées) Choisir la ou les méthode(s)/technologie(s) les plus adaptée Rejoindre CENISIS, c’est rejoindre une entreprise qui : ♟Positionne ses consultants au cœur de la stratégie de transformation digitale 🚀 ⚡️Permet à ses collaborateurs d’avoir un réel impact, d’innover, tester et construire notre avenir 💥 🌏Choisit de porter des valeurs fortes et d’être avancé au niveau social et environnemental avec une forte politique de diversité et d’inclusion #TeamRSE 🍃 🏟 Anime des formations en interne et en externe #CENISISAcademy 📚 Ce qui nous anime ? Nos valeurs basées sur l’audace, la cohésion, l’authenticité et la responsabilité nous poussent à l’innovation et à la croissance. Pour cela, en 2020, CENISIS a intégré l’accélérateur BPI dédié aux entreprises ambitieuses pour ainsi, devenir une Data Agency. En tant qu’entreprise engagée dans une démarche responsable, nous accordons une grande importance à l’impact du bien-être personnel et collectif et à l’engagement envers la diversité, l’équité et l’inclusion. Ton profil ? Tu es issu(e) d’une formation supérieure Bac+3/5 de type licence ou master dans le domaine de l’ingénierie avec une orientation Data. Idéalement tu possèdes une expérience significative de 3 ans dans la Data. Ton savoir-être : Ta capacité à fédérer une équipe et à contribuer à la réussite de celle-ci dans ses différents projets Ta curiosité, ton envie de toujours innover, et ton autonomie Tu es force de proposition et tu aimes le challenge et challenger les autres Ta différence, ce qui fait ta force et ta richesse pour l’entreprise Ton savoir-faire : Ton expertise élevée dans les technologies de manipulation des données Ta maîtrise des technologies de base de données (NoSql, SQL, …), Ta maîtrise des technologies type Cassandra, Python, R, … Ta compréhension des problématiques des datascientists Ta capacité à mettre en musique des solutions dans une démarche DataOps Alors tu es partant(e) pour relever le défi ? N’hésite pas à postuler, ce serait le début d’une superbe aventure ensemble ! A compétences égales, tous nos postes sont ouverts aux personnes en situation de handicap. Le processus de recrutement ? Première rencontre avec Marine, Human Resource Manager. Deuxième échange avec ton futur Manager, Laurence et/ou Laurent, Responsable Fondations Data ou Jérôme, Responsable du Pôle Data Insight. Troisième échange avec Gilles, Directeur Offres et Innovation et/ou Cédric, Dirigeant.","CENISIS, a French Data Management company, is seeking a Data Engineer who will play a significant role in their community. The ideal candidate should have a Bachelor's or Master's degree in engineering with a data focus, at least three years of experience in the field, and strong expertise in data manipulation technologies. The Data Engineer will be responsible for managing and establishing the necessary structures and big data types for data scientists to exploit, collecting, storing and utilizing data, constructing data collection and analytics tools, choosing suitable methodologies/technologies, and contributing to team success. CENISIS is committed to being socially and environmentally responsible, and the recruitment process includes several meetings with key team members.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
113,34757,https://www.welcometothejungle.com/fr/companies/aphp/jobs/ingenieur-donnees-imagerie-medicale-projet-operandi_paris,Ingénieur Données - Imagerie Médicale (projet OPERANDI),Assistance Publique - Hôpitaux de Paris - DSI,"{NVIDIA,Oracle,UNIX,bash,Hive,Nvidia,Docker,Postgresql,MySQL,gitlab,Kafka,Linux,Jenkins,Kubernetes,HBase,Hadoop,Jupyter,R,Spark,sql,Python}",Télétravail ponctuel autorisé,Paris,"Intelligence artificielle / Machine Learning, Big Data, Santé",CDD / Temporaire,2022-08-08,"L’ Assistance Publique - Hôpitaux de Paris (AP - HP) est un établissement public de santé et le centre hospitalier universitaire - CHU - de la région Ile-de-France, reconnu mondialement pour sa recherche. Le département Web Innovation Données (WIND) s’inscrit au sein de sa Direction des Systèmes d’Information. Sa mission ? 🎯Réaliser les projets numériques innovants au contact du monde hospitalier. Ses projets phares ? 🚀 Construire le plus large entrepôt public de données de santé en Europe ! Le projet vise à valoriser les données produites à l’AP-HP pour la recherche, l’innovation et le pilotage des soins, tout en protégeant les données patient. L’Entrepôt de Données de Santé, c’est déjà +8 millions de patients dont les données sont structurées et référencées sur une plateforme Big Data dédiée. 🙋‍♀️🙋‍♂Faciliter le quotidien des patients! Le domaine gère notamment toutes les applications mobiles et tous les téléservices de l’AP-HP. 🔬Monter une plateforme Bio-Informatique centrale pour assister les pôles de biologie de l’ AP-HP dans leurs besoins informatiques (gestion du séquençage, déploiement de ressources de calcul). 🌼Développer et déployer au niveau national les outils de collecte et d’analyse épidémiologique des données relatives aux maladies rares. La mission de votre équipe Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP. ​ L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision. ​ La Plateforme Big Data de l’AP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (24 Nvidia P40, 12 NVIDIA V100), de 10 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives. ​ Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP. Dans le domaine de l’imagerie médicale, les images sont majoritairement produites dans les plus de 20 services de radiologie de l’APHP et stockés dans un PACS Centrale APHP, géré par le pôle imagerie de la DSI. Vos missions Au sein de l’équipe en charge de la Plateforme mégadonnées de l’APHP, vous serez recruté dans le cadre du projet OPERANDI. Le projet OPERANDI, Optimisation et amélioration de l’efficacité des thérapies ciblées par radionucléides dans les cancers digestifs par imagomics, coordonné par le Pr Valérie Vilgrain, est lauréat de l’appel à projet Recherche Hospitalo-Universitaire en santé (RHU) – Appel à projets – vague 5 – 2021. Le projet OPERANDI vise à l’élaboration d’algorithmes d’intelligence artificielle basés sur l’imagerie multi-échelle prédictive et pronostique, au développement d’une approche holistique de la thérapie guidée simultanément par TEP-IRM, au décodage des phénomènes de radio-résistance et de réponse tumorale aux traitements et à l’évaluation de nouvelles combinaisons de médicaments et radiopharmaceutiques, ceci dans le but d’améliorer la sélection, le traitement et le suivi des patients. Vous serez directement intégré dans l’équipe Imagerie de la plateforme mégadonnées. Tout en bénéficiant de l’ensemble des expertises et compétences de la plateforme mégadonnées, vous devez compléter et mettre en œuvre l’ensemble des composants nécessaire à la collecte et l’exploitation des données d’imageries prévues dans le projet RHU OPERANDI. Cela sera réalisé au travers de développements spécifiques, d’intégration d’outils pré-existants et libres ainsi que d’outils et logiciels mis à disposition par les partenaires académiques ou industriels du projet. Afin d’accompagner au mieux la réalisation du projet, vous serez en charge de mettre en œuvre le suivi et le cadrage du projet technique en interagissant avec les médecins, chercheurs, industriels, ingénieurs, data-scientist du projet. Vous intervenez dans le cadre de groupes de travail pluridisciplinaires visant la définition de nouvelles fonctionnalités et vous réaliserez le test et la validation des nouvelles fonctionnalités implémentées avant leur mise en production. Par ailleurs, vous participez à l’assistance à la mise en œuvre et à la maintenance en condition opérationnelle des outils développés. En tant que data engineer spécialisé en imagerie médicale, vous : Rédiger des cahiers des charges, spécifications fonctionnelles et techniques ainsi que des dossiers d’architecture technique ; Concevoir et développer des outils (sélection de cohortes de patients, modélisation, algorithmes d’analyse, méthodes statistiques, visualisation, etc.) adaptés au contexte du cluster big data ; Contribuer à la mise en place de pipelines de traitement et d’analyse de données d’imagerie médicales radiologiques (DICOM) et anatomocytopathologies (Lame virtuelle); Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark) ; Rédiger la documentation technique ainsi que la documentation utilisateur ; Dans le cadre des développements réalisés en Open Source, participer à l’animation de la communauté autour des projets créés par la résolution de bugs, la gestion des suggestions de modification du code (Pull/Request) ou encore la gestion des propositions d’améliorations ; Intervenir sur la conception d’outils pour l’annotation de données médicales d’imagerie, textuelles, physiologiques et autres, et ce, afin de permettre aux chercheurs d’entraîner des modèles de Machine Learning/Deep Learning en lien avec l’émergence de l’Intelligence Artificielle à l’AP-HP ; Assurer la sécurisation des applications ou outils développés ; Réaliser une veille technique dans son domaine d’activité et un transfert de compétence au sein de l’équipe. Vous avez un savoir faire dans un de ces domaines : Expertise en Programmation Informatique (Windows & UNIX) Bonne maîtrise des langages Python/R et de bash Maîtrise des architectures et de l’écosystème Big Data (Hadoop, Hive, HBase, Spark, Kafka, …) Bonnes connaissances des bases de données Oracle, Postgresql ou MySQL et langages associés (sql) Bonne maîtrise des données d’imagerie médicales radiologiques (DICOM, NIFTI …) Bonne maîtrise des données d’imagerie médicales anatomocytopathologiques (SVS, NDPI, MRXS, …) Connaissance approfondie en méthodes de développement logiciel (méthodes agile), méthodes d’analyse et de modélisation (Kanban, UML …) Connaissance des méthodologies devops et des outils associés (Docker, Kubernetes, Jenkins…) Connaissance des outils de versionning (gitlab Connaissance des outils d’intégration & de déploiement continue (CI/CD) Connaissances en méthode de conduite de projet (planification, reporting, analyse de risques, …) Idéalement, vous avez des connaisances … du modèle de donnée OMOP et du standard d’interopérabilité HL7-FHIR en administration d’environnements Linux des problématiques fonctionnelles hospitalières (structures, processus) et des métiers de la santé en droit des données informatiques des bonnes pratiques de sécurité informatique ; de la réglementation informatique et libertés ; Et une expérience concernant le travail en équipe, Concevoir et évaluer un projet / un processus relevant de son domaine de compétence ; Identifier, analyser, prioriser et synthétiser les informations relevant de son domaine d’activité ; Animer / communiquer / motiver au sein d’une équipe projet ; Capacité à animer des réunions courtes, en imposant une préparation et un compte rendu ; Rédiger et mettre en forme des notes, documents et /ou rapports, relatifs à son domaine de compétence ; Concevoir et rédiger une documentation spécifique à son domaine de compétence ; S’exprimer en public ; Au travers de 2 à 3 entretiens vous échangerez avec différents chefs de projets et le directeur de la plateforme","L'AP-HP, un centre hospitalier universitaire de renommée mondiale, cherche un data engineer spécialisé en imagerie médicale pour rejoindre leur équipe Plateforme Big Data. Le candidat sera chargé de concevoir et développer des outils pour la collecte et l'analyse de données d'imageries prévues dans le projet RHU OPERANDI. La personne idéale doit avoir des connaissances en programmation informatique, en écosystème Big Data, en données d'imagerie médicale, en méthodes de développement logiciel et de conduite de projet, ainsi que des connaissances en sécurité informatique et en réglementation informatique.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,1,1,0.027697749441558416
324,56541,https://www.welcometothejungle.com/fr/companies/fabernovel/jobs/data-engineer-marketing_paris_FABER_zxr4wmK,Data Engineer (Marketing),FABERNOVEL,"{Scala,SQL,Python,noSQL}",Télétravail ponctuel autorisé,"46 rue Saint Lazare, Paris, 75009","IT / Digital, Stratégie, Transformation, Formation",CDI,2023-03-26,"Créé en 2003 au cœur de l’écosystème numérique français, Fabernovel naît d’une conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure. Aujourd’hui, ce sont 350 talents, sur 4 continents, experts du conseil en transformation numérique et de la création de produits et de services numériques. Nous maîtrisons les expertises liées au design, aux technologies, au marketing et aux cultures nouvelles dans l’entreprise et accompagnons de grandes entreprises de tous secteurs d’activité dans leur projet de transformation digitale et culturelle. Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Analysts, Product Managers, Media Specialists, Finance Managers, DevOps, Communication Managers, Business Developers… qui font naître l’innovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de méthodologies à la pointe, avec toujours l’objectif de les rendre le plus autonome possible. Rattaché(e) au pôle Marketing de l’agence et à l’équipe Tech, vous êtes garant du développement d'architectures et flux Data, de la collecte multi-sources de données, du pilotage et de la pertinence de ces données. Vos missions : Analyser les besoins d’infrastructure des données du client pour proposer la solution la plus pertinente : Data Warehouse, Database etc. Concevoir, construire et mettre en production des solutions d’extraction, de transformation et de chargement des données (ETL) Créer, automatiser, gérer et maintenir des flux de données Assurer la qualité et l’accessibilité de la donnée pour qu’elle soit facilement exploitable par les experts Fabernovel et les clients. Trouver et mettre en place la meilleure solution d’architecture basée sur le besoin, la nature / volumétrie de la donnée et l’environnement du SI du client. Assurer la maintenance de projets internes et des missions clients. Assister les experts Fabernovel et nos clients dans la mise en place d’un socle data robuste et fiable (outils de webanalyse, dashboarding, ETL), à travers l’audit des dispositifs de mesure, la proposition de solutions techniques adaptées et l'exploration de techniques d’automatisation / de nettoyage de la donnée (redressement, enrichissement…) Faire de la veille active (tendances marchés, solutions innovantes) pour mieux conseiller nos clients ou participer à la rédaction d’études de cas / livres blancs en support des équipes communication et commerciales de l’agence. Assurer la transmission et le partage de connaissance à ses pairs. Profil recherché Diplômé d’une école d’ingénieur, d’un Master en ingénierie informatique ou équivalent. A au moins 1 an d'expérience en data engineering A déjà évolué sur un environnement Cloud PaaS, IaaS (Google, Amazon...) Maîtrise la programmation en Python et / ou Scala A une bonne connaissance du Web en général, et des problématiques data engineering en particulier Est à l'aise avec le Data processing Dispose de bonnes connaissances en SQL, noSQL & est familier avec au moins un ETL ou équivalent A une connaissance des outils de data management (webanalyse, data viz, DMP,...) Est rigoureux, organisé, pragmatique et curieux Maîtrise l’Anglais technique Fait preuve d’aisance rédactionnelle et relationnelle Une certification Google Cloud Platform est un plus Ce que nous offrons à tous nos talents Des projets riches et impactants, chez Fabernovel nous transformons les environnements, les situations, avec nos propres méthodes et secrets de fabrication. Une société apprenante ou nous avons conçu notre propre Learning development factory pour un partage de connaissance et un apprentissage continue. Un management fondé sur la bienveillance, il n’y a pas d’échec, seulement des itérations et des occasions d’apprendre. De la liberté dans ses choix : Flex office, horaires aménageables, possibilité de remote, culture de l’intrapreunariat. Des avantages toujours sympa, avec des locaux au coeur de Paris, des paniers fruits, du café/thé, des salles de jeux techs et low techs, ainsi que des salles de siestes. Mais aussi… Une Carte Swile prise en charge à 60% par Fabernovel Accès à des offres privilèges Classpass Remboursement de 50% des transports RTT PC ou MacBook À propos de nous : Créé en 2003 au cœur de l’écosystème numérique français, Fabernovel naît d’une conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure. Aujourd’hui, ce sont 350 talents, sur 3 continents, experts du conseil en transformation numérique et de la création de produits et de services numériques. Nous maîtrisons les expertises liées au design, aux technologies, au marketing et aux cultures nouvelles dans l’entreprise et accompagnons de grandes entreprises de tous secteurs d’activité dans leur projet de transformation digitale et culturelle. Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Analysts, Product Managers, Media Specialists, Finance Managers, Communication Managers, Business Developers…qui font naître l’innovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de méthodologies à la pointe, avec toujours l’objectif de les rendre le plus autonome possible. Fabernovel s’engage à accorder la même considération à toutes les candidatures, sans distinction discriminatoire. L’inclusivité fait partie de nos valeurs et nous souhaitons faire vivre la même expérience à tou.te.s","Fabernovel, a digital transformation company with 350 employees across four continents, is seeking a data engineer with experience in cloud environments such as Google Cloud Platform or Amazon Web Services. The successful candidate will have knowledge of data management tools, programming in Python and/or Scala, and data processing. Other requirements include a master's degree in computer engineering, a good level of English, and the ability to work well in a team. Fabernovel offers a positive, learning-based workplace culture, flexible hours, and remote working options, as well as other perks.",Bac +5 / Master,Entre 250 et 2000 salariés,> 1 an,1,1,0.027697749441558416
141,56521,https://www.welcometothejungle.com/fr/companies/datapy/jobs/data-engineer-spark-scala_paris,Data Engineer  SPARK et python ou SCALA,Datapy,"{GCP,python,Jenkins,Scala,GitLab,Kubernetes,AWS,Docker,via,Spark,Azure,Hadoop}",Télétravail partiel possible,"94, Rue Saint-Lazare, Paris, 75009",IT / Digital,CDI,2023-03-26,"La donnée et la technologie sont des leviers majeurs pour rendre le monde meilleur. Les données sont devenues une ressource centrale des entreprises. DataPy industrialise leur traitement et le développement des applications qui les utilisent. DataPy accompagne ses consultants et ses clients avec des valeurs socialement et écologiquement responsables. La mission consiste en la construction de bout en bout d applications permettant d’exploiter des données: Cadrage de la question, des besoins et de la problématique Ingestion des données depuis les systèmes existants Modélisation et transformation de données via Spark Développement, déploiement et optimisation de jobs Spark Création des tables, analyse et recherche d informations dans les bases de données Développement des reportings et outils d analyse et visualisation des données Utilisation de technologies et méthodes de DevOps pour industrialiser les projets Stack technique: Spark Langage: Scala, python Infrastructure selon le contexte du client : Hadoop, Azure, AWS ou GCP, avec souvent des projets de migrationCI/CD et Devops: Terraform, Ansible, Jenkins, Azure Devops, GitLab, JUnit, Sonarqube, Kubernetes, Docker Dans le cadre de cette mission, vous serez amené à développer vos compétences sur les technologies de CI/CD et de devops. Data Engineer, avec a moins minimum 3 ans d’expérience confirmée sur Spark et Scala . Les qualités humaines requises: Force de proposition, Rigueur, Réactivité, Esprit analytique et de synthèse, Esprit d équipe, Excellent relationnel, Sens de l organisation, Sens de la qualité Le processus de sélection comprend un entretien avec un responsable Datapy, un entretien avec notre client permettant de préciser finement la mission, et éventuellement un test technique auquel vous pourrez vous préparer.","DataPy is seeking a Data Engineer with at least 3 years of confirmed experience in Spark and Scala to develop end-to-end applications for exploiting data in socially and environmentally responsible ways. The role involves framing questions and requirements, ingesting data, modeling and transforming data using Spark, developing Spark jobs, creating tables and analyzing databases, and developing reporting and analysis tools. The job requires proficiency with DevOps and CI/CD technologies such as Terraform, Ansible, Jenkins, Azure Devops, GitLab, JUnit, Sonarqube, Kubernetes, and Docker. The ideal candidate should possess qualities such as proposal strength, rigor, agility, analytical and synthetic thinking, teamwork, excellent relationship skills, organizational skills, and quality awareness.",Bac +5 / Master,N,> 3 ans,2,0,0.027697749441558416
301,56980,https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer-confirme-h-f_neuilly-sur-seine,Data Engineer Confirmé.e,LittleBigCode,"{GCP,Scala,AWS,via,R,Azure,SQL,Python}",Télétravail partiel possible,"7 Rue de Chartres, Neuilly-Sur-Seine, 92200","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"LittleBigCode est un laboratoire de conseil digital spécialisé dans la conception d’applications d’Intelligence Artificielle et de plateformes Big Data. Leur mission est de contribuer à démocratiser l’usage de ces technologies en construisant avec leurs clients des solutions utiles et profitables pour la société de demain. Dans les faits, ils permettent à leurs clients (sociétés du CAC40, ETI, PME et startup) de valoriser leurs données en la rendant exploitable sur le Cloud. Puis, ils la rendent intelligible via l’industrialisation de modèles d’Intelligence Artificielle orientés « Aide à la décision » ou « Automatisation ». Pour cela, ils délivrent des applications clés en main et développent également leurs propres solutions tout en intervenant sur des missions de conseil. Nous cherchons à renforcer notre équipe technique grâce à un profil Data Engineer ! Concrètement au quotidien, tu travailleras en mode agile et en équipe (composée de Data Scientist, d’architectes, de coach Devops …). Quel sera ton rôle chez nous ? Tu interviendras sur les activités et problématiques suivantes : Conseil et expertise auprès de nos clients sur leurs projets stratégiques : Modélisation, Conception & Delivery Formation, accompagnement & animation : Formation et accompagnement des équipes dans leur montée en compétences Organisation & Animation des communautés et des Tech-Events (Workshops, Challenge interne, Hackaton …) Rédaction des articles R&D et Solutions : Participation au développement de solutions internes Proposition et création de solutions innovantes Avant-vente : Participation aux appels d’offres Réalisation de POC Tu es diplômé.e d’une grande école d’ingénieur en mathématique, statistique ou informatique et tu as au moins 3 ans d’expérience ! N’oublie pas que nous recherchons un profil confirmé pour ce poste ce qui signifie que tu dois maitriser ton environnement technique ! Tu es solide sur les concepts de modélisation et structuration de données. Tu maîtrises l’industrialisation de pipelines d’ingestion et la mise en production de modèles Data Sciences. Tu maîtrises parfaitement les langages : Python, SQL (si possible Scala) et tu sais délivrer un code propre facilement maintenable et industrialisable. Tu sais parfaitement utiliser l’une des plateformes suivantes : Azure, GCP, AWS et connais également bien les différentes typologies de Base de données. Tu es robuste sur la mise en place et l’utilisation d’ETL. Si en plus tu as une expérience les environnements de données à haut volume … … Alors n’attends plus et viens rencontrer notre LittleBigTeam !","LittleBigCode is seeking a Data Engineer to join their team of Agile developers. The ideal candidate would have at least three years of experience working in a mathematical, statistical, or IT field, as well as solid knowledge of data structuring and modeling concepts, pipeline data ingestion, and data science model production. Additionally, the candidate should be proficient in Python, SQL, and one of the following platforms: Azure, GCP, or AWS.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
294,56885,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_tours,Expert.e technique ETL Semarchy xDI / Stambia,CGI,{},Télétravail partiel possible,"Tours, 37000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Semarchy xDI / Stambia • Participer aux échanges avec l’éditeur Semarchy • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné.e d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert.e technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global leader in digital consulting and services, seeks an experienced technical expert in data integration and ETL using Semarchy xDI/Stambia. The role involves improving the efficiency and effectiveness of solutions, collaborating with engineers to find technical solutions, contributing to technical documentation, providing training, and participating in pre-sale and recruitment activities. The successful candidate will have at least three years of experience in digital services or consulting, a passion for teamwork and learning, and an audacious and ambitious spirit. Knowledge of data quality and governance is desirable, and CGI is an inclusive employer that promotes career development and well-being for all employees.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
326,52913,https://www.welcometothejungle.com/fr/companies/helloasso/jobs/database-administrator_begles,Data Engineer,HelloAsso,"{Python,nosql,Snowflake,Synapse,Kafka,sql,SQL,SISense,Tableau}",Télétravail partiel possible,"2, Rue Marc Sangnier, Bègles, 33130","FinTech / InsurTech, Économie collaborative",CDI,2023-03-20,"Notre mission est d’apporter la meilleure innovation technologique aux acteurs de l’innovation sociale 🚀 🏆HelloAsso est la solution de paiement leader du secteur associatif. Depuis 2009, nous avons accompagné +215 000 organismes à collecter 850 millions d’euros grâce à nos services. Nous faisons partie de ces pionniers qui se sont appuyés sur la tech pour jouer un rôle positif sur la société ⚡️ Et pour concrétiser cette vision nous nous appuyons sur un modèle vertueux unique en France : HelloAsso est 100% gratuit pour les associations et financé librement par les internautes qui souhaitent donner de l’ampleur à notre impact 🔁🌱 Quels que soient nos métiers, notre équipe de +100 personnes partage le goût de l’audace, de l’engagement et de l’innovation qui fait bouger les lignes. 🫵🏼 Votre futur rôle chez HelloAsso Au sein de l’équipe DevOps vous garantissez la cohérence, la qualité, la sécurité et l’accessibilité permanente des informations . Votre rôle est de concevoir, gérer et maintenir les systèmes de collecte, de stockage, de traitement et de diffusion de données pour répondre aux besoins opérationnels et analytiques de HelloAsso. 🚀 Vos futures missions 🛢️ Conception et développement de systèmes de stockage de données robuste et fiables Vous évaluez les besoins en matière de données de l’entreprise. Vous sélectionnez et mettez en place les technologies de stockage de données appropriées aux besoins évalués Vous concevez et mettez en oeuvre des systèmes de stockage de données maintenables et scalables Vous mettez en place un processus de surveillance pour garantir la fiabilité et la disponibilité des systèmes ✏️ Collecte, préparation et traitement de données Vous élaborez des stratégies pour collecter et acquérir des données de diverses sources. Vous êtes en charge du nettoyage, de la validation et de la transformation des données pour les rendre utilisables pour les analyses et les applications. Vous mettez en place des processus pour garantir la qualité, la sécurité et l’intégrité des données. Vous concevez et mettez en oeuvre des systèmes pour traiter des grandes quantités de données. Vous gérez le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD ☎️ Support technique et assistance Vous collaborez avec les équipes de données et d’analyse pour déterminer les besoins en matière de données et les aider à les résoudre. Vous mettez en place et veillez au maintien du catalogue de données Les équipes techniques grandissent à vos côtés grâce à vos formations et partages de bonnes pratiques Vous maîtrisez les technologies de stockage de données, en particulier Event streaming (Kafka,…), CDP (Segment), Data Cloud (Synapse Analytics, Snowflake), Data discovery/reporting/BI (Tableau, SISense, QlikSense,…) Vous avez des compétences en programmation, notamment en Python (pySpark) et SQL, Vous avez une connaissance approfondie de l’ingénierie des données, y compris les techniques de collecte, de nettoyage, de validation et de transformation de données, en particuler de modélisation de la donnée (sql et nosql) Vous avez une expérience en mise en œuvre de pipelines de données et en automatisation des processus de gestion de données. Vous êtes pédagogue Persévérant.e et curieux.se sont des adjectifs qui vous définissent Phase 1 : un entretien avec RH + Manager Phase 2 : un test technique","HelloAsso, the leading payment solution for the nonprofit sector, is looking for a DevOps engineer to design, manage, and maintain data collection, storage, processing, and dissemination systems for operational and analytical needs. Responsibilities include developing robust and reliable data storage systems, collecting and preparing data from diverse sources, supporting technical teams, and providing training and best practices. Required skills include expertise in data storage technologies, programming (Python, SQL), data engineering (collection, cleaning, validation, transformation, data modeling), and data pipeline implementation and automation. The hiring process involves an interview with HR and a manager, followed by a technical test.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
132,73630,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-cdi-f-h_grenoble_ATOS_4ZmzXkl,Data Engineer (Confirmé) - CDI -,Atos,"{SnowFlake,Microsoft,Kafka,Hive,Redshift,Kibana,CouchBase,HDFS,Beam,AWS,BigQuery,Azure,Spark,Redis,Logstash,ElasticSearch,Java,MongoDB,Python,Cassandra,Teradata,Hadoop,Docker,Kubernetes,NoSQL}",Télétravail partiel possible,"28 Rue Gustave Eiffel, Grenoble, 38000",IT / Digital,CDI,2023-04-22,"Bienvenue chez Atos, où nous imaginons le futur de la tech. Leader international du numérique sécurisé et décarboné, Atos contribue à façonner les nouvelles technologies avec ses clients. Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carrière valorisants basés sur des programmes de formation, de certification et de mobilité. C’est pourquoi chez Atos, la diversité des compétences et des expériences de nos équipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l’avenir de notre entreprise et de la société. LA MISSION QUE L’ON VOUS CONFIE : Au sein d'équipes dynamiques, vous aurez pour missions principales : Conseiller en architecture en gouvernance de la donnée. Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA. Mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud pour les projets stratégiques de nos clients. VOTRE PROFIL POUR REUSSIR : De formation supérieure BAC +5 en Informatique d`une Ecole d’Ingénieur ou d’un Mastère universitaire dans le domaine des sciences informatiques que vous avez complété par une expérience significative en Data Science / Data Engineering. Votre stack technique : Requis : Connaissance des écosystèmes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS … ; Expertise en développement Python ou Java Spring Boot ; Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam… ; Connaissance des architectures conteneurs : Docker, Kubernetes. Apprécié : Connaissance d’un des services managés BigData de Google Cloud Platform / AWS / Microsoft Azure ; Connaissance des approches Agile & DevOps. Soft skills : Passionné(e) d’informatique en progressant et en vous tenant à jour sur toutes les technologies et architectures, vous êtes créatif(ve), autonome, rigoureux(se), curieux(se), motivé(e) et avez le sens du travail en équipe et du relationnel alors rejoignez-nous ! Niveau de langue : Anglais : niveau intermédiaire minimum recommandé et Français exigé. Description du profil : POUR VOUS CONVAINCRE DE NOUS REJOINDRE : Travailler à Grenoble dans une ambiance et cadre de travail agréable avec nos clients en direct . Un accompagnement personnalisé avec montée en compétences, formation et évolution sur des projets long terme. Un employeur attentif à votre épanouissement avec des possibilités de télétravail pouvant aller jusqu’à 50% du temps Un package d’avantages avec régime de santé très favorable, RTT disponibles dès votre arrivée et un CE très dynamique, remboursement des déplacements en transport en commun. NOTRE PROCESSUS DE RECRUTEMENT : Prise de contact avec un recruteur pour une préqualification Evaluation technique en fonction du profil Entretien avec nos ingénieurs commerciaux / managers Vous voulez en découvrir plus ? N’hésitez plus et postulez dès à présent ! #TheFutureIsOurChoice",,Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
339,37436,https://www.welcometothejungle.com/fr/companies/consortia/jobs/consultant-data-engineer_paris,Consultant(e) Data engineer (Paris),Consortia,"{Azure,NoSQL,Scala,AWS,Spark,GCP,SQL,Hadoop,Python}",Télétravail partiel possible,"58 Boulevard Gouvion-Saint-Cyr, Paris, 75017",Bureau d'études et d'ingénierie,CDI,2022-10-18,"Acteur majeur de la Data intelligence, le Groupe Estia rassemble une centaine d’experts de la donnée, mettant à profit leurs compétences autour d’un projet commun : le management et la valorisation de l’information au service des directions IT. Vous êtes Informatics lover et le monde de la Data vous passionne ? Rejoignez Consortia en qualité de consultant(e) Data engineer. • Votre mission principale consiste à intervenir en clientèle sur des demandes d’expertise solution/méthodologie • Grâce à votre expertise en Big Data, vous concevez des plateformes permettant de traiter des volumes importants de données et mettez en place des bases de données • Vous veillez à ce que les pipelines de données déployés soient sécurisés et clairs pour analyser et exploiter la donnée Diplômé(e) d’un Bac +5 en Ecole d’ingénieurs ou Master 2 en statistiques et/ou data, vous avez un intérêt prononcé pour les nouvelles approches et outils de la Data Ingénierie. Fort d’une solide expérience en Data Ingénierie (3 ans minimum) acquise en cabinet de conseil ou en entreprise, vous avez développé une expertise sur des outils comme Python, Spark, Scala et en Big Data, ainsi que sur des environnements Hadoop et/ou Cloud (GCP, AWS ou Azure). Vous êtes à l’aise sur des environnements SQL et NoSQL. Vous avez une bonne connaissance de l’anglais et avez idéalement une sensibilité aux méthodes agiles. Vous faites preuve de dynamisme, êtes un(e) adepte du travail en équipe et accordez une grande importance à la qualité & la fiabilité de vos livrables. En outre, vous avez un sens du service client développé et une capacité à communiquer, vulgariser et présenter votre travail. • 1er entretien : RH • 2ème entretien : Opérationnel (manager ou superviseur) • 3ème entretien : Direction en binôme avec un ingénieur d’affaires lors du 1er ou 2ème entretien","The Estia Group is seeking a Data Engineer consultant to design platforms for managing and processing large data volumes, secure data pipelines, and implement databases. Applicants should have a master's degree in statistics or data science, solid experience in data engineering, and expertise in Python, Spark, Scala, and Big Data tools. Strong English language skills and a sensitivity to agile methodologies are preferred, as well as the ability to work well in teams and prioritize quality and reliability. The hiring process involves three interviews with HR, operational management, and a director, possibly alongside a business engineer.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
332,57068,https://www.welcometothejungle.com/fr/companies/illuin-tech/jobs/data-engineer-kafka-cassandra_neuilly-sur-seine,Data Engineer Kafka / Cassandra,ILLUIN Technology,"{React,Python,UNIX,Kubernetes,AWS,Docker,Kafka,R,Cassandra,Elasticsearch,Git,Java,SQL,Lucene,Bash,Postgresql}",Télétravail partiel possible,"183, Avenue Charles de Gaulle, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"ILLUIN Technology, c’est LA référence pour le développement de solutions technologiques de pointe en France. En à peine 6 ans, ILLUIN Technology est passée de 11 à 80+ Illuiners et a atteint un chiffre d’affaires de 7,2 M€ en 2022 en réalisant des projets sur mesure aussi diversifiés - IA, web, mobile, AR/VR, IoT, etc. - que bluffants sur le plan technique et UX. Le secret ? Leurs quelques 50+ clients grands comptes, startups, asso, etc. vous le disent : “ILLUIN, ce sont des personnes agréables, dotées d’un très haut niveau technique, polyvalentes et toujours engagées.” Et ce n’est pas tout ! Depuis 2 ans, la société propulse aussi ses propres produits utilisant l’état de l’art du NLU dans le domaine de l’IA conversationnelle et du traitement intelligent de document (parsing, search…). Pourquoi nous rejoindre ? 🏅 Nous sommes certifiés HappyAtWork 2022 et avec le 2ème meilleur score des startups françaises 🌍 Nous donnons 1500€ à une association pour chaque cooptation et autant au cooptant 🚀 Nous avons un framework d’évolution clair et transparent qui permet de se projeter 💸 Nous proposons un package de rémunération des plus attractifs du marché et une évolution rapide 🌿 Nous donnons du sens au travail : coaching d’étudiants, Tech4Good, unité Data x Santé, startup studio… 😍 Nous valorisons plus que tout la bienveillance, la stimulation intellectuelle et l’équilibre pro-perso 💻 Nous travaillons sur du matériel haut de gamme (Macbook Pro / DELL XPS, écran QHD) → Votre mission En tant que Data Engineer Kafka / Cassandra, votre rôle sera d’industrialiser des solution d’IA scalable à grande échelle dans un cluster Apache Kafka, de développer des pipelines de transformation de données à gros volume ainsi que de mettre en place des solutions de persistance de données dans des bases de données Cassandra / Postgresql / Elasticsearch. Ces solutions s’inscrivent dans le cadre de projets sur-mesure pour nos clients ou pour répondre aux besoins en data engineering de nos produits ILLUIN Technology. → Vos responsabilités Participer à la conception et l’optimisation de solutions technologiques traitant un gros volume de données à grande échelle et répondant aux besoins des utilisateurs/clients Réaliser des projets en équipe, encadré.e par des profils expérimentés qui vous feront monter en compétences Perfectionner ses compétences et chercher constamment à améliorer les outils et les méthodes employées (veille technologique, R&D, échanges de bonnes pratiques, hackathons) Participer à des code reviews avec les membres de votre équipe, challenger les implémentations, partager votre expertise et faire grandir les illuiners juniors autour de vous Prendre part aux cérémonies et sprint reviews en lien direct avec le client / nos équipes produits Participer au développement de projets internes transverses : recherche, OPS, sécurité, formations, … Participer à l’évolution de notre offre de Data Engineering en épaulant ponctuellement l’équipe commerciale grâce à votre expertise technique Nous cherchons le match parfait 💓 …mais nous croyons à la richesse des rencontres ! Alors si vous n’êtes pas certain.e de matcher notre recherche nous vous encourageons à nous contacter quand même ✉️ ✅ Must have Expérience avec le langage de programmation Java Bonne compréhension des bases de données SQL Bonne compréhension du fonctionnement d’Apache Kafka Compréhension de base du fonctionnement d’Apache Cassandra Expérience avec Git et des outils d’intégration continue Expérience avec Docker 🌈 Nice to have Expérience avec le framework backend Spring / Spring Boot Bonne compréhension du fonctionnement du Web Tests unitaires et d’intégration Expérience en OPS (Kubernetes, Terraform, Ansible, …) Expérience avec de l’indexation Lucene Expérience avec Elasticsearch / stack ELK Expérience avec le langage de programmation Python Connaissances de base UNIX & Bash Expérience sur des outils cloud (Google Cloud, AWS, OpenStack, …) Usage d’un framework front-end (React, Angular, Vue, …) Connaissances en IA / data science (machine learning, deep learning, NLP) 🤩 Les gens disent de vous que… Vous êtes engagé.e et prêt.e à donner le meilleur de vous-mêmes Vous êtes curieux.se, flexible, empathique, autonome Vous avez le sens du partage et le sens du travail en équipe Vous partagez nos valeurs : confiance, empowerment, excellence, innovation Après un 1er contact par téléphone, voici le processus : Test technique à distance (1h) Entretien Tech Live Entretien Human Fit Entretien Head of Software Engineering Entretien CEO La plupart des entretiens se font en présentiel mais l’option visio est également possible. Dans l’ensemble, entre le premier contact et la remise de proposition, il s’écoule rarement plus de 2 semaines !","ILLUIN Technology is seeking a Data Engineer with expertise in Kafka and Cassandra to work on custom projects for clients and ILLUIN Technology's own products. The role involves developing data transformation pipelines at scale, implementing data persistence solutions in Cassandra, and participating in the development of transversal internal projects. The ideal candidate has experience with Java, SQL databases, and Apache Kafka, as well as version control and continuous integration tools. Nice-to-have skills include experience with Spring, ELK stack, and cloud tools such as AWS or Google Cloud. The company values teamwork, innovation, and excellence and offers attractive compensation and career growth opportunities.",Bac +5 / Master,Entre 50 et 250 salariés,> 3 ans,2,0,0.027697749441558416
106,72901,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_nantes_ASI_4ogDM0K,Data Engineer,ASI,"{Microsoft,Azure,NIFI,Matillion,Kafka,Spark,NoSQL,SQL,Airflow,Glue,S3,Talend,Java}",Télétravail partiel possible,Nantes,"IT / Digital, Transformation, Big Data",CDI,2023-04-22,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Avec Simon GRIFFON, responsable de l’équipe Data Nantaise, nous recherchons un Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une équipe dédiée, principalement en contexte agile, voici les missions qui pourront vous être confiées : Participer à la rédaction de spécifications techniques et fonctionnelles Maîtriser les formats de données structurés et non structurés et savoir les manipuler Connecter une solution ETL / ELT à une source de données Concevoir et réaliser un pipeline de transformation et de valorisation des données et ordonnancer son fonctionnement Prendre en charge les développements de médiations Veiller à la sécurisation des pipelines de données Concevoir et réaliser des API utilisant les données valorisées Concevoir et implémenter des solutions BI Participer à la rédaction des spécifications fonctionnelles et techniques des flux Définir des plans de tests et d’intégration Prendre en charge la maintenance évolutive et corrective Traiter les problématiques de qualité de données En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes : L’écosystème data notamment Microsoft Azure Les langages : SQL , Java Les bases de données SQL et NoSQL Stockage cloud: S3, Azure Blob Storage… Les ETL/ESB et autres outils : Talend , Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue... Nos engagements : Avec Simon, votre manager de proximité , vous co-construisez votre trajectoire professionnelle Vous bénéficiez d'une offre de formation riche en adéquation avec vos attentes grâce à la ""ASI Academy"" Vous intégrez les différentes communautés techniques d'ASI, pour partager des bonnes pratiques et participer aux actions d'amélioration continue Vous pouvez participer (ou animer si le cœur vous en dit) à des évènements internes de type dej’tech et midi geek, mais aussi à des évènements externes : Camping des Speakers, DevFest, Salon de la Data … Vous évoluez dans une entreprise porteuse d’une démarche RSE VRAIMENT active . Issu d’une formation supérieure en informatique, mathématiques ou spécialisé en Big Data, vous avez une expérience minimale de 3 ans en ingénierie des données et d'une expérience opérationnelle réussie dans la construction de pipelines de données structurées et non structurées. Le salaire proposé pour ce poste est compris entre 36 000 et 40 000 €, selon l'expérience et les compétences, tout en respectant l'équité salariale au sein de l'équipe. Attaché à la qualité de ce que vous réalisez, vous faites preuve de rigueur et d' organisation dans la réalisation de vos activités. Doté d'une bonne culture technologique , vous faites régulièrement de la veille pour actualiser vos connaissances. Un bon niveau d’anglais, tant à l’écrit qu’à l’oral est recommandé. Vous souhaitez (comme nous) agir pour un numérique plus responsable au service de ses utilisateurs. Vous savez travailler en équipe et vous accordez de l'importance au partage et à l' entraide . Enfin, vous adhérez à nos valeurs de respect , de bienveillance et d' engagement professionnel et sociétal . À compétences égales ce poste est ouvert aux personnes en situation de handicap",,Non spécifié,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
334,56611,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/ingenieur-data-h-f-poei_puteaux,Ingénieur Data  | POEI,Datascientest,"{Java,Python}",Télétravail ponctuel autorisé,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"DATASCIENTEST ? LA REFERENCE EN DATASCIENCE Créée en 2017, DataScientest révolutionne la formation en Data Science et devient leader en France ! Notre école compte plus de 6 000 apprenants à son actif, et a séduit 50 entreprises dont une trentaine du CAC40 et des leaders internationaux (BCG, Allianz, Christian Dior, Axa…), Nous formons aussi les demandeurs d’emploi en leur offrant un CDI au sein de nos entreprises partenaires Présents en Espagne et en Allemagne, notre pédagogie repose sur une structure hybride : Qui allie l’adaptabilité du distanciel avec une plateforme entièrement conçue par nous-même et La motivation du présentiel avec des séances de coaching animées par nos enseignants data scientists ! En tant qu’Ingénieur Data, vous serez chargé(e) de proposer les meilleures solutions à l’entreprise en leur permettant d’optimiser leur activité, à travers quelques missions principales : Développer des solutions pour traiter des volumes importants de données, Concevoir, collecter et fabriquer des données brutes, Créer des outils et algorithmes pour le traitement des données, Préparer des données pour le Data Analyst, Sécuriser des Pipelines données pour les Data Analysts et Data Scientists, Organiser l’architecture du cloud, Contribuer à l’effort d’animation technique, de veille technologique et d’innovation Et si nous parlions de vous ? Issu(e) d’une filière scientifique bac+5 ou d’un diplôme d’ingénieur, Vous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la Data, Vous maîtrisez un langage objet type Java, Python, C++, etc. Vous êtes demandeur d’emploi N’attendez plus, envoyez nous votre CV, nos équipes se feront un plaisir de vous contacter et de vous accompagner pour préparer vos entretiens avec notre entreprise partenaire.","DataScientest seeks an experienced Data Engineer to develop solutions to help companies optimize their activities. The role involves designing, collecting, processing, and preparing data for analysis by Data Analysts and Data Scientists. The ideal candidate should have a scientific background, a degree in engineering, and significant experience in development, network architecture, or Data. Proficiency in Java, Python, C++, or a similar object-oriented language is crucial. DataScientest provides an innovative hybrid teaching method combining virtual and in-person mentoring, with partnerships with major companies like Allianz, Christian Dior, and Axa. DataScientest also offers job opportunities to job seekers, including a CDI with partner organizations.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,1,1,0.027697749441558416
374,57066,https://www.welcometothejungle.com/fr/companies/societe-generale-assurances/jobs/dataops-engineer_la-defense,Dataops Engineer,Société Générale Assurances,"{Jenkins,Trino,LakeFS,Gitlab,Kubernetes,Cloudera,HDFS,Kedro,MLflow,Hive,Spark,Superset,Python,linux}",Télétravail partiel possible,La Défense,Assurance,CDI,2023-03-26,"Présente en France avec Sogécap, Antarius, Sogessur et Oradéa Vie, et dans 9 pays à l'international, Société Générale Assurances propose une gamme complète de produits et de services répondant aux besoins de la clientèle de particuliers, de professionnels et d'entreprises, en matière d'assurance-vie épargne, d'épargne retraite et de protection des personnes et des biens. Votre rôle La direction du DataLab effectue des travaux transverses visant à valoriser au mieux les données disponibles en interne. Le DataLab cherche à renforcer les moyens techniques lui permettant de démocratiser l'accès et l'usage des données ainsi qu'accélérer et faciliter la mise en production des applications Data et IA. En tant que DataOps Engineer, vous intervenez sur l'évolution et le maintien de la plateforme de développement data interne. Vous travaillerez notamment sur les sujets suivants : Release management des applications Data et IA Evolution des solutions de Data orchestration Implémentation d'une solution de Data quality Entraînement et évaluation continue des modèles ML Maintenance et évolution du Framework de développement data science Diplômé d'une formation orientée informatique, vous justifiez d'une expérience significative en data et platform engineering (4 ans et +). Vous avez une connaissance approfondie sur les pratiques du software engineering et sur les différentes approches de modélisation, stockage et requêtage des données. Vous maîtrisez linux et au moins un système distribué orienté Data. L'écosystème Python vous est familier. Des connaissances en Machine Learning sont un plus. Environnement technique : Vous travaillerez sur une ou plusieurs de ces Plateformes : Plateforme Data Science : Jupyterhub, VScode (code-server), MLflow, Apache Superset, Trino, LakeFS, Kedro Plateforme DevOps: Gitlab, Nexus, MLflow, Jenkins, Kubernetes, Vault, Gatling Plateforme Big Data: Cloudera Data Platform (HDFS, Hive, Spark,..) Informations générales Poste à pourvoir en CDI à partir de mars 2023 basé à Paris La Défense (92).","Société Générale Assurances is seeking a DataOps Engineer to strengthen its internal data development platform. The role involves release management of data and AI applications, data orchestration, data quality implementation, ML model training and evaluation, and maintenance and evolution of the data science development framework. The ideal candidate should have a degree in computer science, a significant experience in data and platform engineering, knowledge of software engineering practices, and familiarity with Python and Linux. Knowledge in Machine Learning is a plus.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
152,56459,https://www.welcometothejungle.com/fr/companies/polyconseil/jobs/data-engineer-h-f-cdi_paris_POLYC_WA1Dg7r,Data Engineer -  - CDI,Polyconseil,"{DBT,PostgreSQL,Snowflake,Azure,Docker,MongoDB,Databricks,Luigi,Kafka,Git,NoSQL,ElasticSearch,Kubernetes,AWS,SQL,Airflow,via,Spark,GCP,Python}",Télétravail ponctuel autorisé,"14, Boulevard Poissonnière, Paris, 75009","Logiciels, IT / Digital",CDI,2023-03-26,"Expert de la transformation numérique depuis 1989, Polyconseil possède un positionnement atypique, alliant expertise en conseil et réalisation de produits digitaux. Nos équipes s’intègrent sur toute de la chaîne de valeur, afin d’avoir une vue d’ensemble d’un projet et d’en maîtriser chaque étape : cadrage des besoins, préconisations, conception, développement et déploiement de solutions innovantes et complexes. Nous accompagnons aussi bien des grands comptes, que des institutions publiques ou des start-ups, dans des secteurs variés tels que : Médias, Assurance, Mobilité, Aérospatial, Écologie, etc. Nous intervenons sur des projets à forte valeur ajoutée et apportons un accompagnement sur-mesure à nos clients, en constituant des équipes multidisciplinaires de Développeur(se)s, Product Managers, Digital Consultant(e)s, UI / UX Designers, Data Scientists et InfraOps. Polyconseil est fondé sur des valeurs d’excellence, de bienveillance et d’entraide favorisant la responsabilisation et la montée en compétence graduelle de tous nos collaborateurs. Pourquoi rejoindre Polyconseil ? Vous intervenez sur des missions à impact et voyez le résultat de vos actions Vous êtes responsabilisé(e) et évoluez dans un environnement propice à l’ apprentissage et à la progression , au contact de talents qui se tirent vers le haut. Vous travaillez dans une ambiance à la fois détendue et stimulante , prônant esprit d’équipe et prises d’initiative Vous profitez d’une vie interne riche en événements (sportifs, culturels, culinaires…) Votre équilibre vie pro / vie perso est respecté et vous bénéficiez d’une politique de télétravail flexible Vous rejoignez nos locaux récents en plein Paris (Paris 9, métro Grands Boulevards, lignes 8-9) Vous avez accès à la participation, plan épargne entreprise avec abondement, tickets restaurant… Intégré(e) au sein de l’équipe Data, vous intervenez notamment sur : Le développement, déploiement et maintenance de pipelines d’ETL/ELT La mise en place d’APIs et de backends applicatifs La définition et mise en place de modèles de données, administration de base de données L’utilisation de plateformes et outils Cloud La compréhension et application de principes d’architecture La supervision et monitoring d’applications Entouré(e) de nos experts, vous montez rapidement en compétence sur les technologies suivantes : Python, Apache Spark, MongoDB, ElasticSearch, Airflow, et participez au développement de nouveaux produits innovants dans le cadre de notre Datalab. En fonction de vos appétences, vous aurez également la possibilité de vous impliquer sur des sujets transversaux pour accompagner notre croissance : recrutement, réponses aux AOs, organisation d’événements, chantiers internes (RSE…) etc. Principales technologies à utiliser ou à découvrir Langages : Python, SQL, DBT, Spark Bases de données : PostgreSQL, base de données NoSQL (MongoDB, ELK…) Orchestration : Airflow, Luigi DevOps : Git, CI/CD, Docker, Kubernetes/Nomad, Ansible… Outils Cloud : AWS, GCP, Azure, Snowflake, Databricks… Autres : Kafka Quelques exemples de missions : Développement et commercialisation en SaaS d’un système de gestion intelligente de la politique de stationnement pour une centaine de villes en France Solution d’optimisation du pricing des produits vendus via une plateforme de ventes aux enchères en ligne Développement d’une plateforme de suivi et de prédiction des incidents sur un parc IT Développement from scratch d’un feature store à destination des data scientists d’un acteur de la réassurance Algorithmes de détection de fraude auprès d’assureurs Conception d’une plateforme data temps réél sur AWS Vos moyens pour réussir Formation : dès votre arrivée, vous avez accès à un large panel de formations et ressources documentaires pour approfondir vos connaissances sur vos sujets de prédilection ou bien découvrir des sujets nouveaux par simple curiosité. Nous finançons également des formations AWS Management opérationnel : vous êtes accompagné(e) par un manager de mission et un Talent Manager tout au long de votre parcours chez nous Contact constant avec d’autres métiers / équipes au sein de nos locaux Issu(e) d’une école d’ingénieurs ou d’une école spécialisée en développement informatique, vous possédez minimum 2 années d’expérience en Data Engineering et maîtrisez Python et SQL. Une expérience ou une formation spécifique (ex : Udemy) avec le calcul distribué, le traitement des données temps réel ou les bases de données NoSQL est un plus. Avoir déjà travaillé avec un ou plusieurs fournisseurs de cloud (AWS, GCP, Azure notamment) est également apprécié. Nous recherchons avant tout un fit humain, et de futur(e)s collègues avec qui nous prendrons plaisir à travailler chaque jour. Alors, si comme nous vous possédez : Une curiosité naturelle pour le monde du numérique Un goût pour le challenge Une envie de progresser et d’apprendre Un esprit d’équipe à toute épreuve Une réelle volonté de transmettre vos connaissances et d’aider les autres Une très bonne maîtrise de la langue française …n’hésitez pas à nous envoyer votre candidature !","Polyconseil, a digital transformation expert, is seeking a Data Engineer with at least two years of experience in data engineering, Python, SQL, and cloud providers. The successful candidate will work on a range of tasks, including administering databases, developing ETL/ELT pipelines, and employing API and application backend solutions. The company offers comprehensive training and resources to help employees develop professionally, a balanced work-life policy, and a generous employee benefits package.",Bac +5 / Master,Entre 250 et 2000 salariés,> 2 ans,1,1,0.027697749441558416
377,56682,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-bi-f-h_nantes,Data Engineer / BI Developer,Micropole,"{Microsoft,durable,Talend,SAP,Informatica,AWS,R,GCP,SQL,Qlik,Tableau}",Télétravail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Data Engineer F/H Localité : Nantes Type de contrat : CDI Niveau d’expérience minimum : 2 ans Vous souhaitez rejoindre une entreprise pionnière des grandes innovations data et digitales, au sein d’une agence à taille humaine où règnent entraide et convivialité, engagée en faveur d’un numérique plus responsable au service de clients principalement implantés régionalement ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur grâce à la puissance du Cloud ? Rejoignez Micropole ! Dans vos missions quotidiennes , vous serez amené(e) à : Participer aux recueil du besoin auprès des Directions Métiers ; Rédiger les dossiers de conception technique ; Intervenir sur toute la chaîne de valeur de la donnée : extraction à l'aide d'un ETL, modélisation & dataviz ; Préparer et dérouler les tests ; Accompagner la maîtrise d’ouvrage dans la validation de livrables, l’assistance à la recette et la conduite du changement sur le projet ; Capitaliser et partager les bonnes pratiques, connaissances et retours d’expérience au sein de nos communautés. Vos compétences techniques : Vous maîtrisez parfaitement au moins un ETL du marché (Informatica, Talend, Big Query, Data Factory, etc) et la création de tableaux de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI...) idéalement dans un environnement Cloud ; SQL n’a plus de secrets pour vous. Vos atouts : Vous êtes diplômé(e) d’une formation supérieure en Informatique décisionnelle ; Vous possédez une expérience d'au moins 3 ans dans la fonction ; Votre esprit d’analyse, de synthèse, votre organisation et vos capacités rédactionnelles sont souvent reconnus ; Vous appréciez travailler en équipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C’EST : - Intégrer une communauté de 1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. - Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. - S’assurer d’une innovation continue grâce à : Notre écosystème de partenaires technologiques Notre accélérateur de start’up databoost’R Nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C’EST : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; La participation à nos communautés sur la base du volontariat. PROCESSUS DE RECRUTEMENT : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – Si votre profil correspond à nos attentes, vous êtes recontacté(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist pour la région ouest pour un premier échange téléphonique ; Etape 2 – Un premier entretien est programmé avec l’un d’entre eux sur site ou à distance Etape 3 – Vous rencontrez Stéphanie ou Camille les manager de l’équipe Data de l’Ouest pour un second entretien En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un développement rapide sur le Data, le Digital et Cloud, les équipes portent l’ensemble de la proposition de valeur du Groupe. Présent au plus près de l’écosystème de partenaires, de réseaux professionnels et d’acteurs du développement économique, nous accompagnons nos clients des secteurs de l’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et du public dans leur transformation data et digitale, notamment au travers de méthodologies innovantes comme le Datathinking® ou Lego Serious Play®. L’agence Grand Ouest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit et met en place des méthodes, compétences et expertises pour le développement d’un numérique responsable au sein des organisations À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Compétences Modélisation informatique decisionnelle","Micropole is seeking a Data Engineer to work on their projects ranging from requirement gathering to technical design, data extraction, and model building. The ideal candidate should have at least 2 years of experience in data-driven decision-making and strong knowledge of ETL tools, data visualization software, and Cloud environments. They should also have excellent analytical, communication and team collaboration skills. Micropole is a leading European data transformation and consulting firm with over 1200 experts and several innovation ecosystems, and promotes a sustainable and responsible form of digital transformation.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
310,58095,https://www.welcometothejungle.com/fr/companies/sancare/jobs/data-engineer_paris_SANCA_ed4r6Dy,Data Engineer,Sancare,"{GitHub,Docker,Linux,Git,RabbitMq,SQL,Python}",Télétravail partiel possible,"5, Rue Saint-Germain-l'Auxerrois, Paris, 75001","Intelligence artificielle / Machine Learning, Big Data, Santé",CDI,2023-03-26,"Sancare propose des outils prédictifs utilisant les dernières avancées en intelligence artificielle pour mettre ces données au service des métiers de la santé. L’équipe de Sancare est composée d’une trentaine de personnes spécialisées dans le développement informatique, le machine learning et la santé. Nous avons de plus la chance d’être accompagnés par des chercheurs reconnus dans le domaine du machine learning, ainsi que par des médecins et experts du monde de la santé. Être chez Sancare, c’est avant tout être une équipe bienveillante, qui s’entraide et cherche constamment à progresser. Nous sommes une équipe soudée, avec des valeurs fortes et partagées : Persévérer en s’entraidant Rester proche du besoin client Allier rigueur et pragmatisme Grandir et faire grandir les autres Collaborer avec transparence et respect. Nous recherchons une Data Engineer avec de solides compétences opérationnelles et souhaitant rejoindre une équipe dynamique, expérimentée et motivée, afin d’accélérer l’arrivée de nos solutions en rupture dans le monde de la santé. La gestion et le traitement de la donnée sont au coeur des problématiques de Sancare. Comme chaque hôpital dispose de son propre système d’information, des connecteurs doivent être implémentés pour chacun, afin de nourrir les algorithmes de machine learning. Les moyens d’accès et le format des données contenues dans les dossiers patients sont très variés et diffèrent d’un établissement à un autre. De plus, de nombreuses mesures sont à respecter afin de garantir la sécurité et la confidentialité des données. Missions : Développement de connecteurs permettant la transmission des données hospitalières entre les SI hospitaliers et les logiciels de Sancare Développement d’outils de standardisation et de traitement des données hospitalières en vue de leur utilisation par les algorithmes de machine learning Amélioration et maintenance des fonctionnalités existantes de traitement de données Gestion opérationnelle des différents services de traitement de données. Les avantages Sancare : Des superbes locaux en plein centre de Paris (Châtelet) Une organisation du travail flexible (109 jours de télétravail par année civile pour les salariés en forfait jour: soit deux jours de télétravail possibles par semaine et ce forfait pourra être porté à 131 jours de télétravail si les salariés au forfait jour justifient d’un temps de déplacement domicile-bureau supérieur à 3h par jour: soit trois jours de télétravail possibles par semaines pour les personnes à plus d’1h30 du bureau) Tickets restaurant Éligibilité BSPCE Mutuelle Alan Hello CSE Chez Sancare on n’est jamais à l’abri d’un apéro ou d’un cours de street-art ! Des retours d’expérience réguliers dans des formats variés (afterworks, séminaires, …) pour valoriser le partage d’idées et la connaissance commune. Expérience significative dans le développement en Python orienté objet (3ans à 5ans) Expérience de développement sous Linux Expérience dans la manipulation de données avec le langage SQL Pratique avancée des outils d’intégration continue avec Git et tests unitaires Des qualités d’autonomie, de flexibilité et de responsabilité L’esprit d’équipe et la volonté de prendre part à une aventure collective Un intérêt pour le monde de la santé Sont un plus : Familiarité avec Docker et RabbitMq Expérience avec les données de santé dans le secteur hospitalier N’hésitez pas à partager vos projets personnels de développement (sur GitHub ou ailleurs). Entretien Visio avec Thomas notre Head Of Recruitment Test Technique puis entretien de pair programing avec l’équipe Entretien avec notre fondateur","Sancare, a health-tech company specialized in predictive tools, is looking for a Data Engineer with 3-5 years of experience in Python, Linux, SQL, and CI tools to develop connectors between hospital information systems and Sancare's software. The ideal candidate should demonstrate autonomy, flexibility, and a collaborative mindset. Knowledge of Docker, RabbitMq, and healthcare data is a plus. Working at Sancare offers benefits such as flexible work arrangements, regular after-work events, and a dynamic and supportive team.",Non spécifié,Entre 15 et 50 salariés,> 3 ans,2,0,0.027697749441558416
179,56697,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-powercenter-informatica-h-f_tours,Expert technique ETL Powercenter Informatica,CGI,{Informatica},Télétravail partiel possible,"Tours, 37000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Powercenter Informatica. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Powercenter Informatica • Participer aux échanges avec l’éditeur Powercenter • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données ou dans le MDM ou sur Informatica Cloud sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI, a global consulting and digital services leader, is seeking a Data Integration Expert with a solid experience in ETL Powercenter Informatica. The ideal candidate is passionate about data and decision-making, enjoys learning and sharing knowledge, and has at least three years of experience in data integration within digital services or consulting firms. The role includes analyzing and improving solutions, collaborating with engineers and other experts, participating in technical documentation, providing technical support, and participating in technical recruitment. CGI offers diverse career paths, including technical management, integration consulting, or BI project management. The company is an inclusive employer, committed to the career development of all candidates and employees, regardless of gender or ability.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
365,56322,https://www.welcometothejungle.com/fr/companies/ornikar/jobs/bi-engineer_paris,Analytics Engineer,Ornikar,"{Metabase,matillion,Snowflake,Dataiku,Looker,PowerBI,moderne,Mixpanel,Qlik,Airbyte,scale,SQL,Airflow,Redshift,dbt,via,BigQuery,GCP,Tableau}",Télétravail partiel possible,"France, Paris, 23230","Mobilité, FinTech / InsurTech, EdTech",CDI,2023-03-26,"Ornikar étoffe son offre historique d’auto-école et devient une plateforme d’accès à la mobilité pour les jeunes ! Leur volonté : réinventer l’expérience des jeunes générations autour de l’apprentissage de la conduite, et les accompagner grâce à un écosystème de services tels que l’assurance automobile. Fondée en 2013 et leader sur la modernisation du permis de conduire, l’équipe Ornikar continue d’évoluer et de militer pour l’émancipation des jeunes et la transition vers leur indépendance ! Aujourd’hui constituée de 260 collaborateurs, leur équipe connaît une croissance continue construite sur de solides fondations : leur produit permis de conduire (plateforme d’e-learning et marketplace de mise en relation avec nos enseignants de la conduite) d’une part, mais également leur connaissance utilisateur approfondie qui leur permet d’offrir une assurance auto plus proche des besoins des jeunes assurés : modulable, simplifiée, adaptée à tous avec un prix et des options personnalisées. À propos de la Team Data 📊 La data est une direction à part chez Ornikar composée d’une vingtaine de personnes, et s’organise autour de plusieurs métiers complémentaires (Data Analysts, Analytics Engineers, Data Engineers, Machine Learning Engineers) dont certains en contact permanent avec des équipes métiers (produit, marketing, opérations). Nous avons principalement 3 missions : L’aide à la décision : on accompagne les équipes à tous les niveaux de management, que ce soit pour des objectifs stratégiques, de développement produit, de métier… Nous menons des analyses complexes pour permettre aux équipes de prendre les décisions basées sur des chiffres qui nous permettront d’atteindre nos objectifs ou d’identifier de nouveaux leviers de croissance. L’efficacité opérationnelle : Les équipes chez Ornikar sont très sensibles aux enjeux data, ce qui nous a permis de mettre en place d’une part le self-service BI pour leur permettre d’effectuer leurs recherches quantitatives en parfaite autonomie, et d’autre part nous répondons à des problématiques d’automatisation de flux de données pour enrichir leurs outils et accélérer leur quotidien. Des features data et algorithmes que nous développons pour apporter encore plus de valeur différentiante à nos produits, et faire de la data un élément fort de notre proposition de valeur. Pour soutenir ces missions, toute l’équipe participe à la construction d’une stack Data de pointe répondant aux enjeux d’une équipe Data moderne. Nous recherchons un·e Analytics Engineer 🌋 Le développement de l’activité d’assurance d’Ornikar s’accompagne d’un grand nombre d’engagements contractuels et légaux quant à la mise à disposition de données auprès d’acteurs tiers, partenaires ou régulateurs. Des sinistres aux indicateurs de production, en passant par les métriques financières ou opérationnelles, toutes les activités de l’entreprise sont concernées. Plus généralement, Ornikar a à coeur d'établir ses prises de décision sur une offre de donnée partagée, comprise et maîtrisée par toutes les équipes, indépendamment de leur appétence technique. Notre objectif est de centraliser la production de rapports d’intégration, comptables et réglementaires, en termes de création, maintenance et révision, et de renforcer nos bonnes pratiques en la matière en s’inspirant des standards du développement moderne : optimisation et résilience du code, peer review, gestion des versions et des environnements, alertes et observabilité, tests et qualité, documentation et indempotence. Le ou La Analytics Engineer aura également la responsabilité de transposer ces standards aux rapports internes orientés métier. Les missions du poste : Gérer la relation avec les demandeurs finaux (régulateurs, partenaires), et les équipes internes associées à la bonne réalisation des rapports (Data Engineers, Data Analysts, équipes plateforme) Récolter, documenter et cadrer les expressions de besoins en matière de rapports, structurer une feuille de route et prioriser les sujets en fonction des enjeux légaux, opérationnels et métiers Développer, déployer, maintenir et améliorer les métriques et rapports réglementaires, comptables et d’intégration, ainsi que la modélisation de donnée sous-jacente. Intégrer des standards de sécurité, de confidentialité et de protection des données personnelles En garantir la fiabilité et la ponctualité par tous les moyens nécessaires (optimisation du code ou de la stack, rajout de tests et d’alertes, réconciliations et validation de données, mise en place de bonnes pratiques DevOps) Former les interlocuteurs métiers et les membres de l'équipe au bon usage des rapports et des tableaux de bord Etre l’interlocuteur privilégié en cas d’audit, et les anticiper (pistes d’audit, ajouts de logs, conservation des métadonnées, indempotence, conservation des rapports partagés, documentation, lineage, versions) Notre stack en quelques mots : Mixpanel, Appsflyer, Airflow/Airbyte, GCP dont BigQuery, dbt, Metabase, Dataiku Aussi, l’équipe étant encore en développement, on reste très ouverts aux initiatives (technos / outils / etc.) ! Nous rejoindre, c’est la garantie de travailler dans un environnement stimulant, d’avoir de l’impact dans la structuration de l’équipe et de ses process et de participer à la croissance d’un super projet. Vous êtes notre candidat·e idéal.e si 🤩 Vous avez une expérience au préalable en SQL, en bases de données relationnelles, en environnement Big Data et en Data warehouse Cloud (Snowflake, Redshift, etc.) Vous avez déjà occupé un poste en modélisation de données, conception de DWH et pipelines de données (orchestration, transformation, ETL ou ELT) Vous connaissez un outil de transformation comme dbt, SSIS, matillion ou Data Form (chez nous, nous utilisons dbt !) Cerise sur le gâteau si... 🍰 Vous possédez une expérience préalable avec un ou plusieurs outils de visualisation de données (Looker, Tableau, Spotfire, PowerBI, Metabase, Qlik Vous avez la connaissance de BigQuery et de l’environnement GCP Nous sommes votre entreprise idéale si vous recherchez… Une start-up française devenue scale-up qui se structure, développe de nouveaux produits et s’exporte à l’international 🌎 Une vision nouvelle et innovante qui dépoussière le secteur de l'assurance Un leadership inspirant et expert du secteur L'agilité d'une structure à taille humaine, et la place pour des initiatives innovantes et créatives Un environnement de travail respectueux de tous et toutes. En tant que membre fondateur du pacte IDEA , nous nous engageons pour la diversité, l'équité & l’inclusion Ce qu’Ornikar a à vous offrir… 🎁 Une rémunération fixe entre 47k€ et 55k€, en fonction de votre niveau d’impact et d’expertise observé pendant nos entretiens. Parmi nos avantages 1 jour de RTT par mois en plus des 25 jours de congés légaux Notre charte de télétravail hybride (3 jours par semaine en présentiel dans nos locaux WeWork pour les franciliens, 2 jours par mois si vous bénéficiez d’un contrat full-remote hors Île-de-France) Une carte Swile qui vous permettra à la fois de bénéficier de 11€/jour de tickets restaurant pris en charge à 50% par Ornikar, et de 42€/mois de remboursement transport pris en charge à 100% par Ornikar Un abonnement sport et bien-être Gymlib Une assurance santé complémentaire avec Alan Les frais de gestion pour votre épargne salariale avec Epsor La possibilité de passer votre permis gratuitement Des centaines de réductions et avantages via Leeto , partenaire de notre Comité Social Économique L'accès à notre plateforme associative Vendredi pour vous engager en parallèle de votre activité chez nous Notre process de recrutement 🔥 Un premier entretien avec Romane, notre Talent Acquisition Specialist ou directement avec votre futur manager Thibault. Un entretien d’une heure avec Thibault notre Head of Data Ops Assurance 🔭 Un test technique à réaliser chez vous ⚙️ La restitution du test avec l’un de nos Data Analysts/Analytics Engineer et un membre de l'équipe Tech 📊 Une rencontre avec Aurélien Rayer notre Chief Data Officer et un membre d’une équipe métier","Ornikar is looking for an Analytics Engineer to manage the relationship with external regulatory partners while taking the lead on the development, deployment, maintenance, and improvement of regulatory, accounting, and integration metrics and reports. Candidates should have experience in SQL, data modeling, cloud data warehousing, and transformation tools along with prior experience working with data visualization tools. Ornikar offers a hybrid telework policy, flexible working hours, and numerous employee benefits.",Non spécifié,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
280,56925,https://www.welcometothejungle.com/fr/companies/descartesunderwriting/jobs/data-engineer-scientific-engine-airflow-dvc_paris,"Data Engineer - Scientific Engine (Airflow, DVC) (Starting 2024)",Descartes Underwriting,"{python,Git,LAMP,spark,azure,Gitlab,Kubernetes,Airflow,GitHub,DVC,AWS,Docker,via,Linux,GCP,Python}",Télétravail ponctuel autorisé,"148 Rue de Courcelles, Paris, 75017","Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‘full stack’ insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (250+ and counting) - our diverse team is headquartered in Paris and operates out of our 12 global offices in North America, Europe, Australia, Singapore, and Hong Kong. ABOUT DESCARTES UNDERWRITING Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‘full stack’ insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (250+ and counting) - our diverse team is headquartered in Paris and operates out of our 12 global offices in North America, Europe, Australia, Singapore, and Hong Kong. ABOUT YOUR ROLE Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects. You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events. 🔔 KEY MISSIONS 🔔 Setup, automate, maintain and update: Connections to external and internal APIs Data preparation process Model training and inference process Data storage process Associated CI/CD pipelines Associated package versioning and releasing pipeline Modularization of code base Notification tools to inform the team of the status of the operations Setup data storage, data processing and data visualizing tools, by : Assessing the pains and needs of the teams Benchmarking the open source and private solutions Assessing the security, price and reliability of data architecture Following the development the evolution of technologies on the topic Forecasting the usage of the tools Tracking the cost of the tools Participate in: Tech stack selection Discussions with tech partners Training of software and underwriting teams Support and debug of internal users TECH STACK 🖥 ️ Cloud provider: GCP Code versioning tool: Git + Gitlab OS: Linux Container: Docker Container orchestrator: Kubernetes Website architecture: LAMP Code base: Python Notification tool: Slack DATA STACK 🗄 ️ Types: images, timeseries, Storage: GCP bucket Version: DVC (roll out in progress) Pipeline: Airflow (PoC stage) Data base: to be setup depending on the use cases In our project, data is collected by sensors (satellite, weather station, IoT). We don’t work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation …). EQUIPMENT 🖱 ️ Laptop: Dell Latitude 7530 OS: you decide ABOUT YOU EXPERIENCE & QUALIFICATIONS 👩 ‍ 💻👨 ‍ 💻 [Hard skills] Knowledge of the tech stack or equivalent tools Experience converting python code to efficient data engineering tools (eg: spark) Experience with Docker Experience with a cloud provider (GCP, AWS or azure) Experience automating a CI/CD pipeline Good knowledge in English and fluency in French [Soft skills] Desire to train junior developers and explain CI/CD and cloud tools Desire to suggest improvements to the architecture [Nice-to-have] Experience working data science project or scientific code Experience with Kubernetes Experience in HPC Contribution to an open source project MINDSET 💥 Strong interest with climate issue (it’s not a hoax, many people suffer from it) Being comfortable to work alongside corporate insurers (some still wear suits 👔) You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline) Strong team spirit and ability to work (you’ll have to review code and have your code reviewed) Rigorous, creative and meticulous mind (we handle large insurance, we take our time) Strong desire to learn (there’s no limitation to the tech used, we’re happy to test and learn new tools) Eagerness to work in a multi-cultural environment (policies and teams are from all around the world 🗺️) WHY JOIN DESCARTES UNDERWRITING? Join a company with a true purpose – help us help our clients be more resilient towards climate risks Commitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.); Work in a collaborative & professional environment; Be part of an international team that values diversity; Benefit from a nice referral scheme for successfully referring peers; You can benefit from a hybrid work mode thanks to our telecommuting agreement. OUR COMMUNITY At Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences. With equal skills, all our positions are open to people with disabilities. HOW TO APPLY If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application! https://www.descartesunderwriting.com/careers/ If you don’t check all the requirements in the description, don’t worry. We can try to make some room for you within the company if you’re motivated to work on climate risk. RECRUITMENT PROCESS Step 1: Call and HR Interview with our Talent Recruiter Step 2: Technical project submitted via GitHub Step 3: Technical interview Step 4: Manager interview Step 5: Final round interview with the team (Candidates can opt to have the manager interview before the technical project and interview)","Descartes Underwriting is seeking a data engineer to help build and maintain data pipelines for its scientific engine modeling climate phenomena. The ideal candidate should have experience with Python, Docker, cloud providers, automating CI/CD pipelines, and Kubernetes. Additionally, the candidate should have a strong interest in climate issues and a desire to work in a collaborative environment with diverse teams from around the world. Descartes Underwriting is committed to fostering an inclusive work environment that respects all differences.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,1,1,0.027697749441558416
284,56781,https://www.welcometothejungle.com/fr/companies/the-information-lab/jobs/consultant-data-engineer-experimente_paris_TIL_dM95MA9,Consultant.e data engineer expérimenté.e,The Information Lab,"{Snowflake,Alteryx,Tableau}",Télétravail ponctuel autorisé,"6, Rue Auber, Paris, 75009","Logiciels, IT / Digital, Big Data",CDI,2023-03-26,"The Information Lab a été fondée en 2010 par des passionnés de data autour des solutions Tableau, Alteryx et Snowflake. Ils sont convaincus que ce sont les meilleures technologies pour accompagner la transformation digitale de leurs clients. Cette spécialisation leur permet d’être les premiers partenaires de ces éditeurs et d’être des experts reconnus de ces solutions en France et en Europe. The Information Lab a posé ses valises en France en 2015. Ils ont aujourd’hui plus de 250 clients sur tous les secteurs d’activité : banque, assurance, logistique, ONG, retail, etc. L’équipe est répartie dans toute la France, la majorité se trouvant à Paris. Rattaché(e) au pôle Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous métiers. Vos missions ont pour objet le traitement, l’analyse, l’enrichissement des données de nos clients et l’adoption par nos clients des technologies que nous proposons. Au sein d’une équipe de 5 à 8 personnes, vous réalisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre “pod leader” (chef d’équipe). Votre rôle consiste à : Intervenir en avant-vente et cadrer vos missions Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours à quelques mois Mener des projets de bout en bout, en méthode classique ou agile, en coordination avec les équipes de nos clients, nos équipes internes et les éditeurs partenaires Présenter les livrables de vos missions et mettre en avant leur ROI Former nos clients à nos technologies Mettre vos compétences au service de vos collègues au-delà des missions dont vous avez la charge et participer au développement des compétences en partageant vos retours d’expérience Participer aux activités d’évangélisation, par exemple : rédaction de posts de blogs, participation aux communautés des éditeurs, interventions lors d’événements (salons, conférences, webinaires) Participer aux projets internes (BI interne, méthodes & qualités) Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires. Vos principales qualités : Excellentes facultés d’écoute et de communication, orale et écrite Aptitude à travailler sur plusieurs sujets en parallèle, à prioriser Humilité et capacité à apprendre ainsi qu’à transmettre ses connaissances Sens du service, un bon relationnel avec les clients et la rigueur nécessaire au succès de leurs projets Team player Compétences méthodologiques : Analyse du besoin et cadrage de mission Construction d’indicateurs métiers à partir de données brutes Idéalement connaissance d’un ou plusieurs métiers et de leurs indicateurs clés Préparation de données complexes à des fins d’analyse Méthodes de gestion de projet (classique et agile) Capacité prouvée à réaliser des démonstrations d’outils Compétences techniques : Connaissance d’au moins Alteryx Designer ou Tableau Prep (idéalement vous avez déjà une expérience solide sur ces outils) Maîtrise d’autres outils d’analyse de données Connaissance de la modélisation de données à des fins d’analyse Expérience professionnelle : vous bénéficiez d’au moins 5 ans d’expérience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis d’utiliser les technologies similaires aux nôtres. Idéalement, vous avez déjà une expérience dans un cabinet de conseil ou une ESN. Langues : Français, Anglais professionnel Situation géographique : Ile-de-France. Déplacements en France à prévoir. Rémunération : 50 à 65 k€, selon expérience. Ecrivez-nous à jobs@theinformationlab.fr avec votre CV, et dites-nous pourquoi vous souhaitez nous rejoindre. Nos entretiens sont réalisés par vos futurs homologues, vous permettant de leur poser toutes vos questions sur leur métier de consultant et la vie @ TIL !","The Information Lab is looking for a consultant with excellent communication skills, the ability to work on multiple projects simultaneously, and a desire to learn and share knowledge. The consultant should be able to analyze client needs, advise on solutions, and deliver complex data projects using Alteryx, Tableau, and similar technologies. The position requires at least five years of experience and fluency in French and English. The consultant will work with clients of all sizes and sectors and will travel within France. The salary ranges from €50,000 to €65,000 per year.",Bac +5 / Master,N,> 5 ans,1,1,0.027697749441558416
371,39670,https://www.welcometothejungle.com/fr/companies/ba-sh-1/jobs/data-engineer-f-h_paris,data engineer f/h,ba&sh,"{Snowflake,durable,SQL,Talend}",Télétravail partiel possible,"67 Av. Raymond Poincaré, Paris, 75116",Mode,CDI,2022-11-29,"En 2003, Barbara Boccara & Sharon Krief, entrepreneuses et créatives, se lancent pour créer ba&sh et son vestiaire idéal où toutes les femmes pourraient s’exprimer, avec modernité, simplicité et chic. Elles offrent la possibilité d’être libres, belles et bien. Puis, en 2015, L Catterton, le fonds d’investissement de LVMH, accompagne ba&sh dans son expansion internationale et son développement en hyper-croissance, dans un environnement transformé par la révolution digitale. ba&sh est une maison innovante, dynamique et tournée vers les problématiques de demain. Elle lance officiellement en 2021, son programme de développement durable BLOSSOM et établit un plan d’action concret tourné vers une profonde transformation ambitieuse. Bien plus qu’une marque, ba&sh souhaite couvrir les thématiques sociales, environnementales et sociétales par le choix de matières éco responsables, transparence & traçabilité dans la chaine de valeur, accompagnement des fournisseurs, suivi et réduction des émissions de gaz à effet de serre, économie circulaire et innovations durables. Au sein de l’équipe de la direction des systèmes d’information, vous rapportez directement au Responsable de projets informatiques. A ce titre, vos missions sont les suivantes : Suivi de l’exécution de la roadmap technique Développement de flux Responsable de la gouvernance et le management des données Evolution de l’architecture du Hub Être force de propositions Préparation des projets et des kick-offs Participer à/organiser l’établissement des sprints Garantir la bonne exécution des sprints Rédaction et maintien de la documentation technique Cette liste n’est pas exhaustive et sera susceptible d’évoluer avec le développement de ba&sh. Vous vous reconnaissez dans ce parcours : Formation supérieure Bac +4/+5 type école d’ingénieur ou formation spécialisée en informatique Appétence/intérêt prononcé pour le domaine du retail Au moins 3 années d’expérience sur un poste similaire en tant que data engineer Vous vous démarquez pour votre : Structuration, rigueur et sens du détail Esprit transverse et votre relationnel Curiosité, proactivité, rigueur et organisation Appétence pour faire de la veille technique et suivre les sujets liés à la data. Vous maitrisez : Parfaitement Talend, le PL/SQL, la modélisation de donnée et les règles de gouvernance associées. La connaissance de la Cloud Data Platform Snowflake serait un plus. ba&sh n’attend plus que vous ! Chez ba&sh, nous croyons que la diversité est une force, et nous nous engageons à la cultiver. La diversité sous toutes ses formes (genre, âge, nationalité, culture, croyances religieuses, orientation sexuelle, …) enrichit les échanges et le cadre de travail, favorisant ainsi le développement de l’entreprise & de chacun des individus qui la composent. En tant qu’employeur qui positionne l’égalité des chances au cœur de son système de valeurs, nous accueillons et considérons les candidatures de l’ensemble des candidats qualifiés et compétents. Nous nous engageons à continuer à avancer vers un ba&sh toujours plus inclusif, où chaque employé développe un fort sentiment d’appartenance. Si vous souhaitez rejoindre une marque en pleine expansion avec une vraie philosophie, faites-nous parvenir votre candidature.","ba&sh, a French clothing brand focused on sustainability, is seeking a data engineer to join its information systems team. The ideal candidate will have at least three years of experience in a similar role, a background in computer science or a related field, and strong knowledge of Talend, PL/SQL, data modeling, and data governance. The data engineer will manage data flows, improve data architecture, propose innovative solutions and contribute to the development of sustainable practices within the company. Diversity is at the heart of ba&sh's values, and the company encourages all qualified candidates to apply.",Bac +4,Entre 250 et 2000 salariés,> 3 ans,2,0,0.027697749441558416
94,73664,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_kRNw38z,System Team Engineer DataOps,Enedis,"{Python,Scala,Teradata,Linux,MEM,Jupyter,Kafka,Hadoop,Bash,Spark,UNIX,mem,Git}",Télétravail partiel possible,"11 place des Vosges, Courbevoie, 92400",Energie,CDI,2023-04-22,"Enedis est une entreprise de service public, gestionnaire du réseau de distribution d'électricité. Elle développe, exploite, modernise le réseau électrique et gère les données associées. Elle facilite la transition énergétique des territoires en les accompagnant dans le développement et la planification de leur production d'électricité d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le dépannage 24h/24, le relevé des compteurs et toutes les interventions techniques. Indépendante, Enedis délivre la même qualité de service aux fournisseurs d'énergie. Comme le prévoit la loi, elle a établi un code de bonne conduite auquel ses collaborateurs sont formés afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des métiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilité du Système d'information dans un contexte de forte numérisation des métiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engagée notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Système d'Information à la transformation numérique ou dans le positionnement d'Enedis comme opérateur de données, la DSI met en oeuvre de nombreux projets majeurs en lien avec les métiers concernés. Chez Enedis comme chez EDF, ce sont au total 230 métiers qui composent notre activité et permettent chaque jour de travailler à créer un monde neutre en CO2. Oublions les idées reçues, oui vous pouvez travailler chez Enedis même si vous n'êtes pas électricienne ou électricien. Pour accompagner ses clients tout en répondant aux défis de la transition énergétique et numérique, le Groupe mobilise toutes les compétences, en France et à l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Le monde de l'IT et des nouvelles technologies vous intéresse ? Contribuer à la réussite de la transformation digitale et numérique du Groupe EDF vous plairait ? Et travailler en mode collaboratif dans des espaces de travail innovants, inspirants et épanouissants ? C'est ce que nous vous proposons en rejoignant une équipe dynamique, agile et passionnée ! Un des enjeux majeurs d'Enedis est de devenir un opérateur de confiance de Données énergétiques. Afin de répondre à cet enjeu, Enedis a mis en place une plateforme de données pour l'entreprise. Cette plateforme est composée d'une infrastructure de données centralisée construite sur Hadoop et d'outils à destination des équipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'améliorer cette plateforme sur plusieurs axes : migration vers le cloud, évolution de l'architecture avec en cible une plateforme modulaire composant des services managés, automatisation et montée en gamme de l'offre de services internes permettant aux équipes de gagner en autonomie dans la création de véritables produits de données. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des équipes du train SAFe DataServices4U - équipe SPHINX, en charge de l'infrastructure data des activités exploratoires (big data, big mem, GPU) - définira, développera, mettra en place et maintiendra les outils et infrastructures adéquats aux opérations du reste du train (équipes data scientists et data engineers). - veillera à garantir les opérations des solutions permettant le traitement de volumes importants de données tout en garantissant la sécurité de celles-ci - définira les enablers à prendre en compte dans l'équipe - sera Tech. Lead d'une équipe d'une dizaine de personnes - testera les réalisations de l'équipe - contribuera aux démonstrations faites aux équipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous êtes issu d'une formation de type Bac +5 dans le domaine de l'IT / système d'information / Numérique et DATA - Vous disposez d'une expérience d'au moins 4 ans dans des activités équivalentes, au cours desquelles vous avec avez développé de solides compétences techniques - Vous avez un profil Ingénieur Big Data disposant de compétences d'analyse, de synthèse, de créativité et d'une appétence pour l'innovation. - Vous avez de bonnes connaissances de l'administration système UNIX : maîtrise de Linux (Redhat), Bash - ainsi que composants sécurité et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacités de communication (orales et écrites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacités de coordination - Vous faites preuve de curiosité, d'esprit de synthèse, de méthodologie et de rigueur dans un environnement complexe Le poste est situé à Courbevoie, avec une possibilité de télétravail partiel. La rémunération sera proposée selon vos compétences, vos expériences acquises et vos diplômes. L'étude de rémunération sera effectuée en adéquation avec le marché de l'emploi actuel. Par ailleurs, des primes variables sur les résultats, intéressement, épargne salariale sont mises en place. Cette mission est un moyen idéal d'accroître votre valeur professionnelle, vos compétences et de progresser vers d'autres directions du Groupe. Alors n'hésitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes à toutes les compétences, toutes les énergies et toutes les personnalités sans exclusion. Le poste proposé est donc ouvert à toutes et à tous. Venez découvrir nos différents réseaux qui oeuvrent à favoriser la mixité dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0",,Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
368,56685,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-f-h_suresnes_AXA_wgNQjro,Data Engineer,AXA,"{Databricks,Git,Scala,Kubernetes,Docker,Spark,Azure,NoSQL,SQL,Python}",Télétravail partiel possible,Suresnes,"Banque, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l’assurance et de la gestion d’actifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous protéger en donnant à chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! L’équipe « Big Data » de Direct Assurance a pour mission principale de contribuer à la dynamique continue d’innovation et de perfectionnement de l’entreprise en résolvant des problématiques business concrètes par la mise en place d’une plateforme Data dans le Cloud, ainsi que la conception et la réalisation de solutions techniques de data science en s’appuyant sur des sources de données variées tant en interne qu’en externe. Vos missions seront les suivantes : Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles Assurer le suivi de la production Participer, avec l’équipe, au développement de la plateforme sur Azure et à la définition des bonnes pratiques de développement Accompagner les équipes métier dans la prise en main de la plateforme Azure et les aider à monter en compétences en programmation en s’assurant du respect des standards internes Environnement technique : Spark, Scala, Python, Cloud Azure, OpenShift, SQL De formation Bac+5 (ou plus) en développement informatique / data engineering, vous justifiez d'une première expérience en stage ou alternance au cours desquels vous avez pu développer les compétences techniques suivantes : Spark Scala + Python Cloud Azure (DataFactory, ADLS, Databricks) Bonnes connaissances sur les architectures de données et le cloud Solides connaissances des processus collaboratifs et outils de développement (DevOps, Git, CI/CD…) SQL Les qualités suivantes sont nécessaires : Bonne faculté pour appréhender les couches technologiques et les outils Capacité à travailler de manière collaborative au sein d’équipes pluridisciplinaires Autonomie, grande rigueur, pragmatisme et réelle capacité à délivrer Bon niveau d’anglais, parlé et écrit Les connaissances suivantes seraient un plus : OpenShift, Docker, Kubernetes Framework de stream processing Data visualisation Bases NoSQL Le poste est basé à Suresnes (92) à proximité de la Défense.","AXA is hiring a Big Data Engineer for its Direct Assurance team to work on data science solutions for both internal and external data sources. The successful candidate should have experience with Spark, Scala, Python, Cloud Azure, OpenShift, and SQL as well as solid knowledge of collaborative processes and development tools. The role requires an ability to work collaboratively in a multidisciplinary team and good English language skills. The position is located in Suresnes, France.",Bac +5 / Master,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
151,56417,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-powercenter-informatica-h-f_paris,Expert.e technique ETL Powercenter Informatica,CGI,{Informatica},Télétravail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services numériques, CGI est convaincue que l’innovation technologique permet aussi bien d’accélérer la transformation de la société et de son économie, que le développement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences réparties partout en France Des synergies en Europe de l’ouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d’activités représentés (Banques, assurances et services financiers, CPG, retail et luxe, Énergie & Utilities, Industrie, Secteur public, Transport) 4 métiers : business consulting, intégration de systèmes, business solutions, managed IT services Développement, cybersécurité, big data, intelligence artificielle… Autant d’enjeux qui rythmeront votre quotidien. Vous êtes passionné.e par le Décisionnel et la Data et avez déjà une très solide expérience sur l’outil ETL Powercenter Informatica. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation (> 250 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Data que ceux de votre domaine de compétences initial. Votre rôle au sein du Centre d’Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients. Vos missions sont : • Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place • Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l’intégration de données • Participer à l'élaboration et la révision de normes / documentation technique dans le cadre des projets • Animer des formations internes et externes. Accompagner la montée en compétences des équipes • Assurer un support technique aux équipes et aux clients au quotidien • Participer aux avants ventes en tant qu’expert.e ETL Powercenter Informatica • Participer aux échanges avec l’éditeur Powercenter • Participer à la qualification technique de candidats en recrutement Fort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique, dans le consulting autour de l’intégration de données, ou dans une fonction de Chef.fe de Projet BI. - Passionné.e d’informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager. - Vous êtes également doté.e d'un esprit audacieux et ambitieux. - Vous faites preuve d’initiative et travaillez sur le long terme. - Vous justifiez d’au moins 3 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil en tant qu’expert.e technique dans le domaine de l’intégration de données. - Vous justifiez également et si possible d’une pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualité de données, de la gouvernance des données ou dans le MDM ou sur Informatica Cloud sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.","CGI is a global leader in digital consulting and services, helping companies and administrations transform to become more innovative and efficient. They are seeking a technical expert in data integration with at least 3 years of experience, particularly with ETL Powercenter Informatica. The role involves analyzing solutions to improve efficiency, collaborating with engineers to find technical solutions, leading internal and external training, and providing technical support to teams. The successful candidate will have opportunities for growth into technical leadership, data integration consulting, or BI project management. Knowledge of data quality, governance, MDM, or Informatica Cloud is a plus. CGI is an inclusive employer dedicated to the career development and well-being of all employees.",Non spécifié,> 2000 salariés,> 3 ans,2,0,0.027697749441558416
445,56425,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-engineer_utrecht,Data Engineer,Artefact,{},NaN,"Utrecht, 3511","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that’s why we identify as “marketing engineers”. In order to improve the performance and impact of brands, and consumers’ experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). Who we are Artefact is a new generation of a data service provider, specializing in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organizations. We are proud to say we’re enjoying skyrocketing growth. We have 1100+ employees across 16 offices who are focused on accelerating digital transformation and marketing excellence with our 1000+ clients. Thanks to a unique mix of company assets: State of the art data technologies, agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client. What you will be doing: Key responsibilities As a Data Engineer, your role will encompass: Conducting ambitious projects in the transformation of clients through data Collaborating with the other Divisions (Activation, Creativity, and Strategy) to provide comprehensive services to your clients Developing privileged relationships with our clients, using your technical abilities to assist in the transformation of their marketing department You’ll also participate in international projects. Among your responsibilities as a Data Engineer, you will be responsible for: Performing data projects Securing delivery on your projects Communicating your work and achievements among the team Working closely with your Consulting counterpart to build and maintain strong relationships with your clients and best understand their needs Ensuring that your solutions are bringing value to the client Being a good team player, knowing your role and responsibility in the global ambition Being a great tech person Demonstrating the skill and credibility required to ensure the success of our clients’ initiatives Researching and developing new technical approaches to address problems efficiently Sharing best practices and contributing to Artefact’s institutional knowledge Embodying Artefact’s values and inspiring others to do the same Qualifications: Education & experience required A Master’s degree in computer science, machine learning, mathematics, or related fields Hands-on experience developing and applying data-driven solutions in a corporate or consulting setting, preferably in a consumer marketing context (experience in the web industry is a plus) Strong knowledge of computer science, data processing, algorithms, and data architecture Intellectual curiosity and excellent problem-solving skills, including the ability to structure and prioritise an approach for maximum impact What we are looking for A Doer : you get things done and inspire your teams to do the same An Analyst : you LOVE data and think every company should take their decisions with facts A Pragmatist : you have a hacker mindset and always find the quick wins A Mentor : your clients and teams naturally seek for advice An Adventurer : you’re an entrepreneur constantly looking for problems to solve We welcome people from all nationalities, and background, but are focusing on people who already reside in The Netherlands. Why you should join us Artefact is the place to be: come and build the future of marketing Progress: every day offers new challenges and new opportunities to learn Culture: join the best team you could ever imagine Entrepreneurship: you will be joining a team of driven entrepreneurs. We won’t give up until we make a huge dent in this industry! Come join us!","Artefact, a consulting firm specializing in AI and data, is seeking a data engineer to help transform clients through data by collaborating with other divisions, developing relationships with clients, and performing data projects. The ideal candidate should have a master's degree in computer science or a related field, hands-on experience with data-driven solutions, and excellent problem-solving skills. Additionally, they should be a doer, analyst, pragmatist, mentor, and adventurer. Artefact offers a challenging and entrepreneurial environment for career growth.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
143,50432,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-london-or-remote-uk_london,Software Engineer Data Preparation - London or Remote UK,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",NaN,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working 'œunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a full-stack software engineer to work on the Data preparation part of their platform, as well as other core features. The ideal candidate should have experience in software development and an interest in data processing, be customer-oriented, and have firsthand experience in building a real product. They should also be humble, kind, and curious about working ""under the hood."" Dataiku offers a flexible work-life balance, autonomy, and opportunities for learning and giving back. They are an equal opportunity employer committed to treating all employees with dignity, decency, and fairness.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
214,65905,https://www.welcometothejungle.com/fr/companies/longevity-partners/jobs/database-engineer_austin,Database Engineer,Longevity Partners,"{MySQL,Azure,MongoDB,shell,DuckDB,PostgreSQL,AWS,Cassandra,Linux,R,SQL,NoSQL,MariaDB,Python}",NaN,"Austin, 78701","Environnement / Développement durable, Energie, Immobilier commercial",CDI,2023-04-05,"Founded in 2015, Longevity Partners assists and advises real assets businesses at every stage of their ESG approach, to turn environmental and social issues into levers for value creation throughout their activities. With offices in ten cities around the world, Longevity Partners has established itself as a reference in the field of independent ESG consulting. This presence has been growing steadily over the years, to the point of being recognised by the Financial Times as the fastest growing ESG consultancy in Europe in 2022. Longevity Partners assists companies in the transition to a low-carbon economy, particularly in the following areas: Analysis of the challenges; definition of ESG strategies; facilitation of the deployment and development of programs related to social responsibility Implementation of operational solutions for environmental and social efficiency Support for the validation of asset performance Sustainable design, asset repositioning, Net-Zero Carbon, identification, and management of climate risks Company Overview Longevity Partners is a multi-disciplinary energy and sustainability consultancy and investment business. It was established in 2015 to support the transition to a low carbon economy in the UK, USA, Europe and worldwide. Position Overview: The company is recruiting a Database Engineer who can provide vision & creativity to new data environments that can transform the way Longevity Partners delivers value to its clients. This critical role is an exciting opportunity that will involve building and maintaining the development of a new database ecosystem that can enable information to move seamlessly throughout our company. An ideal candidate will use their extensive knowledge of back-end infrastructure to enable meaningful, human-oriented data products that can power critical decision-making both within Longevity and on behalf our clients. The team is currently managing a wide variety of internal and client-side projects, even though this position will not be responsible for interfacing directly with clients. This position reports to the Associate Director of Data Science + Analytics and is based principally in our offices in Austin, TX, with minimal expectations for travel. Essential Functions Build and maintain database ecosystems that are high-quality and reliable Design + build both NoSQL + SQL database warehouses Orchestrate data backups + recovery processes Analyze database performance, pain points, and implement improvements to speed + efficiency Ensure data security and protection across both storage and transfers Help develop ETL and data pipeline maps Provide thoughtful + responsive management support for database ecosystems Define, enforce and document database policies, protocols and best-practices. Design + perform tests and evaluations processes to ensure data security, performance, and integrity Assist with monitoring databases, implementing required upgrades and resolving critical issues. Requirements 5+ years of experience as a Database Administrator or Architect Extensive experience with database standards and developing end-user applications Exceptional problem solving skills. Excellent understanding of conventional SQL, query optimization and NoSQL databases (MongoDB, MariaDB, Cassandra, PostgreSQL, MySQL) as well as emerging tools like Apache Arrow, Arrow Flight, + DuckDB Experience with cloud database management systems like Azure and AWS Experience with time series databases preferred Excellent knowledge of data backup, recovery, security, integrity Experience with database design, documentation and optimization Prior experience using DBA case tools (frontend/backend) and third-party tools Knowledge and experience with Linux, shell, networking tools, and version control Experience working and developing with APIs ETL experience programming in R or Python (Preferred) Experience designing and maintaining APIs or API wrappers (Preferred) BS or graduate degree in a computer-related discipline or relevant certification (Preferred) Experience or familiarity with Shiny, RStudio Connect, and Quarto ​ Benefits Employee Health and Dental Benefits that are 100% Paid For by LP Guaranteed 401k Retirement Contributions by Employer Generous PTO Offerings Fun and Relaxed Office Environment Ability to work in a hybrid working environment","Longevity Partners, an ESG consultancy firm, is seeking a Database Engineer to develop and maintain a high-quality and reliable database ecosystem. The ideal candidate should have at least five years of experience as a Database Administrator or Architect, with exceptional problem-solving skills and extensive knowledge of SQL, NoSQL databases, and emerging tools like Apache Arrow and DuckDB. The position comes with health and dental benefits and a 401k retirement plan, among other benefits.",Bac +3,Entre 50 et 250 salariés,> 5 ans,0,1,0.013848874720779208
228,60138,https://www.welcometothejungle.com/fr/companies/thales/jobs/alternance-data-engineering-supply-chain-f-h_bordeaux,Alternance – Data engineering supply-chain,Thales,"{durable,POWERBI}",NaN,Bordeaux,"Logiciels, Cybersécurité, Aéronautique / Spatiale",Autres,2023-03-28,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Sur le Campus Thales Bordeaux, nous concevons, développons et livrons des systèmes, des équipements et des services pour assurer la réussite des missions aéroportées de nos clients, dans les domaines du transport, de la surveillance et du combat. La Direction Industrielle recherche un alternant en tant que Data engineering supply-chain (F/H), au sein du Campus Thales Bordeaux. QUI ETES-VOUS ? Issu d’une formation de niveau BAC+3 à dominante informatique, vous recherchez une alternance d’une durée de 1 à 2 an(s) ? Vous avez des connaissances générales en Supply chain ? Vous avez des compétences significatives en développement logiciel VBA, POWERBI ? Idéalement, vous maîtrisez le traitement de données et vous avez un fort intérêt pour les systèmes d’informations de production ? Vous savez faire preuve de rigueur, d’une bonne capacité d’écoute, d’analyse et de synthèse ? Vous êtes force de proposition, doté d’un bon relationnel ? Vous appréciez collaborer et travailler en équipe ? Votre niveau d’anglais vous permet de lire, écrire et parler avec des termes techniques ? Vous vous reconnaissez ? Alors vous avez de bonnes chances de vous épanouir dans nos équipes ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Au sein du Centre de Compétence Industrie de Thales Defence Mission Sytems, vous intégrerez le Département Supply-chain. Dans le cadre de vos missions, en support aux activités du service data management, vous serez en charge de développer des tableaux de bord de pilotage supply-chain. Vous serez intégré à une équipe de 10 personnes sur le campus Thales Bordeaux En nous rejoignant, vos principales missions seront les suivantes : • Prendre en charge de la mise à jour des indicateurs de pilotage de la supply-chain industrielle et du reporting associé aux supply-chain managers et responsables de ligne de production. • Développer des outils d’aide à la décision à partir d’extraction des données de l’ERP en s’appuyant sur les rapports BI existants et en les personnalisant par des macro excel et des traitements POWERBI • Maquetter des reports pour répondre aux besoins opérationnels des lignes de production Au fil du développement de vos compétences, vous serez amené à prendre en charge la spécification aux équipes de développement BI des besoins des utilisateurs et à en assurer le suivi jusqu’à la mise en place (développement, test, mode opératoire, support). Le rythme de l'alternance doit permettre, dans la mesure du possible, d'assurer une continuité dans les missions. Cette alternance sera l’opportunité pour vous de travailler en équipe au sein d’une entreprise innovante, de valoriser les acquis académiques en environnement industriel et développer de nouvelles compétences. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales is looking for an alternate Data Engineering Supply-Chain, with knowledge in supply chain and software development. The candidate should be interested in information systems and have significant competence in VBA Development and Power BI. They should be able to work in a team, have a good sense of analysis and proposal, and have proficiency in reading, writing, and speaking with technical terms in English. The main duties include developing and updating dashboards for industrial supply-chain management using ERP data and existing BI reports, developing decision-making tools for different production lines, and personalizing reports according to production line requirements. The candidate will also need to provide user requirements to the BI development team, aid the development of BI tools, and deliver support.",Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
244,4069,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/saas-full-stack-developer_paris,Software Engineer Dataiku Online - Paris,Dataiku,"{React,go,Dataiku,python,regard,Kubernetes,Docker,Python}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online’s team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku souscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is either at the company HQ in Paris (Gare de Lyon) or remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented — you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: - Hands-on expertise working with Docker and Kubernetes - Experience on an high availability SaaS - Knowledge in DataScience, AI and Machine Learning - Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) Dataiku’s culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking an experienced developer with expertise in full-stack development and an interest in SaaS platforms. The role involves actively contributing to the design and implementation of a SaaS portal associated with the managed service offering. The ideal candidate has experience building a real SaaS portal, is customer-oriented, and has working knowledge of Python (Flask) and Vue.JS. Bonus points for expertise in Docker and Kubernetes, experience on a high availability SaaS platform, and knowledge in data science, AI, and machine learning. The position can be either at the company headquarters in Paris or remote.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
439,50212,https://www.welcometothejungle.com/fr/companies/mantu/jobs/data-engineering-manager_madrid,Data Engineering Manager,Mantu,"{Microsoft,Azure,Synapse,GIT}",NaN,"Madrid, 28014","Logiciels, IT / Digital, Organisation / Management",CDI,2023-02-07,"Mantu is an independent and international consulting player, founded in 2007. Mantu stands out for the breadth of its intervention spectrum, which responds to all the challenges of business transformation. Its activities are divided into 4 practices: Leadership & Advocacy, Technology, Digital Marketing & Experience, Total Talent Management. A wide range of skills, all serving a single mission: connecting and powering companies with leading team and technology, to succeed faster and sustainably. From its headquarters in Geneva, Switzerland, Mantu relies on a community of 10,000 talented people in more than 60 countries on 5 continents and a turnover of 810 million euros. Mantu is strongly committed to the development of its talented people and their skills. Its community of over 110 nationalities guarantees a multicultural experience. An experience characterized by the group’s strong confidence in its teams: whether in young people, by offering them rapid career development, or in the autonomy and level of responsibility entrusted to them. Whatever their specialty or activity´s sector, all Mantu brands address environmental and social issues with the same determination to align the pioneering spirit dear to its DNA with our collective responsibility. Your role: As a data engineering manager, you will primarily manage, coach, and develop a data engineering team. Coordinate with analyst and report maker on needs, fulfil and organize backlog. Deliver, with your teammates, new features, data flows and datasets efficiently with Microsoft Azure Data services (Data Factory, Synapse, Database, Datalake, Logic Apps) and Power BI. Dispatch development across your team members, organize plannings and deliveries. Review team code, ensure quality, manage source control (GIT) and CI/CD (Azure Dev Ops) operations. Analyze data engineering issues and requests to provide strong support to users’ communities. Works to set the data vision and roadmap with head of department, IT, and governances. Profile description : • You are Data enthusiast and have strong technical experience specifically in the development of datawarehouse or something equivalent• You already have project management habits.• You like to drive and follow multiple tasks & projects at the same time. You are able to prioritize and estimate technical tasks within the team.• You are solution oriented and find technical ways to answer needs. You plan sustainable solutions.• You are graduated from Engineering School or hold an IT Master Degree• You have between 4 and 10 years of experience minimum working in Microsoft Data and Azure topics. DevOps experience is a plus.• You are a proactive person who like to learn new things. You are curious, you like to understand the global picture and work in international teams","Mantu, an international consulting firm, is seeking a data engineering manager to lead and develop a team, coordinate with analysts and report makers, deliver new features and datasets using Microsoft Azure Data services and Power BI, manage source control and CI/CD operations, analyze issues and requests, and set the data vision and roadmap. The ideal candidate should have strong technical experience in data warehouse development, project management skills, ability to prioritize and estimate technical tasks, and hold an Engineering School degree or IT Master Degree with at least 4-10 years of experience in Microsoft Data and Azure topics. DevOps experience is a plus, and the candidate should also be a proactive learner who enjoys working in international teams.",Bac +5 / Master,> 2000 salariés,> 10 ans,0,1,0.013848874720779208
130,37283,https://www.welcometothejungle.com/fr/companies/dhl-information-services/jobs/senior-dwh-bi-data-engineer_praha,DWH/BI Data Engineer,DHL Information Services,"{PowerBI,Teradata,tabular,Azure,SQL,DAX,Tableau}",NaN,N,"Application mobile, Logiciels, Intelligence artificielle / Machine Learning, Robotique",CDI,2022-10-18,"Deutsche Post DHL, the world’s leading logistics company with the distinctive yellow-red logo needs no introduction. Even though DHL IT Services are a part of it, you will not find any packages here. In DHL IT Services, they provide IT services to all Deutsche Post DHL divisions: DHL Express, DHL Supply Chain, DHL Global Forwarding & Freight, Post & Parcel and e-Commerce. They are a global IT organization with two key data centers – one in Kuala Lumpur/Cyberjaya (Malaysia) and one here in Prague. Do you enjoy crunching data? Do you feel at home when writing T-SQL statements, making the code as lean as possible and optimising query performance? Do you have experience with database backups and restores and other database and server administration? Or you like to get your hands dirty with data on Azure? Are you eager to learn Teradata SQL? Does it bring you joy to turn raw data into valuable information and insights to help your business colleagues to make better business decisions? If your answer is yes, then we must definitely talk! You will be: • Involved in development of strategic DWH/BI solutions using SQL Server, Teradata, Analysis Services, Azure Data Service and Power BI • Participating in requirement analysis and solution design • Cooperating with other developers, eventually technical leading of the product team • Providing ad-hoc analyses of data by SQL querying and possibly using presentation layer of choice (Tableau, PowerBI, Excel..) • Improving performance of current long-running queries • Connecting new data sources • Performing unit testing of your code and peer review of the pull requests from your team colleagues using Azure DevOps • Working In DevOps oriented culture with high trust, high spirit and great colleagues that make you smile every day You should have: • Passion about data • Experience with database and dimensional modelling for DWH/BI solutions • Ability to write advanced T-SQL queries • Advanced knowledge of SSAS – tabular model • Experience in Database and Windows Server Administration • Experience with database and dimensional modelling for DWH/BI solutions… • Knowledge of DAX and PowerBI – knowledge of Tableau would be a bonus • Azure skills are very welcome • Ability to manage your time efficiently to avoid over-commitments • Ready to learn extremely fast in a very agile, high pace environment. • Pro-active and critical thinking • Continuous improvement mindset You will get from us: • Great team of professionals and possibility of development • Modern offices in Chodov next to metro station • Home office possibilities • Permanent contract • CAFETERIA employee benefit program with wide selection of benefits from Edenred • Extra week of holiday (25 days/year) • 6 Self-sickness days/year • Full salary compensation for up to 10 days absence due to illness per calendar year • Lunch vouchers fully covered by company • Multisport card • Mobile and laptop • Fruit days, sport clubs for employees • Referral program In DHL ITS Prague, you will have the opportunity to be part of over 1650 highly skilled IT professionals of 67 nationalities. Would you like to develop your career in DHL ITS Prague – the largest data center operation in the Czech Republic? Start your application now!","DHL IT Services is seeking a Data Warehouse Developer to develop strategic DWH/BI using SQL Server, Teradata, Analysis Services, Azure Data Service and Power BI. The ideal candidate should have a passion for data, experience with database and dimensional modelling for DWH/BI solutions, advanced T-SQL query writing ability, and know-how of SSAS Tabular Model. The role involves working in a DevOps culture and providing ad-hoc analyses of data, improving query performance, and connecting new data sources. The benefits include a modern office, home office possibilities, employee benefit programs, extra week of holiday, and more.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
300,63012,https://www.welcometothejungle.com/fr/companies/sifflet/jobs/data-engineer_paris,Data Engineer,Sifflet,"{Azure,Scala,AWS,scale,Sifflet,GCP,Java,SQL,Python}",Télétravail ponctuel autorisé,"5, Rue des Italiens, Paris, 75009","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data",CDI,2023-03-31,"Created in 2021, Sifflet is an early-stage start-up backed by Tier 1 investors. We are building the world’s best observability platform to enable companies to trust their data and excel at data-driven decision-making. It’s normal if you’ve never heard of data observability because we’re building this category! We are based in Paris but serve organizations from all over the world, from scale-ups to large enterprises. Young, ambitious, and extremely passionate about data. We are looking for an experienced Data Engineer to join our ML engineers Marie and Gwennaëlle. In this role, you will, Design, build, and maintain the infrastructure required for data processing and analysis (we’re still at the beginning, there’s a lot to build) Work closely with all the teams to ensure that the data infrastructure supports the needs of the organization and enables data-driven decision-making. Collaborate with the engineering team to solve technically complex challenges, hiring, and shaping the culture. This is a key moment to join Sifflet, as we’re still a small team with a lot of room to grow: you’ll have a major impact on the development of our data-driven initiatives. You have a BS/MS/PhD in a scientific field or equivalent experience. You have at least 3 years of experience in data engineering , ideally in a start-up. Strong technical skills in areas such as data modeling, database design, ETL processes, data warehousing, and programming languages such as SQL, Python, Java, and Scala. Strong knowledge of a major cloud environment (AWS, GCP, or Azure) You have excellent communication skills and the ability to adapt messaging to technical and non-technical audiences. You are autonomous, organised, self-motivated and able to drive ambitious projects to success from conception through coding to deployment. You value ownership of your projects from design to production .","Sifflet, a data observability startup, is seeking an experienced Data Engineer to design, build, and maintain the company's infrastructure required for data processing and analysis. The ideal candidate should have at least 3 years of experience in data engineering, strong technical skills in data modeling, database design, ETL processes, data warehousing, as well as programming languages such as SQL, Python, Java, and Scala. Additionally, the candidate should have strong knowledge of a major cloud environment (AWS, GCP, or Azure), excellent communication skills, and the ability to adapt messaging to technical and non-technical audiences.",Non spécifié,Entre 15 et 50 salariés,> 3 ans,1,0,0.013848874720779208
136,48256,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-finance-tableau-dataviz-bi-factory-f-m-d_croix,DataViz Engineer - Financial Solutions,Decathlon Technology,"{AWS,dataset,GCP,SQL,Github,Tableau}",NaN,"4 Rue du Professeur Langevin, Croix, 59170","Grande distribution, Sport, E-commerce",CDI,2023-02-05,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Pour répondre au mieux à son ambition de pilotage par la data, Decathlon a organisé une DATA UNIT à laquelle la BI Factory est rattachée. L’équipe BI Finance est une composante de la BI Factory et répond aux besoins des process métiers suivants: Stock & marge Comptabilité Omnicommerce Encaissement Production Trésorie Achats Systèmes financiers TA RESPONSABILITE : Au sein de l'équipe BI Finance, ta mission principale consiste à : Répondre à des demandes d’analyses récurrentes de KPIs en mettant à disposition des métiers, de manière automatique et régulière, des outils de data visualisation performants. Intervenir dès la finalisation du cadrage projet par le Project Manager jusqu’à la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : les autres Dataviz Engineers, les métiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e Dataviz Engineer, basé-e dans la région Lilloise. Le périmètre technique : Maîtrise de Tableau Software (QlikSense un plus) Maîtrise du SQL Maîtrise d'un ETL/ELT un plus Rédaction de documentation dans Github Méthodologie Agile (SAFE) CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience d’au moins 3 ans en développement de data visualisation et parle un Anglais courant (relation avec des équipes à l'international). Tu as déjà produit de la data visualisation performant avec Tableau Software Pour réussir, tu dois savoir: Comprendre le besoin métier / interagir avec les interlocuteurs fonctionnels Comprendre un modèle de données et t'en servir. Modéliser un dataset afin de développer des visualisations en assurant les performances techniques Développer le flux d’extraction des data nécessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages métiers exprimés lors du cadrage Maîtriser les technologies utilisées et les bonnes pratiques de développement Partager ton avancement et les difficultés rencontrées lors des instances AGILE dédiées. Rédiger la documentation technique permettant d’assurer un run efficace Tu es particulièrement sensible à l’impact de la pratique du sport pour les valeurs qu'elle t'a permise d’acquérir dans ton style de leadership et la vie en équipe ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes, Lyon, Londres, Madrid et Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a Data Visualization Engineer in the Lille region to support its mission of making sports accessible to everyone through innovative digital products and sustainable practices. The successful candidate will have at least three years of experience in developing data visualizations using tools such as Tableau and a strong understanding of SQL and ETL/ELT processes. The engineer will work with the BI Finance team to develop and deliver automated and high-quality data visualization solutions to meet the needs of various business processes. The ideal candidate must be comfortable interacting with different stakeholders, understanding business requirements, and complying with agile methodologies. Decathlon offers flexibility, growth opportunities, certification programs, employee shareholding, and a diverse and inclusive work environment.",Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
23,67013,https://www.welcometothejungle.com/fr/companies/salsify/jobs/data-systems-integration-engineer_lisbon,Data & Systems Integration Engineer,Salsify,"{go,Athena,color,Boomi,Workato,Looker,Alteryx,SQL,Domo,Python,Tableau}",NaN,"Lisbon, 1050-115","SaaS / Cloud Services, Big Data",CDI,2023-04-07,"Salsify was created to empower brands and retailers to win on the digital shelf. Salsify solutions offer unique functions to help drive results. For Manufacturers Empowering brand manufacturers to manage, syndicate, and optimize product content for winning shopping experiences. For Retailers Empowering retailers to create engaging, high-quality shopping experiences for the digital shelf. For Distributors Empowering retail distributors to manage unique ecommerce product data management needs. Come join a company who is a key leader in the industry scaling the next core commerce infrastructure and on the path from $100M to $500M! Founded in 2012, Salsify helps brand manufacturers, distributors, and retailers in over 80 countries collaborate to win on the digital shelf. As the market leader globally, our products are shopper-centric, frictionless, and create memorable commerce experiences. Our products provide a competitive edge through experiences that improve brand trust, amplify product differentiation and assortments, increase conversion rate, improve profit margins, and speed time to market. Learn how the world’s largest brands, including Mars, L'Oreal, Coca-Cola, Bosch, and GSK, as well as retailers and distributors such as E.Leclerc, Carrefour, Metro, and Intermarché use Salsify everyday to stand out on the digital shelf. At Salsify, we strive to embody an equitable, diverse, and inclusive company culture. We are united across countries, levels, tenures, and a host of other dimensions of diversity. We understand that while work is just one aspect of who we are, a truly inclusive culture accounts for the full authenticity of every single human being that works here. About the Opportunity Are you a data and / or a systems integration junkie? Do you like to work with new technology to solve complex technical issues related to moving data (ELT/ETL), building data models, or providing systems integration / automation solutions? The role of the Data & Systems Integration Engineer is a new role at Salsify on our Business Technology team, and it’s a role that is expected to have a high impact on our Data & Automation strategy across the business. In this individual contributor role, you will have the opportunity to work on solutions like Domo, Workato, Boomi, Alteryx, and Amazon Athena. You also may have the opportunity to use your Python skills as we evaluate different solutions and identify how existing systems can integrate with other systems or pull / push data to our data warehouse and business intelligence platforms. We are looking for someone who has an appetite for a big challenge and is ready to demonstrate their technical skills. A majority of your role will be focused on using out-of-the box solutions, but we also welcome creativity, innovation, and ideas on how to solve problems most effectively. While the majority of your work will be focused on technical tasks such as building ETL jobs, data models, or systems integration solutions, there is a customer service component that is important to the job too. Being customer friendly, collaborative, and authentic are important traits to the role as well. How You'll Make an Impact: Become the subject matter expert for how to build and manage our data warehouse Become the go-to person for all things related to data and systems integration Become well versed in capabilities of the technologies that we support internally for data and systems integration Create a governance model that allows data stewards and analysts to self-serve their data needs Develop relationships, build trust, have a high quality mindset, and collaborate effectively with others Don’t let your ego get in the way of success You'll Enjoy This Role If You Have: Must have prior experience working in a data engineer or systems integration role SQL, Python, and other data modeling / querying languages are required Must be able to understand and articulate the pros and cons of various data warehouse, ETL/ELT, data modeling, and business intelligence solutions Experience with BI tools such as Domo, Looker, or Tableau is preferred Experience working with systems integration tools like Boomi or Workato is preferred Experience working on teams that support internal business operations (e.g. IT, Business Systems) is preferred What We Have for You: Competitive Salary Equity Unlimited Vacation Medical, Dental and Vision Insurance (Multicare) Life Plan Meal Allowance Referral Bonuses #LI-KT1 #LI-Remote Salsify loves a good success story and it would be our privilege to help write yours! We recognize that talent and potential come in all forms and that years of experience does not guarantee on the job effectiveness or leadership potential. Our hiring process involves recognizing a person’s achievements, subject matter expertise, and passion, not just check marks next to a job description. If you have an interest in our roles please do not hesitate to apply - we would be happy to speak with you! A member of Talent ' talent@salsify.com ' will be reaching out about next steps if we would like to move forward. Salsify’s mission is to empower brand manufacturers to win on the digital shelf. Helping brand manufacturers to win online is what we do. Our culture is who we are. We are empowered. We are positive thinkers. We take action. We care deeply. These values have driven Salsify’s growth and earned the company numerous top workplace awards. We are headquartered in Boston, Massachusetts and have hubs in Lisbon (Portugal), Paris (France), and Sydney (Australia). If you are excited to work in a fast-paced environment with a team that values agility, curiosity and passion, we want to hear from you! Please see our Candidate Privacy Statement for information on the personal data we process in connection with your application. An Inclusive Place To Work Salsify does not discriminate based on race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. Studies have found that people of color and women do not apply to jobs if they do not meet all the requirements. At Salsify we are committed to empowering a diverse workforce. We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Accommodations Salsify is committed to an inclusive hiring process, and we aim to provide accommodations for persons with disabilities. If you need any accommodations for the application or throughout the interview process please contact cx@salsify.com .",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,0,1,0.013848874720779208
448,56560,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_brest_ASI_KV32Rpz,Data Ingénieur - Manipulation et valorisation des big-datas,ASI,"{MySQL,Oracle,ElasticSearch,Scala,Kafka,Cassandra,PostGreSQL,Spark,SQL,Java,NoSQL,Hadoop,Python,Cloudera}",NaN,Brest,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Vous aurez pour mission de : Concevoir et réaliser un sourcing de données Big Data Temps réels ou non Maîtriser les formats de données non structurés et savoir les manipuler Concevoir et réaliser une chaîne de traitement dans un environnement Big Data Concevoir et réaliser des applications et API utilisant les données valorisées Gérer et administrer les bases de données filesystem et NoSQL Ecosystème en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, Big Query Langages de développement : Python, Java, Scala. Idéalement titulaire d’un Bac+4/5 (Ecole d’Ingénieur ou Universitaire), vous maitrisez : Hadoop (Cloudera)et/ou une solution de base de données NoSQL Le requêtage SQL, HiveQL Le développement Spark avec SQL, Python et/ou Scala Le développement Java (API en particulier) Les bases de données relationnelles (PostGreSQL, Oracle, SQLServer, MySQL…)","ASI, a digital expertise firm committed to responsible and positive impacts through digital transformation, seeks a Big Data Consultant to design and implement data processing and API applications in Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, and BigQuery using Python, Java and Scala. The ideal candidate holds a bachelor's or master's degree in engineering or computer science and has experience in Hadoop, NoSQL databases, SQL querying, Spark, Java and SQL databases.",Bac +4,Entre 250 et 2000 salariés,> 5 ans,0,1,0.013848874720779208
3,72829,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/an-apprentice-12-24-months-data-engineering-m-f_paris,An apprentice 12/24 months – Data Engineering,Sanofi,"{Python,Scala,JavaScript,NoSQL,SQL}",NaN,"54 Rue la Boétie, Paris, 75008",Pharmaceutique / Biotechnologique,CDI,2023-04-22,"At Sanofi, we pursue the miracles of science to improve people’s lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi’s roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Sanofi is dedicated to supporting people through their health challenges. We are a global biopharmaceutical company focused on human health. We prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. We stand by the few who suffer from rare diseases and the millions with long-term chronic conditions. With more than 100,000 people in 100 countries, Sanofi is transforming scientific innovation into healthcare solutions around the globe. Sanofi, Empowering Life In this context, Sanofi is looking for: AN APPRENTICE – DATA ENGINEERING (M/F) Location: Paris (XVIIe) Assignment : Within the Digital Health Department and in connection with your tutor, you will participate in an international project on a high-impact drug. In this context, your missions will consist in: Support connected ecosystem solutions such as patients’ glycemic control and full disease management, leveraging connected pens, Help building symptom checking apps able to understand diseases and track symptoms, Participate in creating remote treatment solutions to provide individual recommendations, accessible by anyone, anytime, anywhere, Support personalized care models, informed by Artificial Intelligence, to identify symptoms’ early signals and recommend corrective actions to the patient and the care giver. Required profile : You are looking for an apprenticeship contract of 12/24 months , starting between September and October 2023 as part of a training of level BAC +4/+5 or equivalent in Computer Science, Engineering with math background. For this position, you justify a first experience or knowledge of programing languages such as Python, Scala and different database systems such as SQL, NoSQL. Knowledge in JavaScript is a plus. Self-starting and self-motivating team player, your rigor and your analytical mind allow you to carry out your missions. Open-minded, you enjoy working in a team and interacting on transversal topics. If you are interested in our mission, send us a CV and cover letter. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.",,Bac +4,N,Non spécifié,0,1,0.013848874720779208
236,11359,https://www.welcometothejungle.com/fr/companies/smart/jobs/data-engineering-manager_paris_SA_DJe9ND0,Data Engineering Manager,Smart AdServer,"{Insider,color,Scala,Kafka,scale,R,Spark,blend,Dataflow,GCP,Java,Hadoop}",NaN,Paris,AdTech / MarTech,CDI,2022-01-25,"Smart est une AdTech française proposant une plateforme de monétisation publicitaire à destination des plus importants sites web dans le monde. Leur objectif ? Disrupter l’industrie de la publicité digitale avec des solutions performantes, des formats innovants et toujours plus de qualité. Basée en plein cœur de Paris (IXᵉ), la société poursuit son développement international avec désormais 12 bureaux dans le monde (ouverture du bureau de Singapour en 2019) et rejoint les classements “Champions de la Croissance” par Les Echos et “Fast 500 EMEA” par Deloitte. Leur fierté ? Une team de plus de 420 Smarties qui s’épanouissent à travers une culture d’entreprise prônant l’ownership et qui vit à travers 4 valeurs essentielles : Care, Innovation, Transparency et Excellence. 👫 About the team At Smart, we’re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic. Our innovation team based in Paris, Krakow and Nantes is composed of 90 straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges. 🤝Your mission At Smart, Data is core. We ingest tens of billions of events daily. This data is then transformed and crunched to be used by our customers and everybody throughout the company (BI analytics, data science ML algorithms, customer reporting, invoicing and more) Our Data Engineering Team is responsible for building a scalable and robust platform that handles log ingestion, data storage and optimization, aggregation and external access through dedicated APIs. You report directly to our CTO and you are responsible for our data stack, as well as designing its future evolutions to make it more reliable, more powerful, more flexible. ✏️ What you'll do Manage the Data Engineering team and hire new talents Promote a strong engineering culture and passion for quality and things well done Drive and design a highly performing and robust data pipeline Define platform KPIs (latency, accuracy, response time, …) and associate them to ambitious objectives Identify data needs and design systems to guarantee the success of new projects Interact with other managers and team leads to guarantee a smooth delivery of our R&D wide projects 👇About you 2+ years successfully managing and leading an engineering team Passion for large scale data ecosystems (several PBs of stored data, billions of events per day) Experience with big data technologies in production (Hadoop, Spark, Kafka, Java, Scala, …) Experience with the GCP stack (Dataflow, Big Query, pub/sub, ...) Enthusiasm to discover and push new technical environments Fluent in English and French Master Degree in a technical field (Engineering, Computer Science, Applied Math) 👋 About us Headquartered in France, Smart employs over 420 employees in 12 countries in Europe, America, and Asia. The company is backed by private equity, led by Capital Croissance through a management buyout operation in 2019. With the recent acquisitions of LiquidM (2019) and DynAdmic (2021), Smart accelerates its growth in three key areas - CTV&OTT, US expansion & Marketer Services. The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies. Smart has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment. Smart works directly with hundreds of buyers and more than 1,000 publishers worldwide including Meredith, Insider, The Guardian, Cafe Media, Groupe Marie Claire, Le Figaro, Altice, and PlutoTV to deliver display, video, native, and rich-media ads to over 50,000 sites and apps. Thanks to its holistic ad monetization platform (Adserver/SSP/Buyer Tools/DSP) , brands can achieve greater efficiency through their advertising spend and publishers can act with certainty and have the control they need to provide the right blend of transaction models, channels, format (Display, Audio, Video, CTV, Mobile) and audience data to deliver true value path optimization to brands. Come and lead the charge with us in building a transparent ecosystem based on quality . ---------------------- Smart AdServer is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@smartadserver.com This content is blocked Youtube cookies are required to show you this content Accept cookies","Smart is an AdTech company based in Paris, with a team of over 420 employees in 12 countries. They are looking for a Data Engineering Manager to lead their data engineering team and manage the development of a scalable and robust data platform. The ideal candidate should have experience managing engineering teams, a passion for large-scale data ecosystems, experience with big data technologies, and be fluent in English and French.",N,N,N,0,1,0.013848874720779208
15,4806,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/analytics-engineer_paris,Analytics Engineer,Dataiku,"{UNIX,Dataiku,regard,PostgreSQL,S3,Snowflake,R,SQL,Python}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Dataiku is looking for an Analytics Engineer to join our fast-growing Product team, who will work on the collection and processing of our product usage data. Your role will be key in supporting the development of our product. Your missions will be run in tight partnership with several Dataiku’s key teams: R&D, Marketing, Operations and Customer... In this role, you will: Define, lead, maintain our data pipeline collecting usage data of our product ( available both as a SaaS and on-premise). Contribute to and leverage our analytics stack (Dataiku Platform, Amazon S3, PostgreSQL, Snowflake, etc...) and build automations for your team. Build a framework and provide recommendations (including for efficiency and performance of the SQL queries) to data analysts from other teams so that they can leverage product usage data. Support the Product team and provide insights or reports around specific product usage questions. Work with Product and Engineering teams to build, maintain, and refine high-level dashboards for specific features or user types. You might be a good fit if you have: Master’s degree or equivalent: engineering school, business school, etc… 2-4 years of experience working with large data sets for analytics Strong knowledge of SQL and relational databases Ability to code in Python Knowledge of basic terminal UNIX commands Ability to synthesise data into a suitable format to drive actionable insights for Product and Customers teams Great attention to details and ability to work independently Enjoy sharing & learning from others About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking an analytics engineer to work on the collection and processing of product usage data, with the aim of supporting the development of the firm's AI platform. The successful candidate will help to define, lead and maintain the data pipeline for both on-premise and SaaS deployments. The role requires experience working with large data sets for analytics, with working knowledge of SQL and relational databases, and coding skills in Python, and shell scripting. Dataiku promotes a culture of diversity, dignity, and fairness as an equal opportunity employer.",Bac +5 / Master,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
14,72983,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineering-geo-engineering-team_paris,Data Engineering - Geo Engineering Team,Groupe SeLoger,"{PostgresQL,Github,Python,Jenkins,Datadog,Grafana,Docker,R,Kubernetes,Airflow,AWS,SQL,ElasticSearch,GCP}",NaN,"7 Boulevard Haussmann, Paris, 75009","Application mobile, IT / Digital, Média",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Français dans la réalisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d’offrir à chacun de nos utilisateurs, une expérience immobilière simple et efficace afin qu’ils concrétisent leurs projets d’achat, de vente ou de location en toute sérénité. Nous mettons à disposition des Français le plus large choix d’annonces afin de leur faciliter la recherche d’un bien selon leurs critères propres, et répondre à toutes les questions soulevées par la réalisation d’un projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque préférée des Français pour se repérer et se lancer dans leur projet immobilier. Le poste Nous recherchons un Data Engineer GEO pour rejoindre l’équipe chargée des relations entre vendeur et agent au sein de l’entité Marketplace du groupe. L'équipe Data Science est chargée de produire et d'exposer les insights les plus pertinents sur le marché du logement (cartes de prix, outils d'estimation, ...) et les analyses data-driven à un large public : particuliers, agents immobiliers, institutions privées et publiques. Au sein de ce pôle, notre équipe Geo Engineering est composée de plusieurs profils ayant une forte expertise en géographie informatique (sources de données géographiques, modélisation vectorielle, géocodage, application web de cartographie…) et des compétences en extraction et traitement de l'information, gestion de bases de données, architecture système et logicielle … Nous travaillons en étroite collaboration avec des doctorants, docteurs en mathématiques, économie, finance et statistique, Machine Learning et Data Engineers. Vos responsabilités Intégrer et consolider les meilleures sources de données géographiques dans des modèles de données spécialisés pour faciliter le développement de nos projets de R&D Exposer des APIs et UIs géographiques (querying, geocoding, mapping, routing, …) à haute disponibilité et forte volumétrie pour assurer le développement de nos plateformes immobilières Renforcer l'équipe Data Science en leur fournissant un environnement de R&D stable Garantir le bon fonctionnement (production, exposition, surveillance) et évolution de nos plateformes immobilières Compétences recherchées A une forte expérience en Python et SQL * Incarne les valeurs d'entraide, bienveillance et quête de l'excellence Est rigoureux, curieux, autonome et constructif A une forte appétence pour et/ou une première expérience en systèmes d'information géographique Outils GCP, AWS Python, Docker, Airflow, PostgresQL, ElasticSearch, Kubernetes Github, Jenkins, ArgoCD, Terraform, Grafana, Datadog Postgis, GDAL, QGIS",,Non spécifié,Entre 250 et 2000 salariés,> 5 ans,0,1,0.013848874720779208
321,56492,https://www.welcometothejungle.com/fr/companies/bpi-france-digital/jobs/data-engineer-core-banking-system-f-h_toute-la-france,Data Engineer Core Banking System  – France entière (Hybride),Bpifrance.io,"{durable,Python,Jenkins,Gitlab,Kubernetes,attentive,AWS,Kafka,Spark,Docker,Datadog,Mongodb,Aws,Postgresql}",NaN,Toute La France,FinTech / InsurTech,CDI,2023-03-26,"Bpifrance, une banque pas comme les autres Bpifrance, Banque publique d'investissement est une banque citoyenne qui accompagne les entreprises, de l'amorçage jusqu'à la cotation en bourse, du crédit aux fonds propres. Si nous sommes une structure historique, organisée et reconnue, nous avons l’esprit agile et rapide et les moyens de notre transformation. Nous sommes LA banque partenaire des entrepreneurs, présente à leurs côtés au cœur de nos 50 implantations. Présents à chaque étape de leur vie ; nous rejoindre c’est œuvrer pour leur compétitivité et une mission d’intérêt générale. Notre ambition ? Devenir une Fintech . Et nous avons besoin des meilleurs ! Nous souhaitons transmuter pour devenir une FINTECH et offrir les meilleurs services digitaux à l’ensemble de nos clients, grâce à des plateformes digitales : plateformes d’octroi de prêt en ligne et la Banque en Ligne Bpifrance (BEL). Le goût du challenge Notre challenge: déployer toutes les solutions Tech d'aujourd'hui, de demain, et ainsi offrir à nos clients des outils adaptés et novateurs, tout en ayant une conscience Green IT afin de servir l'avenir de façon durable. Vos missions au service de l’économie française Nous recherchons un data engineer « pas comme les autres » !​ ​ Rejoignez l’équipe Core Banking System du train Data & IA et contribuez à la transformation Data Centric de BPIFRANCE. Au sein de la plateforme Cloud AWS, vous contribuerez à la construction d’une architecture Data composée de comptoir de données, cœur du SI, et de Micro-Services accélérant la valorisation de la donnée pour nos clients. ​ ​ En plus de cela, vous serez impliqué.e sur :​ ​ Concevoir et développer des pipelines de données des comptoirs de données​ Mettre en place des tests unitaires et d’intégration​ Réaliser des déploiements des flux​ Documenter les flux de données produits​ Assurer le RUN des comptoirs​ Participer à la conception, au refactoring et aux choix techniques en collaboration avec le Techlead​ Participer aux développement des bonnes pratiques DevSecOps pour améliorer la fiabilité et la fréquence des déploiements​ Participer à toutes les cérémonies de l’agilité à l’échelle de l’entreprise (SAFe)​ ​ Vous serez en interaction avec les architectes, Tech Leads et Data Designer du train. Votre environnement technique sera le suivant : Data : Postgresql, Atlas Mongodb​ Cloud : stack Aws ​ Langages / Frameworks : Python, Spark, openApi, API Gateway​ Architecture : Microservices, API (REST), Évènementiel (Kafka, Kstream)​ DevSecOps : Gitlab, Gitlab CI, Docker, Kubernetes, Jenkins, Maven, Tanzu, Ansible, Terraform, Shifleft​ Testing : Cucumber, Postman, Gherkin, Selenium​ Observability : Datadog, ELK ​ ​ Prêts à rejoindre notre équipe ? Vous avez un background de data engineer talentueux et passionné, doté d’un diplôme supérieur en informatique. Vous avez une expérience professionnelle dans des environnement bancaires à forts enjeux sur des projets ambitieux. Vos compétences en développement ajouté à votre appétence pour les environnements DATA, font de vous un profil avec un fort potentiel.​ ​ Vous avez déjà travaillé dans des environnements AGILE et en Feature team démontrant votre capacité à travailler dans des contextes challengeant.​ ​ Vous souhaitez continuer de développer et d’améliorer sans cesse les services et pratiques pour améliorer la qualité et accélérer le delivery.​ Les + du poste : Des challenges tech à relever et des événements tech futuristes auxquels vous serez acteur.trice et convié.e Vivre au rythme d’une culture Tech affirmée au cœur d’une équipe soudée Vibrer au son d’un podcast hebdo Assister à des Town Hall (événements virtuels & soirées) trimestriels Poste ouvert sur toute la France, à la condition d’être situé à moins de 3h de TGV de Paris (exemple : Nantes, Lyon, Lille, Montpellier..) Les bonnes raisons de rejoindre l’aventure Bpifrance ! Un travail avec du sens : Vous contribuerez à une mission unique d’utilité publique au service de l’économie française et au sein d’une banque engagée sur des sujets de société (climat, jeunesse, égalité des chances…). Un environnement dans lequel il fait bon vivre : Vous intégrerez des équipes dynamiques et bienveillantes, au sein d’une entreprise attentive à la Qualité de Vie au Travail de ses collaborateurs. Nos certifications Happy Trainees et Meilleurs Employeurs France par Glassdoor en témoignent ! Des conditions avantageuses : Vous bénéficierez des nombreux avantages qu’offre le groupe pour ses collaborateurs : télétravail, congés payés supérieurs au minimum légal, épargne salariale attractive, CSE, dispositifs de Qualité de Vie au Travail… Un tremplin pour votre carrière : Vous profiterez des meilleures conditions mises en place chez Bpifrance pour développer vos compétences et construire votre parcours de carrière, grâce à un accompagnement sur-mesure et des parcours de formation complets et personnalisés. Travailler chez Bpifrance, c’est intégrer une banque pas comme les autres, un projet d’entreprise ambitieux et tourné vers l’avenir. C’est plus qu’un métier : c’est une mission, une équipe, un réseau et un écosystème. Pour découvrir nos autres opportunités et tout savoir de la vie au sein du groupe, rendez-vous sur notre site carrière ! Bpifrance est une banque citoyenne dotée d’un code de déontologie et d’une politique anti-corruption. Avant de postuler, nous vous invitons à consulter notre politique relative à la gestion des données à caractère personnel disponible sur notre site.","Bpifrance, a public investment bank, is seeking a talented and passionate data engineer to contribute to its data-centric transformation. The ideal candidate should have experience working with Python, Spark, Postgresql, and MongoDB, as well as proficiency in DevSecOps tools like Docker, Jenkins, and GitLab CI. The successful candidate will work on developing robust data pipelines, implementing testing and integration protocols, deploying data flows, documenting the data produced, and improving the reliability and frequency of deployments. The role is open to candidates across France.",Bac +5 / Master,Entre 250 et 2000 salariés,> 5 ans,0,1,0.013848874720779208
161,49889,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-reunion-island-or-remote-europe_paris,Software Engineer Data Visualization - Reunion Island or Remote Europe,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",NaN,Reunion Island,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend).- Prototype and create new ways to import and request data at large scale.- Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions.- Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best.- Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with experience in software development and an interest in data visualization tools. The ideal candidate should have experience building a real product, be comfortable with both front-end and back-end development, and have an eye for design. The role involves building components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way, prototyping and creating new ways to import and request data at large scale, and brainstorming new features with product managers and UX designers. Dataiku is committed to providing a rewarding, enjoyable, and diverse work experience for all employees.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
158,56968,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-flow-engineering-manager-f-m-d_croix,Data Flow Engineering Manager,Decathlon Digital,"{durable,Kafka,IBM,SAP}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES DATA EXCHANGE DE DECATHLON Les équipes Data Exchange de Decathlon ont pour mission d'être garante de la création et du bon fonctionnement des échanges de données sur l'intégralité du SI Monde (e-commerce, retail, logistique, supply., finance, RH..) au travers des technologies Webmethods, SAP PO, MQ et Kafka. REJOINS L'ÉQUIPE DATA IN MOTION L'équipe Data In Motion est responsable des technologies de messaging (Webmethods, SAP PO, IBM MQ) et accompagne la transformation digitale en permettant au SI de communiquer environ 84 millions de flux qui circulent par mois, grâce au travail de l’équipe. Dans le cadre de la croissance de l'équipe, celle ci créé deux postes de Team Leaders qui se répartirons le périmètre technologique suivant : 1. Webmethods et SAP PO : 8 collaborateurs internes Webmethods : 552 Flows (178 critiques)24 M de messages par mois250 partenaires B2B SAP PO : 116 Flows (10 Critiques)30 M de messages par mois 2. IBM MQ, IBM ITX, AS400 : 5 collaborateurs internes 277 Flows (36 critiques)30 M de messages par mois Les deux postes en CDI de Data Flow Engineering Managers (un remplacement suite à une mobilité interne, et une création de poste) sont basé-e à Lille. TES RESPONSABILITES Ton challenge consiste a assurer la responsabilité du pilotage de la fin de la technologie IBM MQ au profit de nouvelles technologies Co-écrire un projet ambitieux, cohérent et aligné avec le domaine ainsi qu'avec la stratégie Groupe ; Leader une culture d'ingénierie saine et collaborative conforme aux valeurs de l'entreprise ; Developper les compétences des coéquipiers de ton équipe, les inspirer et développer leur talent ; Assurer l'animation régulière de proximité du collectif dans le réalisation de leur mission et du projet ; Développer l'efficience de tes équipes et mettre en place les bonnes pratiques ; Animer l’équipe en s’adaptant à la diversité des problématiques rencontrées et en s’engageant sur les résultats ; Assurer la performance durable de ton activité et le respect de tes engagements. CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as une expérience d'au moins 2 ans en management directe d'une équipe technique (forte autonomie de l'équipe) ; Ton style managérial est particulièrement orienté sur la collaboration et l'empowerment de l'équipe ; Tu as une bonne culture technique et une appétence pour la data - sans être un expert de telle ou telle technologie - tu recherches l’impact sur une stratégie technique et porter une vision et partager tes points de vue avec tes coéquipier-e-s (co-construction) ; Tu as une expérience dans la gestion, l’encadrement et le mentorat en vue de fournir avec eux des solutions de haute qualité Tu as envie de rejoindre une entreprise à impact positif Le plus de ta candidature : ton parcours t'a permis d'avoir une expérience dans les échanges de données chez un retailer, un équipementier ou une ESN (projet forfait exclusivement). CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien","Decathlon is seeking two Data Flow Engineering Managers to lead and develop their Data in Motion team responsible for ensuring the successful operation of Webmethods, SAP PO, IBM MQ and other technologies which help to process up to 84 million flows, as part of the Decathlon worldwide SI. Responsibilities include: overseeing IBM MQ technology’s termination, collaborating on ambitious projects, leading with a healthy engineering culture, developing team members' skills and making sure their collective efforts align with project completion goals. Candidates should have at least 2 years of direct technical team management experience, an interest in data and technical expertise. Decathlon offers a diverse work culture, two days of telecommuting per week, and the opportunity to work with an impact-driven company in a collaborative and empowering work environment.",Non spécifié,> 2000 salariés,> 2 ans,0,1,0.013848874720779208
145,2272,https://www.welcometothejungle.com/fr/companies/softbank-robotics-europe/jobs/ingenieur-data-f-h_paris,Ingénieur data,SoftBank Robotics Europe,"{GIT,Mapreduce,Python,Jenkins,EMR,Scala,Shell,Redshift,Glue,AWS,Hadoop,Linux,Spark,Java,SQL,Jupyter,EC2,Tableau}",NaN,Paris,"Objets connectés, Robotique",CDI,2021-12-27,"SoftBank Robotics Europe (SBRE) conçoit des robots interactifs et bienveillants. Filiale du groupe mondial SoftBank et leader en robotique humanoïde, SoftBank Robotics Europe est basée à Paris et emploie 350 personnes. Créatrice des robots NAO & Pepper, aujourd’hui utilisés dans plus de 70 pays, dans des domaines aussi divers que la recherche, l’éducation, la distribution, la banque, le tourisme, la santé ou le divertissement, SoftBank Robotics Europe a pour objectif de rendre leurs robots accessibles à tous pour qu’ils deviennent des compagnons du quotidien. NAO est le premier robot de l’aventure, un vrai précurseur qui a conquis le monde académique. Pepper, quant à lui, est déjà le nouveau compagnon des familles japonaises et un nouvel outil pour aider à accueillir et informer les visiteurs dans de nombreuses entreprises. En tant qu'Ingénieur Data au service Cloud OSS, vos tâches principales seront les suivantes : - Connaître les besoins en termes d'outils à développer - Concevoir la méthode optimale pour développer les outils - Agréger et stocker de grandes quantités de données dans des bases de données - Développer des outils de visualisation de données et analyser les KPI - Connaître les besoins en termes d'analyses prédictives - Concevoir la méthode optimale pour faire les analyses - Développer, tester, sélectionner et mettre en production des algorithmes qui permettent de répondre aux besoins - Connaître les besoins en termes d'intégration des systèmes d'information - Développer des outils qui unifient les différentes sources de systèmes d'information Requirements Compétences techniques demandées : - Maîtrise de la manipulation de grandes bases de données IOT (Internet Of Things) pour la flotte mondiale des robots et de diverses sources de données (Spark, Hadoop, No SQL, Streaming, Mapreduce) - Maîtrise d'outils d'analyse de données : Jupyter, Jupyter Hub - Maîtrise des frameworks des machines learning / deep learning : Tensor flow, Scikit-learn - Bonnes connaissances du développement Cloud (AWS, EMR, EC2, Glue, Redshift, RDS…) - Expérience du système GIT, Jenkins, Terraform, Ansible - Maîtrise des langages : Python, Linux, SQL, Shell scripting ; en plus : Scala, Java - Un plus : connaissance des outils de visualisation (Tableau, AWS Quicksight) Compétences relationnelles : - Savoir communiquer et se faire entendre Autres compétences requises : - Maîtrise de l'anglais ou du japonais professionnel ; Maîtrise du chinois appréciée - Sens des priorités, rigueur Ce contenu est bloqué Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","SoftBank Robotics Europe is seeking an Engineer with expertise in data manipulation, analysis, and cloud development to develop tools for its fleet of robots. The ideal candidate should have experience in managing large datasets and knowledge of IoT technology, tools for data analysis, machine learning frameworks, and cloud development. Strong communication skills and proficiency in Python, Linux, SQL, and Shell scripting are needed, along with fluency in English or Japanese.",N,N,N,0,1,0.013848874720779208
9,2299,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-london_london,Software engineer Data Presentation - London,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",NaN,London,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku’s culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking a talented software engineer with experience in software development and an interest in data visualization tools to create usable, intuitive, and beautiful interfaces and scalable engines for Dataiku DSS. The candidate must be customer-oriented, proficient in both frontend and backend development, and have firsthand experience building a real product. They will work closely with product managers and UX designers to brainstorm new features and iteratively refine solutions. Dataiku offers a flexible work-life balance, trusting its people to do their best and stay away from artificial deadlines. The company is committed to ensuring that each employee has the most rewarding, enjoyable, and memorable work experience.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
382,34233,https://www.welcometothejungle.com/fr/companies/deliveroo/jobs/analytics-engineer-data-engineer_paris,"Analytics Engineer, Data Engineer",Deliveroo,"{parquet,ElasticSearch,Ruby,Go,Scala,Looker,Kubernetes,AWS,Snowflake,Lambda,Kafka,via,Spark,instrumental,Docker,Python,EC2}",NaN,Hyderabad,"Application mobile, E-commerce, FoodTech",CDI,2022-08-08,"Lorsque Will Shu, le CEO et fondateur de Deliveroo, a déménagé à Londres en 2013, il a découvert une ville foisonnant de très bons restaurants. Mais à sa grande surprise, peu d’entre eux proposaient de livrer leurs plats. Dès lors, il s’est donné pour mission de faire venir la cuisine des meilleures pépites de quartier directement chez les gens. En offrant aux restaurateurs un canal de vente supplémentaire, et l’opportunité de faire progresser leur chiffre d’affaires, Deliveroo joue un rôle économique majeur au sein de l’écosystème de la restauration en France. Aujourd’hui, Deliveroo collabore avec 160 000 restaurants et 180 000 livreurs sur 11 marchés géographiques, afin de proposer la meilleure expérience de livraison de repas et de courses d’épicerie au monde. Deliveroo est présent sur 11 marchés : Australie, Belgique, Emirats arabes unis, Espagne, France, Hong Kong, Irlande, Italie, Koweït, Pays-Bas, Royaume-Uni, Singapour. Présent en France, son deuxième marché mondial, depuis 2015, Deliveroo travaille aujourd’hui avec plus de 26 000 restaurants et commerces partenaires, et offre une opportunité d’activité flexible et bien rémunérée à 22 000 livreurs partenaires qui nous font confiance. Deliveroo continue depuis ses débuts de grandir géographiquement et d’innover : développement d’une offre d’épicerie, créations de sites Editions dédiés à la livraison de plats par de grandes marques exclusives, services technologiques innovants pour les restaurateurs, etc The Analytics & Data Engineering team enables Deliveroo to be data driven in how we build products and make decisions. We are responsible for ensuring the completeness, accuracy, and timeliness of key data sets across all three sides of our marketplace: riders, restaurants, and consumers. We help ensure that the right data is generated at source as we innovate in our products. Our team builds (and maintains) tools and develops solutions to ingest, transform and surface data for teams across the company and other disciplines in Tech to consume, including partnering closely with data science and machine learning engineering. We both own pipelines and processes where the use-case is primarily of an analytical nature (i.e. human decisions) and producing data sets that power algorithms like dispatching orders to riders. We set the strategy for providing reliable, timely robust business-critical data to these teams via our Kafka message bus, Snowflake data warehouse, and our BI tool Looker. We utilise a variety of data-focused products to build scalable solutions. You could be a good fit for our team if you are comfortable working with unfamiliar codebases, internal, open source or third party. If you have a desire to deeply understand how how a business works and to play an instrumental role in positively affecting the company trajectory, Deliveroo may be the right place for you. Our skills We need skilled software engineers who enjoy solving infrastructure and data problems with code. We don't expect you to meet all of the below but would love you to have experience in some of these areas. Pride in readable, well-designed, well-tested software 5+ years of experience with various data technologies, in particular analytics, aggregation, search and streaming technologies such as Spark, ElasticSearch and MPP data warehouses. Experience with operating systems, configuration management and ""Infrastructure as Code"". (We use AMIs, Docker Images, Terraform and Kubernetes). Experience with data lake design, and working with different file formats found within lakes (parquet, csv, json etc.) Most of our coding currently happens in Python, but we have some applications also written in Scala. Experience in data engineering type roles that involve partnering with others in the product/application space to ensure that data is treated like a 1st class citizen from the outset of product development. Professional experience writing infrastructure services and applications in any language, and a willingness to quickly get up to speed on the wider Deliveroo engineering stack (Ruby/Rails, Go and, Python). Experience with VMs, containers and serverless compute platforms. (We use AWS for compute, e.g. EC2, ECS and Lambda). Life at Deliveroo We are a growing team, with very large impact, seeking to answer some of the most interesting questions out there. We move fast, we’re always looking for new ideas and we’re very transparent about the decisions we make and why we make them. There are so many questions we need to answer and plenty more we haven’t even encountered. How do data and technology help restaurants to grow as consumer habits change? How can we predict what someone wants to order for dinner long before the idea has even crossed their mind? At Deliveroo these are just some of the tough problems we are solving - and there is no challenge that cannot be yours. No solution is owned by a particular team, which means the scope for growth and personal impact is enormous.","Deliveroo is seeking skilled software engineers with experience in data technologies, infrastructure, and strong coding abilities to join its Analytics & Data Engineering team. The team is responsible for ensuring data completeness, accuracy, and timeliness across all three sides of the marketplace and builds tools and solutions to ingest, transform, and surface data for teams across the company. Deliveroo is a fast-moving company seeking to solve tough problems in the food delivery industry, and engineers in this role will have a significant impact on the company's trajectory.",Non spécifié,Entre 250 et 2000 salariés,> 5 ans,0,1,0.013848874720779208
427,49577,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_kglgqWo,Data Engineer,FACILECOMM (SHIPPINGBO),"{Redis,MongoDB,Pandas,PostgreSQL,Redshift,Airflow,AWS,R,SQL}",NaN,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-02-07,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait mené(e) jusqu’à cette annonce ! Peut-être est-ce toi, le/la futur(e) Data Engineer que nous attendons… En tout cas, nous l’espérons. Dans un premier temps, permets nous de nous présenter. Qui est Shippingbo ? La première chose que tu dois te demander c’est “qui est Shippingbo” et c’est une très bonne question ! Shippingbo est une technologie logistique e-commerce fondée en 2016, par la société facilecomm. Nous mettons à disposition des vendeurs en ligne une technologie qui leur permet d’optimiser toute leur chaîne logistique : depuis la récupération des commandes, jusqu’à leur expédition, en passant par la préparation. Pour la faire très simple, on est la technologie de l’ombre qui permet à ton site favori de te livrer dans les meilleurs délais, tout en te notifiant de l’avancée de ta commande. Pas mal, non ? Notre ambition : permettre à nos clients de proposer aux consommateurs un parcours d’achat au top, digne des géants du e-commerce ! Aujourd’hui, nous comptons pas moins de 1000 clients aux activités e-commerce assez variées : e-commerçants, retailers, fournisseurs, grossistes…. mais dont le point commun reste la vente en ligne ! Avec près de 72% de croissance en 2021 et plus d’1 milliard d’euros de GMV, nous sommes bien décidés à poursuivre sur cette lancée pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage européen d’ici 3 ans ! Shippingbo cherche aujourd’hui à développer les outils d’analyse qu’elle met à disposition de ses clients ainsi qu’à développer de nouvelles fonctionnalités se fondant sur l’analyse des données. En tant que data engineer, votre rôle sera de construire et maintenir les entrepôts et pipelines de données. Vos missions principales consisteront à : Participer à la définition des schémas de données et aux choix d’architecture ; Définir et optimiser les requêtes faîtes par l’API et celles au cœur des pipelines ; Préparer des datasets exploitables à des fins d’analyse ; Identifier de facon plus générale les moyens optimaux de répondre à l’ensemble des requêtes de données ; Optimiser également le fonctionnement des pipelines et maintenir les systèmes surveillant leur bon fonctionnement et la qualité des données ; Participer à l’administration, la configuration et le paramétrage des bases de données. - Vous avez au moins 2 ans d’expérience comme data engineer (ou des rôles similaires) et dans la construction et la maintenance de pipelines de données ; - Vous avez une connaissance approfondie de SQL , de l’optimisation de requêtes et des entrepôts de données ; - Vous avez une expérience avec au moins une base de donnée orientée colonnes ; - Idéalement vous avez également une expérience avec une base de donnée orientée documents et une base de donnée clé-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en métro, arrêt Ramonville) Rattaché au département R&D de l'entreprise Mise à disposition d’outils informatiques Tickets restaurant >>> Venez découvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversité occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'égalité professionnelle et l'emploi des travailleurs en situation de handicap. A compétences équivalentes, ce poste est ouvert à tous.","Shippingbo is looking for a Data Engineer to develop and maintain data warehouses and pipelines, support the definition of data schemas and architecture, optimize queries, prepare datasets, and administer and configure databases. The ideal candidate should have at least 2 years of experience in data engineering, a deep understanding of SQL and data warehousing, and experience with column-oriented, document-oriented, and key-value databases. Shippingbo offers a permanent contract, based in Toulouse, and a range of benefits including IT tools and restaurant tickets.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,0,1,0.013848874720779208
126,57142,https://www.welcometothejungle.com/fr/companies/aldebaran/jobs/data-engineer-f-h_paris,Data engineer,Aldebaran - a part of United Robotics Group,"{Kinesis,Glue,AWS,lambda,S3,R,Python}",NaN,"43 rue du Colonel Pierre Avia , Paris, 75015","Objets connectés, Robotique",Autres,2023-03-26,"Aldebaran, anciennement connu sous le nom de SoftBank Robotics Europe, est le leader de la robotique humanoïde, fabricant des robots emblématiques NAO et Pepper. Depuis sa création en 2005, nous sommes devenus le leader du marché des robots humanoïdes. Plus de 40 000 robots sociaux et d’interaction - NAO et Pepper - sont utilisés dans plus de 70 pays, dans divers secteurs, allant du commerce de détail au tourisme, en passant par la santé et l’éducation. Après avoir développé et commercialisé les robots humanoïdes NAO et Pepper, Aldebaran développe désormais une nouvelle génération de robots de services. Ces développements mobilisent de nombreux métiers (électronique, mécanique, logiciel) au sein de la R&D. En 2022, Aldebaran a uni ses forces à celles du groupe allemand United Robotics. Aldebaran emploie actuellement plus de 180 personnes dans ses bureaux de Paris, son siège social, et de Suzhou. Aldebaran, anciennement connu sous le nom de SoftBank Robotics Europe, est le leader de la robotique humanoïde, fabricant des robots emblématiques NAO et Pepper. Depuis sa création en 2005, nous sommes devenus le leader du marché des robots humanoïdes. Plus de 40 000 robots sociaux et d'interaction - NAO et Pepper - sont utilisés dans plus de 70 pays, dans divers secteurs, allant du commerce de détail au tourisme, en passant par la santé et l'éducation. Après avoir développé et commercialisé les robots humanoïdes NAO et Pepper, Aldebaran développe désormais une nouvelle génération de robots de services. Ces développements mobilisent de nombreux métiers (électronique, mécanique, logiciel) au sein de la R&D. En 2022, Aldebaran a uni ses forces à celles du groupe allemand United Robotics. Aldebaran emploie actuellement près de 180 personnes dans ses bureaux de Paris, son siège social, et de Suzhou. Au sein de l’équipe Cloud, le data engineer intégrera une équipe DATA responsable du développement des produits destiné au collecte, process et exploitation des données robot. L’objet de ce rôle consiste à définir et à implémenter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui gèrent les robots du groupe. Le data engineer aura pour rôle de: ● évaluer les choix d’architectures et de solution technique lors de mise en place de PoC ● concevoir et développer des services Data en respectant la spécification fonctionnelle et la méthodologie agile ● agréger et stocker de grandes quantités de données, Mise en place de solutions pour le data processing ● intégrer/Développer des outils de visualisation de données et analyser les KPI ● développer, tester, sélectionner et mettre en production des algorithmes qui permettent de répondre aux besoins ● réaliser des analyses de données ● la mise en place de tests de charge et fonctionnelles pour les solutions Data ● investiguer et corriger les bugs remontés par les utilisateurs ● contribuer à la mise en place de l’infrastructure et outil de déploiement (CI/CD) Requirements Pour la bonne exécution de ces fonctions, au moins 6 ans en tant que développeur sur des projets data en Cloud en Python et avec comme Cloud provider AWS. Les compétences technique suivantes seront requises: ● Une bonne compréhension des technologies d’infrastructure et de déploiement. Une certification AWS sera appréciée. ● Compétence technique sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS ● Une bonne compréhension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels. ● Une bonne connaissance et une expérience pratique de Scrum\Scrumban et des méthodes agiles est nécessaire. ● Une bonne maîtrise du français et de l’anglais (lu, écrit, parlé) est indispensable. ● Des expériences dans des environnements fortement internationaux sont un plus. Benefits Nos principaux avantages : Une culture du bien-être en entreprise qui a fait ses preuves (happy events, budget célébration et convivialité par équipes et directions, séminaires d'entreprise, restauration collective de qualité, environnement de travail agréable...) Un engagement fort en matière de responsabilité sociale (promotion de l'égalité professionnelle, création d'ERG, performance de notre plan diversité et inclusion, référent handicap) Une forte culture du télétravail encadrée de manière appropriée ! Tous nos postes sont ouverts aux personnes en situation de handicap.","Aldebaran, a leading humanoid robotics manufacturer, is seeking a data engineer with at least 6 years of experience in Python and AWS. The role involves designing and developing data services, aggregating and storing large amounts of data, and analyzing KPIs. A good understanding of infrastructure and deployment technologies, AWS services, and Scrum/Scrumban methodologies is required. The company offers a strong corporate culture of well-being, social responsibility, and telecommuting. The position is open to people with disabilities.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,0,1,0.013848874720779208
262,56730,https://www.welcometothejungle.com/fr/companies/enea-consulting/jobs/data-science-and-software-engineer-manager,Data Science and Software Engineer Manager,Blunomy (formerly Enea Consulting),"{GCP,Azure,go,Dask,AWS,R,Spark,Git,Python}",NaN,Melbourne,"Environnement / Développement durable, Stratégie, Energie",CDI,2023-03-26,"Let’s get right to the point: we believe the best is yet to come, if we put everything we have into inventing new rules for a new economy. We want to play a role in creating these innovative rules and tools, beginning with new ways to define what success is. So, who are we? We’re the Blunomists: a unique breed of highly experienced business explorers and experts who provide the multidisciplinary skills that are so often fragmented today. We believe breaking silos is the only way to move towards a regenerative society that’s decarbonized, circular and inclusive. 🌎 We are action-oriented and offer more than a consulting-only business model: we don’t shy away from complexity, we work hand-in-hand with our clients and partners in the long term and we share the risks when it comes to success. From strategic advice to industrial partnerships and innovative data solutions, we strive to provide end-to-end transformations. We’re never happier than when we’re pushing boundaries: • Accelerating the go-to-market rate for promising and innovative technologies • Transforming existing infrastructure into low-carbon and resilient infrastructure • Switching from linear and global supply chains to multiple, circular, local, ethical and largely bio- sourced supply chains, while ensuring social cohesion • Optimizing land use to respond to growing needs for food and housing, recreate biodiversity, produce bioenergy and capture carbon • Ensuring that this period of increased attention on the environment creates a reduction in inequalities, with a particular focus on the development of essential infrastructure around the world These are the transition bottlenecks that get us up in the morning. 🌅 Although we’ve already got plenty of incredible projects to work on, we’re a growing organization. So, stay tuned in the coming months to find out more about us, and until then, feel free to send us your application! Blunomy is the result of a perfect match between Isabelle Kocher de Leyritz, former CEO of ENGIE and internationally renowned business leader, and Enea Consulting, a pioneering strategy consulting firm specializing in the energy transition. Sharing a common goal of bringing about a positive economy, they decided to join forces to contribute to make change happen. Blunomy was founded by Isabelle Kocher de Leyritz in 2022. ENEA Consulting brought 100% of its shares in the adventure, to build a common future in a truly unique company. Blunomy is fully owned by Blunomy Manco, a company composed of Blunomy’s managers. Blunomy is an international strategy consulting firm, dedicated to accelerating the move towards a regenerative society that is decarbonised, circular and inclusive. We do this by partnering with those in the energy supply chain, as well as financial institutions, business and entrepreneurs to ensure the transition of their resources from brown to green. We have been operating since 2007, previously trading as Enea Consulting, and continue to expand our international team of Blunomists. Our high performing, multidisciplinary team are based across 6 offices: Melbourne, Sydney, Paris, Singapore, Hong Kong and London. We come from a wide variety of backgrounds and experiences, are open minded and focused on the future, united by shared values and are passionate about sustainable development and energy access. We are looking for a passionate, engaging and ambitious Data Science and Software Engineering Manager to join our team in either Melbourne or Sydney. We invite all of those who want to break the mould to join us to get change done! About the role: Data analytics in the energy and climate space is growing at an incredible rate. Blunomy provides data-based solutions to support the energy industry, financial institutions and supply chains through their digitisation, decentralisation and decarbonisation transitions. Our tools support improved energy market operability, automation and planning. We are also developing digital solutions that better measure impact and transition speed, to help decarbonise financial resources. We are looking for someone who is passionate about energy, climate change and data analytics to do-well-and-do-good by delivering data science products to crack transition challenges. As a Manager , you will be responsible for: managing the end-to-end delivery of the project engaging and communicating with the client anticipating and managing project risks, timelines, and budget code quality (PR review) managing and leading analysts and senior analysts In this setting, you will be exposed to the diversity of current energy challenges, leveraging your data and analytical skills to address them. We are always growing the products we deliver but over the last 12 months we have delivered: Load forecasting: model and predict the evolution of the load on the electrical network. Use machine learning, data analytics and a fair amount of software development to forecast long-term energy consumption, daily energy profiles and Distributed Energy Resources (Electric Vehicles, Battery, Solar PV). PV connections approval tool: dynamically model the energy network bringing together power flow modelling and machine learning to determine the PV hosting capacity of the local area. Used in production to approve hundreds of PV connection requests a day. Vegetation management using LiDAR: collect three dimensional images of the local network gathered by drone or helicopter. Use machine learning and geometric models to detect and manage vegetation near powerlines. Bushfire risk modelling: model and compute the network‑related bushfire risk based on fault ignition likelihood. Calculate the consequences of bushfires such as property damage or agricultural loss. Low-Voltage network mapping: identify errors within the current mapping of the low-voltage network, especially targeting customers whom connection to the network has not been properly recorded. This was performed using outlier detection with out-of-bag predictors. Depending on the objectives, projects will entail tasks of varying nature. Your first focus will be on projects requiring data analytics capabilities. We are looking for a motivated, experienced and passionate person to join our growing team. The right person will have some of the following, and a willingness and ability to learn the rest. An undergraduate degree or a postgraduate in a relevant discipline such Computing Science, Statistics, Mathematics or Engineering. 5+ years’ experience on data science projects and at least 2 years’ experience in managing projects and staff. A background in data science or software development. Some experience or a passion for energy, environment and/or sustainable development. Knowledge of statistical and machine learning concepts and algorithms. Experience with the data science tool kit: Python or R Source control (such as Git) software engineering and app development skills Knowledge of cloud computing (such as Azure, GCP, AWS) Parallel computing (such as Spark or Dask) is a plus. Consultant tool kit: Good oral and written communication Client engagement skills An ability to work to project timelines. Fluent in English To be eligible to apply for this position, candidates must be either an Australian citizen or have full working rights in Australia. Location: Melbourne or Sydney CBD Salary: Depending on experience Work type: Full Time, starting ASAP","Blunomy, an international strategy consulting firm dedicated to accelerating the transition towards a regenerative society, is looking for a Data Science and Software Engineering Manager for their Melbourne or Sydney office. The role involves managing end-to-end delivery of projects, engaging with clients, and leading a team of analysts and senior analysts. The ideal candidate should have 5+ years of experience in data science projects, at least 2 years of experience in managing projects and staff, background in data science or software development, and a passion for energy, environment, and/or sustainable development. Fluency in English and working rights in Australia are necessary for eligibility.",Non spécifié,Entre 50 et 250 salariés,Non spécifié,0,1,0.013848874720779208
409,36973,https://www.welcometothejungle.com/fr/companies/kiwi/jobs/analytics-engineer_bratislava_KIWIC_9KkWRA8,Analytics Engineer,Kiwi.com,"{Microsoft,regard,Airflow,Looker,Fivetran,Keboola,Snowflake,scale,Stitch,BigQuery,Azure,SQL,Python,Tableau}",NaN,N,"Logiciels, Tourisme",CDI,2022-10-12,"Kiwi.com is an online travel agency that developed its own algorithm for finding flight tickets. Their mission is to move people from any A to any B anywhere in the world, affordably and conveniently. They are achieving this by creating virtual interlining, by combining flights, trains and buses, in their search. Kiwi.com was founded in 2012 in Brno, the Czech Republic and today they’re called a young scale-up. They even got awarded by Forbes that they are the most successful Czech startup! Today, Kiwi.com is counting more than a thousand employees in their core offices and they have offices in Brno and Prague (the Czech Republic), Bratislava (Slovakia), London (UK) and Barcelona (Spain). As an Analytics Engineer, you will define, prepare, maintain, and document data sets (mainly in form of data models) so that users are able to get actionable insights from the data in a self-service way. You will work with Data Platforms, Business Analysts, and Data Intelligence teams to implement data modeling solutions and help to streamline company information management. Job responsibilities: Elicit business data requirements, identify data sources and required data elements, perform data validation and integration activities. Translate business data needs to specific technical requirements and tasks. Take responsibility for the whole ETL/ELT solution and design new sustainable solutions from the ground up. Oversee the data warehouse, source system tables, and transformations necessary for intelligent reporting, thus ensuring that business users have access to reliable data which are essential to make informed decisions. Work in conjunction with Data Engineering to build scalable and manageable data intelligence solutions. Diagnose data quality issues using formal problem-solving techniques and probe underlying issues to generate potential solutions. Make recommendations and guide corrective and/or preventive actions. Write and document the results of your work to make them easily understandable to other colleagues. We would love to see you apply, if You: Have at least 2 years of relevant experience in the area of business intelligence, data analytics, or data engineering. Have a solid understanding of data integration tools, ETL/ELT processes, data modeling concepts, and data warehouse architecture. Are familiar with data pipeline orchestration tools such as Airflow, Fivetran, Keboola, or Stitch. Have experience with DWH platforms like BigQuery, Snowflake, Azure Data Warehouse, or MS SQL Server. Have a good knowledge of database principles, strong proficiency in SQL and programming languages (like Python) used for data manipulation and data analysis. Have an inquisitive, analytical problem-solving mindset. Have experience with BI tools like Looker, Tableau, or similar is welcomed. Are Fluent English (C1 level). We offer you We give our employees a freedom to choose between the environment of work from home and our modern office located in Zuckermandel where you can enjoy sleeping spots, chillout zones, free refreshments, parking for car/bicycle/motorbike. We also enjoy benefits, such as meal vouchers, 25 days vacation, sick days, Multisport card, Employee Assistance Program. Flight vouchers to celebrate your kiwi anniversaries. Hardware from Apple or Microsoft based on your preferences. Relocation package (including visa transfer support). We offer unlimited contracts within a forward-thinking and ambitious company. Dogs, kids, and parties are welcome in our offices. The salary is starting at 2200 Euro (depending on seniority). Interested? Join us and hack the traditional ways of travel! Kiwi.com is proud to be an equal opportunity workplace and employer. We review applications for employment without regard to their race, colour, religion, sex, sexual orientation, gender identity, national origin, ancestry, citizenship, age, uniformed services, genetic information, physical or mental disability, medical condition, marital status, or any other basis prohibited by law. Throughout the recruitment process and for some time after it’s finished, we’re going to process your Personal Data. You can find all the necessary information in our Privacy Policy available at: https://jobs.kiwi.com/recruitment-privacy-policy/ .#LI-BS1","Kiwi.com is seeking an Analytics Engineer to prepare, maintain, and document data sets for users to access actionable insights in a self-service way. The successful candidate should have at least two years of relevant experience in business intelligence or data engineering, a solid understanding of data integration tools and warehouse architecture, proficiency in SQL and programming languages, and knowledge of database principles. Kiwi.com offers a flexible working environment, benefits, and a competitive salary starting at €2200, depending on seniority.",N,N,N,0,1,0.013848874720779208
54,62974,https://www.welcometothejungle.com/fr/companies/ibanfirst/jobs/data-engineer_dijon_IBANF_ORRXLKb,Data Engineer,iBanFirst,"{MySQL,GIT,Talend,Metabase,DBT,Airflow,Snowflake,R,Java,SQL,Python,Tableau}",NaN,"2b Avenue de Marbotte, Dijon, 21000","FinTech / InsurTech, Finance",CDI,2023-03-31,"iBanFirst is a global financial services provider delivering solutions across banking borders. As an alternative to the traditional bank offer, iBanFirst helps international SMEs to thrive while simplifying their daily operations. To do so, iBanFirst has developed a cutting-edge core banking platform enabling fast, secure and cost-effective multicurrency transactions. Thanks to iBanFirst, financial teams can make and receive payments in over 30 currencies and hedge foreign exchange risks. Founded in Paris in 2013, iBanFirst is a French company headquartered in Belgium. It is regulated as a payment institution, passported throughout the European Union, and serves thousands of customers all over Europe. Member of the SWIFT network and SEPA certified, iBanFirst holds AISP and PISP accreditations under PSD2. The company has raised €46m from Xavier Niel and leading European venture capital funds, such as Elaia and Bpifrance Large Venture, among others. In May 2021, iBanFirst completed a growth equity funding round with Los Angeles-based private equity firm Marlin Equity Partners. Job description The R&D team at iBanFirst provides key features to disrupt the B2B payments and FX solutions market. Our web platform combines a full range of financial products and services with a robust core banking infrastructure. We are looking for a Data Engineer for our Data Engineering team who can help us develop, maintain and push our product to the next level. You will be part of a team with strong collaboration, curiosity is in you DNA and you are ready to proactively share your ideas with us to unlock the potential of a borderless world. This is a hybrid role with at least 50% of time being spent in either our Paris or Dijon offices. What you will do Complete our Data engineer team by bringing rigor and enthusiasm Help maintain and develop our data acquisition and transformation chain enrich our possibility of sharing the resulting indicators understand the needs of the business and the data analyst team and propose robust and innovative solutions to meet them What do you bring? Master SQL language and GIT versioning Have a minimum of 2 years of experience in the use of the Python language and mastery of the associated good practices Be comfortable with APIs to collect and disseminate Be a force of proposal and exchange within the team of data engineers on the maintenance and the evolution of the eco system in place Plus points Have used DBT / Airflow / Snowflake / Terraform before Be comfortable with Java Have Cloud or real-time relative skills Be familiar with the world of Finance Tech stack Python, Talend, DBT for data acquisition and transformation Snowflake, MySQL for data storage Airflow for job scheduling Terraform for configuration management Tableau, Metabase for dataviz What do we offer? Various missions and projects in an innovative and rising start-up in a thriving industry (fintech) A key role and a unique opportunity to shape the future of iBanFirst A professional and international team with a flat hierarchy A nice work environment Who are we? iBanFirst is an international financial services provider offering alternative payment solutions to traditional banking. iBanFirst is a fintech that developed a banking platform to enable international SMEs to carry out fast, secure and fairly priced multi-currency transactions. Thanks to iBanFirst, finance teams can send and receive payments in more than 30 currencies and benefit from personalized support to cover their foreign exchange exposure. Since 2016, iBanFirst has raised 46 million euros and in May 2021, the Californian fund Marlin Equity Partners invested €200M to further accelerate the growth and development of iBanFirst. Joining iBanFirst is a unique opportunity to develop your skills and evolve quickly in an international company that is at the cutting edge of innovation. #LI-CM1 #-LI-Hybrid","iBanFirst seeks a data engineer to join their team in Paris or Dijon to develop, maintain and enhance their data acquisition and transformation processes to enable fast and secure multicurrency transactions with a wide range of financial products and services. Candidates should have a minimum of 2 years of experience in using Python language and API collection, be proficient in SQL and GIT versioning, and have excellent collaboration skills. Knowledge of DBT, Airflow, Snowflake, Terraform, Java, and finance tech is a plus. The company offers a challenging work environment, an innovative fintech field, and a professional international team with a flat hierarchy.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
257,56716,https://www.welcometothejungle.com/fr/companies/thales/jobs/alternance-data-engineer-f-h_paris,Alternance - Data Engineer,Thales,"{Kubeflow,durable,Scala,DVC,Hive,Spark,Git,Hadoop,Python,AirFlow,MLFlow}",NaN,Paris,"Logiciels, Cybersécurité, Aéronautique / Spatiale",Autres,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L’intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Chez Thales, tout commence par l’Intelligence Humaine. C’est pourquoi notre ambition est de vous offrir la meilleure « expérience » possible. Nous nous efforçons de mettre en place les conditions de votre développement, de faciliter votre quotidien, votre équilibre vie personnelle - vie professionnelle, et d’étendre vos perspectives. Un savoir-faire technologique au service de la société. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d’une centaine de disciplines, de l’optique à la physique quantique, du traitement du signal à la connectivité et à l’intelligence artificielle. Rejoindre Thales, c’est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C’est donc être au cœur d’une formidable aventure technique. Une attention portée à l’équilibre des collaborateurs au service de leur réussite. C’est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d’accorder la flexibilité nécessaire à l’équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C’est aussi la possibilité d’évoluer, de changer de fonction ou d’activité, voire de pays. QUI SOMMES-NOUS ? Thales Digital Factory s’inscrit dans le programme de transformation de Thales qui a pour ambition de devenir un acteur incontournable et exemplaire du digital, et ce dans l’ensemble de ses marchés. Notre mission consiste à accélérer la transition numérique du Groupe Thales en s'aventurant dans de nouveaux modes de travail et de décision. Notre stratégie s’articule autour de 6 valeurs : Responsabilisation, Orientée sur la donnée, Centrée sur l’utilisateur, Collaboration, Amélioration continue et Culture de l’échec. Nos bureaux se répartissent de Paris à Singapour en passant par Montréal au cœur d'écosystèmes innovants. Thales Digital Factory se distingue également grâce à son incubateur qui accompagne des start-ups internes et externes, ses plateformes digitales, son centre d’excellence Cloud et le développement de MVP, porteurs d’innovation pour l’offre digitale du Groupe et de nos clients. QUI ETES-VOUS ? Vous êtes étudiant en école d’ingénieur et vous suiviez une spécialisation en Data ? Vous êtes à la recherche d'une alternance pour l'année 2023-2024? Vous avez à minima un BAC+3 ? Vous êtes apte à communiquer et écrire aisément en anglais ? Vous disposez d’une base de connaissances métier sur les éléments suivants : -Les enjeux du métier de la donnée -Le cycle de vie de la donnée (extraction, transformation, traitement) dans un contexte d’exploitation par de la data science. Vous disposez d’une base de connaissances sur les langages et outils suivants : - Python - Scala - Hive -Hadoop -Git ​ Vous disposez également d’un panel de compétences sur : - Les principes MLOps - Spark - Kubeflow -AirFlow -MLFlow -DVC Vous êtes de nature curieuse ? Vous êtes reconnu pour votre autonomie ? Vous souhaitez apprendre ? Vous vous reconnaissez ? Parlons missions ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE Vous occupez un rôle de Data Engineer au sein du Data Studio. L’environnement dans lequel vous allez évoluer : Le Data Studio, embarqué dans la Thales Digital Factory, a pour mission de développer des solutions d’Intelligence Artificielle/de Data Science innovantes pour les marchés de Thales. Cette équipe de deux personnes gère des projets innovants relatifs au traitement d’image, à l’analyse de log, au traitement de textes ou séries temporelles. Le Data Studio est associé à la discipline Data & Algorithme réunissant des experts du métier Data (Data Engineer, Data Architect, Data Scientist, Algoritmicien). Cette communauté se réunit de manière hebdomadaire pour partager des savoirs et pratiques relatifs au métiers de la data et permet de maintenir un niveau permanent sur ce domaine en constante évolution. Les enjeux : Le groupe Thales a mis en place une stratégie de transformation, par le biais de l’exploitation de la donnée. Le Data Studio a pour objectif de concrétiser cette transformation, en accompagnant les différents départements du groupe Thales dans la mise en place et l’industralisation de solutions à base d’IA. Vos missions couvriront : Le support à l’équipe de Data Scientist pour les aspects de Data Engineering - depuis le collecte des données jusqu’à la mise en place de solution industrialisée, mise entre les mains d’utilisateurs. L’industrialisation d’une solution de traitement de données texte (NLP) – à l’état de prototype, cette solution a besoin d’être développée de manière itérative, en fonction des nouveaux cas d’usage qu’elle pourra servir. Cette mission s’effectue dans des environnements technologiques divers, cloud ou on-premise, streaming ou batch et la variété des cas d’usage à traiter garantissent une montée en compétence pratique pendant les temps en entreprise. L’aide à qualification technique des opportunités de l’équipe Data Studio – pour chaque mission potentielle, il s’agira de comprendre les contraintes techniques liées à la demande et valider la faisabilité technique et la valeur associée. Nous sommes toujours en phase ? N'attendez plus, rejoignez-nous! Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.","Thales Digital Factory is seeking a Data Engineer student for an internship for the 2023-2024 academic year. The Data Engineer will work on data engineering aspects from data collection to the industrialization of a text data processing solution. Skills required include a knowledge of data challenges and the data lifecycle, as well as proficiency in Python, Scala, Hive, Hadoop, and Git, and a curiosity to learn and work autonomously.",Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
171,56897,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/dataops-engineer-data-solutions-factory-f-m-d_croix,DataOps Engineer - Data Solutions Factory,Decathlon Digital,"{DynamoDB,PostgreSQL,Hive,Elasticsearch,Datastudio,Kinesis,Talend,Hbase,Kafka,GCS,Linux,Dataflow,NoSQL,BigQuery,Jenkins,Kubernetes,AWS,YARN,Github,Hadoop,Jupyter,Prisma,Sagemaker,EMR,Airflow,Redshift,S3,Druid,Spark,Superset,GCP,Tableau}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. REJOINS L'EQUIPE DATAOPS DE LA DATA SOLUTIONS FACTORY DE DECATHLON L’entité Data de Decathlon coordonne l’ensemble des activités visant à l’accélération et la généralisation de l’usage et la valorisation des données. Au sein de la BU Data, l ’équipe DataOPS innove tous les jours pour répondre au mieux aux besoins de notre data platform . Nos enjeux sont : Une plateforme data entièrement multi-cloud (AWS & GCP) De la haute disponibilité, avec une plateforme résiliente et des technologies innovantes La sécurité au coeur de nos projets Les besoins de nos data scientist, data engineers data analystes, et développeurs traduits en solutions techniques Composée d’une 15aine d’experts, l’équipe DataOPS t’attends pour apporter ta contribution à ce grand enjeu qu’est la Data. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e DataOPS Engineer, basé-e, au choix à Lille ou Paris (si tu es localisé.e hors de la région lilloise, prévoir une déplacement sur Lille à un rythme d'1 journée / par semaine ou 2 jours tous les 15 jours). TES RESPONSABILITES Expert.e dans ton domaine, tu conçois, déploies et maintiens les offres techniques pour l’ensemble des infrastructures de la BU Data, tout en suivant les stratégies techniques de l’entreprise (excellence opérationnelle, full cloud, full automatisation, sécurité). Tu participes et contribues aux stratégies techniques de l’entreprise au sein de la communauté OPS . En tant que référent.e sur les technologies que tu gères, tu partages et fais grandir tes collègues Tu participes au processus de support, en prenant en charge avec l’équipe les demandes, incidents et problèmes en escalade sur ton périmètre d’expertise Tu contribues à la transformation du SI Tu accompagnes les changements stratégiques liés à l’infrastructure Tu aides au recrutement de profils OPS externes, tu les formes et les animes. Le périmètre technique : Un environnement full cloud (AWS-GCP) complètement infra-as-code (Terraform, Ansible) ; Une plateforme Kubernetes, avec full CI/CD (Flux, Jenkins, Github Action…), haute disponibilité, haute sécurité (Prisma,...) ; Une infrastructure d'échange de données, en pleine évolution pour être 100% industrialisable, avec de multiples technologies : Kafka, Talend, Airflow, Kinesis, Dataflow... Une infrastructure DataViz : QlikSense, Superset, Quicksight, Datastudio, Tableau ; De multiples technologies de stockage : S3, Redshift, PostgreSQL, GCS, BigQuery ; Une plateforme Hadoop : EMR, Hive, Spark, YARN, Ranger, Atlas ; Des bases de données NoSQL : Elasticsearch, Druid, DynamoDB, Hbase ; De multiples environnements de développements Data : Github, Jupyter, RStudio, Sagemaker ; Une grande communauté OPS très soudée, qui partage les bonnes pratiques, construit des process communs, etc. CE DONT TU AURAS BESOIN POUR RÉUSSIR Tu as au moins 2 ans en tant qu'OPS sur Linux, conteneurisation, monitoring, CI/CD, automatisation & industrialisation ET en environnement Cloud (AWS fortement apprécié) Tu as une appétence pour la data (Spark, Airflow, Sagemaker, BigQuery), et la gestion de bases de données relationnelles et NoSQL ; Tu aimes évoluer en contexte Agile et tu as envie de travailler dans un environnement international (anglais technique maîtrisé). Tu es f orce de propositions, et aimes le challenge ! Passionné·e de technique et de sécurité, la veille technologique sera une part importante de ton activité ; Rejoindre une entreprise qui rend accessible au plus grand nombre le plaisir et les bienfaits du sport fait sens pour toi et tu as envie de partager tes passions en équipe ! Tu as envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Possibilité de travailler au choix dans l’un des bureaux de Decathlon Technology à Lille, Paris, Nantes ou Lyon (prévoir un déplacement régulier sur Lille, à un rythme de 2 ou 3 jours tous les 15 jours ) Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a DataOPS Engineer to join their Data Solutions Factory team in Lille or Paris. The successful candidate will be responsible for designing, deploying, and maintaining technical offerings for data infrastructure, contributing to technical strategy, and providing support while participating in infrastructure changes. The ideal candidate will have at least two years of experience in Linux OPS, containerization, monitoring, CI/CD, automation, and industrialization in a cloud environment (AWS preferred) and possess an interest in Spark, Airflow, Sagemaker, and BigQuery.",Non spécifié,> 2000 salariés,> 2 ans,0,1,0.013848874720779208
61,73359,https://www.welcometothejungle.com/fr/companies/make-1/jobs/summer-internship-data-engineer_prague,Summer Internship - Data Engineer,Make,"{Celonis,Python,BigQuery,scale,color,regard,SQL,Snowflake,Java}",NaN,"Menclova, Prague, 180 00","Logiciels, SaaS / Cloud Services",Autres,2023-04-22,"Make is the leading visual platform for anyone to design, build, and automate anything - from tasks and workflows to apps and systems - without coding. Make enables individuals, teams, and enterprises across all verticals to create powerful custom solutions that scale their businesses faster than ever. Make powers over 500,000+ organizations around the globe. Make has been a part of Celonis, a German software company focused on process mining, currently one of the most valuable start-ups in Germany and NYC, since 2020. Make currently operates as an independent business unit under the Celonis umbrella. Join us for the ride! Make is the leading visual platform for anyone to design, build, and automate anything—from tasks and workflows to apps and systems—without the need for coding skills. We are headquartered in the flourishing tech hub of Prague, Czech Republic, and our teams are spread across the USA, UK, Germany, France, Canada, India and Chile, among other locations. Join us on a 3-month internship ( July-September) for University students who want to gain real-life work experience in a fast-growing SaaS company. As a Summer Intern, you will be part of real projects and take more responsibility as you grow. We are looking for an enthusiastic and motivated student to join as a Data Engineer. Data engineering is the intersection of data management, orchestration, DataOps, data architecture, security and software engineering. Data engineers handle management of the data lifecycle - beginning with getting data from source systems and ending with serving data for various use cases such as analysis and machine learning. Responsibilities You will get familiar, adopt and participate on our system and concepts of working with data throughout the whole lifecycle such as: Communication with producers of data - product developers. Work closely with our Analytics and Data Science teams Development, tests and integration of ingestion jobs. Data modeling to reflect the goals and business logic of the company. Serving data in appropriate shape and form based on the business needs to facilitate data driven decision making. Orchestrate the whole flow. Contribute to the data architecture and gain knowledge about the data warehousing, design patterns and data tools. Work on data governance and data quality. Assist in adopting and spread of software engineering best practices. Requirements Pursuing a degree in Computer Science, Data Analytics, or a related field. Work on school projects implemented in Python/Java/C++. Big plus is work related to data oriented applications. Work on a school project focused on development of databases and information systems. Basic understanding of data modeling techniques and normalization. Hands-on experience writing SQL queries. Strong problem solving, conceptualization, and communication skills. Exposure to CI/CD. Knowledge of building ETL/ELT data pipelines is a plus. Knowledge of cloud data warehouses such as Snowflake or BigQuery is a plus. Strong written and verbal fluency in English What we offer: 🌎 Multinational team with 42 nationalities creating the future of automation 🍎 Notebook/Macbook and 34’’ curved monitor 🍍 Snack bar, coffee, tea, fruit and vegetable, and sweets all day - every day - available for everyone 🥗 Monday breakfast, Wednesday lunch, and Friday break, with company-provided food and drinks, with music and lively discussion ⏰ Flexible working hours 🐕‍🦺 Company therapy pets (dog-friendly office) 🖨️ Company 3D printer 🥳 Parties, and company events If you see a match, let us know and apply now! #careeratmake Make is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment and equal opportunity in all aspects of employment. We will not tolerate any unlawful discrimination or harassment of any kind. We make all employment decisions without regard to race/ethnicity, color, sex, pregnancy, age, sexual orientation, gender identity or expression, transgender status, national origin, citizenship status, religion, physical or mental disability, veteran status, or any other factor protected by applicable anti-discrimination laws. As a US federal contractor, we are committed to the principles of affirmative action in accordance with applicable laws and regulations. Different makes us better. Accessibility and Candidate Notices",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,0,1,0.013848874720779208
261,56966,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/ia-project-engineer-data-value-lab-f-m-d_croix,IA Project Engineer - Data Value Lab,Decathlon Digital,"{GCP,SQL,Python,AWS}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. LES EQUIPES DU DATA VALUE LAB DE l'IA FACTORY DE DECATHLON Le Data Value Lab , au sein de l'unité Decathlon AI factory, est l'équipe chargée de découvrir & définir les cas d'utilisation d'IA qui apportent le plus de valeur ajoutée. Mais aussi d'assurer l'expérimentation de ces cas d'usages. Le terme X4, qui signifie eXplore, eXamine, eXperiment et eXtend, résume parfaitement le modus operandi de l'équipe. Au sein du Data Value Lab, nous utilisons une approche agile ""test & learn"" pour analyser le potentiel de valeur, la faisabilité d'un cas d'usage et mesurer la performance de la solution avant d'en étendre les succès (industrialisation). Nous sommes étroitement liés aux parties prenantes métiers de l'entreprise et aux équipes d'IA (personnalisation, tarification, prévision, optimisation des offres) chargées de déployer à grande échelle les résultats de nos expérimentations . L'équipe joue un rôle central dans l'établissement de nouvelles orientations en matière d'IA au sein de Decathlon, en expérimentant les dernières technologies d'apprentissage automatique pour résoudre des problèmes commerciaux à fort impact et en diffusant la culture de l'IA dans toute l'organisation.Vous serez en charge de projets qui ont le potentiel de définir l'avenir du sport. Rejoindre nos équipes c'est vraiment une chance de façonner l'industrie du sport grâce aux données et à l'IA Dans le cadre de l’ouverture d’un poste en interne, nous recrutons en CDI un-e Data Value Engineer, basé-e à Paris (prévoir des déplacements réguliers de 2 jours tous les 15 jours sur Lille). VOS RESPONSABILITES En tant que Senior Data Value Engineer au sein du Data Value Lab, vous devrez: Être dédié à 100% aux projets digitaux stratégiques liés à la transformation de l'entreprise par l'IA, sur des sujets transverses (Sports & Process, Supply Chain, Marketing, Offre, Pricing, Sustainability principalement) Vous identifierez, cadrerez, prioriserez et construirez des solutions d'IA pour les métiers : réalisation d'un business case, traduction d'un problème métier en solution d'IA, estimation du potentiel de valeur, exploration des données pour déterminer un niveau de faisabilité et enfin pilotage du build avec les équipes de Data Science. Vous remettrez en question les problèmes métiers, la valeur potentielle et la faisabilité technique des besoins remontés . Vous serez amené à projeter des cas d'usages pragmatiques à partir de nos trajectoires digitales priorisées. Vous utiliserez vos connaissances des applications business de l'IA, ainsi que votre maitrise du cycle de vie d'un projet de Data Science , pour définir les cas d'usages d'IA à fort impact et garantir leurs mise en oeuvre. Vous serez en charge de l'organisation, de la préparation et de l'exécution des workshops métiers lors de la phase de Design, avec des parties prenantes à 360° afin d'identifier des besoins ou alors les cadrer. Vous appliquerez la méthodologie agile pour mener à bien votre feuille de route et animer votre roadmap. V ous serez en charge du pilotage du projet lors des phases de Define et de Build , en collaborant avec des parties prenantes techniques et métiers. Vous identifierez les données critiques (à valeur) à collecter et à intégrer dans le domaine des données d'entreprise, en partie grâce à vos cadrages. Vous communiquerez efficacement l'analyse et les résultats des expérimentations, en passant par une mesure concrète de la valeur créée. Et ce par le biais de visualisations, de documents et de présentations à toutes les parties prenantes. CE DONT VOUS AUREZ BESOIN POUR RÉUSSIR Vous avez au moins 3 ans d'expérience en tant que Consultant-e Data, Business Translator, PM Data ou Data Scientist; qui vous as permis-e d'être un-e solide généraliste Data sur l'ensemble du cycle de vie de la donnée. Hards Skills : Vous avez acquis une expertise des applications IA pour les business, de la traduction d'un problème métier en solution d'IA ; Vous comprenez et vous avez une connaissance complète du cycle de vie d'un projet de Data Science, ainsi que des besoins et exigences en matière de données; Vous avez acquis une expérience en Business Analyse; Vous avez de solides compétences de restitution d'analyses, pitch/argumentation ; Vous avez acquis une expérience en management de projet Data, pilotant des équipes transverses à la fois techniques et métiers; Vous avez des compétences en analyse des données : analyse et visualisation exploratoires des données; Vous avez un niveau de base en SQL et/ou en Python ; Vous êtes expérimenté en techniques de Design Thinking et leurs applications aux produits Data; Soft Skills : Vous avez d' excellentes compétences interpersonnelles, analytiques, de communication et de présentation - capacité à communiquer des résultats complexes de manière simple ; Vous avez des compétences solides en matière de résolution de problèmes, l'accent étant mis sur le développement de produits ; Vous aimez découvrir et résoudre des problèmes ; chercher de manière proactive à clarifier les exigences et les orientations ; vous êtes une personne autonome qui prenez des responsabilités lorsque cela est nécessaire ; Vous êtes capable d'explorer différentes directions à partir de données et êtes capable de changer rapidement de direction en fonction de l'analyse ; Vous êtes passionné.e par le sport et la mobilité Vous avez envie de rejoindre une entreprise à impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de télétravail par semaine (jours libres) ; Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Possibilité de se certifier dès la première année (AWS, GCP, etc..) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, notamment implantées à Paris, Lille, Nantes, Lyon et Amsterdam. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .","Decathlon is seeking a Senior Data Value Engineer for its Data Value Lab team in Paris to work on strategic digital projects related to the company's AI transformation. The role involves identifying, prioritizing, and building AI solutions for various business areas, challenging business problems, and value potential. The ideal candidate should have at least three years of experience as a data consultant, business translator, PM data, or data scientist, with expertise in AI applications for business, data science project lifecycle, and data analysis. They should also have excellent interpersonal, communication, problem-solving, and presentation skills and be passionate about sports and mobility. Decathlon offers a positive impact work environment, telecommuting, competitive compensation, stock options, mentoring, and training opportunities, among other benefits.",Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
362,50175,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-london-or-remote-uk_london,Software Engineer Data Visualization - London or Remote UK,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",NaN,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend).- Prototype and create new ways to import and request data at large scale.- Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions.- Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best.- Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku’s culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer to create intuitive, beautiful interfaces and scalable engines for its platform, which empowers non-technical users to process and analyze data with either user-friendly interfaces or code. The ideal candidate has experience in software development and data visualization tools, is customer-oriented, and comfortable with both frontend and backend development. Dataiku values diversity and is an equal opportunity employer.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
337,34803,https://www.welcometothejungle.com/fr/companies/inetum/jobs/data-engineer-azure-h-f_orleans_INETU_qD4d0wr,Data Engineer Azure,Inetum,"{Microsoft,Azure,Databricks,GitHub,AZURE}",NaN,Orléans,IT / Digital,CDI,2022-08-08,"Inetum est une ESN agile, une société de services et de solutions digitales, et un groupe international qui aide les entreprises et institutions à tirer le meilleur du digital flow. Dans un contexte de mouvement permanent, où les besoins et les usages se réinventent sans cesse, le groupe Inetum s'engage auprès de tous les acteurs pour innover, s'adapter continuellement et garder une longueur d'avance. Avec son profil de multi-spécialiste, Inetum met au service de ses clients une combinaison unique de proximité, d'organisation sectorielle et de solutions de qualité industrielle. Présent dans plus de 26 pays, le Groupe compte près de 27 000 collaborateurs et a réalisé en 2020 un chiffre d'affaires de 1,966 milliard d'euros. Tous nos postes sont ouverts aux personnes en situation de handicap. Inetum région Centre, recherche un profil AZURE Data Engineer. Vos principales missions consistent à : Concevoir et mettre en oeuvre des solutions sur la plateforme Microsoft Azure pour la persistance, l'enrichissement et l'analyse de données Conseiller sur différents types d'architecture Data lake et Data warehouse pour répondre au mieux aux besoins des clients dans le respect des politiques sécurités Mettre en place les tests pour assurer la qualité des livrables et l'intégrité des données produites Vous engager dans des projets clients, allant de la conception à la mise en oeuvre de projets cloud (configuration, développements, documentations...) Assurer le Rôle de conseil pour la mise en oeuvre des bonnes pratiques La mise en oeuvre des stratégies de contrôle des coûts et recherche d'optimisations financières des services La rédaction de dossier d'architecture technique et de dossier de spécifications techniques Ce que nous allons vous apporter : La consolidation de vos connaissances par la formation et des certifications. De formation supérieure en informatique, avec plusieurs années d'expériences. Vous avez une bonne connaissance des technologies Azure et une expérience significative sur le Cloud Azure IAAS, PAAS Vous démontrez d'excellentes compétences dans le relationnel avec les clients et en interne. Vous êtes autonome et savez travailler en équipe. Compétences techniques : Expérience de développement Big Data, Modélisation décisionnelle, en étoile (Datawarehouse, Datamart), en offrant des niveaux élevés de performance, de sécurité, d'évolutivité, de maintenabilité et de fiabilité de la solution Microsoft AZURE Expérience sur l'intégration de données Définition des indicateurs Azure Data Factory, GitHub, Azure DevOps minimum 3 ans Facultatif : Databricks","Inetum is seeking an Azure Data Engineer to design and implement solutions on Microsoft Azure for data persistence, enrichment, and analysis, advise on different types of Data lake and Data warehouse architecture, implement testing for quality and data integrity, and engage in client projects from design to implementation. The ideal candidate should have a good understanding of Azure technologies and experience on Azure Cloud IAAS and PAAS, in addition to excellent communication skills and the ability to work independently and in a team. Technical skills required include experience with Big Data development, decision modeling, and integration, as well as knowledge of Azure Data Factory, GitHub, and Azure DevOps. Optional skills include experience with Databricks.",N,N,N,0,1,0.013848874720779208
99,73676,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-solutions-engineer_paris,Data Solutions Engineer,Numberly,"{python,javascript,Python,SQL}",NaN,"28 rue de Châteaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa création en 2000, Numberly, Marketing Technologist, aide ses clients à se différencier par la qualité de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d’identifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de manière plus efficace et pertinente. Trois pôles complémentaires permettent de répondre aux enjeux des annonceurs, de l’acquisition à la rétention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l’impact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour créer des expériences personnalisées. Avec des équipes à Paris, Londres, Dubaï, Montréal et New York, Numberly opère dans plus de 50 pays : le groupe, résolument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours à la qualité d’exécution et la satisfaction client, en restant curieux, agile et innovants, un état d’esprit qui anime Numberly depuis plus de 20 ans ! Numberly offers one of the most advanced independent Customer Data Platform in France. For more than 10 years, Numberly has been improving its in-house solution, enabling data integration and usage in real-time. We combine our own tech infrastructure, our machine learning algorithms, and deep API integrations with the ecosystem to help brands build their data assets and optimize their marketing investments. What You Will Do: As a Solutions Engineer, you will join the Data team to work on our Customer Data Platform. Your role will be to make sure Numberly's solution is properly set up and ready to deliver the best performances for our clients. You will be working closely with people across Data Engineers, Software Engineers, Product and Marketing teams. Responsibilities will include: Create the technical specifications to implement Numberly’s solution on the client’s side Be the Tech Expert for clients' advanced discussions Ensure that everything is well set from a technical point of view Challenge our way of working and define new processes to maximize our internal efficiency Act as a Technical Project Manager to fix, develop or improve client-specific projects (from writing technical specifications to the delivery) Be able to work closely with both Tech (Data Scientists, Software Engineers, Data Engineers, Data Analysts) and Business teams (Media Traders, Marketing, Legal) to ensure we deliver the best possible solution to our client. At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (“Live my life” in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Who You Are: Minimum qualifications: Engineering master degree or business master degree with strong technical dimension You are curious about how things work and do not hesitate to be hands-on You have a problem-solving mindset with a strong tech curiosity You are a team-player and you enjoy working in a highly collaborative environment Fluent in English Preferred qualifications: Skilled in any data crunching language (SQL, Python...) At ease with understanding javascript or python scripts You already worked with a data visualization tool",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
279,56706,https://www.welcometothejungle.com/fr/companies/realadvisor/jobs/data-acquisition-engineer_geneva,Data Acquisition Engineer,RealAdvisor,"{React,MongoDB,NodeJS,Kubernetes,GitHub,PostgreSQL,Docker,github,TypeScript,GCP,GraphQL,Clickhouse}",NaN,"Geneva, 1201","Intelligence artificielle / Machine Learning, Immobilier commercial, Immobilier particulier",Freelance,2023-03-26,"RealAdvisor is a European PropTech startup based in Geneva. We use the power of cutting-edge web, data mining and machine learning technologies to make real estate transactions more transparent, fair and efficient. We help over 250k monthly users in their real estate projects whether they are: Searching for a place to buy or rent on our listings aggregator Estimating the value of their home online using our algorithms or browsing market data Our team has over 10 nationalities and is spread across Europe working remotely or based in our offices in Geneva & Zürich. We are looking for a talented Data Acquisition Engineer to make new scrapers and maintain current stack of scrapers. You will work with a rockstar team of developers and data scientists (incl. Kaggle Masters) with over 10k github stars with over 10 nationalities and is spread across Europe working remotely. Our data acquisition stack is composed of NodeJS, Playwright, TypeScript, Temporal.io, MongoDB, Kubernetes, Helm, Terraform and GitHub Actions. Our application stack is composed of NextJS, React, Svelte, GraphQL, NodeJS, PostgreSQL & Clickhouse, GCP, Google AI Platform, Terraform, Nomad. Here are a couple of things you will be doing: Develop new scrapers and parsers for new countries & portals Migrate existing scrapers and parsers from our old stack Maintain and improve existing scrapers and parsers You’re the perfect candidate if you: Have extensive experience with NodeJS and TypeScript Are experienced in Docker, MongoDB, Relational Databases Are comfortable communicating in English Have a keen eye for checking every small detail Have passion for Data Acquisition Problem Solving Have shipped projects to production Have experience with large data sets and cloud computing Considered a plus: You have an interest in real estate / economics Enjoy writing extensive documentation Please send your proposal with details of your experience level, plus links to your previous works (if applicable). Important note: your proposal should start with “realadvisor-120485” as first line, this way we can see you have actually read our job posting and not applying automatically. We will send you a test challenge consisting of writing a simple scraper with NodeJS + TypeScript + ESM","RealAdvisor, a European PropTech startup based in Geneva, is seeking a talented Data Acquisition Engineer to develop new scrapers and maintain the current stack of scrapers. The ideal candidate should have extensive experience with NodeJS and TypeScript, be experienced in Docker, MongoDB, and Relational Databases, have a keen eye for details, and a passion for data acquisition problem-solving. Knowledge of real estate and economics is considered a plus. Fluency in English is a must.",Non spécifié,Entre 15 et 50 salariés,Non spécifié,0,1,0.013848874720779208
177,2540,https://www.welcometothejungle.com/fr/companies/blade-shadow/jobs/data-software-engineer-h-f_paris_SHADO_ZmwMl8y,Data Software Engineer,Shadow,"{Go,via,Docker,SQL,Python,Bash}",NaN,Paris,SaaS / Cloud Services,CDI,2021-12-27,"Fondée en 2015 , Shadow est une entreprise française dont l’objectif est de rendre l'informatique haut de gamme accessible à tous.te.s ! Chez Shadow, nous révolutionnons la façon dont les utilisateurs du monde entier utilisent les ordinateurs pour travailler et jouer. La promesse ? Accédez à un PC puissant depuis le cloud qui peut faire tourner n'importe quelle application et jeu sur tous les écrans grâce à une configuration jamais obsolète ! Aujourd'hui, Shadow compte plus de 100 000 client.e.s réparti.e.s en Europe et aux États-Unis. Notre équipe comprend désormais près de 140 collaborateurs et collaboratrices, basé.e.s à Paris et la Silicon Valley, qui ont pour mission commune de révolutionner le monde informatique. Shadow est une entreprise fondamentalement humaine, se nourrissant de l'énergie issue de la rencontre de profils très divers, avec le grain de folie de ceux qui peuvent rendre l'impossible possible. “lls ne savaient pas que c’était impossible, alors ils l’ont fait” Si tu es désireu.x.se de débuter une nouvelle aventure au sein d’une équipe qui pense “outside the box”, qui te fera grandir à la fois professionnellement et personnellement, alors Shadow est fait pour toi ! Soyez libre d’esprit en créant, travaillant et jouant avec Shadow ! Depuis 2015, Shadow propose le meilleur de l’informatique , utilisable n’importe où et n’importe quand grâce au cloud computing . Nous sommes convaincus que créer de nouveaux outils puissants et accessibles à tous.tes, permettra à chacun.e.s de réaliser des choses extraordinaires. Aujourd’hui Shadow c’est une communauté comptant plusieurs dizaines de milliers d’utilisateur.trice.s en Europe et aux Etats-Unis , qui nous challenge au quotidien à devenir une meilleure version de nous-même. Mais Shadow c’est avant tout une équipe en constante croissance qui compte 130 collaborateur.rice.s basés entre Paris & la Silicon Valley . Une entreprise fondamentalement humaine qui se nourrit de l'énergie issue de l’échange entre des profils très divers , avec le grain de folie de ceux qui peuvent rendre l'impossible possible . Si tu es désireu.x.se de commencer une aventure au sein d’une équipe aux idées infinies, qui te fera grandir à la fois professionnellement et personnellement, alors rejoins Shadow ! Nous recherchons activement un.e Data Software Engineer pour rejoindre notre équipe Engineering ! Tes missions: -Concevoir et créer une toute nouvelle architecture data évolutive afin de répondre à l'ambition de scaling-up de l'entreprise; -Definir les technologies les plus adaptées pour le stockage et le traitement de données. Cela comprend l'étude, la mise en œuvre et le déploiement; -Développer des méthodes de mesure et de monitoring de la précision des metrics surveiller la précision des mesures, puis les analyser pour les optimiser; -Collaborer avec notre Machine Learning Enginer sur le déploiement des modèles de machine learning (MLOps); -Rendre les datas facilement utilisables par tous dans l'entreprise; -Mettre en place et maintenir des outils à disposition des collaborateurs Shadow. Ton profil: Tu ne te reconnais pas à 100% dans les critères ci-dessous ? Aucun problème, envoie quand même ton CV! Ces derniers ne sont pas tous éliminatoires: Ta passion, ta curiosité et ta motivation nous aideront à te faire grandir ;) -Tu possèdes au moins 3 ans d’expérience dans un poste similaire; -Tu sais créer et maintenir des pipelines; -Tu as créé from scratch et scalé un Data Warehouse; -Tu as une solide expertise en programmation (Python, Go et Bash); -Tu maîtrises SQL, Docker et les tests unitaires; -Tu es à l’aise avec les frameworks de traitement de données en temps réel; -Tu possèdes une bonne expérience en analyse data; -Tu as de bonnes connaissances en machine learning; -Tu fais preuve d’autonomie et tu restes proactif.ve dans tes missions; -Tu es un vrai team player, tu travailleras étroitement avec plusieurs équipes pour atteindre un succès commun; -Tu maîtrises l’anglais (écrit ; oral). Nos petits plus: -Une très bonne ambiance au sein d’une équipe passionnée ! -Ta machine virtuelle dispo de suite; -Des bureaux en plein cœur de Paris (2eme), parfait pour les afterworks ! -Un CSE au top qui t’accompagne dans toutes les situations et qui te trouve des super plans (via notre plateforme Leeto); -Les meilleurs outils pour faciliter ton expérience chez Shadow (Payfit, Alan, Swile…); -Télétravail sur ce poste possible. Tu peux aussi venir tous les jours si tu le souhaites ! ; -Le goûter à volonté (manger/bouger); -Tout pour apprendre à connaître tes collègues “en off”: Borne d’arcade, jeu de fléchettes, game night... -Petit-déjeuner du lundi au mercredi pour bien commencer la semaine; -Le reste est à découvrir ;) Et bien sûr: -Tickets restaurant (via Swile); -Remboursement à 50% du pass navigo; -Cotisation à 50% de la mutuelle (ALAN). Ton process de recrutement: Nous te proposerons un appel de 30 minutes, avec une personne de l’équipe de recrutement pour faire connaissance et te présenter le poste. S’il nous semble pertinent (à toi et à nous) d’avancer, tu rencontreras: 1)Edouard, notre Chief information Officer 2)Martin, notre Business Intelligence Director et Baptiste, notre Data Engineer 3)Octave, notre CTO N’attends plus, rejoins-nous ! Shadow valorise la diversité des personnes qu’elle embauche et accompagne. La diversité, pour Shadow, c’est favoriser un milieu de travail où les différences individuelles sont reconnues, appréciées et respectées de façon à développer le plein potentiel et les forces de chacun.e. Restez vous-même, vous êtes le.a bienvenu.e ;) Ce contenu est bloqué Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","Shadow is seeking a Data Software Engineer with at least 3 years of experience in a similar role to join their Engineering team. The engineer will be responsible for designing and creating a new scalable data architecture, defining the most appropriate technologies for data storage and processing, developing methods for measuring and monitoring metric accuracy, and collaborating with the Machine Learning Engineer on machine learning model deployment. The ideal candidate must have experience in programming, SQL, Docker, and unit testing, as well as real-time data processing frameworks and data analysis. A team player with autonomy, proactiveness, and English fluency is preferred. Shadow is committed to diversity and welcomes candidates of different backgrounds.",N,N,N,0,1,0.013848874720779208
195,56522,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_strasbourg,DATA ENGINEER,ACTINVISION,"{Microsoft,MySQL,GCP,Talend,Matillion,AWS,Snowflake,Alteryx,Azure,Java,SQL,Python,Tableau}",NaN,"5, Quai de Paris, Strasbourg, 67000","Intelligence artificielle / Machine Learning, Transformation, Big Data",CDI,2023-03-26,"Fondée en 2014, Actinvision est un regroupement de Data Heroes accompagnant différents acteurs dans leur transformation vers une culture data. Créant un lien de confiance avec ses clients, elle donne à ces derniers les moyens d’analyser leurs innombrables données. Mêlant expertise technique de haut niveau et créativité sans limites, elle développe des approches personnalisées destinées à valoriser les données de l’organisation. Actinvision, c’est aujourd’hui plus de 300 clients en France et à l’international dans divers secteurs, allant de l’industrie à la grande distribution en passant par le secteur financier. Son fief se trouve dans la région Grand Est et plus précisément en Alsace, à Strasbourg. C’est de là qu’est dirigé l’ensemble des opérations, notamment mené à travers un second bureau, positionné à Paris. Actinvision est, en interne, une communauté multiculturelle “fun” orientée autour de la data et, en externe, un partenaire reconnu et privilégié par de nombreuses entreprises leaders du marché : Tableau, Alteryx, Snowflake, Microsoft, Talend, etc. Entreprise accréditée “Happy at Work” par ChooseMyCompany Vous serez amené(e) à travailler sur différents projets innovants , pour des clients de toute taille , dans des secteurs divers et variés tels que l’agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l’énergie, l’industrie, la pharma/chimie ou encore la santé. En tant que Data Engineer passionné(e), vous aiderez nos clients à relever les challenges d’aujourd’hui et de demain en intégrant leurs données au sein d’infrastructures, On-Premise et Cloud. A la suite d’une période d’intégration destinée à vous familiariser avec la méthodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l’analyse du besoin client à la livraison de la solution technique en passant par le chiffrage et les développements. Vous évoluerez en équipe mais également de manière autonome dans un environnement technique porteur d’innovations incluant par exemple la modélisation et la construction d’entrepôts de données (Data Warehouses), le design de flux d’intégration au moyen d’outils (e.g. Talend ou ADF, Matillion etc. ) permettant l’alimentation de ces derniers, ou encore la mise en place et l’optimisation dans le respect des bonnes pratiques d’architectures Data, notamment Cloud (e.g. Snowflake ou Azure). Le développement des compétences est un aspect primordial. Ce développement continu est appuyé par les ressources officielles mises à disposition par l’ensemble des éditeurs partenaire d’Actinvision et complété par des ressources internes. Les compétences acquises pourront être valorisées aux travers de certifications éditeurs hautement qualifiantes. MISSIONS PRINCIPALES : • Participer en équipe ou de façon autonome à la mise en œuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intégration et stockage de la donnée • Recueil du besoin client technico-fonctionnel permettant la mise en place d’ architectures pour la collecte et l’extraction de données depuis diverses sources (bases de données Cloud, applications métier, API, etc.), la manipulation et la transformation de ces données, puis le chargement de ses dernières au sein de base de données de type Data Warehouses (DWH) • Design des infrastructures/architectures Data et modélisation des DWH cibles, lesquels seront principalement utilisés dans le cadre d’opérations de Reporting et/ou de Data Visualisation • Réalisation de flux d’intégration et transformation de donnée De formation Bac+5 en informatique, vous disposez de minimum 1 an d’expérience sur un poste similaire. Savoir-faire, compétences techniques requises : • Langage SQL et modélisation DWH • Pratique d’un outil d’intégration ETL / ELT • Connaissances en bases de données relationnelles (e.g. SQL Server ou MySQL) • Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP) • Connaissances de la chaîne de valeur de la Data, et particulièrement de la BI Savoir-faire, compétences techniques appréciées : • Connaissances en architectures Cloud (sécurité, performances, maîtrise des coûts, etc.) • Programmation procédurale, e.g. T-SQL ou PL/SQL • Un langage de programmation orienté objet, e.g. Java ou Python • A l’aise avec l’utilisation d’API / de Web Services • Notions sur l’ESB Savoir-être, compétences fonctionnelles : • Passion pour la Data • Autonomie / Travail et esprit d’équipe (incluant le partage des connaissances) • Force de proposition / Capacité à rechercher et trouver des solutions • Créativité et curiosité • Dynamisme et réactivité • Sens du service • Capacité à participer à l’animation de la communauté (interne et externe) • Anglais technique • Pour un poste confirmé : Expérience probante dans les domaines du DWH et de l’intégration de données (cloud et/ou on-prem) Moyenne de temps du process de recrutement chez Actinvision : 15 jours Pré qualification téléphonique : 15 à 20 minutes Entretien technique : 1h00 Entretien RH : 1h00","Actinvision is a data consulting firm seeking a passionate Data Engineer with knowledge in ETL tools, SQL, and data warehousing. The Data Engineer will participate in all project phases from client analysis to solution delivery, and work with various sectors, including finance, retail, agriculture, and energy. Actinvision encourages team collaboration, innovation, and professional development opportunities with official resources from their technology partners. The ideal candidate is a creative problem solver, team player, and fluent in English with at least one year of experience.",Bac +5 / Master,Entre 50 et 250 salariés,> 1 an,0,1,0.013848874720779208
268,62111,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_brest_ASI_4oZeyg8,Data Ingénieur - Manipulation et valorisation des big-datas,ASI,"{MySQL,Oracle,ElasticSearch,Scala,Kafka,Cassandra,PostGreSQL,Spark,SQL,Java,NoSQL,Hadoop,Python,Cloudera}",NaN,Brest,"IT / Digital, Transformation, Big Data",CDI,2023-03-30,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Vous aurez pour mission de : Concevoir et réaliser un sourcing de données Big Data Temps réels ou non Maîtriser les formats de données non structurés et savoir les manipuler Concevoir et réaliser une chaîne de traitement dans un environnement Big Data Concevoir et réaliser des applications et API utilisant les données valorisées Gérer et administrer les bases de données filesystem et NoSQL Ecosystème en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, Big Query Langages de développement : Python, Java, Scala. Idéalement titulaire d’un Bac+4/5 (Ecole d’Ingénieur ou Universitaire), vous maitrisez : Hadoop (Cloudera)et/ou une solution de base de données NoSQL Le requêtage SQL, HiveQL Le développement Spark avec SQL, Python et/ou Scala Le développement Java (API en particulier) Les bases de données relationnelles (PostGreSQL, Oracle, SQLServer, MySQL…)","ASI is a digital expertise company that develops digital services for public and private organizations to support them in their digital transformation. They are looking for a Big Data Developer who can design and execute real-time and non-real-time data sourcing, manipulate unstructured data formats, develop an end-to-end processing chain in a Big Data environment, and create applications and APIs using the data. The ideal candidate should have a degree in Engineering or a related field and experience with Hadoop, NoSQL databases, SQL and HiveQL querying, Spark development, and Java.",Bac +4,Entre 250 et 2000 salariés,> 5 ans,0,1,0.013848874720779208
387,34756,https://www.welcometothejungle.com/fr/companies/axians/jobs/consultant-data-engineer-f-h_la-defense,Consultant Data Engineer,Axians France,"{durable,GIT,regard,HADOOP,Hive,Spark,SQL,JAVA}",NaN,La Défense,"Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Cybersécurité",CDI,2022-08-08,"Rejoindre Axians, c'est rejoindre un réseau d'entreprises agiles présentes dans 26 pays et composé de 12 000 collaborateurs réalisant un CA de 2,6 Milliards d'euros. Axians est la marque de VINCI Energies dédiée aux solutions ICT, c'est-à-dire la maitrise de l'ensemble des technologies de l'information et de la communication : Réseaux d'entreprises, digital Workspace & Collaboration, Cloud privé et hybride, Cybersécurité sur projets ou en Services Managés. Nous accompagnons nos clients entreprises privées, secteur public, opérateurs et fournisseurs de services - dans la transformation de leurs solutions digitales. Fortement impliquée sur nos territoires respectifs, Axians a une forte politique de développement durable en s'engageant sur une réduction de 40% de ses émissions de CO2 à l'horizon 2030 mais également d'actions solidaires touchant à l'insertion, à l'éducation au travers de la Fondation VINCI et de nombreux partenariats écoles.Connexion, performance, efficience énergétique, datas : dans un monde en évolution permanente, VINCI Energies accélère le déploiement des nouvelles technologies pour concrétiser deux mutations majeures : la transformation digitale et la transition énergétique. Ancrées dans les territoires et organisées en mode agile, les entreprises de VINCI Energies rendent les infrastructures d'énergie, de transport et de communication, les usines ainsi que les bâtiments chaque jour plus fiables, plus sûrs, plus efficients. 2021 : 15,1 milliards d'euros (chiffre d'affaires) // 85 700 collaborateurs // 1800 entreprises // 55 pays www.vinci-energies.com Dans le cadre du développement de notre activité, nous recherchons un consultants Data Engineer (F/H) pour intervenir chez l'un de nos clients à Paris La Défense. Votre mission portera sur des tâches parmi les suivantes : - Participer aux cérémonies (daily, affinage, sprint planning) - Assurer les développements spécifiques - Réaliser des tests unitaires et d'intégration - Garantir la maintenabilité et les performances des programmes développés - Maintenir à jour la documentation - Apporter un regard critique sur les fonctionnalités déjà développées ou à développer. Vous possédez un diplôme d'ingénieur ou Master en informatique (spécialité statistique ou informatique décisionnelle) et vous bénéficiez d'un expérience minimum de 2 ans sur des projets utilisant les éco-système Big Data. Compétences techniques : - Langage SQL - Technologie HADOOP : Spark, Hive - Développement JAVA - GIT - Connaissance en modélisation de la donnée Compétences relationnelles et fonctionnelles : - Esprit d'équipe et connaissance des méthodes agiles - Pro-activité et regard critique sur la conception de traitement techniques - Connaissance du domaine de l'assurance","Axians, part of VINCI Energies, is looking for a Data Engineer Consultant to join their team in Paris La Defense. The role involves participating in daily planning, developing specific programs, conducting unit and integration testing, ensuring program maintainability and performance, updating documentation, and providing critical insight on developed and to-be-developed functionalities. The ideal candidate should possess a degree in computer science, statistics, or decision-making, have a minimum of 2 years' experience working with Big Data ecosystems, and have experience with SQL, HADOOP technology like Spark and Hive, Java development, and data modeling. The role also requires teamwork, knowledge of agile methodology, and a proactive approach to technical processing design.",Bac +5 / Master,Entre 250 et 2000 salariés,> 1 an,0,1,0.013848874720779208
410,37143,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_niort_ASI_0rWWPNz,Data Engineer,ASI,"{DynamoDB,Matillion,Glue,Cassandra,Hive,Neo4J,Azure,Cloudera,MongoDB,Talend,Kafka,NoSQL,CouchDB,HBase,Java,Hadoop,Redis,EMR,Scala,Airflow,HDFS,S3,Spark,Python}",NaN,N,"IT / Digital, Transformation, Big Data",CDI,2022-10-18,"ASI est un cabinet d’expertises numériques qui accompagne les organisations publiques et privées dans leur transformation digitale en développant des services numériques destinés à leurs collaborateurs, partenaires et clients. Nous sommes présents dans 7 villes en France : Nantes (notre siège), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un numérique aux impacts positifs (social, environnemental, sociétal…), notre raison d’être inscrite dans nos statuts traduit nos engagements : agir pour un monde numérique responsable au service de l’humain. 🌳 Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, Développeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte… Nous sommes une belle et grande communauté de 500 collaborateurs aux compétences complémentaires qui partagent les mêmes valeurs : confiance, écoute, engagement et plaisir de travailler dans le bonne humeur ! 😀 Dans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin. Dans le cadre du développement de nos expertises Data et pour répondre aux enjeux de nos clients, nous recherchons un Data Engineer pour intégrer notre équipe Niortaise Au quotidien : Vous concevez et réalisez un sourcing de données Big Data, temps réel ou non Vous maîtrisez les formats de données non structurés et savez les manipuler Vous modélisez un schéma de base de données relationnelle ou non-relationnelle Vous connectez une solution ETL / ELT à une source de données (fichiers, API, base de données, flux temps réel) Vous concevez et réalisez un pipeline de transformation et de valorisation des données et ordonnancez son fonctionnement Vous veillez à la sécurisation des pipelines de données Vous concevez et réalisez des API utilisant les données valorisées Vous réalisez une veille technologique constante. Parlons de vous : Issu d’une formation supérieure en informatique, mathématiques ou spécialisé en Big Data. Vous possédez une expérience minimum de 2-3 ans en ingénierie des données et d'une expérience opérationnelle réussie dans la construction de pipelines de données structurées et non structurées. Vous avez une expérience pratique dans l’un ou plusieurs des environnements technologiques suivants : L’écosystème Data : Spark, Hive, HDFS, Kafka, HBase et idéalement une distribution Hadoop (Cloudera, EMR, HDInsight) Les langages : Scala, Java, Python Les bases de données NoSQL : MongoDB, Cassandra, DynamoDB, CosmosDB, CouchDB, Redis, Neo4J Stockage cloud: S3, Azure Blob Storage… Les ETL/Outils d'orchestration du marché : Matillion, Airflow, Datafactory, Glue, Talend,... Le respect et l’engagement font partie intégrante de vos valeurs. Vous avez l’esprit d’équipe et vos qualités relationnelles vous permettent de vous intégrer facilement au sein de l’équipe. À compétences égales ce poste est ouvert aux personnes en situation de handicap .","ASI is seeking a Data Engineer to join their team in Niort to support the development of their Data expertise and meet client needs. The ideal candidate should have a minimum of 2-3 years of experience in data engineering and should possess practical experience in one or more of the following technological environments: Data Ecosystem, Languages, NoSQL Databases, Cloud Storage, and ETL/Orchestration Tools. The candidate should also have excellent teamwork skills and a commitment to respect and engagement. The position is open to all, including people with disabilities.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,0,1,0.013848874720779208
289,56734,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-software-engineer-m-f-d_utrecht,Data & Software Engineer,Artefact,{},NaN,"Utrecht, 3511","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that’s why we identify as “marketing engineers”. In order to improve the performance and impact of brands, and consumers’ experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). tl;dr From design to deployment , you manage your solution end-to-end, while also optimising the performance, security and scalability. Salary range : from 42K-80k euro per year in France, or equivalent in other countries. Our working language is in English and preferably the local language of the office. The team The most tech people of our Data & Consulting division, the title of ""Data engineer"" or ""Software engineer"" does not describe everything our amazing women and men can do: data engineering, operation management, security, cloud architecture, MLOps, and more. Presenting in each and every office of Artefact, working seamlessly with our consultants and data experts, our Data & Software engineers are the ones who make our data projects come true. Mission You will work with the team to identify your clients' needs and define innovative solutions of which you will be ownership from start to end. You manage both its conception and implementation, while also optimising the performance and scalability. You will also coach others, keep abreast of industry news/updates and get stuck into training sessions with our business partners and suppliers, such as Google & Amazon. You share your knowledge, learnings and success, with the capability of presenting and communicating. Desirable skills You are the master of several, or all the value chain's activities of the projects: cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, continuous integration and deployment; You have no problem popularizing technical terms or solutions to more business-oriented profiles, you can work in a team with very diversified profiles. You know how to prioritize your tasks, respect deadlines, and anticipate projects' risks. ... or soon you will be, contact us! Why should you join us Artefact is the place to be: come and build the future of data and marketing Innovation: We have a passion for creating impacting projects, and believe innovation can come from anyone. Action: We make things rather than telling people how to make them. Collaboration: We believe in bringing talented people together, in winning together, and in learning from each other. Come join us!","Artefact is a consulting firm specializing in AI and data, seeking a data or software engineer to work with clients to identify their needs and develop end-to-end solutions. The ideal candidate will have proficiency in various aspects of the project value chain, including cloud infrastructure and machine learning engineering, and will have the ability to communicate technical solutions to business-oriented profiles. With a passion for innovation and collaboration, Artefact offers an exciting opportunity to build the future of data and marketing. Salary ranges from 42K-80k euro per year.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
414,39629,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer-barcelona_barcelona,Data Engineer,Contentsquare,"{go,regard,ContentSquare,Go,color,Scala,Akka,AWS,Contentsquare,scale,Kafka,Elasticsearch,Spark,ClickHouse,Java}",NaN,"Barcelona, 08007","SaaS / Cloud Services, E-commerce",CDI,2022-11-29,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they’ve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe’s hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team – known as the CSquad – representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of passionate and talented developers, designing and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at ContentSquare ! We collect several billions events per day, and query hundreds of terabytes in real time. Your daily work will consist of: •Designing efficient architectures to store and analyze petabytes of data •Leading large scale projects and mentoring other developers •Implementing complex acquisition workflows •Thinking of smart data formats to serve the functionalities of the product, while minimizing the cost •Developing tools to help data-scientists ....by using some open source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have an interest in functional programming and seek to develop your skills in Data engineer programming languages. Kafka, Akka, Spark, AWS… You have had the chance to discover or work with these big data technologies. Ideally, you have some experience on a wide range of databases and you are interested in streaming. You would like to challenge yourself developing distributed infrastructure with a real time and data-intensive environment. You would like to share your skills and take part in technical choices. Why join ContentSquare’s Data Engineering team? •You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data •You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences •You are looking for an environment where you’ll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategical corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross team innovation days, we are committed to innovate towards tomorrow’s user experience. You’ll also have: flexible working hours, remote ; yoga, and many other activities; after work beers provided every Friday, monthly parties…and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare: ▪️ We’re humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ▪️ We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ▪️ We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ▪️ Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ▪️ Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ▪️ Work flexibility: hybrid and remote work policies. ▪️ Generous paid time-off policy (every location is different). ▪️ Immediate eligibility for birthing and non-birthing parental leave. ▪️ Wellbeing allowance. ▪️ Home Office Allowance. ▪️ A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ▪️ Every full-time employee receives stock options, allowing them to share in the company’s success. ▪️ We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don’t meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is seeking a data engineer to design and develop a new data architecture, including designing efficient architectures to analyze petabytes of data, leading large-scale projects, implementing complex acquisition workflows, and developing tools to help data scientists. The ideal candidate has 2-3 years of experience and is proficient in backend languages such as Scala, Java, or Go, as well as big data technologies such as Kafka, Akka, and Spark. The company offers a variety of cool projects, flexible work hours and remote working, career development opportunities, competitive benefits, and a friendly team.",Non spécifié,Entre 250 et 2000 salariés,> 2 ans,0,1,0.013848874720779208
295,56767,https://www.welcometothejungle.com/fr/companies/decilia/jobs/azure-data-engineer-h-f_boulogne-billancourt,Azure Data Engineer,Decilia,"{Microsoft,Databricks,Scala,Synapse,Spark,Azure,SQL,Python}",Télétravail ponctuel autorisé,"39, Rue de la Saussière, Boulogne-Billancourt, 92100",IT / Digital,CDI,2023-03-26,"Décilia est une ESN Gold Partner Microsoft. Spécialiste de la data depuis 14 ans, elle accompagne ses clients dans la réalisation de projets complexes et innovants. Poste : Azure Data Engineer (H/F) Type de contrat : CDI à plein temps Lieu : Normandie ou Ile de France Niveau d’expérience : confirmé Salaire : selon profil Décilia est une ESN Gold Partner Microsoft. Spécialiste de la data depuis 14 ans, nous accompagnons nos clients dans la réalisation de projets complexes et innovants. Dans le cadre de la croissance de nos activités, nous recrutons un(e) Azure Data Engineer. En tant que Azure Data Engineer , vous serez amené(e) pour le compte de nos clients à : Développer et optimiser des pipelines de données (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions, Assurer le recueil du besoin client Participer à la conception de Datalake, Travailler en étroite collaboration avec l’équipe architectes, Industrialiser des modèles de Machine Learning issus de notre entité Décilia Science Utiliser au quotidien la méthodologie SCRUM et DEVOPS Pourquoi nous rejoindre ? Décilia favorise la consolidation des connaissances de ses consultants par la formation et la multiplication des certifications ; Devenez référent d’une brique technologique, et à terme, animez une de nos squads ! Vous serez accompagné personnellement par un coach et boosterez vos compétences relationnelles ; Un grand nombre de vos missions seront en télétravail ; Bénéficiez d’un cadre de travail stimulant et bienveillant : 2 agences idéalement situées à Boulogne-Billancourt (Les Passages) et à Rouen Centre (Palais de Justice) Plusieurs événements internes organisés : séminaires, tech lunch, afterworks, team building,… Et intégrez une entreprise certifiée « Happy at Work » depuis 3 ans ! Environnement technique : Cloud : Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning) Langages: Python, Scala, SQL, C# Big Data : Spark, Databricks Niveau d’expérience : confirmé Et pour plus d’informations sur l’entreprise et son processus de recrutement n’hésitez pas à consulter notre site internet : Decilia.fr Si vous aimez les challenges, l’esprit d’équipe, la bonne humeur, rejoignez une société à taille humaine en postulant dès maintenant !!","Décilia, a Microsoft Gold Partner, is seeking an Azure Data Engineer with experience in developing and optimizing data pipelines and conducting elicitation of client needs. The candidate should have expertise in working with Microsoft Azure, Python, Scala, Spark, and Databricks. The company offers a stimulating work atmosphere, training, and certification opportunities, as well as a chance to become a technology reference and eventually lead a squad.",Bac +5 / Master,Entre 15 et 50 salariés,> 3 ans,1,0,0.013848874720779208
338,56797,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/support-engineer-data-exchange-f-m-d_croix_DT_VdMRw52,"Support Engineer, Data Exchange",Decathlon Digital,"{Solarwinds,splunk,SAP,Kafka,IBM}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, grâce à ses produits innovants et fort de sa culture reposant sur l’accessibilité, Decathlon ne cesse de réinventer le marché du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd’hui, nous tirons parti de cette culture de l’innovation et de notre expertise digitale pour qu’un public plus large puisse bénéficier des plaisirs du sport et ce, à l’aide de la technologie. Nous créons de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d’occasion, mais aussi services de location d’une large gamme de produits Decathlon et de partenaires. Notre objectif: créer un écosystème digital de produits et services. Nos équipes tech françaises implantées à Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert·e·s de la data, uni·e·s pour construire et faire évoluer nos produits dont le but unique est de répondre aux besoins de nos 500 millions d’utilisateurs. La BU Data Exchange La BU Data Exchange regroupe des équipes d'échanges de données sur nos technologies Webmethods, SAP PO, IBM MQ et Kafka. Notre mission : être garant du bon fonctionnement et de la création des échanges de données de l’intégralité du groupe au sein de notre système d'information et avec nos partenaires. REJOINS L'ÉQUIPE Data in Motion L'équipe Data In Motion est responsable des technologies de messaging : Webmethods, SAP PO et IBM MQ. Nous accompagnons la transformation digitale et permettons au SI de communiquer sur les domaines Logistique, Ecommerce, Retail, Supply, Finance, RH. Ce sont environ 200 millions de flux qui circulent par mois, grâce au travail de l’équipe. Dans le cadre de l’ouverture d’un poste en interne, nous recrutons un-e Ingénieur-e support, basé-e à Lille. TES RESPONSABILITÉS Prendre en compte les demandes des utilisateurs (incidents et tickets), support niveau 2 & 3 Anticiper les incidents (monitoring, proactivité) Diagnostiquer et qualifier les problèmes Déclencher les actions correctives, à son niveau directement, ou en alertant d’autres équipes, tout en priorisant les cas les plus critiques Vérifier le bon fonctionnement des développements envoyés en production Le périmètre technique : Nos Enterprise Service Bus (ESB) : SAP PI/PO, Webmethods, IBM MQ Échanges de données : (Rest, Idoc, API, FTP, SOAP, JMS, Proxy...) Monitoring : Solarwinds, splunk IT System Management JIRA Qui es-tu : Que tu sois ingénieur expérimenté.e ou débutant.e, nous saurons te former et t'accompagner dans ta progression Tu es orienté.e “Client” : animé.e par les besoins métiers et la satisfaction utilisateur Tu communiques avec aisance au sein de ton équipe, mais aussi auprès d’équipes tiers et tu sais d’adapter aux situations critiques / crises. Tu as une forte curiosité technique et envie d’apprendre pour travailler sur des sujets variés et analyser les problèmes afin de proposer des solutions à tes utilisateurs CE QUE NOUS OFFRONS 2 jours de télétravail par semaine Liberté de choix de l'outil de travail (Mac, Windows, Chromebooks) Équipe projet en local et partage avec le réseau mondial (parcours international) Montée en compétences et mentorat (diversité de projets, langages et technologies, certification, events) Formations internes et externes Actionnariat salarié Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de réinventer le sport de demain et de devenir la plus grande plateforme numérique sportive ? c’est l’objectif que nous nous fixons chez Decathlon. “Rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre” est notre mission depuis toujours. Une vocation qui atteint aujourd’hui son paroxysme en augmentant l’expérience du sport par les technologies et répondant aux besoins de nos 500 millions d’utilisateurs à travers le monde. Nous créons ainsi de nouvelles expériences pour les sportives et sportifs – coaching virtuel, programmes de fidélité, expériences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c’est aujourd’hui plus de 2500 profils techniques : software engineers, product managers, expert·e·s de la data, du Cloud et de la cybersécurité, en France et à l’étranger, implantées à Paris, Lille et Londres. Decathlon est engagé dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des séniors, de la mixité sociale, de l'égalité entre les femmes et les hommes. Nous recrutons avant tout des personnalités et la diversité au sein de nos équipes est un enjeu majeur car elle est source d’innovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon seeks an experienced or beginner Engineer Support to join the Data In Motion team responsible for messaging technology. The candidate will offer support, diagnose, and qualify problems, while being proactive in anticipating and addressing incidents. The engineer will also ensure the correct functioning of developments, including monitoring the performance of the system. The position is based in Lille, with the perk of working two days a week from home. Decathlon is an equal opportunity employer committed to diversity and inclusion.",Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
431,49637,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-dataops-h-f-innovative-tech_niort_DIT_xoPAMLM,Data Engineer - DataOps  - Innovative Tech,Devoteam Innovative Tech,"{scala,java,python,Databricks,k8s,Cloudera,linux,Docker,via,Kafka,Neo4J,Spark,Cassandra,Azure,Hadoop,Elastic}",NaN,"493 Avenue de Paris, Niort, 79000","IT / Digital, Stratégie, SaaS / Cloud Services",CDI,2023-02-07,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs stratégies de modernisation de plateformes. Face à l’avènement du Cloud et des nouvelles méthodes de travail qui en découlent, les DSI doivent aujourd’hui répondre à plusieurs enjeux majeurs pour être agiles, porteuses d’innovation, perçues comme un véritable “business partner” tout en ayant une gestion responsable de la consommation énergétique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant à adopter une posture créative et apprenante. Franck et ses équipes niortaises n'attendent que vous pour relever de nouveaux défis. Ensemble vous accompagnerez nos clients dans la transformation de leur projet vers la mise en œuvre et le déploiement de solutions data. Ce qu'on attend de vous ? Vous disposez d'au moins trois années d'expérience sur des sujets similaire en développement Hadoop/Spark et Ansible. Vous aimez travailler en mode Agile Vous avez cette double compétence Dev & Infra Vous exposez la donnée via des API, vous automatisez le provisionning/monitoring des environnements Data Ce qu'on vous apportera ? Un manager à vos côtés en toute circonstance Une communauté Data France où vous trouverez votre place : Ideation Lab, Hackathon, Meetup ... Un parcours de formation et de certification via “myDevoteam Academy” sur les technologies du moment et à venir : Azure Data, Databricks, Spark, Elastic.io, Neo4J, Kafka, Cloudera, Cassandra, Ansible, Docker, k8s … La possibilité de vous i nvestir personnellement : être formateur interne, leader de communauté, participer aux entretiens candidats, aider à développer nos offres et pourquoi pas manager ta propre équipe ... Expert dans le domaine de la Data : 3 à 5 ans d’expérience post diplôme Ecole d’ingénieurs ou Master 2 en informatique Des certifications seront un plus spécialement sur Spark, Azure, Databricks Une double compétence dév (java, scala, python) infra (linux, ansible, k8s) Une bonne connaissance des API Rest et microservices Un excellent relationnel, vous aimez travailler en équipe and you are fluent in english , indeed ! Alors n'hésitez pas à répondre à l'annonce de @Margaux et rejoignez la communauté Devoteam ! Le saviez-vous? Le Groupe Devoteam œuvre pour l'égalité des chances, pour la promotion au mérite de ses collaboratrices et de ses collaborateurs et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.","Devoteam Innovative Tech is seeking an experienced Data Expert with a strong background in Hadoop/Spark development, Ansible, DevOps, and API exposure for a transformational role in Niort. The ideal candidate must have experience working in Agile environments, a double skillset in both development and infrastructure, a good understanding of REST APIs and microservices, and excellent communication skills. This role offers opportunities to work with cutting-edge technology, continuous learning through training and certification, personal development, and be part of Devoteam’s growing data community. The company also promotes equal opportunity, inclusivity, and diversity in the workplace, and all positions are open to people with disabilities.",N,N,N,0,1,0.013848874720779208
430,48019,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-h-f-innovative-tech_lille_DIT_Aw2zX8D,Data Engineer  - Innovative Tech,Devoteam Innovative Tech,"{DataStudio,Looker,Keras,TensorFlow,AWS,QlikView,GCP,Tableau}",NaN,"8 Rue Anatole France, Lille, 59800","IT / Digital, Stratégie, SaaS / Cloud Services",CDI,2023-02-05,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs stratégies de modernisation de plateformes. Face à l’avènement du Cloud et des nouvelles méthodes de travail qui en découlent, les DSI doivent aujourd’hui répondre à plusieurs enjeux majeurs pour être agiles, porteuses d’innovation, perçues comme un véritable “business partner” tout en ayant une gestion responsable de la consommation énergétique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant à adopter une posture créative et apprenante. L'équipe lilloise n’attendent que toi pour relever de nouveaux défis. Ensemble nous accompagnerons nos clients dans la transformation de leur projet. Tes missions si tu l’acceptes : Accompagner les grands comptes dans leur projet de mise en place de projets Data avec GCP, AWS ou tout autre système Big data. Analyser les besoins clients : Animer des ateliers Préconiser des architectures cibles Rédiger des dossiers d'architecture et spécifications techniques Définir les méthodologies de déploiement et plans de migration Construire les architectures de données : Concevoir et mettre en place des systèmes de données résilients et sécurisés Construire et déployer les pipelines de données (ETL) Assurer la migration des données vers les nouveaux environnements Analyser les données : Analyser les données sources afin d’identifier et évaluer des cas d’usage métier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…) Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les équipes clients aux méthodes et concepts du cloud Diplômé(e) d’une école d’ingénieurs ou d’un Master 2 en informatique , tu souhaites t'investir dans une équipe dynamique, passionnée et aux valeurs humaines. And You are fluent in english ! Tu es désireux (se) de t'investir dans des projets challengeants et gagner rapidement en responsabilités. Rejoigne la tribu ! Tu veux en savoir plus? Viens échanger directement avec nos ambassadeurs . Le Groupe Devoteam oeuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme dediscrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation.","Devoteam Innovative Tech seeks a data architect to work with big data systems such as GCP and AWS while accompanying clients in their data-related transformations. The ideal candidate has experience in data analysis and integration, building secure data pipelines, providing methodologies for deployment, and is familiar with BI and visualization applications. The candidate must also be fluent in English, hold a Master's degree in computer science or engineering, and have a passion for working in a dynamic and innovative team. The company is committed to equality and fighting against discrimination.",N,N,N,0,1,0.013848874720779208
125,73151,https://www.welcometothejungle.com/fr/companies/armee-de-l-air-et-de-l-espace/jobs/responsable-data-engineer_bordeaux_ADLEDL_kAXRjpz,Responsable Data engineer,armée de l'Air et de l'Espace,{},NaN,"Bordeaux, 33000, Gironde, Nouvelle-Aquitaine, France",Administration publique,CDD / Temporaire,2023-04-22,"Créée en 1934, l’Armée de l’Air est devenue l’armée de l’Air et de l’Espace 🛩🛰 le 11 septembre 2020. 🧑‍✈️ 365 jours par an, 7 jours/7, 24 heures/24, les femmes et les hommes de l’armée la plus féminisée (24%) assurent avec détermination la protection des français. ➡ Pilotes, mécaniciens, contrôleurs aériens, fusiliers commandos, pompiers, spécialistes de l’infrastructure, informaticiens, sauveteurs: ils participent tous au succès des opérations aériennes. Vous êtes chargé(e) : - De piloter et réaliser des extractions de données issues des Systèmes d’Information (SI) du MCO-A De piloter et superviser les activités de Reprise de Données (RdD) produites par l’équipe Datafactory De piloter l’analyse et la mise en cohérence des données De travailler en partenariat avec les équipes “catalogue” et “qualité des données” De s’assurer, en relation avec les industriels, de l’adéquation de la fourniture des données Données non contractuelles. · Période de formation initiale ~ 1.328 € net · Aspirant ~ 1.408 € net (à l’issue de la formation militaire initiale) · Sous-lieutenant ~ 1.810 € net (à partir de 6 mois d’aspirant) · Lieutenant ~ 1.958 € net (après 1 an de sous-lieutenant) \ À titre indicatif, hors primes et indemnités ; solde pour un célibataire sans enfant logé sur base.* L’accès à chaque grade est soumis à la parution d’un décret de nomination. Vous justifiez d’un bac** +3 ou équivalent dans le domaine Data** Vous avez la nationalité française Vous avez moins de 30 ans à la date de signature du contrat",,Bac +3,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
40,73087,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/an-apprentice-12-24-months-data-engineering-m-f_paris_SANOF_GRXgZ3X,An apprentice - 12/24 months – Data Engineering,Sanofi,"{Python,Scala,JavaScript,NoSQL,SQL}",NaN,"54 Rue la Boétie, Paris, 75008",Pharmaceutique / Biotechnologique,CDI,2023-04-22,"At Sanofi, we pursue the miracles of science to improve people’s lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi’s roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Sanofi is dedicated to supporting people through their health challenges. We are a global biopharmaceutical company focused on human health. We prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. We stand by the few who suffer from rare diseases and the millions with long-term chronic conditions. With more than 100,000 people in 100 countries, Sanofi is transforming scientific innovation into healthcare solutions around the globe. Sanofi, Empowering Life In this context, Sanofi is looking for: AN APPRENTICE – DATA ENGINEERING (M/F) Location: Paris (XVIIe) Assignment : Within the Digital Health Department and in connection with your tutor, you will participate in an international project on a high-impact drug. In this context, your missions will consist in: Support connected ecosystem solutions such as patients’ glycemic control and full disease management, leveraging connected pens, Help building symptom checking apps able to understand diseases and track symptoms, Participate in creating remote treatment solutions to provide individual recommendations, accessible by anyone, anytime, anywhere, Support personalized care models, informed by Artificial Intelligence, to identify symptoms’ early signals and recommend corrective actions to the patient and the care giver. Required profile : You are looking for an apprenticeship contract of 12/24 months , starting between September and October 2023 as part of a training of level BAC +4/+5 or equivalent in Computer Science, Engineering with math background. For this position, you justify a first experience or knowledge of programing languages such as Python, Scala and different database systems such as SQL, NoSQL. Knowledge in JavaScript is a plus. Self-starting and self-motivating team player, your rigor and your analytical mind allow you to carry out your missions. Open-minded, you enjoy working in a team and interacting on transversal topics. If you are interested in our mission, send us a CV and cover letter. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.",,Bac +4,N,Non spécifié,0,1,0.013848874720779208
251,2447,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris_paris,Software engineer Data Presentation - Paris,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we’ve set out to build the future of AI. Let’s do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let’s face it — there’s nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented — you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you’ve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku’s culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it’s what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don’t get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku, a platform for Everyday AI, is seeking a talented software engineer to create usable, intuitive and visually appealing user interfaces and their scalable engines for Dataiku DSS. The ideal candidate should be comfortable with both front-end and back-end development, understand customer needs and have experience building a real product. Dataiku's platform combines big data and AI technologies to empower data scientists and business analysts, and the company has more than 900 employees across the globe, with offices and remote workers.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
44,61889,https://www.welcometothejungle.com/fr/companies/betclic/jobs/data-engineering-manager-h-f_bordeaux,Data Engineering Manager,Betclic Group,"{durable,TABLEAU,Talend,SNOWFLAKE,DBT,Uber,Snowflake,Azure,AtScale,SQL,Tableau}",NaN,"117 Quai de Bacalan, Bordeaux, 33300",Application mobile,Autres,2023-03-30,"Entreprise française leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c’est : 🧑‍🤝‍🧑 11 millions de joueurs vibrants au rythme des compétitions sportives ⭐️ Une offre très large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ⚽️ Plus de 50 sports ouverts aux paris 📅 300 000 évènements sportifs disponibles aux paris chaque année 🖥 60 000 évènements sportifs diffusés en live chaque mois 🎰 Plus de 3 000 jeux de casino à expérimenter 🃏 Plus de 2 millions de parties de poker jouées chaque mois 🚀 De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l’UBB, les Boxers de Bordeaux… Depuis sa création en 2005, Betclic est une société de technologie “mobile-only”, animée par une passion inébranlable pour le sport. Guidé par l’émotion et le plaisir du jeu, Betclic développe des applications de divertissement mobile et place ses clients au cœur d’une expérience de jeu unique en innovant avec agilité et rapidité pour offrir toujours plus de jeux et plus de fun à ses joueurs. Notre ambition ? Proposer à nos clients l’expérience de jeu la plus divertissante grâce à des applications simples, immersives et innovantes. Betclic, dont le siège est à Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalités parmi ses 800 collaborateurs répartis dans 5 pays d’Europe : France, Italie, Malte, Pologne, et Portugal. WE ARE BETCLIC Entreprise française leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c'est :• ‍‍ 11 millions de joueurs vibrants au rythme des compétitions sportives • ⭐ Une offre très large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne• ⚽ Plus de 50 sports ouverts aux paris • 300 000 évènements sportifs disponibles aux paris chaque année • 60 000 évènements sportifs diffusés en live chaque mois • Plus de 3 000 jeux de casino à expérimenter• Plus de 2 millions de parties de poker jouées chaque mois• De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l'UBB, les Boxers de Bordeaux…Depuis sa création en 2005, Betclic est une société de technologie ""mobile-only"", animée par une passion inébranlable pour le sport. Guidé par l'émotion et le plaisir du jeu, Betclic développe des applications de divertissement mobile et place ses clients au cœur d'une expérience de jeu unique en innovant avec agilité et rapidité pour offrir toujours plus de jeux et plus de fun à ses joueurs. Notre ambition ? Proposer à nos clients l'expérience de jeu la plus divertissante grâce à des applications simples, immersives et innovantes.Betclic, dont le siège est à Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalités parmi ses 800 collaborateurs répartis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal. Les profils recherchés sont ceux qui ont l'ambition de construire en équipe, qui sont prêts à relever des challenges tous plus passionnants les uns que les autres, et qui ont cette volonté de créer des solutions offrant une expérience client inédite. L'univers du sport et du jeu vous fait vibrer ? Vous aimez les défis et participer à l'effort collectif ? Betclic vous propose de rejoindre l'aventure !#JoinBetclic #WeAreBetclic Chez Betclic, la transformation DATA est toujours en marche et s'accélère. Nos Apps sont à la pointe de ce qui se fait dans notre industrie digitale et évoluent sans cesse. La bonne gestion de la DATA devient un des principaux leviers d'accélération de nos activités. Au sein de l'équipe DATA FABRIC vous serez au cœur de l'activité : offre, jeux, protection du joueur, sécurité, performance des plateformes, régulation, marketing, analytics, excellence opérationnelle, etc… Avec la DATA, Betclic casse les codes. Fini le monolithe traditionnel. Place aux DATA PRODUCTS, à la donnée et à une organisation distribuées au plus près des équipes Produit et des équipes Métier. ENTER THE GAME Envie de participer à la transformation DATA de Betclic ? Envie de concevoir des outils de pilotage pour aider les équipes Business à devenir DATA-DRIVEN ? En tant qu'expert en Data (Engineering et Business Intelligence), vous aimez partager votre savoir, votre expérience et votre vision. Vous souhaitez développer votre leadership, dans ce contexte nous recherchons notre futur Data Engineering Manager, qui prendra en charge une équipe de 3-4 Data/BI Engineers. Grace à votre expertise vous pourrez continuer à contribuer au design et au delivery et ainsi développer vos compétences TECH. Votre équipe est intégrée dans une organisation en Data Squad (Data Mesh) au service d'un domaine Métier. Ces Data Squads regroupent, en plus de l'expertise en ingénierie dont vous aurez la responsabilité, des analystes, des scientistes, des MLOps. Les équipes Tech Betclic sont organisées autour des principes de développement agiles et s'organisent en squad et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique. Grâce à cette organisation chaque Squad a la responsabilité de A à Z de ses projets : développement, livraison, suivi de production. You build it, you run it, you own it ! Votre quotidien sera de travailler avec un large éventail de technologies innovantes telles que Snowflake, Stacks Amazon et Azure, Tableau, Talend, DBT Cloud, AtScale, en particulier. Et par conséquent d'assurer le maintien des compétences de votre équipe. Vous participerez au développement de l'écosystème DATA de Betclic permettant à la compagnie d'avoir toujours une meilleure vision de son activité et un réel avantage concurrentiel. Vous contribuerez au virage pris par Betclic qui vise à décupler la création de DATA PRODUCTS à forte valeur ajoutée et ainsi accompagner le développement de l'offre et du produit Betclic. YOUR ROLE WITHIN BETCLIC Dans ce contexte; vos missions sont les suivantes: Manager une équipe de 3-4 Ingénieurs BI/Data Collaborer avec l'équipe d'ingénieurs BI/Data pour aider à la conception, au delivery (modélisation, flux DATA. processus d'automatisation, …) Concevoir, implémenter et gérer les nombreux KPI de l'entreprise Offrir des conseils stratégiques aux différentes équipes de Betclic sur l'optimisation des résultats et de leur données Superviser les processus de Version Control et de QA pour garantir l'exactitude et la qualité des données du delivery de votre équipe Garantir un haut niveau de qualité de service (QOS/SLA) des DATA PRODUCTS dont votre équipe a la charge Concevoir et mettre en œuvre de nouveaux tableaux de bord intuitifs et innovants (sur desktop et mobile) Surveiller et résoudre les problèmes opérationnels ou de données (Incident Management, Problem Management) Garantir la disponibilité et la fiabilité des données dans les délais prévus Participer aux astreintes liées à nos activités/livrables stratégiques WHO WE ARE LOOKING FOR? Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, un amour pour la technique, un peu de zèle et une réelle passion pour leur métier ! Ce job est fait pour vous si: Vous avez une expérience réussie de 4 ans minimum en tant qu'ingénieur BI/Data Votre leadership vous a déjà permis de vous exprimer, de vous positionner comme un manager, un décideur. Vous aimez échanger, négocier, convaincre autour de vous. Vous avez un sens de l'écoute exacerbé. Vous aimez rendre service et relever les challenges. Vous pouvez justifier d'un grande aisance et autonomie dans la conduite des sujets que vous prenez en charge. Vous avez un gout prononcé pour les échanges et la collaboration intra/inter-équipes. Vous savez communiquer en Anglais Vous maitrisez l'utilisation de plusieurs bases de données (en particulier SNOWFLAKE) et de technologie d'intégration de données (ELT/ETL) Vous maitrisez SQL et êtes expérimenté dans l'utilisation de bases de données relationnelles, dans la création de requêtes optimisées Vous avez l'habitude d'utiliser des outils de Dataviz tel que TABLEAU Vous vous intéressez aux architectures et univers cloud Une affinité avec l'univers du pari sportif et du sport en général est un plus WHAT CAN YOU EXPECT? Un package de rémunération attractif25 jours de congés payés et 10 jours de repos compensateursUne carte Ticket Restaurant® financée à hauteur de 50% (10€/ jour)Une mutuelle d'entreprise prise en charge à 100% pour vous et vos enfants Un abonnement de transport pris en charge à hauteur de 50% ou une prime annuelle de mobilité durable (200€ pour les trajets domicile – travail en transport durable)Un pack mobilité (aide au déménagement) Une flexibilité de travail encadrée par un accord sur le télétravailUn souci constant de développement des compétences avec un programme de formation annuel personnaliséDes évolutions de carrière dans un environnement internationalDes locaux hors du commun avec un rooftop aménagé pour profiter d'animations régulières, de pauses et de déjeuners au soleil face à la Cité du VinDes cours de sports 2 fois par semaineEt l'opportunité de travailler dans une atmosphère conviviale, jeune et fun !Poste en CDI à pourvoir dès que possible à BordeauxBetclic Group - 117 quai de Bacalan 33300 BORDEAUX Tous nos postes sont ouverts aux personnes en situation de handicap.","Betclic, a French leader in sports betting and online gaming, is seeking a Data Engineering Manager to join their Data Fabric team. The ideal candidate will have at least 4 years of experience as a BI/data engineer and possess strong leadership skills. Responsibilities include managing a team of 3-4 BI/data engineers, collaborating with teams to design and deliver KPIs, offering strategic advice, and ensuring data quality and availability. Betclic offers a competitive compensation package, flexible work arrangements, and a fun, international work environment.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
344,56529,https://www.welcometothejungle.com/fr/companies/aircall/jobs/senior-data-analytics-engineer_madrid,Data Visualization Engineer,Aircall,"{Kinesis,Flink,GitLab,Redshift,Airflow,Looker,Lambda,AWS,Spark,SQL}",NaN,"Madrid, 28014","SaaS / Cloud Services, Electronique / Télécommunications",CDI,2023-03-26,"Aircall is on a mission to revolutionize the business phone industry! We exist to empower every professional to have richer conversations. We provide an entirely cloud-based voice solution, which seamlessly integrates with popular productivity and helpdesk tools. We have raised more than $220 million since 2015, and our base of 8000+ customers (and growing) is at our forefront. Behind our product are the amazing teams driving it, split between Paris, New York, Sydney, Madrid, London, Berlin and remote locations. Despite our distance, we all work together to drive our product! Aircall is a place where voices are valued. Backed by over $220 million of investment since 2015, we create technology that fuels accessible, transparent and collaborative communication to empower our base of 14,000+ customers (and growing) to make authentic, human connections. Conversation is a cornerstone of our culture. Wherever our people find themselves in the Aircall world – Paris, New York, Sydney, Madrid, London, Berlin, Tel Aviv, or at home – everyone has a voice that is valued. Whatever your background, wherever you’re from – we want you to join the conversation. Let’s talk. We are looking for an engaged and passionate Data & Analytics Senior Engineer to join our growing Engineering Team. **This position can be fully remote within Europe** Your role at Aircall: - Design & build great analytics solutions for our 10000+ customers across the world - Design & maintain easy to use data models, ensuring their quality - Design & develop reliable data pipelines and be accountable for them - Maintain data model documentations & definitions available to all in our Data Catalog, allowing easy understanding of our data warehouse - Influence product and cross-functional teams to identify data opportunities to drive impact. - Mentor team members through giving and receiving actionable feedback. Our stack: - AWS (Lambda, SQS, Kinesis, Redshift), Airflow, Flink, Spark, Looker, - A continuous deployment process based on GitLab A little more about you: - A Bachelor's degree in a technical field (eg. computer science or mathematics). - 3+ years experience in the data warehouse space, ETL design, implementation and maintenance - Proven experience with schema design and dimensional data modeling - Proficient in SQL and working with Looker/LookML (or equivalent technologies) - Shipping and maintaining code in production. - You like sharing your ideas, and you're open-minded. We love to take care of our people and offer the following benefits: 💻 Full remote 🏥 Medical insurance for you and your family 🍔 9€/day meal allowance 💪 45€/month for Gym expenses 🏖️ 25 days off 👶 150€/month allowance per child < 10 years of age 📈 Stock options to be part of Aircall's success. Aircall is constantly moving forward. We’re building new roads to complete our journey, and we’re taking people with us who have the same builder mentality. Let’s grow together: Aircall is a place for those who dare to be bold and seek responsibility, excellence, and the opportunity to push themselves to new heights. We’re creating a place where great people trust one another and thrive together. People flourish at Aircall and now is the time to be part of the team and the journey we’re on. Why join us? 🚀 Key moment to join Aircall in terms of growth and opportunities 💆‍♀️ Our people matter, work-life balance is important at Aircall 📚 Fast-learning environment, entrepreneurial and strong team spirit 🌍 45+ Nationalities: cosmopolite & multi-cultural mindset 💶 Competitive salary package & benefits DE&I Statement: At Aircall, we believe diversity, equity and inclusion – irrespective of origins, identity, background and orientations – are core to our journey. We pride ourselves on promoting active inclusion within our business to foster a strong sense of belonging for all. We’re working to create a place filled with diverse people who can enrich and learn from one another. We’re committed to ensuring that everyone not only has a seat at the table but is valued and respected at it by providing equal opportunities to develop and thrive. We will constantly challenge ourselves to make sure that we live up to our ambitions around diversity, equity and inclusion, and keep this conversation open. Above all else, we understand and acknowledge that we have work to do and much to learn. Want to know more about candidate privacy? Find our Candidate Privacy Notice here.","Aircall is seeking a Data & Analytics Senior Engineer to design, build and develop analytics solutions for the company's growing customer base, providing data expertise and insight to drive impactful decision making. The successful candidate should have experience in data warehousing, ETL design, and a strong proficiency in SQL and Looker/LookML, as well as a technical Bachelor's degree. Aircall offers full remote working and competitive benefits, including medical insurance, a 25-day annual leave allowance, and gym and meal allowances. The company is committed to promoting diversity, equity, and inclusion in its workforce, creating a strong sense of belonging for all.",Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
117,73309,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad-copy_berlin,Data Engineering Manager - Customer squad,Back Market,"{Python,Scala,Datadog,Lambda,via,Spark,color,AWS,dynamodb,GCP}",NaN,"Berlin, 10117","Environnement / Développement durable, Économie collaborative, E-commerce",CDI,2023-04-22,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world’s leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of more than 1,000,000 tons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: “be a coach not a dictator” is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc… - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We’re here to SABOTAGE: It’s our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team. Back Market is helping to address one of the biggest challenges of our time: climate change. We take this so seriously that we were awarded status as a “Société à Mission”, or company with a social mission, by the French government. We know we can’t tackle a global problem without a globally representative team so we are committed to embedding diversity, equity and inclusion principles in every aspect of our organization. But more importantly, being One Loving & Free Spirited Tribe is in our DNA as it is one of the five foundational values of our company since we got started way back in 2014. We are committed to hiring and supporting diverse teams of people from all backgrounds, experiences, and perspectives. We know our lofty goals cannot be reached unless everyone has a seat at the table along with the resources and opportunity to grow.",,Non spécifié,Entre 250 et 2000 salariés,Non spécifié,0,1,0.013848874720779208
349,11205,https://www.welcometothejungle.com/fr/companies/d2si/jobs/data-engineer_paris,Data Engineer,Devoteam Revolve,"{NoSQL,Jenkins,Scala,AWS,Docker,via,Spark,GCP,Java,SQL,Hadoop,Python}",NaN,Paris,"IT / Digital, SaaS / Cloud Services",CDI,2022-01-25,"Les équipes de Devoteam Revolve travaillent en partenariat avec les DSI, les entités digitales et les métiers pour les accompagner dans leur transformation numérique . Spécialistes du Cloud et du DevOps , nos consultantes et consultants travaillent en co-création avec nos client·es, le Cloud étant le terrain de jeu propice à cette transformation. Les collaborateurs et collaboratrices de Devoteam Revolve posent ainsi les bases de nouvelles méthodes de travail et de collaboration au travers notamment du mentoring et de l’apprentissage entre pairs. Passionné.e par le Big Data, vous êtes convaincu.e que le cloud est l’environnement naturel des systèmes Big Data ? Ça tombe bien, nous aussi. Rejoignez la #teamD2SI ! Au sein de D2SI, nous évoluons dans un contexte pur cloud, qui vous permettra de travailler sur des sujets de data engineering sur des plateformes cloud AWS ou/et GCP . Vous travaillerez sur des problématiques métiers de big data en collaboration avec les data scientists, les data analysts, les équipes BI et équipes infra…. En tant que Data Engineer vous devrez développer, construire et maintenir des pipelines de data. Votre rôle sera en quelques sortes de créer un outillage sur mesure qui permettra d’extraire, transformer et injecter toutes sortes de données dans l’entreprise via un Datalake ou des BDD ! Pour mener à bien votre mission, la maîtrise de Python est un prérequis, celles de Spark, Scala ou Java sont fortement recommandées ainsi que les bonnes pratiques de développement. Vous aimez également évoluer dans un écosystème Hadoop et vous avez une connaissance générale des BDD SQL et NoSQL pour extraire la donnée. Enfin des connaissances d’outils DevOps sont appréciés tel que Docker, outils de CI/CD tel que Jenkins… 1 - Entretien RH - parce que travailler ensemble veut dire se connaître, se comprendre, et s’accorder 2 - Entretien Tech - parce que le meilleur moyen de se challenger, c’est de se rencontrer 3 - Entretien Final - parce que l’on-boarding de nos nouvelles recrues doit se faire de manière qualitative Ce contenu est bloqué Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","Data Engineer with expertise in Python, Spark, Scala or Java, and strong knowledge of Big Data ecosystems like Hadoop and SQL and NoSQL databases, is required to join Devoteam Revolve's Cloud and DevOps specialized team, working on big data projects in collaboration with data scientists, data analysts, BI teams, and infrastructure teams. Candidates should also have knowledge of DevOps tools like Docker and CI/CD tools like Jenkins.",N,N,N,0,1,0.013848874720779208
47,67465,https://www.welcometothejungle.com/fr/companies/mars-france/jobs/site-ie-data-engineer-f-m-x_cambrai,Site IE Data Engineer X),MARS,"{color,via,regard}",NaN,"Cambrai, 59400","Grande distribution, Agroalimentaire / Nutrition animale, Distribution sélective, Grande consommation",CDI,2023-04-07,"M&M’S®, Twix®, Royal Canin®, Ben’s Original®, Pedigree® Skittles®, Whiskas® - Mars abrite certaines des marques les plus connues au monde. Chaque jour, les 130 000 associés de Mars dans le monde ont l’occasion de travailler dans les secteurs de la confiserie, des repas familiaux, des produits pour animaux de compagnie, des services vétérinaires et bien plus encore. Mais ce qui distingue MARS, c’est son objectif. Mars est une entreprise familiale, et fière de l’être, depuis plus de 100 ans. C’est grâce à cette indépendance que MARS peut penser en termes de générations, et non de trimestres, afin d’investir dans l’avenir à long terme de l’entreprise, de ses collaborateurs et de notre planète tout en restant fidèles aux mêmes principes éprouvés. Chez Mars, nous pensons en termes de générations, mais nous traitons chaque jour comme une opportunité d’œuvrer pour le monde que nous voulons. Unis par notre ambition de faire la différence, nous travaillons avec détermination, intégrité et vision - en combinant nos diverses compétences pour façonner l’avenir de certaines des marques les plus appréciées au monde. Alors, préparez-vous à saisir toutes les opportunités, à prendre des responsabilités et à avoir un réel impact. Job Description: Site IE Data Engineer (F/M/X) Royal Canin Location : Cambrai (1 hour from Lille) Contract : Permanent The Site IE data engineer will partner with the site teams; Production Manager, Technical Manager … to develop and execute the overall site F I activities through Mars Supply Excellence and supporting all pillar s in the day-to-day activities to improve site performance by improving data management. He/she will be responsible for all data reporting and 1st level analysis related to site performance KPI reporting and benchmarks and will be the 1 st contact for all data reporting system for improvement and new tool s implementation . The role is responsible for data integrity and adherence to the established ways of calculation , management (through tools … ) and reporting. What are we looking for? Process Management experience with analytic and priority setting capabilities Ability to solve problems and influence with a strong customer focus 3 to 5 years experience in Supply (Manufacturing) with a collaborative approach Experience in Lean and TPM with strong communication skills Fluent in French & English University degree in Ind. Engineering, Engineering or equivalent qualification What would be your key responsibilities? Proactive for associate Safety , QFS and SIG roadmap Daily, weekly, periodically and annual data reporting for line performance such as TRS/OEE by line and equipment including the different element that builds the TRS/OEE reports. As well as for lines speeds, flowrates, NQC elements such as (run setup, re-use, destruction). This will also applied to data required such as MTBF, MTBR, MTBS… for selected lines within the site MSE deployment plan Responsible to prepare the data in such a way that could provide ability to drill down and identify root causes for downtimes working closely with the site teams Maintains and ensures the accuracy of the data within the designated tools/systems while supporting new tool implementation, setting up recommendation to improve. Support testing and implementation of new systems and enhancements such as automating KPI calculations and performance reporting and display Deliver tangible savings from continuous improvement projects / FI activities identified by the operation team and other supporting functions . independently elaborate and implement improvement proposals and where necessary, with various departments such as HSE, RI, Q&FS, PPTS, US team (DD team and TLs) all this in collaboration with the operators Active member of local & regional IE/MSE team, give functional support to the team when it ‘s needed. What can you expect from Mars? At Mars, we believe in a relationship of mutual trust, dignity and respect between our company and Associates that is more meaningful than the standard employer/employee relationship. As Associates, we can expect to be respected, supported and valued as individuals, to be treated fairly and equitably. ​ Royal Canin's CSR commitments, to build a better world for tomorrow: Since 2015, no waste to landfill is made by the 16 Royal Canin factories in the world ​ All Royal Canin products manufactured in Europe are ISO 14001 certified from design to factory gate Since 2017, Royal Canin has supported the K-DOG program of the Curie Institute, which trains dogs to detect breast cancer via olfaction. #LI-NM1 #LI-Onsite Mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. The company is pleased to provide such assistance, and no applicant will be penalized as a result of such a request.",,Non spécifié,> 2000 salariés,Non spécifié,0,1,0.013848874720779208
235,11382,https://www.welcometothejungle.com/fr/companies/april-technologies/jobs/data-analyst-f-h-paris-5746_paris,DATA Engineer  - PARIS,APRIL,"{Oracle,SAS,Qlik,Talend,via,R,Java,NoSQL,SQL,Python,Tableau}",NaN,Paris,"Assurance, Big Data, Logiciels",CDI,2022-01-25,"April est numéro 1 du courtage d’assurance en France, animé par un esprit d’innovation et de “pionnier’ depuis sa création. Nous accompagnons plus de 14,000 intermédiaires d’assurance. APRIL conçoit, distribue et gère des solutions spécialisées d’assurance ainsi que des prestations d’assistance pour ses partenaires et clients particuliers, professionnels et entreprises. Notre mission est de rendre la souscription d’assurance des particuliers et professionnels la plus simple et rapide possible, pour les courtiers comme pour les assurés. Pour atteindre cet objectif nous construisons une plateforme digitale multicanale innovante et proposant une expérience utilisateur de haut niveau, quel que soit le produit souscrit. L’équipe en charge du développement business et technologique de cette plateforme et son expansion est en pleine croissance. Très orientée tech, digital et UX, nous sommes animés par la volonté de faire de notre infrastructure Front une référence afin de rendre la plus scalable et performante possible. Notre challenge actuel ? Répondre aux attentes d’innovation de notre base d’utilisateurs (la plus grande de France) tout en maintenant un haut niveau de qualité technique et d’expérience. Pour atteindre cette ambition, nous souhaitons nous appuyer sur une plateforme tech de haut niveau. Pourquoi travailler avec nous ? Vous bénéficierez des moyens et réseaux d’un groupe d’envergure tout en évoluant dans un environnement hyper dynamique. Très responsabilisé, vous pourrez être impliqué dans la conception technique de la plateforme et aurez la possibilité de faire monter en compétence votre équipe. Vous développerez une expertise très rapidement et la mettrez en œuvre dans une équipe multidisciplinaire. Venez travailler et exploiter les différentes sources de données afin de réaliser, présenter et communiquer des analyses métiers avancées. Votre objectif : éclairer et objectiver les prises de décisions des différentes parties prenantes de l'entreprise. Et si être « DATA Analyst » chez APRIL vous permettait … de choisir un métier dont vous pourrez être fier : «accompagner et protéger à chaque moment qui compte, simplement» telle est la mission et la raison d’être partagée par l’ensemble de nos collaborateurs, de développer votre expertise dans un environnement en pleine transformation, au carrefour de l’innovation et de l’expérience client : notre ambition à horizon 2023, être un acteur digital, omnicanal et agile, champion de l'expérience client, de vous engager au sein d'une entreprise engagée : nous rejoindre, c’est faire partie d’un Groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de 4 axes (santé, aidants, éducation et environnement) avec un impact sociétal positif et réel. Nous nous engageons à promouvoir des emplois respectant la diversité et la différence, ouverts à chacun. Vos futures missions : 1. Gestion des données et support à la décision contribuer à la mise en œuvre d’une plateforme Data fiable, agile et sécurisée permettant d’orchestrer des données issues du Back Office, participer aux ateliers d'expression des besoins internes métiers comprendre leurs problématiques et les traduire de manière analytique, extraire les données nécessaires à l'analyse, analyser les données (modèles et tests statistiques) restituer les résultats des analyses sous forme de tableaux de bord ou au travers d'outils de data vision, échanger sur les résultats et les solutions avec les équipes métiers, participer au contrôle de la qualité des données tout au long de leurs traitements, Participer aux audits assureurs, Maintenance et évolution des outils existants (Extractions via Talend/ SQL/ PLSQL/ Reporting Tableau & Power BI) Participer à la clôture comptable : Lancement des outils comptable, analyser les résultats dans leurs grandes masses pour vérifier l’intégrité des données. 2. Veille et développement de l'activité contribuer à la promotion de la culture DATA au sein de l'entreprise, assurer une veille technologique sur les outils d'analyse de la donnée et proposer des améliorations sur les process existants. Cette opportunité est à pourvoir dans le cadre d’un remplacement . Directement rattaché.e à Omar , Responsable de développement informatique , vous rejoindrez notre équipe Parisienne composée de 4 collaborateurs. Dès votre arrivée, vous bénéficierez d'un parcours d'intégration pour favoriser votre prise de poste. Une fois autonome dans vos missions, vous pourrez bénéficier de notre accord télétravail. Vous disposez au minimum d'un Bac +5 en informatique, vous possédez une expérience professionnelle de 3 ans concluante en tant que Data Analyst, idéalement dans le secteur de l'assurance ou de la banque. Vous pourrez également mettre à profit : vos compétences techniques : techniques statistiques, gestion de bases de données, outils de bases de données (Ex : SQL/ NoSQL/PLSQL), SGBD relationnels (Oracle, SQL Server), ETL (Talend), langages de programmation (Ex : Java, SQL, Python, R, SAS etc.), Excel VBA, outils de visualisation (Qlik, Tableau, Power BI), connaissance du RGPD, connaissance des principes de cybersécurité. La connaissance du modèle de données du progiciel Cleva et Salesforce, vos compétences transverses : capacité d'analyse et de synthèse, rigueur, orientation client, adaptabilité, capacité d'organisation et de planification, travail en équipe et en transverse, communication écrite, communication orale, la pratique de l’anglais professionnel sera un plus. Cette opportunité est faite pour vous ? N'attendez plus pour postuler en nous adressant votre CV accompagné de quelques lignes sur votre projet professionnel et ce qui pourrait vous épanouir aujourd'hui. Ce sera la première étape de notre processus de recrutement. Si vous n’êtes pas sûr(e) que cette offre soit LA bonne, d’autres postes sont à pourvoir , alors n’hésitez pas à consulter notre site carrière et/ou notre page Linkedin ! Ce contenu est bloqué Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","APRIL, the #1 insurance brokerage in France, is seeking a Data Analyst with technical skills in statistics, database management, data visualization tools (Qlik, Tableau, Power BI), and programming languages (Java, SQL, Python, R, SAS). The successful candidate will extract, analyze, and communicate data insights to support decision-making for the company's digital and UX platform. The role requires an understanding of the insurance or banking industry and a minimum of three years of professional experience. The company offers a dynamic and agile work environment and opportunities for personal and professional development.",N,N,N,0,1,0.013848874720779208
170,56869,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-business-intelligence-f-h_niort,Data Engineer,Micropole,"{Microsoft,durable,Qlikview,Talend,SAP,Informatica,AWS,TALEND,via,R,PowerBI,BigQuery,GCP,SQL,Python,Tableau}",NaN,"4 Rue du 14 Juillet, Niort, 79000",IT / Digital,CDI,2023-03-26,"Micropole est accélérateur de la transformation des entreprises par la Data. Du conseil à la mise en œuvre opérationnelle, Micropole accompagne les entreprises dans leur stratégie data, et les transformations organisationnelles, humaines et technologiques associées. Sa mission : aider ses clients à garder un temps d’avance en exploitant tout le potentiel de la data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compréhension des enjeux de transformation de leurs métiers et/ou secteurs d’activité, par la data. Ils conçoivent, construisent, sécurisent et déploient, à l’échelle, des modèles opérationnels et performants, pour permettre une croissance durable et responsable. En résumé : Poste : Data Engineer (F/H) Localité : Niort Type de contrat : CDI Niveau d’expérience : Au moins 3 ans Comme nous, vous êtes passionné(e) par la donnée et convaincu(e) que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales , au sein d’une agence à taille humaine où règnent entraide et convivialité et engagée en faveur d’un numérique plus responsable au service de clients principalement implantés régionalement ? Rejoignez l'aventure Micropole à Niort ! En intégrant l’Agence Niortaise vous viendrez renforcer une équipe soudée qui porte l’esprit d’équipe, ayant à cœur de faire de votre intégration un succès et de vous accompagner dans votre montée en compétences. Idéalement située dansl’hypercentrede Niort, l’agence Micropole se trouve à proximité des transportsen commun et des axes routiers. Vous aurez l'opportunité d'intervenir sur des projets data innovants, riches et variés et participerez activement au rayonnement de l'agence sur le bassin niortais. Dans vos missions quotidiennes , vous serez amené(e) à: Participer au recueil des besoins des métiers ; Rédiger les dossiers de conception technique ; Modélisez les entrepôts de données ; Développer des flux de données via des ETL, Concevoir des tableaux de bord via des outils de reporting et datavisualisation ; Vousaccompagnez la maîtrise d’ouvrage dans la validation de livrables, ls tests, l’assistanceà la recette et la conduite du changement sur le projet, Vos compétences techniques : Vous maîtrisez la manipulation des données (préparation, modélisation, restitution), Vous maîtrisez parfaitement au moins un ETL du marché (Informatica, Talend, BigQuery, Datafactory,...) et la création de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, Cognos...), Python ou SQL n’ont plus de secrets pour vous, Vos atouts : Diplômé(e)d’une formation supérieure en Informatique parcours BI, Data, Aide à la Décision, Vouspossédez une expérience d'au moins 3 ans dans la fonction, Votreesprit d’analyse, de synthèse, votre organisation et vos capacitésrédactionnelles sont souvent reconnus, Vousappréciez travailler en équipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C’EST : - Intégrer une communauté de 1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine. - Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus. - S’assurer d’une innovation continue grâce à : Notre écosystème de partenaires technologiques Notre accélérateur de start’up databoost’R Nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C’EST : Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; La participation à des projets internes sur la base du volontariat. PROCESSUS DE RECRUTEMENT : Chez Micropole, le processus de recrutement est réactif et transparent. Etape 1 – Si votre profil correspond à nos attentes, vous êtes recontacté(e)s dans les 72 heures qui suivent votre candidature par Céline ou Mikaël nos Talent Specialist pour la région ouest pour un premier échange téléphonique ; Etape 2 – Un premier entretien est programmé avec l’un d’entre eux sur site ou à distance Etape 3 – Vous rencontrez Stéphanie ou Camille les manager de l’équipe Data de l’Ouest pour un second entretien En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique) MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un développement rapide sur le Data, le Digital et Cloud, les équipes portent l’ensemble de la proposition de valeur du Groupe. Présent au plus près de l’écosystème de partenaires, de réseaux professionnels et d’acteurs du développement économique, nous accompagnons nos clients des secteurs de l’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et du public dans leur transformation data et digitale, notamment au travers de méthodologies innovantes comme le Datathinking® ou Lego Serious Play®. L’agence Grand Ouest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit et met en place des méthodes, compétences et expertises pour le développement d’un numérique responsable au sein des organisations. À PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement. MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Compétences ETL Informatica TALEND PowerBI Qlikview SAPBO","Micropole is seeking a Data Engineer to join their team in Niort, France. The ideal candidate should have at least three years of experience in data manipulation, ETL development, and data visualizations. They will be responsible for collecting business requirements, developing technical design documents, modeling data warehouses, and developing data flows. They should also have expertise in at least one ETL tool (Informatica, Talend, BigQuery, Datafactory) and one data visualization tool (Power BI, Tableau, QlikSense, SAP BO, Cognos). Micropole is an international consulting and technology firm specializing in Data & Digital.",Bac +5 / Master,Entre 250 et 2000 salariés,> 3 ans,0,0,0.0
296,56877,https://www.welcometothejungle.com/fr/companies/scalapay/jobs/data-engineer_milan,Data Engineer,Scalapay,"{Athena,Kubernetes,Glue,AWS,magic,S3,scale,Linux,Git,SQL,Python}",NaN,"Milan, 20121","FinTech / InsurTech, Mode, Art de vivre",CDI,2023-03-26,"Scalapay transforme la façon dont les consommateurs réalisent leurs achats online et en magasin, en permettant aux commerçants d’offrir à leurs clients des expériences magiques. Avec plus de 4 000 détaillants dans les secteurs de la mode, de la beauté, de la maison et du voyage qui nous font confiance (Moschino, Calzedonia, Gérard Darel, Nike, Shein, pour n’en citer que quelques-uns), nous avons plus d’un million de clients qui utilisent Scalapay aujourd’hui en Europe. Après une série B de 497M$ en février 2022 menée par Tencent et Willoughby Capital, nous avons obtenu le statut de licorne ! Grâce à cela, nos équipes grandissent rapidement et nous recherchons des talents extraordinaires pour venir rejoindre l’aventure et nous aider à façonner l’avenir du paiement et des produits checkout dans l’écosystème eCommerce. Travailler avec nous signifie un quotidien où tout va très vite, où chacun a l’opportunité de mener des projets passionnants et stimulants, et de faire partie d’une équipe animée par 4 valeurs très fortes : #createmagic #staycurious #beimpactful #playasateam. Nous sommes fiers d’être l’une des 10 meilleures startups pour lesquelles travailler selon LinkedIn, et la startup de l’année 2021 en Italie. This is where your magic happens. If you love it, Scalapay it 🖤 Thanks to our innovative BuyNow PayLater payment solution, Scalapay is transforming the way more than 2 million customers buy online and in-store, empowering 5,000+ merchants to give their customers magical shopping experiences. Being only 3 years old didn’t stop us from becoming a unicorn 🦄 We have raised over $700mln and we did this thanks to a team built around our 4 core values: #createmagic #staycurious #beimpactful #playasateam . This is where your magic happens. If you love it, Scalapay it ♥ THE MISSION Data-driven decisions are the centre of our efforts to automate processes and support decisions across the business. As Data Engineer , your role will focus on developing distributed software for large-scale heterogeneous data processing, the development of ETL and reverse ETL pipeline. You will be responsible for: - Data modelling - Data lineage - Data quality / Data observability - SLA, performance and scalability You’ll be required to discuss requirements for data access and integrations with colleagues across the business, design solutions to the company’s problems and implement these using modern software processes in the cloud. The role gives a large amount of autonomy and the chance to work with a top-notch team of experienced data experts. Who we are looking for: - Strong Python and SQL experience - Experience building and deploying ETL pipelines - Experience with API integration - Ability to scope projects and decompose work into tasks - Familiarity with Linux-like development stacks, including Git, Kubernetes, etc - Familiarity with AWS infrastructure (such as S3, Athena, Glue, etc) - Knowledge of Data Modeling / Data Observability is a plus - Ability to engage with colleagues on business processes - A Bachelor's degree in computer science or a related field Why you should join Scalapay: - Attractive packages based on skills and experience - International environment with significant challenges to be met every day - Lots of opportunities to work with a team of industry tech leaders who are focused on delivering products that offer exceptional user experiences - Personalised support to accelerate your professional growth and take ownership of the products you deliver: we want to help you grow! - Latest technologies and being encouraged to bring your flair to the role Recruitment Process: 1) A quick chat with one of our Talent Acquisition team members 2) The first interview with the Hiring Manager to deep dive into your experiences and better understand your motivation 3) A case study to test your hard skills 4) A Meet The Team session where you’ll get to meet different people at Scalapay and see if you’ll fit into our culture _________________________________________________________________________ Want to learn more? Don't hesitate to explore our Careers website and Careers website, and our LinkedIn, WTTJ, Meritocracy and Glassdoor pages. Pro tip: send your CV in English 😉 Super Pro tip: we know that application processes can be scary and frustrating but… we look for talent, not people that tick all our boxes. We believe in the power of diversity: Scalapay is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation.","Scalapay is seeking a Data Engineer with strong Python and SQL skills to develop distributed software for large-scale heterogeneous data processing, ETL and reverse ETL pipelines. The role involves scoping projects, designing solutions, and implementing them using modern software processes in the cloud. Candidates should be familiar with AWS infrastructure, Linux-like development stacks, Git, and Kubernetes, and have experience with API integration, data modelling, and data observability. Scalapay offers an international environment, attractive packages based on skills and experience, and opportunities to work with a team of industry tech leaders dedicated to delivering products with exceptional user experiences.",Bac +3,Entre 50 et 250 salariés,> 3 ans,0,0,0.0
188,37270,https://www.welcometothejungle.com/fr/companies/nnit/jobs/python-developer-digital-biomarkers-data-engineering_prague,Python Developer (Digital Biomarkers Data Engineering),NNIT Czech Republic,"{SciPy,MySQL,go,UNIX,MongoDB,Microsoft,Mapreduce,Pandas,Luigi,Hadoop,Kafka,Spark,Azure,NoSQL,SQL,Python,NumPy}",NaN,N,"IT / Digital, SaaS / Cloud Services, Cybersécurité",CDI,2022-10-18,"NNIT is a leading provider of IT transformation services and solutions to international life sciences companies and for the Danish private and public sector. Working in NNIT means being part of an international team with talented colleagues who all work the NNIT way. Each and every day, more than 3,000 NNIT colleagues go to work globally towards a common goal to make a mark on business and society, by bringing digital transformation to life. At NNIT, IT is not just IT. For those at NNIT, working with IT, is to ensure that vital parts of our society are functional and developing in vital areas such as pharma production, banking, transportation and food supplies. In short, they handle critical infrastructure across sectors and across countries. That is why making a mark means everything to NNIT. Their values are not just phrases that were written down and hung up on a poster. They are alive in the offices around the world and embodied when meeting their customers and other stakeholders. NNIT are open and honest, value adding and conscience driven in every aspect. At NNIT, independent thinking and individual responsibility is encouraged, allowing you to pave the way and make your mark in and with NNIT. There are very few boring days with NNIT. There are fun days, busy days, inspiring days, suprising days and so forth. They are all part of everyday life at NNIT. Our Life Science unit is looking for a Python developer to further develop the Remote Monitoring Patient Platform collecting sensor data from digital devices handed out in clinical studies. You will be dedicated to one of our big pharma client and work closely with the whole team of great IT professionals. The successful candidate will establish processes and implementations to enable and facilitate the mining of digital biomarkers out of the mentioned data. In addition, the candidate will help the staff to setup and maintain new digital biomarker studies. You need to expect to be working closely with the client, sometimes from their offices. Responsibilities: ● Develop the computational back-end of applications used to discover Digital Biomarkers ● Help to automate the creation of reports and dashboards supporting the analytics driven decision taken from the sensor data collected ● Participate in technical decision regarding the implementation of new algorithm to mine sensor data ● Enhance the existing infrastructure that handles the data collected from sensors used in clinical trials ● Proactively collaborate with a team comprising data scientists, software engineers and life science experts. Your experience: ● Bachelor with emphasis on coursework of a quantitative nature (e.g. Computer Science, Engineering, Mathematics, Data Sciences) ● 3 years of software development experience ● Experience in or eagerness to write and maintain ETLs (extract, transform, load) pipelines which operate on a variety of structured and unstructured sources ● Experience with SQL and NoSQL data stores ● Deep knowledge of Python and frameworks around it. ● Previous working experience with the common Python data analysis (e.g. NumPy/SciPy, Pandas, Scikit-learn, SQLAlchemy, etc.) and, ideally, data pipelining (e.g. Luigi) libraries ● Knowledge of UNIX internals and workload management systems (SLURM, SGE /UGE) ● Ability to write standards-compliant database related code for MongoDB and MySQL ● Strong working knowledge of best coding practices (versioning, TDD, debugging) ● Strong analytical skills combined with conceptual thinking and structured working style; ability to work in a multicultural team ● Fluent in English. It’s good if you also have: ● Previous experience in designing, creating, and implementing methods, algorithms and pipelines of digital signal processing ● Experience with the Microsoft Azure environment ● Experience with big-data systems (in particular Hadoop, Apache Spark, Apache Kafka and Mapreduce) with respective ecosystems ● Previous working experience within an AGILE environment (ideally SCRUM) ● Project-based work experience in the pharmaceutical industry/consulting preferred. Please submit your application in English.","NNIT is seeking a Python developer with experience in back-end development, ETL pipelines, SQL, NoSQL data stores, data analysis libraries, Unix internals, and workload management systems. The successful candidate will work within the Life Science unit and collaborate with data scientists, software engineers, and life science experts to implement algorithmic solutions for biomarker data analysis collected from clinical studies. Knowledge of digital signal processing, Microsoft Azure, big data systems, and agile development is a plus. The candidate should have a bachelor's degree in a quantitative field, three years of software development experience, and strong communication skills in English.",Non spécifié,Entre 250 et 2000 salariés,> 3 ans,0,0,0.0
131,37284,https://www.welcometothejungle.com/fr/companies/lemonade/jobs/data-engineer_tel-aviv_LEMON_Ll5Vj2G,Data Engineer,Lemonade,"{Airflow,Adept,AWS,Kafka,Lemonade,Spark,NoSQL,SQL,Python}",NaN,N,"Assurance, FinTech / InsurTech",CDI,2022-10-18,"Our mission is simple: Create the world’s most loved insurance through technology and social impact. As a certified Public Benefit Corporation and B Corp, Lemonade is constantly challenging how the insurance industry does business. We’re creating an experience that is fast, affordable, and hassle-free across renters, homeowners, pet, life and car insurance. And through our annual Giveback program, in which leftover premiums are donated to charities our customers choose, we’ve donated over $6 million to a variety of organizations in need. Lemonade is currently available in the United States and in Europe (France, Germany, the Netherlands, and the UK) and continues to expand globally. We’re looking for a Data engineer to join our Data Platform team in TLV. As part of the Data infrastructure group, you’ll be responsible for building scalable and accessible data solutions that help data consumers from around the organization produce crucial business insights. In this role you’ll Build a scalable platform that draws data from multiple sources and formats, and allows for all users to easily consume it Develop and manage orchestration tools, governance tools, data discovery tools, and more Ensure our scalable data systems and pipelines run smoothly so that analysts, data scientists, machine learning engineers, and other stakeholders can access them effectively and efficiently Help expand and optimize our data pipelines architecture Take part in designing and architecting data solutions for all application requirements in a distributed microservices environment What you’ll need 3+ years knowledge in data engineering or database development (background in the big data domain is an advantage). SQL expertise, working with various databases (relational and NoSQL), data warehouses, and third-party data sources and AWS cloud services Proficient with Python Adept at building, designing, and optimizing data pipelines, architecture, and data sets Familiarity with the data engineering tech stack: ETL and ELT tools, Airflow, Spark, Kafka Experience working in an agile development environment is an advantage. Ability to work in an office environment","Lemonade, a certified Public Benefit Corporation and B Corp in the insurance industry, is seeking a Data Engineer for their Data Platform team in TLV. The candidate will be responsible for building scalable and accessible data solutions, developing and managing orchestration tools, ensuring smooth data systems and pipelines, optimizing data pipelines architecture, and designing data solutions for all application requirements in a distributed microservices environment. The ideal candidate should have 3+ years of experience in data engineering, SQL expertise, proficiency in Python, familiarity with the data engineering tech stack, and experience working in an agile development environment.",Non spécifié,Entre 250 et 2000 salariés,> 3 ans,0,0,0.0
