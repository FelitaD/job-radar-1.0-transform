,id,url,title,company,stack,remote,location,industry,type,created_at,text,summary,education,size,experience,remote_num,exp_num,rank
350,56587,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-engineer_london,Junior Data Engineer,Artefact,"{GCP,Azure,AWS,BigQuery,Git,SQL,Python,Postgres}",T√©l√©travail total possible,London,"Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that‚Äôs why we identify as ‚Äúmarketing engineers‚Äù. In order to improve the performance and impact of brands, and consumers‚Äô experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). Junior Data Engineer About us: Artefact is a new generation of a data service provider, specialising in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we‚Äôre enjoying skyrocketing growth. Our broad range of data-driven solutions in data consulting and digital marketing are designed to meet our clients‚Äô specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we‚Äôve acquired with our 1000+ client base around the globe. We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client. Role Profile: As a Data Engineer at Artefact, you will be given opportunities to innovate, build, train and communicate with a team made up of consultants, data scientists, creatives and engineers to identify business needs and define innovative solutions. You will work in a collaborative team which champions knowledge sharing. You will work in an environment that encourages coaching & collaboration at all levels. Allowing you to work closely with other departments & keep abreast of industry news/updates and share your discoveries with others. Your technical skills: Programming skills in Python including building, testing and releasing code into production SQL skills with exposure working with relational/columnar databases (e.g. BigQuery, SQL Server, Postgres) Experience using Git and version controlling A willingness to learn and find solutions to complex problems Exposure with one of the main cloud providers (GCP, Azure, AWS) is desirable Experience with agile software delivery and CI/CD processes is a bonus Your mindset: Curious, you are always seeking innovative solutions for your clients Sharing of knowledge is essential for you and you actively participate in the diffusion of information within Artefact (seminaries, formations, certifications) Entrepreneurial, you bring solutions, new ideas, within your team at Artefact You are able to act on the whole value chain of projects (infrastructures and platforms creation, data collection, application of machine learning models, APIs REST creations, of front-ends, of tests, continuous deployments) You have strong communication skills and can popularize technical terms or solutions to more business oriented profiles, you can work in a team with very diversified profiles You are independent in managing your tasks and timelines Why you should join us Artefact is revolutionizing marketing: join us to build the future of marketing Progress: every day offers new challenges and new opportunities to learn Culture: Check out our website (Artefact.com) or Instagram (Artefact UK) to find out more about our diverse, vibrant culture here Entrepreneurship: you will be joining a team of driven entrepreneurs. We won‚Äôt give up until we make a huge dent in this industry! Hit apply, and see whether what we offer is what you‚Äôve been looking for!","Artefact, a consulting firm specialized in AI and Data, is seeking a Junior Data Engineer to work with a team of consultants, data scientists, creatives and engineers to identify business needs and define innovative solutions. The ideal candidate must have programming skills in Python, SQL skills, experience using Git and version control, ability to learn and solve complex problems, and familiarity with cloud providers. Artefact offers a vibrant culture, opportunities to learn and grow, and a chance to revolutionize marketing.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,3,0.08309324832467525
30,56722,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-gdo-data-software-engineer-h-f_paris,ALIT GDO - DATA SOFTWARE ENGINEER,Air Liquide,"{DynamoDB,DBT,Glue,Lambda,Docker,EC2,Postgresql,Athena,Gitlab,Prometheus,Git,grafana,AWS,SQL,EMR,Airflow,Redshift,S3,Python}",T√©l√©travail total possible,"Paris, 74000","Environnement / D√©veloppement durable, Sant√©, Energie, Digital",CDI,2023-03-26,"Air Liquide est un leader mondial des gaz, technologies et services pour l‚Äôindustrie et la sant√© . Oxyg√®ne, azote et hydrog√®ne sont des petites mol√©cules essentielles √† la vie, la mati√®re et l‚Äô√©nergie. Gr√¢ce √† l‚Äôengagement et l‚Äôinventivit√© de ses collaborateurs pour r√©pondre aux enjeux de la transition √©nerg√©tique et environnementale, de la sant√© et de la transformation num√©rique , Air Liquide cr√©e encore plus de valeur pour l‚Äôensemble de ses parties prenantes. La diversit√© et l‚Äôinclusion du handicap au sein de notre organisation nous permet de r√©pondre au mieux aux d√©fis complexes des march√©s que nous servons, de stimuler l‚Äôinnovation et de contribuer √† cr√©er de la valeur pour nos clients, nos partenaires et la soci√©t√© en g√©n√©ral. Notre m√©thode de gestion des talents ‚Äì de l‚Äôembauche au d√©veloppement de leur carri√®re ‚Äì sont le reflet de notre engagement en faveur de la diversit√© et de l‚Äôinclusion du handicap . La conjugaison de ces √©l√©ments et de la grande part d‚Äôintrapreneuriat au sein d‚Äô√©quipes √† taille humaine nous permet de relever des challenges ambitieux. Au sein de la division Innovation et D√©veloppement, le d√©partement Global Data Operations (GDO) accompagne nos ambitions de strat√©gie et de gouvernance, en apportant l'expertise et les plateformes technologiques Data & IA n√©cessaires au d√©veloppement de solutions diff√©renciantes pour les m√©tiers d'Air Liquide. Au sein de GDO, la Product Line Data Lake & AI √† pour mission d'accompagner la strat√©gie de d√©ploiement √† l'√©chelle d'Air Liquide : il s'agit de construire, op√©rer et faire √©voluer la data platform du groupe. L'√©quipe est compos√©e de profils pluridisciplinaires et √† en charge sp√©cifiquement les produits et strat√©gies data lake et data science dans des contextes g√©ographiques √©tendus sur diff√©rents Hub ( Am√©rique, Asie, Europe et Afrique) ainsi que des contraintes fortes li√©es aux l√©gislations impos√©es par nos activit√©s business. Vous ferez partie de l'√©quipe Core Data Platform , et rapporterez au Data Platform Product Manager. Vos responsabilit√©s incluent la conception et l'op√©ration des produits que compose la data platform Air Liquide telle que les services d'Ingestion, de transformation, de data quality et tooling divers pour supporter toutes les activit√©s projets : Contribuer au d√©veloppement et √† la maintenance des nouvelles fonctionnalit√©s des produits lake Contribuer √† l'am√©lioration de l'architecture technique de la plateforme Contribuer √† la revue de code Contribuer √† la correction des bugs fonctionnels et techniques Contribuer √† l'am√©lioration de la qualit√© du code et du produit en participant √† l'√©criture des tests unitaires, fonctionnels, d'int√©grations, de charges et End-to-End Contribuer √† la documentation fonctionnelle et technique de l'application Contribuer √† l'am√©lioration de l'observabilit√© de la plateforme Bonne application des r√®gles de s√©curit√© et de confidentialit√© du Groupe li√©es au traitement de la donn√©e Education et Exp√©rience Bac + 5 de formation Ing√©nieur ou formation sup√©rieure en sciences Informatiques, id√©alement avec une orientation Data 3+ ann√©es d'exp√©riences en relation avec le poste Exp√©rience de travail en environnement agile Comp√©tences techniques Langage : Python CI/CD : Git, Gitlab-CI,Docker Observability: Prometheus, grafana Cloud : Tr√®s bonnes connaissances des technologies AWS Data analytics: EMR, Lambda, DynamoDB, Athena, Glue Catalog, AWS Batch, EC2, S3 Orchestration: Airflow , AWS StepFunction Database : Redshift ,Postgresql API: FastApi, Falcon Comp√©tences fortement appr√©ci√©es : SQL, PySpark , DBT, Apigee, Cloudformation, Terraform Comp√©tences non techniques Proactivit√© et orientation utilisateurs Ouverture d'esprit et esprit d'√©quipe Curiosit√© et prise d'initiative. Capacit√© √† travailler dans un environnement matriciel international Capacit√© d'analyse et de synth√®se L'anglais et le fran√ßais courants √† l'√©crit comme √† l'oral sont indispensables. Horaires et lieux de travail Le poste est bas√© √† Paris XIe sur le Campus de La Factory. Des d√©placements occasionnels pourront √™tre n√©cessaires en France ou √† l'√©tranger. Manager : Data Platform Product Manager Ce que nous offrons L'utilisation des derni√®res technologies et la possibilit√© de travailler avec des experts techniques tr√®s reconnus dans leur domaine La possibilit√© d' apprendre et de monter en comp√©tences en continu dans une √©quipe r√©cente, agile et en croissance Des perspectives d'√©volution au sein du groupe gr√¢ce √† notre politique de mobilit√© interne Un cadre de travail stimulant et multiculturel au c≈ìur de Paris, avec un accord t√©l√©travail en place (3 jours par semaine de t√©l√©travail) De nombreux avantages : Participation/Int√©ressement, prime vacances, carte tickets restaurants, CE, 152‚Ç¨/mois de CESU pour les personnes ayant √† charge un ou plusieurs enfant(s) de 3 ans ou moins ‚Ä¶","Air Liquide is seeking a Data Platform Engineer with at least 3 years of relevant experience in a similar role, strong Python skills, and expertise in AWS cloud, data analytics, and CI/CD tools. The successful candidate will be responsible for designing and operating the data platform at Air Liquide, contributing to the development of new features, improving the platform's technical architecture, reviewing and correcting code, and ensuring data security and confidentiality. A degree in Computer Science or a related field is required, and the candidate should be proactive, a team player, and able to work in an international, matrixed environment. The position is based in Paris but may require occasional travel within France or internationally.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,3,3,0.08309324832467525
391,34673,https://www.welcometothejungle.com/fr/companies/axionable/jobs/data-engineer-junior_paris,Data Engineer Junior,Axionable,"{GCP,durable,python,Django,Shell,HDFS,AWS,Azure,NoSQL,SQL}",T√©l√©travail total possible,Paris,"Intelligence artificielle / Machine Learning, Environnement / D√©veloppement durable, Big Data",CDI,2022-08-08,"Axionable est le leader de l‚Äôintelligence artificielle durable en France et au Canada. Certifi√© B Corp et labellis√© GreenTech Innovation, membre du Conseil d‚ÄôAdministration du collectif de r√©f√©rence Impact AI, Axionable s‚Äôengage dans la r√©solution de probl√©matiques m√©tiers √† impact positif gr√¢ce √† une IA √©thique et durable. Son √©quipe d‚Äôexperts du conseil en Data/IA et en d√©veloppement durable d√©veloppe une nouvelle approche business de la Data et l‚ÄôIA, capable de combiner r√©sultat √©conomique avec impact social, soci√©tal et environnemental. Axionable agit notamment dans les secteurs de la banque/assurance, de l‚Äô√©nergie et des utilities, des transports, industrie, des m√©dias, du luxe, du BTP, de l‚Äôimmobilier, des m√©dias et de la sant√©. Il accompagne ses clients de bout en bout, depuis l‚Äôaudit strat√©gique, l‚Äôanalyse et la classification des donn√©es, jusqu‚Äôau d√©ploiement de solutions d‚ÄôIA responsables. Fond√© en 2016, et depuis toujours ind√©pendant, autofinanc√© et rentable, il conna√Æt depuis une forte croissance. Axionable compte 50 collaborateurs r√©partis entre Paris et Montr√©al. En tant que Data Engineer Junior (F/H), vous contribuerez √† la r√©alisation de plateformes (Big) Data et Intelligence Artificielle (IA) permettant de r√©pondre aux besoins m√©tiers de nos clients. Vos missions consisteront √† : D√©finir et mettre en ≈ìuvre des pipelines (Datalake, Datawarehouse, ‚Ä¶) d‚Äôingestion et de traitement de donn√©es (On-premise & Cloud) , Mettre en place et Industrialiser des solutions gr√¢ce aux outils DevOps / CloudOps (Terraform, Ansible, CI/CD, ‚Ä¶), Contribuer √† la mise en place de tableaux de bord (Power BI, Data Studio, ‚Ä¶) Participer √† la construction d‚Äôinterfaces transactionnelles d‚Äôun point de vue API back-end (Django), Interagir avec nos experts data science et m√©tiers, Participer √† la veille technologique dans votre domaine d‚Äôexpertise et √™tes force de proposition. Le poste est √† pourvoir √† partir de septembre 2022 Axionable s‚Äôengage en faveur de l‚Äô√©galit√© des chances, de la diversit√© et de l‚Äô√©quit√©. Nous encourageons tout¬∑e candidat¬∑e ayant l‚Äôexp√©rience requise √† postuler √† nos offres. Bac +5, Master en Informatique ou √©cole d‚Äôing√©nieur sp√©cialis√© en syst√®me d‚Äôinformation et Big Data Dot√©¬∑e d‚Äô une premi√®re exp√©rience significative sur un poste similaire (stage/alternance) Avoir une exp√©rience mettant en jeux un middleware de stockage de la donn√©e tels que DatawareHouse, HDFS ou NoSQL Connaissances dans le d√©veloppement avec les langages python, Shell, SQL Les connaissances sur l‚Äôun des trois principaux fournisseurs de cloud public (Azure, GCP,AWS) sont tr√®s appr√©ci√©s Positif¬∑ve et adoptant une posture en faveur de la Responsabilit√© Soci√©tale de l‚ÄôEntreprise (RSE) Autonome, curieux¬∑se et passionn√©¬∑e des sujets IA et data Mobile ponctuellement pour intervenir sur les sites de nos clients Fran√ßais courant, l‚Äôanglais courant est un plus 1 Entretien RH + 2 Entretiens","Axionable, the leader in sustainable Artificial Intelligence in France and Canada, seeks a Junior Data Engineer with a Master's in Computer Science or Engineering and Big Data, and a first significant experience in a similar role. The candidate should have knowledge of middleware storage such as DatawareHouse, HDFS or NoSQL, and development with Python, Shell, SQL. Experience with Cloud providers such as Azure, GCP, or AWS and proficiency in French and English are pluses. The Data Engineer will work on building pipelines, tableboards, and interfaces alongside Axionable's Data Science experts and should be responsible, independent, and passionate about data and AI topics.",N,N,N,3,3,0.08309324832467525
227,58076,https://www.welcometothejungle.com/fr/companies/sicara/jobs/data-engineer_paris,Data Engineer Junior,Sicara,"{Microsoft,Scala,AWS,Spark,Azure,Hadoop,Python}",T√©l√©travail partiel possible,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"Sicara est une startup experte en data, bas√©e √† Paris : nous r√©volutionnons les projets data en combinant notre m√©thodologie agile de delivery de projet et notre savoir-faire en data science et data engineering afin d‚Äôaider nos clients √† capitaliser sur le potentiel de la donn√©e. Filiale du groupe Theodo, un √©cosyst√®me de 9 filiales et +400 personnes situ√©es √† Paris, Londres, New York et Casablanca, cr√©√©e en novembre 2016 , Sicara est pass√©e de 2 √† 35 personnes en quatre ans. Pour soutenir notre croissance de 50%, nous cherchons √† faire grandir notre portefeuille client. R√©guli√®rement en contact avec les √©quipes techniques et les consultants Sicara seniors, nos AI Project Managers utilisent leurs comp√©tences pour d√©ployer la m√©thodologie projet de d√©veloppement de solution en data science. Sur nos projets, tu seras amen√©(e) √† : Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Travailler en √©quipe de 2 √† 4 data engineers √©paul√©s par un coach agile et un coach technique Mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) sur le cloud D√©ployer les pipelines de donn√©es (ETL et ELT) Assurer la migration des donn√©es vers les nouveaux environnements Mettre en place des outils de contr√¥le de la qualit√© de la donn√©e Accompagner et former les √©quipes clients Au sein de Sicara, tu seras amen√©¬∑e √† : Contribuer √† notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog. Contribuer √† am√©liorer nos savoir-faire en exp√©rimentant continuellement de nouvelles m√©thodes et de nouveaux outils afin d‚Äôam√©liorer l‚Äôefficacit√© des √©quipes. Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur Tu as une forte app√©tence pour le secteur de la data et tu as id√©alement une premi√®re exp√©rience dans le conseil ou dans la tech Tu as une exp√©rience pass√©e en tant que Data Engineer Tu as envie de progresser et d‚Äô√©voluer dans un environnement challengeant et bienveillant au quotidien Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data (Spark, Scala, Hadoop) Tu connais ou as envie d‚Äôapprendre √† utiliser l‚Äôun des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure) 1 entretien RH + 2 entretiens techniques + 2 entretiens dirigeants","Sicara, a data startup based in Paris, is seeking an AI Project Manager to support its growth and work with technical teams and senior consultants to deploy the project methodology for data science solutions. The role involves analyzing data sources, working in a team of 2-4 data engineers, and implementing resilient and secure data systems on the cloud. The ideal candidate should have a strong interest in data, previous experience in consulting or tech, and be familiar with Python, Big Data technologies, and Cloud Providers. The hiring process includes an HR interview, two technical interviews, and two interviews with executives.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 6 mois,2,3,0.06924437360389604
423,43178,https://www.welcometothejungle.com/fr/companies/axians/jobs/data-engineer-h-f-f-h_nice,DATA ENGINEER,Axians France,{NoSQL},T√©l√©travail partiel possible,Nice,"Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Cybers√©curit√©",CDI,2023-01-30,"Rejoignez Axians Database une soci√©t√© du P√¥le Axians Communication & Cloud, marque de VINCI Energies d√©di√©e aux solutions ICT. Le positionnement d'Axians offre √† ses clients une large gamme d'expertises, une comp√©tence depuis la conception de l'infrastructure avec int√©gration des meilleures solutions technologiques, jusqu'au support garantissant une haute disponibilit√©. Axians Database est une soci√©t√© sp√©cialis√©e dans la gestion de la donn√©e. Implant√©e sur le territoire national, nos quatre m√©tiers historiques sont le Conseil, les Services Manag√©s, la Formation et la Gestion des Actifs. En une quinzaine d'ann√©es, Axians Database a su s'imposer comme l'un des leaders de la gestion des syst√®mes de bases de donn√©es en France. Nous disposons aujourd'hui d'un haut niveau de certifications et d'expertises sur les SGBD majeurs du march√©. Nous sommes aujourd'hui √† la veille d'une importante phase de croissance en partie li√©e √† des sujets innovants : DevOps, Clouds publics, NoSQL et automatisation. Dans le cadre de notre d√©veloppement, nous recrutons √† Sophia-Antipolis ou Aix-en-Provence en CDI, un.e : DATA ENGINEER (H/F) Pour accompagner notre forte croissance nous recherchons un(e) Data Engineer. Vous serez en charge au quotidien : * D'analyser les besoins clients * D'animer des ateliers afin d'√©tudier et cadrer les besoins clients * De pr√©coniser les solutions et architectures cibles * De d√©finir les m√©thodologies de d√©ploiement et les plans de migration * De r√©diger les dossiers d'architecture et les sp√©cifications techniques * De construire les architectures de donn√©es * De concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (datawarehouse, datalake, syst√®mes temps-r√©els) * De construire et d√©ployer les pipelines de donn√©es * D'assurer la migration des donn√©es vers les nouveaux environnements * D'assurer une veille technologique continue sur les solutions cloud * D'accompagner et former les √©quipes clients aux m√©thodes et concepts du cloud Autonome sur votre poste, vous appr√©ciez communiquer et √©changer techniquement avec l'ensemble des collaborateurs. Vous travaillerez dans un souci constant d'am√©lioration et de modernisation de nos outils. Vous serez donc encourag√© √† √™tre force de propositions. Vous √™tes la personne id√©ale pour rejoindre notre √©quipe si ‚Ä¶ De formation Bac+5 en informatique, vous avez entre 0 et 2 ans d'exp√©rience (stage ou alternance inclus) sur un poste similaire. Rigoureux et proactif, vous serez force de proposition et vous impliquerez pleinement dans les missions qui vous seront confi√©es. Votre envie et votre capacit√© √† grandir techniquement, votre go√ªt pour le partage et le travail en √©quipe vous poussent √† aller plus loin et voir autrement. Votre futur √©cosyst√®me : Une √©quipe dynamique compos√©e de collaborateurs aux profils vari√©s comprenant des jeunes professionnels et des experts confirm√©s. Cet environnement vous permettra de d√©velopper vos comp√©tences au quotidien. Une entreprise vivante qui veille √† l'√©panouissement de ses salari√©s (t√©l√©travail, organisation de challenges, animations...). Envie d'un nouveau challenge, il est d√©sormais temps de nous rejoindre !","Axians Database seeks a Data Engineer to analyze customer needs, suggest solutions and architectural designs, and create resilient and secure data systems. The ideal candidate will have a degree in computer science, 0-2 years of experience in a similar position, be proactive and rigorous, and possess a desire to learn and grow technically. Axians offers a dynamic work environment with opportunities for telecommuting and employee engagement initiatives.",Bac +5 / Master,Entre 250 et 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
449,50017,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-analytics-all-genders_paris,Junior Data Engineer - Analytics (All Genders),Dailymotion,"{Aerospike,Docker,Beam,Kafka,Linux,Dataflow,Git,NoSQL,Bash,Kubernetes,Java,SQL,Airflow,Druid,Spark,BigQuery,GCP,GO,Python}",T√©l√©travail partiel possible,"140, Boulevard Malesherbes, Paris, 75017","Big Data, M√©dia, Publicit√©",CDI,2023-02-07,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Dailymotion is seeking a Data (Analytics) Engineer for the Analytics Engineering team. You will join the Data Engineering & Machine Learning craft. A craft consists of multiple teams of engineers and machine learning experts who collaborate daily to create and run Data products in Dailymotion. Inside this craft, the Analytics Engineering team‚Äôs mission is to provide trustworthy and available data to enable analysis & insights throughout the company (B2C, B2B products, and business teams). Analytics Engineering team builds and maintains products like our multi-petabyte data warehouse, event processors (at tens of thousands of messages per second), highly scalable client-facing analytics, data ingestion & distribution, synchronizing data across databases & systems, etc. The team is responsible for making costs-performance tradeoffs around data modeling & architecture. The team is also involved with training users of our data on SQL and analytics best practices and spearheading a significant effort around data governance. Analytics Engineering is a new and emerging space within the Data sphere. As an Analytics Engineer, you bring a software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. It requires a mix of programming skills and data skills on a day-to-day basis. If you are interested in solving challenging business problems with your skills, consider applying to this role. Your impact will be broad and across all of Dailymotion‚Äôs businesses. What you will do: Collect vast amounts of raw data from internal sources and external sources in batch and streaming modes. Expose the data through APIs, flat files, data marts, etc., for internal and external users. Design Druid datasets for external facing consumers for speed, consistency, cost, and efficiency. Write complex and optimal SQL queries to transform data in our data lake into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations through Airflow. Investigate data discrepancy, data quality issues. Debug performance issues using query plan. Design BigQuery table data model to efficiently answer business use cases considering cost and performance. Ensure data is clean, consistent, and available. Perform data quality checks, create monitors. Catalog and document the business entities, data marts, dimensions, metrics, business rules, etc. Be a knowledge guide on the various business entities, data marts. Train users of our data on SQL and analytics best practices. Come up with new tools, processes, documents and explore new tech during the cool-down periods. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Remote in France / Sophia Antipolis / Paris Type of contract: Permanent Start Date: ASAP For the France offices üá´üá∑ üè° Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) üí∞International Group Savings Plan offered through the Vivendi Group üçº 8 weeks paid Paternity leave or Co-parental leave üï∂Ô∏è Excellent Employee Culture (Company Events / Training / Parties / All hands ‚Ä¶) üöÄ Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review ‚Ä¶) üè• Company-paid Health Insurance and Personal Services Vouchers (CESU) üöÜCommuter benefit coverage - Public Transport and Bike refund ‚õ±Ô∏è Paid Time off ‚Äì RTT and Saving time plan (CET) ‚úÖ Meal Vouchers üé°Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles BS/MS in Computer Science, Engineering or related field 2+ years experience around Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. 1+ years of experience developing and debugging software in Python. Good business modeling skills: going from a stakeholder‚Äôs expressed requirements to an actual data model. Ability to work with multiple stakeholders - Product, Engineers, Analysts, Product managers, DevOps, etc. Comfortable working with Linux and the GCP stack Experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies is a plus. Experience in real-time analytics databases like Apache Druid is a plus. Familiarity with NoSQL technologies such as Aerospike is a plus. Writing and speaking proficiency in English Technologies used by the team: Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine, etc), Python, GO, Airflow, SQL, Git, Java, JSON, Bash, Docker, Druid, Kubernetes, etc","Dailymotion is looking for a Data (Analytics) Engineer to join their Analytics Engineering team. The team's mission is to provide trustworthy and available data to enable analysis and insights throughout the company. The role requires skills in Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. It also requires software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. The ideal candidate will have experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies. The role is permanent and can be remote or office-based in France.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,3,0.06924437360389604
246,37378,https://www.welcometothejungle.com/fr/companies/qotid/jobs/product-owner-data-h-f-cdi_paris,Product Owner / Data engineering  (CDI),QOTID,"{dataset,via,SQL}",T√©l√©travail total possible,N,SaaS / Cloud Services,CDI,2022-10-18,"Bonjour √† toi et bienvenue chez Qotid ! üëã Tu souhaites embarquer dans une aventure humaine pleine de challenge ? Alors, tu es au bon endroit ! Qotid est une Fintech qui propose une solution de pilotage de la performance √† destination des dirigeants de PME et directions financi√®res (DAF, RAF, Experts comptables) qui leur permet de consolider des donn√©es de diverses sources (logiciel de ventes, logiciel comptable, etc) et de les visualiser √† travers une interface de data visualisation no code pour cr√©er des tableaux de bords sur mesure, suivre leur rentabilit√© et pr√©voir facilement leur tr√©sorerie via la r√©alisation de budgets. Nous avons d√©velopp√© notre propre solution de business intelligence et mobilisons l‚Äôexpertise de notre √©quipe pour perfectionner notre solution et r√©pondre aux besoins du march√©. Pour acc√©l√©rer notre croissance, nous avons besoin d‚Äôun(e) vrai(e) champion(ne) comme Product Owner / Data Engineering! Tes missions principales : ‚Ä¢ Analyse des besoins du client ‚Ä¢ Mod√©lisation de la base de donn√©e ‚Ä¢ R√©daction et priorisation des users stories ‚Ä¢ Gestion du backlog, suivi et animation des √©quipes techniques en m√©thode Agile ‚Ä¢ Challenger les √©quipes sur les fonctionnalit√©s et le design ‚Ä¢ Phase de tests et recettes ‚Ä¢ Contr√¥le qualit√© sur la plateforme, gestion des bugs et correction en base de donn√©e ‚Ä¢ Preparation de dataset en vu des tests unitaires ‚Ä¢ Gestion et mise √† jour des supports internes. De formation ing√©nieurs, commerce ou universitaire bac +5 vous justifiez d‚Äôune exp√©rience minimum de 2 ans sur des enjeux autour de la data (collecte, mod√©lisation, visualisation) en stage ou en CDI dans le domaine du contr√¥le de gestion, finance d‚Äôentreprise, gestion de projet finance. Comp√©tences : ‚Ä¢ Tu as l‚Äôesprit startup : dynamisme, adaptabilit√© et bonne humeur. ‚Ä¢ Tu fais preuve d‚Äôune grande autonomie et d‚Äôune implication √† toute √©preuve ‚Ä¢ Tu es force de proposition et tu aimes te fixer des objectifs ambitieux. ‚Ä¢ Tu as une forte app√©tence pour les chiffres. Une connaissance sur les enjeux finance et comptabilit√© est un plus. ‚Ä¢ Vous avez de l‚Äôexp√©rience en pilotage de projet et maitriser la m√©thode Agile. ‚Ä¢ Vous √™tes √† l‚Äôaise avec la Data et vous avez quelques connaissances en langage SQL, en gestion de base de donn√©es et sur les environnements ETL ‚Ä¢ Vous ma√Ætrisez l‚Äôanglais oral et √©crit. Une deuxi√®me langue est un plus Le lieu de travail est √† Station F mais peut √©galement √™tre total ou partiel Remote.","Qotid, a Fintech company, is seeking a Product Owner/Data Engineering with at least 2 years of experience in data collection, modeling, and visualization. The ideal candidate should have a startup mindset, strong analytical skills, be highly autonomous, and fluent in English. The position is located at Station F but can be partially or fully remote. Experience in Agile project management and SQL is required.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 6 mois,3,2,0.06924437360389604
159,57149,https://www.welcometothejungle.com/fr/companies/cartelis/jobs/consultant-data-engineer-h-f-cdi_paris,Consultant Data / Analytics Engineer (junior) - Paris,Cartelis,"{Dataiku,Metabase,Airbyte,PostgreSQL,Octolis,DBT,Airflow,dbt,BigQuery,SQL,Python,Tableau}",T√©l√©travail partiel possible,"33, Rue Stephenson, Paris, 75018","Digital Marketing / Data Marketing, IT / Digital, Big Data",CDI,2023-03-26,"Cartelis est un cabinet de conseil qui intervient sur des projets o√π les donn√©es clients sont au c≈ìur des enjeux : Ing√©nierie data / Marketing relationnel / Analytics & BI. Sur ces projets, Cartelis intervient sur l‚Äôensemble de la chaine de valeur, de la conception avec les √©quipes dirigeantes jusqu‚Äô√† √† leur adoption par les √©quipes m√©tiers, et op√®re sur la transformation digitale de startups matures (Openclassrooms, Blablacar, SendinBlue, etc.) et de grands groupes (Renault, Randstad, Valeo, etc.). Fond√©e par une √©quipe d‚Äôentrepreneurs, Cartelis a vite rencontr√© un vrai succ√®s du fait de la qualit√© de ses interventions et ses m√©thodologies efficaces. Cartelis fait partie des rares cabinets qui travaille aussi bien pour les meilleurs startups (BlaBlaCar, OpenClassroom, Sendinblue‚Ä¶) que pour des ETI et grands comptes (Randstad, Renault‚Ä¶). Le cabinet a pour ambition de consolider sa position de r√©f√©rence du conseil en data marketing. Pour porter ce projet, le cabinet s‚Äôappuie sur l‚Äôexpertise d‚Äôune dizaine de consultants et vise de doubler de taille d‚Äôici √† fin 2022. Concr√®tement, √™tre consultant chez Cartelis c‚Äôest : Faire du conseil dans un cabinet qui refuse d‚Äôenvoyer ses consultants en r√©gie, et qui travaille vraiment en multi-missions. D√©velopper rapidement ses comp√©tences business et techniques en travaillant sur des missions vari√©es. Participer √† des aventures entrepreneuriales : l‚Äô√©quipe Cartelis est amen√©e √† √©pauler les structures historiquement lanc√©es par le cabinet ( Salesdorado , la Fabrique du Net, Octolis‚Ä¶). Descriptif du poste R√¥le dans l‚Äô√©quipe Tu prendras une place importante dans la r√©alisation de nos missions data ainsi qu‚Äô√† la vie interne du cabinet en pleine croissance. Exemples de missions clients Ing√©nierie Data : cr√©ation de flux de donn√©es (API, ETL‚Ä¶), mod√©lisation (dbt) et cr√©ation de bases de donn√©es Cloud (Snowlake, PostgreSQL, BigQuery) Data Analytics : encadrement d‚Äôune √©quipe d‚Äôanalystes en charge de l‚Äôexploitation de donn√©es avanc√©es (SQL, Python, Dataiku‚Ä¶) et de reportings automatis√©s (Tableau, Metabase‚Ä¶) Process automation : automatisation des process et des flux de donn√©es. Missions internes : selon ta charge de travail et tes envies, tu participeras √† la vie du cabinet et pourras √©galement intervenir sur nos autres activit√©s ( Octolis , Salesdorado) sur les aspects suivants notamment : Am√©lioration des process internes Accompagnement aux √©volutions produits Les avantages Notre ambition pour toi ? Te former pour que tu puisses devenir Head of Data d‚Äôune belle bo√Æte tech ou devenir consultant data de haut niveau. √Ä l‚Äôintersection du conseil digital et de l‚Äôing√©nierie data, tu b√©n√©ficieras d‚Äôune double-exp√©rience tr√®s pris√©e sur le march√© du travail au sein d‚Äôun secteur en pleine expansion. Tu travailleras sur plusieurs clients en parall√®le pour monter en comp√©tence plus rapidement. Tu √©volueras dans un environnement √† la fois exigeant et bienveillant, au sein d‚Äôune √©quipe jeune et sympathique. Cadre de travail sur mesure : chaque membre de l‚Äô√©quipe adapte sa pr√©sence au bureau selon ses besoins et envies, allant du 100% pr√©sentiel dans des bureaux lumineux d√©di√©s √† l‚Äô√©quipe, au 100% t√©l√©travail. Cette flexibilit√© est permise gr√¢ce √† une optimisation en continu de l‚Äôorganisation interne, qui permet de faciliter les √©changes, en distanciel ou non. ‚ÄúLe groupe vit bien‚Äù : rencontres autour de pause-d√©jeuner pour d√©couvrir les restaurants alentours, bi√®res partag√©es lors de l‚Äôap√©ro bi-mensuel, week-end de team building en dehors de Paris. Tu es issu d‚Äôune formation d‚Äôing√©nieur / informatique Tu as de fortes capacit√©s d‚Äôorganisation, un sens de l‚Äôanalyse aiguis√© et un esprit d‚Äôinitiative Tu es un excellent communicant √† l‚Äôoral comme √† l‚Äô√©crit Tu as un bon niveau d‚Äôanglais √† l‚Äô√©crit et √† l‚Äôoral Les univers de la data et du marketing t‚Äôint√©ressent Tu sais coder dans 2 de ces 3 langages JS/SQL/Python Les petits plus : tu as d√©j√† utilis√© des outils data √† la mode (DBT, Airflow, Airbyte‚Ä¶) Les petits plus : tu ma√Ætrises certains outils martech (CRM, marketing automation, GTM, Google Analytics‚Ä¶) Le precessus de recrutement se fait en 4 √©tapes : Remplir ce formulaire de candidature Une √©tude de cas data √† pr√©parer chez toi Une √©tude de cas d‚Äô1h type ‚ÄúMarket sizing‚Äù sans pr√©paration avec un consultant Un dernier entretien avec un directeur associ√©","Cartelis, a consulting firm specializing in data-driven projects such as data engineering, relational marketing, analytics, and BI, is seeking a consultant with coding skills in either JavaScript, SQL, or Python. The ideal candidate should have strong organizational skills, excellent communication skills, and an initiative-driven mindset. Successful applicants will have the opportunity to work on multiple client projects simultaneously and participate in the development of internal projects. The company offers a flexible working environment, with a mix of remote and in-person work options. The recruitment process includes four stages, including an at-home data case study and a one-hour exercise with a consultant.",Bac +5 / Master,< 15 salari√©s,> 6 mois,2,3,0.06924437360389604
254,56309,https://www.welcometothejungle.com/fr/companies/lydia/jobs/analytics-engineer_paris_LYDIA_wwlgKoV,Analytics Engineer,Lydia,"{dbt,SQL,python}",T√©l√©travail partiel possible,"Paris, 75004","Application mobile, Banque",CDI,2023-03-26,"With over 7 million active users and an impressive 5,000 new customers joining every day, Lydia aims to become one of Europe‚Äôs leading financial services organisations. Founded in 2013, Lydia has been recognised as one of France‚Äôs most promising start-ups through its recent inclusion into the ""Next 40"" ranking. After raising ‚Ç¨112 million from investors in 2020, we have plans to accelerate our European deployment while continuing to offer additional innovative solutions. From top-security contactless mobile payment to a wide array of app-based services, Lydia puts people at the centre of the digital banking experience. We are looking for an Analytics Engineer to join the Customer Care squad. This squad is in charge of humanizing banking digital experience and support users efficiently. You will be the data referent of this specific company vertical, responsible for everything from data ingestion to data analysis, all while improving and maintaining the Data Warehouse. To help the squad reach its goals, you will be in close contact with a diverse team of talents: mobile developpers, backend, frontend, product owner, etc‚Ä¶ You will also have the opportunity to contribute to the Data Engineering story : A transverse team of 3 data engineers dedicated to improve our tooling, improve processes, etc. All to enable you to meet your goals. What you will do : - Proactively design and maintain a robust and product friendly data model for our Data Warehouse for each business unit with an eye towards performance and scalability. - Example Projects: Design a data model to let the marketing team and data analysts follow-up conversions in a maintainable and scalable way. - Collaborate with data engineers to design and implement state-of-the-art pipeline frameworks and apply coding guidelines and principles to ETL and ELT code. - Example Projects: Build an efficient reverse ETL task to give customer care agents access to enriched data for a personalized customer experience. - Collaborate with Product and Tech teams to ensure the data sent by apps is able to fulfill the analytical needs of each business unit. - Example Projects: Check that the data collection specifications will fit the analytical needs of the marketing team when a new product is launched. You are in the right place if : - You have a MSc in computer science or related fields from an engineering school - You have had an experience (internship or full-time) in an analytical position (data engineer, data analyst, software engineer) - You are willing to help end-users in their analytical journey - You are willing to code in python and SQL with high quality coding standards - You have between 0 and 5 years experience - You are curious and autonomous - You are fluent in English, both orally and in writing Nice to have : - knowledge of dbt - a previous experience in a customer care related field Recruitment Process : - Initial interview by phone with the Recruitment Team ; - First round of interviews at Lydia with the Vertical Lead Manager ; - Technical Case Study; - Second round of interviews with a member of our Data team. At Lydia, we believe that diversity is a strength. Diversity is part of our culture and identity. We want to create an inclusive culture where all forms of diversity are seen as a real value to the company. Lydia is therefore proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, colour, national origin, sex, sexual orientation, gender identity, gender expression, physical characteristics, age, status as an individual with a disability, or other applicable legally protected characteristics.","Lydia, a digital banking start-up in France, is seeking an Analytics Engineer to join their Customer Care squad, responsible for humanising the banking digital experience and supporting users efficiently. The successful candidate will be responsible for data ingestion, analysis, and maintaining the Data Warehouse, working closely with a diverse team of talents. Required skills include a MSc in computer science, experience in an analytical field, coding proficiency in Python and SQL, and fluency in English. Diversity is valued, and Lydia is an equal employment opportunity employer.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,< 6 mois,2,3,0.06924437360389604
416,39703,https://www.welcometothejungle.com/fr/companies/pwc/jobs/data-engineer-junior-cdi-f-h_neuilly-sur-seine,Data Engineer Junior | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",T√©l√©travail partiel possible,"63, rue de villiers , Neuilly-Sur-Seine, 92200","Strat√©gie, Audit",CDI,2022-11-29,"Chez PwC, nous croisons les approches et multiplions les possibles pour inventer un monde de solutions durables. Nous associons les meilleurs talents aux derni√®res technologies pour aider nos clients √† d√©cupler la confiance. C'est la strat√©gie mondiale du r√©seau PwC, The New Equation. Parce que votre terrain de jeu est sans limites, nous vous offrons des missions ambitieuses, une organisation flexible, un environnement de travail unique et des opportunit√©s de d√©veloppement illimit√©es. En France, PwC est certifi√© Top Employer. Nous sommes √©galement partenaire officiel des Jeux Olympiques et Paralympiques de Paris 2024, en accompagnant son comit√© d'organisation dans la tenue du plus grand √©v√©nement mondial : l'opportunit√© de contribuer √† des projets complexes et porteurs de sens. Faites partie des 8 000 nouveaux talents qui rejoindront nos √©quipes France et Maghreb d'ici 2025. Rejoignez vous aussi La Nouvelle √âquation. PwC poursuit sa strat√©gie mondiale The New Equation, port√©e par l'humain, nos engagements responsables, soci√©taux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la r√©alit√© virtuelle et de technologies √©mergentes. Notre communaut√© Data et IA r√©unit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la cha√Æne de valeur, de la strat√©gie √† l'ex√©cution, afin d'accompagner nos clients sur l'ensemble de leurs m√©tiers et de leurs entit√©s, dans leur ""data transformation "". Ce que vous pouvez attendre de nous En tant que Data engineer dans les √©quipes Data & IA de PwC votre mission sera de: Contribuer √† la d√©finition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en √©troite collaboration avec les data architects Mettre en ≈ìuvre ces solutions en mode Agile en optimisant : La performance et le passage √† l'√©chelle La qualit√© des donn√©es et des mod√®les au fil du temps La coh√©rence avec les outils et les frameworks existants La qualit√© et conformit√© (revue cyber, Cloud, auditabilit√© des traitements, RGPD) Mise en place de CI/CD pour le d√©ploiement des solutions chez les clients Notre boite √† outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes - Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous √™tes dipl√¥m√©(e) ou futur(e) dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√© (type Master2..) avec une majeure en syst√®me d'information, en Data ou en Datascience. Vous √™tes particuli√®rement int√©ress√© par la mise en oeuvre de solutions data compl√®te et par la gestion des flux et leur orchestration (notamment √©v√©nementielle) tout cela dans des environnements cloud Vous avez pu exercer cet int√©r√™t et vos talents dans vos exp√©riences pass√©es sur une ou plusieurs composantes de la cha√Æne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD‚Ä¶ Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte √©cologique","PwC is seeking a Data Engineer to contribute to the definition and design of innovative Data Analytics and Big Data solutions in collaboration with their Data Architect team. The role involves implementing solutions in an Agile manner with a focus on scalability, data quality, and compliance while utilizing technologies such as Microsoft Azure, Google Cloud Platform, Amazon Web Services, and Python. Candidates should have experience with data pipelines, data lakes, machine learning algorithms, and APIs, and possess a global mindset to design sustainable solutions.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
451,56938,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-adtech-all-genders_paris,Junior Data Engineer - AdTech (All Genders),Dailymotion,"{Flink,Beam,Jenkins,Go,Airflow,Kubernetes,Datadog,Dataflow,Docker,Java,SQL,K8S,Python,BigQuery}",T√©l√©travail partiel possible,"140, Boulevard Malesherbes, Paris, 75017","Big Data, M√©dia, Publicit√©",CDI,2023-03-26,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Our team context: Dailymotion is seeking a Junior Data Engineer to join the Data tribe. Our tribe is responsible for all the Data products at Dailymotion; your work will have an impact throughout Dailymotion‚Äôs business and help make data-driven decisions on products and strategy. You will join a team of Data and Machine Learning engineers who have built Software that processes hundreds of terabytes of data, billions of real-time events, hundreds of tasks automated by Airflow and millions of API calls every day. Multiple machine learning projects including recommender systems, semantic annotations, spam detection, and fraud detection. What we will do together: Our stack runs almost exclusively on Google Cloud Platform. You will work in an environment made up of Data Lakes (BigQuery, etc.), data streaming platforms (Beam / Dataflow, Flink, etc.), orchestration and scheduling platforms (Airflow), container-oriented deployment, and management platforms (Docker, K8S, Jenkins), SQL. You will also participate in data modeling activities and design of data flows until their implementation and support in production. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Paris Type of contract: Permanent Start Date: ASAP For the France offices üá´üá∑ üè° Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) üí∞International Group Savings Plan offered through the Vivendi Group üçº 8 weeks paid Paternity leave or Co-parental leave üï∂Ô∏è Excellent Employee Culture (Company Events / Training / Parties / All hands ‚Ä¶) üöÄ Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review ‚Ä¶) üè• Company-paid Health Insurance and Personal Services Vouchers (CESU) üöÜCommuter benefit coverage - Public Transport and Bike refund ‚õ±Ô∏è Paid Time off ‚Äì RTT and Saving time plan (CET) ‚úÖ Meal Vouchers üé°Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles Why you are a perfect candidate for us: ‚Ä¢ You have at least 1 year accumulated experience as a Data Engineer ‚Ä¢ You are fluent in English and French ‚Ä¢ You are a team player, continually suggesting improvements and effective collaboration. ‚Ä¢ You like to implement new technologies and innovative solutions as well as the associated prototyping. ‚Ä¢ You know how to write technical specifications. ‚Ä¢ You have hands-on experience or interest in building/managing Big Data pipelines. ‚Ä¢ You will be motivated in working on building batch and streaming data streams to process a large number of events. ‚Ä¢ You have hands-on experience with different languages e.g.: Python, Go lang, Java, monitoring of development standards to ensure delivery of reusable and good quality code. ‚Ä¢ You have hands-on experience with different types of databases and SQL knowledge. ‚Ä¢ You have experience establishing and maintaining integration tests. ‚Ä¢ Experience on how to automate your deployments (Docker, Kubernetes, CI, Datadog‚Ä¶) ‚Ä¢ You have an entry-level knowledge on how to analyze, design, or improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes. What we offer you: ‚Ä¢ Additional opportunities as we grow and learn together. ‚Ä¢ Join our open, collaborative culture. ‚Ä¢ Exciting, dynamic projects to work on. ‚Ä¢ Flexibility to work remotely.","Dailymotion is seeking a Junior Data Engineer for their Data tribe. Candidates should have at least one year of experience as a Data Engineer, hands-on experience or interest in building and managing Big Data pipelines, and experience with different types of databases and SQL knowledge. Candidates should also be a team player and have an entry-level knowledge of analyzing, designing, or improving the efficiency, scalability, and stability of data collection, storage, and retrieval processes. The position offers opportunities for growth, dynamic projects, and flexibility to work remotely.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,3,0.06924437360389604
383,34317,https://www.welcometothejungle.com/fr/companies/bforbank/jobs/data-engineering-manager-h-f_la-defense,Data Engineering Manager,BforBank,"{Oracle,Python,GitLab,Looker,Informatica,Kafka,via,Neo4j}",T√©l√©travail partiel possible,La D√©fense,Banque,CDI,2022-08-08,"Sur le mod√®le d'une ""Tech company"", BforBank place l'innovation et le digital au coeur de sa transformation. Notre mission, offrir √† nos clients une exp√©rience bancaire incomparable pour r√©pondre leurs besoins et usages mobile. Rejoindre BforBank c'est rejoindre une √©quipe engag√©e dans un grand projet de d√©veloppement strat√©gique en France et en Europe. Nous sommes aujourd'hui 280 passionn√©(e)s et recherchons nos talents de demain. Vous avez l'esprit d'initiative ? Vous partagez les valeurs d'engagement et de performance ? Vous √™tes anim√© par le travail en √©quipe ? Ces qualit√©s nous rassemblent, n'h√©sitez plus et rejoignez-nous ! Pr√©sentation du service Au sein de la direction Tech, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d'usage data et d'automatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data. Vos missions principales sont les suivantes : En tant que Manager du pole Data Engineering, tu es le point d'entr√©e des directeurs m√©tiers Produits, Exp√©rience Client, Performance, Conformit√© afin de les accompagner dans leurs projets technologiques li√©s √† la data. En tant que Manager, tu auras la charge de construire ton √©quipe, de l'animer et de la faire grandir. Ton √©quipe sera constitu√©e d'experts Tech, de Data Engineers, d'Agile Delivery Leads, de Business Analysts IT, de testeurs Les projets sont men√©s soit en mode agile au sein de squads pluridisciplinaires, soit en cycle en V. Plus concr√®tement: Management op√©rationnel et hi√©rarchique Responsable du staffing et du capacity planning de l'√©quipe, Management humain des ressources de son domaine: d√©veloppement des comp√©tences, des parcours professionnels, satisfaction collaborateurs Recrutement internes, Sourcing des ressources tech int√©grant des squads / projets du p√©rim√®tre (en lien avec les leads chapter), Responsabilit√© d'un budget externe, Optimisation du dispositif pour remplir tes objectifs Delivery des projets Suivi d'un portefeuille de projets, Appui aupr√®s des squads et projets de votre p√©rim√®tre pour que le delivery soit le plus efficace possible, que la squad travaille en autonomie, et que les objectifs soient remplis, Appui √† l'on boarding des nouveaux collaborateurs: poste de travail, habilitations, logistique, Facilite la planification des releases et permet l'identification des adh√©rences en transversalit√© des squads, Aide les directions M√©tiers √† atteindre leurs objectifs de qualit√© Favoriser la diffusion des bonnes pratiques de delivery et de d√©veloppement logiciel dans votre p√©rim√®tre, S'assurer de la bonne coordination des diff√©rents intervenants des services Tech, y compris Architectes et DevOps. Transformation Tech Ambassadeur de la Tech aupr√®s des directions M√©tiers et des Product Managers, vous aurez un r√¥le de conseil Tech sur votre p√©rim√®tre, Participation active √† la veille Technologique et l'acculturation DATA de l'entreprise, Contribution √† la diffusion de la culture Tech dans l'entreprise, Point d'entr√©e du ou des directeurs M√©tiers pour la direction Tech pour votre p√©rim√®tre, Favorise le travail en transversal au sein de la direction Tech et au-del√†, Contribue aux chantiers de transformation tech, et accompagne les √©quipes, S'approprie les OKR et contribue via vos actions √† l'atteintes de KR, Relai de la transformation des modes de travail Comp√©tences recherch√©es : Ce que vous ma√Ætrisez : Le pilotage de projets en cycle en V et en agile Le management op√©rationnel de profils technologiques L'architecture d'un SI Les th√©matiques Comptabilit√© Bancaire et/ou Conformit√© Bancaire, ou RH L'int√©gration de progiciels ou de solutions en mode Saas. Ce poste est fait pour vous si : Vous avez une premi√®re exp√©rience r√©ussie en tant que Manager IT Vous faites preuve de leadership Vous avez une bonne capacit√© √† f√©d√©rer et √† communiquer au-del√† de votre √©quipe Vous savez travailler dans des environnements en forte transformation et aimer la conduite du changement Vous √™tes autonome et rigoureux Outils informatiques : Environnement Technique : Database : Big Query, Oracle, Neo4j Pipeline/processing : Kafka, Informatica, Python Reporting : Looker, Business Objects, Linkurious Infra : Google Cloud Platform et On Premise Ops : Terraform, GitLab Ce que vous ma√Ætrisez : Le pilotage de projets en cycle en V et en agile Le management op√©rationnel de profils technologiques L'architecture d'un SI Les th√©matiques Comptabilit√© Bancaire et/ou Conformit√© Bancaire, ou RH L'int√©gration de progiciels ou de solutions en mode Saas. Ce poste est fait pour vous si : Vous avez une premi√®re exp√©rience r√©ussie en tant que Manager IT Vous faites preuve de leadership Vous avez une bonne capacit√© √† f√©d√©rer et √† communiquer au-del√† de votre √©quipe Vous savez travailler dans des environnements en forte transformation et aimer la conduite du changement Vous √™tes autonome et rigoureux Formation: Tu es dipl√¥m√©(e) d'un master en √©cole d'ing√©nieur ou √©quivalent. Chez BforBank nous recherchons avant tout des comp√©tences. Vous ne disposez pas du dipl√¥me requis mais avez des exp√©riences √©quivalentes ? N'h√©sitez pas √† postuler ! Exp√©rience : Exp√©rience de 5 ans minimum en tant que manager d'une √©quipe IT data.","BforBank is seeking a Manager of Data Engineering to lead a team of experts in technology and data engineering, responsible for deploying and operating the best technological solutions to meet the bank's data usage and process automation needs. Key skills required include project management, operational management, leadership, good communication skills, and the ability to work in a rapidly changing environment. The successful candidate will have at least 5 years of experience as an IT data team manager and a master's degree in engineering or equivalent.",Bac +5 / Master,Entre 250 et 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
193,54871,https://www.welcometothejungle.com/fr/companies/pwc/jobs/data-engineer-junior-cdi-f-h_neuilly-sur-seine_PF_ewYAaAm,Data Engineer Junior | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",T√©l√©travail partiel possible,"63, rue de villiers , Neuilly-Sur-Seine, 92200","Strat√©gie, Audit",CDI,2023-03-24,"Chez PwC, nous croisons les approches et multiplions les possibles pour inventer un monde de solutions durables. Nous associons les meilleurs talents aux derni√®res technologies pour aider nos clients √† d√©cupler la confiance. C'est la strat√©gie mondiale du r√©seau PwC, The New Equation. Parce que votre terrain de jeu est sans limites, nous vous offrons des missions ambitieuses, une organisation flexible, un environnement de travail unique et des opportunit√©s de d√©veloppement illimit√©es. En France, PwC est certifi√© Top Employer. Nous sommes √©galement partenaire officiel des Jeux Olympiques et Paralympiques de Paris 2024, en accompagnant son comit√© d'organisation dans la tenue du plus grand √©v√©nement mondial : l'opportunit√© de contribuer √† des projets complexes et porteurs de sens. Faites partie des 8 000 nouveaux talents qui rejoindront nos √©quipes France et Maghreb d'ici 2025. Rejoignez vous aussi La Nouvelle √âquation. PwC poursuit sa strat√©gie mondiale The New Equation, port√©e par l'humain, nos engagements responsables, soci√©taux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la r√©alit√© virtuelle et de technologies √©mergentes. Notre communaut√© Data et IA r√©unit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la cha√Æne de valeur, de la strat√©gie √† l'ex√©cution, afin d'accompagner nos clients sur l'ensemble de leurs m√©tiers et de leurs entit√©s, dans leur ""data transformation "". Ce que vous pouvez attendre de nous En tant que Data engineer dans les √©quipes Data & IA de PwC votre mission sera de: Contribuer √† la d√©finition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en √©troite collaboration avec les data architects Mettre en ≈ìuvre ces solutions en mode Agile en optimisant : La performance et le passage √† l'√©chelle La qualit√© des donn√©es et des mod√®les au fil du temps La coh√©rence avec les outils et les frameworks existants La qualit√© et conformit√© (revue cyber, Cloud, auditabilit√© des traitements, RGPD) Mise en place de CI/CD pour le d√©ploiement des solutions chez les clients Notre boite √† outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes - Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous √™tes dipl√¥m√©(e) ou futur(e) dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√© (type Master2..) avec une majeure en syst√®me d'information, en Data ou en Datascience. Vous √™tes particuli√®rement int√©ress√© par la mise en oeuvre de solutions data compl√®te et par la gestion des flux et leur orchestration (notamment √©v√©nementielle) tout cela dans des environnements cloud Vous avez pu exercer cet int√©r√™t et vos talents dans vos exp√©riences pass√©es sur une ou plusieurs composantes de la cha√Æne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD‚Ä¶ Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte √©cologique","PwC is seeking a Data Engineer to join its Data & AI teams. The successful candidate will be responsible for designing and implementing innovative data analytics and big data solutions in a cloud environment, collaborating closely with data architects. The ideal candidate should have experience in various data-related components, including cloud infrastructure, data pipelines, data lakes, machine learning algorithms, and APIs, among others. Proficiency in Python, Docker, Kubernetes, Git, and cloud platforms such as Azure, AWS, or GCP is required. A degree in Computer Science or a related field is also required.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
191,49832,https://www.welcometothejungle.com/fr/companies/canopee/jobs/data-engineer-coperneec_paris,Data Engineer - COPERNEEC,Canopee Group,"{MapReduce,Tensorflow,Scala,Kafka,R,Spark,Azure,Hadoop,Python}",T√©l√©travail total possible,"77 Boulevard Berthier, Paris, 75017","Intelligence artificielle / Machine Learning, Transformation, Finance",CDI,2023-02-07,"Coperneec est un cabinet de conseil sp√©cialiste de la valorisation de la Data. Les expertises de nos consultants couvrent toute la cha√Æne des savoir-faire : Data Science, Data Analysis, Data Engineering et Data Business Analysis. Nos m√©thodes et techniques scientifiques √©prouv√©es permettent de r√©soudre les probl√©matiques Data dans tous les secteurs de l‚Äôindustrie. Le but : extraire la connaissance √† partir des donn√©es et p√©renniser les avanc√©es technologiques qui en d√©coulent. La R&D est au c≈ìur de notre ADN ! ¬´ From revolution to performance ¬ª avec Coperneec ! Vous √™tes Data Engineer et avez un go√ªt prononc√© pour les probl√©matiques data, l‚Äôimpl√©mentation technique de solutions innovantes et l‚Äôadministration de plateformes Big Data √† fortes valeurs ajout√©es ? Coperneec recrute ! En nous rejoignant, vous aurez l‚Äôoccasion d‚Äôint√©grer des p√¥les de Data Engineering au sein de Directions M√©tier, Data Labs, ou DSI, dans un √©cosyst√®me allant du secteur bancaire et financier √† l‚Äôensemble de l‚Äôindustrie. Vous serez amen√©(e) √† : Comprendre pr√©cis√©ment les probl√©matiques m√©tier, ainsi que la compl√©xit√© des environnements IT associ√©s Participer √† des projets d‚Äôarchitecture, proposer et d√©velopper des outils ‚Äúin house‚Äù offrant un acc√®s et un traitement de la donn√©e optimis√© Etre garant de l‚Äôimpl√©mentation des algorithmes et de leur performance Vous communiquerez vos r√©sultats et vos solutions en les confrontant avec les √©quipes m√©tier et techniques Vous √©voluerez √©galement au sein de la Practice Data Engineering, et pourrez y d√©velopper des √©tudes et travaux de recherches innovants. Vous √™tes diplom√©(e) d‚Äôune Ecole d‚ÄôIng√©nieur et/ou d‚Äôun 3√®me cycle universitaire sp√©cialis√© en Data Science ou Data Engineering Vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie en tant que Data Engineer tous secteurs Python, Hadoop, Scala, Spark, MapReduce, Kafka, Tensorflow, infrastructures Cloud Azure‚Ä¶ Autant de termes qui n‚Äôont plus de secret pour vous ;) Vous √™tes bon(ne) communiquant(e) et n‚Äôavez pas peur d‚Äôalterner entre conseil et expertise technique Rigoureux(se) et curieux(se), vous faites preuve d‚Äôautonomie et aimez relever de nouveaux challenges scientifiques et techniques","Coperneec, a consultancy firm specializing in Data, is hiring a Data Engineer who has expertise in Python, Hadoop, Scala, Spark, MapReduce, Kafka, and infrastructures Cloud Azure. The candidate must have a degree from an engineering school or a specialized university and a successful experience as a data engineer in various sectors. The role involves understanding business issues, participating in architecture projects, proposing and developing tool solutions, ensuring algorithm implementation and performance, and communicating results and solutions to both technical and business teams. The candidate must be a good communicator, rigorous and curious, and able to switch between technical expertise and consulting.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 6 mois,3,2,0.06924437360389604
60,63386,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-retail-bordeaux_bordeaux,Ing√©nieur Big Data - Retail - Bordeaux,Sopra Steria,"{Oracle,Python,omni,Nifi,Scala,Shell,Kibana,Kafka,Hive,Spark,SQL,Java,NoSQL,Hadoop,Jupyter}",T√©l√©travail partiel possible,"20 avenue Pythagore, Bordeaux, 33700","IT / Digital, Organisation / Management",CDI,2023-03-31,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Retail ¬ª accompagne les grands acteurs de la distribution en Europe : am√©liorer les parcours clients omni-canaux, la performance des canaux de vente digitaux et physiques, ma√Ætriser les op√©rations pour adapter les processus logistiques, proposer une offre mixant produits / services en √©tant innovant, tels sont nos challenges quotidiens. Notre connaissance du m√©tier (logistique, distribution, point de vente) et notre expertise technologique nous permettent d'√™tre un partenaire privil√©gi√© du secteur pour r√©pondre aux nouveaux modes et usages des consommateurs. Votre futur environnement de travail : La Business Unit Retail de Bordeaux est une √©quipe √† taille humaine qui compte plus de 80 collaborateurs passionn√©s intervenant sur des projets complexes, agiles, et √† forte technicit√©. Leur objectif : accompagner les plus gros retailers et acteurs T√©l√©com de la r√©gion dans leur projet de transformation et le d√©ploiement de leurs outils pour leur permettre de garder une longueur d'avance et de r√©pondre √† leurs enjeux de time tomarket ! Votre r√¥le et vos missions : - Concevoir et d√©velopper des solutions Data/IA √† des fins analytics & dashboarding - Accompagner des M√©tiers dans la compr√©hension des Analytics et la mise en oeuvre de solution ""data driven"" - Mettre en oeuvre des solutions industrielles exploitables, mesurables et op√©rables - Communiquer et traduire les r√©sultats complexes et leurs implications aux parties prenantes - Capitaliser sur les solutions pour cr√©er de nouveaux produits, de nouveaux services et de nouvelles opportunit√©s de digitalisation, de valorisation de la donn√©e - Assurer un r√¥le de veille technologique sur tous les outils autours de la data, IA et BI. Ce que nous vous proposons : - Progresser et d√©velopper vos comp√©tences : Avec le dispositif de Management RH, vous √™tes acteur(trice) de votre carri√®re, vous √™tes au centre du dispositif avec votre manager op√©rationnel et votre mentor. Avec un objectif de plus de 5j de formation/an/collaborateur, vous √™tes accompagn√©(e) pour acqu√©rir toutes les comp√©tences n√©cessaires au bon d√©roulement de votre mission et votre carri√®re. L'Academy Sopra Steria dispense aussi bien des formations techniques, que m√©thodologiques ou encore de d√©veloppement personnel. - Construire un avenir positif en mettant le digital au service de l'humain - Evoluer dans une entreprise qui encourage l'audace, la curiosit√© et l'envie d'entreprendre Les avantages √† nous rejoindre : - Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions. - Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement et des primes vacances. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy - La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª. Votre profil : De formation Bac+ 5, vous justifiez d'une exp√©rience en tant que Data Engineer, dans le domaine du Big Data, et vous √™tes passionn√©(e) par les nouvelles technologies. Dynamique, curieux(se), adaptable et force de proposition, vous √™tes capable et avez envie de travailler aussi bien avec des √©quipes techniques que des √©quipes m√©tiers. Vous avez de bonnes connaissances particuli√®rement : - Dans l'√©cosyst√®me Data et IA - Sur les technologies informatiques pour manipuler des bases de donn√©es (Oracle, posgres, NoSQL,..) et sur les framework Hadoop, Spark , Hive , Oozie , Nifi, Jupyter, Kafka - Sur les langages informatiques (SQL, Scala, Python, Java , Shell) vous permettant d'√™tre autonome sur la manipulation des donn√©es - Sur les outils BI et data visualisation (Kibana, Qliksense, power BI ..) - En agilit√© et sur les outils associ√©s (scrum, confluence, Jira, ..) Au-del√† de votre expertise technique, vous avez une bonne communication orale et √©crite en fran√ßais et en anglais et √™tes capable de vulgariser votre discours. Chez Sopra Steria, nous sommes engag√©s pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les diff√©rences. Tous nos postes sont ouverts aux personnes en situation de handicap. https://www.soprasteria.fr/carrieres/decouvrez-sopra-steria/nos-engagements-rse","Sopra Steria, an European Tech leader, is seeking a passionate Data Engineer with experience in Big Data and knowledge of data ecosystem, AI, Hadoop, Spark, Hive, Oozie, Nifi, Jupyter, Kafka, and SQL/Scala/Python/Java/Shell programming. The successful candidate will work collaboratively with technical and business teams to develop, communicate and implement data-driven solutions for clients in the Retail sector. Sopra Steria encourages personal and professional development, promotes an inclusive and respectful work environment, and offers a comprehensive benefits package.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
183,56774,https://www.welcometothejungle.com/fr/companies/groupe-bpce/jobs/data-engineer-h-f-nantes_nantes,Data Engineer [] - Nantes,Groupe BPCE,"{durable,DataIku,Anaconda,GIT,Jenkins,Scala,R,Hive,Spark,GCP,SQL,Hadoop,Python}",T√©l√©travail partiel possible,"Nantes, 44200","Banque, FinTech / InsurTech, Finance",CDI,2023-03-26,"BPCE SI est une entreprise informatique du Groupe BPCE. Avec ses 19 implantations en r√©gions, BPCE SI intervient au plus pr√®s des √©tablissements bancaires. Chaque jour, plus de 2600 collaborateurs imaginent, inventent, testent des solutions innovantes pour faciliter la vie des utilisateurs des Caisses d'Epargne, des Banques Populaires et de plusieurs filiales et √©tablissements bancaires comme le Cr√©dit Coop√©ratif et la SocFim. A travers l'utilisation de nos solutions bancaires, nous sommes pr√©sents dans le quotidien de pr√®s de 1 Fran√ßais sur 2 ! Plus de 80 m√©tiers sont pr√©sents au sein de BPCE SI et plus de 50 technologies et langages de d√©veloppement sont utilis√©s dans nos solutions bancaires ! Entreprise humaine et engag√©e, notre politique de Responsabilit√© sociale de l'entreprise porte des sujets cl√©s comme la mixit√©, la diversit√©, le handicap, la qualit√© de vie au travail et le d√©veloppement durable. Nous attachons une attention particuli√®re √† la r√©ussite de chacun(e). Nos √©quipes sont accompagn√©es tout au long de leur parcours et √©voluent dans un environnement de travail stimulant pour exprimer leurs talents. Alors, pour booster votre carri√®re et profiter de la diversit√© des terrains de jeux que proposent BPCE Solutions informatiques et le Groupe BPCE, rejoignez-nous ! Poste et missions Aupr√®s du Manager du Produit Data Services, vous intervenez dans l'√©quipe Lab & Services - Socle Data en tant que support dans le traitement des sujets Data, en accompagnant les Banques et les acteurs du Groupe BPCE. Sur la base des expressions de besoins auxquelles vous contribuez : Vous d√©finissez les sp√©cifications, concevez, d√©veloppez et mettez √† disposition des solutions logicielles et/ou des corrections sur un p√©rim√®tre applicatif Data principalement orient√© nouveaux usages (Big data Hadoop/Cloud, Power BI, Stambia, ‚Ä¶) Vous participez √† la r√©solution des incidents et effectuez le support utilisateurs Vous ex√©cutez des activit√©s de Data Analyse : Obtenir des donn√©es ad√©quates, trouver les sources de donn√©es pertinentes, faire des recommandations sur les bases de donn√©es √† consolider, modifier, rapatrier, externaliser, internaliser, concevoir des datamarts, voire des entrep√¥ts de donn√©es (data warehouses). Analyser les donn√©es pour traduire une probl√©matique M√©tier en probl√®me math√©matiques/statistiques et r√©ciproquement. Vous ex√©cutez des activit√©s de Data Ingenierie sur l'√©cosyst√®me Big Data / Google Cloud Platform (GCP) servant aux cas d'usages avanc√©s de Data Science des √©tablissements ou Organe Central. Expert en donn√©es Big Data, le Data ing√©nieur r√©alise les composants logiciels, les teste, les assemble et les met √† disposition pour mise en Production, en assure la maintenance corrective ou √©volutive, s'assure de leur comportement, leur pertinence dans le temps. Il r√©dige et met √† jour les documentations associ√©es, Il construit les flux d'alimentation de donn√©es de la plateforme : cr√©ation de Datalab, alimentation du Datalake‚Ä¶, Il ma√Ætrise les processus d'ing√©nierie logicielle : qualit√© de code, disciplines de test, gestion de configuration, automatisation packaging/d√©ploiement, Il adopte une d√©marche d'am√©lioration continue en proposant des am√©liorations de l'usine de d√©veloppement, Il industrialise les mod√®les de Data Science en garantissant la p√©rennit√©, robustesse et performance des traitements en production ; en utilisant les patterns de d√©ploiement standards, utilis√© sur les plateformes concern√©es, Il peut assister les Data Scientist en contribution √† l'analyse, la pr√©paration des donn√©es l'exploration des solutions, Il est en support technique des √©tablissements sur les briques applicatives de la plateforme, Il effectue les veilles techniques et technologiques qui lui permettent d'analyser, concevoir et d√©velopper les composants, et participer √† la mise en place de nouvelles briques techniques, Il r√©alise les tests, la mise en production, la maintenance et la documentation de votre solution. Vous avez d√©velopp√© vos comp√©tences sur : D√©veloppements Big Data sur √©cosyst√®me GCP/Big Query, Spark/SparkML, Hive, Scala, Python, R, Anaconda/Miniconda, DataIku, ... Outils CI/CD : GIT, Bitbucket, Jenkins, XLR, XLD‚Ä¶ Data analyse et connaissance de syst√®mes d√©cisionnels : SQL, HQL, BI Au-del√† de vos comp√©tences techniques, vous √™tes reconnu(e) pour votre esprit d'√©quipe, curiosit√© et autonomie. Vous avez d√©montr√© vos capacit√©s d'analyse et de recherche sur incidents ainsi que sur la compr√©hension et prise en charge de probl√®me en autonomie.","BPCE SI is seeking a Big Data Engineer who will work within the Data Services team to provide support in the handling of data issues, assist banks and other BPCE Group actors, and participate in the analysis, design, development, and deployment of software solutions relating to new uses of data. The ideal candidate will have experience with Big Data developments on the GCP ecosystem, Spark/SparkML, Hive, Scala, Python, R, Anaconda/Miniconda, DataIku, and SQL/HQL in addition to strong teamwork, curiosity, and analytical skills. The role will involve a wide range of activities, including data analysis, data engineering, and technical support.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
189,37435,https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/junior-data-engineer-all-genders_paris_DAILY_5PD8wr,Junior Data Engineer (All Genders),Dailymotion,"{Aerospike,Docker,Beam,Kafka,Linux,Dataflow,Git,NoSQL,Bash,Kubernetes,Java,SQL,Airflow,Druid,Spark,BigQuery,GCP,GO,Python}",T√©l√©travail partiel possible,N,"Big Data, M√©dia, Publicit√©",CDI,2022-10-18,"Founded in 2005, dailymotion is a global video streaming service that connects over 250 million entertainment-seekers to their personal world of news and entertainment. Built on a clever player, intuitive algorithm, and on carefully-selected recommendations made by their experts who really love great videos, dailymotion is the one-stop place for enjoying stories from the best creators around in one heightened video experience. Dailymotion is owned by Vivendi and head-quartered in Paris with offices in London, New-York, Singapore, Marseille and Sophia-Antipolis. Dailymotion is seeking a Data (Analytics) Engineer for the Analytics Engineering team. You will join the Data Engineering & Machine Learning craft. A craft consists of multiple teams of engineers and machine learning experts who collaborate daily to create and run Data products in Dailymotion. Inside this craft, the Analytics Engineering team‚Äôs mission is to provide trustworthy and available data to enable analysis & insights throughout the company (B2C, B2B products, and business teams). Analytics Engineering team builds and maintains products like our multi-petabyte data warehouse, event processors (at tens of thousands of messages per second), highly scalable client-facing analytics, data ingestion & distribution, synchronizing data across databases & systems, etc. The team is responsible for making costs-performance tradeoffs around data modeling & architecture. The team is also involved with training users of our data on SQL and analytics best practices and spearheading a significant effort around data governance. Analytics Engineering is a new and emerging space within the Data sphere. As an Analytics Engineer, you bring a software engineering mindset, best practices to maintain analytics code, and to model data from its source to its use in the data warehouse as business and reporting data. It requires a mix of programming skills and data skills on a day-to-day basis. If you are interested in solving challenging business problems with your skills, consider applying to this role. Your impact will be broad and across all of Dailymotion‚Äôs businesses. What you will do: Collect vast amounts of raw data from internal sources and external sources in batch and streaming modes. Expose the data through APIs, flat files, data marts, etc., for internal and external users. Design Druid datasets for external facing consumers for speed, consistency, cost, and efficiency. Write complex and optimal SQL queries to transform data in our data lake into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations through Airflow. Investigate data discrepancy, data quality issues. Debug performance issues using query plan. Design BigQuery table data model to efficiently answer business use cases considering cost and performance. Ensure data is clean, consistent, and available. Perform data quality checks, create monitors. Catalog and document the business entities, data marts, dimensions, metrics, business rules, etc. Be a knowledge guide on the various business entities, data marts. Train users of our data on SQL and analytics best practices. Come up with new tools, processes, documents and explore new tech during the cool-down periods. Additional Information At Dailymotion, we empower candidates to take action. If this job sounds like a great opportunity for you, be confident in your skills, we are always happy to meet you! If needed, we can accommodate our recruitment process for your special abilities. Location: Remote in France / Sophia Antipolis / Paris Type of contract: Permanent Start Date: ASAP For the France offices üá´üá∑ üè° Hybrid Work Framework (4 types of remote work: Full office /Flex office (1/2 days remote) / Flex remote (1/2 days at the office) / Full remote + ability to work 3 months abroad) üí∞International Group Savings Plan offered through the Vivendi Group üçº 8 weeks paid Paternity leave or Co-parental leave üï∂Ô∏è Excellent Employee Culture (Company Events / Training / Parties / All hands ‚Ä¶) üöÄ Career development support (training / career check-in with HR / internal mobility / compensation cycle / 360 quarter feedback review ‚Ä¶) üè• Company-paid Health Insurance and Personal Services Vouchers (CESU) üöÜCommuter benefit coverage - Public Transport and Bike refund ‚õ±Ô∏è Paid Time off ‚Äì RTT and Saving time plan (CET) ‚úÖ Meal Vouchers üé°Workers representatives committee(sports membership/cinemas vouchers/gift vouchers/discount) Feel free to explore Dailymotion culture a little further, please check out: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles BS/MS in Computer Science, Engineering or related field 2+ years experience around Big Data, Data warehousing, writing complex SQL, and debugging complex SQL. 1+ years of experience developing and debugging software in Python. Good business modeling skills: going from a stakeholder‚Äôs expressed requirements to an actual data model. Ability to work with multiple stakeholders - Product, Engineers, Analysts, Product managers, DevOps, etc. Comfortable working with Linux and the GCP stack Experience with PubSub, Data flow, Data Processor, Airflow or Kafka, Spark, or other streaming technologies is a plus. Experience in real-time analytics databases like Apache Druid is a plus. Familiarity with NoSQL technologies such as Aerospike is a plus. Writing and speaking proficiency in English Technologies used by the team: Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine, etc), Python, GO, Airflow, SQL, Git, Java, JSON, Bash, Docker, Druid, Kubernetes, etc","Dailymotion is hiring a Data (Analytics) Engineer to join the Analytics Engineering team. The role involves collecting and transforming large amounts of raw data, designing Druid datasets for external consumers, writing complex SQL queries, and identifying dependencies for transformations. The ideal candidate will have experience in big data, data warehousing, complex SQL, and Python, as well as good business modeling skills and the ability to work with multiple stakeholders. Knowledge of cloud-based technologies and real-time analytics databases is a plus. The position is permanent and can be done remotely in France, Sophia Antipolis, or Paris.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,3,0.06924437360389604
20,49877,https://www.welcometothejungle.com/fr/companies/free/jobs/junior-data-engineer-h-f_paris,Junior Data Engineer  -,Free,"{git,IAM}",T√©l√©travail partiel possible,"16 Rue de la Ville-l'√âv√™que, Paris, 75008",Electronique / T√©l√©communications,CDI,2023-02-07,"Chez Iliad-Free, nous sommes persuad√©s que la Diversit√© est une richesse ! Cr√©√© en 1999, le Groupe ILIAD est un acteur majeur des t√©l√©communications en Europe. Op√©rateur innovant, inventeur de la 1√®re box triple-play au monde, ILIAD est aujourd‚Äôhui pr√©sent en France, en Italie et en Pologne et compte 14 700 collaborateurs au service de 42,7 millions d‚Äôabonn√©s. Maison-m√®re de FREE, le groupe est aujourd‚Äôhui un op√©rateur int√©gr√© Fixe et Mobile Tr√®s Haut D√©bit qui se distingue par ses offres simples et accessible. Rattach√©(e) au Responsable Data Engineering, vous ≈ìuvrez √† la construction et √† la maintenance de la plateforme data d‚ÄôIliad. En cours de construction, cette plateforme assemblera des composants open-source et des d√©veloppements internes avec une haute exigence sur la solidit√©, la performance, l‚Äôergonomie et la s√©curit√©. Accompagn√©(e) par le management du p√¥le, vous participerez au d√©veloppement et au support de cette plateforme ainsi que sa connexion avec le reste du SI des entit√©s d‚ÄôIliad. Vous participerez √©galement avec les data scientists √† la r√©alisation de cas d‚Äôusage. Vous serez amen√© √† travailler, selon les priorit√©s internes, vos go√ªt et comp√©tences sur plusieurs de ces √©l√©ments. La plateforme comporte plusieurs √©l√©ments : Base de donn√©es Plateforme d‚ÄôETL Gestion des droits (IAM) Syst√®me de Self-service de Data Infrastructure de d√©ploiement de Dashboard Infrastructure de d√©ploiement de mod√®le (training et inf√©rence) Analytique sur l‚Äôutilisation de la plateforme Hard-skills : Connaissance th√©orique et pratique du d√©veloppement Un ou plusieurs langages de programmation Familier avec 3 domaines parmi 4 : ops/database/backend/frontend Pratique du d√©veloppement collaboratif (git) Soft-skills : Esprit d‚Äô√©quipe et communication efficace avec ses pairs et ses managers Ax√© sur les r√©sultats, pragmatique et agile Int√©ress√© par l‚Äôinformatique et ouvert sur les m√©thodes (XP, Agile, Craft‚Ä¶) Capable de challenger les autres et de recevoir du feedback Niveau de formation Bac+5 ou √©quivalent dans le domaine de l‚Äôinformatique Evolution possible Data Engineer Senior Data Engineer Lead Data Engineer Principal Data Engineer","Iliad-Free seeks a Data Engineer to build and maintain their data platform using open-source components and internal developments. The platform includes a database, ETL platform, IAM, self-service data system, dashboard deployment infrastructure, model deployment infrastructure, and analytics. The ideal candidate should have theoretical and practical knowledge of development, familiarity with multiple programming languages and domains (ops/database/backend/frontend), practice of collaborative development (git), effective communication and teamwork skills, and an interest in IT and Agile methodologies. A Bac+5 degree in computer science or equivalent is preferred, and the position offers growth opportunities up to Principal Data Engineer.",> Bac +5 / Doctorat,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,3,0.06924437360389604
187,37291,https://www.welcometothejungle.com/fr/companies/ekimetrics/jobs/data-engineer-junior-h-f-n-paris_paris,Junior Consultant Data Engineer  /N),Ekimetrics,{R},T√©l√©travail partiel possible,N,"IT / Digital, Strat√©gie, Audit, Big Data",CDI,2022-10-18,"Ekimetrics est leader europ√©en en data science avec +320 data scientists et +1000 projets depuis 2006. Pr√©sents √† Paris, Londres, NY et HK, ils menent des projets dans +50 pays et pour tous les secteurs d‚Äôactivit√© : services financiers, Retail, Telecom, Sant√©, etc. Leur mission est d‚Äôaider les entreprises √† auditer leurs opportunit√©s data, enrichir leur capital analytique, et d√©ployer des solutions actionnables permettant de maximiser leur performance marketing et op√©rationnelle, et r√©-√©nergiser les business models. Leur focus absolu est de d√©livrer des gains √† court terme, tout en garantissant le d√©veloppement du capital data de nos clients √† long terme. Ils s‚Äôengagent √† proposer les approches data science les plus avanc√©es, et √† construire des pratiques AI √©thiques et durables. Quelques chiffres cl√©s : 16 ann√©es d‚Äôexp√©rience en Data Science +320 data scientists 4 bureaux √† Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit g√©n√©r√© pour nos clients depuis 2006 +1000 projets Data Science Ekimetrics est leader europ√©en en data science avec + 320 data scientists et +1000 projets depuis 2006. Pr√©sents √† Paris, Londres, NY et HK, nous menons des projets dans +50 pays et pour tous les secteurs d‚Äôactivit√© : services financiers, Retail, Telecom, Sant√©, etc. Notre mission est d‚Äôaider les entreprises √† auditer leurs opportunit√©s data , enrichir leur capital analytique , et d√©ployer des solutions actionnables permettant de maximiser leur performance marketing et op√©rationnelle , et r√©-√©nergiser les business models . Notre focus absolu est de d√©livrer des gains √† court terme, tout en garantissant le d√©veloppement du capital data de nos clients √† long terme. Nous nous engageons √† proposer les approches data science les plus avanc√©es, et √† construire des pratiques AI √©thiques et durables. Quelques chiffres cl√©s : 16 ann√©es d‚Äôexp√©rience en Data Science +320 data scientists, tous consultants 4 bureaux √† Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit g√©n√©r√© pour nos clients depuis 2006 +1000 projets Data Science Forts de notre expertise en Data Engineering, nous accompagnons nos clients dans leur Transformation Data afin qu'ils puissent mener √† bien des initiatives ambitieuses orient√©es vers la donn√©e. Nous conseillons nos clients dans le choix de la technologie la plus appropri√©e ainsi qu'√† la mise en place d' Architectures Data robustes et √©volutives. Notre mission est aussi d'accompagner des projets en Business Intelligence & en industrialisation d'algorithmes. D√©couvrez nos derniers projets en Data Engineering : * Pour un opticien, accompagnement dans le design et le d√©ploiement d‚Äôune architecture data lake et dans la construction d‚Äôun mod√®le de donn√©es business constituant le r√©f√©rentiel d‚Äôentreprise (MDM). * Pour un acteur du tourisme, identification des uses cases pertinents et construction d‚Äôune road map data strat√©gique sur 3 ans pour le comit√© de direction. * Enfin pour un acteur de l‚Äôagroalimentaire, mise en place le master data management : architecture, structuration de la plateforme, et int√©gration cloud. Vos missions : * Concevoir et d√©velopper des cha√Ænes complexes * Impl√©menter et industrialiser des algorithmes dans un environnement Big Data * D√©velopper des outils destin√©s √† faciliter l‚Äôacc√®s aux pipelines de donn√©es * Approfondir vos connaissances en Machine Learning * Participer aux activit√©s de R&D (Veille, formations, animation de Meetups, Hackathons, etc.) Profil recherch√© : * Bac+ 5 Ecole d'ing√©nieur ou √âquivalent * Premi√®re exp√©rience sur des sujets Big Data (Projet ou exp√©rience professionnelle) * Exp√©rience dans l‚Äôindustrialisation d‚Äôalgorithmes * Exp√©rience dans un environnement Cloud * Connaissances avanc√©es en acquisition de donn√©es * App√©tence pour la Data Science. Ce que nous offrons : Ekimetrics est pour la premi√®re ann√©e certifi√© Great Place to Work *Un package attractif fixe + variable individuel + int√©ressement + prise en charge de votre pass Navigo √† 50% ou indemnit√© v√©lo + une carte ticket restaurant Edenred + une excellente couverture mutuelle Alan et une politique de t√©l√©travail flexible *Un environnement de travail inspirant : des bureaux en plein c≈ìur de Paris sur les Champs-Elys√©es avec des expositions d‚Äô≈ìuvres d‚Äôart r√©guli√®res sur nos murs * Des formations vari√©es adapt√©es √† tous les niveaux pour rester √† la pointe de votre expertise * Des parcours de carri√®res adapt√©s √† chacun avec des possibilit√©s de mobilit√©s √† l‚Äôinternational * La possibilit√© de participer √† des conf√©rences sur des sujets data * Des √©quipes de sport & des cours de gym (Crossfit, Yoga, Boxing, Football, Basketball) En tant qu‚Äôemployeur, Ekimetrics offre √† tous les m√™mes opportunit√©s d‚Äôacc√®s √† l‚Äôemploi sans distinction de genre, ethnicit√©, religion, orientation sexuelle, statut social, handicap et d‚Äô√¢ge. Ekimetrics veille √† d√©velopper un environnement de travail inclusif qui refl√®te la diversit√© dans ses √©quipes.","Ekimetrics, the European leader in data science, is seeking a Data Engineer to design and develop complex chains, implement and industrialize algorithms in a big data environment, develop tools to facilitate access to data pipelines and participate in R&D activities. The ideal candidate will have a degree in engineering, experience in big data projects, knowledge of data acquisition, and a strong interest in data science. Ekimetrics offers an attractive package including an excellent fixed salary, flexible remote work, and career development opportunities, among others. The company is committed to diversity and inclusivity in the workplace.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,3,0.06924437360389604
215,65923,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-gdo-bi-data-engineer-h-f_paris,ALIT GDO - BI Data Engineer,Air Liquide,"{Azure,durable,Dax,SQL}",T√©l√©travail partiel possible,"Paris, 74000","Environnement / D√©veloppement durable, Sant√©, Energie, Digital",CDI,2023-04-05,"Air Liquide est un leader mondial des gaz, technologies et services pour l'industrie et la sant√©. Pr√©sent dans 75 pays avec 66 400 collaborateurs, le Groupe sert plus de 3,8 millions de clients et de patients. Oxyg√®ne, azote et hydrog√®ne sont des petites mol√©cules essentielles √† la vie, la mati√®re et l'√©nergie. Elles incarnent le territoire scientifique d'Air Liquide et sont au c≈ìur du m√©tier du Groupe depuis sa cr√©ation en 1902. Air Liquide a pour ambition d'√™tre un leader de son industrie, d'√™tre performant sur le long terme et de contribuer √† un monde plus durable - avec au c≈ìur de sa strat√©gie, un engagement marqu√© en faveur du climat et de la transition √©nerg√©tique. Air Liquide est de longue date sensibilis√©e √† la diversit√© et √† l'√©galit√© professionnelle, et poursuit son engagement pour l'emploi des personnes en situation de handicap. Air Liquide a entam√© avec succ√®s sa transformation Digitale et IT , centr√©e sur l'exp√©rience client et l'am√©lioration de de la profitabilit√© des op√©rations, deux piliers majeurs de notre programme NEOS. Cette transformation impacte notre fa√ßon de r√©aliser, g√©rer et monitorer nos op√©rations. Elle implique aussi la d√©finition de nouveaux modes de collaborations, la cr√©ation de nouvelles comp√©tences et de nouveaux postes. Aujourd'hui, le d√©partement Digital & IT poursuit cette transformation tant au niveau de l'infrastructure (GIO), des plateformes data (GDO), que des applications m√©tiers (DSI ou BIS) et des dispositifs cr√©√©s autour de l'innovation, des m√©thodes d'innovation et de la data (Fabs et Factory). Le d√©partement Global Data Operations (GDO) a √©t√© cr√©√© dans l'entit√© Air Liquide IT pour supporter les ambitions du Groupe en mati√®re de gestion des donn√©es, apporter l'expertise technologique pour le d√©veloppement de nouvelles solutions diff√©renciantes pour le business Air Liquide, avec un focus particulier sur les sujets autour de la data dans un premier temps. GDO dans sa phase initiale op√®re trois plateformes : Business Intelligence, Data Lake et API. Au sein de GDO, et rapportant au Technical Lead BI Group le ou la BI Data Engineer d√©fini la roadmap technique pour la Product Line en coh√©rence avec la strat√©gie et les besoins exprim√©s par le Solution Owner et le Product Line manager. Il ou elle est int√©gr√©.e sur les projets structurants et travaille en coordination avec les product managers et le m√©tier afin de s'assurer de la bonne r√©ponse technologique face aux besoins exprim√©s. En tant que BI Data Engineer vous aurez les responsabilit√©s suivantes : Concevoir, d√©velopper, tester et mettre en production des traitements de donn√©es dans diff√©rents contextes m√©tier et applicatifs Concevoir, mettre en oeuvre et optimiser, avec les data architects et devops, les pipelines de traitement de la donn√©e permettant l'alimentation des applications data depuis les sources de donn√©es du Groupe Assurer le support des traitements de donn√©es mis en oeuvre Contribuer √† la d√©finition des processus, standards et m√©thodes techniques permettant d'assurer un haut niveau de qualit√© de service et de livrables R√©aliser et participer avec l'√©quipe √† la veille technologique/l'√©tat de l'art des technologies utilis√©es et √™tre force de proposition Respecter les r√®gles de s√©curit√© et de confidentialit√© du Groupe au sein de la plateforme, et des traitements de donn√©es (security by design, privacy by design) Comp√©tences techniques Exp√©rience minimum de 3-5 ans dans le design et l'impl√©mentation de solution Azure BI de grande envergure Certification sur les produits Data Azure n√©cessaires AZ-900, DP-203 ) Excellente ma√Ætrise SQL & Dax / Azure Data Factory / Azure Analysis services Connaissance des m√©thodologies de d√©veloppement Comp√©tences non techniques Faire preuve d'autonomie, d'esprit d'initiative et de motivation Exp√©rience pass√©e de larges projets de BI en connexion directe avec le m√©tier Capacit√© √† travailler dans un environnement matriciel international (BIS, GIO, Fabs Digitales, IT industriel, entit√©s business) Esprit critique, analyse et r√©solution des probl√®mes Capacit√©s de communication √©crites et orales, en particulier pour vulgariser les sujets techniques L'anglais et le fran√ßais lus, √©crits et parl√©s sont indispensables. Localisation g√©ographique : France / Ile de France / Paris - Le poste est bas√© √† Paris XIe sur le Campus de La Digital Factory. Cat√©gorie professionnelle : Ing√©nieurs et Cadres Des d√©placements occasionnels pourront √™tre n√©cessaires en France ou √† l'√©tranger. Astreintes √† pr√©voir T√©l√©travail 3jrs/semaine","Air Liquide seeks a BI Data Engineer with at least 3-5 years of experience in Azure BI solution design and implementation. The role involves designing, developing, testing, and implementing data processing in various business contexts and applications. The successful candidate must have excellent SQL and Dax / Azure Data Factory / Azure Analysis services skills, be able to work independently, and communicate effectively in English and French, among other qualifications. The job is based in Paris, France, and may require occasional travel.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
453,56847,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/gdo-data-engineer-h-f-self-service-data-initiatives_paris,GDO - DATA ENGINEER  - SELF SERVICE DATA INITIATIVES,Air Liquide,"{durable,git,Tensorflow,Athena,pandas,GitLab,bash,IAM,Glue,AWS,S3,linux,via,moderne,Sagemaker,SQL,Python,numpy}",T√©l√©travail partiel possible,"Paris, 74000","Environnement / D√©veloppement durable, Sant√©, Energie, Digital",CDI,2023-03-26,"Air Liquide est un leader mondial des gaz, technologies et services pour l‚Äôindustrie et la sant√© . Oxyg√®ne, azote et hydrog√®ne sont des petites mol√©cules essentielles √† la vie, la mati√®re et l‚Äô√©nergie. Gr√¢ce √† l‚Äôengagement et l‚Äôinventivit√© de ses collaborateurs pour r√©pondre aux enjeux de la transition √©nerg√©tique et environnementale, de la sant√© et de la transformation num√©rique , Air Liquide cr√©e encore plus de valeur pour l‚Äôensemble de ses parties prenantes. La diversit√© et l‚Äôinclusion du handicap au sein de notre organisation nous permet de r√©pondre au mieux aux d√©fis complexes des march√©s que nous servons, de stimuler l‚Äôinnovation et de contribuer √† cr√©er de la valeur pour nos clients, nos partenaires et la soci√©t√© en g√©n√©ral. Notre m√©thode de gestion des talents ‚Äì de l‚Äôembauche au d√©veloppement de leur carri√®re ‚Äì sont le reflet de notre engagement en faveur de la diversit√© et de l‚Äôinclusion du handicap . La conjugaison de ces √©l√©ments et de la grande part d‚Äôintrapreneuriat au sein d‚Äô√©quipes √† taille humaine nous permet de relever des challenges ambitieux. Au sein de la division Innovation et D√©veloppement, le d√©partement Global Data Operations (GDO) accompagne nos ambitions de strat√©gie et de gouvernance, en apportant l'expertise et les plateformes technologiques Data & IA n√©cessaires au d√©veloppement de solutions diff√©renciantes pour les m√©tiers d'Air Liquide. Au sein de GDO, la Product Line Data Lake & AI a pour mission d'accompagner la strat√©gie de d√©ploiement √† l'√©chelle d'Air Liquide : i) disponibilit√© des donn√©es pour les g√©ographies du groupe, ii) diversification des cas d'usages pour les domaines m√©tiers (BI, Data Science, Digital), iii) passage √† l'√©chelle de l'IA Data du groupe. L'√©quipe travaille en m√©thodologie agile et s'appuie sur une plateforme moderne pour alimenter les cas d'usage m√©tier dans diff√©rents hubs g√©ographiques ( Am√©rique, Asie, Europe et Afrique). Le programme AI Readiness a pour objectif de faire monter les utilisateurs data du groupe Air Liquide en comp√©tences Data & IA d'ici √† 2025. Ce programme inclut des initiatives permettant de rendre nos donn√©es plus accessibles et fiables √† un nombre grandissant de Data Users au sein du Groupe afin de permettre aux Op√©rations de prendre les meilleures d√©cisions, de cr√©er des produits porteurs d'avantage comp√©titif, tout en tenant compte des enjeux de d√©veloppement durable (optimisation, performance √©nerg√©tique, stockage de l'√©nergie via le d√©veloppement de la fili√®re hydrog√®ne, ‚Ä¶). Dans ce cadre, la GDO Data Suite est la solution Air Liquide d'exposition et mise √† disposition des donn√©es des diff√©rents Data Lakes, permettant aux consommateurs de d√©couvrir et d'utiliser cette donn√©e aux travers de notebooks en Python ou SQL worksheets. Missions Au sein de GDO, l'√©quipe User Service GDO Data Suite a pour mission d'assurer l'adoption et le bon accompagnement des utilisateurs des offres self service Data propos√©es par GDO : Data Studio, Data Portal entre autres. La personne sp√©cifiquement en charge du support utilisateur sera amen√©e √† collaborer avec des Data Analysts, Data Scientists, Data Engineers et Machine Learning Engineers dans le cadre du programme AI Readiness qui vise √† d√©ployer les comp√©tences et les outils d'IA au sein du groupe Air Liquide. Ambassadeur Data Suite, le/la Data Engineer fera partie int√©grante de la User Service team , point d'entr√©e des utilisateurs pour la prise en main et accompagnement sur les produits Data Studio et Data Portal . Pour promouvoir l'adoption et la r√©tention des utilisateurs, il/elle devra notamment: Collaborer avec les Data users du groupe, de la cr√©ation de leur projet data sur Data Portal au d√©veloppement de celle-ci sur Data Studio. Accompagner les utilisateurs finaux dans la prise en main de ces outils et services, au travers de coaching, partage de connaissances, voire de formation pour leur permettre de d√©velopper en continu leurs comp√©tences de programmation. Capitaliser sur ces collaborations pour faire √©voluer les produits en collaboration avec les √©quipes Data Studio et Data Portal, en anticipant et remontant les besoins utilisateurs. D√©finir et promouvoir les bonnes pratiques d'usage et de d√©veloppement aupr√®s des Data users, en mettant en place ou en consolidant des m√©thodes et des bonnes pratiques. Animer la communaut√© des data users √† travers des communications, compagnes de feedback pour mesurer la satisfaction etc. D√©finir et mettre en place des KPI pour suivre l'adoption et l'usage des produits. Education et Exp√©rience A partir de Bac+5, Formation Ing√©nieur(e) en Sciences Informatiques, avec une forte orientation data. Comp√©tences techniques De bonnes connaissances en d√©veloppement Python avec une ma√Ætrise de librairies de Machine Learning (numpy, pandas, scikit-learn, Tensorflow, etc.) Technologies cloud: AWS (Sagemaker, CloudWatch, S3, IAM, Athena, Glue, Lake Formation, Fargate, RDS, CLoudFormation ) Syst√®me : OS linux, bash. Ma√Ætrise de git, GitLab Ma√Ætrise de l'apprentissage statistique et en Machine/Deep Learning (apprentissage supervis√©, non supervis√©, etc.) Seraient un plus: Des notions en gestion de donn√©es : collecte, analyse, distribution, etc. Des notions d'Int√©gration Continue / D√©ploiement Continue (CI/CD) Ma√Ætrise des best practices en mati√®re de code Quelques connaissances en Infrastructure as Code (IaC): Cloudformation, Terraform Comp√©tences non techniques Un esprit curieux et d'initiative. Un sens utilisateur pour d√©livrer un service efficace Capacit√© √† travailler dans un environnement international Excellentes capacit√©s de communication √©crites et orales, en particulier pour vulgariser les sujets techniques. Capacit√© d'analyse et de synth√®se avec un esprit critique. L'anglais et le fran√ßais courants √† l'√©crit comme √† l'oral sont indispensables. Horaires et lieux de travail Le poste est bas√© √† Paris XIe sur le Campus de La Digital Factory. Des d√©placements occasionnels pourront √™tre n√©cessaires en France ou √† l'√©tranger. Manager : Data Platform Product Manager Ce que nous offrons L'utilisation des derni√®res technologies et la possibilit√© de travailler avec des experts techniques tr√®s reconnus dans leur domaine La possibilit√© d'apprendre et de monter en comp√©tences en continu dans une √©quipe r√©cente, agile et en croissance Des perspectives d'√©volution au sein du groupe gr√¢ce √† notre politique de mobilit√© interne Un cadre de travail stimulant et multiculturel au c≈ìur de Paris, avec un accord t√©l√©travail en place (3 jours par semaine de t√©l√©travail) De nombreux avantages : Participation/Int√©ressement, prime vacances, carte tickets restaurants, CE, 152‚Ç¨/mois de CESU pour les personnes ayant √† charge un ou plusieurs enfant(s) de 3 ans ou moins ‚Ä¶","The Global Data Operations (GDO) department at Air Liquide is seeking a Data Engineer with strong Python development skills and expertise in machine learning libraries, cloud technologies (especially AWS), and Linux operating systems to ensure adoption and support of self-service data products like Data Studio and Data Portal. The successful candidate will be part of the User Service team responsible for coaching, training, and promoting good practices among data users in collaboration with other data scientists, data engineers, and machine learning engineers at Air Liquide. The Data Engineer will also contribute to the AI Readiness program aimed at upskilling data users across Air Liquide and support the development of differentiated solutions for Air Liquide's businesses worldwide. The Data Engineer will be based in the Digital Factory campus in Paris and may need to travel occasionally both in France and abroad.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,2,3,0.06924437360389604
133,37393,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/junior-data-engineer-m-f_gentilly,Accelerator - Junior Data Engineer,Sanofi,"{GCP,Splunk,Gitlab,Tibco,GitHub,PowerBI,AWS,Snowflake,Shell,scale,R,Airflow,Kedro,Azure,Github,SQL,Python,Tableau}",T√©l√©travail partiel possible,N,Pharmaceutique / Biotechnologique,CDI,2022-10-18,"At Sanofi, we pursue the miracles of science to improve people‚Äôs lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi‚Äôs roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Le contenu du poste est libell√© en anglais car il n√©cessite de nombreuses interactions avec nos filiales √† l'international, l'anglais √©tant la langue de travail. CONTEXT Who we are in a nutshell We are a global biopharmaceutical company focused on human health. Our purpose is to find treatment to fight pain and ease suffering. We combine breakthrough science and advanced technology to develop life-changing medicines and vaccines. Digital & Data is at the heart of Sanofi: our ambition is to be the leading digital healthcare platform to develop & deliver medicine faster, enable healthcare professionals to improve treatments and help patients improve their health. Our scale, strong connections within health ecosystems across leveraging the world, and ability to leverage Sanofi‚Äôs capabilities make us the best place to push the boundaries of medicine through technology. Why joining Sanofi Digital Executive sponsorship and governance, with newly appointed CDO & leadership team Digital & data culture in place with agile ways of working and a strong ecosystem (Sanofi Ventures, BD Partnerships) Unique diversity of medical & technical challenges, with mobility opportunities Awarded ‚ÄúTop Employers France‚Äù 2021 And more specifically, why ‚ÄúAccelerator powered by Sanofi‚Äù A new entity launched March 1st to Become the leading Digital Health platform A separate location, in WeWork (Paris 75017), 5 minutes walk away from the future Sanofi HQ location Startup-like streamlined processes to ensure delivery speed Focused on end-to-end building the most transformative and profitable products The products you will work on We are building next-gen health & digital products, Data Analytics and Artificial Intelligence, including Digital Health products improving the patient experience and treatment adherence, through innovative digital products (Software as Medical Devices) Connected ecosystem solutions such as patients‚Äô glycemic control & full disease management, leveraging connected pens Symptoms checking apps able to understand disease and track symptoms Remote treatment solutions providing individual recommendations, accessible by anyone, anytime, anywhere Personalized care model informed by AI to identify symptoms‚Äô early signals and recommend corrective actions to the patient and the care giver Omnichannel products supporting multi-channel engagement with healthcare providers & patients Multi-channel digital targeting platform to deliver tailored digital campaigns Machine learning and predictive analytics to improve engagement (calls, chats) based on feedback Recommendation engines for cross selling/up-selling and next-best action delivery to sales reps Tailored content delivery based on preference and viewing history Digital Marketing products optimizing marketing campaign‚Äôs reach and impact Market analytics tools to understand key dynamics across categories and identify growth/uplift potential Strategic allocation tools, able to dynamically model impact of different scenarios and achieve sales targets Tactical allocation tools, with built-in ROI response modelling, at ‚Äúbrand x touchpoint level‚Äù JOB PURPOSE You as a Data Engineer You are a dynamic Data Engineer interested in challenging the status quo to ensure the seamless creation and operation of the data pipelines that are needed for the enterprise data and analytics initiatives following industry standard practices and tools for the betterment of our global patients and customers. You are a valued influencer and leader who has contributed to making key datasets available to data scientists, analysts, and consumers throughout the enterprise to meet vital business use needs. You have a keen eye for improvement opportunities while continuing to fully comply with all data quality, security, and governance standards. Your key responsibilities will be Work with business teams to understand requirements, and translate them into technical needs Gather/organize large & complex data assets, and perform relevant analysis Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business case Create data models and optimize queries performance Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new ‚Äústandard data pipelines‚Äù within Sanofi to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community Remains up to date on company‚Äôs standards, industry practices and emerging technologies PROFILE Key Technical Requirements & Qualifications Experience with AWS cloud services (Azure & GCP a plus) Good knowledge of SQL and relational databases technologies/concepts Experience working with data models and query tuning Experience in Data warehousing solutions (Snowflake a plus) Experience in Integration Services (IICS, Tibco a plus) Working knowledge of scripting languages (Python, R a plus) Familiarity with Source Code Management Tools (GitHub a plus) Familiarity with Visualization Tools (PowerBI, Tableau a plus) Familiarity with Project Management Tools (JIRA, Confluence a plus) Familiarity with Service Management Tools (Service Now a plus) Experience working in life sciences/pharmaceutical industry is a plus Relevant cloud certifications (AWS, Azure, Snowflake, IICS) are a plus Experience on working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements is a plus Additional qualifications Strong experience in automation tools and methodologies specifically using Gitlab, Github action, Terraform, Ansible Experience with programming languages such as JSON, YAML, Shell Scripting. Experience with backup system like Netbackup & CommVault Good knowledge of ServiceNow and monitoring tool such as Splunk, BPPM Experience with Real World Data (e,g, EHR, Claims) and standard data models (e,g, OMOP, FHIR) Experience using frameworks to create pipelines (e.g. Apache Airflow, Kedro) Soft and behavioral skills Excellent written and verbal communication skills Experience working with multiple teams to drive alignment and results Service-oriented, flexible, positive team player Self-motivated, takes initiative Problem solving & critical thinking Your background 1-3 years of experience in a data team as Data Engineer Bachelor‚Äôs Degree or equivalent in Computer Science, Engineering, or relevant field Experience in the healthcare industry is a strong plus #Accelerator At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.","Sanofi, a global biopharmaceutical company focused on human health, is seeking a dynamic Data Engineer to contribute to seamless creation and operation of data pipelines, ensuring compliance with standards for data quality, security, and governance. The candidate¬†should have experience with AWS cloud services, SQL and relational databases, data warehousing solutions, integration services, and scripting languages. Knowledge of Source Code Management Tools, Visualization Tools, Project Management Tools, and Service Management Tools would be an added advantage. The ideal candidate should have excellent verbal and written communication skills, be service-oriented, flexible,¬†a positive team player, and possess good problem-solving skills with a critical thinking approach. The position requires 1-3 years of experience as a data engineer with a Bachelor's Degree in Computer Science, Engineering, or a relevant field.",Non sp√©cifi√©,N,Non sp√©cifi√©,2,3,0.06924437360389604
373,57160,https://www.welcometothejungle.com/fr/companies/lita-co/jobs/data-engineer-analyse-esg_paris,Data Engineer/ Analyse ESG - RIFT (CDI),LITA.co,"{MySQL,via,Python}",T√©l√©travail total possible,"24, Rue du Rhin, Paris, 75019","FinTech / InsurTech, Finance",CDI,2023-03-26,"LITA.co est n√©e d‚Äôune volont√© de r√©pondre √† 2 enjeux majeurs : le fort besoin de financement des entreprises √† impact social et environnemental positif, et le manque de transparence et de sens des investissements qui sont propos√©s au grand public. Acteur majeur de l‚Äô√©conomie sociale et solidaire, en lien √©troit avec le MIF (Mouvement Impact France) agr√©e ESUS (Entreprise solidaire d‚Äôutilit√© sociale) et certif√©e B Corp, LITA.co est aujourd‚Äôhui le leader europ√©en de l‚Äôinvestissement en ligne d√©di√© √† l‚Äôimpact positif. Pour aller plus loin, LITA.co a d√©velopp√© l‚Äôapplication ‚ÄúRIFT‚Äù, permettant de scanner son √©pargne pour lever le voile d‚Äôopacit√© sur l‚Äôimpact de nos produits d‚Äô√©pargne (assurance vie, √©pargne bancaire). Une volont√© de transparence qui se concr√©tise par une analyse personnalis√©e via des indicateurs aussi concrets qu‚Äôinnovants. ü§î Pourquoi nous recrutons sur ce poste ? En tant que Data Engineer, tu auras la charge de d√©velopper la base de donn√©es, colonne vert√©brale de l‚Äôapplication RIFT ( https://riftapp.fr/ ) Tu sera responsable de la structuration, de l‚Äôint√©gration et de la mise √† jour des donn√©es de mesure d‚Äôimpact et des donn√©es financi√®res, afin d‚Äôapporter plus de transparence aux utilisateurs sur la fa√ßon dont leur √©pargne est investie. Au sein d‚Äôune √©quipe de 4 personnes (le directeur, 2 d√©veloppeurs, 1 charg√© de communication), tes principales missions seront : La restructuration du serveur de calcul RIFT et son int√©gration dans l‚Äô√©cosyst√®me logiciel La mise en place de processus de scraping de donn√©es publiques (donn√©es extra-financi√®res, composition des portefeuilles, controverse) La participation √† l‚Äôam√©lioration des m√©thodologies de mesure d‚Äôimpact sur la base des jeux de donn√©es les plus aboutis du march√© (empreinte carbone, impact biodiversit√©, indicateurs sociaux) Profil recherch√© Nous recherchons un profil : Ing√©nieur avec au minimum 2 ans d‚Äôexp√©rience sur un poste similaire, Ayant une grande aisance dans le traitement de donn√©es, Maitrisant Python et MySQL (indispensable pour le poste), Ayant de grandes capacit√©s d‚Äôapprentissage et d‚Äôautonomie sur l‚Äôensemble de l‚Äôenvironnement de d√©veloppement, R√©actif.ve, rigoureux.se, avec l‚Äôesprit d‚Äô√©quipe. Le plus ? Un profil ayant des connaissances financi√®res basiques et un int√©r√™t pour la finance √† impact. 1 entretien avec Sixtine, Charg√©e RH 1 entretien avec L√©o, Directeur de RIFT 1 entretien avec Eva Sadoun, Pr√©sidente de RIFT","LITA.co, a major actor in the social and solidarity economy in France, is seeking a Data Engineer to develop the database structure of its application RIFT, which aims to provide transparency on the impact of investment products. The ideal candidate should have at least two years of experience, be proficient in Python and MySQL, and have a strong ability to learn and work independently. A basic knowledge of finance and an interest in impact investing would be a plus.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
282,56607,https://www.welcometothejungle.com/fr/companies/eldo/jobs/data-engineer-f-h_toulouse_ELDO_r9gzY5G,Data Engineer,Eldo,"{MySQL,Talend,PostgreSQL,Airflow,AWS,via}",T√©l√©travail total possible,"Lab'O√Økos Saint Aubin, Toulouse, 31000","SaaS / Cloud Services, B√¢timent / Travaux publics, Digital",CDI,2023-03-26,"Eldo, c‚Äôest la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s‚Äôam√©liorer au quotidien pour d√©velopper leur activit√© üöÄüíö √Ä propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l‚Äôam√©lioration de l‚Äôhabitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la premi√®re plateforme europ√©enne de solutions digitales √† destination des professionnels, marques et consommateurs du secteur de l‚Äôam√©lioration de l‚Äôhabitat. Nous sommes une √©quipe de passionn√©s qui souhaitent r√©volutionner le secteur de l‚Äôam√©lioration de l‚Äôhabitat (76 milliards d‚Äô‚Ç¨). Avec notre suite SaaS nous accompagnons les pros et marques du secteur √† d√©velopper leur activit√© en optimisant chaque √©tape du cycle de vente avec leurs clients. Du moment o√π ils les trouvent sur le web, jusqu‚Äô√† leur satisfaction √† la fin des travaux. Sur notre site B2C, nous aidons les particuliers √† trouver des pros de confiance gr√¢ce aux avis et photos de leurs voisins, pour r√©aliser les travaux de leurs r√™ves. Nous avons un positionnement et un service unique avec : üíªüì≤ une suite applicative SaaS, d√©velopp√©e avec et pour les pros et marques du b√¢timent üì∑üí¨ + 100 000 avis accompagn√©s de photos, vid√©os ; üë®‚Äçüîß des milliers d‚Äôentreprises r√©f√©renc√©es avec un taux de renouvellement/satisfaction de 90%. üè°üí∞ un partenariat avec Google et une certification AFNOR Laur√©ats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs √† succ√®s comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d‚Äôici 2030 la premi√®re plateforme mondiale de solutions digitales √† destination des professionnels de l‚Äôam√©lioration de l‚Äôhabitat. Eldo, c‚Äôest la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s‚Äôam√©liorer au quotidien pour d√©velopper leur activit√© üöÄüíö √Ä propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l‚Äôam√©lioration de l‚Äôhabitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la premi√®re plateforme europ√©enne de solutions digitales √† destination des professionnels, marques et consommateurs du secteur de l‚Äôam√©lioration de l‚Äôhabitat. Nous sommes une √©quipe de passionn√©s qui souhaitent r√©volutionner le secteur de l‚Äôam√©lioration de l‚Äôhabitat (76 milliards d‚Äô‚Ç¨). Avec notre suite SaaS nous accompagnons les pros et marques du secteur √† d√©velopper leur activit√© en optimisant chaque √©tape du cycle de vente avec leurs clients. Du moment o√π ils les trouvent sur le web, jusqu‚Äô√† leur satisfaction √† la fin des travaux. Sur notre site B2C, nous aidons les particuliers √† trouver des pros de confiance gr√¢ce aux avis et photos de leurs voisins, pour r√©aliser les travaux de leurs r√™ves. Nous avons un positionnement et un service unique avec : üíªüì≤ une suite applicative SaaS, d√©velopp√©e avec et pour les pros et marques du b√¢timent üì∑üí¨ + 100 000 avis accompagn√©s de photos, vid√©os ; üë®‚Äçüîß des milliers d'entreprises r√©f√©renc√©es avec un taux de renouvellement/satisfaction de 90%. üè°üí∞ un partenariat avec Google et une certification AFNOR encore renouvel√©e cette ann√©e ! (processus de collecte, mod√©ration et restitution des avis) Laur√©ats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs √† succ√®s comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d‚Äôici 2030 la premi√®re plateforme mondiale de solutions digitales √† destination des professionnels de l‚Äôam√©lioration de l‚Äôhabitat. Descriptif du poste Chez Eldo notre Dream Team s‚Äôagrandit ! üë©‚ÄçüöÄ Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer. Si tu aimes la donn√©e et que les statistiques n‚Äôont aucun secret pour toi‚Ä¶ alors Alessandro et la team n‚Äôattendent que toi ! Regarde par la fen√™tre de l‚Äô√©quipe Product Engineering ! üëÅ La Team Product Engineering, c‚Äôest plus d'une dizaine de collaborateurs passionn√©s et ambitieux accompagn√©s par nos √©quipes marketing, sales, grands comptes‚Ä¶! Ton r√¥le chez Eldo Tu travailleras quotidiennement √† l‚Äô am√©lioration de nos applications (modifications de l‚Äôactuel et cr√©ation) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualit√© et granularit√© de cette derni√®re, le tout, en √©tant un support pour les √©quipes en interne. Pour la partie ‚ÄúEngineer‚Äù, tu seras attendu sur la scalabilit√© de la partie Data, la mise en place d‚Äôarchitecture d√©di√©e, la gestion de la s√©curit√© de la data, la connexion entre l‚Äôarchitecture data et la partie applicative et d√©veloppement produit. Pour la partie ‚ÄúAnalyste‚Äù , tu seras en charge de recueillir les donn√©es internes (bases de donn√©es, fichiers‚Ä¶) et externes (HubSpot, Google Analytics, Partoo‚Ä¶), puis de les centraliser au sein d‚Äôun datawarehouse pour ensuite permettre leur restitution via un outil d√©di√© √† la Business Intelligence (tu seras force de proposition sur les outils √† utiliser). Tu devras bien √©videmment documenter et sp√©cifier les √©l√©ments de services ou mod√®les d√©velopp√©s, ainsi que maintenir une veille active sur les services utilis√©s et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus ad√©quates solutions. Ayant un r√¥le fortement orient√© et driv√© par l‚ÄôImpact business et utilisateur, tu seras naturellement au sein de l‚Äô√©quipe Produit, compos√©e de Product Manager, Product Designer. Tes √©changes quotidiens seront bien √©videmment avec cette √©quipe, mais pas que. Les d√©veloppeurs et toutes les autres √©quipes seront pour toi des stakeholders privil√©gi√©s afin de r√©pondre au mieux au besoin de la strat√©gie Produit et Entreprise. Les √©quipes Product Engineering (PE) travaillent en utilisant la m√©thodologie Agile. Ton environnement de travail sera le suivant: MySQL, PostgreSQL ETL/ELT, Jobs Talend orchestr√©s par Airflow, Hevo data pour la partie no code. APIs d‚Äôoutils externes √† une entreprise (ex : Google Analytics, HubSpot‚Ä¶). Outils de reporting/dashboarding (Amazon QuickSight¬∞. Toucan Toco pour la partie embed dans l‚Äôapplication) Outils de documentation, Confluence, et outils de suivi des t√¢ches/incidents, JIRA. Environnement cloud (AWS) Cela pour √™tre un super fit si en plus, tu as/es : Soft skills autonome curieux(se) une bonne communication diplomate un esprit de synth√®se flexible Social skills Ouverture d‚Äôesprit Orient√© Business Bienveillance Sens de l‚Äôinitiative üîùüòç Ce que l‚Äô√©quipe aime par-dessus tout sur ce poste L‚Äôhumour au quotidien, via des petites blagues souvent de bonne qualit√© (mais pas toujours) La team Product Engineering Les afterworks L‚Äôaventure d‚Äôune belle croissance Pouvoir mettre sa pierre √† l‚Äô√©difice üëç Les petits + qui font kiffer Contrat forfait jour + RTT Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge √† 70% Un club employ√© (billetterie, produits high-tech, voyage, etc..) La carte tickets resto --> Swile est notre ami Primes cooptations Remote ponctuel o√π tu veux en France Goodies, welcome lunch & drinks (et pas que de bienvenue) 1 break dans l‚Äôann√©e dans une destination surprise Eldo est la soci√©t√© qu‚Äôil te faut si tu aimes ‚Ä¶ üíö Le management de proximit√© et impliquant L‚Äôautonomie, les prises d‚Äôinitiatives, les challenges #growthmindset √âvoluer au sein d‚Äôune √©quipe fun et bienveillante Les moments de partage en √©quipe L‚Äôid√©e de mettre ta pierre √† l‚Äô√©difice et de participer √† une aventure humaine et professionnelle INCROYABLE üîé Le process de recrutement chez Eldo 1 - √âchange visio RH (45‚Äô) 2 - Use case 3 - √âchange avec des membres de l'√©quipe Product Engineering ! (60') 4 - √âchange avec ton futur manager, le CPTO (60') Ce poste peut-√™tre en 100% en full remote avec des d√©placements √† pr√©voir 1 fois par mois sur Toulouse pris en charge par Eldo Alors, s√©duit(e) ? poste sans tarder ton CV et sors ta plus belle plume üòé Eldo est une entreprise handi-accueillante","Eldo is looking for a Data Engineer to improve their applications, propose architectures, data pipelines and algorithms on large sets of data, support internal teams and centralize data to enable BI tools. The ideal candidate should have knowledge of MySQL, PostgreSQL, ETL/ELT, and AWS, as well as soft skills such as autonomy, curiosity, and communication. Eldo is a handi-friendly company that provides remote work, benefits, and a fun and challenging work environment.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,3,1,0.05539549888311683
380,33985,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/ios-software-engineer-paris_paris,iOS Software Engineer - Mobile Data Collection,Contentsquare,"{Node,Azure,Datadog,React,go,Typescript,Kafka,Flink,Grafana,Golang,Akka,AWS,Contentsquare,Java,regard,color,Scala,Kibana,Spark,ClickHouse,Python}",T√©l√©travail total possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We‚Äôve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we‚Äôre not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! üöÄ Our mission At Contentsquare, all employees share one goal: to help brands create exceptional online experiences with our industry-leading digital experience analytics platform. In the mobile data collection team, we are on a mission to build the industry leading digital experience analytics SDK. With a stellar growth, billions of users , a complex business environment and the need for us to have a very high level of quality, performance and privacy, you‚Äôll find an engaging, rewarding and supportive work environment at Contentsquare. We are looking for developers who understand that development is a team effort, who are proud of a job well done and know how to implement simple and efficient solutions to solve challenging and unique problems. üíª Our stack On the data collection side, our SDK works on native iOS applications (implemented in Swift) and native Android applications (SDK is in Java - converted to Kotlin over time -, Unit Tests and Sample App in Kotlin). We also support various multi-platform frameworks (React Native, Flutter, Capacitor/Ionic, Cordova) with specific bridges. The Tag (implemented in Typescript) that collects data on websites (both desktop and web mobile) is implemented and maintained by the Web Team. Our APIs are mostly designed with our specific constraints in mind. For example, the most data intensive ones use Protocol Buffers . Our backend uses a combination of technologies such as Kafka , Spark, Flink , Akka , ClickHouse and languages such as Scala , Golang, Python , C++. Our monitoring and deployment are handled through Kibana, Grafana , Terraform, Datadog and finally, everything is hosted on AWS and Azure. Our frontend is a micro-frontend SPA developed mainly in Angular / Vue.js and Node.js . üß† Our challenges Our first challenge is to navigate through uncharted territories, native APIs and poorly documented features to make sure we collect all the relevant data we need to compute our insights. In addition we obviously must ensure a very high level of performance (as well as the least impact on user experience), stability and be very mindful about data and CPU consumption. Our rapid growth requires a strong focus on software architecture, code sharing and automation to sustain our delivery capacity while increasing our teams' size. Finally, we are not a tracking company, so collecting PII (Personal Identifiable Information) is an absolute no-go for us and we take it very seriously! ü§ó Skills & Mindset If you have already worked on any kind of software SDK your experience will be of great interest to us. In the same way, if you have notable experience in high performance code, automated non-regression and performance testing, software bridges (between technologies, native and non-native), or if you enjoy testing new technologies or frameworks such as Flutter/Dart, Swift UI, Compose, React Native/Typescript, we would love to hear from you. As a team we are really involved in producing a high quality SDK. We expect our developers to know how to unit test their code, to write easy to read & maintain code and documentation as well as being comfortable doing pair programming with their team members. üèù What we offer An healthy working environment with supportive team members, a place to grow both technically and as an individual Autonomy, responsibilities and opportunities An Engineering Career Path (with clear defined progression steps and opportunities to mentor and be mentored) to make sure you always learn something new Plenty of opportunities for training and development Attractive salary and stock options Flexible working conditions (full remote, 100% in office or any hybrid setup of your choice) A dynamic and multi-cultural company with +50 nationalities Good health insurance Many benefits such as reductions on gym membership and leisure activities While we are offering fully remote opportunities, employees need to be fiscally based in one of our main countries to be hired by one of our office. Please ask your recruiter for more information. Why you should join Contentsquare - We‚Äôre humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we‚Äôd like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company‚Äôs success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is seeking developers to join their mobile data collection team to build the industry-leading digital experience analytics SDK. The ideal candidates will have experience with software SDKs, high-performance code, automated testing, and software bridges. The company offers a supportive work environment, career development opportunities, a competitive salary and benefits package, and the chance to work with a dynamic and multicultural team.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
150,56383,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-h-f_brest,Data Engineer confirm√©(e) ‚Äì,Thales,"{durable,GIT,R,JAVA,Python}",T√©l√©travail total possible,Brest,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES-VOUS ?PROFIL :Vous venez d'√™tre dipl√¥m√©(e) d'un master d'une √©cole d'ing√©nieur et justifiez d'une exp√©rience significative d'environ 2 ans (stages professionnels/stages, projets universitaires ou personnels tels que GIT Hub, Meet Ups, etc.)Vous √™tes d√©brouillard(e), innovant(e) et orient√©(e) solutionsVous avez l'esprit d'√©quipeVous aimez √©galement travailler de mani√®re ind√©pendante et recherchez les responsabilit√©s COMP√âTENCES : Vous √™tes capable de vous adapter et de r√©agir au changement Vous savez et aimez concevoir, d√©velopper et tester des solutions et/ou des composants logiciels s√©curis√©s Vous pouvez d√©montrer votre connaissance des langages et cadres de programmation Full Stack ou pure back/pure front (JAVA, C, C++, Python, ou tout autre) Vous √™tes familier(√®re) avec la compilation/construction de code/int√©gration continue. Vous avez connaissance des plateformes informatiques, des syst√®mes d'exploitation et des hyperviseurs du SI Vous connaissez les principes Agile CE QUE NOUS POUVONS FAIRE ENSEMBLE :En tant que ""Software Solutions Engineering Role"" chez Thales, vous serez amen√©(e) √† : Travailler au sein d'une √©quipe Scrum avec d'autres d√©veloppeurs de logiciels, en mode Agile Contribuer √† la d√©finition des besoins, √† la conception du logiciel et √™tre impliqu√©(e) dans les aspects architecturaux des projets logiciels Int√©grer les composants logiciels dans un syst√®me logiciel enti√®rement fonctionnel Ecrire un code bien con√ßu, document√© et testable D√©velopper, tester et ex√©cuter le cycle de vie complet du d√©veloppement logiciel Concevoir, mettre en ≈ìuvre et tester des fonctionnalit√©s en tenant compte de l'√©volutivit√©, des performances, du d√©ploiement/de l'exploitation et de l'exp√©rience de l'utilisateur(ice) final(e). Faire des estimations et contribuer √† la planification avec les membres de l'√©quipe Collaborer avec d'autres ing√©nieur(e)s en solutions logicielles afin de partager les connaissances et d'am√©liorer le produit/solution dans son ensemble.VOTRE CARRI√àRE CHEZ THALESDiff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines :Explorez un espace attentif au d√©veloppement personnelD√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexeChoisissez entre une expertise technique ou un parcours de leadershipConstruisez une carri√®re internationale au sein d'un groupe d'ing√©nierie de premier plan. Le poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d‚Äôhabilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l‚ÄôIGI 1300 SGDSN/PSE du 09 ao√ªt 2021. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales seeks a Software Solutions Engineering graduate to join their team, with diverse opportunities to work within the information and communication security sectors, and provide global solutions for vital systems. The ideal candidate has a technical aptitude for designing, developing, and testing collaborative full-stack software solutions, familiar with coding languages and frameworks such as JAVA, C++, or Python. Join an Agile Scrum team, contribute to defining software specifications and architectural aspects, and collaborate with other software engineers to continuously develop and test the product. Thales upholds an inclusive, flexible work culture with international career opportunities.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
86,73554,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/front-software-engineer-f-m-d-data-observability_paris,Front Software Engineer  - Data Observability,Decathlon Digital,"{NodeJS,Github,AWS,GraphQL,via,Kafka,Javascript,Docker,Kubernetes,React,Git,GitHub,GCP,TypeScript}",T√©l√©travail total possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES DATA DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour accompagner cette transformation digitale internationale de Decathlon, les √©quipes Data √©voluent et mettent au c≈ìur de leurs enjeux : La qualit√© et l‚Äôaccessibilit√© de la donn√©e La scalabilit√© des processus associ√©s au cycle de vie de la donn√©e (ingest, store, transform, expose) L‚Äô√©lasticit√© des infrastructures et des services Int√©gr√© au c≈ìur de la data platform votre r√¥le sera de servir ces deux enjeux majeurs Garantir l'acc√®s et l'usage de la donn√©e pour tous nos utilisateurs data en d√©livrant outils et guidelines La scalabilit√© REJOINS L'√âQUIPE DATA OBSERVABILITY En fournissant la capacit√© √† identifier, diagnostiquer, tracer et r√©soudre les √©v√®nements de transformation de la donn√©e dans le SI de Decathlon, nous donnons le pouvoir aux √©quipes data de fiabiliser leurs produits et d'en mesurer la qualit√©. En tant que Software Engineer Frontend tu auras pour mission de cr√©er les meilleures exp√©riences possibles et unifi√©es via des interfaces pour nos √©quipes internes. Dans le cadre de l‚Äôouverture d‚Äôun poste en CDI, nous recrutons un-e Software Engineer, bas√©-e, au choix √† Paris o√π √† Lille. P√©rim√®tre d‚Äôaction Tu prendras part de bout en bout au d√©veloppement d'un portail complet et de nouvelles fonctionnalit√©s (React/ Svelte) en lien avec le Product Manager. Tu √©volueras √©galement au contact des autres co√©quipi√®res et co√©quipiers : l‚Äôam√©lioration continue et l‚Äôautonomie sont particuli√®rement valoris√©es chez Decathlon ! Ton exigence technique (qualit√© du code, pratiques, patterns, outils‚Ä¶) et tes qualit√©s relationnelles permettent de diffuser les bonnes pratiques dans l‚Äô√©quipe, en collaboration avec le Tech Lead. TES RESPONSABILITES Construire une plateforme front pour rendre l'observabilit√© accessible √† tous intervenir sur toute la cha√Æne de livraison des fonctionnalit√©s : conception, impl√©mentation, tests, documentation technique, exemples, API, SDK‚Ä¶ √™tre moteur dans le processus d'int√©gration et de livraison continue se montrer force de proposition dans les choix techniques mais aussi aussi dans nos moyens de collaboration Le p√©rim√®tre technique : HTML / CSS : accessibilit√©, standards W3C, web performance‚Ä¶ Svelte / Vue JS / ReactJS / GraphQL / Material UI Javascript / TypeScript, NodeJS Git (Github Actions) Tests unitaires et fonctionnels Outils collaboratifs : Confluence, Slack, Jira‚Ä¶ Infrastructure : AWS, Kafka, Docker, Kubernetes‚Ä¶ CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience (minimum 3-5 ans) du d√©veloppement web frontend (Svelte / Vue JS / React), des architectures micro services / micro frontend, et de d√©ploiement continu et tu as d√©j√† effectu√© de l'UX design Tu as un bon niveau d‚Äôanglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu as un √©tat d'esprit agile tourn√© vers l'am√©lioration continue, l'intelligence collective, l‚Äôentraide et la solidarit√© Tu aimes travailler dans un environnement collaboratif (Pair Prog, Code Review, et √©cosyst√®me GitHub) Tu as une passion de la technique que tu aimes partager Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style relationnel et la vie en √©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon √† Lille o√π √† Paris (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme d'1 ou 2 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Digital, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©s notamment √† Paris, Lille et Amsterdam. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .",,Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
277,56775,https://www.welcometothejungle.com/fr/companies/la-releve/jobs/data-engineer-chez-l-un-de-nos-1000-clients-f-h_paris,Data Engineer chez l‚Äôun de nos 1000 clients,La Rel√®ve,"{PostgreSQL,Dagster,Azure,Docker,MySQL,MongoDB,Beam,Django,Kafka,GCS,Dataflow,NoSQL,MariaDB,PyTorch,Flink,Kubernetes,AWS,Argo,SQL,Tensorflow,Scala,Airflow,S3,R,Spark,BigQuery,GCP,Python}",T√©l√©travail partiel possible,"26, Rue Laffitte, Paris, 75009",Recrutement,CDI,2023-03-26,"Cr√©√©e en 2014, La Rel√®ve est un acteur incontournable dans le recrutement sur-mesure de talents aupr√®s des acteurs de la French Tech : de la startup en qu√™te de croissance au grand groupe en pleine transformation digitale. Nous sommes une 15aine de recruteurs passionn√©s et accompagnons plus de 900 entreprises dans la recherche de la perle rare dans les domaines suivants : tech, marketing, sales, produit et design. En 2021, ce sont plus de 400 talents qui ont trouv√© le projet de leurs r√™ves gr√¢ce √† notre √©quipe d‚Äôexperts bas√©s √† Paris et Madrid. La Rel√®ve ne cesse d‚Äô√©voluer et de se r√©inventer. Depuis plus d‚Äôun an d√©j√†, nous continuons notre belle √©volution avec le lancement de La Rel√®ve On Demand, notre service RPO (d√©l√©gation d‚Äôexpert en recrutement dans les entreprises), et l‚Äôouverture de notre bureau √† Madrid. √âchanger avec l‚Äôun de nos recruteurs, c‚Äôest rencontrer un expert du recrutement tech et se voir proposer une multitude d‚Äôoffres dans des entreprises diverses et vari√©es. Nous travaillons avec de nombreux acteurs √©conomiques, de la start-up au grand groupe, avec tout type de technologie data ! Vous avez une app√©tence particuli√®re ? Nous travaillons avec des entit√©s √©voluant dans de nombreux secteurs : √©ducation, m√©dia, food, RH, art, √©cologie, sant√©, e-commerce, logistique et bien d‚Äôautres. Bien que de nombreuses entreprises soient localis√©es √† Paris, nous travaillons avec des entreprises bas√©es dans toutes les r√©gions fran√ßaises, et/ou proposant du t√©l√©travail partiel ou total. Nous travaillons avec des entreprises √©voluant sur tout type de stack technique et avec des outils et m√©thodologies divers et vari√©s. Voici une liste d‚Äôexemples courants, mais non exhaustifs : S3, Delta Lake, BigQuery, GCS Spark, Google Dataflow Airflow, Argo, Dagster Kafka, Beam, Flink Terraform, Kubernetes, Docker AWS, GCP, Azure, OpenStack R, Scala, Python, Django, PyTorch, Sci-Kit Learn, Tensorflow SQL, MySQL, NoSQL, PostgreSQL, MongoDB, MariaDB ETL Les qualifications : du Bac+2 au Doctorat en passant par les profils en reconversion, les crit√®res des entreprises sont tout aussi vari√©s qu‚Äôils sont nombreux, et nous prenons plaisir √† rencontrer tout type de profil ! L‚Äôexp√©rience : nous accompagnons tout type de s√©niorit√©. La r√©mun√©ration : tr√®s variable selon les profils et les entreprises auxquelles vous postulez, nous nous assurons qu‚Äôelle soit toujours juste et en phase avec vos pr√©tentions, et nous sommes aussi pr√©sents pour vous assister dans la n√©gociation si n√©cessaire. Le t√©l√©travail : √©galement tr√®s variable selon les niveaux de s√©niorit√©, de responsabilit√© et les pratiques au sein des entreprises auxquelles vous postulez, nous vous communiquons la politique de t√©l√©travail de l‚Äôentreprise d√®s notre premier √©change pour que vous puissiez imm√©diatement vous projetez. Vous postulez √† cette offre et vous remplissez les champs demand√©s. Votre profil est √©tudi√© attentivement, pour d√©terminer si nous sommes ou non en mesure de vous accompagner de mani√®re pertinente dans votre recherche. Si ce n‚Äôest pas le cas, nous vous en informerons ! Vous √©changez de vive voix avec un membre de notre √©quipe tech, qui prend le temps de comprendre votre besoin et vos app√©tences. Et nous vous s√©lectionnons uniquement nos offres en CDI qui vous correspondent. Nous vous suivons pendant tout le processus : nous vous accompagnons avant et apr√®s les entretiens pour vous y pr√©parer et recueillir vos retours, et vous partager ceux de l‚Äôentreprise. Vous obtenez le poste qui vous convient : si tout le processus de recrutement se passe bien, vous serez bient√¥t pr√™t pour votre futur emploi. Pour autant, nous ne vous laissons pas tomber, loin de l√† ! Nous restons disponibles pour toute question suppl√©mentaire, et nous gardons contact avec vous lors de vos premi√®res semaines pour s‚Äôassurer que votre int√©gration se d√©roule bien.","La Rel√®ve is a recruitment agency specializing in personalized talent recruitment in the French Tech sector. They have over 900 clients in the tech, marketing, sales, product, and design industries, and work with companies of all sizes and regions in France. They are looking for candidates with a diverse range of qualifications and experience, and provide assistance throughout the recruitment process, as well as continuing support during the candidate's first few weeks in their new position.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 6 mois,2,2,0.05539549888311683
83,56993,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-big-data-h-f_montpellier_CGI_LALwMW5,Data Engineer Big Data,CGI,"{Python,MongoDB,Neo4j,Scala,Kafka,Cassandra,Hive,Spark,Git,Java,NoSQL,Hadoop,nifi}",T√©l√©travail total possible,"Montpellier, 34000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le domaine de la Data et avez d√©j√† une exp√©rience significative sur des probl√©matiques de data engineering : construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es, ‚Ä¶ Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi‚Ä¶) et/ou NoSQL (MongoDB, Neo4j, Cassandra‚Ä¶) et vous maitrisez un des trois langages suivants : Java, Scala, Python. Vous souhaitez diversifier vos comp√©tences Big Data pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 200 consultants) ? Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Big Data que ceux de votre domaine de comp√©tences initial. En tant que Data Engineer, vous serez int√©gr√©.e √† un p√¥le de consultants.es sp√©cialistes du Big Data intervenants sur des projets stimulants. Vos missions seront : ‚Ä¢ Analyser, conseiller, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs techniques et autres experts.es afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques ‚Ä¢ R√©aliser les travaux d‚Äôimpl√©mentation des solutions (pr√©paration des donn√©es, industrialisation des mod√®les, communications entre les diff√©rentes technologies,‚Ä¶) ‚Ä¢ Produire les projets en mode agile avec des processus et outils de d√©veloppement de derni√®re g√©n√©ration (DevOps, Git, CI/CD‚Ä¶) ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique ‚Ä¢ Animer des formations internes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique Big Data aux √©quipes et aux clients au quotidien Accompagn√©.e et entour√©.e par une communaut√© Data passionn√©e, l‚Äô√©change, le partage et les formations vous offriront un v√©ritable espace pour vous √©panouir. La proximit√© et le suivi personnalis√© de votre manager, puis un bon nombre d‚Äô√©v√©nements tout au long de l'ann√©e, renforceront encore la convivialit√© et l‚Äôesprit d'√©quipe ! Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique ou dans le consulting de solutions Data. - Passionn√©.e d‚Äôinformatique et de donn√©es, vous aimez le travail en √©quipe, apprendre et partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez de 2 √† 5 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil dans le Domaine du Big Data. - Vous disposez d'une vision large des technologies et vous ma√Ætrisez au moins une technologie Big Data. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, is looking for a passionate and experienced Data Engineer with expertise in data engineering, pipeline construction, data science application industrialization, and database modeling, among others. The candidate must have knowledge of Big Data tools, such as Hadoop, Spark, Hive, Kafka, Nifi, and/or NoSQL solutions. They must also have proficiency in at least one of the following programming languages: Java, Scala, or Python, and be willing to diversify their skill set. The position involves working on large-scale national and international projects for various industries, while collaborating with technical engineers and other experts. The role requires analyzing, recommending, implementing, and providing technical support for Big Data solutions. Additionally, CGI offers a supportive and inclusive work culture, professional development opportunities, and a clear career path. CGI is also an employer that supports inclusion and values the well-being and career advancement of its employees.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
180,56860,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/developpeur-data-engineer-teletravail_MD_W0ZLb0V,D√©veloppeur / Data Engineer - T√©l√©travail,MP DATA,"{Azure,MongoDB,Django,Git,Airflow,AWS,Snowflake,S3,Kafka,GCS,Spark,GCP,Java,SQL,Hadoop,Python,Postgres}",T√©l√©travail total possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-03-26,"Bonjour ! MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance, l‚Äôexploitation de leur donn√©es et leur d√©carbonation. Les collaborateurs, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement. Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais. MP DATA accompagne ses clients sur toute la chaine de la donn√©e au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences. Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort, et des possibilit√©s d‚Äô√©volution int√©ressantes. MP DATA, recrute un d√©veloppeur , avec des affinit√©s pour le m√©tier de Data Engineer (ou un Data Engineer) afin de travailler pour un client, acteur majeur du secteur transport, le tout en t√©l√©travail. Accompagn√© par un Lead Data Engineer, vous monterez en comp√©tences sur l‚Äôutilisation de nombreuses technologies notamment AWS , Python , Snowflake , Spark , Airflow, Ansible. Vos missions seront les suivantes : Proposer des architectures et orienter le choix des technologies adapt√©es aux besoins de diff√©rents projets Data Concevoir et mettre en ≈ìuvre les traitements d‚Äôalimentation du DataLake et de transformation des donn√©es Cr√©ation de pipelines de donn√©es, traitement et transformation de la donn√©e. Garantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats Identifier, collecter, explorer, comprendre et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnelles Assurer le suivi de la production De formation Bac+5 (ou plus) en d√©veloppement informatique / data engineering, vous justifiez d‚Äôune premi√®re exp√©rience professionnelle au cours de laquelle vous avez pu d√©velopper les comp√©tences techniques suivantes : Python Spark, Kafka, Hadoop Cloud : AWS (S3, Lambdas,‚Ä¶) / GCP / Azure Technologies de stockage : Snowflake / GCS / Azure Blob SQL : Postgres / MongoDB Django / Flask CI/CD : Ansible / Git Terraform C/C++ / Java / Rust Alors venez grandir avec nous ! 1 entretien RH -> 1 entretien technique -> 1 entretien dans les locaux","MP DATA is seeking a developer or data engineer with experience in Python, AWS, Snowflake, Spark, and Airflow to work remotely with a major player in the transportation industry. The successful candidate will propose architectures, design and implement data pipelines, ensure data quality, and identify and integrate data for business and operational issue resolution. The company offers the opportunity to work on exciting projects with a strong technical framework and interesting career growth prospects.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 1 an,3,1,0.05539549888311683
181,56969,https://www.welcometothejungle.com/fr/companies/thales/jobs/dataengineer-departement-ia-bigdata_sophia-antipolis_THALE_q0DLXgG,DataEngineer - D√©partement IA & BigData,Thales,"{Oracle,PostgreSQL,Cassandra,Hive,Nvidia,Microsoft,durable,MongoDB,Kafka,NoSQL,Flink,AWS,HBase,Storm,Java,SQL,Hadoop,GCP,MinIO,Scala,HDFS,S3,Spark,Pig,AZURE}",T√©l√©travail total possible,Sophia Antipolis,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces. Nos √©quipes de la Direction de l‚ÄôIng√©nierie Logicielle ( DIL ) fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces . Le d√©partement IA & Big Data recherche plusieurs Ing√©nieurs DataEngineer (H/F) bas√©s √† Sophia Antipolis (06). QUI ETES-VOUS ? De formation Bac+4 ou Bac +5 (type √©cole d‚Äôing√©nieur), vous poss√©dez de bonnes connaissances dans le domaine de la donn√©e (Data Science, Data Engineering, Stockage), en ing√©nierie logicielle globalement. Une connaissance cloud serait un r√©el atout, qu‚Äôil soit public (AWS, GCP, AZURE) ou priv√©. Principales activit√©s que vous r√©aliserez : Mise en place de pipelines de traitement de donn√©es Utilisation de l‚Äô√©tat de l‚Äôart des technologies actuelles d√©di√©es √† ces activit√©s : Kafka / Spark / Spark Streaming / Flink / Storm D√©veloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie) Utilisation de tous les types de stockage actuels SQL : Oracle, SQLServer, PostgreSQL NoSQL : Cassandra / MongoDB / HBase Objet : S3 / MinIO Vous avez de bonnes exp√©riences en d√©veloppement logiciel et/ou scripting (principalement Scala & Java). Vous √™tes √† l‚Äôaise en Anglais. Vous √™tes curieux(se) et rigoureux(se). Vous aimez travailler en √©quipe au quotidien. Pour vous le succ√®s n‚Äôest que collectif. Vous vous reconnaissez ? Alors parlons missions ‚Ä¶ CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Le d√©partement IA & Big Data f√©d√®re et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d‚Äôune structure permettant d‚Äôacc√©l√©rer la transformation des enjeux Data de nos clients. Nos savoir-faire : Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie Projets d‚Äôint√©gration syst√®me Nos domaines m√©tier : Maintenance pr√©dictive, Traitement d‚Äôimage pour la sant√© Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de r√©ponse Aerospace : Centre de Mission et de Contr√¥le, Dynamique du Vol, Qualit√© Image, Occupation des sols, Sondage Atmosph√©rique Nos partenaires : Recherche : INRIA, CNRS, 3IA Externes : Nvidia, Microsoft En collaboration avec les membres de notre d√©partement : Vous contribuerez au d√©veloppement et √† la scalabilit√© de nos plateformes au travers d‚Äôactivit√©s d‚Äôautomatisation, de cr√©ation de services manag√©s et d‚ÄôAPI. Vous accompagnerez nos clients dans leurs projets de valorisation de donn√©es en proposant des solutions techniques et fonctionnelles, √©valu√©es, choisies et opportunes. Vous participerez √† l‚Äôint√©gration des plateformes techniques s√©curis√©es d√©velopp√©es par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com) Vous collaborerez √† nos publications, conf√©rences et webinars. Vous serez partie prenante de la 3√®me r√©volution industrielle impactant tous les secteurs d‚Äôactivit√©, √©nergie, sant√©, industrie, ‚Ä¶ La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant √† cette offre . Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is seeking a Data Engineer with a background in data science, data engineering, and storage, with knowledge in cloud technologies (public or private). The position involves setting up data processing pipelines, utilizing current technologies such as Kafka, Spark, and Flink, and working with Hadoop stacks, SQL and NoSQL databases, and object storage systems. The position also involves collaborating with team members and clients to provide technical and functional solutions for data valorization projects.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
390,34754,https://www.welcometothejungle.com/fr/companies/l-oreal/jobs/data-security-engineer-l-oreal-france_clichy,Data Security Engineer - L'Or√©al France,L'Or√©al France,{IAM},T√©l√©travail total possible,Clichy,"Luxe, Cosm√©tique, E-commerce",CDI,2022-08-08,"Notre Raison d‚Äô√™tre : Cr√©er la beaut√© qui fait avancer le monde. Le d√©sir de beaut√© est une force puissante qui nous fait avancer. La beaut√© ne se limite pas √† l‚Äôapparence. Elle nous donne confiance en nous, en qui nous voulons √™tre, et dans notre relation avec les autres. Depuis plus d‚Äôun si√®cle, nous exer√ßons ce m√©tier unique : cr√©ateur de beaut√©. Notre but est d‚Äôoffrir √† tous, partout dans le monde, le meilleur de la beaut√© en termes de qualit√©, d‚Äôefficacit√©, de s√©curit√© et de sinc√©rit√© pour satisfaire tous les besoins et d√©sirs de beaut√© dans leur infinie diversit√©. Et parce que nous sommes le leader de la beaut√©, nous sommes conscients que tout ce que nous faisons peut avoir un impact significatif. C‚Äôest pourquoi nous agissons pour : Inventer le futur de la beaut√© en ayant recours au meilleur de la technologie et de la science, inspir√©es par la nature. Faire avancer l‚Äôinnovation sociale en offrant √† nos collaborateurs le meilleur en mati√®re de conditions de travail, de formation et de protection sociale. Construire une entreprise toujours plus inclusive qui refl√®te la diversit√© des consommateurs que nous servons. Nouer des partenariats durables avec nos clients et fournisseurs, bas√©s sur la confiance et le d√©veloppement mutuels. ≈íuvrer partout pour la cause des femmes et au d√©veloppement des communaut√©s qui nous entourent. Prot√©ger la beaut√© de la plan√®te en luttant contre le changement climatique, en respectant la biodiversit√© et en pr√©servant les ressources naturelles. Here are some more insights concerning your missions: Ensure compliance of the Data Platform with L‚ÄôOr√©al group security rules Be proactive to analyze security weaknesses/data leaks and propose solutions consistent with L‚ÄôOr√©al eco-system and in partnership with Global Enterprise Architecture team and Security team. Define security, privacy, and quality tools & services for Data Platform in collaboration with data platform and data services managers. Be part of the development team for the defined tools & services defined. Define the continuous improvement plan (plan, do, check act) to improve data & platform security quality: define the KPI, implement and get the feedback loop. Handle internal and externa audits (feedbacks, follow-up) Communicate, train, and educate data platform security topics in front of stakeholders (business platform teams, IT teams, zones teams, etc.) Do a proactive technology watch about Data and Cloud Security In this specific position, it will be important for you to: Have a solid experience in Google Cloud Platform Have an experience in API security management Have a confirmed experience Google Cloud Platform security (IAM, secrets management, Zerotrust ‚Äì OAuth2, serverless security and constraint) Have already a first experience on Google Cloud Platform cost management Have an appetency for IT security in application and enterprise level Be able to lead technical presentations, workshops, architecture design sessions, proofs of concept to prove the legitimacy of proposed solutions Be able to interact with all levels of management, Team spirit with other Data Tech Lead and be empathic: share difficulties and ideas; solve problem together Be determined to ensure the application of security rules by teams Innovator: Aware of new IT innovations and development best practices Advanced degree in engineering or technical/scientific field of study 4-6 years technical experience 3-4 years technical experience in google cloud platform 1-2 years technical experience in security cloud We love people that are curious, collaborative, eager to have an impact and who value innovation, autonomy, and team spirit.","L‚ÄôOr√©al is seeking for a Data Tech Lead who will ensure compliance of the Data Platform with L‚ÄôOr√©al group security rules, analyze security weaknesses/data leaks, handle internal and external audits, communicate and train data platform security topics, and do a proactive technology watch about Data and Cloud Security. To qualify, the applicant must have solid experience in Google Cloud Platform, API security management, Google Cloud Platform security, and Google Cloud Platform cost management, as well as possess an appetency for IT security in the application and enterprise level. An advanced degree in engineering or technical/scientific field of study is required.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
149,56432,https://www.welcometothejungle.com/fr/companies/tactill/jobs/operations-engineer-100-remote_paris,Data & Automation Engineer (100% Remote),Tactill,"{Javascript,Intercom,Zapier,DataStudio,DBT,scale,BigQuery,SQL}",T√©l√©travail total possible,"48 avenue du G√©n√©ral Leclerc, Paris, 75014","Application mobile, Objets connect√©s",CDI,2023-03-26,"TL;DR Poste : Data & Automation Engineer Contrat : CDI Seniorit√© : Exp√©riment√© Salaire : 45 - 65K‚Ç¨ /an Localisation : 100% Remote Stack : Amplify / BigQuery / DBT / Zapier / ReTool / SaaS Tech Team : 9 personnes Soci√©t√©s de recrutement / pr√©-embauche / SSII / ESN nous n‚Äôexternalisons pas le recrutement. Merci Plus d‚Äôinfos üëá Chez Tactill, nous nous sommes fix√©s une mission audacieuse : permettre aux commer√ßants de vendre partout o√π ils en ont besoin. C‚Äôest pourquoi, en boutique ou dans la rue, nous leur offrons les meilleurs outils pour encaisser et g√©rer leur business. Tu veux en savoir plus -> https://www.tactill.com Notre solution s‚Äôappelle Tactill et elle transforme iPhones et iPads en caisses enregistreuses mobiles et connect√©es. D√©j√† utilis√©e par des milliers d‚Äôentreprises, nous voulons faire de Tactill la r√©f√©rence de l‚Äôencaissement mobile. La Team üë©‚Äçüíª Notre √©quipe tech est constitu√©e de 9 personnes compl√©mentaires : [ Gr√©goire - Founder & CEO ] ( https://www.linkedin.com/in/gr%C3%A9goire-lopez-232b6334 /) [ Elodie - Founder & CPO ] ( https://www.linkedin.com/in/elodie-godart-a47a6437 /) [ Giorgi - ArchiTech & iOS ] ( https://www.linkedin.com/in/giorgi-shavgulidze-77aaa856 /) [ Alexandre - Backend ] ( https://www.linkedin.com/in/alexandre-bernard-89561ab7 /) [ Jennifer - Frontend ] ( https://www.linkedin.com/in/jennifer-c-575b46153 /) [ Ugo - Senior UX/UI ] ( https://www.linkedin.com/in/ugo-jauffret /) [ Tristan - UX/UI ] ( https://www.linkedin.com/in/tristan-chapelle-a4763a54 /) [ Stephane - QA ] ( https://www.linkedin.com/in/stephane-hildbrand /) [ Mathias - QA ] ( https://www.linkedin.com/in/mathias-porzier-b50654194 /) De la sp√©cification fonctionnelle aux tests automatiques en passant par le design, toutes les √©tapes de notre process ont √©t√© r√©fl√©chies, construites et automatis√©es (quand c‚Äôest possible). Nous connaissons le co√ªt de la dette technique et nos d√©cisions tendent √† s‚Äôen affranchir tant que faire se peut. Mission üéØ Tactill n‚Äôest pas qu‚Äôun logiciel SaaS. C‚Äôest √©galement une entreprise qui d√©pend de nombreux process pour servir ses clients. Notre ambition est de les am√©liorer et de les automatiser. Cette ambition s‚Äôinscrit dans un projet global de refonte de toutes nos stacks (produit, marketing, sales, support, data, logistique, comptabilit√© ‚Ä¶) Pour y arriver, notre √©quipe produit cherche aujourd‚Äôhui un Data & Automtation Engineer pour prendre en charge la construction de la v2 de notre stack op√©rationnelle. Cette mission est vaste et tu interviendras sur de nombreux projets : Data -> update de notre stack data (Stich Data + BigQuery + DBT + DataStudio) Marketing -> update et automatisation de la stack markeing (Intercom + Pipedrive + custom code) Sales -> update de la stack sales (Pipedrive + RingOver + custom code) Logistique -> automatisation de nos process logistiques (Chargebee + FlxPoint + custom code) Acquisition -> construction de la stack de tracking et referring (Referral) NoCode -> construction d‚Äôapps internes Nous creuserons chacun de ces sujets ensemble et tu seras accompagn√© par notre CEO qui a construit le v1 de cette stack. Tu seras ‚Äúa team of one‚Äù mais pas de panique ‚Ä¶ Tu seras accompagn√© par l‚Äô√©quipe qui a d√©j√† construit la v1 de la stack op√©rationnelle La stack actuelle est document√©e et nous avons une vision claire de la stack v2 Tu seras int√©gr√© √† l‚Äô√©quipe produit et tu profiteras des process de devs d√©j√† en place Cette mission n‚Äôinclut pas de composante manag√©riale (en tous cas pas √† moyen terme) Formation üßë‚Äçüéì Le niveau d‚Äôabstraction de notre stack est important. Nous cherchons donc une personne √† l‚Äôaise avec les concepts avanc√©s de l‚Äôing√©nierie informatique (architecture, mod√©lisation de donn√©es, design pattern, programmation fonctionnelle, compl√©xit√© algorithmique ‚Ä¶). Ton niveau acad√©mique est moins important pour nous que ta capacit√© √† comprendre et am√©liorer l‚Äô√©xistant, cependant un dipl√¥me scientifique du sup√©rieur sera un plus. Comp√©tences üß† Javascript : Ton niveau en JS est irr√©prochable et tu ma√Ætrises le paradigme fonctionnel. Data : Tu maitrises SQL sur le bout des doigts. Clean code : Ton code est propre, lisible, test√© et document√©. Documentation : Tu sais √©crire une documentation claire et tu sais √† quel point c‚Äôest important. Low Code : Tu as l‚Äôambition de d√©l√©guer le maximum de compl√©xit√© √† des outils robustes. Business : Tu comprends les enjeux business d‚Äôune entreprise de logiciels BONUS - DBT : Une premi√®re exp√©rience avec l‚Äôoutil sera un plus. Exp√©rience üí™ Nous cherchons quelqu‚Äôun qui a roul√© sa bosse et rencontr√© les pi√®ges classiques du d√©veloppement. Fort d‚Äôau moins 2 ans d‚Äôexp√©rience dans un poste similaire, tu as id√©alement travaill√© dans une startup et particip√© √† son scale. En revanche, tu es plus int√©ress√© par la tech et le logiciel que par le startup game, game auquel nous ne jouons pas. Profil üëÄ Excelsior est la devise que nous portons tous. Ainsi, nous cherchons une personne passionn√©e par ce qu‚Äôelle fait et qui consacre du temps √† sa passion. Un projet personnel qui t‚Äôanimes √† beaucoup de valeur √† nos yeux. Notre team est 100% remote, avec ses avantages et ses inconv√©nients. Il est important pour nous que tu aies d√©j√† eu une exp√©rience similaire et que tu sois √† l‚Äôaise avec ce mode de fonctionnement. En r√©sum√©, autonomie et responsabilit√© font partie de tes qualit√©s. Bonus ‚≠êÔ∏è Tu as d√©j√† particip√© √† un projet entrepreneurial en temps que co-founder Avantages üç≠ 100% Remote Tactill n‚Äôest pas l√† pour te dire o√π travailler. Tu aimes bosser sous le soleil ? On part du principe que tu es adulte et que tu connais les conditions de ta productivit√©. Boite tech Les fondateurs de Tactill sont des ing√©nieurs amoureux du beau logiciel. Nous avons conscience de la difficult√© de construire des syst√®mes robustes et maintenables et nous ne prenons pas de d√©cisions h√¢tives pour gagner trois francs six sous. Off-sites au soleil Nous organisons plusieurs fois par an des off-sites dans des endroits chauds et ensoleill√©s pour que la team puisse se retrouver. Ton arriv√©e devrait d‚Äôailleurs coller avec notre spring break 2023. Sant√© et frugalit√© Chez Tactill, on prend en charge 100% de ta mutuelle. En revanche, pas de CE, tickets restau ou ch√®ques vacances. On pr√©f√®re te r√©mun√©rer √† ta juste valeur plut√¥t que de te donner de la monnaie de singe en √©change de quelques euros sur ton salaire. Soci√©t√©s de recrutement / pr√©-embauche / SSII / ESN passez votre chemin. Merci Tu postules ici On √©tudie ton profil et on te fait un retour (max 1 semaine) On fait connaissance sur Google Meet (30 minutes) Petit test technique (4 heures max) On t‚Äôinvite √† rencontrer la team On c√©l√®bre ton arriv√©e au soleil","Tactill, a mobile and connected cash register software company, is seeking an experienced Data & Automation Engineer for a fully remote position. The engineer will work on a broad range of projects to update and automate the company's operational stack, including data, marketing, sales, and logistics. The ideal candidate should have a strong command of JavaScript, SQL, clean code, low code, business concepts, and documentation, as well as at least two years of experience in a similar role. Being passionate about software engineering, having a personal project, and being comfortable with remote work are additional desirable qualities.",Bac +3,< 15 salari√©s,> 2 ans,3,1,0.05539549888311683
323,56514,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_bordeaux,Data Engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,GCP,Java,Python}",T√©l√©travail total possible,Bordeaux,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-03-26,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Description du poste Participer √† la d√©finition des besoins et √† la r√©daction des User Stories, Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e, Concevoir et construire des architectures de donn√©es, Int√©grer des sources de donn√©es, Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives, Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux. Profil Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple, Vous maitrisez les bases de l‚Äôanalyse statistique, Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts. #LI-JH1 Efficace , vous ne remettez pas √† demain ce qui peut √™tre fait d√®s aujourd‚Äôhui M√©thodique , les plans d‚Äôaction sont dans votre ADN Organis√© , vous √™tes l‚Äôas des to-do list","Extia, a consulting firm for IT, digital, and engineering, is looking for a Data Analyst to work with data scientists in developing data analysis modules, integrating data sources, and executing ETL processes. The ideal candidate should have experience in ETL, data mining, machine learning, big data, and graph theory, as well as knowledge of statistical analysis and programming languages such as Python and R. Experience in Linux, storage tools, cloud infrastructure, and real-time streaming is a plus. Methodical, efficient, and organized candidates are preferred.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
77,73484,https://www.welcometothejungle.com/fr/companies/schneider-electric/jobs/cloud-data-engineer-f-h_grenoble,Cloud Data Engineer,Schneider Electric,"{Github,Python,Presto,Scala,Microsoft,Azure,durable,Databricks,Spark,Kubernetes,Docker,R,AWS,Flink,Java}",T√©l√©travail total possible,"160, Avenue des Martyrs, Grenoble, 38000","Ing√©nieries Sp√©cialis√©es, Objets connect√©s, Energie",CDI,2023-04-22,"Schneider Electric est leader mondial de la gestion de l‚Äô√©nergie et des automatismes. Nous concevons, r√©alisons et mettons en ≈ìuvre des solutions innovantes pour une gestion de l‚Äô√©nergie s√ªre, efficace, fiable et durable. La raison d‚Äô√™tre de Schneider Electric est de permettre √† chacun de tirer le meilleur de son √©nergie et de ses ressources, afin de concilier progr√®s et d√©veloppement durable pour tous. Nous nommons cette ambition : Life is On. Notre mission est d‚Äô√™tre le partenaire digital du d√©veloppement durable et de l‚Äôefficacit√© de nos clients. Nous menons la transformation num√©rique en int√©grant les technologies de l‚Äô√©nergie et des automatismes les plus avanc√©es. Nous connectons jusqu‚Äôau cloud, produits, plateformes de contr√¥le, logiciels et services sur l‚Äôensemble du cycle de vie de vos activit√©s pour une gestion int√©gr√©e de l‚Äôhabitat r√©sidentiel, des b√¢timents tertiaires, des data centers, des infrastructures et des industries. Chez Schneider Electric , nous nous engageons √† r√©soudre des probl√®mes concrets pour cr√©er un avenir √©lectrique durable et num√©ris√©. L' Intelligence Artificielle a le potentiel de transformer les industries et d'aider √† d√©bloquer l'efficacit√© et la durabilit√©.Au sein de notre Global AI Hub , nous combinons notre expertise de longue date en mati√®re de fabrication et de domaine avec une innovation de pointe en mati√®re d'IA, d'apprentissage automatique et d'apprentissage profond pour favoriser une prise de d√©cision plus intelligente, l'agilit√© et la d√©carbonisation.Au sein de l'√©quipe AI Technology, nous recrutons un.e Cloud Data Engineer. Le groupe AI Technology (70 personnes) d√©veloppe 2 plateformes d'IA s'appuyant sur Azure et AWS pour r√©pondre aux besoins externes et internes. Vos responsabilit√©s : Ing√©nierie de pipelines de donn√©es efficaces, √©volutifs et adaptables pour traiter des donn√©es structur√©es, semi-structur√©es et non structur√©es. Maintenir et repenser les ensembles de donn√©es et les pipelines existants pour servir une grande vari√©t√© de cas d'utilisation. Mettre en ≈ìuvre l'observabilit√© des donn√©es et surveiller les pipelines de donn√©es en production afin d'en assurer le bon fonctionnement. Agir en tant que partenaire de l'√©quipe d'ing√©nierie de la plateforme et de l'√©quipe d'apprentissage automatique, comprendre leurs d√©fis et faire des recommandations avis√©es qui leur permettent d'avoir des solutions de donn√©es. Ecrire de l'infrastructure en tant que code pour d√©ployer notre infrastructure de donn√©es R√©diger des travaux ETL pour collecter et agr√©ger des donn√©es. Construire des mod√®les de donn√©es de haute qualit√©. Identification, mise en ≈ìuvre de composants et de biblioth√®ques partag√©s √† r√©utiliser d'un contexte √† l'autre. Sp√©cification, conception, mise en ≈ìuvre, test, validation et industrialisation de fonctions avanc√©es de gestion des donn√©es √† int√©grer dans les produits, syst√®mes et solutions. Collaboration avec des experts en donn√©es et en domaines afin d'identifier les m√©thodes, les outils et les technologies de transformation des donn√©es en vue d'√©laborer des plateformes et des offres de produits. Contribution √† l'identification et √† l'√©valuation de partenaires externes potentiels. Contribution √† la protection de la propri√©t√© intellectuelle, √† la capitalisation des connaissances et √† la communication interne et externe. Votre profil : Master ou doctorat ou dipl√¥me √©quivalent en traitement de donn√©es, informatique avec minimum 2 ans d'exp√©rience. Expert en ing√©nierie de pipeline de donn√©es utilisant des technologies telles que Presto, Spark ou Flink et ou les services g√©r√©s √©quivalents des fournisseurs de cloud public. Comp√©tences/exp√©rience en g√©nie logiciel : capacit√© √† coder, d√©boguer, tester (y compris les tests unitaires, les tests fonctionnels et les tests d'int√©gration) et d√©panner tout au long du processus de d√©veloppement de l'application et en mode agile. Id√©alement, connaissance du march√© de la gestion et de l'automatisation de l'√©nergie. Orientation vers la r√©solution de probl√®mes, l'obtention de r√©sultats et l'application de la technologie √† des cas concrets. Comp√©tences de communication efficaces, y compris une aptitude √† raconter des histoires bas√©es sur des donn√©es : convaincre avec des mots, avoir un impact avec des donn√©es et influencer avec des images. Autonomie ET capacit√© √† coop√©rer. Ouverture d'esprit ET rigueur scientifique. Anglais courant. Technologies : Langages : Python, Java, Scala Plateformes cloud : Microsoft Azure, AWS Outils : Kubernetes, Databricks, Docker, Spark, OpenDataSoft, Github, Terraform.Notre offre comprend une r√©mun√©ration attractive et va bien au-del√†. Nous offrons des avantages comp√©titifs, un environnement de travail qui encourage le d√©veloppement professionnel, un onboarding qualitatif et un accompagnement tout au long des diff√©rentes √©tapes de votre vie (formation, opportunit√©s de carri√®re, parentalit√©, flexibilit√©‚Ä¶), dans un lieu de travail formidable.Pourquoi nous? Schneider Electric est le chef de file de la transformation num√©rique de la gestion et de l'automatisation √©nerg√©tique. Nos technologies permettent au monde d'utiliser l'√©nergie de mani√®re s√ªre, efficace et durable. Nous nous effor√ßons de promouvoir une √©conomie mondiale √† la fois viable sur le plan √©cologique et hautement productive. 25,7 milliards d'euros de chiffre d'affaires global 137 000+ employ√©s dans plus de 100 pays 45 % du chiffre d'affaires de l'IdO 5 % du chiffre d'affaires consacr√© √† la R&D Vous devez soumettre une demande en ligne pour √™tre pris en consid√©ration pour ce poste. Ce poste sera post√© jusqu'√† ce qu'il soit rempli.",,Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
137,34411,https://www.welcometothejungle.com/fr/companies/addixware/jobs/data-engineer-f-h_sophia-antipolis_ADDIX_eNAO97Y,Data Engineer,AddixGroup,"{Azure,explosion,Python,DataBricks}",T√©l√©travail total possible,Sophia Antipolis,Logiciels,CDI,2022-08-08,"AddixData (ADD) fait partie du premier groupe fran√ßais d‚Äôing√©nierie informatique sp√©cialis√© dans la transformation digitale. ADD constitue l‚Äôun des 2 hub technologiques et B2B d‚ÄôAddixGroup. Il fournit des solutions et des services aux entreprises qui veulent apporter de l‚Äôintelligence √† leurs donn√©es informatiques. L‚Äôoffre Data est n√©e de l‚Äôexplosion du volume des donn√©es informatiques et du fait que nous consid√©rons qu‚Äôune donn√©e informatique d√©nu√©e d‚Äôintelligence n‚Äôa aucune valeur. Il est devenu essentiel d‚Äôen faire le tri et d‚Äôapporter de l‚Äôintelligence humaine √† toutes ces donn√©es afin de construire un monde qui soit plus vertueux. Compos√© d‚ÄôIng√©nieurs et Docteurs en Data Science, ADD r√©pond √† l‚Äôensemble des probl√©matiques li√©es √† la Data : Analyse des donn√©es, nettoyage et traitement, machine learning, business Intelligence, d√©ploiement de bases de donn√©es et int√©gration de solutions data. Nous sommes pr√©sents sur Paris, Aix-en-Provence et Sophia-Antipolis. AddixData a remport√© un projet innovant pour son partenaire sp√©cialiste de la valorisation immobili√®re. Notre client recup√®re, traite et valorise beaucoup de donn√©es provenantes de diff√©rentes sources, afin de proposer √† leurs clients des informations cl√©s des biens immobiliers, les points d‚Äôint√©r√™ts et les risques permettant √† l‚Äôacheteur de se positionner en s√©curit√© sur l‚Äôachat d‚Äôun bien. Dans ce contexte, vous intervenez en temps que Data Engineer pour piloter ce projet. Vous ma√Ætrisez DataBricks et vous connaissez Azure. Python n‚Äôa pas de secret pour vous? Vous souhaitez rejoindre une √©quipe dynamique et agile ? Ce projet est fait pour vous !","AddixData is a hub of AddixGroup that provides data solutions and services to businesses. They are looking for a Data Engineer with expertise in DataBricks and Azure, and proficiency in Python to pilot a data project for their client specializing in real estate valuation. The ideal candidate will be part of a dynamic and agile team.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,3,1,0.05539549888311683
147,56321,https://www.welcometothejungle.com/fr/companies/thales/jobs/s3ns-site-reliability-engineering-engineer-data-platform-f-h_paris_THALE_LaQzel6,S3NS - Site Reliability Engineering - Engineer Data Platform,Thales,"{durable,shell,Go,Git,Kubernetes,Docker,Spanner,Linux,Unix,GCP,Java,NoSQL,Python}",T√©l√©travail total possible,Paris,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? S3NS est n√© du partenariat industriel entre Thales, leader mondial de la cyber s√©curit√©, et Google Cloud, leader mondial des solutions cloud. Nous avons pour ambition d‚Äôoffrir le meilleur des deux mondes √† l‚Äôensemble des organisations soucieuses de prot√©ger leurs donn√©es sensibles (institutions publiques, OIV, OSE‚Ä¶). C‚Äôest-√†-dire une solution √©quivalente √† Google Cloud Platform (incluant √† la fois les services IaaS et PaaS de GCP) et respectant les exigences du label SecNumCloud. Une premi√®re offre, ‚ÄòContr√¥les locaux avec S3NS‚Äô, est d√©j√† disponible depuis juillet 2022 pour permettre √† nos clients de b√©n√©ficier d‚Äôun premier niveau de transparence et contr√¥les additionnels, et d'acc√©l√©rer la trajectoire vers le cloud de confiance. QUI ETES-VOUS ? Vous √™tes passionn√© par l‚Äôinnovation technologique, le Cloud et les d√©ploiements de services et d‚Äôinfrastructure ‚Äúas code‚Äù ? Vous aimez op√©rer des syst√®mes critiques de grande envergure ? Dipl√¥m√© d‚Äô√©cole d‚Äôing√©nieur vous justifiez d'une exp√©rience reconnue sur des march√©s r√©gul√©s (secteur bancaire/m√©dical‚Ä¶) avec une exposition internationale. Vous justifiez de 5 ans d'exp√©rience minimum dans le software engineering, l‚Äôautomatisation, et le d√©veloppement (S√©curit√© et conformit√©, Automatisation, R√©solution de probl√®mes). Vous avez une exp√©rience de migration d‚Äôinfrastructure priv√©e ou hybride vers le cloud. Vous maitrisez : Un ou plusieurs des langages suivants : C, C++, Java, Python, Go Les cha√Ænes de valorisation de donn√©es incluant les aspects fonctionnels (Collecte et transport h√©t√©rog√®nes et/ou nombreuses, le traitement -normalisation, enrichissement, corr√©lation, analyse - maintenance pr√©dictive, d√©tection d‚Äôanomalies, clusterisation - notification, ‚Ä¶ ‚Äútemps-r√©el‚Äù et/ou ‚Äúbatch‚Äù), le stockage, archivage, indexation et l‚Äôexposition, exploration des donn√©es. Les aspects techniques d‚Äôinfrastructure sous-jacente, file de message, BD relationnelle, BD NoSQL, stockage objet,orchestrateurs et moteurs de traitements (pipeline, machine learning, IA), outils de visualisation et d‚Äôexploration Les aspects op√©rationnels tel que le MCO, de S√©curit√© et de Modernit√© de la solution, int√©grit√©, confidentialit√©, haute disponibilit√©, √©lasticit√©, utilisabilit√© Les technologies de containerisation (ex. Docker, Kata Containers) et d‚Äôorchestration (ex. Kubernetes, Swarm), d‚Äòh√©bergement Open Source (Linux, Docker, Kubernetes, Openstack) A minima un cloud public (ex. GCP) Les OS Linux / Unix et langages de scripting shell Les pratiques du SRE (Infra-As-Code, Git, Continuous Deployment, Terraform, Ansible) CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : En int√©grant l‚Äô√©quipe, vous serez dans un premier temps contributeur de la construction d‚Äôune stack data pour d√©livrer les services du Cloud de Confiance: design, d√©finition SLO/SLI, mise en ≈ìuvre des services, tests, etc. Vous b√©n√©ficierez d‚Äôune latitude importante quant aux choix effectu√©s dans ces phases de design et d'impl√©mentation. En partenariat avec Google, vous pouvez b√©n√©ficiez d‚Äôun parcours de formation acc√©l√©r√© et intense sur les technologies GCP, afin d‚Äô√™tre parfaitement form√© √† la stack technique de Google (ex. Borg, Colossus, Spanner). Vos responsabilit√©s: Mettre en ≈ìuvre et op√©rer en respectant l'√©tat de l‚Äôart de la cyber s√©curit√© toutes les solutions et/ou outils afin d‚Äôam√©liorer l'offre Plateforme Cloud de Confiance : depuis l‚Äôarchitecture, le d√©veloppement, le d√©ploiement, jusqu‚Äôaux op√©rations d‚Äôinfrastructure. Contribuer au design, au d√©veloppement et √† l‚Äôint√©gration des solutions d‚Äôautomatisation et de suivi des infrastructures afin de nous permettre une mise √† l‚Äô√©chelle de nos op√©rations sensibles et processus critiques de hautes disponibilit√©s. Identifier, initier, d√©velopper une boucle d‚Äôam√©lioration continue pouvant √™tre d√©ploy√©e rapidement. Participer √† la construction de cha√Ænes de valorisation de donn√©es permettant d‚Äôimpl√©menter nos Trust Services ET op√©rer les services data et IA de Google dans un environnement Cloud de Confiance.","Thales, in partnership with Google Cloud, is seeking a Senior Software Engineer experienced in software engineering, automation, and development, with at least 5 years of experience in regulated markets. The successful candidate will be responsible for implementing and operating cybersecurity solutions and tools to improve the Cloud Platform of Trust, contributing to the development and integration of infrastructure automation solutions, and providing technical input for the continuous improvement of data monetization chains. A strong knowledge of infrastructure, message queues, databases, containerization, and orchestration tools is required.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
392,34765,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_el2OOAy,BI Engineer & Data Visualisation,Numberly,"{SQL,PowerBI}",T√©l√©travail total possible,Paris,"Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2022-08-08,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception √† la r√©alisation d‚Äôapplications d‚Äôoutils d‚Äôaide √† la d√©cision et monitoring de performance r√©pondant aux probl√©matiques m√©tiers de nos clients. Vous √™tes amen√© √† : Intervenir sur des missions de cadrage et d‚Äôanalyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de r√©pondre aux attentes des clients; Concevoir et r√©aliser les reporting d‚Äôaide √† la d√©cision en apportant une attention aux enjeux de self BI, ainsi que sur l‚ÄôUX/UI Desktop et mobile; D√©ployer des projets de Data Visualisation sous PowerBI en priorit√© mais possiblement en participant aux choix d‚Äôautres outils de restitution; Accompagner les clients dans la bonne compr√©hension et mont√©e en comp√©tence sur l‚Äôexploitation et le maintien des tableaux de bord. Vous assurerez √©galement une veille technologique, et proposerez des solutions standardis√©es, fiables, √©volutives li√©es √† votre activit√©. Chez Numberly, on partage une passion pour la transmission : des s√©minaires hebdomadaires, des talks avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment gr√¢ce :- aux Jedi Masters attribu√©s aux nouvelles recrues ;- aux Vis ma vie dans des √©quipes diff√©rentes ;- aux Happy Meetings suivis par toutes les √©quipes dans le monde pour partager l‚Äôactualit√© du groupe. Nous cultivons la libert√© de parole qui permet √† tous de participer au rayonnement du groupe. A travers 1000mercis impacts mais aussi par nos activit√©s qui cr√©ent de la valeur dans l‚Äôopen Internet, nous agissons positivement sur notre √©cosyst√®me. Numberly est Gender Equal by design (index de l‚Äô√©galit√© Femmes / Hommes de 97/100 en 2020, certification WeConnect International). Numberly est un environnement international (vous interagissez au quotidien avec de nombreuses nationalit√©s) o√π l‚Äôon se sent comme chez soi : des bureaux √† notre image, des cuisines conviviales, une biblioth√®que pointue, un grand studio de musique tout √©quip√©, de la place pour les v√©los. Du caf√©, du th√© et des tisanes √† volont√©. Des mystery lunchs, des soir√©es d√©guis√©es et des cours de sport. Possibilit√© d'√™tre en remote jusqu'√† 50% de votre temps (√† organiser comme vous le souhaitez). Carte Swile (titres-restaurants). Poste disponible √† Paris. Numberly accueille les candidats en situation de handicap. Vous avez au moins 2 ans d'exp√©rience dans la mise en place de projets datawarehouse et datamart. Vous avez une app√©tence particuli√®re au domaine du Big Data, avec des r√©alisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et comp√©tences sur les technologies suivantes : ETL et SQL. Vous √™tes curieux(se), autonome, force de proposition et avez l‚Äôesprit d'√©quipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont r√©compens√© le travail de Numberly en Europe et aux USA) au sein d‚Äôune √©quipe jeune (27 ans de moyenne d‚Äô√¢ge) et internationale (25 nationalit√©s). Encore mieux si Vous avez de l‚Äôexp√©rience sur PowerBI. Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, m√©dia et la relation client.","Numberly, a marketing technology company, seeks a Data Visualization Project Manager with at least 2 years of experience in data warehouse and datamart projects. The ideal candidate will have strong knowledge of ETL and SQL, proficiency in Big Data, and experience with BI/reporting and dataviz. The role involves working on all phases of application design and development, from requirements analysis to reporting and KPI identification, and the successful candidate will have the ability to work autonomously, take initiative, and be a team player. Remote work up to 50% of the time is possible, and the company is committed to a diverse and inclusive workplace.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
74,56537,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad_paris_BM_qldjWyN,Data Engineering Manager - Customer squad,Back Market,"{color,dynamodb,Scala,Lambda,AWS,via,Spark,GCP,Datadog,Python}",T√©l√©travail total possible,"199, Rue Championnet, Paris, 75018","Environnement / D√©veloppement durable, √âconomie collaborative, E-commerce",CDI,2023-03-26,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world‚Äôs leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of 963,226‚ÄØtons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: ‚Äúbe a coach not a dictator‚Äù is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc‚Ä¶ - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We‚Äôre here to SABOTAGE: It‚Äôs our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team.","BackMarket is seeking an Engineering Manager for their Customer data team. The candidate must have the skills to build and develop sustainable and efficient teams, manage a team of data and analytics engineers, have a tech vision for the team, execute effective growth plans, improve processes and product, and work well with non-tech partners. The stack is AWS, GCP, Spark, Terraform, Python, and Scala. BackMarket offers an attractive salary, equity, and various benefits. They are an Equal Opportunity Employer and committed to reducing electronic waste.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
146,50483,https://www.welcometothejungle.com/fr/companies/immortal-game/jobs/analytics-engineer_paris,Analytics Engineer,Immortal Game,"{DBT,Looker,Fivetran,dbt,Snowflake,scale,Stitch,BigQuery,SQL,Python,Tableau}",T√©l√©travail total possible,"29, Rue de Clichy, Paris, 75009","Application mobile, Blockchain",CDI,2023-02-07,"üëã About Us Immortal Game is the World‚Äôs First Play-and-Earn Chess Platform. Our mission is simple: create the best online chess experience for players, streamers, and professionals, while striving to transform the chess industry for the better. We are building the community-driven chess platform for the next generation, adding a new layer of strategy and monetization through NFTs to this over 1000-year-old game. Based in Paris, our 30 employees come from diverse backgrounds and we plan to scale to 50+ people in the next six months. Our platform is live, we‚Äôre growing fast and are backed by some of the top investor firms in Web3 and Entertainment. Do you have experience in data product development? Are you skilled in SQL data modeling using dbt, Snowflake or similar tools? Do you know what is the difference between ETL and ELT? If yes, you could be our first Analytics Engineer! As we ambition to build the best online chess platform, we need the best data analytics stack to help us! About the team Led by Boris, Immortal Game‚Äôs Data Team take care of building and maintaining the data pipeline using modern cloud-based tools. On the Analytics branch we define and monitor company KPIs and analyze player and games data to drive new features and improve our chess platform. The AI branch deploys ML models for cheat detection, recommendation systems and other coming applications like our Chess Academy. Responsibilities üöÄ Work closely with all stakeholders (game design/tech/business) on data & analytics initiatives. Participate actively in KPI‚Äôs definitions. Build and maintain our data pipeline and data models. Analyze and solve data quality and performance issues. Write accurate data documentation and top-quality code following best practices. Maintain and advocate for these standards through code and doc review. Find a good balance between ad hoc requests and long-term projects. Participate in recruitment to build our modern data team from scratch. üíº What we are looking for 5+ years of experience in data product development. Advanced knowledge of SQL based data modeling and Python. Experience in DBT and maintaining large scale ETL / ELT processes. Experience working with data warehouses like Snowflake or BigQuery and data visualization tools such as Looker or Tableau. Fluent in English with excellent communication skills (written and verbal). Working proficiency in French. ü§© Nice-to-have Analytic industry experience with video games. Experience with Fivetran / Stitch / Segment to automatically integrate data from different sources. You are a chess lover ‚ôüÔ∏è üî• Why you should join us An experienced core team of business leaders with many successes already under their belt A spicy package of cash and tokens. Flexibility to work from anywhere in the world. Great employee perks! Benefits üí∞ Competitive salary As we plan to attract and retain the best talents on the market, we offer enticing salaries, benefits, and development opportunities. If you are the right person for the job, there won‚Äôt be much to haggle. ü©∫ Health Extremely comprehensive health insurance through Alan‚Äôs best plan. üçé Wellbeing Gym subscription contribution and a break room stocked with fresh fruit every day. üèùTeam Getaways Immortal Game getaways with the whole team to have fun and work together. ‚òÄÔ∏èOffices Enjoy our brand-new Paris office, full of natural light and awesome people! üö≤ Commuting Country-specific commuter benefits.","The Immortal Game, the world's first play-and-earn chess platform, is seeking an Analytics Engineer with experience in SQL data modeling using tools such as Snowflake or dbt. The position involves building and maintaining the data pipeline and models, analyzing data quality and performance issues, and defining and monitoring company KPIs. The company offers a competitive salary, comprehensive health insurance, gym subscription contribution, and other benefits with the flexibility to work from anywhere in the world. Fluency in French and experience with Fivetran/Stitch/Segment are desirable, as is prior experience in the video games analytics industry.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 5 ans,3,1,0.05539549888311683
186,37138,https://www.welcometothejungle.com/fr/companies/owkin/jobs/data-engineer-semantic_paris_OWKIN_GQ696Dq,Data Engineer Semantic,Owkin,"{go,regard,color,owkin,via,Owkin}",T√©l√©travail total possible,N,"Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDI,2022-10-18,"Owkin exists to find the right treatment for every patient. Our focus is to use artificial intelligence to discover and develop better treatments for unmet medical needs, starting with the fight against cancer. In November, Owkin became a ‚Äòunicorn‚Äô - a startup worth more than $1 billion - through a $180 million investment from pharmaceutical company Sanofi. As a result, we are now looking for the brightest and best talent to help us to go even further in achieving our mission. About us Owkin exists to find the right treatment for every patient. Our focus is to use artificial intelligence to discover and develop better treatments for unmet medical needs, starting with the fight against cancer. In November, Owkin became a 'unicorn' - a startup worth more than $1 billion - through a $180 million investment from pharmaceutical company Sanofi. As a result, we are now looking for the brightest and best talent to help us to go even further in achieving our mission. Learn more about us About the role You will stablish a harmonized data management practice, specifically to manage data quality and delivery for internal and external projects, with the assistance of external experts when required.You will coordinate internal and external data throughout the whole life cycle (governance, curation, processing) In particular, you will: Evaluate and implement the structure and content of different standardization tools such as Common Data Models (e.g. FHIR, OMOP, PCORnet) or standard terminologies (e.g. SNOMED-CT, LOINC, ATC) Promote data quality by searching and properly evaluating sources of information to determine possible limitations in reliability or usability, apply sampling techniques to effectively determine and define ideal categories to be questioned Compare and analyze statistical information to identify patterns, relationships and problems Prepare detailed reports for management and other departments by analyzing and interpreting data Ensure project management for data delivery to ensure all projects can start in the timely manner, following phases of the implementation lifecycle using FAIR approach and classical project management lifecycle Manage external suppliers (like Clinical Research Associate profiles) for specific projects Train people on how to properly organize findings and read data collected Contribute to the maintenance of the Owkin‚Äôs Data Catalog on a functional data layer as well as maintain internal data knowledge to answer RFPs and by providing support to commercial teams on topics related to data (questions, studies‚Ä¶) Possibility to design or contribute to computer code using various languages to improve and update software and applications Position is based in the Paris or Nantes office, under the responsibility of the Data Platform Lead. The responsibilities missions described are not an exhaustive list; additional tasks may be assigned or the scope of the job may change as necessitated by business demands. About you Required qualifications / experience: Bachelor‚Äôs degree in mathematics, statistics, computer science or related field Experiences on Health Data management and FAIR principles, data governance, Common Data Models (CDMs) Knowledge of healthcare Information System and principles softwares Strong math and analytical skills are essential to complete job requirements successfully Ability to complete milestones and work toward multiple deadlines simultaneously Excellent multitasking skills and task management strategies Ability to use necessary databases and software Able to compile and organize statistical information retrieved and present findings to management Good level in English Preferred qualifications/bonus: Experience working with private and sensitive personal information Interpersonal and customer service skills are required when meeting with and interviewing potential clients What we offer Competitive salary & excellent benefits package Flexible work organization and access to remote work Friendly and informal working environment Opportunity to work with an international team with high technical and scientific backgrounds Recruitment Process & Security Please attach a cover letter and a CV. Owkin is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, sex, gender, sexual orientation, age, color, religion, national origin, protected veteran status or on the basis of disability. Owkin is a great place to work. Unfortunately, being a coveted workplace means we are vulnerable to recruitment phishing scams. We urge all job seekers and candidates to be wary of potential scams. Most of these have individuals posing as representatives of prominent companies, including Owkin, with the aim of obtaining personal, sensitive, or financial information from applicants. These scams prey upon an individual‚Äôs desire to obtain a job and can sometimes ‚Äúfeel‚Äù like a genuine recruitment process. Some red flags are identified below. Should you encounter a recruitment process that claims to be for Owkin but is not consistent with the below, please do not provide any personal or financial information: Legitimate Owkin recruitment processes include communication with candidates through recognized professional networks, such as LinkedIn. However, further communication is always through an official Owkin email address (from the @owkin.com domain), over the phone or though Recruitment platforms (WelcomeKit, talent.io, hidden.market, Fifty Talent or Hiresweet); Legitimate Owkin recruiters will not solicit personal data from candidates during the application phase including, but not limited to, date of birth, social security numbers, or bank account information; Legitimate Owkin interviews may be conducted over the phone, in person, or via an approved enterprise videoconferencing service (such as Google Meets or Highfive). They will never occur via Signal, Telegram or Messenger Legitimate Owkin offers of employment are based on merit and only extended once a candidate has interviewed with members of the hiring team. Offers will be extended both verbally and in written format. Owkin may request some personal information to initiate the hiring process, but this will be through protected means. If you think that you have been a victim of fraud, Check the identity of recruiters on LinkedIn and the website https://owkin.com/team/ Check the existence of the position on our website https://owkin.welcomekit.co/ Notify Owkin's recruitment unit at this address hiring@owkin.com contact the following authorities: [FR] https://www.internet-signalement.gouv.fr/ [UK] https://www.actionfraud.police.uk/reporting-fraud-and-cyber-crime [US] https://www.ftccomplaintassistant.gov/#crnt&panel1-1","Owkin, an AI-driven biotech startup focused on discovering and developing better treatments for unmet medical needs, is seeking a Data Manager to establish a harmonized data management practice, manage data quality and delivery for projects, evaluate and implement tools for standardization, and manage external suppliers. The ideal candidate will have a bachelor's degree in mathematics, statistics, computer science, or a related field, experience in health data management and FAIR principles, strong math and analytical skills, and the ability to use necessary databases and software. The position is based in Paris or Nantes, France, and offers a competitive salary and benefits package, flexible work organization, and an opportunity to work with an international team with high technical and scientific backgrounds. Owkin is an equal opportunity employer.",Bac +3,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
144,57083,https://www.welcometothejungle.com/fr/companies/sicara/jobs/data-engineer_paris_SICAR_qgQrRM5,Data Software Engineer - CDI - Paris,Sicara,"{Microsoft,Scala,AWS,Spark,Azure,Hadoop,Python}",T√©l√©travail partiel possible,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"Sicara est une startup experte en data, bas√©e √† Paris : nous r√©volutionnons les projets data en combinant notre m√©thodologie agile de delivery de projet et notre savoir-faire en data science et data engineering afin d‚Äôaider nos clients √† capitaliser sur le potentiel de la donn√©e. Filiale du groupe Theodo, un √©cosyst√®me de 9 filiales et +400 personnes situ√©es √† Paris, Londres, New York et Casablanca, cr√©√©e en novembre 2016 , Sicara est pass√©e de 2 √† 35 personnes en quatre ans. Pour soutenir notre croissance de 50%, nous cherchons √† faire grandir notre portefeuille client. R√©guli√®rement en contact avec les √©quipes techniques et les consultants Sicara seniors, nos AI Project Managers utilisent leurs comp√©tences pour d√©ployer la m√©thodologie projet de d√©veloppement de solution en data science. Sur nos projets, tu seras amen√©(e) √† : Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Travailler en √©quipe de 2 √† 4 data software engineers √©paul√©s par un coach agile et un coach technique Mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) sur le cloud D√©ployer les pipelines de donn√©es (ETL et ELT) Assurer la migration des donn√©es vers les nouveaux environnements Mettre en place des outils de contr√¥le de la qualit√© de la donn√©e Accompagner et former les √©quipes clients Au sein de Sicara, tu seras amen√©¬∑e √† : Contribuer √† notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog. Contribuer √† am√©liorer nos savoir-faire en exp√©rimentant continuellement de nouvelles m√©thodes et de nouveaux outils afin d‚Äôam√©liorer l‚Äôefficacit√© des √©quipes. Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur Tu as une forte app√©tence pour le secteur de la data et tu as id√©alement une premi√®re exp√©rience dans le conseil ou dans la tech Tu as une exp√©rience pass√©e en tant que Data Software Engineer Tu as envie de progresser et d‚Äô√©voluer dans un environnement challengeant et bienveillant au quotidien Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data (Spark, Scala, Hadoop) Tu connais ou as envie d‚Äôapprendre √† utiliser l‚Äôun des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure) 1 entretien RH + 2 entretiens techniques + 1 entretiens dirigeants","The AI Project Manager at Sicara, a data startup in Paris, will work in a team of 2-4 data software engineers to implement data science solution development methodology. The candidate should have experience in data software engineering, knowledge of Python and Big Data technologies, and experience using cloud providers like AWS or Google Cloud Platform. The role involves analyzing data sources and working with business experts, deploying data pipelines, and ensuring secure data systems. The company offers a challenging and supportive work environment, with opportunities for learning and growth.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 6 mois,2,2,0.05539549888311683
372,56964,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_london,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",T√©l√©travail total possible,"Shoreditch High Street, London, E1 6","FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they‚Äôre given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We‚Äôve raised over ‚Ç¨260M from leading investors, and been named a French tech unicorn. And we‚Äôre not stopping there! About our people & culture We believe that people do their best work when they‚Äôre given the freedom to thrive and grow. That‚Äôs why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth ‚Äî with benefits to match! -Fully covered Oyster card for traveling to and from our new office (up to ¬£250 monthly depending on location) -¬£45 monthly wellness allowance, accruable, to be used on whatever wellness means to you - through the Ben platform - Access to Moka.care for emotional and mental health wellbeing - Pension scheme (on salary sacrifice): 5% employee / 5% employer (by Aviva) - 28 days of holidays - Latest Apple Mac equipment - Company virtual events - Visit our other offices: Paris, Berlin & Hamburg - Great office snacks to fuel your day - A positive team to work with daily! - Vitality private health insurance (for you and your family/partner) - Bupa private dental care Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk, a spend management platform for finance teams, is seeking an Analytics Engineer to join their team responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. The role involves designing, developing and maintaining the company's analytics infrastructure, including data pipelines, data warehousing and data visualisation tools to support reporting and analytics needs of the organisation. The ideal candidate should have at least 1-2 years of experience in analytics engineering, business intelligence or a similar role, with strong proficiency in SQL and experience with data modelling, ETL processes and data warehousing.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 1 an,3,1,0.05539549888311683
370,56886,https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/data-engineer,Data Engineer,52 Entertainment,"{Deepnote,Airbyte,Prefect,Looker,Kubernetes,Prometheus,dbt,BigQuery,GCP,SQL,Github,Python}",T√©l√©travail total possible,Villeneuve-D'ascq,Jeux vid√©o,CDI,2023-03-26,"52 Entertainment is a leading e-gaming company, worldwide leader on the Online Bridge with recognized brands like Bridge Base Online , Funbridge , Exoty , Casualino and on the e-sailing thanks to its well known Virtual Regatta . One of the worldwide leader on a lot of e-mind and strategy games like Tarot, Canasta or Belote to name a few. At the crossroads of gaming, entertainment and e-sport 52 entertainment provides unique experiences to truthful communities. Based in France (Lille) with offices and people all around the globe 52 entertainment invents the tomorrow‚Äôs company based on People , Innovation and Mindset . Job description We are looking for a Data Engineer to join our Data Team. You will be responsible for developing, implementing, and monitoring the Data Pipelines of several games of the group . You will work inside the Data Team (1 Data Engineer, 2 Analytics Engineers, 4 Data Analysts, 1 Data scientist) and you will report to the Head of Growth and Data. We use a modern data stack that is primarily composed of Google BigQuery, dbt, Airbyte, Prefect, Deepnote and Looker . The Data Engineering activities focus on GCP, Airbyte, Prefect but also includes Prometheus, Thanos, Graphana tools and Kubernetes nodes management. Team description The Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia). The Data team is fully remote (but all the team is currently based in Europe). We are using top notch communication & project management tools (Slack/Jira/Confluence) and a fantastic stack of technical tools (Airbyte, Prefect, Google Big Query, dbt, Looker, ‚Ä¶) . We talk to each other on a daily basis and organize frequent virtual coffees ‚òïÔ∏è. Some are geeks, some are not, apply as you are, we‚Äôre a diversity-friendly team üßï üëßüèΩ ü•∑ üë®üèø üë© ü¶æ. Stack Data: Airbyte, Prefect, Google BigQuery, dbt, Github, VSCode, Deepnote & Looker Project Management: Slack, Google Drive, Confluence, Jira Missions Create, monitor, and optimize Data Pipelines for existing Games and third-party sources. Manage relations with B.U. Developers and be proactive to prevent pipeline deprecation because of products evolution. Ingest third-party data and setup data consumption endpoints. Ensuring best practices for data integrity and performances. Investigate new initiatives like Data Cataloging, Data Discovery, ML Ops Provide our Data Scientists with Big Data tools that will allow them to process our data more easily (prediction, machine learning, ‚Ä¶). We‚Äôre excited about you because‚Ä¶ You‚Äôve been hesitating between Dev Ops and Data Engineering for a while, but realized that the later was much more fun While you already have some experience in this role, you are passionate to learn even more and want to grow as an expert in a friendly team, while being coached by a senior Data Engineer. You can easily discuss technical concepts with other Dev Ops to help other teams create systems you will need to connect your pipelines to. You like to learn new concepts and tools and are not afraid of getting your hands dirty. Benefits Work in a start-up with exceptional growth Highly interesting work environment with flat hierarchies, fast pace and fun You‚Äôll have a real impact on people‚Äôs lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development. Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best. Extreme autonomy. No micro-managing here. After onboarding, you‚Äôll be given high-level direction and then left to solve it the way you feel is best. Amazingly friendly Data team. Your Profile Minimum 1.5 year of experience either in Data Engineering, Big Data or DevOps Familiar with modern data stacks and principles (cloud-based platforms/data-lakes and managed services) Skilled in SQL and Python Experienced in working in interdisciplinary teams and in multi-cultural team environments Strong communication skills and facilitation abilities Priorities management & time management skills Highly open minded Diplomacy, pedagogy and humility Fluent English. Collecting applications until April 7th 2023 First interviews from March 27th 2023 onward. Our hiring process is sequential : we know job seeking is a stressful time of life, and we‚Äôll make sure things are transparent from our side. If you don‚Äôt pass step 2, we won‚Äôt waste your time on step3. Interview steps Step 1 Visio-call - Preliminary interview where the scope of mission, our company, your aspirations, and salary compensation are discussed to see if we agree on the important things on both sides (30 min) Step 2 Written case-study - Few questions to check that written communication is clear Step 3 Technical case-study - Skills check (take home assignment) on some data problems (no more than 2 hours of involvement) Step 3 Visio-call - Debrief from assignment + Experience and background discussion to get to know you and your experience in Data. Interview questions will be sent ahead of time.","52 Entertainment, a leading e-gaming company, is hiring a Data Engineer to work on developing, implementing, and monitoring the Data Pipelines of several games. The successful candidate should have experience in either Data Engineering, Big Data, or DevOps, be skilled in SQL and Python, have strong communication skills, and be familiar with modern data stacks and cloud-based platforms. The Data team is fully remote and uses top-notch communication and project management tools. The company offers flexibility, autonomy, and a friendly team environment with opportunities for personal and professional growth.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
330,49657,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote-uk_london,Software Engineer Data Presentation - Remote UK,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",T√©l√©travail total possible,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer with experience in software development and an interest in data visualization tools. The ideal candidate is customer-oriented, at ease with both frontend and backend development, and has firsthand experience building a real product. The engineer will work with a team to create usable, intuitive, and beautiful interfaces for Dataiku DSS and will prototype new ways to interact with data or integrations with other products. Dataiku's culture offers flexible work-life balance, autonomy, and opportunities to learn from colleagues. They value diversity and are an equal opportunity employer.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
153,56458,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-engineer-adot_saint-denis,Data Engineer - Adot,Veepee,"{Node,Docker,React,MongoDB,Pytorch,Trino,Kafka,Presto,Git,ScyllaDB,Postgres,Akka,AWS,scale,RabbitMQ,Java,SQL,Hadoop,Redis,spark,Scala,Airflow,dbt,Druid,Spark,GraphQL,Python,Tableau}",T√©l√©travail total possible,"249 Avenue du Pr√©sident Wilson, Saint-Denis, 93210","Application mobile, E-commerce",CDI,2023-03-26,"In 2001, the vente-privee concept was born. Based on the simple but revolutionary idea of transforming the old stock clearance business through digital technology. Back then, the e-commerce was just starting up in Europe, vente-privee set up a digital platform, so that major brands could sell their stock at greatly reduced prices in an attractive environment that protected their image. Vente-privee invented the digital model of event-driven sales, and became a pure player retailer that completely disrupted retail codes in its historical sector: fashion. In 2019, vente-privee changed its name, becoming a European brand: Veepee. The site thus asserted its position as the European leader in online event-driven sales. Every day, the Veepee website offers its members access to these sales. Ready-to-wear, fashion accessories, home equipment, toys, sports articles, high-tech, gastronomy products and more are sold in limited quantities for a certain period (between 3 and 5 days) at significant discounts, with a high-quality presentation. By 2022, Veepee had over 66 million members in ten countries around the world. This success is due to a constant quest for innovation, creativity and quality in terms of both offer and service, under the leadership of Jacques-Antoine Granjon. ‚ÄúOur mission is to create an event every day, to maintain that spark of desire.‚Äù A tried and tested recipe that is now being copied on a global scale. But because innovation and diversification are important to Veepee, they constantly reinvent it, with connected business, Brandsplace, second-hand goods, etc. Veepee‚Äôs pioneering and entrepreneurial spirit continuously drives it to develop and create new activities like Re-cycle and Re-turn, which prove its determination to combine profitable growth with social and societal responsibility. 20 years after its creation, Veepee was the first French unicorn to cross the ‚Ç¨1 billion threshold in turnover in 2014 ‚Äì without ever resorting to fundraising. Veepee occupies a prominent place in the French Tech landscape, and is again one of the Next 40, for the fourth year running. The group now has a workforce of 5,500 in 10 countries and posted a turnover of ‚Ç¨3.2 billion in 2021. The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee . With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Le groupe vente-privee a regroup√© ses diff√©rentes marques europ√©ennes, compos√©es de 6000 employ√©s, au sein d'un conglom√©rat unifi√© : Veepee . Avec Privalia, vente-exclusive, Designer & Friends, Eboutic et vente-privee, Veepee a r√©alis√© un chiffre d'affaires de 3,7 milliards d'euros en 2018. Pr√©sent dans 14 pays d√©sormais, Veepee prend une place pr√©pond√©rante dans le paysage europ√©en du commerce digital. Adot, filiale de veepee, est une solution marketing, poss√©dant un DSP propri√©taire permettant √† ses clients (annonceurs) de diffuser de fa√ßon cibl√©e, leurs campagnes publicitaires. Gr√¢ce √† notre DMP propri√©taire nous utilisons aussi nos donn√©es pour r√©aliser des √©tudes marketing. üìÑ DESCRIPTION DU POSTE Nous cherchons une personne int√©ress√©e par le stockage, le traitement et l‚Äôanalyse de donn√©es volumineuses (10 To bruts par jour, 500 000 requ√™tes par seconde), que ce soit en batch ou en streaming. üéØ MISSIONS Au sein de l‚Äô√©quipe Data, vous serez amen√©.e √† travailler directement avec les Data Engineers, Scientists, Analystes. Vous aurez √©galement une relation privil√©gi√©e avec l'√©quipe Dev. Vous serez confront√©.e √† nos diff√©rentes probl√©matiques : Ingestion, formatage et contr√¥le de la qualit√© des donn√©es en temps r√©el et en batch, venant de partenaires ou d‚Äôautres √©quipes Adot, avec diff√©rentes contraintes (at most once ou at least once, selon l'importance de la source) D√©veloppement de services autour de la donn√©e Mise √† disposition des donn√©es aux diff√©rentes √©quipes Automatisation des agr√©gations et analyses de donn√©es Gestion de l'infrastructure de l'√©quipe Data Revues de code, int√©gration continue ‚öôÔ∏èNotre stack actuelle Pipeline de donn√©es : Spark, dbt, Scala, Kafka, Airflow, Akka, Python, Presto/Trino, Pytorch Dataviz : Tableau Cloud : AWS Mais aussi : Node.js, React, Redux, GraphQL, Druid, ScyllaDB, MongoDB, Postgres, Redis, Docker, Nomad, Consul, Terraform, Ansible,... üëâ PR√â REQUIS Vous avez de bonnes connaissances en Python & SQL Vous avez des notions en Scala et/ou Java Vous portez un int√©r√™t pour Spark Vous maitrisez les syst√®mes de stockage distribu√©s, leurs avantages et leurs contraintes Vous connaissez les pratiques classiques de software engineering : usage de Git et pratique de code reviews, culture du test, CI/CD. Vous √™tes responsable de votre code de l'IDE jusqu'√† la prod Vous √™tes tr√®s curieux¬∑euses et aimez √™tre √† la pointe en faisant r√©guli√®rement de la veille technologique. üëâ LE PETIT PLUS Vous avez travaill√© sur un projet √† forte volum√©trie et/ou dans un environnement Spark/Hadoop Vous avez travaill√© avec Kafka ou une file de message telle que RabbitMQ ou ActiveMQ Vous avez d√©j√† travaill√© avec dbt Vous √™tes familier des plateformes cloud, si possible AWS Vous avez d√©j√† travaill√© avec Airflow Vous aimez travailler en collaboration avec des profils diff√©rents du v√¥tre et partager vos connaissances Vous aimez faciliter et automatiser les t√¢ches r√©p√©titives ‚úÖ AVANTAGES Un environnement enrichissant et humain Vous apprendrez beaucoup de choses techniques mais pas seulement Un environnement de travail stimulant avec de nombreux projets et innovations Politique de t√©l√©travail pouvant aller jusqu'√† 3 jours par semaine Un parcours d'int√©gration complet pour rencontrer l'ensemble des √©quipes et √™tre form√© sur son poste et aux process internes Une qualit√© de vie au travail : budgets team building, cours de yoga, sensibilisation √† la sant√© mentale, √©v√©nements internes de coh√©sion... ‚ùì WHO WE ARE Veepee·µÄ·µâ·∂ú ∞ is a part of Veepee and one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you‚Äôll be sure to find your place, no matter the technology you want to work with. If you love to try things why don‚Äôt you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, and to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, a European online retailer, is seeking a Data Engineer with experience in handling large volumes of data in both batch and streaming. The successful candidate will work closely with Data Engineers, Scientists, Analysts, and the Dev team to develop services around data, handle infrastructure, automate data analysis, and manage the data pipeline. Proficiency in Python and SQL, familiarity with Scala and Java, and knowledge of Spark and distributed storage systems are required. Experience with Kafka, dbt, Airflow, and cloud platforms is preferred. Veepee offers a stimulating work environment with opportunities for growth, telecommuting up to three days a week, and various benefits.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
307,56462,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_berlin,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",T√©l√©travail total possible,Berlin,"FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they‚Äôre given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We‚Äôve raised over ‚Ç¨260M from leading investors, and been named a French tech unicorn. And we‚Äôre not stopping there! About our people & culture We believe that people do their best work when they‚Äôre given the freedom to thrive and grow. That‚Äôs why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth ‚Äî with benefits to match! - 100% reimbursed public transport to the office or bike perk of 30 Euro - Latest Apple equipment (MacBook Air) - 28 days of annual leave - Monthly budget of ‚Ç¨50 for wellness-related spending - Access to Moka.care (platform for emotional and mental well-being) - A friendly remote policy - 3 days onboarding trip to Paris & access to our other offices across Europe - Great office snacks to fuel your day - A positive team to work with daily! Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk is looking for an Analytics Engineer to join their data team and build the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. The responsibilities of the role include collaborating with stakeholders to identify business requirements, developing and maintaining ETL processes, designing and developing data models, leading data governance initiatives, and monitoring and troubleshooting issues with the infrastructure. The ideal candidate should have at least 1-2 years of experience in analytics engineering or business intelligence, strong proficiency in SQL, knowledge of database design, optimization, and maintenance, and experience with data modeling, ETL processes, and data warehousing.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 1 an,3,1,0.05539549888311683
121,73599,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-scientist-environnement-full-teletravail_MD_1lgk0dx,Data Engineer / Scientist - Environnement - Full t√©l√©travail,MP DATA,"{Postgres,GCS,Azure,Django,SQL,Kafka,Spark,MongoDB,AWS,Git,S3,Snowflake,Java,GCP}",T√©l√©travail total possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-04-22,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance, l‚Äôexploitation de leur donn√©es et leur d√©carbonation. Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement. Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais. MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences. Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort, et des possibilit√©s d‚Äô√©volution int√©ressantes. MP DATA, recrute un(e) Data Scientist avec des affinit√©s pour le m√©tier de Data Engineer (H/F) afin de travailler pour un client, acteur majeur du secteur de la sant√© √† Paris. Vous serez amen√© √† intervenir sur plusieurs probl√©matiques notamment : travail des donn√©es, d√©veloppement d‚Äôalgorithmes de machine learning, d√©ploiement de ces algorithmes. Tout cela autour de cas d‚Äôusages industriels √† forte valeur ajout√©e et impact environnemental positif. Accompagn√© par un Lead Data Scientist et un Lead Data Engineer, vous monterez en comp√©tences sur : le management des flux de donn√©es (pr√© processing, feature engineering‚Ä¶) ainsi que la mise en place et l‚Äôindustrialisation de ces mod√®les de machine learning. Les seniors vous guideront step by step dans l‚Äôutilisation de ces nouvelles technologies. Ing√©nieur d‚Äôune Grande √âcole, vous avez des connaissances en machine learning acquises lors de votre scolarit√© ou de vos exp√©riences pass√©es (stage ou c√©sure). Votre autonomie, votre capacit√© √† √™tre force de proposition et votre esprit de synth√®se ont √©t√© reconnues durant vos pr√©c√©dentes exp√©riences (stage ou c√©sure). Vous √™tes int√©ress√©s pour vous d√©passer en data science & data engineering et vous avez des premi√®res exp√©riences dans ce domaine, comme par exemple : C/C++ / Java / Rust Spark Kafka Cloud : AWS / GCP / Azure Technologies de stockage : Snowflake / S3 / GCS / Azure Blob Django / Flask Git SQL : Postgres / MongoDB CI/CD. Alors venez grandir avec nous !",,Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,3,1,0.05539549888311683
345,34212,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris-or-remote-france_paris,Software Engineer Data Presentation - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",T√©l√©travail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do : We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do : With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if : You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. (Note: This is a Software Engineering job. We have separate Data Scientist positions open) Dataiku‚Äôs culture is right for you if : You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer with experience in data visualization tools to create usable, intuitive, and beautiful interfaces and scalable engines for Dataiku DSS. The ideal candidate should be customer-oriented and comfortable with both frontend and backend development, with firsthand experience building real products. The position offers autonomy, flexible work-life balance, and a commitment to diversity, equity, and inclusion. Dataiku's technical stack includes Javascript, AngularJS, Angular, D3.js, Java, Spring, and Python.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
342,56340,https://www.welcometothejungle.com/fr/companies/thales/jobs/s3ns-site-reliability-engineering-engineer-data-platform-f-h_paris,S3NS -  Data Platform Engineer,Thales,"{durable,shell,Go,Git,Kubernetes,Docker,Spanner,Linux,Unix,GCP,Java,NoSQL,Python}",T√©l√©travail total possible,Paris,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? S3NS est n√© du partenariat industriel entre Thales, leader mondial de la cyber s√©curit√©, et Google Cloud, leader mondial des solutions cloud. Nous avons pour ambition d‚Äôoffrir le meilleur des deux mondes √† l‚Äôensemble des organisations soucieuses de prot√©ger leurs donn√©es sensibles (institutions publiques, OIV, OSE‚Ä¶). C‚Äôest-√†-dire une solution √©quivalente √† Google Cloud Platform (incluant √† la fois les services IaaS et PaaS de GCP) et respectant les exigences du label SecNumCloud. Une premi√®re offre, ‚ÄòContr√¥les locaux avec S3NS‚Äô, est d√©j√† disponible depuis juillet 2022 pour permettre √† nos clients de b√©n√©ficier d‚Äôun premier niveau de transparence et contr√¥les additionnels, et d'acc√©l√©rer la trajectoire vers le cloud de confiance. QUI ETES-VOUS ? Vous √™tes passionn√©(e) par l‚Äôinnovation technologique, le Cloud et les d√©ploiements de services et d‚Äôinfrastructure ‚Äúas code‚Äù ? Vous aimez op√©rer des syst√®mes critiques de grande envergure ? Dipl√¥m√© d‚Äô√©cole d‚Äôing√©nieur vous justifiez d'une exp√©rience reconnue sur des march√©s r√©gul√©s (secteur bancaire/m√©dical‚Ä¶) avec une exposition internationale. Vous justifiez de 5 ans d'exp√©rience minimum dans le software engineering, l‚Äôautomatisation, et le d√©veloppement (S√©curit√© et conformit√©, Automatisation, R√©solution de probl√®mes). Vous avez une exp√©rience de migration d‚Äôinfrastructure priv√©e ou hybride vers le cloud. Vous maitrisez : Un ou plusieurs des langages suivants : C, C++, Java, Python, Go Les cha√Ænes de valorisation de donn√©es incluant les aspects fonctionnels (Collecte et transport h√©t√©rog√®nes et/ou nombreuses, le traitement -normalisation, enrichissement, corr√©lation, analyse - maintenance pr√©dictive, d√©tection d‚Äôanomalies, clusterisation - notification, ‚Ä¶ ‚Äútemps-r√©el‚Äù et/ou ‚Äúbatch‚Äù), le stockage, archivage, indexation et l‚Äôexposition, exploration des donn√©es. Les aspects techniques d‚Äôinfrastructure sous-jacente, file de message, BD relationnelle, BD NoSQL, stockage objet,orchestrateurs et moteurs de traitements (pipeline, machine learning, IA), outils de visualisation et d‚Äôexploration Les aspects op√©rationnels tel que le MCO, de S√©curit√© et de Modernit√© de la solution, int√©grit√©, confidentialit√©, haute disponibilit√©, √©lasticit√©, utilisabilit√© Les technologies de containerisation (ex. Docker, Kata Containers) et d‚Äôorchestration (ex. Kubernetes, Swarm), d‚Äòh√©bergement Open Source (Linux, Docker, Kubernetes, Openstack) A minima un cloud public (ex. GCP) Les OS Linux / Unix et langages de scripting shell Les pratiques du SRE (Infra-As-Code, Git, Continuous Deployment, Terraform, Ansible) CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : En int√©grant l‚Äô√©quipe, vous serez dans un premier temps contributeur de la construction d‚Äôune stack data pour d√©livrer les services du Cloud de Confiance: design, d√©finition SLO/SLI, mise en ≈ìuvre des services, tests, etc. Vous b√©n√©ficierez d‚Äôune latitude importante quant aux choix effectu√©s dans ces phases de design et d'impl√©mentation. En partenariat avec Google, vous pouvez b√©n√©ficiez d‚Äôun parcours de formation acc√©l√©r√© et intense sur les technologies GCP, afin d‚Äô√™tre parfaitement form√© √† la stack technique de Google (ex. Borg, Colossus, Spanner). En tant qu' Engineer Data Platform , vos missions seront les suivantes : Mettre en ≈ìuvre et op√©rer en respectant l'√©tat de l‚Äôart de la cyber s√©curit√© toutes les solutions et/ou outils afin d‚Äôam√©liorer l'offre Plateforme Cloud de Confiance : depuis l‚Äôarchitecture, le d√©veloppement, le d√©ploiement, jusqu‚Äôaux op√©rations d‚Äôinfrastructure. Contribuer au design, au d√©veloppement et √† l‚Äôint√©gration des solutions d‚Äôautomatisation et de suivi des infrastructures afin de nous permettre une mise √† l‚Äô√©chelle de nos op√©rations sensibles et processus critiques de hautes disponibilit√©s. Identifier, initier, d√©velopper une boucle d‚Äôam√©lioration continue pouvant √™tre d√©ploy√©e rapidement. Participer √† la construction de cha√Ænes de valorisation de donn√©es permettant d‚Äôimpl√©menter nos Trust Services ET op√©rer les services data et IA de Google dans un environnement Cloud de Confiance Int√©ress√©(e) Rejoignez-nous!","Thales is seeking an Engineer Data Platform with experience in software engineering, automation, and development, and exposure to regulated markets such as banking or healthcare. The ideal candidate should have a minimum of five years' experience in the migration of private or hybrid IT infrastructure to cloud. They should be proficient in at least one programming language such as C++, C, Python, or Java, have knowledge of containerization, orchestration technologies, and Linux/Unix, and have experience with security and compliance. The role's responsibilities will include working with Thales and Google to build secure cloud platforms and data handling systems for clients.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
306,34611,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-paris-or-remote-france_paris_DATAI_3Nw4a3o,Software Engineer Data Preparation - Paris or Remote France,Dataiku,"{Python,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Jupyter}",T√©l√©travail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings, to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly visual interfaces or code. To help us fulfil this mission, we are looking for a talented fullstack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers such as: - Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, '¬¶ and processing data using the latest processing engines: Spark on K8s, SQL with UDFs - SQL workbench & Jupyter notebooks - Integration with IDEs - Help and onboarding experience - Plugins infrastructure - Automation & public REST APIs Our current technical stack is based on a mix of Java, Javascript and Python. What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphical explain plans in our SQL workbench (Note: This is a Software Engineering job. We have separate Data Scientist positions open) You are the ideal recruit if: You have experience in software development and are interested in data processing You are customer-oriented '‚Äù you want to understand how the product is used and solve actual customer problems You know Data science is 80% preparing data and 20% complaining about preparing data You are curious about working '≈ìunder the hood' and want to learn how things are built You have firsthand experience (either professional or personal) building a real product You are humble and kind You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku, a New York City-based provider of a platform which automates AI, requires a full-stack software engineer, who will be responsible for developing Dataiku's data-preparation, integration and core features. The successful candidate should be customer-orientated, curious about working behind-the-scenes, and have worked on a real-life project before.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
347,56354,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-h-f_bordeaux_NEXTO_0L3eOd,Data Engineer -,NEXTON,{powerBI},T√©l√©travail total possible,Bordeaux,"Design, IT / Digital, Digital",CDI,2023-03-26,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, Nexton conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, professionnalisme et performance. Et pour vous ? Notre politique de d√©veloppement des comp√©tences dynamique saura vous s√©duire avec un programme de suivi de carri√®re sur-mesure. NEXTON, leader du conseil digital op√©rationnel recrute un Data Engineer H/F , en CDI , √† Bordeaux ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, Nexton conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance. Et pour vous ? Notre politique de d√©veloppement des comp√©tences dynamique saura vous s√©duire avec un programme de suivi de carri√®re sur-mesure. Le contexte: Vous √©voluez au sein d'une squad agile qui g√®re l'ensemble de l'outillage des postes de travail et smartphones de notre client grand compte (secteur bancaire) et de ses filiales. Vos missions : Participer au montage d'un datalake / Datawarehouse, Elaborer le dossier d'architecture, Analyser les donn√©es en fonction des besoins utilisateurs, Mettre en place l'outil powerBI et le configurer, Contribuer √† la mise en place d'API pour offrir de la donn√©e aux utilisateurs en ayant besoin, Concevoir les architectures et les combinaisons technologiques qui permettent de r√©soudre les probl√®mes identifi√©s, Configurer les solutions big data appropri√©es aux √©quipes. Vous avez √©tudiez les syst√®mes d'informations, la Big Data ou le traitement de donn√©es lors d'un parcours sup√©rieur de type √©cole d'ing√©nieurs (BAC+5). Votre capacit√© √† r√©gler des probl√®mes techniques complexes et votre autonomie dans le recherche de solutions li√©es √† la Big Data font partie de vos qualit√©s professionnelles. Vous travaillez de mani√®re autonome dans un contexte agile, un minimum de quatre ann√©es d'exp√©riences sur un poste de data engineer est n√©cessaire pour √™tre op√©rationnel sur ce poste. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'ann√©e : - Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'ann√©e - Des moments privil√©gi√©s avec votre manager Pr√™ts √† nous rejoindre ? Rencontrons-nous !","Nexton, a company specialized in digital transformation, is hiring a Data Engineer with a minimum of four years of experience in a similar role to join their agile team in Bordeaux. The successful candidate will participate in the development of a Data Lake/Datawarehouse, build the architecture dossier, analyze data based on user needs, configure PowerBI, and contribute to the implementation of APIs. The ideal candidate should have a degree in Information Systems, Big Data, or Data Processing and possess problem-solving skills related to Big Data. Nexton offers career advancement opportunities and networking events throughout the year.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
123,72226,https://www.welcometothejungle.com/fr/companies/inato/jobs/data-engineer_paris,Data Engineer,Inato,"{Airbyte,Looker,PostgreSQL,Airflow,Kubernetes,dbt,scale,MixPanel,BigQuery,GCP,SQL,Python}",T√©l√©travail total possible,"14, Boulevard Montmartre, Paris, 75009","Logiciels, Pharmaceutique / Biotechnologique, Sant√©",CDI,2023-04-08,"Inato is a tech-for-good company striving to bring clinical research to each and every patient across the globe. To do this, they are building the world‚Äôs first clinical trial marketplace designed to improve visibility, access, and engagement across a more diverse population of doctors and their patients. Drug development is a complex and rewarding endeavor: their platform enables sponsors and community-based researchers to work together when developing effective treatments for diseases affecting millions of people. WHO WE ARE Inato is a Tech for Good company striving to bring clinical research to each and every patient, regardless of who they are or where they live. To do this, we are building the world's first clinical trial platform to create greater visibility, access, and engagement across a more diverse population of doctors and their patients. Drug development is a challenging, intellectually complex, and rewarding endeavor : we enable global pharmaceutical companies to confidently partner with community-based researchers to increase patient access to the latest medical innovations. The platform currently offers clinical trials from leading companies to over 1,000 sites across the globe. And we are well poised for growth in 2023. We are a growing team of passionate pharmaceutical experts, software engineers, professional services members, and many more - all bringing their unique perspective to solve the challenges facing clinical research. Our team members live by our company values to be bold, resilient, caring, and pragmatic. If this sounds like you, join us! The role We are seeking an experienced Data Engineer to join our fast-growing data team. In this role, you will play a critical part in helping us build a scalable data infrastructure that supports the data team's mission to provide high-value analysis and tools to Inato‚Äôs team so they can make faster and better data-driven decisions. This is an exciting opportunity to make a meaningful impact in a small and dynamic team that is changing the face of the industry. Our stack includes Google BigQuery, Segment, Airbyte, Looker Studio, Husprey, Retool, dbt, MixPanel, and more. üíä Responsibilities Design, build and maintain our data pipelines and infrastructure to ensure efficient and reliable data ingestion and processing. Collaborate with the Data and Product team to expose data to the product and implement machine learning models into production. Monitor and troubleshoot our data infrastructure to ensure maximum uptime and performance. Work with cross-functional teams to ensure data availability, quality, and consistency across the organization. üíä Requirements 3+ years of experience in data engineering, with experience in building and maintaining data pipelines at scale. Strong experience with data processing languages such as Python and SQL. Experience with database technologies such as PostgreSQL. Familiarity with cloud-based data infrastructure and storage, preferably GCP. Experience with ETL/ELT tools such as Airflow, Segment, Airbyte Familiarity with infrastructure tools such as Terraform, and Kubernetes. üíä Perks Remote-first philosophy & flexible hours Amazing office in Grands Boulevards, Paris where you can meet with colleagues if this is important for you Top-of-the-line equipments Compensatory time (RTT) Free health insurance (Alan Blue, 100% paid by Inato) Meal vouchers (Swile) Contribution to healthy activities (Gymlib) Free books & learning material Inato is an Equal Opportunity Employer for any minority, disability, gender identity, or sexual orientation.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
114,57114,https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer_bruxelles,Data Engineer,LittleBigCode,"{GCP,Mongo,Scala,AWS,Kafka,Cassandra,R,Spark,Azure,SQL,Hadoop,Python}",T√©l√©travail total possible,"54, Avenue Louise, Bruxelles, 1050","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"LittleBigCode is a digital consulting laboratory specializing in Data and Artificial Intelligence. Our mission is to democratize the use of these technologies by co-building useful applications with our customers for the Society of the future, particularly on subjects related to health, mobility or the environment. For this, we deliver turnkey projects and also work on consulting assignments while developing our own solutions. Finally, we combine Cloud technologies, AGILE methods and DevOps culture to facilitate industrialization and scaling up. Our big success so far: A community of more than 40 enthusiasts of Data Science & Data Engineering domains International presence & missions ‚Äì we are launching our new office in Belgium! Workshops, Innovation contests, customers challenges taken up As such, we are looking to build our technical team in Belgium ! Join us ! What will be your tasks with us? Concretely on a daily basis, you will work in AGILE mode and as a team (made up of Data Scientists, architects, Devops coach, etc.). You‚Äôll support our customers on their Data, delivery & release challenges. You will be working in the following areas: Consulting & expertise among our customers on their strategic projects: Analyze our customers‚Äô strategic challenges around Data issues Make your contribution to define their ambitions and their Data roadmap Audit & projects framing (architecture, methodology, code quality) Achievements/ support of projects that involve Data centric architecture set up R&D and Solutions: Participation in the development of internal solutions Proposal and creation of innovative solutions Who are you? You have a Master in engineering (Computer Science, Mathematics, Statistics‚Ä¶) and you have some experiences as a Data Scientist! You have some relevant programming experiences, and you are familiar with Big Data technologies such as Spark, Hadoop, Kafka, Cassandra, Mongo among others You are fully proficient with the following languages: Python, SQL (if possible, Scala) You are familiar with data services of at least one major Cloud Provider (Azure, AWS, GCP) and with the different Database types You are strong on data structuration & modulization concept You are familiar with ETL use & set up Note that we are also big devotees of DevOps so the more you are comfortable with it, all the better! Fluent in English + in Dutch and/or French","LittleBigCode is seeking a Data Scientist who will join their technical team in Belgium. The ideal candidate should have a master's in engineering with relevant programming experience and expertise in Big Data technologies such as Spark, Hadoop, Kafka, Cassandra, and Mongo. They should also be proficient in Python, SQL, and Scala and have familiarity with data services of major cloud providers. Additionally, the candidate should be familiar with ETL setup and have strong data structuration and modulization concept skills. The candidate should also have experience in consulting and expertise, audit and project framing, R&D, and solutions development. Fluency in English and Dutch or French is required.",Bac +5 / Master,Entre 15 et 50 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
341,34770,https://www.welcometothejungle.com/fr/companies/mediaperformances/jobs/data-engineer-f-h_courbevoie,Data Engineer,M√©diaperformances,"{Javascript,Beam,Git,Collibra,Tableau,PowerBI,Snowflake,via,GCS,Bigquery,GCP,Sql,SQL,Python,Datastudio}",T√©l√©travail total possible,Courbevoie,"M√©dia, Grande consommation, Publicit√©",CDI,2022-08-08,"Depuis plus de 35 ans, M√©diaperformances aide les marques de grande consommation √† d√©velopper leurs ventes dans les enseignes de la grande distribution alimentaire. Ils mettent en place des campagnes publicitaires omnicanales √† destination des personnes qui font leurs courses (les shoppers) pour influencer leur comportement d‚Äôachat. Ils proposent des m√©dia en magasin et aussi en digital : des campagnes publicitaires achet√©es en programmatique et cibl√©es gr√¢ce √† de la data comportementale, des applications mobiles, des bons de r√©duction d√©mat√©rialis√©s, des √©crans digitaux, etc. Le m√©tier de M√©diaperformances √©voluant en m√™me temps que les comportements d‚Äôachat, ils doivent toujours suivre les tendances et s‚Äôadapter aux √©volutions de la consommation. En 2022 et pour la troisi√®me ann√©e cons√©cutive nos collaborateurs nous ont √©lus ‚ÄúGreat Place To Work‚Äù officialisant ainsi qu‚Äôil faisait bon travailler chez M√©diaperformances. Nous sommes engag√©s depuis plusieurs ann√©es dans un d√©marche RSE volontariste. D‚Äôabord en d√©finissant notre raison d‚Äô√™tre ‚Äúpromouvoir via nos m√©dias une consommation plus responsable‚Äù puis en √©tant certifi√©s B Corp, la certification internationale qui r√©pond aux standards les plus √©lev√©s en mati√®re de performances sociale, soci√©tale et environnementale. Au c≈ìur de cette strat√©gie d‚Äôacc√©l√©ration digitale, le Data Engineer aura un r√¥le central. Il aura, en effet, pour missions principales de : Participer √† la conception et √† la construction de notre plateforme de donn√©es Construire des pipelines de donn√©es en ayant recours √† diff√©rentes technologies et langages (Python, Sql, Beam ‚Ä¶) Assurer la qualit√© des donn√©es collect√©es, pr√©parer et optimiser le stockage et le chargement, Travailler de pair avec nos data scientists pour optimiser la performance de nos projets et d√©velopper de nouveaux cas d‚Äôusage Assurer et am√©liorer le monitoring des diff√©rents flux d√©j√† existants en mettant en place des processus d‚Äôautomatisation et d‚Äôindustrialisation Assurer le Cataloging des donn√©es au sein de la plateforme D√©finir des KPIs et cr√©er des tableaux de bord de co√ªt et d‚Äôutilisation Il sera amen√© √† collaborer avec diff√©rents services dans l‚Äôentreprise : La DSI, les d√©veloppeurs de nos filiales, le trading desk, ainsi que des partenaires ext√©rieurs retailer et GAFAM‚Ä¶ Il d√©pendra du Chief Data Officer, direction de l‚Äôacc√©l√©ration digitale. Vous √™tes passionn√© par le domaine de l‚Äôinformatique et la data et avez d√©j√† une exp√©rience sur des enjeux data engineering et big data sur un environnement cloud. Vous avez une grande capacit√© √† recueillir le besoin, le designer et le mettre en place. Les probl√©matiques retail, marketing client et m√©dias ne vous sont pas √©trang√®res. ‚Ä¢ Vous √™tes dipl√¥m√©s d‚Äôun minimum BAC +5 d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun master dans un domaine connexe √† la data. ‚Ä¢ Vous √™tes Automne. Vous savez vous adapter (notamment pour assurer la gestion multi projet) et faites preuve de curiosit√©. Votre exp√©rience : Vous justifiez d‚Äôau moins 2 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶) Vous disposez de solides connaissances sur les architectures de donn√©es et le cloud. Vous √™tes certifi√© et/ou avez de l‚Äôexp√©rience sur l‚Äôenvironnement cloud GCP (Bigquery, GCE, Cloud run, Source repository, GCS, data proc, data flow) Vous avez de solides comp√©tences en Python, SQL Vous avez une bonne connaissance des processus et outils de d√©veloppement modernes (DevOps, Terraform, Git, CI/CD‚Ä¶) ; Vous connaissez un ou plusieurs outils de cataloging et de data lineage (Collibra, Dataedo, etc) Les plus : Vous disposez d‚Äôune exp√©rience en visualisation de donn√©es d√©montr√©e sur un outil au moins (Datastudio, PowerBI, Tableau) Vous ma√Ætrisez Javascript, compr√©hension des API Vous avez travaill√© avec des solutions du type DMP/CDP, Snowflake M√©diaperformances s‚Äôengage dans l‚Äôinsertion des personnes en situation de handicap et traite l‚Äôensemble des candidatures dans le respect des grands principes de non discrimination.","Mediaperformances is seeking a Data Engineer to help build its data platform and construct pipelines using different technologies and languages. The successful candidate must have at least two years of experience in data engineering, solid knowledge of data architectures and cloud, and be familiar with Python, SQL, and development tools. A degree in engineering or a data-related field is required. Experience with data visualization tools and DMP/CDP solutions is a plus. The company is committed to non-discrimination and welcomes applications from candidates with disabilities.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
111,34563,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-dataiku-online-paris-or-remote-france_remote,Software Engineer Dataiku Online - Paris or Remote France,Dataiku,"{React,go,Dataiku,python,regard,Kubernetes,dataiku,Docker,Python}",T√©l√©travail total possible,Levallois-Perret,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online‚Äôs team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku subscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is either at the company HQ in Paris (Gare de Lyon) or remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented ‚Äî you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: Hands-on expertise working with Docker and Kubernetes Experience on an high availability SaaS Knowledge in DataScience, AI and Machine Learning Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking an experienced developer with interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. The platform consists of a cloud infrastructure and a launchpad where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources, and manage the Dataiku subscription. The ideal recruit should have experience working on a full-stack application, building a real SaaS portal, and understanding the customer's needs. Bonus points for those with hands-on expertise working with Docker and Kubernetes, knowledge in Data Science, AI, and Machine Learning, advanced knowledge in Python, and Vue.JS. Dataiku culture promotes work-life balance, autonomy, and caring for their employees.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
291,56997,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/data-engineer-f-h_la-defense_INGNI_z7g6P2,Data Engineer -,Ing√©niance,"{GCP,Redis,Scala,Kubernetes,AWS,Storm,Cassandra,Hadoop,Azure,Java,NoSQL,SQL,Python,Cloudera,docker}",T√©l√©travail total possible,La Defense,IT / Digital,CDI,2023-03-26,"Ing√©niance, est une soci√©t√© de conseil sp√©cialis√©e dans des projets li√©s aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajout√©e en associant innovation technologique, transformation digitale, expertise m√©tier (Banque, Finance et Assurance) & m√©thodes agiles. Technology-oriented, elle offre une r√©elle expertise √† ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l‚ÄôAgilit√©. Son projet d‚Äôentreprise s‚Äôappuie aussi sur des valeurs humaines, soci√©tales et environnementales (Label EcoVadis Gold). La proximit√©, la performance, la convivialit√© et le progr√®s sont des atouts sur lesquels elle b√¢tit son√©volution collective au quotidien. Quelles seront vos missions ? Vos missions s'inscrivent dans un contexte de travail Agile, au sein du centre d'expertise Data en charge du d√©veloppement et de la gestion des syst√®mes de collecte, normalisation croisement et restitution des donn√©es. Dans ce cadre, vous contribuerez √† : D√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, stockage) D√©velopper des moyens de restitution de la donn√©e (APIs, g√©n√©ration fichier, autres...) Industrialiser et automatiser les tests des APIs (Swagger, Postman, ...) D√©velopper des moyens de parall√®lisation des processus (Apache Storm, Multithreading, ...) D√©finir les bonnes pratiques de d√©veloppements sur le cloud (AWS, Azure, GCP, ...) R√©diger la documentation n√©cessaire au partage et √† la maintenance du code Faire partie d'une √©quipe agile et suivre la m√©thodologie Scrum Qui √™tes-vous ? Entre 5 et 10 ans d'exp√©rience en d√©veloppement dont au moins 3 sur un programme DATA Vous ma√Ætriser un langage de programmation (Java, C#, Scala, Python) Vous √™tes √† l'aise avec les architectures distribu√©es ou sur le cloud et leur mise en place. Vous avez de solides connaissances en SQL ainsi que sur des bases de donn√©es NoSQL (Mango, Redis, Cassandra) Vous avez d√©j√† travaill√© avec des outils de conteneurisation comme docker et d'orchestration tel que Kubernetes Enfin vous avez d√©j√† impl√©ment√© des solutions dans le cloud (AWS, Azure, GCP...) Les comp√©tences que vous renforcerez : Vous interviendrez sur la conception et le d√©ploiement d'environnements ¬´ clusturis√©s ¬ª de type Datalake (Hadoop/Cloud & distributions Hortonworks, Cloudera) Vous pourrez vous confronter et contribuer √† une communaut√© d'experts Vous accompagnerez les √©quipes de Datascientist, d'experts du Machine Learning et des approches statistiques, sur des projets de mise en oeuvre de ces approche s et du traitement des donn√©es associ√©es. Vous √©voluerez dans un environnement fonctionnel riche","Ing√©niance is seeking a Senior Data Engineer with 5-10 years of experience in Java, C#, Scala, Python, and related cloud technologies such as AWS, Azure, and GCP. The successful candidate will be responsible for developing data pipelines, building data ingestion and storage solutions, and implementing NoSQL databases. The job entails working in an Agile environment and following Scrum methodology. The role is focused on developing new pipelines, creating means of data restitution, automating testing, and parallelizing processes.  The successful applicant will work within Ing√©niance's Data Excellence Centre team, supporting the development and management of data collection, cross-checking, and restitution systems.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
333,57164,https://www.welcometothejungle.com/fr/companies/javelo/jobs/data-engineer_paris,Data Engineer,Javelo,"{CircleCI,React,Ruby,Airbyte,DBT,AWS,Snowflake,Docker,Elastic,Datadog,SQL,Github,Python,Postgres,Tableau}",T√©l√©travail total possible,"26 rue Henry Monnier, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Vous avez d√©j√† entendu que les ‚ÄúRH ne sont pas comp√©tents‚Äù et que de nombreux managers ne traitent pas leurs collaborateurs √† ‚Äúleur juste valeur‚Äù ? Nous aussi. Pourtant, les managers et RH ne manquent ni de comp√©tences, ni de volont√©‚Ä¶ Simplement d‚Äôoutils efficaces ! Chez Javelo, nous proposons une plateforme SaaS permettant aux RH de mettre en place des rituels manag√©riaux r√©guliers. Tout √ßa pour quoi ? Pour √©changer un feedback objectif et individualis√©‚Ä¶ Et permettre √† chacun de s‚Äô√©panouir dans un environnement de travail sain ! C‚Äôest √ßa l‚ÄôADN de Javelo : beaucoup de feedbacks et de transparence pour permettre √† chacun d‚Äô√©voluer et atteindre nos objectifs ambitieux ! Le tout dans une entreprise qui a a coeur de maintenir un environnement de travail sain et convivial :) Au sein de l‚Äô√©quipe tech et produit, tu as un r√¥le cl√© dans la valorisation et le partage de la donn√©e business et produit en interne. ‚úî Ô∏èPourquoi nous rejoindre? Tu auras une forte responsabilit√© dans la construction d'une application utilis√©e par des centaines d‚Äôentreprises de 300 √† 20.000 collaborateurs. Tu travailleras au sein d‚Äôune √©quipe √† taille humaine Tu auras une grande autonomie dans le choix de tes approches et outils. Tu rejoindras une √©quipe de passionn√©s qui aiment partager üß¢ Tes missions : Avec de plus en plus de clients utilisateurs de notre application SaaS, nous voulons augmenter notre capacit√© √† √©couter nos utilisateurs en ajoutant une analyse Data de l‚Äôutilisation de notre application. L‚Äôobjectif est de s‚Äôinspirer de nos utilisateurs pour mieux r√©pondre √† leurs attentes. Pour cela, nous souhaitons int√©grer un Data Engineer au sein de notre √©quipe technique. Tu seras en charge des missions suivantes : Concevoir et impl√©menter l‚Äôarchitecture Data de l‚Äôapplication pour assurer un stockage et un acc√®s aux donn√©es pertinents Mettre en place les pipelines d‚Äôanalyse Data Concevoir et int√©grer dans le produit des fonctionnalit√©s Data R√©fl√©chir avec l‚Äô√©quipe produit et l‚Äô√©quipe tech √† la mise en place des bons indicateurs. G√©rer la maintenance technique : s‚Äôassurer que les pipelines et features fonctionnent correctement, tiennent la charge‚Ä¶ Participer √† la vie de l‚Äô√©quipe, √™tre impliqu√© dans l‚Äôam√©lioration de nos process, nos standards et nos outils. La stack Data sort √† peine de terre : il y a tout (ou presque) √† mettre en place de la bonne mani√®re üòâ! üõ†Ô∏è Notre Stack Technique Data Snowflake Airbyte DBT AWS Tableau Google Analytics Backend / Infrastructure Ruby/ RubyOnRails, AWS, ECS, Fargate, Postgres, Elastic, Docker, Github, CircleCI, Datadog Front-end React Webpack, ViteJS Jest, React Testing Library, ESLint, Prettier In-House UIKit, Storybook üéì Ton profil : Comme tu feras partie d'une √©quipe de plusieurs d√©veloppeurs avec des bonnes pratiques d√©j√† mises en place, il te faut √™tre familier avec les m√©thodes agiles et les workflow de travail en √©quipe ( GitFlow, Github flow ou similaire) Tu es dipl√¥m√© d'une √©cole d'ing√©nieur ou d‚Äôune √©cole sp√©cialis√©e en d√©veloppement (type 42) . Tu as une exp√©rience d'au moins 4 ans en tant que Data Engineer. Tu est engag√© √† concevoir, impl√©menter une architecture Data maintenable, testable et document√©e. Tu es autonome et responsable - capable de porter une mission de la conception √† la livraison en communiquant avec les bons interlocuteurs, et t'assurant de la qualit√© de la livraison. Tu es passionn√© et volontaire pour partager ton expertise au sein de l‚Äô√©quipe (sharing, reporting‚Ä¶) Tes Comp√©tences: Tu disposes de comp√©tences/connaissances dans les domaines suivants : Exp√©rience confirm√©e en d√©veloppement de pipelines de donn√©es Solides comp√©tences en SQL et mod√©lisation de bases de donn√©es Bonnes comp√©tences en visualisation de donn√©es Connaissance d‚ÄôAirbyte, DBT, Snowflake ou outils √©quivalents Une comp√©tence en Ruby et Python est un plus. üéØ Si tu souhaites rejoindre une √©quipe dynamique, dans aventure internationale, ta candidature est la bienvenue - m√™me si tu ne coches pas toutes les cases! üéØ Si tu es motiv√© par l‚Äôid√©e de r√©pondre √† un vrai besoin: aider les entreprises √† avoir un suivi plus fin de la performance de leurs collaborateurs et favoriser leur engagement et leur mont√©e en comp√©tence, rejoins-nous! üóÇ Bon √† savoir : Type de contrat - Cadre - CDI üíº R√©mun√©ration entre 40 et 60k üí∏ Bureaux situ√©s au coeur de Paris, situ√©s entre Pigalle et St Georgesüóº Politique de t√©l√©travail flexible üè† Mutuelle Alan Blue ‚ù§Ô∏è‚Äçü©π Carte Swile üç≠ Pass Navigo pris en charge √† 50% üöÖ 34 jours de cong√©s par an üå¥ 1 s√©ance de sophrologie par mois üßò Abonnement √† Mokacare pour prendre soin de toi üíÜ Environnement international üåç Nos offres sont ouvertes aux salari√©(e)s reconnu(e)s travailleurs et travailleuses handicap√©(e)s (RQTH)","Javelo is seeking a Data Engineer with at least 4 years of experience to implement and design a maintainable, testable, and documented data architecture. The ideal candidate should have experience in SQL and data pipeline development, and should be familiar with agile workflows, GitFlow, Github Flow, or similar methods. The candidate should be passionate and willing to share their knowledge with the team. Javelo‚Äôs stack includes Snowflake, Airbyte, DBT, AWS, Tableau, Google Analytics, Ruby, RubyOnRails, React, Webpack, ViteJS, and Jest, among others. Benefits include flexible telecommuting, health insurance, subsidized public transportation, monthly relaxation sessions, and an international work environment.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 4 ans,3,1,0.05539549888311683
400,35712,https://www.welcometothejungle.com/fr/companies/pricehubble/jobs/data-engineer_milan,Data Engineer,PriceHubble,"{GCP,Azure,Kubernetes,PostgreSQL,Airflow,AWS,via,Spark,Docker,SQL,Python}",T√©l√©travail total possible,N,"Logiciels, Immobilier particulier",CDI,2022-09-28,"PriceHubble is a B2B proptech company that develops valuation and analysis solutions for the residential real estate market. To get straight to the point, its solutions allow real estate professionals (investors, developers, banks, real estate agents, brokers, etc.) to evaluate their real estate assets as closely as possible, to advise their individual customers and to offer a digital and personalized experience. Big data and machine learning are at the heart of its model. PriceHubble is already present in 9 countries (Switzerland, France, Germany, Austria, Japan, the Netherlands, Belgium, Czech Republic and Slovakia) and now has more than 130 employees worldwide. Data engineers are the central productive force of PriceHubble. As a mid-level data engineer, your mission will be to improve the data-engineering work in PriceHubble. You will be given the responsibility for parts of our data engineering systems. Your daily challenges will be to add, improve, and maintain a wide range and variety of datasets. Doing so will expose you to a wide variety of tasks ranging from building the infrastructure (Spark on Kubernetes), through generating pipeline to process and expose new data sources, to building machine-learning models extracting features from raw data. Your Mindset You are convinced that success in data science is achieved via data-monopolies. You are highly motivated to join an organization who is committed to building the best in class data-engineering software for acquiring, processing, and enriching real-estate data. The following challenges speak to you: gather vast amounts of data about real estate consolidate, improve, and link this data to generate data sets no one else has on the market do that all over the world You are keen to join a startup right in its growth phase, and are not afraid to refactor code to get it to the new engineering standards that will support the growth of the organisation. At work, your team is your main asset: you are keen to mentor junior team members. In the startup, you are committed to create the company you want to work in; in terms of competence, standards, and mindset. Responsibilities Extract, clean, structure and transform complex raw and processed datasets to extract insights from them Retrieve a wide variety of datasets and integrate them into the data pipeline Create and maintain an efficient data infrastructure Build data enrichment pipelines, using machine-learning when appropriate Continuously provide new ideas to improve our engines and products Requirements MSc in Computer Science or equivalent At least 2 years of experience in a similar position Proficiency in at least one object-oriented programming language and at least one scripting language; Experience in working with Python and its ecosystem In-depth understanding of basic data structures and algorithms Familiarity with software engineering best practices (clean code, code review, test-driven development, ...) and version control systems Advanced knowledge of relational databases and SQL Comfortable working in English; you have a great read, good spoken command of it Nice to haves Experience with the ETL and data processing tools we‚Äôre using is a strong advantage: PySpark, PostgreSQL, Airflow Experience with Docker and Kubernetes orchestration is a strong advantage Working experience with cloud providers (GCP, AWS or Azure) Understanding of core machine learning concepts is an advantage Worked previously in ‚Äòagile‚Äô team(s) and looking forward to doing it again * We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas. Benefits Join an ambitious and hungry team and enjoy the following benefits: üí∞ Competitive salary because we always want to attract the best talents. üìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success. üè¢ Very well-located offices with a great remote work policy and the possibility to work from different places. üïì Flexible working hours and work life balance.","PriceHubble is seeking a mid-level data engineer to improve the data engineering work in the company, which develops valuation and analysis solutions for the residential real estate market. The successful candidate will need at least two years of experience in a similar position, proficiency in at least one object-oriented programming language and one scripting language, advanced knowledge of relational databases and SQL, and experience with software engineering best practices and version control systems. Strong advantages include experience with ETL and data processing tools like PySpark, PostgreSQL, and Airflow, as well as experience with Docker and Kubernetes orchestration and cloud providers like GCP, AWS, or Azure. The successful candidate will be motivated to gather vast amounts of data about real estate and consolidate and improve it to generate data sets that no one else has on the market. They will also work to mentor junior team members and help create a culture of competence, standards, and mindset. PriceHubble offers flexible working hours, a work-life balance, and a learning and development program.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
302,57005,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_VR3jad9,BI Engineer & Data Visualisation,Numberly,"{via,SQL,PowerBI,BigQuery}",T√©l√©travail total possible,"28 rue de Ch√¢teaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-03-26,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception √† la r√©alisation d‚Äôapplications d‚Äôoutils d‚Äôaide √† la d√©cision et monitoring de performance r√©pondant aux probl√©matiques m√©tiers de nos clients. Vous √™tes amen√© √† : Intervenir sur des missions de cadrage et d‚Äôanalyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de r√©pondre aux attentes des clients; Concevoir et r√©aliser les reporting d‚Äôaide √† la d√©cision en apportant une attention aux enjeux de self BI, ainsi que sur l‚ÄôUX/UI Desktop et mobile; D√©ployer des projets de Data Visualisation sous PowerBI en priorit√© mais possiblement en participant aux choix d‚Äôautres outils de restitution; Accompagner les clients dans la bonne compr√©hension et mont√©e en comp√©tence sur l‚Äôexploitation et le maintien des tableaux de bord. Vous assurerez √©galement une veille technologique, et proposerez des solutions standardis√©es, fiables, √©volutives li√©es √† votre activit√©. Chez Numberly, nous partageons une passion pour la transmission : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment gr√¢ce : - aux ‚ÄúJedi Master‚Äù, attribu√©s √† chaque nouvel arrivant- aux Vis ma vie dans des √©quipes diff√©rentes ;- aux Happy Meetings : des rendez-vous mensuels internes pour se retrouver avec toutes nos √©quipes dans le monde et partager l‚Äôactualit√© du groupe. Nous cultivons la libert√© de parole qui permet √† tous de participer au d√©veloppement du groupe. Nous agissons positivement sur notre √©cosyst√®me √† travers 1000mercis impacts et via nos activit√©s qui cr√©ent de la valeur dans l‚ÄôOpen Internet et participent √† l‚Äôenrichissement de l‚ÄôOpen Source. Numberly est acteur de la diversit√© et Gender Equal by design : certification WeConnect International Un gender equity score de 97/100 Numberly est un environnement international avec plus de 30 nationalit√©s dans nos √©quipes. Des bureaux √† l‚Äôimage de chacune des √©quipes, une biblioth√®que g√©n√©reuse, un grand studio de musique tout √©quip√©, deux chats, du tri s√©lectif et du lombricompostage, la possibilit√© de venir avec votre animal de compagnie et de la place pour les v√©los ! Dans chaque cuisine : caf√©, th√©, infusions √† volont√© et aussi des mystery lunchs, des cours de yoga, des cours de sport et des soir√©es (souvent d√©guis√©es). Possibilit√© d'√™tre en remote jusqu'√† 50% de votre temps (√† organiser comme vous le souhaitez) et de travailler jusqu‚Äô√† 60 jours (ouvr√©s) cons√©cutifs en remote. Carte Swile ( titres-restaurants ). Mobilit√© possible dans nos diff√©rents bureaux √† l'international. Numberly accueille les personnes en situation de handicap. Poste disponible √† Paris ou Londres. Vous avez au moins 2 ans d'exp√©rience dans la mise en place de projets datawarehouse et datamart. Vous avez une app√©tence particuli√®re au domaine du Big Data, avec des r√©alisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et comp√©tences sur les technologies suivantes : ETL et SQL. Vous √™tes curieux(se), autonome, force de proposition et avez l‚Äôesprit d'√©quipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont r√©compens√© le travail de Numberly en Europe et aux USA) au sein d‚Äôune √©quipe jeune (27 ans de moyenne d‚Äô√¢ge) et internationale (25 nationalit√©s). Encore mieux si Vous avez de l‚Äôexp√©rience sur PowerBI et/ou BigQuery Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, m√©dia et la relation client.","Numberly is looking for a BI/Reporting Project Manager to design and implement data visualizations and monitoring tools to meet clients' business challenges. The ideal candidate should have a minimum of 2 years of experience in datawarehouse and datamart projects, knowledge of ETL and SQL, and a particular interest in Big Data. The role involves working closely with clients to understand their needs, proposing KPIs, and designing and implementing self BI UX/UI desktop and mobile. The successful candidate will join an agile, innovative and international team of more than 500 people in Paris, London, Dubai, Montreal, and New York. Remote work is possible up to 50% of the time, and mobility across the international offices is an option. Numberly is an advocate for diversity and gender equal by design, with leadership in open source and open internet.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
105,34139,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/senior-android-software-engineer_paris,Android Software Engineer - Mobile Data Collection,Contentsquare,"{Node,Azure,Datadog,React,go,Typescript,Kafka,Flink,Grafana,Golang,Akka,AWS,Contentsquare,Java,regard,color,Scala,Kibana,Spark,ClickHouse,Python}",T√©l√©travail total possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We‚Äôve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we‚Äôre not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! üöÄ Our mission At Contentsquare, all employees share one goal: to help brands create exceptional online experiences with our industry-leading digital experience analytics platform. In the mobile data collection team, we are on a mission to build the industry leading digital experience analytics SDK. With a stellar growth, billions of users , a complex business environment and the need for us to have a very high level of quality, performance and privacy, you‚Äôll find an engaging, rewarding and supportive work environment at Contentsquare. We are looking for developers who understand that development is a team effort, who are proud of a job well done and know how to implement simple and efficient solutions to solve challenging and unique problems. üíª Our stack On the data collection side, our SDK works on native iOS applications (implemented in Swift) and native Android applications (SDK is in Java - converted to Kotlin over time -, Unit Tests and Sample App in Kotlin). We also support various multi-platform frameworks (React Native, Flutter, Capacitor/Ionic, Cordova) with specific bridges. The Tag (implemented in Typescript) that collects data on websites (both desktop and web mobile) is implemented and maintained by the Web Team. Our APIs are mostly designed with our specific constraints in mind. For example, the most data intensive ones use Protocol Buffers . Our backend uses a combination of technologies such as Kafka , Spark, Flink , Akka , ClickHouse and languages such as Scala , Golang, Python , C++. Our monitoring and deployment are handled through Kibana, Grafana , Terraform, Datadog and finally, everything is hosted on AWS and Azure. Our frontend is a micro-frontend SPA developed mainly in Angular / Vue.js and Node.js . üß† Our challenges Our first challenge is to navigate through uncharted territories, native APIs and poorly documented features to make sure we collect all the relevant data we need to compute our insights. In addition we obviously must ensure a very high level of performance (as well as the least impact on user experience), stability and be very mindful about data and CPU consumption. Our rapid growth requires a strong focus on software architecture, code sharing and automation to sustain our delivery capacity while increasing our teams' size. Finally, we are not a tracking company, so collecting PII (Personal Identifiable Information) is an absolute no-go for us and we take it very seriously! ü§ó Skills & Mindset If you have already worked on any kind of software SDK your experience will be of great interest to us. In the same way, if you have notable experience in high performance code, automated non-regression and performance testing, software bridges (between technologies, native and non-native), or if you enjoy testing new technologies or frameworks such as Flutter/Dart, Swift UI, Compose, React Native/Typescript, we would love to hear from you. As a team we are really involved in producing a high quality SDK. We expect our developers to know how to unit test their code, to write easy to read & maintain code and documentation as well as being comfortable doing pair programming with their team members. üèù What we offer An healthy working environment with supportive team members, a place to grow both technically and as an individual Autonomy, responsibilities and opportunities An Engineering Career Path (with clear defined progression steps and opportunities to mentor and be mentored) to make sure you always learn something new Plenty of opportunities for training and development Attractive salary and stock options Flexible working conditions (full remote, 100% in office or any hybrid setup of your choice) A dynamic and multi-cultural company with +50 nationalities Good health insurance Many benefits such as reductions on gym membership and leisure activities While we are offering fully remote opportunities, employees need to be fiscally based in one of our main countries to be hired by one of our office. Please ask your recruiter for more information. - Why you should join Contentsquare - We‚Äôre humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we‚Äôd like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company‚Äôs success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is looking for developers to join its mobile data collection team. The team is responsible for building the industry-leading digital experience analytics software development kit (SDK) for native iOS and Android applications, as well as various multi-platform frameworks. The role requires experience in software development as a team effort, unit testing, and developing simple and efficient solutions to solve challenging and unique problems. The company offers a healthy working environment, autonomy, opportunities for growth and development, flexible working conditions, and a multicultural environment.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
297,56975,https://www.welcometothejungle.com/fr/companies/spikeelabs/jobs/data-engineer-f-h-nice_nice,Data Engineer  Nice,SpikeeLabs,"{MongoDB,Flink,Talend,Scala,PostgreSQL,PowerBI,Kafka,R,Elasticsearch,Hadoop,Hive,Spark,Azure,NoSQL,SQL,Python,Tableau}",T√©l√©travail total possible,"Nice, 06300","Logiciels, IT / Digital",CDI,2023-03-26,"SpikeeLabs est une soci√©t√© d‚Äôing√©nierie, implant√©e √† Paris, Rennes, Nantes et Saint-Malo. Son objectif ? Offrir aux entreprises une expertise en termes de d√©veloppement et d‚Äôint√©gration de solutions au c≈ìur des syst√®mes d‚Äôinformation (SI). Cr√©√©e en 2016, elle se d√©marque aujourd‚Äôhui par : sa focalisation sur les probl√©matiques enfouies et les applications back-office, son approche ¬´ m√©tier ¬ª notamment gr√¢ce √† son expertise reconnue dans les domaines des t√©l√©coms et du transport, sa transparence et ses valeurs, v√©cues et v√©hicul√©es au quotidien par ses salari√©s, son mode de fonctionnement qui favorise les liens, l‚Äôesprit d‚Äô√©quipe, les mont√©es en comp√©tence, les initiatives et la bonne humeur ! Vous connaissez les syst√®mes d‚Äôinformation et la circulation de la donn√©e ? Vous avez un go√ªt prononc√© pour la transformation de donn√©es brutes en information valoris√©e ? Alors venez donc nous rencontrer, vous √©voluerez au sein d‚Äôune toute nouvelle agence √† Nice, accompagn√© par nos √©quipes issues des agences de Paris, Rennes, Nantes et Saint-Malo, dans une ambiance start-up au c≈ìur de Nice ! A propos du poste Au sein de l‚Äôentit√© bas√©e √† Nice, vous interviendrez en tant que Data Engineer sur les donn√©es applicatives des syst√®mes d‚Äôinformation de nos clients ou celles g√©n√©r√©es par notre solution in-house de facturation BillingLabs. Votre poste comportera deux dimensions : ‚Ä¢ Technique : architecture et solutions techniques associ√©es au traitement de la donn√©e ‚Ä¢ Fonctionnelle : capacit√© √† analyser les processus m√©tier du client et les donn√©es associ√©es afin de les valoriser Vos responsabilit√©s ou missions seront principalement : ‚Ä¢ Analyser et documenter les besoins de nos clients en mati√®re de collecte et traitement de la donn√©e ‚Ä¢ Concevoir des solutions techniques permettant la collecte et le traitement de volumes importants de donn√©es (mise en place de pipeline de donn√©es, datalake ‚Ä¶). ‚Ä¢ D√©finir et mettre en ≈ìuvre des processus de validation, correction et nettoyage des donn√©es. ‚Ä¢ Mettre en place des solutions d‚Äôexploitation de ces donn√©es (en particulier des solutions de calcul parall√®le). ‚Ä¢ D√©ployer des solutions de visualisation et pr√©sentation des donn√©es. Et vous ? ‚Ä¢ Vous maitrisez les grands principes d‚Äôun syst√®me d‚Äôinformation, du stockage, de la circulation et la transformation de la donn√©e ‚Ä¢ Vous avez d√©j√† mis en ≈ìuvre ou utiliser les technologies suivantes : o Bases de donn√©es SQL (SQL Server, PostgreSQL) et NoSQL (ex : MongoDB, Elasticsearch‚Ä¶) o Langages de d√©veloppement adapt√©s au traitement de la donn√©e (ex : Python, Scala, R‚Ä¶) o Technologies ‚ÄúBig Data‚Äù (ex : Hadoop, Hive, Spark, Flink‚Ä¶) o Middlewares - ETL, ESB, Message Broker (ex : Talend, Azure Data Factory, Apache Kafka‚Ä¶) o Data visualization (ex : Tableau Software, PowerBI, ELK‚Ä¶) ‚Ä¢ Vous maitrisez l‚Äôanglais technique sur votre p√©rim√®tre ‚Ä¢ Vous avez l‚Äôenvie et vous vous sentez la capacit√© de partager votre savoir au sein d‚Äôune √©quipe pour la faire grandir ‚Ä¢ Vous √™tes pragmatique, proactif et orient√© r√©sultat ‚Ä¢ Et si : o Vous avez d√©j√† port√© la responsabilit√© d‚Äôune migration de donn√©es o Vous avez d√©j√† port√© la mise en place d‚Äôun datalake ou d‚Äôune base BigData Dites-le-nous, ce serait un vrai plus ! Rejoignez-nous ! Notre soci√©t√© SpikeeLabs travaille depuis 2016 aupr√®s de ses clients √† la r√©alisation de technologies centr√©es sur l‚Äôouverture des syst√®mes d‚Äôinformations aux nouvelles applications, notamment les applis digitales. Depuis, SpikeeLabs connait une forte croissance tant en termes de chiffre d‚Äôaffaires que de clients servis. Notre expertise est d√©velopp√©e en mode agile et s‚Äôadresse aujourd‚Äôhui en particulier aux acteurs du monde des t√©l√©coms, du transport mais aussi de la banque ou de l‚Äô√©nergie. L‚Äôentreprise a √©galement d√©velopp√© et commercialise sa propre solution de facturation (BSS). Les bonnes raisons de nous rejoindre : ‚Ä¢ Vous aimerez aller de l‚Äôavant, √™tre efficace et contribuer au d√©veloppement d‚Äôune entreprise qui monte, qui monte‚Ä¶ tout en gardant la t√™te sur les √©paules ! ‚Ä¢ Une id√©e, une intuition, une proposition ? Chez SpikeeLabs, on a confiance en vous, on vous √©coutera et on s‚Äôappuiera sur vous pour aller de l‚Äôavant ! ‚Ä¢ Vous travaillerez dans un esprit empreint de valeurs humaines fortes, v√©cues au quotidien et volontairement ancr√©es par nos fondateurs passionn√©s. Nos agences sont implant√©es sur Paris, Rennes, Nantes, Saint-Malo et Nice. Modalit√©s ‚Ä¢ Prise de poste : d√®s que vous le pouvez, nous vous attendons ! Nous ne recrutons que sur profil ! ‚Ä¢ CDI et statut Cadre (Convention SYNTEC) ‚Ä¢ R√©mun√©ration √† n√©gocier ensemble selon votre profil et vos exp√©riences ‚Ä¢ Avantages : tickets restaurant, 12 jours de RTT, Mutuelle, accord d‚Äôentreprise, int√©ressement, Compte Epargne temps, T√©l√©travail. ‚Ä¢ Lieu : Nice ¬´ Grand Ar√©nas ¬ª En toute simplicit√©, nous sommes disponibles pour r√©pondre √† vos questions si vous en avez. Alors‚Ä¶n‚Äôh√©sitez pas par t√©l√©phone au 02.30.96.21.60 ou par mail √† recrutement@spikeelabs.fr","SpikeeLabs, a Paris-based engineering company, is seeking a Data Engineer in Nice to work on clients' application data and in-house billing solution. The chosen candidate must have experience with data storage, processing, and transformation, as well as SQL and NoSQL databases, data processing languages, and Big Data technologies. The role is both technical and functional, involving the analysis of business processes and data to generate value. The position is a permanent full-time role with benefits such as meal vouchers, RTT days, and telecommuting.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
293,57054,https://www.welcometothejungle.com/fr/companies/follow-health/jobs/data-engineer_rennes,Data Engineer,Follow,"{MySQL,MongoDB,Beam,via,Spark,Docker,PHP,NoSQL,SQL}",T√©l√©travail total possible,"2 Rue de la Mabilais, Rennes, 35000","Logiciels, Sant√©",CDI,2023-03-26,"Construit en collaboration avec des m√©decins et des chirurgiens sp√©cialis√©s, Follow est un logiciel innovant de suivi du dossier patient. En constante √©volution, il propose √† ses utilisateurs une interface ludique, et aide les m√©decins √† optimiser le suivi de leurs patients en les rendant acteurs. De parents m√©decins, Roman Collin a fait na√Ætre l‚Äôid√©e en 2015. Soutenu par des m√©decins, 118 m√©decins investisseurs et le fond de Xavier Niel, le produit √©volue rapidement, l‚Äô√©quipe grandit et triple en un an. Les membres de l‚Äô√©quipe, dont la bonne humeur dicte le quotidien, ont tous le m√™me but : celui de r√©volutionner le suivi patient ! Nous avons actuellement 20 postes ouverts ! Ci-apr√®s une interview de Roman COLLIN, pr√©sident et fondateur de Follow, qui communique notamment sur ces postes pour faire grandir notre √©quipe: https://www.linkedin.com/posts/fwhealth_follow-la-start-up-de-solution-digitale-activity-6993490658019704832-dbb8 La solution Follow offre une nouvelle perspective aux professionels de sant√© ainsi que leurs patients: la garantie d‚Äôune donn√©e accessible, claire, mais qui contribue aussi √† favoriser la s√©curit√© des prescriptions ainsi que les √©changes avec d‚Äôautres confr√®res ou directement les b√©n√©ficiaires de soins. Dans le but de p√©r√©niser la donn√©e chez Follow, nous cr√©ons une √©quipe Data au travers de laquelle tu auras l‚Äôoccasion de rejoindre notre autre Data Engineer. Missions Tes principales missions en tant que Data Engineer seront de : üí™ Travailler √† la robustesse de flux de donn√©es, de la collecte √† la transformation üè≠ Industrialiser les strat√©gies d‚Äôint√©gration de gros volumes de donn√©es üìä Proposer des m√©triques de suivi de notre donn√©e üõ† Contribuer √† l‚Äô√©laboration et l‚Äôoptimisation de notre mod√®le de donn√©es üôã Mettre au point et faire √©voluer un syst√®me de self-extraction de donn√©es √† destination de nos utilisateurs üß™ G√©n√©rer des exports de donn√©es √† destination de recherches m√©dicales L‚Äô√©quipe tech Nous sommes port√©s avant tout sur la collaboration mutuelle pour avancer ensemble autour des sujets fonctionnels et techniques. Voici quelques-unes de nos valeurs : La bienveillance La remise en question et l‚Äôam√©lioration continue La haute technicit√© L‚Äôhumour m√™me dans l‚Äôadversit√© L‚Äô√©quipe tech est aujourd‚Äôhui compos√©e de : ‚öôÔ∏è 3 Backend Developers üñºÔ∏è 2 Frontend Developers üõ†Ô∏è 1 Full Stack Developer üíΩ 3 Data Engineers Perks Vous profiterez entre autres choses de : 7 semaines de cong√©s par an Une mutuelle prise en charge √† 100% par Follow Tickets restaurants via carte Swile Des stock options (BSPCE) Un budget conf√©rence annuel (300‚Ç¨ et un ‚Äújour offert‚Äù) Un acc√®s √† un compte PluralSight Premium Encore plus √† venir ! üì£ Mais nous recrutons aussi un QA Engineer, un Senior Full Stack Developer et un Product Manager, tous sur des cr√©ations de postes! Consultez nos diff√©rentes offres. üòä Tu fais d√©j√† preuve de deux ans d‚Äôexp√©rience dans le Data Engineering, et ton approche pragmatique et exp√©rimentale te permet d‚Äôobtenir rapidement des r√©sultats. Tu as pour vocation de p√©r√©niser la donn√©e, que ce soit lors de son int√©gration jusqu‚Äô√† sa restitution. Tu as a minima les comp√©tences/connaissances suivantes : Apache Spark SQL (MySQL) NoSQL (MongoDB) Google Cloud Platform Docker Aussi, les comp√©tences suivantes seront un plus : Apache Beam Trifacta Dataprep PHP (Symfony) Rencontre avec Yoann, VP of Engineering (45min) Tech, team & culture fit avec l‚Äô√©quipe tech (1h30) Rencontre avec Roman, CEO (30min)","Follow, a patient tracking software, is seeking a Data Engineer to work with their team of developers to create robust data flows, collect and transform data, and propose metrics for data tracking. The ideal candidate will have at least two years of experience in Data Engineering and be proficient in Apache Spark SQL, MySQL, NoSQL, Google Cloud Platform, and Docker. Additionally, experience with Apache Beam, Trifacta Dataprep, and PHP (Symfony) is a plus. Follow offers benefits such as seven weeks of annual leave, 100% covered health insurance, and stock options.",Bac +3,Entre 15 et 50 salari√©s,> 2 ans,3,1,0.05539549888311683
292,56926,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-h-f_brest_THALE_NRKa2Y3,Data Engineer confirm√©(e) ‚Äì,Thales,"{durable,GIT,R,JAVA,Python}",T√©l√©travail total possible,Brest,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES-VOUS ?PROFIL :Vous venez d'√™tre dipl√¥m√©(e) d'un master d'une √©cole d'ing√©nieur et justifiez d'une exp√©rience significative d'environ 2 ans (stages professionnels/stages, projets universitaires ou personnels tels que GIT Hub, Meet Ups, etc.)Vous √™tes d√©brouillard(e), innovant(e) et orient√©(e) solutionsVous avez l'esprit d'√©quipeVous aimez √©galement travailler de mani√®re ind√©pendante et recherchez les responsabilit√©s COMP√âTENCES : Vous √™tes capable de vous adapter et de r√©agir au changement Vous savez et aimez concevoir, d√©velopper et tester des solutions et/ou des composants logiciels s√©curis√©s Vous pouvez d√©montrer votre connaissance des langages et cadres de programmation Full Stack ou pure back/pure front (JAVA, C, C++, Python, ou tout autre) Vous √™tes familier(√®re) avec la compilation/construction de code/int√©gration continue. Vous avez connaissance des plateformes informatiques, des syst√®mes d'exploitation et des hyperviseurs du SI Vous connaissez les principes Agile CE QUE NOUS POUVONS FAIRE ENSEMBLE :En tant que ""Software Solutions Engineering Role"" chez Thales, vous serez amen√©(e) √† : Travailler au sein d'une √©quipe Scrum avec d'autres d√©veloppeurs de logiciels, en mode Agile Contribuer √† la d√©finition des besoins, √† la conception du logiciel et √™tre impliqu√©(e) dans les aspects architecturaux des projets logiciels Int√©grer les composants logiciels dans un syst√®me logiciel enti√®rement fonctionnel Ecrire un code bien con√ßu, document√© et testable D√©velopper, tester et ex√©cuter le cycle de vie complet du d√©veloppement logiciel Concevoir, mettre en ≈ìuvre et tester des fonctionnalit√©s en tenant compte de l'√©volutivit√©, des performances, du d√©ploiement/de l'exploitation et de l'exp√©rience de l'utilisateur(ice) final(e). Faire des estimations et contribuer √† la planification avec les membres de l'√©quipe Collaborer avec d'autres ing√©nieur(e)s en solutions logicielles afin de partager les connaissances et d'am√©liorer le produit/solution dans son ensemble.VOTRE CARRI√àRE CHEZ THALESDiff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines :Explorez un espace attentif au d√©veloppement personnelD√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexeChoisissez entre une expertise technique ou un parcours de leadershipConstruisez une carri√®re internationale au sein d'un groupe d'ing√©nierie de premier plan. Le poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d‚Äôhabilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l‚ÄôIGI 1300 SGDSN/PSE du 09 ao√ªt 2021. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales seeks a Software Solutions Engineering Role, who needs to be a newly graduated engineer with significant experience of around 2 years. The candidate must be able to develop full-stack solutions, compile/construct code, integrate continuous design, have knowledge about programming languages like JAVA, C, C++, Python, etc. and work in a team under Agile principles. The position requires the ability to uncover secrets for the national defense and perform national defense habilitation procedures under Code de la defense and IGI 1300 SGDSN/PSE.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
168,56663,https://www.welcometothejungle.com/fr/companies/reech/jobs/data-engineer-h-f_rennes,Data Engineer,Reech,"{ElasticSearch,Solr,AWS,Kafka,Hadoop,Spark,RabbitMQ,NoSQL,SQL}",T√©l√©travail total possible,"61 rue Jean Gu√©henno, Rennes, 35000","SaaS / Cloud Services, Marketing / Communication, AdTech  / MarTech",CDI,2023-03-26,"Cr√©√©e en 2015 par Guillaume et Maxime DOKI-THONON, Reech est une entreprise experte du Marketing d‚ÄôInfluence . Gr√¢ce √† sa technologie propri√©taire permettant d‚Äôidentifier et de qualifier les bons influenceurs (parmi 7 millions !), coupl√©e √† l‚Äôexpertise de ses 50 collaborateurs, Reech construit l‚Äô√©cosyst√®me d‚Äôinfluence des marques qu‚Äôelle accompagne, telles que Coca-Cola, Carrefour, Spontex, Philips, Groupe Galeries Lafayette, Yves Rocher, autour de deux offres : Avec Reech Agency , le c≈ìur de m√©tier de Reech est d‚Äôaccompagner de A √† Z les marques dans leur strat√©gie d‚Äôinfluence, et ce depuis 2015. Avec son offre technologique lanc√©e en 2020, Reech Influence Cloud , Reech permet aux marques et aux agences d‚Äôutiliser une solution SaaS modulaire bas√©e sur la donn√©e et l‚ÄôIA, facilitant l‚Äôactivation, l‚Äôanalyse et l‚Äôamplification de l‚ÄôInfluence. Qu‚Äôelles souhaitent un accompagnement cl√© en main, un socle technologique leur permettant d‚Äôinternaliser l‚Äôinfluence ou un entre-deux, gr√¢ce √† ses diff√©rentes offres, Reech est d√©sormais le seul acteur qui permet aux marques de placer le curseur d‚Äôun accompagnement en Influence Marketing sur une infinit√© de positions. üí™ VOS RESPONSABILIT√âS : √Ä Rennes, au sein d‚Äôune √©quipe Agile au top, tes missions seront : √âtudier, concevoir et impl√©menter l‚Äôarchitecture pour la collecte, le stockage et l‚Äôexploitation des donn√©es Garantir la disponibilit√© des bases de donn√©es pour une exploitation optimale par l‚Äôensemble des √©quipes Assurer et surveiller l‚Äôautomatisation des mises √† jour des donn√©es depuis le sourcing √† la g√©n√©ration d‚Äôentit√©s et d‚Äôattributs üå± ENVIRONNEMENT : Reech est fier d‚Äôavoir √©t√© √©lu entreprise o√π il fait bon vivre , avec un premier prix venant r√©compenser sa culture d‚Äôentreprise et manag√©riale ‚ô° L‚Äô√©quipe : Tech, rattach√©e au CTO et co-fondateur, Maxime DOKI-THONON Locaux : dans le centre de Rennes, 61 Rue Jean Gu√©henno T√©l√©travail : 2 jours par semaine √† partir de 3 mois d‚Äôanciennet√© Avantages : mutuelle Alan et carte Swile pour le d√©jeuner Tu poss√®des 1 an d‚Äôexp√©rience minimum. Tu as de bonnes connaissances des technos big data (ElasticSearch ou Solr, Hadoop/Spark, etc.) et des bases de donn√©es (SQL et NoSQL). Tu es affut√© sur le service bus (RabbitMQ, Kafka, ‚Ä¶) et orient√© micro-services, CI/CD et scalabilit√©. Tu es √† l‚Äôaise avec l‚Äôanglais technique. Tu es bon communiquant, capable de pitcher un chantier technique important. Curieux et rigoureux, tu es en veille techno permanente. Les + Tu as d√©j√† travaill√© sur la partie infra (AWS, OVH, Terraform, ‚Ä¶). Tu as d√©j√† travaill√© dans un contexte Agile (Scrum). Tu es int√©ress√© par le machine learning, data-science la data visualisation.","Reech, a marketing agency specializing in influencer marketing, is seeking a Data Engineer in Rennes. The role entails designing and implementing an architecture for data collection, storage, and exploitation and ensuring the availability of databases for optimal use by all teams. The ideal candidate should have at least one year of big-data technos experience, familiarity with service bus, and excellent communication skills. The agency offers telecommuting two days a week, healthcare benefits, and an on-site culture that has earned awards for employee satisfaction.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
363,50452,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote-germany_berlin,Software Engineer Data Presentation - Remote Germany,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",T√©l√©travail total possible,Berlin,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer to develop usable and intuitive software interfaces and scalable engines for its platform. The ideal candidate should have experience in software development, be customer-oriented, and have experience with either frontend and backend development or mastery of frontend coding with no fear of diving into backend coding. They should also have firsthand experience building products and a keen eye for design. The environment at Dataiku is flexible and autonomous, with a culture that encourages learning and collaboration. Dataiku is committed to diversity, equal opportunity, and fair treatment of all employees.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
110,73013,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/dataops-engineer-data-solutions-factory-f-m-d_paris,DataOps Engineer - Data Solutions Factory,Decathlon Digital,"{GCS,Github,Linux,DynamoDB,Jupyter,Kafka,Dataflow,Hive,Kinesis,Redshift,Hbase,Jenkins,Superset,Tableau,Airflow,AWS,YARN,Talend,Datastudio,Druid,BigQuery,Elasticsearch,PostgreSQL,Spark,S3,Sagemaker,Prisma,Hadoop,Kubernetes,NoSQL,EMR,GCP}",T√©l√©travail total possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOINS L'EQUIPE DATAOPS DE LA DATA SOLUTIONS FACTORY DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Au sein de la BU Data, l ‚Äô√©quipe DataOPS innove tous les jours pour r√©pondre au mieux aux besoins de notre data platform . Nos enjeux sont : Une plateforme data enti√®rement multi-cloud (AWS & GCP) De la haute disponibilit√©, avec une plateforme r√©siliente et des technologies innovantes La s√©curit√© au coeur de nos projets Les besoins de nos data scientist, data engineers data analystes, et d√©veloppeurs traduits en solutions techniques Compos√©e d‚Äôune 15aine d‚Äôexperts, l‚Äô√©quipe DataOPS t‚Äôattends pour apporter ta contribution √† ce grand enjeu qu‚Äôest la Data. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e DataOPS Engineer, bas√©-e, au choix √† Lille ou Paris (si tu es localis√©.e hors de la r√©gion lilloise, pr√©voir une d√©placement sur Lille √† un rythme d'1 journ√©e / par semaine ou 2 jours tous les 15 jours). TES RESPONSABILITES Expert.e dans ton domaine, tu con√ßois, d√©ploies et maintiens les offres techniques pour l‚Äôensemble des infrastructures de la BU Data, tout en suivant les strat√©gies techniques de l‚Äôentreprise (excellence op√©rationnelle, full cloud, full automatisation, s√©curit√©). Tu participes et contribues aux strat√©gies techniques de l‚Äôentreprise au sein de la communaut√© OPS . En tant que r√©f√©rent.e sur les technologies que tu g√®res, tu partages et fais grandir tes coll√®gues Tu participes au processus de support, en prenant en charge avec l‚Äô√©quipe les demandes, incidents et probl√®mes en escalade sur ton p√©rim√®tre d‚Äôexpertise Tu contribues √† la transformation du SI Tu accompagnes les changements strat√©giques li√©s √† l‚Äôinfrastructure Tu aides au recrutement de profils OPS externes, tu les formes et les animes. Le p√©rim√®tre technique : Un environnement full cloud (AWS-GCP) compl√®tement infra-as-code (Terraform, Ansible) ; Une plateforme Kubernetes, avec full CI/CD (Flux, Jenkins, Github Action‚Ä¶), haute disponibilit√©, haute s√©curit√© (Prisma,...) ; Une infrastructure d'√©change de donn√©es, en pleine √©volution pour √™tre 100% industrialisable, avec de multiples technologies : Kafka, Talend, Airflow, Kinesis, Dataflow... Une infrastructure DataViz : QlikSense, Superset, Quicksight, Datastudio, Tableau ; De multiples technologies de stockage : S3, Redshift, PostgreSQL, GCS, BigQuery ; Une plateforme Hadoop : EMR, Hive, Spark, YARN, Ranger, Atlas ; Des bases de donn√©es NoSQL : Elasticsearch, Druid, DynamoDB, Hbase ; De multiples environnements de d√©veloppements Data : Github, Jupyter, RStudio, Sagemaker ; Une grande communaut√© OPS tr√®s soud√©e, qui partage les bonnes pratiques, construit des process communs, etc. CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as au moins 2 ans en tant qu'OPS sur Linux, conteneurisation, monitoring, CI/CD, automatisation & industrialisation ET en environnement Cloud (AWS fortement appr√©ci√©) Tu as une app√©tence pour la data (Spark, Airflow, Sagemaker, BigQuery), et la gestion de bases de donn√©es relationnelles et NoSQL ; Tu aimes √©voluer en contexte Agile et tu as envie de travailler dans un environnement international (anglais technique ma√Ætris√©). Tu es f orce de propositions, et aimes le challenge ! Passionn√©¬∑e de technique et de s√©curit√©, la veille technologique sera une part importante de ton activit√© ; Rejoindre une entreprise qui rend accessible au plus grand nombre le plaisir et les bienfaits du sport fait sens pour toi et tu as envie de partager tes passions en √©quipe ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .",,Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
142,72447,https://www.welcometothejungle.com/fr/companies/shine/jobs/lead-data-engineer_paris,Lead Data Engineer,Shine,"{Beam,Metabase,grid,scale,BigQuery,GCP,Python}",T√©l√©travail total possible,"Paris, 75001","Application mobile, FinTech / InsurTech",CDI,2023-04-08,"Shine simplifie le quotidien des ind√©pendant¬∑es et petites entreprises pour leur permettre de se concentrer sur ce qui compte vraiment : leur r√©ussite. ‚ú® C‚Äôest un compte pro responsable , qui propose des services en ligne et un v√©ritable copilote administratif . Shine simplifie l‚Äôexp√©rience bancaire et administrative des ind√©pendant¬∑es, gr√¢ce √† un √©quilibre entre service en ligne et accompagnement humain. Les entrepreneur¬∑es peuvent se reposer sur une √©quipe d‚Äôexpert¬∑es disponibles sept jours sur sept pour r√©pondre √† toutes leurs interrogations administratives et sur une application et des fonctionnalit√©s innovantes: un compte pro 100% en ligne, avec une application simple et intuitive, pour g√©rer leur activit√© un copilote administratif, pour les accompagner de la cr√©ation de leur entreprise √† la gestion quotidienne des assurances in√©dites, pour prot√©ger l‚Äôactivit√© des ind√©pendant¬∑es Au del√† de cette mission, Shine en tant qu‚Äôentreprise aspire √† avoir un impact social et √©cologique positif . La startup a √† c≈ìur de favoriser la diversit√© et l‚Äôinclusion au sein de ses √©quipes et de sa communaut√©. Elle est √©galement labellis√©e B Corp. Enfin, Shine fait partie du mouvement 1% pour la plan√®te et reverse 1% de son chiffre d‚Äôaffaires annuel √† des associations environnementales. Lanc√© en 2018, Shine a lev√© 10,8 millions d‚Äôeuros aupr√®s de Daphni, Kima Ventures, XAnge et plusieurs business angels. La startup a rejoint en 2020 la Soci√©t√© G√©n√©rale et acc√©l√®re son d√©veloppement tout en restant une structure ind√©pendante. Rejoindre Shine aujourd‚Äôhui, c‚Äôest faire partie d‚Äôune √©quipe internationale de 130 personnes passionn√©es qui travaillent en remote ou dans leurs bureaux dans le centre de Paris. C‚Äôest aussi aider 100 000 entrepreneur¬∑es et prendre part √† leur croissance pour impacter des millions de personnes ! Shine‚Äôs engineering team Data engineering at Shine is about designing efficient data pipelines and backend development. We build the most reliable data architecture to insure the best collect, analysis and data visualisation possible - it goes without saying that data team play an essential role for Shine ! Our squad is made of 4 Data Engineers, 1 scientists, 5 analysts and a head of data to insure top synchronisation with our product and or business ‚ú® Regarding our stack we are using : Python , GCP , BigQuery , App engine , Pub/Sub , Beam , Mode , Metabase , Data studio & Segment Joining as a Lead Data Engineer means üëã Hiring, mentoring and leading a 4 Data engineers team ( Reshma , Patrice , Timoth√© , Romain ) Lead billions of data in an efficient & ethical way Developing strong data pipelines for 100K+ users Creating a reliable and consistent code to insure our technical scale Having a strong impact on our data architecture by proposing new implementations It's a match if ü§ù You have a strong experience (5+ years) in Data engineering You are proficient and comfortable with Python, writing production-ready code, testing and monitoring You have experience in managing or leading a team You already worked in a cloud environnement (not necessarily GCP) You are also interested about Data science / Data analysis and operational subjects You give a lot of attention to details in your work You stick to Shine‚Äôs values üíõ You can communicate clearly in English (our data team is international!) Working at Shine is joining a fast paced scale-up, a useful and UX driven product but not only‚Ä¶ Before anything else, it‚Äôs being a part of a great human experience in a company driven by amazing values toward people and ecological matters We do believe that caring is not only about giving autonomy, responsibility and encouraging proactivity. That‚Äôs why we offer: üí∞ A fair and transparent salary grid - Level D to E (70K‚Ç¨ to 85K‚Ç¨) for this job ( More informations ) üè† A flexible and remote-friendly environnement. From France and Europe! üè¢ A brand new and stunning office in Paris - Also a nice corner in Station F üñ•Ô∏è Everything you need to work in perfect conditions (Co-working space, furniture, monitors, mouse, etc.) And a lot more ! Feel free to ask to Anna√Øg during your first call. But also üë©‚Äçüíª 1 freelancing day / month. The perfect occasion to put yourself in a Shine‚Äôs user‚Äôs shoes (Shine premium is offered to help ofc) üë™ A second parent leave extended to 8 weeks + 3 days of parental leave for sick child üíö Healthcare program 100% covered by Shine for you and your family üé∂ Culture budget : 275‚Ç¨/ year to buy books or listen to music (Spotify, Deezer ‚Ä¶) ü§∏ Sport pack: 300‚Ç¨ per year to subscribe to gym, participate in sport competitions ‚Ä¶ Take care of yourself! üö¥‚Äç‚ôÇÔ∏è Bike + transport : Refund of your fees, on jump seats like on bike paths! ‚òÄÔ∏è 35 days of holidays for everyone! üèù 1% salary bonus in June to enjoy your Holiday You wonder about our hiring process ? 1Ô∏è‚É£ A 30‚Äô first call with Anna√Øg, our data talent acquisition specialist, to get to know each other and tell you more about Shine. 2Ô∏è‚É£ A 60‚Äô interview about your data experiences with Nicolas , our Head of data 3Ô∏è‚É£ A a 45‚Äô case study with Reshma and Timoth√© + a 45‚Äô cultural interview to give you more context about Shine‚Äôs values. 4Ô∏è‚É£ An immersion day for you to understand Shine‚Äôs culture, meet the team and introduce our data engineering with some reflectional exercices.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
459,56439,https://www.welcometothejungle.com/fr/companies/free2move/jobs/data-engineer-h-f_paris,Data Engineer,Free2move,"{Gitlab,Airflow,PostgreSQL,AWS,S3,dbt,Snowflake,Lambda,SQL,Python,EC2,Tableau}",T√©l√©travail total possible,"45, Rue de la Chauss√©e-d'Antin, Paris, 75009","Mobilit√©, √âconomie collaborative, Tourisme",CDI,2023-03-26,"Cr√©√©e en 2016, Free2Move üöÄ simplifie les usages li√©s √† la mobilit√© en proposant une large offre de services pour satisfaire les besoins de üöò d√©placement de tous. Avec Free2Move, vous pouvez louer un v√©hicule pour faire une course ou une citadine pour votre s√©jour en Italie üèñÔ∏è, r√©server un parking durant votre week-end √† Paris‚Ä¶ le tout en un clic, sur notre plateforme web/mobile ! üì≤ N√©e du rapprochement du Groupe Stellantis üöó et de la start-up TravelCar, Free2Move, gr√¢ce √† son agilit√© et √† son esprit de conqu√™te a r√©ussi √† s‚Äôimposer en √† peine 6 ans üöÄ comme un acteur de r√©f√©rence pour r√©volutionner la mobilit√© de tous les voyageurs. Devenu le r√©flexe #1 pour plus de 6 millions d‚Äôutilisateurs üëë, Free2Move op√®re dans plus de 170 pays √† travers les 5 continents üåé et est disponible en 30 langues et 26 devises. 5000 partenaires nous font confiance et plusieurs centaines de milliers de v√©hicules sont disponibles ! Si vous souhaitez rejoindre une √©quipe de +250üèÜ experts et des projets internationaux audacieux, alors vous √™tes au bon endroit ! üéØ Vous √©voluerez dans une structure ultra-dynamique, innovante, agile, tourn√©e vers l‚Äôinternational et int√©grerez nos talentueuses ‚ù§Ô∏è√©quipes‚ô•Ô∏è, pleines d‚Äôid√©es et de motivation et aux comp√©tences pluridisciplinaires, √† la crois√©e de l‚Äô√©co-syst√®me digital et du secteur de l‚Äôautomobile, en pleine mutation. üí∫ REJOIGNEZ-NOUS ! üíØ C‚Äôest passionnant, vous verrezüî•! Your next missions : We have a great new opportunity for a Data Engineer to join our Data Team. He / She will join the Data department composed of 26 people divided into 5 teams. As part of the SHARE NOW Data Warehouse Team, you are in charge of the end-to-end development of our Data Warehouse and Business Intelligence solutions. You will be in constant knowledge exchange with all team members and always taking on new challenges. As part of the job, you will have the opportunity to continually expand your technical and methodical expertise as well as strengthen your business sense. More specifically, you will be responsible for : You work as part of the team on the conception, design, implementation, optimization and technical management of our Data Warehouse and Business Intelligence solutions. You implement ETL processes to integrate and enrich data from different sources like Amazon S3, PostgreSQL or REST API. You design and implement relational and multidimensional database systems as well as different types of reports and dashboards according to the business requirements. You develop our Business Intelligence solution using a modern tech stack (Snowflake, dbt, Airflow, Gitlab CI/CD and other Amazon Web Services). You identify potentials both with respect to architecture and the technologies used. You are in exchange with different business departments to support them in their data needs. Expected skills: üîß You have successfully completed your master‚Äôs degree in Computer science or a related field. üîß You are passionate about creating a well architected modern data infrastructure and working on projects with business impact. üîß Expert in SQL and/or SQL-based languages and performance tuning of SQL queries. Some hands-on experience in Python is good to have. üîß You have knowledge in the technologies we use, especially AWS (e.g. S3, Lambda, EC2) and Snowflake, ideally also Airflow and dbt. üîß You are comfortable with CI/CD pipelines and DevOps workflows. üîß You ideally have several years of experience in developing and maintaining complex Data Warehouse solutions. üîß You ideally bring first experience in Tableau and visualizing complex data üîß Your strengths include an analytical mind and an affinity towards data and facts üîß You have a strong command of English (spoken and written). üîß You enjoy working in a dynamic environment and are known for working in an effective, efficient and motivated manner. What we offer: Working at Free2Move means becoming part of a tribe in which the culture of performance rhymes with a good atmosphere. It is also: A start-up spirit supported by a large Group ü•á Depending on your mission, a possibility to work in full remote wherever you are, in hybrid or within our different offices! ‚õµÔ∏è The opportunity to revolutionize the uses of mobility with us! üöò A neat integration to start well üéÅ Lots of possibilities for development üìà Collaboration with multidisciplinary and international teams üí™üèº International projects to perfect your background! üåç An attractive salary üí∏ A Swile card to enjoy all the restaurants around you! üçù A mutual insurance financed at 60% and a providence in case of hard times financed at 100%! An access to our E-Learning platform üìö : for the development of languages and other skills Table football battles to relax ‚öΩÔ∏è ...This list is not exhaustive... Job type: - CDI OR PERM OR within the head office in the heart of the 9th district in Paris - To be filled asap üëÄ *Psst...! On vous file une combine :) Postulez, de pr√©f√©rence, en anglais üá∫üá≤","Free2Move, a mobility services company, is seeking a Data Engineer to join its data team. The team member will be responsible for end-to-end development of the company's data warehouse and business intelligence solutions, including implementing ETL processes, designing and implementing database systems, developing BI solutions using modern tech stack, and identifying potential areas for architecture and technology improvements. The ideal candidate will have a master's degree in computer science or a related field, expertise in SQL and/or SQL-based languages, knowledge of AWS, Snowflake, Airflow, and dbt, and experience in developing and maintaining complex data warehouse solutions. Free2Move offers competitive compensation, career development opportunities, and a dynamic work environment.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
197,56785,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-business-intelligence-f-h_rennes,Data Engineer,Micropole,"{Microsoft,durable,Talend,SAP,Informatica,AWS,R,GCP,SQL,Qlik,Tableau}",T√©l√©travail total possible,"14 Rue du Patis Tatelin, Rennes, 35700",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√©‚ÄØ: Data Engineer F/H Localit√© : Rennes Type de contrat : CDI Niveau d‚Äôexp√©rience‚ÄØminimum : 2 ans Vous souhaitez rejoindre une entreprise pionni√®re des grandes innovations data et digitales, au sein d‚Äôune agence √† taille humaine o√π r√®gnent entraide et convivialit√©, engag√©e en faveur d‚Äôun num√©rique plus responsable au service de clients principalement implant√©s r√©gionalement ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur gr√¢ce √† la puissance du Cloud ? Rejoignez Micropole ! Dans vos missions quotidiennes , vous serez amen√©(e) √† : Participer aux recueil du besoin aupr√®s des Directions M√©tiers ; R√©diger les dossiers de conception technique ; Intervenir sur toute la cha√Æne de valeur de la donn√©e : extraction, mod√©lisation & dataviz ; Pr√©parer et d√©rouler les tests ; Accompagner la ma√Ætrise d‚Äôouvrage dans la validation de livrables, l‚Äôassistance √† la recette et la conduite du changement sur le projet ; Capitaliser et partager les bonnes pratiques, connaissances et retours d‚Äôexp√©rience au sein de nos communaut√©s. Vos comp√©tences techniques : Vous ma√Ætrisez parfaitement au moins un ETL du march√© (Informatica, Talend, Big Query, Data Factory, etc) et la cr√©ation de tableaux de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI...) id√©alement dans un environnement Cloud ; SQL n‚Äôa plus de secrets pour vous. Vos atouts : Vous √™tes dipl√¥m√©(e) d‚Äôune formation sup√©rieure en Informatique parcours Donn√©es ; Vous poss√©dez une exp√©rience d'au moins 2 ans dans la fonction ; Votre esprit d‚Äôanalyse, de synth√®se, votre organisation et vos capacit√©s r√©dactionnelles sont souvent reconnus ; Vous appr√©ciez travailler en √©quipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C‚ÄôEST‚ÄØ: - Int√©grer une communaut√© de 1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. - Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud‚ÄØ: AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. - S‚Äôassurer d‚Äôune innovation continue gr√¢ce √†‚ÄØ: Notre √©cosyst√®me de partenaires technologiques Notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR Nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C‚ÄôEST‚ÄØ: Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole‚ÄØ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles‚ÄØ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion‚ÄØ; La participation √† des projets internes sur la base du volontariat. PROCESSUS DE RECRUTEMENT‚ÄØ: Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì Si votre profil correspond √† nos attentes, vous √™tes recontact√©(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist en R√©gion pour un premier √©change t√©l√©phonique‚ÄØ; Etape 2 ‚Äì Un premier entretien est programm√© avec l‚Äôun d‚Äôentre eux sur site ou √† distance Etape 3 ‚Äì Vous rencontrez St√©phanie ou Camille les manager de l‚Äô√©quipe Data de l‚ÄôOuest pour un second entretien En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en savoir plus‚ÄØ: https://www.linkedin.com/company/micropole/mycompany/ MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un d√©veloppement rapide sur le Data, le Digital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur du Groupe. Pr√©sent au plus pr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs du d√©veloppement √©conomique, nous accompagnons nos clients des secteurs de l‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et du public dans leur transformation data et digitale, notamment au travers de m√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ. L‚Äôagence Grand Ouest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit et met en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôun num√©rique responsable au sein des organisations #LI-CB1 Comp√©tences Talend QlikSense","Micropole seeks a Data Engineer with at least 2 years of experience in the field, to join their team in Rennes. The ideal candidate should possess expertise in at least one ETL tool and experience creating data visualizations with tools such as Power BI, Tableau or Spotfire. They will work with the team to assist clients with data-driven transformation and responsible cloud-based solutions. Micropole encourages a team-oriented approach and offers a range of training opportunities for continuous growth.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
41,73121,https://www.welcometothejungle.com/fr/companies/weefin/jobs/lead-data_paris,Lead Data Engineer,WeeFin,"{Github,Python,Node,Linux,Pandas,durable,scale,PostgreSQL,Bash,NoSQL,AWS,SQL}",T√©l√©travail total possible,"71, Rue du Faubourg Saint-Martin, Paris, 75010","Strat√©gie, Transformation, FinTech / InsurTech",CDI,2023-04-22,"Weefin est une startup √† impact dont le but est de d√©mocratiser la finance durable. Nous construisons ESG Connect, le produit WeeFin, se positionnant au coeur de l‚Äôanalyse extra-financi√®re : entre les fournisseurs de donn√©es ESG (Environnement, Social et Gouvernance des entreprises) et les institutions financi√®res (nos clients). Notre produit leur permet de noter les entreprises dans lesquelles elles investissent pour mesurer l‚Äôimpact de leurs investissement sur l‚Äôenvironnement et la soci√©t√©. ESG Connect a pour vocation de faciliter la validation, l‚Äôexploitation et l‚Äôenrichissement des donn√©es fournisseurs dans le contexte particulier de chacun de nos clients. Ce qui nous conduit √† mettre en place des pipelines data, des m√©canismes de notification, une librairie de calculs configurables par les utilisateurs‚Ä¶ Nos challenges : Normaliser les donn√©es provenant des diff√©rents fournisseurs Proposer des moyens innovants de pr√©senter la donn√©e normalis√©e, sa qualit√© et les r√©sultats des calculs aux diff√©rents m√©tiers gravitant autour du produit G√©rer la donn√©e et les r√©sultats dans le temps pour satisfaire des besoins de simulation, d‚Äôaudit‚Ä¶ Notre stack : Cloud provider : AWS, principalement du serverless Infra As Code : Terraform/Terragrunt CI/CD : Github Scripting : Python, Bash Front : Node, Vue3, Cypress OS : Linux Bases de donn√©es : SQL et NoSQL Depuis notre lev√©e de fonds, WeeFin est entr√©e en phase de scale et recherche de nouveaux profils pour renforcer l‚Äô√©quipe Tech ! Au sein de l‚Äô√©quipe Tech, les missions du/de la lead data sont les suivantes : Participer au d√©veloppement de notre plateforme : am√©lioration de nos processus de d√©veloppement ; am√©lioration de notre architecture data ; Choisir et benchmarker de nouvelles technos data (PolarRS, Pandas 2.0) ; Participer √† l‚Äô√©laboration de la roadmap technique ; Comprendre et int√©grer les sp√©cifications fonctionnelles ; Participer √† la mont√©e en comp√©tences de l‚Äô√©quipe : partager les bonnes pratiques et retours d‚Äôexp√©rience, faire des feedbacks‚Ä¶ Vous avez de l‚Äôexp√©rience avec des moteurs de calcul Vous ma√Ætrisez Python, PostgreSQL et avez d√©j√† travaill√© avec Pandas Vous √™tes pr√™t.e √† travailler sur l‚Äô√©volution de l‚Äôarchitecture en gardant du temps pour la production en continu",,Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
258,56824,https://www.welcometothejungle.com/fr/companies/yousign/jobs/data-engineer-h-f-x_paris,Data Engineer /X),YOUSIGN,"{Typescript,Airflow,Kubernetes,Uber,dbt,scale,Dagster,Docker,PHP,SQL,Python}",T√©l√©travail total possible,"4, Rue Royale, Paris, 75008",SaaS / Cloud Services,CDI,2023-03-26,"At Yousign, we are reinventing the electronic signature experience with a fast, legal, secure and 100% European SaaS solution. üñä‚ö° Founded in 2013 by Luc Pallavidino and Antoine Louiset in Caen, our scale-up is now present in France üá´üá∑, Italy üáÆüáπ and Germany üá©üá™ ! Our goal? To become the European leader in electronic signatures by enabling freelancers and SMBs, to simplify their workflows. ü§∏‚ôÄÔ∏è üöÄ In order to achieve this‚Ä¶ 2019: we integrated into the eFounders, one of the best SaaS start-up studios in Europe, 2021: we raised 30 million euros from the eFounders and Lead Edge Capital, famous for having invested in BlaBlaCar, Asana, Zoom, Spotify and Uber. We offer two e-signature solutions: a web app, ready to use and accessible from anywhere, an API (Application Program Interface), which can be easily integrated into business softwares At this time, Yousign is : more than 200 yousigners in our offices in Paris and Caen, or in full-remote (+40% are working remotely) üë¶ üíª more than 12,000 customers who trust us on a daily basis ü§ù over 4 million signatures every month üîù An impressive annual growth rate, which makes us the most successful e-signature scale-up in Europe üá™üá∫ Ton √©quipe Tu rejoindras l'√©quipe Data compos√©e de 5 Analystes et 2 Data Engineer, et rattach√©e √† Product & Engineering. La Team Product & Engineering est le coeur de Yousign et c‚Äôest l‚Äô√©quipe la plus grande de la soci√©t√©. Nous sommes actuellement en pleine croissance et cherchons des talents exp√©riment√©s pour rejoindre cette aventure. Ton r√¥le La squad Data Engineering - au sein de l'√©quipe data - de Yousign est en charge de la construction et de la maintenance de la Data Platform. Tu seras donc un des garants de cette Data Platform, en charge de son d√©veloppement et de son am√©lioration continue pour accompagner Yousign dans ses besoins croissants ! Tu partageras aussi ton expertise technique avec les autres membres de l'√©quipe data pour les aider √† monter en comp√©tence et √† r√©pondre aux besoins des √©quipes m√©tier. Tu participeras aussi plus globalement √† l'√©vang√©lisation de la data au sein de Yousign. Missions Les principales missions sont les suivantes : D√©velopper et maintenir l‚Äôinfrastructure Data de Yousign Mettre √† disposition les donn√©es pour les utilisateurs internes et externes Participer aux choix technique de l‚Äô√©quipe Data et conseiller les data analystes Construire des pipelines de Data s√©curis√©s, fiables et robustes reposant sur Apache Airflow et dbt Participer √† l‚Äôadministration de notre Data Platform Participer √† l'√©vang√©lisation de la Data pour nos employ√©s et √† l‚Äôam√©lioration de notre maturit√© Data chez Yousign L'√©quipe Product & Engineering de Yousign Le r√¥le de l‚Äô√©quipe Product & Engineering de Yousign est de concevoir, faire √©voluer et maintenir l‚Äôensemble des fonctionnalit√©s de notre produit ainsi que les outils permettant son bon fonctionnement. Elle est compos√©e d‚Äôune cinquantaine de personnes : Des d√©veloppeur‚Ä¢ses front (JS/ReactJS/Typescript) Des d√©veloppeurs‚Ä¢ses back (PHP/Symfony) Des SRE Des Product managers et des Product designers Des Data Engineers et Data Analysts Une √©quipe IT, S√©curit√© et Conformit√© Profil recherch√© Tu es passionn√©.e par la Data, avec au moins 3 ann√©es d‚Äôexp√©riences comme Data Engineer (H/F/X) Tu as d√©j√† mis en place un ELT Tu as d√©j√† travaill√© avec un orchestrateur comme Airflow, Dagster, etc. Tu ma√Ætrises Python et SQL Tu as d√©j√† utilis√© Docker et tu as une app√©tence pour les sujets DevOps Tu as l'esprit d'√©quipe et tu es √† l'√©coute Tu as la volont√© d'apprendre, de progresser et de t'adapter rapidement √† notre environnement technique Les + Tu ma√Ætrises Airflow et dbt Tu as d√©j√† contribu√© au d√©veloppement d'API Tu as d√©j√† utilis√© Kubernetes Tu as une exp√©rience sur le suivi des Data d‚Äôun produit Ce que tu trouveras chez Yousign : Une scale up qui place le Produit et la Technologie au coeur de sa strat√©gie Une m√©thode de management qui favorise l‚Äôautonomie et l‚Äôalignement de toutes les √©quipes sur des objectifs communs ( OKR ) Un environnement propice √† l‚Äôapprentissage et √† la progression Une r√©mun√©ration attractive et des BSPCE Un environnement √† la fois bienveillant, exigeant et tr√®s stimulant Un vrai √©quilibre entre vie personnelle et professionnelle Une v√©ritable culture du travail en remote Les meilleures conditions de travail, quelle que soit ta pr√©f√©rence Si tu es √† Paris: les locaux en plein coeur de Paris au sein du Mus√©e de la Marine Si tu es √† Caen: les locaux sur le port de Plaisance Si tu es en full-remote: un budget qui te permet de t'√©quiper chez toi La carte Swile : 9,5 ‚Ç¨ de tickets restaurants par jour travaill√© Le CE Leeto : plein d‚Äôavantages pour les loisirs, bons d‚Äôachats, etc. Une tr√®s bonne mutuelle et pr√©voyance RTT + journ√©e de solidarit√© offerte Un budget de 400‚Ç¨/an pour participer √† un event de ton choix Si tu ne remplis pas 100% des crit√®res ci-dessus, dis-nous pourquoi tu serais quand m√™me un bon candidat pour ce r√¥le dans ta candidature ! Blog Tech Career Page & Values Stack","Yousign, a European electronic signature scale-up, is looking for a Data Engineer to maintain and develop their Data Platform. The successful candidate should have at least three years of experience as a Data Engineer, have worked with an orchestrator like Apache Airflow, and be knowledgeable in Python and SQL. Compensation includes an attractive salary and BSPCE, a favorable work-life balance, and excellent working conditions in Paris or Caen, or a full-remote option.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
203,55422,https://www.welcometothejungle.com/fr/companies/homeserve/jobs/analytics-engineer-h-f_lyon,Analytics Engineer,HomeServe,"{durable,moderne,BigQuery,Git,SQL,Tableau}",T√©l√©travail total possible,"9, Rue Anna Marly, Lyon, 69007",Assurance,CDI,2023-03-24,"Lanc√©e en 2001, HomeServe France est une soci√©t√© de services pour la maison. Notre mission ? Am√©liorer, entretenir et intervenir en faveur d‚Äôun habitat durable, avec une offre de travaux pour la maison, d‚Äôinstallation des √©quipements et de r√©paration des pannes 7j/7 pour nos clients partout en France. Pour assurer le bon fonctionnement de l‚Äôhabitat et contribuer √† son efficience globale, nos 4 000 professionnels experts en plomberie, √©lectricit√©, chauffage, climatisation et r√©novation √©nerg√©tique interviennent toutes les deux minutes chez nos 1,3 million de clients. HomeServe France emploie plus de 1200 talents anim√©s par un seul objectif : d√©ployer leur √©nergie au service de la transition √©nerg√©tique de la maison de chacun de nos clients. Chaque ann√©e, plus d‚Äôune centaine de collaborateurs prennent part √† l‚Äôaventure HomeServe. Issus d‚Äôhorizons tr√®s diff√©rents, ils participent pleinement √† notre croissance, notre transformation digitale, nos engagements RSE formul√©s au sein de notre programme ‚ÄúEmpreinte 2030‚Äù et l‚Äôaccompagnement de nos clients au quotidien. Alors, pourquoi pas vous ? A propos de nous HomeServe est une soci√©t√© de service experte de la maison depuis plus de 20 ans en France. Nous am√©liorons, entretenons et intervenons en faveur d‚Äôun habitat durable aupr√®s de nos 1,3 million de clients. Comment ? Avec un service d‚Äôassistance et de d√©pannage simple et rapide, l‚Äôinstallation et l‚Äôentretien d‚Äôappareils de chauffage et climatisation et l‚Äôinvestissement sur l‚Äôensemble des infrastructures de la maison permettant d‚Äôagir sur son bilan carbone final. Notre ambition est de couvrir toutes les r√©parations et tous les travaux, pour chaque maison. Int√©grer HomeServe, c‚Äôest rejoindre Une entreprise ‚ÄúGreat Place to Work‚Äù et ‚ÄúBest Workplaces 2021 et 2022‚Äù Un service client certifi√© ¬´ √âlu Service Client de l‚ÄôAnn√©e ¬ª 7 ann√©es cons√©cutives, dans la cat√©gorie Services √† l‚ÄôHabitat Une entreprise engag√©e en faveur du d√©veloppement durable avec son programme RSE Empreinte 2030 qui repose sur 3 piliers strat√©giques : l'environnement, les Hommes et la soci√©t√© et le Client LE POSTE: Rattach√©(e) au responsable Analytics Engineer, vous √™tes en charge de fournir, sous le meilleur format, l‚Äôinformation la plus adapt√©e pour r√©pondre aux enjeux des m√©tiers. Gr√¢ce √† votre contribution, le p√¥le Business Analytics met en ≈ìuvre la strat√©gie Data dans une logique de cr√©ation de valeur en termes de g√©n√©ration de revenus, d‚Äôam√©lioration de l‚Äôexp√©rience client et d‚Äôefficience op√©rationnelle. Sur ce poste, vous jouerez un r√¥le cl√© dans une nouvelle organisation Data positionn√©e au c≈ìur des ambitions strat√©giques de HomeServe. Vos principales missions : Fournir et maintenir des jeux de donn√©es propres et document√©s Etre garant et r√©f√©rent des sujets de mod√©lisation de donn√©es de mani√®re √† faciliter leur exploitation Mettre en place et op√©rer les contr√¥les sur les donn√©es Veiller √† l‚Äôexploitation du code analytique (environnement IDE, versionning, testing,‚Ä¶) Agir comme bras arm√© ‚Äútechnique‚Äù au p√¥le gouvernance pour appliquer des bonnes pratiques de d√©veloppement, comme le contr√¥le des versions et l‚Äôint√©gration continue pour permettre aux Data Analyst et Scientist d‚Äô√™tre plus efficaces Travailler en √©troite collaboration avec les √©quipes m√©tier. Vous serez garant du delivery Data et r√©f√©rent dans le cadre des √©volutions men√©es Enfin, vous serez amen√© √† collaborer largement avec les autres √©quipes du d√©partement (Data Governance, Data Platform et Datalab) respectivement garantes du socle technologique, de la qualit√© des donn√©es et de l‚Äôanalytique avanc√©e Etre Analytics Engineer chez HomeServe, c‚Äôest aussi : Avoir l‚Äôesprit d‚Äôanalyse, √™tre rigoureux et factuel √ätre autonome, vos prises d'initiatives sont fortement encourag√©es. Etre curieux et participer activement √† l'am√©lioration continue de nos process d√©j√† en place Partager son expertise aupr√®s de la communaut√© Data Avoir une aisance relationnelle, l‚Äôesprit d‚Äô√©quipe et √™tre un bon communiquant √ätre rythm√©(e) par la diversit√© des missions et de nombreux projets Votre profil pour r√©ussir dans ce r√¥le : De formation sup√©rieure Bac+4/5, vous b√©n√©ficiez d‚Äôau moins 3 ans d‚Äôexp√©rience dans la data Ma√Ætrise des concepts de mod√©lisation de donn√©es Orientation business d√©montr√©e dans vos pr√©c√©dentes exp√©riences : vous √™tes familiers des probl√©matiques m√©tiers et savez vous adapter au contexte de vos interlocuteurs Comp√©tences techniques (SQL) combin√©es avec des capacit√©s d‚Äôanalyses et un sens prononc√© du business. Connaissance des outils de CI/CD : (Git, Dataform, ‚Ä¶) Capacit√© √† challenger l‚Äôexistant et essayer de nouvelles approches Capacit√© √† g√©rer l‚Äôincertitude et d‚Äôavoir une approche ‚ÄúTest & Learn‚Äù Capacit√© √† travailler dans un environnement transverse et multiculturel La ma√Ætrise de BigQuery et de Tableau Software sont des plus La ma√Ætrise des outils de Digital Analytics (type GA, Piano Analytics) est un plus. Ce que HomeServe vous propose : Prise de poste : d√®s que possible Lieu : Lyon 7√®me Jean-Mac√© (desservi bus, m√©tro, tram, train) Type de contrat : CDI R√©mun√©ration : 45-48 K‚Ç¨ Avantages: Participation, int√©ressement , carte ticket restaurant, transport en commun rembours√©s √† 70%, train √† 85% et indemnit√© kilom√©trique v√©lo, ch√®que CESU‚Ä¶ Un espace de travail moderne qui favorise le bien-√™tre au travail (locaux, outils, conciergerie‚Ä¶) T√©l√©travail nomade possible 10 jours /mois Process Recrutement : - Un √©change t√©l√©phonique avec le recruteur pour faire connaissance - Un entretien avec manager et recruteur - Cas pratique : Une mise en situation permettant de vous projeter dans le poste Pour en savoir plus, rendez vous sur le site HomeServe : www.homeserve.fr","HomeServe France, a company providing services for homes, is seeking an Analytics Engineer to provide and maintain clean and documented datasets for the Business Analytics team. The ideal candidate should have at least 3 years of experience in data and be proficient in data modelling, SQL, and Git, preferably with knowledge of BigQuery and Tableau Software. They should also have strong communication skills, be autonomous, curious, and able to adapt to different contexts. This is a full-time position based in Lyon, France, with a salary range of ‚Ç¨45-48K and benefits including remote work, training, and development opportunities.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,3,1,0.05539549888311683
457,50246,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-remote-germany_berlin,Software Engineer Data Preparation - Remote Germany,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",T√©l√©travail total possible,Berlin,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working '≈ìunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a full-stack software engineer to work on data preparation and other core features of its platform. The ideal candidate should have experience in software development and data processing, be customer-oriented, and have firsthand product building experience. Skills in Java, Javascript, and Python are also preferred. Dataiku's culture emphasizes work-life balance, autonomy, and caring for employees, and the company is committed to diversity and equal opportunity employment.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
422,38988,https://www.welcometothejungle.com/fr/companies/datadog/jobs/data-engineer-data-science-engineering_paris_DATAD_qgKMNzV,Data Engineer - Data Science Engineering,Datadog,"{Java,Go,color,Scala,observable,GitHub,scale,Luigi,Kafka,Spark,Datadog,Hadoop,Python}",T√©l√©travail total possible,"21 Rue de Ch√¢teaudun, Paris, 75009",SaaS / Cloud Services,CDI,2022-11-21,"Datadog (NYSE: DDOG) is a world-class SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers for engineers, Datadog is used by organizations of all sizes across a wide range of industries. We bring together end-to-end traces, metrics, and logs to make applications, infrastructure, and third-party services entirely observable. These capabilities help businesses secure their systems, avoid downtime, and ensure customers are getting the best user experience. About Datadog: We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale‚Äîtrillions of data points per day‚Äîproviding always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way. We need you to design and build machine learning-powered products that help our customers learn from their data and make better decisions in real-time. The Team: We extract and manage data and events from our core products and live systems to make them centrally available for our Data Science team in both batch and real-time ways. We enable Data Scientists to productionize their models and expose their data assets to the rest of the company. If you‚Äôre excited to work on a fast-moving data engineering team with the best open-source data tools at high scale, we want to meet you. You Will: Build distributed, real-time, high-volume data pipelines and work together with others to enable high-scale Data Science Do it with Spark, Luigi, Kafka and other open-source technologies Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more Join a tightly knit team solving hard problems the right way Own meaningful parts of our service, have an impact, grow with the company Requirements: You have a BS/MS/PhD in a scientific field or equivalent experience You have built and operated data pipelines for real customers in production systems You are fluent in several programming languages (JVM & otherwise) You enjoy wrangling huge amounts of data and exploring new data sets You value code simplicity and performance You want to work in a fast, high growth startup environment that respects its engineers and customers You are preferably familiar with Spark and/or Hadoop and know how to put machine learning models in production Is this you? Send your resume and link to your GitHub if available. #LI-ER1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog‚Äôs Applicant and Candidate Privacy Notice .","Datadog is seeking a data engineer who can design and build machine learning-powered products that help customers make better decisions in real-time. Candidates must be comfortable working with Spark, Luigi, Kafka, and other open-source technologies to build distributed, real-time, high-volume data pipelines. The ideal candidate has a scientific degree or equivalent experience, experience building and operating data pipelines, and enjoys wrangling big data sets. Fluency in multiple programming languages and familiarity with Spark and/or Hadoop are also preferred.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
421,38955,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-f-h_massy,Data Engineer,Thales,"{MongoDB,Ruby,Java,moderne,R,PHP,Python}",T√©l√©travail total possible,Rungis,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2022-11-21,"Ceux qui font avancer le monde s‚Äôappuient sur Thales. Dans un monde en constante mutation, √† la fois impr√©visible et riche d‚Äôopportunit√©s, ils sont aux c√¥t√©s de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus s√ªr. Riches de la diversit√© de leurs expertises, de leurs talents, de leurs cultures, leurs √©quipes d‚Äôarchitectes con√ßoivent un √©ventail unique de solutions technologiques d‚Äôexception, qui rendent demain possible d√®s aujourd‚Äôhui. Du fond des oc√©ans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients √† ma√Ætriser des environnements toujours plus complexes pour prendre des d√©cisions rapides, efficaces, √† chaque moment d√©cisif. Quel que soit l‚Äôenjeu. QUI SOMMES-NOUS ? L‚Äôactivit√© Syst√®mes terrestres et a√©riens con√ßoit des syst√®mes, des √©quipements, des capteurs et des services pour le contr√¥le du trafic a√©rien civil et militaire, la d√©fense a√©rienne ainsi que le combat naval et terrestre.Le site de Rungis est id√©alement situ√© √† proximit√© de l‚Äôa√©roport d‚ÄôOrly. Site √† l‚Äôarchitecture moderne, il compte aujourd‚Äôhui plus de 1000 collaborateurs travaillant pour nos trois domaines d‚Äôactivit√© : les radars, le contr√¥le du trafic a√©rien et les syst√®mes d‚Äôarmes avanc√©s. QUI ETES-VOUS ? Vous √™tes une personne de d√©fis et de terrain. Vos exp√©riences ont forg√© votre conviction que l‚ÄôAgilit√© et le Lean permettent √† tous et chacun d‚Äôapprendre, et √† l‚Äôentreprise de progresser et de s‚Äôadapter dans la dur√©e. Au sein de notre √©quipe de Data Management du centre de comp√©tence commun aux Business Lines Airspace Mobility Solutions (AMS) et Integrated Airspace protection Solutions (IAS), vous construisez et optimisez le syst√®me de gestion des donn√©es d‚Äôing√©nierie. Dans ce cadre, vous √™tes responsable de la construction des pipelines de donn√©es. Vous √™tes titulaire d'un (BAC +5) type une √©cole d'Ing√©nieur ou d'un parcours universitaire et vous avez une exp√©rience en analyse de donn√©es; Vous faites preuve de motivation, d'autonomie et d'initiative; Vous faites preuve d'une grande disponibilit√© et d'une tr√®s forte r√©activit√©; Votre esprit d'√©quipe n‚Äôest plus √† prouver et vous aimez le travail collaboratif. CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Vous serez en charge de : Utiliser vos comp√©tences analytiques pour am√©liorer les outils et techniques, et collaborer ainsi √† la conception et au d√©veloppement de solutions innovantes √âtablir une documentation technique en rassemblant les donn√©es et les besoins Agir en tant qu'interface entre l'√©quipe Data Engineering, les clients et les autres contributeurs internes de Thales D√©ployer l'approche DevOps et Continuous Delivery sur un d√©veloppement, ainsi que les outils associ√©s D√©ployer des technologies Back End (langages de programmation ou frameworks), notamment PHP, ASP, C++, C#, Java, Python, Ruby, REST, MongoDB, PaaS...) et Front End pour l‚Äôaffichage des donn√©es (Power BI, ‚Ä¶) Interagir avec un cloud (priv√© ou public), dans tous ses aspects (Infrastructure as a Service=IaaS, Container as a Service=CaaS, Platform as a service=PaaS) Le poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d‚Äôhabilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l‚ÄôIGI 1300 SGDSN/PSE du 09 ao√ªt 2021. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is seeking a Data Engineer to construct and optimize the engineering data management system in the Data Management team. The ideal candidate should possess a degree from an engineering school or university and have experience in data analysis. They should also be a team player, self-motivated, and exhibit a great deal of availability and initiative. The role involves using analytical skills to enhance advanced solutions, working as an interface between clients, and contributing to designing innovative solutions. The successful applicant will need to possess Level 1 Defense Secret clearance.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
66,73402,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech-londres_london,DataOps Engineer - Big Data & Analytics Fintech LONDRES,Opensee,"{go,kubernetes,aws,golang,pandas,python,numpy,scale,Unix,AWS,lambda,bash,azure,SQL,docker,Python,Bash,Docker,Kubernetes,linux}",T√©l√©travail total possible,"London, EC2V 7NA","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee‚Äôs commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What‚Äôs in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client‚Äôs internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Duration : permanent contract Salary : Competitive, profile based Location : London (the City) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!",,Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,3,1,0.05539549888311683
16,73021,https://www.welcometothejungle.com/fr/companies/oh-bibi/jobs/data-software-engineer_paris,Data Software Engineer,Oh BiBi,"{Python,SQL}",T√©l√©travail partiel possible,"16, rue d'Ath√®nes, Paris, 75009","Application mobile, Jeux vid√©o, Digital",CDI,2023-04-22,"Fond√© en 2012 par d‚Äôanciens Gameloft, Oh BiBi rassemble actuellement une 60aine de salari√©s passionn√©s. Au commencement de Oh BiBi, il y avait un r√™ve tr√®s simple : lib√©rer la cr√©ativit√© des √©quipes pour cr√©er des jeux mobiles qui seraient les nouveaux standards de demain. Oh BiBi produit des jeux entre le casual et le midcore, c‚Äôest-√†-dire des jeux qui sont jouables par le plus grand nombre possible, mais qui ont quand m√™me une certaine profondeur. Loin de se cantonner √† un genre de jeu unique, Oh BiBi ne s‚Äôimpose aucune limite et travaille aussi bien sur des jeux de course, de tir, de simulation‚Ä¶ avec √† chaque fois une seule ambition : r√©volutionner le genre sur mobile ! Oh BiBi a fait de la performance, du plaisir de jeu et de la qualit√© esth√©tique des piliers de son travail. Join our innovative Data team as a Data Software Engineer, where you will collaborate closely with a Data Analyst, Data Scientist, and Head of Data. This role offers the opportunity to work on diverse projects and make a significant impact on our products. Responsibilities : Design and implement Reinforcement Learning systems for informed decision-making in A/B testing scenarios Develop state-of-the-art Recommender Systems to enhance our gaming experience Create cutting-edge Generative AI tools for generating personalized content Build efficient Data Analysis pipelines to empower Game and Marketing teams with key business insights Requirements : Master‚Äôs degree in engineering Strong proficiency in Python and SQL Prior experience in development, with a focus on data-driven products Ambition to grow and excel in various aspects of Software and Data Engineering Ability to quickly grasp and work with existing codebases Proactive mindset with a strong capacity for problem-solving Open to self-assessment and continuous improvement Thrive in a dynamic, agile environment and confidently communicate ideas and needs to team members",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 6 mois,2,2,0.05539549888311683
46,73223,https://www.welcometothejungle.com/fr/companies/ascor-communication/jobs/data-engineer-h-f_cesson-sevigne,Data Engineer,Ascor Communication,"{tableau,SAP,Qlik,Informatica,Tableau,SQL,Talend}",T√©l√©travail total possible,"19, Rue du Ch√™ne Germain, Cesson-S√©vign√©, 35510",Formation,CDI,2023-04-22,"Ascor Communication est une entreprise familiale rennaise, en forte croissance, co-dirig√©e par un trin√¥me femmes/homme, parfaitement compl√©mentaire. Nous sommes l‚Äôune des r√©f√©rences fran√ßaises dans le secteur du digital learning , et proposons notamment des formations dans le secteur de la beaut√©, de la petite enfance, de la cuisine, de la p√¢tisserie‚Ä¶ Notre raison d‚Äô√™tre : rendre la formation accessible au plus grand nombre . Certifi√©s AFNOR et QUALIOPI, (1ers en France dans notre secteur), nous formons ainsi chaque ann√©e plus de 6000 apprenants. Notre haut niveau d‚Äôexigence de la satisfaction client repose sur l‚Äôimplication et l‚Äôadh√©sion de tous les salari√©s. Dans le cadre d‚Äôune cr√©ation de poste et de la mise en place de notre entrep√¥t de donn√©es, nous recherchons : Un Data Engineer H/F. Rattach√© au Directeur des Syst√®mes d‚ÄôInformation (DSI), vous aurez la responsabilit√© de ce projet. Vous aurez notamment pour missions de : Mettre en ≈ìuvre un projet Data/Business Intelligence ; Participer au recueil du besoin aupr√®s des directions m√©tiers ; R√©diger des sp√©cifications fonctionnelles, applicatives, et techniques ; Collecter les donn√©es depuis diverses sources et les traiter dans un entrep√¥t de donn√©es ; Accompagner les services m√©tiers dans l‚Äô√©laboration de tableau de bord ; Pr√©parer et d√©rouler les tests ; Accompagner dans la validation de livrables, l‚Äôassistance √† la recette et la conduite du changement sur le projet ; Participer √† la maintenance corrective et √©volutive de l‚Äôentrep√¥t de donn√©es. Nous vous proposons : Une formation interne de plusieurs jours (produits, outils, process‚Ä¶) et un accompagnement tout au long de la collaboration ; Un cadre de travail √† taille humaine ; Une forte dynamique du fait de notre croissance ; Des bureaux desservis par les transports en commun ; 6 semaines de cong√©s. Nos sites internet : www.espace-concours.fr https://www.welcometothejungle.com/fr/companies/ascor-communication De formation sup√©rieure, vous justifiez d‚Äôune exp√©rience de 5 ans. Vous ma√Ætrisez les sujets de construction d‚Äôentrep√¥t de donn√©es et √™tes capable d‚Äôen √©changer avec des interlocuteurs m√©tiers. Vous b√©n√©ficiez d‚Äôune expertise sur des outils ETL du march√© (Informatica, Talend, Big Query, Data Factory, etc) et sur la cr√©ation de tableau de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI‚Ä¶). SQL n‚Äôa plus de secrets pour vous. Votre esprit d‚Äôanalyse et de synth√®se sont souvent reconnus. Vous √™tes autonome et organis√©, et vous savez piloter des projets. Vous appr√©ciez travailler en √©quipe, dans un contexte multi-projets. 1. Merci de nous faire parvenir un CV ainsi que quelques lignes de votre motivation pour ce poste ; 2. Si votre candidature est retenue, un premier √©change t√©l√©phonique sera r√©alis√© ; 3. Si ce dernier est concluant il aboutira √† second entretien.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
417,38957,https://www.welcometothejungle.com/fr/companies/side/jobs/data-engineer_paris_SIDE_kJgLeMw,Data Engineer,Side,"{git,Go,Airflow,scale,Luigi,Kafka,Spark,Docker,SQL,Python}",T√©l√©travail total possible,"33, Rue La Fayette, Paris, Paris, 75009","Application mobile, Recrutement",CDI,2022-11-21,"üëâ‚Äã Side est l‚Äôagence d‚Äôint√©rim 100% en ligne et humaine. Elle a √©t√© lanc√©e en 2016 par 4 amis tout juste sortis de leurs √©tudes. Apr√®s de nombreux jobs √©tudiants, ils √©taient convaincus qu‚Äôen utilisant le digital, il √©tait possible de cr√©er une nouvelle exp√©rience de travail temporaire, plus simple, plus fiable et plus √©panouissante. ü§ù‚Äã En Mai 2022, Side a rejoint le groupe Randstad, pour avoir le plus d‚Äôimpact possible sur le march√© de l‚Äôint√©rim, et p√©renniser son business model. Side pourra b√©n√©ficier de l‚Äôexpertise du g√©ant de l‚Äôint√©rim, des connaissances m√©tiers des diff√©rentes filiales du groupe, et d‚Äôun r√©seau d‚Äôagences avec lesquelles ils pourront collaborer, tout en gardant l‚ÄôADN start-up, la v√©locit√© et l‚Äôatmosph√®re bienveillante et dynamique qui a toujours exist√© au sein de l‚Äôentreprise. üßë‚Äçü§ù‚Äçüßë Side a donc rassembl√© une √©quipe de +60 collaborateurs, tous mobilis√©s pour cr√©er la meilleure exp√©rience int√©rimaire en France, ainsi que 300,000 ‚ÄúSiders‚Äù et 2,000 clients - de la start-up au grand groupe (Etam, Go Sport, DB Schenker, Stuart, Blablacar‚Ä¶). üëî‚Äã La mission de Side est d‚Äô√©quiper les entreprises et candidats avec une technologie au service de l‚Äôhumain, pour que les contrats courts soient synonymes de s√©r√©nit√© et d‚Äôint√©gration sur le march√© de l‚Äôemploi. üì±‚Äã Ils d√©veloppent une app mobile pour les candidats et un outil en ligne pour les entreprises, qui leur permettent de travailler ensemble en moins de 24h, sans se soucier de la charge administrative. Pourquoi rejoindre Side ? üí• Tu souhaites avoir un r√©el impact sur le march√© du travail de demain ? Nous avons besoin de talents comme toi ! üí´ Notre mission est d‚Äôapporter une nouvelle exp√©rience du travail temporaire √† nos candidats et entreprises partenaires : plus fiable, plus simple et plus humaine que ce qui existait jusqu‚Äô√† pr√©sent. Nous sommes une agence en ligne d‚Äôint√©rim, qui se diff√©rencie des autres par : la fiabilit√© du service la simplicit√© d‚Äôusage l‚Äô humain incarn√© par nos √©quipes et nos solutions. Notre r√¥le est d‚Äôapporter un tremplin vers l‚Äôemploi pour les candidats et une haute qualit√© de service pour les entreprises qui recrutent. üåü Les 3 valeurs cl√©s chez Side sont les suivantes : Fight For ‚ÄúYes‚Äù signifie : rester positif, quoiqu‚Äôil arrive, car les choses se passent rarement comme pr√©vues. Chercher et trouver des solutions. Vivre l‚Äôaventure avec enthousiasme. Chez Side nous prenons du plaisir autant dans les grandes victoires que dans les petits accomplissements du quotidien. Be Champions signifie : voir les choses en grand ! Se mettre √† la place de l‚Äôutilisateur, construire la meilleure exp√©rience de travail en faisant preuve de cr√©ativit√©, d‚Äôexcellence et d‚Äôengagement. Travailler √† devenir chaque jour un peu meilleur.es, tels des sportifs de haut niveau, pour avoir un impact r√©el sur le futur du travail en France et dans le monde. Be Buddies signifie que Side √©tait d‚Äôabord une √©quipe avant d‚Äô√™tre une entreprise. Les int√©r√™ts collectifs passent toujours avant les int√©r√™ts personnels. Nous demandons √† chacun de faire preuve d‚Äôempathie et de solidarit√© avec les autres. De communiquer r√©guli√®rement sur son √©tat d‚Äôesprit, notamment dans le cadre du t√©l√©travail. Ta future √©quipe : üë´ L‚Äô√©quipe Produit est une √©quipe soud√©e et anim√©e par des valeurs fortes forg√©es au fil des ann√©es. Rejoindre Side, c‚Äôest rejoindre une √©quipe d‚Äôune dizaine de personnes aux expertises diverses qui valorise : L‚Äôimpact : avoir un √©tat d‚Äôesprit positif, mettre du coeur √† l‚Äôouvrage et chercher √† avoir un impact √† la hauteur des probl√®mes rencontr√©s par les utilisateurs¬∑trices en faisant preuve de curiosit√© et de pragmatisme ; L‚Äôapprentissage : adorer apprendre et relever de nouveaux challenges, comme √ßa a √©t√© le cas lorsque notre produit s‚Äôest restructur√© pour transitionner vers le mod√®le int√©rim ; L‚Äôempathie : s‚Äôefforcer de se mettre √† la place des autres, saisir le contexte et capter les priorit√©s de chacun¬∑e ; L‚Äôesprit d‚Äô√©quipe : mettre le collectif au centre, d√©livrer des retours constructifs et c√©l√©brer les r√©ussites ; Le sens des responsabilit√©s : construire des solutions durables gr√¢ce √† une approche m√©thodique, organis√©e et exigeante qui permette de gagner la confiance des autres. Side garantit l‚Äô√©galit√© des chances √† tous les candidat.e.s. Chaque candidature re√ßue est prise en consid√©ration ind√©pendamment de l‚Äôorigine ethnique et raciale, des opinions, des croyances, du sexe, de l‚Äôorientation sexuelle, de la sant√© ou du handicap. Concernant le r√¥le : L‚Äô√©quipe Produit recherche un Data Engineer exp√©riment√© pour renforcer ses rangs, et propulser nos produits to the next level ! ‚ÜóÔ∏è Ta mission : üí• A l‚Äôaide de tes connaissances, de tes comp√©tences, et de l‚Äôenvironnement Data stable et mature de Side, ton but sera de d√©velopper et d‚Äôapprofondir notre culture tr√®s data-driven , pour permettre √† Side de scale-up. Travaillant main dans la main avec l‚Äô√©quipe BI et l‚Äô√©quipe Produit, tu seras la personne en charge de fournir de la donn√©e √† chaque Business Unit de Side : fournir de nouvelles sources de donn√©es, les enrichir pour obtenir des informations pertinentes et utiles, transformer la data gr√¢ce √† nos outils d‚Äôanalyse et proposer des retours qualitatifs (et vulgaris√©s) √† chaque √©quipe en demande. En t‚Äôappuyant sur ton exp√©rience et ton expertise, tu apporteras ton point de vue technique, dans le but d‚Äôam√©liorer la fiabilit√© et la qualit√© de notre donn√©e. Tu cherches √† √©voluer et √† monter en comp√©tence dans un environnement qui favorise l‚Äôefficacit√© et l‚Äôautonomie ? Alors rejoins-nous ! Nous avons besoin de ton aide pour : üåü Automatiser l‚Äôint√©gration de sources externes avec notre Data Warehouse, et am√©liorer les existantes, Concevoir et mettre en place du code Python et SQL pour cr√©er et am√©liorer nos flux de donn√©es, et r√©duire les bottlenecks. D√©finir les processus et les r√®gles qui viendront fa√ßonner la data de demain Aider Side √† √™tre encore plus data-driven ! Mettre en place des fonctionnalit√©s ayant de l‚Äôimpact, de la discovery jusqu‚Äô√† la livraison. Am√©liorer (ou cr√©er) des analyses existantes pour aider chaque business unit de Side √† performer. Devient les yeux des BU ! Perfectionner nos processus de documentation et de sch√©matisation de la donn√©e. Informations suppl√©mentaires : üí° Pense au futur : toujours anticiper un volume deux fois plus grand que pr√©vu. Pense √† l‚Äô√©quipe : les BU doivent √™tre autonomes et doivent pouvoir exploiter ton travail sans √™tre bloqu√©s. Sois force de proposition : tu es libre d‚Äôexp√©rimenter des mod√®les de machine learning sur des sujets qui te semblent appropri√©s. Ton profil : Un bon niveau d‚Äôanglais 1 ou 2 ans d‚Äôexp√©rience r√©ussi en Python deploy√© en production Exp√©rience avec diff√©rents types de base de donn√©es, notamment celles avec du SQL. Exp√©rience en d√©veloppement conteneuris√© (Docker) Exp√©rience avec un VCS (git ou √©quivalent). Une exp√©rience r√©ussie sur un poste similaire est un plus Bonus üíØ Exp√©rience pass√©e avec des framework ETL (Apache Airflow, Spotify Luigi). Exp√©rience pass√©e avec des ‚Äústream processing frameworks‚Äù (comme Kafka ou Spark). Exp√©rience pr√©c√©dente avec des frameworks Big Data et/ou OLAP databases. Connaissances basiques en statistiques descriptives Un appel de 15min avec une personne de l‚Äô√©quipe Produit Un entretien d‚Äô1h autour du mindset et des valeurs Sur une p√©riode de 48h - un (petit) test technique 30min √† 1h de rencontre avec les membres de ton √©quipe Welcome on board !üéâ Les √©tapes peuvent √™tre adapt√©es suivant les besoins des candidats.","Side, an online temporary work agency, is seeking an experienced Data Engineer to lead their data-driven culture and scale-up the business. The successful candidate will be responsible for providing data to each Business Unit of Side, automating external sources integration, and improving data extraction and transformation workflows. Side seeks someone who is proficient in Python, SQL, containerization, and version control systems, and has prior relevant experience. Fluency in English is required. Framework ETL, stream processing frameworks, OLAP databases, and basic knowledge of descriptive statistics are a plus.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 1 an,3,1,0.05539549888311683
436,49828,https://www.welcometothejungle.com/fr/companies/pricehubble/jobs/engineering-manager-data-ml-platform_vienna_PRICE_ZwAdjAL,Engineering Manager - Data & ML Platform,PriceHubble,"{Kubeflow,Azure,GCP,Tensorflow,scipy,AWS,scale,K8s,Keras,Sagemaker,Python}",T√©l√©travail total possible,Vienna,"Logiciels, Immobilier particulier",CDI,2023-02-07,"PriceHubble is a Swiss B2B proptech company that builds innovative digital solutions for the real estate industry based on property valuations and market insights. Leveraging big data, cutting-edge analytics and great visualisation, PriceHubble‚Äôs products suite brings a new level of transparency in the market, enabling their customers to make real estate and investment decisions based on the most accurate data-driven insights (such as valuations, market analyses, value forecasts or building simulations) and enhance the dialogue with end consumers. PriceHubble‚Äôs digital solutions are designed to help all players across the entire real estate value chain (banks, asset managers, developers, property managers and real estate agents). PriceHubble is already active in 10 countries (Switzerland, France, Germany, Austria, Japan, Netherlands, Belgium, Czech Republic, Slovakia and the United Kingdom) and employs more than 200 people worldwide. About PriceHubble PriceHubble is a PropTech company with over 220 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, Amsterdam and Tokyo. We work on international markets and we are backed by world-class investors. We have a startup environment, low bureaucracy, and an international team and business. The opportunity You will be part of the Data Products team, heading a team of experienced ML and software engineers who build PriceHubble‚Äôs Data and ML Platform. The Data & ML Platform Manager has a key role in supporting the excellence of PriceHubble‚Äôs products, by directing the development of the ideal environment for data engineering and science teams to innovate and deliver PriceHubble‚Äôs world-class, high scale, customer-facing real-estate inference products. As the leading member of the team, the empowerment and growth of your team members will be your main responsibilities. Moreover, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems. Through your contributions, you will help to: Build a team of experts focused on large scale data systems engineering. Manage, maintain and develop the organization‚Äôs ML and Data platforms, with a focus on usability, reliability, performance and efficiency. Define robust, maintainable, state-of-the-art distributed system architectures, to identify improvements to engineering processes and to improve efficiency and reduce effort in platform operation by creating repeatable and automated processes. Steer the development of infrastructure and systems supporting the deployment, monitoring, optimization and scaling of AI-based prediction and insight services in production, from conception to launch. Define requirements, create a roadmap and work with engineers to build, release, assess and iterate. Optimize and streamline the work of data engineering and data science teams, by designing tools and products to facilitate data exploration, model training, deployment and serving processes to achieve insights quality and service quality SLOs We will also expect you to always stay at the forefront of ML engineering, quality management, cloud and data ops best practices in the industry. Requirements BSc or MSc in computer science or related fields At least 1 year of professional experience managing a team of more than 3 engineers At least 2 years of professional experience working on ML platforms Passionate about data and engineering at scale Keen to help teams grow and learn, and to nurture an harmonious engineering culture Solid experience in communicating with both business and technical stakeholders Strong oral, written and presentation skills with ability to clearly explain complex concepts to a variety of audiences Strong practice using agile methodologies and DevOps methods Excellent skills in object-oriented programming, data structures, algorithms as well as designing distributed service architectures in a cloud environment Proficient in the Python data science ecosystem Experience with data systems, ML and ML ops in production, at scale: K8s, Kubeflow, Dataproc, Sagemaker, Tensorflow, scipy, Keras‚Ä¶ Experience working with public cloud platforms (AWS, Azure or GCP) Value end to end ownership of projects, simplicity and getting the right things done Fluent in English both in writing and speaking * We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas. Benefits Join an ambitious and hungry team and enjoy the following benefits: üí∞ Competitive salary because we always want to attract the best talents. üìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success. üè¢ Very well-located offices with a great remote work policy and the possibility to work from different places. üïì Flexible working hours and work life balance.","PriceHubble is seeking a Data & ML Platform Manager with experience in managing teams of more than three engineers, ML platforms, and designing distributed service architectures in a cloud environment. The ideal candidate should possess proficiency in Python data science, object-oriented programming, and agile methodologies, and have excellent communication skills to interact with both business and technical stakeholders. The company offers competitive salaries, flexible working hours, and a learning and development program.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
49,73261,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/bi-engineer-data-visualisation_paris_NUMBE_RKKVNm,BI Engineer & Data Visualisation,Numberly,"{via,PowerBI,BigQuery,SQL}",T√©l√©travail total possible,"28 rue de Ch√¢teaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Vous intervenez sur toutes les phases de la conception √† la r√©alisation d‚Äôapplications d‚Äôoutils d‚Äôaide √† la d√©cision et monitoring de performance r√©pondant aux probl√©matiques m√©tiers de nos clients. Vous √™tes amen√© √† : Intervenir sur des missions de cadrage et d‚Äôanalyse des besoins fonctionnels; Identifier et proposer les bons KPIs permettant de r√©pondre aux attentes des clients; Concevoir et r√©aliser les reporting d‚Äôaide √† la d√©cision en apportant une attention aux enjeux de self BI, ainsi que sur l‚ÄôUX/UI Desktop et mobile; D√©ployer des projets de Data Visualisation sous PowerBI en priorit√© mais possiblement en participant aux choix d‚Äôautres outils de restitution; Accompagner les clients dans la bonne compr√©hension et mont√©e en comp√©tence sur l‚Äôexploitation et le maintien des tableaux de bord. Vous assurerez √©galement une veille technologique, et proposerez des solutions standardis√©es, fiables, √©volutives li√©es √† votre activit√©. Chez Numberly, nous partageons une passion pour la transmission : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment gr√¢ce : - aux ‚ÄúJedi Master‚Äù, attribu√©s √† chaque nouvel arrivant- aux Vis ma vie dans des √©quipes diff√©rentes ;- aux Happy Meetings : des rendez-vous mensuels internes pour se retrouver avec toutes nos √©quipes dans le monde et partager l‚Äôactualit√© du groupe. Nous cultivons la libert√© de parole qui permet √† tous de participer au d√©veloppement du groupe. Nous agissons positivement sur notre √©cosyst√®me √† travers 1000mercis impacts et via nos activit√©s qui cr√©ent de la valeur dans l‚ÄôOpen Internet et participent √† l‚Äôenrichissement de l‚ÄôOpen Source. Numberly est acteur de la diversit√© et Gender Equal by design : certification WeConnect International Un gender equity score de 97/100 Numberly est un environnement international avec plus de 30 nationalit√©s dans nos √©quipes. Des bureaux √† l‚Äôimage de chacune des √©quipes, une biblioth√®que g√©n√©reuse, un grand studio de musique tout √©quip√©, deux chats, du tri s√©lectif et du lombricompostage, la possibilit√© de venir avec votre animal de compagnie et de la place pour les v√©los ! Dans chaque cuisine : caf√©, th√©, infusions √† volont√© et aussi des mystery lunchs, des cours de yoga, des cours de sport et des soir√©es (souvent d√©guis√©es). Possibilit√© d'√™tre en remote jusqu'√† 50% de votre temps (√† organiser comme vous le souhaitez) et de travailler jusqu‚Äô√† 60 jours (ouvr√©s) cons√©cutifs en remote. Carte Swile ( titres-restaurants ). Mobilit√© possible dans nos diff√©rents bureaux √† l'international. Numberly accueille les personnes en situation de handicap. Poste disponible √† Paris ou Londres. Vous avez au moins 2 ans d'exp√©rience dans la mise en place de projets datawarehouse et datamart. Vous avez une app√©tence particuli√®re au domaine du Big Data, avec des r√©alisations de projets BI/reporting et dataviz dans ce contexte; Vous avez de bonnes connaissance sur les sujets et comp√©tences sur les technologies suivantes : ETL et SQL. Vous √™tes curieux(se), autonome, force de proposition et avez l‚Äôesprit d'√©quipe. Vous avez le sens du contact et une forte motivation pour travailler dans un environnement innovant et dynamique (de nombreux prix ont r√©compens√© le travail de Numberly en Europe et aux USA) au sein d‚Äôune √©quipe jeune (27 ans de moyenne d‚Äô√¢ge) et internationale (25 nationalit√©s). Encore mieux si Vous avez de l‚Äôexp√©rience sur PowerBI et/ou BigQuery Vous avez une connaissance du domaine fonctionnel marketing, digital, CRM, m√©dia et la relation client.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
455,57058,https://www.welcometothejungle.com/fr/companies/payplug/jobs/data-engineer_paris,Data Engineer,Payplug,"{MySQL,MongoDB,python,gitlab,Kubernetes,Docker,RabbitMQ,BigQuery,GCP,SQL,Python,Tableau}",T√©l√©travail partiel possible,"110, Avenue de France, Paris, 75013","FinTech / InsurTech, E-commerce",CDI,2023-03-26,"Payplug est la solution de paiement fran√ßaise pens√©e pour les commer√ßants, e-commer√ßants de toutes tailles et fintechs. Avec notre plateforme technologique de pointe, nos outils d√©di√©s √† la conversion et notre ma√Ætrise unique de la cha√Æne de paiement, nous vous invitons √† viser le meilleur, et plus encore. Payplug, c‚Äôest une √©quipe de 400 passionn√©s d√©di√©s √† la r√©alisation de vos plus grandes ambitions. Nous accompagnons aujourd‚Äôhui 20 000 PME telles que Hast et Plantes pour tous, mais aussi de grands groupes comme Maisons du Monde, Veepee et kiwi.com. Payplug fait partie du Groupe BPCE depuis 2017. Payplug est la solution de paiement fran√ßaise pens√©e pour les commer√ßants, e-commer√ßants de toutes tailles et fintechs. Avec notre plateforme technologique de pointe, nos outils d√©di√©s √† la conversion et notre ma√Ætrise unique de la cha√Æne de paiement, nous vous invitons √† viser le meilleur, et plus encore. Payplug, c‚Äôest une √©quipe de 400 passionn√©s d√©di√©s √† la r√©alisation de vos plus grandes ambitions. Nous accompagnons aujourd‚Äôhui 20 000 PME telles que Hast et Plante pour tous, mais aussi de grands groupes comme Maisons du monde, Veepee et kiwi.com . Payplug fait partie du Groupe BPCE depuis 2017 NOTRE AMBITION : Garantir la qualit√© de nos produits Permettre aux √©quipes, et √† nos clients, d‚Äôacc√©der √† des donn√©es fiables et de couvrir leurs besoins dans chaque domaine ! Nous d√©veloppons : Des reports √† destination de nos clients. Des calculs d‚Äôindicateurs strat√©giques. Des dashboards de pilotage, de launch control et de discovery. Des reporting et des analyses de donn√©es. Des contr√¥les industrialis√©s et des alertes. Des flux de donn√©es avec nos partenaires. NOTRE M√âTHODE DE TRAVAIL : Nous sommes 10 dans l‚Äô√©quipe Data (Head of Data, Team Lead BI, Data Analysts & Data Engineers) r√©partis entre 2 squads. Rattach√©s au p√¥le Product & Tech, nous collaborons avec toutes les √©quipes de PayPlug. Pour relever les challenges m√©tiers et clients, nous construisons une plateforme de donn√©es sur GCP (Google Cloud Platform), sur laquelle nous d√©veloppons nos pipelines et nos solutions. Celle-ci remplacera √† terme int√©gralement notre syst√®me existant. Les d√©veloppements se font principalement en SQL et Python. Notre stack technique : ‚óè Data : BigQuery, Cloud Composer/Apache Airlfow, Cloud Data Proc, Cloud PubSub ‚óè BI: Tableau ‚óè Infrastructure g√©n√©rale : Google Cloud Platform ‚óè Conteneur et Orchestration : Docker, Kubernetes ‚óè Versionning et CI/CD : gitlab & gitlab-CI ‚óè Databases : BigQuery, MongoDB, MySQL, Vertica ‚óè Message broker : RabbitMQ Tes missions Tu int√©greras la squad Data, compos√©e d‚Äôun data engineer, d‚Äôun Lead Technique et rattach√©e au Head of Data. Le r√¥le de cette squad est cl√© dans la construction et le maintien de la plateforme de donn√©es ! Tu assureras la mise en place des flux et mod√®les de donn√©es, en fonction des usages m√©tiers. Tu seras garant de la qualit√© des donn√©es, du maintien des pipelines, de la documentation et de la performance de nos solutions. Dans tes missions tu seras aussi amen√© √† √©changer avec les autres √©quipes de Product & Tech (SRE, squads Product & Tech, squad BI, ‚Ä¶). Requirements Data engineer avec au moins une premi√®re exp√©rience ; Tu as d√©j√† d√©velopp√© en SQL et python ; Tu as d√©j√† travaill√© avec GCP ; Tu as de l‚Äôexp√©rience dans la construction, le maintien de pipelines de donn√©es, la mod√©lisation, le monitoring et l‚Äôalerting. Autonome et rigoureux.se, tu as de bonnes qualit√©s relationnelles, ainsi qu‚Äôun bon esprit d‚Äô√©quipe. Ce qui te d√©marque : De nature curieuse, tu aimes investiguer et comprendre les usages et pratiques en data engineering. Tu as de l‚Äôexp√©rience avec le production-grade code (design pattern, test unitaire et d‚Äôint√©gration, CI/CD, ‚Ä¶) Tu souhaites rejoindre une nouvelle √©quipe et construire une plateforme de donn√©es modernes et scalables. √Ä l‚Äô√©coute, tu es soucieux.se de r√©pondre aux besoins de tes coll√®gues. Hiring Process Appel de qualification avec Justine , Talent Managers (20-30') ; Test avec l‚Äô√©quipe Data (1h) ; Interview avec Guillaume , Head of Data (1h) ; 2 r√©f√©rences. Benefits Modalit√©s / avantages de travai l : Organisation de travail hybride ; 25 CP / an & 10 RTT / an ; Des bureaux dans le 13e arrondissement de Paris (Biblioth√®que Fran√ßois Mitterrand). Avantages financiers : Carte Apetiz (titres restaurants) d‚Äôune valeur de 9‚Ç¨ par jour (52% pris en charge) ; Sant√© / Famille : Mutuelle sant√© Malakoff Humanis Abonnements aux transports publics ou Velib pris en charge √† 50% par PayPlug. Autres : Moka.care pour le soutien √† la sant√© mentale de chacun ; Windoo : activit√©s de sport, bien-√™tre et d√©veloppement personnel ;","Payplug is looking for a Data Engineer with GCP experience to join their team, responsible for building and maintaining their data platform. The ideal candidate should have experience in pipeline construction and maintenance, data modelling, monitoring and alerting, as well as strong skills in SQL and Python. The company offers a hybrid work organization, 25 days of vacation, and benefits such as meal tickets, health insurance, and transportation benefits.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 6 mois,2,2,0.05539549888311683
51,62906,https://www.welcometothejungle.com/fr/companies/kooperativa/jobs/data-engineer-m-z_praha_KOOPE_eb4q0pZ,Data Engineer (m/≈æ),Kooperativa,"{Jupyter,NiFi,MapR,Git,Gitlab,Airflow,Informatica,Kafka,Hadoop,Hive,Spark,Docker,Github,SQL,Zeppelin}",T√©l√©travail total possible,"Pob≈ôe≈æn√≠ 665 , Praha, 18600","Assurance, Finance",CDI,2023-03-31,"Kooperativa funguje na ƒçesk√©m trhu u≈æ ƒçtvrt stolet√≠ a za tu dobu vyrostli do velk√© ƒçesk√© firmy s mezin√°rodn√≠m rozhledem i partnery. Maj√≠ p≈ôes dva miliony klient≈Ø a chtƒõj√≠ v√≠c ne≈æ jen vyhovƒõt jejich p≈ô√°n√≠m a po≈æadavk≈Øm, chtƒõj√≠ je p≈ôedƒç√≠t. Nechtƒõj√≠ b√Ωt neosobn√≠ spoleƒçnost√≠, v√≠, ≈æe aby byli √∫spƒõ≈°n√≠, mus√≠ dob≈ôe rozumƒõt lidem a jejich osud≈Øm. To plat√≠ i o p≈ô√≠stupu k zamƒõstnanc≈Øm, v nƒõm≈æ chtƒõj√≠ j√≠t naproti specifick√©mu potenci√°lu ka≈æd√©ho z nich a p≈ôistupovat f√©rovƒõ ke v≈°em bez v√Ωjimky. V t√Ωmu 6 Data Scientist≈Ø a nyn√≠ budujeme datalake pro ulo≈æen√≠ a analytiku velk√Ωch a nestrukturovan√Ωch dat. Hled√°me nad≈°ence pro modern√≠ technologie, kter√Ω n√°m pom≈Ø≈æe s rozvojem nov√© platformy. P≈ôedev≈°√≠m pak s automatizac√≠ datov√Ωch tok≈Ø, architekturou ulo≈æen√≠ dat, nasazen√≠m ML model≈Ø apod. Spoleƒçn√Ωm c√≠lem je vyu≈æ√≠t data pro rozvoj spoleƒçnosti od reportingu a≈æ po implementaci model≈Ø ML/AI a posouzen√≠ jejich praktick√©ho p≈ô√≠nosu. M√°me spoustu zaj√≠mav√Ωch analytick√Ωch √∫loh zejm√©na z oblast√≠ rizikovosti smluv a klient≈Ø, identifikace a generov√°n√≠ obchodn√≠ch p≈ô√≠le≈æitost√≠, segmentace klientsk√©ho portfolia a online chov√°n√≠ klient≈Ø. V r√°mci skupiny VIG zast≈ôe≈°ujeme Advanced Analytics Hub pro tvorbu statistick√Ωch a ML model≈Ø aBig Data Hub pro uchov√°n√≠ a velk√© a nestrukturovan√© data. Co v√°s ƒçek√°? Pr√°ce na zaj√≠mav√Ωch projektech s vysok√Ωm pozitivn√≠m dopadem na fungov√°n√≠ poji≈°≈•ovny a jej√≠ klienty Pr√°ce s velk√Ωmi a nestrukturovan√Ωmi daty obsa≈æen√Ωmi v datech (telematika, IOT, kalkulace, p≈ôepisy hovor≈Ø, fotografie nehod, dokumenty ‚Ä¶) Zaji≈°tƒõn√≠ a automatizace datov√Ωch tok≈Ø uvnit≈ô i mimo firmu √özk√° spolupr√°ce s data scientisty a datov√Ωm architektem, budeme souƒç√°st√≠ jednoho t√Ωmu Spolupr√°ce p≈ôi monitorov√°n√≠ a provozu datov√©ho prost≈ôed√≠ Co budete urƒçitƒõ pot≈ôebovat? Dobrou znalost Pythonu nebo PySparku vƒçetnƒõ notebook≈Ø Jupyter nebo Zeppelin Dobrou znalost pr√°ce s relaƒçn√≠mi datab√°zemi pomoc√≠ SQL Znalosti technologi√≠ pro DWH nebo datalake Z√°jem pozn√°vat a uƒçit se nov√© metody a technologie Co byte mohli zn√°t, ale nen√≠ to nutnost√≠? P≈ôede≈°l√© zku≈°enosti s budov√°n√≠m big data ≈ôe≈°en√≠ ve velk√© spoleƒçnosti Znalost nƒõkter√Ωch z n√°stroj≈Ø a technologi√≠ Spark, Airflow, MapR, Hadoop, Docker, OpenShift, Hive, NiFi Zku≈°enosti s integraƒçn√≠mi n√°stroji SSIS, ODI, Informatica, Pentaho Zku≈°enosti s technologiemi pro datov√© toky REST API, Kafka apod. Zku≈°enosti s n√°stroji pro spr√°vu a verzov√°n√≠ k√≥du Git, Gitlab/Github Znalost princip≈Ø datov√©ho modelov√°n√≠ ETL/ELT Zku≈°enosti s nasazen√≠m a automatizac√≠ DevOps, CI/CD a MLOps Znalost princip≈Ø a aplikac√≠ ML/AI model≈Ø Co v√°m za to nab√≠dnete? 32 dn≈Ø dovolen√© v roce (25 dn≈Ø dovolen√© + 5 voln√Ωch dn≈Ø + 1 charitativn√≠ den + 1 den p√©ƒçe) Flexibiln√≠ pracovn√≠ doba + mo≈ænost pr√°ce z domova Cestovn√≠ poji≈°tƒõn√≠ zdarma, nadstandardn√≠ p≈ô√≠spƒõvek na penzijn√≠ p≈ôipoji≈°tƒõn√≠ (a≈æ 1 000 Kƒç mƒõs√≠ƒçnƒõ) a ≈æivotn√≠ poji≈°tƒõn√≠ (a≈æ 3 150 Kƒç mƒõs√≠ƒçnƒõ), tƒõ≈°it se m≈Ø≈æete tak√© na velk√© slevy na na≈°e produkty a na produkty na≈°ich obchodn√≠ch partner≈Ø V r√°mci bonusov√©ho programu Cafeterie dostanete 12.000 Kƒç (v benefit bodech) a to, jak je uplat≈àovat, je jen na v√°s (sport, relax, kultura, dovolen√°, pobyty, apod.) Dotovan√° karta MultiSport za 500 Kƒç mƒõs√≠ƒçnƒõ Stravn√© 130 Kƒç/den (Kooperativa n√°m n√°jem 105 Kƒç) - v Praze m√°me vlastn√≠ j√≠delnu, bistro a kav√°rnu Intern√≠ i extern√≠ kurzy (IT a jazykov√© kurzy, vzdƒõl√°vac√≠ platforma Seduo), firemn√≠ kouƒç a psycholog, vyu≈æ√≠t m≈Ø≈æete i na≈°i firemn√≠ knihovnu Rozvojov√© a sportovn√≠ akce, zdravotn√≠ a preventivn√≠ programy, ale tak√© mo≈ænost nadstandardn√≠ zdravotn√≠ p√©ƒçe (fyzioterapie, j√≥ga, oƒçkov√°n√≠) Za doporuƒçen√≠ nov√©ho kolegy v√°s ocen√≠me a≈æ 45 000 benefit body do Cafeterie Zamƒõstnaneck√Ω mobiln√≠ tarif, pracovn√≠ telefon a notebook je samoz≈ôejmost√≠","Data Scientist with experience in Python or PySpark, SQL, and DWH/Datalake technologies sought by Kooperativa to work as part of a team of 6 data scientists to build a datalake for storing and analyzing large and unstructured data. The successful candidate will be involved in automating data flows, deploying ML models, and collaborating in the development of analytical solutions in the areas of risk management, customer segmentation and behavior. Kooperativa offers a range of employee benefits, including flexible working hours, home-office opportunities, and access to training and development programs.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
33,56777,https://www.welcometothejungle.com/fr/companies/betclic/jobs/data-engineer-h-f_bordeaux,Data Engineer,Betclic Group,"{durable,Jenkins,Scala,AWS,Uber,Snowflake,Java,Github,Python}",T√©l√©travail total possible,"117 Quai de Bacalan, Bordeaux, 33300",Application mobile,CDI,2023-03-26,"Entreprise fran√ßaise leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c‚Äôest : üßë‚Äçü§ù‚Äçüßë 11 millions de joueurs vibrants au rythme des comp√©titions sportives ‚≠êÔ∏è Une offre tr√®s large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ‚öΩÔ∏è Plus de 50 sports ouverts aux paris üìÖ 300 000 √©v√®nements sportifs disponibles aux paris chaque ann√©e üñ• 60 000 √©v√®nements sportifs diffus√©s en live chaque mois üé∞ Plus de 3 000 jeux de casino √† exp√©rimenter üÉè Plus de 2 millions de parties de poker jou√©es chaque mois üöÄ De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l‚ÄôUBB, les Boxers de Bordeaux‚Ä¶ Depuis sa cr√©ation en 2005, Betclic est une soci√©t√© de technologie ‚Äúmobile-only‚Äù, anim√©e par une passion in√©branlable pour le sport. Guid√© par l‚Äô√©motion et le plaisir du jeu, Betclic d√©veloppe des applications de divertissement mobile et place ses clients au c≈ìur d‚Äôune exp√©rience de jeu unique en innovant avec agilit√© et rapidit√© pour offrir toujours plus de jeux et plus de fun √† ses joueurs. Notre ambition ? Proposer √† nos clients l‚Äôexp√©rience de jeu la plus divertissante gr√¢ce √† des applications simples, immersives et innovantes. Betclic, dont le si√®ge est √† Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalit√©s parmi ses 800 collaborateurs r√©partis dans 5 pays d‚ÄôEurope : France, Italie, Malte, Pologne, et Portugal. WE ARE BETCLIC Entreprise fran√ßaise leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c'est : ‚Äç‚Äç 11 millions de joueurs vibrants au rythme des comp√©titions sportives ‚≠ê Une offre tr√®s large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ‚öΩ Plus de 50 sports ouverts aux paris 300 000 √©v√®nements sportifs disponibles aux paris chaque ann√©e 60 000 √©v√®nements sportifs diffus√©s en live chaque mois Plus de 3 000 jeux de casino √† exp√©rimenter Plus de 2 millions de parties de poker jou√©es chaque mois De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l'UBB, les Boxers de Bordeaux‚Ä¶ Depuis sa cr√©ation en 2005, Betclic est une soci√©t√© de technologie 'mobile-only', anim√©e par une passion in√©branlable pour le sport. Guid√© par l'√©motion et le plaisir du jeu, Betclic d√©veloppe des applications de divertissement mobile et place ses clients au c≈ìur d'une exp√©rience de jeu unique en innovant avec agilit√© et rapidit√© pour offrir toujours plus de jeux et plus de fun √† ses joueurs. Notre ambition ? Proposer √† nos clients l'exp√©rience de jeu la plus divertissante gr√¢ce √† des applications simples, immersives et innovantes. Betclic, dont le si√®ge est √† Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalit√©s parmi ses 800 collaborateurs r√©partis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal. Les profils recherch√©s sont ceux qui ont l'ambition de construire en √©quipe, qui sont pr√™ts √† relever des challenges tous plus passionnants les uns que les autres, et qui ont cette volont√© de cr√©er des solutions offrant une exp√©rience client in√©dite. L'univers du sport et du jeu vous fait vibrer ? Vous aimez les d√©fis et participer √† l'effort collectif ? Betclic vous propose de rejoindre l'aventure ! #JoinBetclic #WeAreBetclic ENTER THE GAME En tant que Data Engineer / Data Ops, vous int√©grez l'√©quipe Data Platform compos√©e de Data Engineer, Data/ML Ops, architecte et dont le r√¥le est de garantir la disponibilit√© de la plateforme et mettre en place les outils et bonnes pratiques autour de la data. Les √©quipes Tech Betclic sont organis√©es autour des principes de d√©veloppement agiles et s'organisent en squad et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique. Gr√¢ce √† cette organisation vous b√©n√©ficierez de la responsabilit√© de A √† Z de vos projets : conception, d√©veloppement, livraison, suivi de production. You build it, you run it ! En rejoignant nos √©quipes Betclic, vous int√©grerez une √©quipe Fullstack o√π vous jouirez d'une autonomie vous permettant de vous enrichir au contact de d√©veloppeurs Backend ou Frontend, de testeurs et de guildes transversales en charge d'expertises compl√©mentaires (DBA, SRE, ARCHI, CI/CD, DATA, etc‚Ä¶). YOUR ROLE WITHIN BETCLIC A partir de l'existant, contribuer √† la d√©finition et √† la mise en ≈ìuvre de la nouvelle g√©n√©ration de l'√©cosyst√®me data qui supporte la proposition d'exp√©riences toujours plus fun pour nos joueurs. Dans ce cadre, vos missions sont les suivantes : Participer aux phases de conception et de d√©veloppement des projets et services data, accompagn√© par les autres membres de l'√©quipe et des architectes / SRE Accompagner les Data Scientist/Analyst dans la mise en place des algorithmes de data science (passage √† l'√©chelle, suivi des bonnes pratiques) Automatiser le d√©ploiement des projets r√©alis√©s par le d√©veloppement d'InfraAsCode (IaC) et de pipelines CI/CD Maintenir et monitorer la plateforme data En fonction du niveau d'exp√©rience, accompagner les d√©veloppeurs juniors dans leur mont√©e en comp√©tence technique TECHNICAL ENVIRONMENT Python / Terraform / Serverless AWS Snowflake Jenkins / Github WHO WE ARE LOOKING FOR? Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, [un amour pour la technique], un peu de z√®le et une r√©elle passion pour leur m√©tier ! Ce job est fait pour vous si : Vous √™tes dipl√¥m√©(e) d'une √©cole d'ing√©nieur, √©cole informatique, MIAGE Vous disposez d'une exp√©rience professionnelle r√©ussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud Public Vous √™tes dot√©(e) de fortes comp√©tences en d√©veloppement, d'une app√©tence pour l'automatisation (CI/CD) et le scripting et vous souhaitez rejoindre un environnement professionnel challengeant. Vous √™tes sensible √† la performance, la fiabilit√©, la maintenabilit√© et la scalabilit√© de votre code et des architectures que vous concevez Vous ma√Ætrisez imp√©rativement un des langages de d√©veloppement Python, Scala, Java et vous avez une exp√©rience r√©ussie avec l'Infrastructure As Code Et enfin, vous parlez anglais couramment WHAT CAN YOU EXPECT? Un package de r√©mun√©ration attractif 25 jours de cong√©s pay√©s et 10 jours de repos compensateurs Une carte Ticket Restaurant¬Æ financ√©e √† hauteur de 50% (10‚Ç¨/ jour) Une mutuelle d'entreprise prise en charge √† 100% pour vous et vos enfants Un abonnement de transport pris en charge √† hauteur de 50% ou une prime annuelle de mobilit√© durable (200‚Ç¨ pour les trajets domicile ‚Äì travail en transport durable) Un pack mobilit√© (aide au d√©m√©nagement) Une flexibilit√© de travail encadr√©e par un accord sur le t√©l√©travail Un souci constant de d√©veloppement des comp√©tences avec un programme de formation annuel personnalis√© Des √©volutions de carri√®re dans un environnement international ‚Ä¢ Des locaux hors du commun avec un rooftop am√©nag√© pour profiter d'animations r√©guli√®res, de pauses et de d√©jeuners au soleil face √† la Cit√© du Vin Des cours de sports 2 fois par semaine Et l'opportunit√© de travailler dans une atmosph√®re conviviale, jeune et fun ! Poste en CDI √† pourvoir d√®s que possible √† Bordeaux Betclic Group - 117 quai de Bacalan 33300 BORDEAUX Tous nos postes sont ouverts aux personnes en situation de handicap.","Betclic, a French leader in online sports betting and gaming, is seeking a Data Engineer/Data Ops to join their Data Platform team. The role involves contributing to the development of a new generation of data ecosystem for improved player experiences, participating in the conception and development of data projects, and monitoring the platform's data. The ideal candidate has at least three years of experience in data engineering or operations within a public cloud environment, strong development skills, and fluency in Python, Scala, or Java. Betclic offers an attractive remuneration package, opportunities for career advancement, a flexible work environment, and a fun office culture.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
230,60556,https://www.welcometothejungle.com/fr/companies/eldo/jobs/data-engineer-f-h_toulouse_ELDO_995WWwA,Data Engineer,Eldo,"{MySQL,Talend,PostgreSQL,Airflow,AWS,via}",T√©l√©travail total possible,"Lab'O√Økos Saint Aubin, Toulouse, 31000","SaaS / Cloud Services, B√¢timent / Travaux publics, Digital",CDI,2023-03-28,"Eldo, c‚Äôest la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s‚Äôam√©liorer au quotidien pour d√©velopper leur activit√© üöÄüíö √Ä propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l‚Äôam√©lioration de l‚Äôhabitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la premi√®re plateforme europ√©enne de solutions digitales √† destination des professionnels, marques et consommateurs du secteur de l‚Äôam√©lioration de l‚Äôhabitat. Nous sommes une √©quipe de passionn√©s qui souhaitent r√©volutionner le secteur de l‚Äôam√©lioration de l‚Äôhabitat (76 milliards d‚Äô‚Ç¨). Avec notre suite SaaS nous accompagnons les pros et marques du secteur √† d√©velopper leur activit√© en optimisant chaque √©tape du cycle de vente avec leurs clients. Du moment o√π ils les trouvent sur le web, jusqu‚Äô√† leur satisfaction √† la fin des travaux. Sur notre site B2C, nous aidons les particuliers √† trouver des pros de confiance gr√¢ce aux avis et photos de leurs voisins, pour r√©aliser les travaux de leurs r√™ves. Nous avons un positionnement et un service unique avec : üíªüì≤ une suite applicative SaaS, d√©velopp√©e avec et pour les pros et marques du b√¢timent üì∑üí¨ + 100 000 avis accompagn√©s de photos, vid√©os ; üë®‚Äçüîß des milliers d‚Äôentreprises r√©f√©renc√©es avec un taux de renouvellement/satisfaction de 90%. üè°üí∞ un partenariat avec Google et une certification AFNOR Laur√©ats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs √† succ√®s comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d‚Äôici 2030 la premi√®re plateforme mondiale de solutions digitales √† destination des professionnels de l‚Äôam√©lioration de l‚Äôhabitat. Eldo, c‚Äôest la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s‚Äôam√©liorer au quotidien pour d√©velopper leur activit√© üöÄüíö √Ä propos Eldo accompagne depuis 2016 les professionnels et marques du secteur de l‚Äôam√©lioration de l‚Äôhabitat dans la digitalisation de leur communication et gestion commerciale. Notre mission : partager les savoirs qui construisent les belles histoires. Nous construisons la premi√®re plateforme europ√©enne de solutions digitales √† destination des professionnels, marques et consommateurs du secteur de l‚Äôam√©lioration de l‚Äôhabitat. Nous sommes une √©quipe de passionn√©s qui souhaitent r√©volutionner le secteur de l‚Äôam√©lioration de l‚Äôhabitat (76 milliards d‚Äô‚Ç¨). Avec notre suite SaaS nous accompagnons les pros et marques du secteur √† d√©velopper leur activit√© en optimisant chaque √©tape du cycle de vente avec leurs clients. Du moment o√π ils les trouvent sur le web, jusqu‚Äô√† leur satisfaction √† la fin des travaux. Sur notre site B2C, nous aidons les particuliers √† trouver des pros de confiance gr√¢ce aux avis et photos de leurs voisins, pour r√©aliser les travaux de leurs r√™ves. Nous avons un positionnement et un service unique avec : üíªüì≤ une suite applicative SaaS, d√©velopp√©e avec et pour les pros et marques du b√¢timent üì∑üí¨ + 100 000 avis accompagn√©s de photos, vid√©os ; üë®‚Äçüîß des milliers d'entreprises r√©f√©renc√©es avec un taux de renouvellement/satisfaction de 90%. üè°üí∞ un partenariat avec Google et une certification AFNOR encore renouvel√©e cette ann√©e ! (processus de collecte, mod√©ration et restitution des avis) Laur√©ats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs √† succ√®s comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d‚Äôici 2030 la premi√®re plateforme mondiale de solutions digitales √† destination des professionnels de l‚Äôam√©lioration de l‚Äôhabitat. Descriptif du poste Chez Eldo notre Dream Team s‚Äôagrandit ! üë©‚ÄçüöÄ Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer. Si tu aimes la donn√©e et que les statistiques n‚Äôont aucun secret pour toi‚Ä¶ alors Alessandro et la team n‚Äôattendent que toi ! Regarde par la fen√™tre de l‚Äô√©quipe Product Engineering ! üëÅ La Team Product Engineering, c‚Äôest plus d'une dizaine de collaborateurs passionn√©s et ambitieux accompagn√©s par nos √©quipes marketing, sales, grands comptes‚Ä¶! Ton r√¥le chez Eldo Tu travailleras quotidiennement √† l‚Äô am√©lioration de nos applications (modifications de l‚Äôactuel et cr√©ation) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualit√© et granularit√© de cette derni√®re, le tout, en √©tant un support pour les √©quipes en interne. Pour la partie ‚ÄúEngineer‚Äù, tu seras attendu sur la scalabilit√© de la partie Data, la mise en place d‚Äôarchitecture d√©di√©e, la gestion de la s√©curit√© de la data, la connexion entre l‚Äôarchitecture data et la partie applicative et d√©veloppement produit. Pour la partie ‚ÄúAnalyste‚Äù , tu seras en charge de recueillir les donn√©es internes (bases de donn√©es, fichiers‚Ä¶) et externes (HubSpot, Google Analytics, Partoo‚Ä¶), puis de les centraliser au sein d‚Äôun datawarehouse pour ensuite permettre leur restitution via un outil d√©di√© √† la Business Intelligence (tu seras force de proposition sur les outils √† utiliser). Tu devras bien √©videmment documenter et sp√©cifier les √©l√©ments de services ou mod√®les d√©velopp√©s, ainsi que maintenir une veille active sur les services utilis√©s et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus ad√©quates solutions. Ayant un r√¥le fortement orient√© et driv√© par l‚ÄôImpact business et utilisateur, tu seras naturellement au sein de l‚Äô√©quipe Produit, compos√©e de Product Manager, Product Designer. Tes √©changes quotidiens seront bien √©videmment avec cette √©quipe, mais pas que. Les d√©veloppeurs et toutes les autres √©quipes seront pour toi des stakeholders privil√©gi√©s afin de r√©pondre au mieux au besoin de la strat√©gie Produit et Entreprise. Les √©quipes Product Engineering (PE) travaillent en utilisant la m√©thodologie Agile. üîùüòç Ce que l‚Äô√©quipe aime par-dessus tout sur ce poste L‚Äôhumour au quotidien, via des petites blagues souvent de bonne qualit√© (mais pas toujours) La team Product Engineering Les afterworks L‚Äôaventure d‚Äôune belle croissance Pouvoir mettre sa pierre √† l‚Äô√©difice üëç Les petits + qui font kiffer Contrat forfait jour + RTT Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge √† 70% Un club employ√© (billetterie, produits high-tech, voyage, etc..) La carte tickets resto --> Swile est notre ami Primes cooptations Remote ponctuel o√π tu veux en France Goodies, welcome lunch & drinks (et pas que de bienvenue) 1 break dans l‚Äôann√©e dans une destination surprise Eldo est la soci√©t√© qu‚Äôil te faut si tu aimes ‚Ä¶ üíö Le management de proximit√© et impliquant L‚Äôautonomie, les prises d‚Äôinitiatives, les challenges #growthmindset √âvoluer au sein d‚Äôune √©quipe fun et bienveillante Les moments de partage en √©quipe L‚Äôid√©e de mettre ta pierre √† l‚Äô√©difice et de participer √† une aventure humaine et professionnelle INCROYABLE Ton environnement de travail sera le suivant: MySQL, PostgreSQL ETL/ELT, Jobs Talend orchestr√©s par Airflow, Hevo data pour la partie no code. APIs d‚Äôoutils externes √† une entreprise (ex : Google Analytics, HubSpot‚Ä¶). Outils de reporting/dashboarding (Amazon QuickSight¬∞. Toucan Toco pour la partie embed dans l‚Äôapplication) Outils de documentation, Confluence, et outils de suivi des t√¢ches/incidents, JIRA. Environnement cloud (AWS) Cela pour √™tre un super fit si en plus, tu as/es : Soft skills autonome curieux(se) une bonne communication diplomate un esprit de synth√®se flexible Social skills Ouverture d‚Äôesprit Orient√© Business Bienveillance Sens de l‚Äôinitiative üîé Le process de recrutement chez Eldo 1 - √âchange visio RH (45‚Äô) 2 - Use case 3 - √âchange avec des membres de l‚Äô√©quipe Product Engineering ! (60‚Äô) 4 - √âchange avec ton futur manager, le CPTO (60‚Äô) Ce poste peut-√™tre en 100% en full remote avec des d√©placements √† pr√©voir 1 fois par mois sur Toulouse pris en charge par Eldo Alors, s√©duit(e) ? poste sans tarder ton CV et sors ta plus belle plume üòé Eldo est une entreprise handi-accueillante","Eldo is hiring a data engineer to improve their applications by proposing data architectures, pipelines, and algorithms. The role involves ensuring data quality and granularity, supporting internal teams, and scaling data. The successful candidate will be responsible for collecting and centralizing internal and external data, maintaining a watch on industry developments, and suggesting appropriate solutions. The role is focused on business impact and user needs, working closely with the product management team. Eldo provides remote work opportunities and employee benefits.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,3,1,0.05539549888311683
64,73385,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f-h-f_paris,Data Engineer,TotalEnergies Digital Factory,"{Python,Azure,Spark,AWS,SQL}",T√©l√©travail total possible,"31 rue des Jeuneurs, Paris, 75002","Logiciels, Big Data, Energie",CDI,2023-04-22,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. TotalEnergies a d√©cid√© d'acc√©l√©rer la production interne de solutions digitales pour ses activit√©s en cr√©ant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilit√© et l'esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Nous cr√©ons et d√©ployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. Nous consid√©rons les personnes comme la ressource la plus pr√©cieuse pour r√©ussir, c'est pourquoi nous tenons non seulement √† recruter les meilleurs talents, mais aussi √† cr√©er des liens uniques entre nos employ√©s. En tant que Data Engineer, tu garantis la qualit√© des pipelines data du produit, tu assures le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es. Dans l'√©cosyst√®me ultra dynamique des nouvelles mobilit√©s (notamment √©lectriques), en phase avec de grands enjeux soci√©taux, nous attendons de toi que tu : ¬∑ Con√ßoives, construises et int√®gres des donn√©es au sein de la Squad et en collaboration avec les autres Squads. ¬∑ Assures le stockage, la consommation, l'int√©gration et la gestion des donn√©es des cas d'utilisation. ¬∑ Fasses l'analyse de l'analyse de l'accessibilit√© des donn√©es et que tu recommandes des solutions pour leur int√©gration. ¬∑ Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de donn√©es. Tu int√®gres √©galement les donn√©es dans le data lake. ¬∑ Collabores avec les data scientists pour la r√©alisation des mod√®les de pr√©diction. ¬∑ Produises un code de qualit√©, mettes en place des tests automatis√©s et syst√©matiques pour le contr√¥ler. ¬∑ Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacit√© des solutions et apporter des pr√©conisations techniques. En parall√®le, tu auras √©galement des missions transverse. Pour ce faire, nous attendons de toi que tu : ¬∑ Assures la veille technologique sur les architectures data et les nouvelles technologies. Coaches et accompagnes la communaut√© des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une exp√©rience d'au moins 4 ans en data engineering, tu es dipl√¥m√© d'un master ou d'une √©cole d'ing√©nieur sp√©cialis√©e en informatique ou math√©matiques. Et si tu as d√©j√† une exp√©rience dans l'√©cosyst√®me de la mobilit√©, de la recharge √©lectrique ou du digital fueling, c'est top ! Les comp√©tences qui sont attendues de toi en tant que Data Engineer : ¬∑ La maitrise de Python, Spark et SQL. ¬∑ Une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles. ¬∑ La capacit√© √† concevoir et √† mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle. ¬∑ Ma√Ætrise des bonnes pratiques de monitoring des flux de donn√©es. ¬∑ Une bonne compr√©hension du machine learning. ¬∑ Une bonne connaissance des m√©thodes Agile (Scrum, Kanban, voir m√™me SAFe ou Nexus). ¬∑ Une culture tech tu sais concevoir et mod√©liser une solution informatique. ¬∑ Si tu as toi-m√™me de bonnes notions de d√©veloppement, c'est un plus notable (stack technique : Cloud Azure ou AWS, C#, .Net). ¬∑ Une exp√©rience avec les outils de gestion de Backlog comme Jira ou Azure DevOps. Si tu en connais plusieurs, c'est encore mieux. ¬∑ Une premi√®re exp√©rience sur un provider de Cloud, AWS de pr√©f√©rence.",,Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
29,54715,https://www.welcometothejungle.com/fr/companies/wuest-partner/jobs/data-engineer_paris,Data Engineer,W√ºest Partner,"{MySQL,MongoDB,ElasticSearch,Python}",T√©l√©travail total possible,"1 Boulevard de la Madeleine, Paris, 75009","Logiciels, Intelligence artificielle / Machine Learning, Immobilier commercial",CDI,2023-03-24,"W√ºest Partner est une soci√©t√© de conseil ind√©pendante et innovante du secteur immobilier. Pionni√®re, l‚Äôentreprise combine depuis 1985, expertise immobili√®re, data et solutions digitales pour faciliter et fiabiliser les prises de d√©cisions. Leur √©quipe, pluri disciplinaire et √† taille humaine, apporte sa contribution √† chacun de ces 3 piliers. ‚Ä¢ Vous piloterez vos projets dans l‚Äôextraction, l'uniformisation et la structuration des donn√©es ‚Ä¢ Vous am√©liorerez la qualit√© et enrichissez les bases de donn√©es existantes ‚Ä¢ Vous optimisez les flux de donn√©es entrants et sortants ‚Ä¢ Vous suivez des projets clients ‚Ä¢ Vous assurerez la veille technologique sur les outils Data et les nouvelles m√©thodes de mod√©lisation Tout ceci en collaboration √©troite avec les √©quipes internationales Vous √™tes dipl√¥m√© d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent (BAC +5), vous b√©n√©ficiez d‚Äôune premi√®re exp√©rience dans la gestion de projet Data et vous souhaitez vous investir dans une structure innovante de taille humaine. Vous avez une aisance particuli√®re pour prendre des responsabilit√©s et pour travailler avec les autres √©quipes technologiques : Dev et Design Facilit√© de manipulation de tout type de base de donn√©es relationnelles (MySQL, Postgre) et non-relationnelles ( MongoDB, ElasticSearch) D√©veloppement machine learning (Python) et/ou backend (JS) ‚Äì La ma√Ætrise des deux est un √©norme plus Vous √™tes : - Curieux - Aimez les environnement agile - Travaillez en mode projet - Grande prise d'initiative, esprit ""self-starter"", autonomie dans l'ex√©cution des t√¢ches - Pro-actif Vous avez un anglais professionnel","W√ºest Partner, an independent and innovative real estate consulting company, is seeking a Project Manager with expertise in data management and manipulation. The ideal candidate will have a degree in engineering or a related field, experience in project management, and skills in handling both relational and non-relational databases, machine learning development, and backend development. The role includes improving data quality, optimizing data flow, and keeping up with new data tools and methods. The candidate should be a self-starter with strong communication skills and the ability to work collaboratively with technology teams.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
249,2704,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-remote_paris,Software engineer Data Presentation - Remote EMEA,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",T√©l√©travail total possible,N,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku‚Äôs culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . #LI-Remote About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku, a platform for Everyday AI, is seeking a software engineer with experience in software development and an interest in data visualization tools to build scalable, user-friendly interfaces for their platform. The ideal candidate will be customer-oriented, comfortable with both frontend and backend development, and have firsthand experience building a real product. Dataiku values a culture of autonomy, flexibility, inclusivity, and caring for employees' work-life balance. They are an equal opportunity employer committed to treating all employees with dignity, decency, and fairness.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
63,73377,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-quality-engineer-m-w-d_hamburg,Data Quality Engineer,Groupe SeLoger,"{AZURE,python,java,scala,sql,javascript,AWS,GCP}",T√©l√©travail total possible,Hamburg,"Application mobile, IT / Digital, M√©dia",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Fran√ßais dans la r√©alisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d‚Äôoffrir √† chacun de nos utilisateurs, une exp√©rience immobili√®re simple et efficace afin qu‚Äôils concr√©tisent leurs projets d‚Äôachat, de vente ou de location en toute s√©r√©nit√©. Nous mettons √† disposition des Fran√ßais le plus large choix d‚Äôannonces afin de leur faciliter la recherche d‚Äôun bien selon leurs crit√®res propres, et r√©pondre √† toutes les questions soulev√©es par la r√©alisation d‚Äôun projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque pr√©f√©r√©e des Fran√ßais pour se rep√©rer et se lancer dans leur projet immobilier. WHAT WE DO IN Marketplace Design‚Äì Product and Tech at AVIV The Marketplace Design Domain at AVIV group is part of the Product & Tech organization and its objective is to deliver the internal services that powers Actor teams to brings safety, trustworthiness and remove opacity from the experience. Building on local expertise from Immowelt (Germany & Austria), Immoweb (Belgium), Groupe SeLoger and Meilleurs Agents (France), we deliver fraud / cheat / information reliability assessment services to raise marketplace safety and reliability in the interactions between Seekers and Owner / Agent. WE ARE LOOKING FOR AN INDIVIDUAL WHO CAN: Will be part of an agile, multidisciplinary, international team and work closely with them to Identify data quality issues, and implement solutions to verify, validate, and monitor data quality. Contributes to analysis of data issues and help identifying business processes and technical improvements that contribute to higher quality data. Work with the product team to establish data quality standards within the sprints, develop a test plan and deliver high quality builds on time. Work with product owners and data engineers to improve the overall experience by suggesting improvements and changes. Design and maintain QA reports for the internal data systems. Align and collaborate with the rest of the data quality team to improve the overall quality, assess risks, promote consistency, identify common needs. Develop test strategies for automation both for backend and data. Write and execute both functional and non-functional data tests. You convince with your analytical way of thinking. INDIVIDUAL WHO HAS: Solid experience (at least 3 Years) as Data Quality Engineer. Practical experience working with agile methodologies. Degree in Computer Science or other relevant qualifications. ISTQB Certification is a plus. Practical experience creating and maintaining ETL and API tests. Experience in automating data tests with frameworks like Deequ or other. Experience in automating APIs tests with javascript or java libraries like fetch, superAgent, restAssured... You are comfortable reading and writing code in at least one programming language, ideally java, scala, python. Basic understanding of sql. Experience with CI/CD Tools. Basics in cloud experience like AWS, GCP, AZURE is plus. A proactive team player that analyses the risk and impact of issues and is working with the team to prioritise and resolve them. Any experience with performance, GDPR, accessibility, interoperability and security testing is a plus. Excellent communication skills, with fluency in English. Willingness to travel from time to time is available.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
62,56598,https://www.welcometothejungle.com/fr/companies/blent-ai/jobs/data-engineer-poei_paris,Data Engineer (POEI),Blent.ai,{},T√©l√©travail total possible,"198 Av. de France, Paris, 75013","Intelligence artificielle / Machine Learning, Big Data, EdTech",CDI,2023-03-26,"Tu es demandeur d‚Äôemploi et tu souhaites devenir Data Engineer ? Rejoins Blent.ai et int√®gre notre parcours d‚Äôexcellence afin d‚Äôacqu√©rir les comp√©tences cl√©s pour devenir Data Engineer, le m√©tier le plus demand√© du march√© de la Data. Notre parcours m√™le comp√©tences techniques et softskills pour te rendre op√©rationnel d√®s ta sortie du parcours et faciliter ton int√©gration au sein de ta nouvelle entreprise. √Ä l‚Äôissue de notre parcours tu int√©greras d‚Äôailleurs les √©quipes d‚Äôun de nos partenaires, en CDI. Les candidats retenus b√©n√©ficieront d‚Äôun parcours de mont√©e en comp√©tences d‚Äôexcellence, enti√®rement pris en charge par P√¥le Emploi dans le cadre du dispositif POEI (Pr√©paration Op√©rationnelle √† l‚ÄôEmploi Individuel). Le Data Engineer accompagne les entreprises dans la construction d‚Äôinfrastructures informatiques pour stocker, g√©rer et administrer de grandes quantit√©s de donn√©es. Les comp√©tences du Data Engineer peuvent √™tre regroup√©es en 4 blocs de comp√©tences : La mise en place et la maintenance de syst√®mes de stockage de fichiers et de bases de donn√©es. La cr√©ation de clusters de calcul parall√®le et de syst√®mes distribu√©s. L‚Äôimpl√©mentation de syst√®mes de gestion de donn√©es en temps r√©el (Data Streaming). L‚Äôautomatisation de pipelines de donn√©es et de d√©ploiement de mod√®les de Machine Learning. Le Data Engineer est capable de construire des solutions techniques permettant de r√©pondre aux probl√©matiques de l‚Äôentreprise, aussi bien sur des sujets de marketing, commerciaux ou op√©rationnels. A qui cette formation s‚Äôadresse ? Les Data Analysts et Data Scientists qui souhaitent profiter de leur expertise Data pour devenir Data Engineer. Les d√©veloppeurs qui souhaitent prendre le virage technologique du Data Engineering. Les √©tudiants et jeunes dipl√¥m√©s qui souhaitent apprendre le Data Engineering par la pratique et se familiariser avec le monde de l‚Äôentreprise. Ce que nous t‚Äôoffrons : La garantie d‚Äô√™tre op√©rationnel √† la sortie de notre parcours d‚Äôexcellence de 3 mois Un CDI aupr√®s d‚Äôun de nos partenaire Un salaire attractif √† la cl√© : 35 000‚Ç¨ √† 50 000‚Ç¨ selon ton profil","Blent.ai is offering a three-month program for job seekers to become a Data Engineer, one of the most demanded roles in the data market. The program combines technical and soft skills to make candidates operational upon completion, and they will be guaranteed a permanent position with one of Blent.ai's partners. The Data Engineer's role involves the implementation of data management systems, real-time data management, and automated pipelines and machine learning deployment. The program is suitable for data analysts, data scientists, developers, and students who want to learn data engineering through practical experience.",Bac +5 / Master,< 15 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
4,58091,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_bordeaux,Data Engineer,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",T√©l√©travail total possible,"Bordeaux, 33000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. ‚Ä¢ Conseil, Audit et Maitrise d‚Äô≈ìuvre. ‚Ä¢ √âtudes d‚Äôopportunit√©, cadrage de projet d‚Äôint√©gration de donn√©es et aide au choix de solution. ‚Ä¢ Accompagnement √† la mise en place de Data Lake / Big Data. ‚Ä¢ Accompagnement de profil junior. ‚Ä¢ Conception et d√©veloppement de flux d‚Äôint√©gration des donn√©es (ETL, ELT, streaming , API ‚Ä¶ ). ‚Ä¢ Conception et mise en ≈ìuvre de plateformes On Premise ou Cloud de stockage des donn√©es dans un Data Lake (Big Data). ‚Ä¢ Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.). ‚Ä¢ Migration des donn√©es. ‚Ä¢ Move to Cloud. ‚Ä¢ Comp√©tences av√©r√©es en gouvernance des donn√©es, qualit√© des donn√©es et catalogue des donn√©es (>4 ans d‚Äôexp√©rience dans le domaine) ‚Ä¢ Animation d‚Äôateliers M√©tier/ IT de d√©finition des processus d‚Äôint√©gration des donn√©es. ‚Ä¢ Animation d‚Äôatelier de d√©finition de plateforme d‚Äôint√©gration et de stockage des donn√©es. ‚Ä¢ Proposition de type d‚Äôarchitecture de gouvernance (centrale, d√©centralis√©e, etc.). ‚Ä¢ Capacit√© √† int√©grer une √©quipe d‚Äôint√©gration des donn√©es. ‚Ä¢ Capacit√© √† proposer des solutions & architectures de donn√©es. ‚Ä¢ Capacit√© √† configurer des outils d‚Äôint√©gration et de Reporting des donn√©es. ‚Ä¢ Formation et pratique d‚Äôoutils de Data Int√©gration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. ). CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital services and consulting, is seeking a Data Integration Consultant with experience in data governance, quality, and cataloging. The ideal candidate will have skills in advising and supporting businesses in their digital transformation, developing ETL workflows, and implementing storage solutions in Data Lake/Big Data platforms. Other required skills include proficiency in Cloud platforms, data migration, architecture governance, and tool configuration. CGI is an inclusive employer that values diversity, career growth, and employee well-being.",Non sp√©cifi√©,> 2000 salari√©s,> 4 ans,3,1,0.05539549888311683
466,56887,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-data-reliability_paris_DATAD_234AOm7,Software Engineer - Global Data Platform,Datadog,"{Redis,color,Golang,Kafka,scale,Cassandra,Elasticsearch,Datadog,Python,Postgres}",T√©l√©travail total possible,"21 Rue de Ch√¢teaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. How do you provide data to a real-time service that monitors hundreds of thousands of servers 24 hours a day? How do you ensure data correctness in the face of infrastructure failures and network partitions, in a high-volume, low-latency environment? What should the infrastructure look like when data may double in size or in throughput on short notice? If you think you have the answers, join us on the Global Data Platform team and help us ensure that we're providing reliable data, at scale, and quickly. At Datadog, we place value in our office culture - the relationships that it builds, the creativity it brings to the table, and the collaboration of being together. We operate as a hybrid workplace to ensure our employees can create a work-life harmony that best fits them. What You‚Äôll Do: Keep our datastores reliable, available and fast. Respond to, investigate and fix issues, whether it‚Äôs deep in the database code or in the client application. Build tooling to minimize customer-facing downtime, and scale up resources on short notice Protect and ensure the consistency of customer data. Work with developers to design data models, and choose the correct datastores, to support orders of magnitude more customer data and traffic. Who You Are: You have min 5 years of experience in software engineering You value correctness and efficiency; you leave no stone unturned when diagnosing production issues You handle infrastructure with code because automation lets you focus on the more difficult and rewarding problems You have production experience with distributed datastores, e.g. Cassandra, Postgres, Kafka, Elasticsearch, Redis You have created tooling for, or submitted contributions to, an open-source datastore You are fluent in Python or Golang Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you‚Äôre passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our Internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-AD1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog‚Äôs Applicant and Candidate Privacy Notice .","Datadog is seeking an experienced software engineer to join its Global Data Platform team. The successful candidate will be responsible for ensuring that the company is providing reliable data, at scale and quickly. Key responsibilities will include responding to, investigating and fixing issues, building tooling to minimize customer-facing downtime, and scaling up resources on short notice. The ideal candidate will have at least five years‚Äô experience in software engineering, be comfortable handling infrastructure with code, and have production experience with distributed datastores. Strong Python or Golang skills are also required.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
6,72850,https://www.welcometothejungle.com/fr/companies/spacefill/jobs/data-engineer_paris,Lead Data Engineer,Spacefill,"{Git,PostgreSQL,NoSQL}",T√©l√©travail total possible,"29, Rue du Faubourg Poissonni√®re, Paris, 75009","Logistique, Supply Chain, SaaS / Cloud Services",CDI,2023-04-22,"La mission de SpaceFill est de flexibiliser les cha√Ænes logistiques Europ√©ennes.‚Ä®Pionnier de la logistique digitale, SpaceFill a construit le premier r√©seau europ√©en d‚Äôentrep√¥ts, embarqu√© sur un logiciel SAAS. La plateforme permet √† ses clients (PME comme grands groupes) de mieux g√©rer leurs stocks et flux de marchandises en quelques clics. Ils peuvent ainsi construire des cha√Ænes logistiques plus efficaces, vertes et r√©siliantes au plus proche de leurs march√©s. Fond√©e en juin 2018 et bas√©e √† Paris, SpaceFill conna√Æt une croissance exponentielle d√®s le lancement de son service. Quelques mois plus tard l‚Äô√©quipe r√©alise une lev√©e de fonds d‚Äô1M‚Ç¨ et remporte le premier prix Gallion Booster. Aujourd‚Äôhui, Spacefill : Une hypercroissance depuis 3 ans (9M‚Ç¨ CA) Plus de 350 clients √† travers plus de 3000 entrep√¥ts en France et en Allemagne, et se pr√©pare √† conqu√©rir l‚ÄôEurope. A lev√© 8M‚Ç¨, puis 25M‚Ç¨ d√©but 2022 75 employ√©s Spacefill permet √† ses clients de piloter leur activit√© logistique √† travers un r√©seau connect√© d‚Äôentrep√¥ts en Europe. En tant Lead Data Engineer, tu as la responsabilit√© de la mod√©lisation de notre base de donn√©es, de la mise en place d‚Äôune data pipeline et de sa maintenance / √©volution. Notre mod√®le repose actuellement sur une base de donn√©es PostgreSQL et la logique m√©tier est encapsul√©e dans celle-ci. Sous la responsabilit√© du VP Engineering, tu auras comme mission d‚Äô√©tablir la strat√©gie et le futur mod√®le qui permettra √† Spacefill de ‚Äúscaler‚Äù son produit et les use cases de ses clients. Tu travailleras √©troitement avec les autres Leads techniques ainsi qu‚Äôavec l‚Äô√©quipe Produit. Informations compl√©mentaires: √âquipement : 1 Macbook Pro 16‚Äù M1Pro 32Go Ram ou ThinkPad + budget de set up de bureau Carte tickets restaurant Swile RTTs Assurance sant√© Alan Stock options (BSPCE) T√©l√©travail partiel ou total possible Convention collective : Syntec P√©riode d‚Äôessai : 4 mois renouvelable Maitrise de PostgreSQL, PL/PGSQL, triggers, migrations, etc Exp√©rience et force de proposition dans le d√©veloppement de data-pipelines / event driven architecture dans le cloud Connaissances ETL, traitement et agr√©gation de donn√©es Connaissances NoSQL Une bonne ma√Ætrise de la communication orale et √©crite Ma√Ætrise de Git Forte autonomie Un premier √©change t√©l√©phonique pour comprendre tes motivations √† nous rejoindre, puis on se rencontre tr√®s rapidement! Un process simple et rapide en moins d‚Äôune semaine.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 7 ans,3,1,0.05539549888311683
55,63027,https://www.welcometothejungle.com/fr/companies/alef-nula/jobs/data-centr-networking-engineer_praha,Data Center Networking Engineer,ALEF,"{Microsoft,Splunk,AWS}",T√©l√©travail total possible,"Pernerova 691 , Praha, 18600","IT / Digital, SaaS / Cloud Services, Cybers√©curit√©",CDI,2023-03-31,"‚Ä¶p≈Øsob√≠ na ƒçesk√©m trhu ji≈æ od roku 1994. Za tu dobu se vypracovala v p≈ôedn√≠ho poskytovatele ≈ôe≈°en√≠ s p≈ôidanou hodnotou v oblasti informaƒçn√≠ch technologi√≠. Spolu s poboƒçkami na Slovensku, v Maƒèarsku, Slovinsku, Chorvatsku, Srbsku, Rumunsku a ≈òecku je v√Ωznamn√Ωm partnerem znaƒçek Cisco, NetApp, F5, Microsoft, AWS a dal≈°√≠ch v regionu st≈ôedn√≠ a v√Ωchodn√≠ Evropy. Hlubok√© technologick√© znalosti jednotliv√Ωch ≈ôe≈°en√≠ umo≈æ≈àuj√≠ roz≈°i≈ôovat nejen pod√≠l samotn√Ωch slu≈æeb, ale t√©≈æ portfolio nab√≠zen√≠ch ≈ôe≈°en√≠ a znaƒçek, mezi kter√© nap≈ô√≠klad pat≈ô√≠ Splunk, AWS, Palo Alto a dal≈°√≠. T√≠m hlavn√≠m, co ALEF odli≈°uje od ostatn√≠ch je jedineƒçn√Ω p≈ô√≠stup a zamƒõstnanci, kte≈ô√≠ disponuj√≠ dlouholet√Ωmi ≈°piƒçkov√Ωmi znalostmi Co Tƒõ napadne jako prvn√≠, kdy≈æ usly≈°√≠≈° term√≠n Datov√© Centrum? Pokud jsou to vƒõci jako Cisco Nexus, VXLAN BGP EVPN, Cisco ACI, nebo REST API a DevNet, nep≈ôest√°vej ƒç√≠st, do t√Ωmu toti≈æ hled√°me nov√©ho kolegu se zamƒõ≈ôen√≠m na s√≠tƒõ a automatizaci v datov√Ωch centrech. Co tƒõ u n√°s ƒçek√°? Mo≈ænost pr√°ce na cel√©m ≈æivotn√≠m cyklu technick√Ωch projekt≈Ø: Pre-sales ‚Äì Aktivity zahrnuj√≠c√≠ prezentace a konzultace pro z√°kazn√≠ky a partnery, v√Ωbƒõr vhodn√©ho ≈ôe≈°en√≠, jeho nacenƒõn√≠, technick√° specifikace, podpora obchodn√©ho oddƒõlen√≠. Design ‚Äì Vytv√°≈ôen√≠ High-Level a Low-Level design dokumentace, kter√° detailnƒõ popisuje navrhovan√© ≈ôe≈°en√≠, spolupr√°ce v r√°mci r≈Øzn√Ωch t√Ωm≈Ø ve firmƒõ na n√°vrhu komplexn√≠ch ≈ôe≈°en√≠. Proof-of-Concept ‚Äì Ovƒõ≈ôov√°n√≠ designov√Ωch rozhodnut√≠ v intern√≠m labov√©m prost≈ôed√≠, p≈ô√≠padnƒõ p≈ô√≠mo u z√°kazn√≠ka Implementace ‚Äì Konfigurace za≈ô√≠zen√≠ podle navrhovan√©ho designu, ladƒõn√≠ a testov√°n√≠ dod√°van√©ho ≈ôe≈°en√≠ Post-implementaƒçn√≠ podpora ‚Äì Oprava nestandardn√≠ch stav≈Ø, chyb, konzultace, dal≈°√≠ rozvoj z√°kaznick√© infrastruktury ≈†kolen√≠ ‚Äì P≈ôed√°v√°n√≠ znalost√≠ a zku≈°enost√≠ z√°kazn√≠k≈Øm, partner≈Øm ƒçi koleg≈Øm prost≈ôednictv√≠m odborn√Ωch kurz≈Ø a konzultac√≠ se zamƒõ≈ôen√≠m na s√≠tƒõ v datov√Ωch centrech a souvisej√≠c√≠ technologie Pr√°ce s nejmodernƒõj≈°√≠mi (nejenom) s√≠≈•ov√Ωmi technologiemi Pr√°ce v kolektivu ≈°piƒçkov√Ωch odborn√≠k≈Ø a CCIE technik≈Ø ≈†irok√° paleta mo≈ænost√≠ a podpora sebevzdƒõl√°v√°n√≠ a rozvoje Co bys mƒõl umƒõt a zn√°t? Obecn√© znalosti s√≠t√≠ a TCP/IP stacku minim√°lnƒõ na √∫rovni CCNP Technologie druh√© vrstvy (Ethernet, VLAN, STP, Port-channel, ‚Ä¶) Technologie t≈ôet√≠ vrstvy (IPv4, IPv6, ARP, ICMP, BGP, OSPF, VRF, multicast, redistribuce,‚Ä¶) Praktick√© zku≈°enosti s konfigurac√≠ a provozem s√≠≈•ov√Ωch prvk≈Ø spoleƒçnosti Cisco Zku≈°enosti s p≈ôep√≠naƒçi Cisco Nexus a syst√©mem NX-OS Komunikaƒçn√≠ a prezentaƒçn√≠ dovednosti v ƒåe≈°tinƒõ a Angliƒçtinƒõ Schopnost t√Ωmov√© i samostatn√© pr√°ce Pozitivn√≠ p≈ô√≠stup k ≈æivotu a pr√°ci V√Ωhoda: Znalost technologi√≠ vPC, BGP VXLAN EVPN, Cisco ACI ‚Ä¶ V√Ωhoda: Zku≈°enosti s programov√°n√≠m/skriptov√°n√≠m a pou≈æit√≠m API. V√Ωhoda: Zku≈°enosti s orchestr√°tory typu Ansible, Terraform nebo Nornir V√Ωhoda: CCNP Data Center / DevNet S√≠tƒõ v datov√Ωch centrech nejsou zase tak odli≈°n√© od klasick√Ωch enterprise s√≠t√≠ a zku≈°enosti z t√©to oblasti jsou velmi dobr√Ωm odrazov√Ωm m≈Østkem pro p≈ôepnut√≠ se do ‚ÄûDC m√≥du‚Äú A co ti m≈Ø≈æeme nab√≠dnout? Stravenkov√Ω pau≈°√°l Mo≈ænost pracovat obƒçasnƒõ z domova a neomezen√© sick days Slu≈æebn√≠ telefon a pracovn√≠ notebook, co≈æ bereme jako samoz≈ôejmost :) Work life balance n√°m nen√≠ ciz√≠. Mo≈ænost a≈æ 10 dn≈Ø dovolen√© nav√≠c dle odpracovan√© doby Roƒçn√≠ kupon na MHD, p≈ô√≠padnƒõ osobn√≠ automobil V√Ωuku anglick√©ho jazyka Mo≈ænost multisport karty V√Ωkonov√© odmƒõny Benefits Bonusy/pr√©mie Mobiln√≠ telefon Nadstandardn√≠ l√©ka≈ôsk√° p√©ƒçe Notebook P≈ô√≠spƒõvek na dopravu Stravenky/p≈ô√≠spƒõvek na stravov√°n√≠ Vzdƒõl√°vac√≠ kurzy, ≈°kolen√≠ Obƒçerstven√≠ na pracovi≈°ti Zv√Ωhodnƒõn√© p≈Øjƒçky zamƒõstnanc≈Øm Zdravotn√≠ volno/sickdays Mo≈ænost obƒçasn√© pr√°ce z domova Firemn√≠ akce plat Dog-friendly office","A leading IT solutions provider in the Czech Republic seeks a networking and automation specialist for data centers. The ideal candidate should possess practical experience in configuring and operating Cisco network devices, knowledge of networking technologies, and proficiency in English and Czech. The job involves working on technical projects' entire life cycle, from pre-sales to post-implementation support, with a team of expert CCIE technicians. The company offers an attractive package, including training opportunities, flexible working hours, health benefits, and a dog-friendly office.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
247,4941,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-dataiku-online-remote-emea_paris,Software engineer Dataiku Online - Remote EMEA,Dataiku,"{React,Dataiku,python,regard,Kubernetes,Docker,Python}",T√©l√©travail total possible,N,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online‚Äôs team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku souscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is fully remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented ‚Äî you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: - Hands-on expertise working with Docker and Kubernetes - Experience on an high availability SaaS - Knowledge in DataScience, AI and Machine Learning - Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking a full-stack developer with experience in creating real SaaS portals to join its team in charge of developing the Dataiku Online Launchpad. The role involves actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Candidates should be customer-oriented, have a humble and kind attitude, and be proficient in Python (Flask) for the backend of the launchpad and VueJS for the frontend. Bonus points for experience working with Docker and Kubernetes, high availability SaaS, knowledge of Data Science, AI and Machine Learning, and highly advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular). This is a fully remote position.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
266,56943,https://www.welcometothejungle.com/fr/companies/ecovadis/jobs/data-engineer-f-m-d_berlin_ECOVA_VQ51pWx,Data Engineer,EcoVadis,"{MongoDB,Databricks,Mongo,color,Airflow,PostgreSQL,Prometheus,DVC,scale,Azure,SQL,Python,Postgres}",T√©l√©travail total possible,Berlin,"Environnement / D√©veloppement durable, SaaS / Cloud Services, SocialTech / GreenTech",CDI,2023-03-26,"EcoVadis is the leading provider of business sustainability ratings. Their solutions are backed by an international team of experts and powerful technology. They analyze data and build sustainability scorecards that give companies actionable insights into their environmental, social and ethical risks. EcoVadis is driven by a diverse team of over 1000 talented professionals representing more than 60 nationalities. The team is based around the globe, including offices in Paris, Barcelona, London, Dusseldorf, Warsaw, Mauritius, New York, Tunis, Hong Kong, Toronto and Tokyo. They hire remotely as well. We are looking for a Data Engineer to contribute to the evolution of our IQ Plus product. IQ Plus leverages intelligence from the world‚Äôs largest sustainability performance database, customer procurement data and screening of supplier-specific documents using the latest data mining and AI technologies. In this new role, reporting to the Engineering Manager, you will work alongside a team of Data Scientists and Machine Learning Engineers. Your will: Build and maintain a distributed data pipeline architecture that can process large volumes of data from multiple sources with high availability and low latency. (MongoDB, Postgres, Prometheus related data extraction processes) Implement data quality checks to ensure data consistency, completeness, and accuracy. (Cleaning data from MongoDB, Postrgres, Google Storage etc) Design and maintain data models and schema structures to support analytics and reporting needs. (Any changes to Mongo, Logging etc) Collaborate with data scientists to develop data pipelines for machine learning models and data science operations. Design and implement data processing workflows for log data to enable effective analysis and visualization. Build and maintain data visualization and monitoring tools to track system performance and detect anomalies. Additional Information Location: Berlin / Remote in Germany Start date: ASAP Everyone at EcoVadis contributes to a culture of trust, respect and empowerment. Our growing team in Germany is full of talented professionals from various sectors who all share a desire to make an impact. We offer competitive salaries and support personal growth from day one with extensive onboarding, mentoring and a brand new e-learning platform bursting with courses and modules so you can learn new skills and fine-tune old ones. Benefits: ‚Ä¢ Support with all the necessary office and IT equipment ‚Ä¢ Wellness allowance for mental and physical wellbeing ‚Ä¢ Annual performance bonus ‚Ä¢ Remote work from abroad policy ‚Ä¢ Flexible working hours ‚Ä¢ Hybrid/ full remote work ‚Ä¢ Health coverage and optional pension scheme ‚Ä¢ Internet and electricity bill allowance ‚Ä¢ CSR activities ‚Ä¢ Subsidized travel and BahnCard 50 ‚Ä¢ Community service day when volunteering. Our hiring team looks forward to reviewing your CV, in English, with a guaranteed response to every application. A new job with purpose awaits you! Don‚Äôt fit all the criteria but still think you‚Äôd be a good candidate? Please apply anyway to give our hiring team the opportunity to assess your skills and to learn more about what you could bring to EcoVadis. We‚Äôre interested in hiring capable people, regardless of professional and educational background. Can the hiring process be adjusted to suit my needs? Yes. We want everyone going through the hiring process with EcoVadis to feel confident that you are able to demonstrate your full potential. We welcome applications from disabled people, people with long-term health conditions, and neurodiverse candidates. If you need any adjustments, including the provision of interview questions, please let the hiring team know. Our team‚Äôs strength comes from everyone‚Äôs uniqueness and is founded upon mutual respect. EcoVadis commits to equity, inclusion and reducing bias in our hiring processes. EcoVadis does not accept any form of discrimination based on color, national or ethnic origin, ancestry, citizenship, religion, beliefs, age, sex, gender identity, sexual orientation, neurodiversity, disability, parental status, or any other protected characteristic that makes you unique. In your application, we encourage you to remove personal information such as: photographs, marital status, number of children, religion, gender, residential postal code, university graduation date, past medical or parental leave(s) taken, nationality (instead, please state if you are legally eligible to work in the job region/country), university name (instead, please state any degrees obtained and the study major). Experience in data modeling, pipelines, data warehousing, and transformation of large-scale data sources Experience building ETL processes, data pipelines and orchestrators (e.g. Airflow, DVC) Extensive experience in No-SQL databases (MongoDB) and SQL (PostgreSQL) Systems-level understanding of Machine Learning concepts and technologies Optimize data storage and retrieval processes using cloud-based solutions such as Azure and Databricks Develop and implement data analytics workflows using Python, SQL, or other programming languages","EcoVadis is hiring a Data Engineer to work with their team of Data Scientists and Machine Learning Engineers, contributing to the evolution of their IQ Plus product. The successful candidate will build and maintain a distributed data pipeline architecture, implement data quality checks and design and maintain data models and schema structures. They should have experience in data modeling, ETL processes, data pipelines, and data warehousing, as well as extensive experience with No-SQL databases and SQL.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,3,1,0.05539549888311683
238,64302,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris_TDF_pP7ANV8,Data Engineer,TotalEnergies Digital Factory,"{AWS,via,Spark,Azure,SQL,Python}",T√©l√©travail total possible,"31 rue des Jeuneurs, Paris, 75002","Logiciels, Big Data, Energie",CDI,2023-04-03,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. TotalEnergies a d√©cid√© d'acc√©l√©rer la production interne de solutions digitales pour ses activit√©s en cr√©ant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilit√© et l'esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Nous cr√©ons et d√©ployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. Nous consid√©rons les personnes comme la ressource la plus pr√©cieuse pour r√©ussir, c'est pourquoi nous tenons non seulement √† recruter les meilleurs talents, mais aussi √† cr√©er des liens uniques entre nos employ√©s. Rejoins-nous en plein c≈ìur de Paris en tant que Data Engineer et int√®gre la tribu Bemo Tech qui d√©veloppe la plateforme de mobilit√© Bemo. Cette plateforme connecte des r√©seaux de mobilit√© (bornes de recharge pour v√©hicules √©lectriques et stations-service) et les solutions √† destination des conducteurs via leur app ou leur v√©hicule connect√© pour une mobilit√© plus connect√©e, plus partag√©e, plus responsable. Au sein de la tribu Bemo Tech, tu rejoindras en particulier la Squad ¬´ Data Places ¬ª en tant que Data engineer, l'une des 6 Squads de Bemo Tech. Ta Squad ¬´ Data Places ¬ª est en charge de la collecte, de la normalisation et de l'enrichissement des donn√©es utilis√©es par la plateforme de mobilit√© pour offrir la meilleure exp√©rience client. Un autre aspect de ton r√¥le est de travailler avec l'entit√© business de Bemo pour pr√©parer les datasets n√©cessaires au reporting et √† l'activit√© d'intelligence √©conomique. En tant que Data Engineer, tu garantis la qualit√© des pipelines data du produit, tu assures le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es. Dans l'√©cosyst√®me ultra dynamique des nouvelles mobilit√©s (notamment √©lectriques), en phase avec de grands enjeux soci√©taux, nous attendons de toi que tu : Con√ßoives, construises et int√®gres des donn√©es au sein de la Squad et en collaboration avec les autres Squads. Assures le stockage, la consommation, l'int√©gration et la gestion des donn√©es des cas d'utilisation. Fasses l'analyse de l'analyse de l'accessibilit√© des donn√©es et que tu recommandes des solutions pour leur int√©gration. Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de donn√©es. Tu int√®gres √©galement les donn√©es dans le data lake. Collabores avec les data scientists pour la r√©alisation des mod√®les de pr√©diction. Produises un code de qualit√©, mettes en place des tests automatis√©s et syst√©matiques pour le contr√¥ler. Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacit√© des solutions et apporter des pr√©conisations techniques. En parall√®le, tu auras √©galement des missions transverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies Coaches et accompagnes la communaut√© des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une exp√©rience d'au moins 4 ans en data engineering, tu es dipl√¥m√© d'un master ou d'une √©cole d'ing√©nieur sp√©cialis√©e en informatique ou math√©matiques. Et si tu as d√©j√† une exp√©rience dans l'√©cosyst√®me de la mobilit√©, de la recharge √©lectrique ou du digital fueling, c'est top ! Les comp√©tences qui sont attendues de toi en tant que Data Engineer La maitrise de Python, Spark et SQL. Une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles. La capacit√© √† concevoir et √† mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle Ma√Ætrise des bonnes pratiques de monitoring des flux de donn√©es. Une bonne compr√©hension du machine learning. Une bonne connaissance des m√©thodes Agile (Scrum, Kanban, voir m√™me SAFe ou Nexus). Une culture tech tu sais concevoir et mod√©liser une solution informatique. Si tu as toi-m√™me de bonnes notions de d√©veloppement, c'est un plus notable (stack technique : Cloud Azure ou AWS, C#, .Net) Une exp√©rience avec les outils de gestion de Backlog comme Jira ou Azure DevOps. Si tu en connais plusieurs, c'est encore mieux. Une premi√®re exp√©rience sur un provider de Cloud, AWS de pr√©f√©rence.","The TotalEnergies Digital Factory is seeking a Data Engineer to join the Bemo Tech tribe, responsible for creating and deploying digital solutions across TotalEnergies sites to provide clean, reliable, and affordable energy. The Data Engineer will work within the ""Data Places"" squad, responsible for collecting, normalizing, and enriching data for the mobility platform. The ideal candidate will have at least four years of data engineering experience, expertise in Python, Spark, and SQL, and a good understanding of big data processing and machine learning. A background in the mobility or digital fuelling ecosystem is a plus.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,3,1,0.05539549888311683
242,57152,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-talend-big-data-h-f_levallois-perret,Data Engineer / Talend Big Data,Micropole,"{Microsoft,durable,Talend,Scala,AWS,R,Spark,GCP,SQL}",T√©l√©travail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√© : Poste : Data Engineer Talend Big Data Localit√© : Levallois-Perret Type de contrat : CDI Niveau d‚Äôexp√©rience : au moins 3 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services. Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! Au sein de notre agence bas√©e √† Levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vousaccompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leurprocessus et dans leur strat√©gie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amen√©(e) √†‚ÄØ: D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions Cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence. Vos comp√©tences techniques : Vous avez un minimum de 3 ann√©es d‚Äôexp√©rience sur des projets Data avec Talend Spark ou SSIS. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala ou SQL)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ; Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visio Etape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) LA VIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ; Participation √† des projets internes sur la base du volontariat. #LI-DM1 Comp√©tences SQL Scala Spark Talend SSIS","Micropole, a digital transformation accelerator, is seeking a data engineer with at least three years of experience in Talend Big Data. The ideal candidate must be passionate about data and optimization, possess comprehensive knowledge of data modelling and analysis, and constantly updated with new tech solutions. The successful candidate will join Micropole's expert cloud team in Levallois-Perret, helping businesses with data-driven digital transformation, modelling and analysing data, and providing consultation and support in security and compliance.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
240,56815,https://www.welcometothejungle.com/fr/companies/klanik/jobs/data-ingenieur-spark-scala_paris,Data ing√©nieur SPARK & SCALA,KLANIK,"{via,ORACLE,SPARK,SCALA}",T√©l√©travail partiel possible,"37 Rue Etienne Marcel, Paris, 75002","Logiciels, IT / Digital, Formation",CDI,2023-03-26,"KLANIK est une soci√©t√© de conseil en Ing√©nierie IT qui accompagne ses clients dans leurs projets digitaux et technologiques. Le groupe KLANIK compte d√©sormais plus de 750 talents, √©voluant dans 16 agences en Europe, Am√©rique du Nord, Afrique et Moyen-Orient. Des experts engag√©s, atypiques et passionn√©s, impliqu√©s dans des projets strat√©giques gr√¢ce √† leur haut niveau de comp√©tences en Software, DevOps, Cloud, Agilit√©, Cybers√©curit√©, Big Data & IA. En parall√®le de leurs m√©tiers, les collaborateurs du groupe KLANIK sont accompagn√©s au quotidien dans leur d√©veloppement personnel et professionnel, via diff√©rentes initiatives engageantes et innovantes : KONSCIOUS : communaut√© interne engag√©e dans les enjeux √©cologiques, sociaux et environnementaux KAMPUS : institut de formation technique certifi√© KORNER : incubateur de start-ups technologiques KLANIK ESPORT : club professionnel e-sport ouvert aux collaborateurs Au sein de l‚Äô√©quipe projet Business Intelligence & Big Data, l‚Äôexpert SPARK/SCALA aura les activit√©s suivantes : - Conception d√©taill√©e, fonctionnelle et technique. - D√©veloppements SPARK / SCALA - Contribution √† la formalisation des plans de tests, ex√©cution des tests unitaires et d‚Äôun premier niveau de tests d‚Äôint√©gration. - R√©solution des anomalies pendant les phases d‚Äôint√©gration fonctionnelle et de recette utilisateur. - Packaging et d√©ploiement en pre-production et production. - Optimisation des traitements afin de garantir la qualit√© de service standards du DWG. - Mise en ≈ìuvre des solutions industrielles et de r√©entrance permettant une reprise optimum des traitements en cas d‚Äôincident en production. - Mise en service et accompagnement au d√©ploiement. - Suivi des environnements. Le consultant devra travailler en √©troite collaboration avec le Chef de Projet, responsable du lot et l‚Äô√©quipe de d√©veloppement du Programme. Vous √™tes la bonne personne si pour vous la qualit√©, la maintenabilit√© et la performance sont des sujets primordiaux. Mais √©galement une exp√©rience de minimum 5 ans sur les technologies suivantes : SPARK SCALA Avec une bonne connaissance de l‚Äôapplication ORACLE Le processus d√©marre par un premier entretien avec un.e HR puis un entretien technique avec l‚Äôun de nos experts, ensuite vient la rencontre avec le ou la Business Manager en charge de l‚Äôoffre.","KLANIK is looking for an experienced expert in SPARK/SCALA with a minimum of 5 years' experience in these technologies and a good knowledge of the Oracle application. The role involves detailed design, development, testing, packaging, deployment, and optimization of processes to ensure quality of service standards. The consultant will work closely with the project manager and development team. KLANIK offers innovative initiatives for personal and professional development such as KONSCIOUS, KAMPUS, KORNER, and KLANIK ESPORT.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
241,56491,https://www.welcometothejungle.com/fr/companies/esens-consulting/jobs/ingenieur-big-data-senior_paris,Data Engineer (confirm√©) - Hadoop | Spark | MongoDB,ESENS,"{MongoDB,DynamoDB,Scala,portable,Kafka,R,Cassandra,Spark,Elasticsearch,Hadoop,Python}",T√©l√©travail partiel possible,"40 Rue du Colis√©e, Paris, 75008",IT / Digital,CDI,2023-03-26,"ESENS accompagne l‚Äôinnovation technologique de ses clients et l‚Äô√©volution professionnelle de ses √©quipes √† Paris, Lille, Bordeaux, Nantes, Lyon, Rennes et Caen. Web, Mobile, DevOps, Design, Data, BI, QA et MOA, ESENS r√©pond aux besoins Web, Mobile, IoT, Design, DevOps et Big Data des entreprises dans tous les secteurs d‚Äôactivit√©. En tant que prestataire de services en technologie num√©rique, Lab de R&D, agence digitale, partenaire associatif impliqu√© dans de nombreuses causes (environnement, sant√©, lutte contre la fracture num√©rique, soutien scolaire, insertion professionnelle des jeunes issus des quartiers, soutien √† la transformation num√©rique des petits commerces‚Ä¶) ou encore sponsor de jeunes talents sportifs, nous avons √† c≈ìur de nous investir dans des projets qui ont du sens pour tous. C‚Äôest notre fa√ßon d‚Äôinnover, d‚Äô√©largir nos univers, d‚Äôenrichir les connaissances et les possibilit√©s de chacun, de construire un futur dans lequel tous se retrouvent et de faciliter l‚Äô√©panouissement professionnel et personnel de celles et ceux qui se reconnaissent et s‚Äôinscrivent avec nous dans cet √©tat d‚Äôesprit d‚Äô√©quipe, de d√©couverte, d‚Äôentraide, de partage et d‚Äô√©change. En tant que Data Engineer chevronn√©.e, rejoins nos √©quipes sur des projets pour l‚Äôensemble des clients d‚ÄôESENS, qu‚Äôils soient start-up ou leader de leur march√©. Pr√©sents dans tous les secteurs d‚Äôactivit√©, nous te proposons de d√©velopper des projets √† long terme (2 √† 3 ans) sur des stacks modernes et pens√©s ‚Äòsur-mesure‚Äô en fonction de tes app√©tences techniques et personnelles. Nos objectifs ? Te proposer des nouveaux challenges qui r√©pondent √† tes attentes et assurer ta mont√©e en comp√©tence entour√©.e de v√©ritables passionn√©s de dev. Chez ESENS, nous sommes investis en continu dans le suivi et l‚Äôaccompagnement personnalis√© de chacun des membres de notre √©quipe et nous sommes convaincus que prendre du plaisir au travail est l‚Äôune des clefs principales de la satisfaction de nos salari√©s et de nos clients ! Tech Specs : Salaire fixe + variable Prime(s) Ordinateur portable Acc√®s au programme de formation interne et externe Organisation de travail flexible : pr√©sentiel, t√©l√©travail, travail hybride, on en discute ? Excellente couverture sant√© en partenariat avec Generali Une vie d‚Äôentreprise et associative riche en √©v√©nements ! Issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôune formation Bac +5 √©quivalente, et avec au minimum 5 ann√©es d‚Äôexp√©rience dans la mise en place d‚Äôarchitecture cloud et de projets data, tu es d√©j√† lead sur le plan technique. De nature curieuse, dynamique, en constante veille technologique, tu souhaites te challenger en continu dans un contexte d‚Äôinnovation et aux c√¥t√©s d‚Äôune √©quipe aussi passionn√©e que toi pour faire √©voluer tes comp√©tences et continuer de tracer ton parcours professionnel. Ton esprit de synth√®se et tes capacit√©s √† structurer ton raisonnement seront des qualit√©s √©galement tr√®s appr√©ci√©es ! Aujourd‚Äôhui, tu es a la recherche d‚Äôun nouveau projet qui allie management, technique, esprit d‚Äô√©quipe et mont√©e en comp√©tences tout en respectant l‚Äô√©quilibre pro / perso. Ta stack de pr√©dilection : Hadoop, Spark, Kafka MongoDB, Cassandra, DynamoDB Python, R, Scala, Elasticsearch Machine Learning, Deep Learning Int√©gration dans le Cloud Sans oublier un bon niveau d‚Äôanglais ! Tu as poursuivi ta lecture jusqu‚Äôici ? Nous sommes par cons√©quent √† quelques jours de notre rencontre dans nos locaux WeWork parisiens situ√©s 40 rue du Colis√©e, √† deux pas des Champs Elys√©es : Rooftop en plein centre de Paris avec vue sur la tour Eiffel Open Bar √† Bi√®re Acc√®s aux espaces WeWork du monde entier Lors de notre premi√®re rencontre, nous nous ferons un plaisir de te pr√©senter ESENS, de te parler de nos √©quipes et de notre projet d‚Äôentreprise. Ce sera aussi, bien s√ªr, l‚Äôoccasion de discuter de ton parcours et d‚Äô√©valuer tes attentes, tes motivations et tes souhaits d‚Äô√©volution. Un second entretien nous permettra de valider tes comp√©tences techniques, fonctionnelles et manag√©riales. Ce sera √©galement l‚Äôoccasion de te faire rencontrer un ou plusieurs membres de notre √©quipe pour √©changer sur diff√©rents contextes de missions et sur le poste propos√©. Pour cl√¥turer notre process de recrutement, tu rencontreras les membres de la direction pour une validation finale qui nous permettra de concr√©tiser notre proposition de collaboration. Bienvenue chez ESENS !","ESENS is seeking an experienced Data Engineer to work on long-term projects for their clients, both startup and leaders in their respective market. The company offers a flexible working environment, personalized support, and continuous training to ensure career growth. The ideal candidate should have a minimum of 5 years of experience in cloud architecture and data projects, as well as expertise in Hadoop, Spark, Kafka, MongoDB, Cassandra, DynamoDB, Python, R, Scala, Elasticsearch, Machine Learning, Deep Learning, and Cloud Integration. The position offers a fixed salary with bonuses, a laptop, access to internal and external training programs, and an excellent health plan. The company also values work-life balance and offers a rich company and associative life with various events.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 5 ans,2,1,0.04154662416233763
272,60442,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer_rouen,Data Engineer,Groupe SII,"{Informatica,Talend}",T√©l√©travail partiel possible,Rouen,IT / Digital,CDI,2023-03-28,"Le Groupe SII est une soci√©t√© de conseil en technologies implant√©e dans 18 pays au travers de 100 implantations. Plus de 13 000 collaborateurs interviennent quotidiennement sur les probl√©matiques de transformation num√©rique des grands-comptes. Une entreprise o√π il fait bon travailler. Labellis√©e Great Place To Work pour la 5√®me ann√©e cons√©cutive, SII m√®ne de nombreuses actions li√©es √† la qualit√© de vie au travail. Nous recherchons un(e) Data Engineer (H/F) pour accompagner les d√©veloppements faits aupr√®s des applications de l‚Äôun de nos clients Grand Compte.
En mode Agile et organis√©e en "" Feature Team "", l'√©quipe technophile vous permettra de participer √† toute la chaine projet. En qu√™te de d√©fis techniques ? Alors n‚Äôh√©sitez plus, postulez ! Votre mission : Pr√©parer les donn√©es √† traiter, Analyser les mod√®les, Concevoir des algorithmes, Programmer en back-end, Interpr√©ter et pr√©senter les r√©sultats, Mettre en production des solutions. Votre profil : Dipl√¥m√©(e) d‚Äôun Bac+5 en informatique, math√©matique ou statistique (Grandes Ecoles, Universit√©s), vous justifiez d'au moins une premi√®re exp√©rience significative dans le traitement de donn√©e avec utilisation ou connaissance d‚Äôun ETL (Talend ou Informatica).Vous √™tes curieux(se), investi(e) et surtout passionn√©(e) par le monde du web. Vous savez travailler en √©quipe et vous vous int√©grer rapidement, vous √™tes autonome, organis√©(e) et rigoureux (se), bon communiquant et dou√©(e) du sens de l'√©coute. Qui sommes-nous ? Le Groupe SII est au coeur de l‚Äôinnovation au service de grands comptes dans des secteurs d‚Äôing√©nierie vari√©s. En 2022, nous avons √©t√© labellis√©s Great Place To Work pour la 5e ann√©e cons√©cutive et reconnus 3e entreprise de ¬´ + de 2500 salari√©s ¬ª o√π il fait bon vivre. Nous sommes tr√®s fiers d‚Äôobtenir cette reconnaissance de nos salari√©s ! Ce succ√®s est le reflet de notre culture bas√©e sur notre volont√© de proposer √† tous nos salari√©s un cadre de travail √©panouissant pour le d√©veloppement de leurs comp√©tences et carri√®res. Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la cr√©ativit√©, la proximit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur. Notre nouvel accord t√©l√©travail permet de l‚Äôappliquer jusqu‚Äô√† 50% de notre temps de travail en fonction de la mission. Le Groupe SII est une soci√©t√© handi-accueillante, signataire de la Charte de la diversit√© en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous ! Comp√©tences requises : Informatica, Talend. Qualit√©s d√©sir√©es : Esprit de synth√®se, Adaptabilit√©, Capacit√©s d'analyse, Autonomie, Bon relationnel, Organisation, Qualit√©s r√©dactionnelles, R√©activit√©. Avantages : Tr√®s bon CSE, Mutuelle et pr√©voyance, Tickets restaurant, Places en cr√®che, Participation aux b√©n√©fices de l'entreprise, Participation aux frais de transport, Primes de cooptation, T√©l√©travail.","SII is seeking a skilled Data Engineer to work on development projects for one of its major customers. The position requires the candidate to have a degree in computer science, mathematics, or statistics (Grandes √âcoles, Universities) and at least one significant experience in data processing, including knowledge of an ETL such as Talend or Informatica. The ideal candidate will be curious, passionate, organised, rigorous, and an effective team player with excellent communication skills. SII is a handi-welcoming company that offers a great workplace and numerous employee benefits, including participation in profit-sharing, teleworking opportunities and participation in transport expenses.",Bac +5 / Master,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
308,57087,https://www.welcometothejungle.com/fr/companies/maltem/jobs/data-engineer-h-f_bordeaux,Data Engineer,Maltem,"{Airflow,S3,Kafka,Spark,Java,Hadoop}",T√©l√©travail partiel possible,"41, Rue Bergeret, Bordeaux, 33000","Organisation / Management, Big Data, Cybers√©curit√©",CDI,2023-03-26,"Fond√© en 2001 par Jean-Luc Clamen et Pascal Mennesson, Maltem est un groupe expert en conseil transformation digitale et de l‚Äôinnovation qui rassemble aujourd‚Äôhui plus de 1 100 collaborateurs, r√©partis dans 12 pays. L‚Äôactivit√© du groupe couvre un large champ de comp√©tences, organis√©es en communaut√©s : Consulting, Data, Agility, Dev, Design Experience et Cyber Security avec une expertise sp√©cifique dans les domaines de la banque, de l‚Äôassurance, de l‚Äô√©nergie et des m√©dias. üëÄ Qui sommes-nous ? Depuis son lancement en 1999, OMNILOG met au c≈ìur de ses priorit√©s l‚Äôaccompagnement, la proximit√© et la stabilit√© de ses collaborateurs afin de permettre √† ses √©quipes de travailler dans des conditions id√©ales et de fournir un travail de qualit√©. Accr√©dit√©s par le label ‚ÄúChoosemycompany : HappyAtWork¬Æ‚Äù, nous permettons √† nos collaborateurs d‚Äô√©voluer dans un cadre professionnel id√©al : √©v√©nements, formations, missions longues, √©quilibre vie pro/vie perso, t√©l√©travail et bien d‚Äôautres. Nos clients sont des acteurs majeurs des m√©dias, du sport et du e-commerce, avec qui nous collaborons pour certains depuis plus de 10 ans (TF1, Canal+, l‚ÄôEquipe, la FFF, Bedrock, Place des Tendances, JCDecaux‚Ä¶ üß† Que recherchons nous ? Nous recherchons notre futur Data Engineer F/H afin de renforcer nos √©quipes. Le poste est situ√© √† Bordeaux, pour notre client, acteur historique en t√©l√©communications, sur un rythme de travail de 3 jours de pr√©sentiel et de 2 jours de t√©l√©travail. üí™ Tes missions seront les suivantes : Mise en place de flux de donn√©es en temps r√©elle, mais aussi en batch. Avec l‚Äô√©quipe, tu seras l‚Äôambassadeur de la qualit√© des donn√©es, de la maintenabilit√© et de la performance des flux. √âtudes du besoin des clients et proposition d‚Äôune solution technique en lien avec les attentes de celui-ci Test et d√©ploiement de la solution mise en ≈ìuvre et sa maintenance Maintenir ses comp√©tences √† jour et les faire grandir, tu auras en effet du temps d√©di√© pour ta mont√©e en comp√©tences dans une logique d‚Äôam√©lioration continue üéØ Les indispensables : Au moins 3 ans d‚Äôexp√©rience en d√©veloppement Java La maitrise du framework Spark Connaissances sur les modules Big Data (Kafka, Airflow, Hadoop, S3) ‚ù§Ô∏è‚Äç Les plus : Un esprit d‚Äô√©quipe L‚Äôenvie de d√©couvrir de nouvelles technos L‚Äôenvie d‚Äôanimer ou de participer √† des √©v√®nements au tour de la tech Une app√©tence pour le devOps et la Data Tu te reconnais et tu cherches un nouveau challenge ? N‚Äôh√©site pas √† postuler et √† nous contacter ! Notre process est le suivant : Entretien RH en visio Entretien technique Entretien projet Bienvenue dans les √©quipes","Maltem is seeking a Data Engineer with at least 3 years of experience in Java development, who has expertise in Spark framework, and knowledge of Big Data modules such as Kafka, Airflow, Hadoop, and S3. The successful candidate will be responsible for implementing real-time and batch data flows, ensuring data quality, proposing technical solutions for clients, testing and deploying solutions, and maintaining their skills through continuous improvement. A team player with a passion for learning new technologies and a desire to participate in tech events is preferred. The position will be located in Bordeaux, with a schedule of 3 days on-site and 2 days of telework.",N,N,N,2,1,0.04154662416233763
309,56594,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer-copy_barcelona,Data Engineer,Contentsquare,"{regard,Go,color,Scala,Akka,Contentsquare,Kafka,scale,Elasticsearch,Spark,R,ClickHouse,Java}",T√©l√©travail partiel possible,"Barcelona, 08007","SaaS / Cloud Services, E-commerce",CDI,2023-03-26,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team ‚Äì known as the CSquad ‚Äì representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of hard-working and dedicated developers, crafting and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at Contentsquare ! We collect several billion events per day and query hundreds of terabytes in real time. Your daily work will consist of: Crafting efficient architectures to store and analyze petabytes of data Leading large-scale projects and mentoring developers Implementing sophisticated acquisition workflows Thinking of inventive data formats to serve the functionalities of the product, while minimizing the cost Developing tools to help data-scientists ....by using some open-source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum of 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have curiosity about functional programming and seek to develop your skills in Data engineering programming languages. Ideally, you have experience with a wide range of databases and are interested in streaming. You would like to challenge yourself, developing distributed infrastructure with a real-time and data-intensive environment. You would like to share your skills and take part in technical choices. Why you should join our R&D department? Here is our R&D Manifesto We write our own story. We think for ourselves, keeping an open mind and engaging in constructive criticism. We are transparent in what we do and why we do it. We build and leverage tech expertise to answer business challenges. Learning from all experiences, we deliver continuous improvements in production. We empower all team members to have an end-to-end impact, take initiative, and bring new ideas to life. We stand together and thrive together; team spirit and solidarity matter even more than strong expertise. We live a human adventure. Why you should join Contentsquare: ‚ñ™Ô∏è We‚Äôre humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ‚ñ™Ô∏è We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ‚ñ™Ô∏è We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ‚ñ™Ô∏è Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ‚ñ™Ô∏è Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ‚ñ™Ô∏è Work flexibility: hybrid and remote work policies. ‚ñ™Ô∏è Generous paid time-off policy (every location is different). ‚ñ™Ô∏è Immediate eligibility for birthing and non-birthing parental leave. ‚ñ™Ô∏è Wellbeing allowance. ‚ñ™Ô∏è Home Office Allowance. ‚ñ™Ô∏è A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ‚ñ™Ô∏è Every full-time employee receives stock options, allowing them to share in the company‚Äôs success. ‚ñ™Ô∏è We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don‚Äôt meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is seeking a Data Engineer to join their team and develop a new data architecture using open-source technologies like Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. Candidates should have proficiency in either Scala, Java or Go, and experience with a wide range of databases and streaming. Contentsquare offers competitive benefits including remote and hybrid work policies, paid time-off, parental leave, wellbeing allowance, and stock options. The company values uniqueness and creates a culture of solidarity and team spirit.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
237,63032,https://www.welcometothejungle.com/fr/companies/everysens/jobs/data-engineering-manager-h-f_lille,Data Engineering Manager,Everysens,"{DBT,FiveTran,BigQuery,Java,Python}",T√©l√©travail partiel possible,"165 Avenue de Bretagne, Lille, 59000","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Objets connect√©s",CDI,2023-03-31,"Everysens est un √©diteur de logiciel SaaS sp√©cialis√© dans l‚Äôoptimisation des flux ferroviaires et multimodaux. Gr√¢ce √† notre solution, les plus grands industriels europ√©ens (Arkema, Total, Saint Gobain, ArcelorMittal, etc) r√©duisent leurs co√ªts de transport et l‚Äôempreinte carbone associ√©e. La logistique est devenue ces derni√®res ann√©es un terrain de jeu pour la digitalisation : IoT, IA et Digital Twin y trouvent de nombreuses applications. Nous int√©grons ces 3 technologies pour apporter visibilit√© et automatisation √† une industrie qui g√®re encore fr√©quemment ses op√©rations sur papier ou Excel. En 5 ans, nous sommes devenus le leader europ√©en du logiciel transport sur le mode ferroviaire, et avons doubl√© notre √©quipe chaque ann√©e. Nous avons gagn√© la confiance du march√© au cours de ces ann√©es, ce qui nous permet de poursuivre notre expansion internationale. Si tu veux nous aider √† forger une supply chain d√©carbon√©e, r√©siliente et collaborative : rejoins-nous ! L‚Äô√©quipe Data Engineering Cette √©quipe d‚Äôune dizaine d‚Äôing√©nieur (Java Backend Software Engineers, Data Engineers, Data Scientist, EDI Integration Engineer) a pour mission de d√©velopper et maintenir nos solutions autour de la DATA, regroupant la gestion des ‚ÄúDigitals Twins‚Äù, de la Data Visualization, de l‚ÄôIA, et des √©changes EDI. La stack technique de l‚Äô√©quipe : Java - Spring Boot / DBT / FiveTran / BigQuery / Toucan Toco / Gravitee / Python. La mission Ta mission consistera, sous la responsabilit√© du VP of Engineering et en lien direct avec les √©quipes produit et direction technique, √† : PEOPLE MANAGEMENT F√©d√©rer ton √©quipe pour atteindre les objectifs; Assurer le suivi de carri√®re de tes collaborateurs; Assurer le coaching de tes collaborateurs; Recruter les bonnes personnes. DELIVERY MANAGEMENT Assurer l‚Äôalignement avec les √©quipes Produit, Projet, Direction Technique et les autres managers de l‚ÄôEngineering; Valider les sp√©cifications entrantes; R√©aliser la planification des t√¢ches de l‚Äô√©quipe et l‚Äôadapter d√®s que n√©cessaire; Assurer l‚Äôorganisation et l‚Äôanimation quotidienne des collaborateurs. Assurer la connaissance et le respect du processus de production au sein de l‚Äô√©quipe; Assurer le respect des engagements de livraisons; Identifier et mettre en oeuvre les axes d‚Äôam√©lioration de la performance de l‚Äô√©quipe; Assurer la mise en place des indicateurs et le reporting r√©gulier associ√©. TECHNICAL MANAGEMENT Accorder une partie de ton temps aux aspects techniques avec l‚Äôobjectif d‚Äôam√©liorer les pratiques et la performance de l‚Äô√©quipe; Lorsque n√©cessaire, arbitrer les d√©cisions techniques; Garantir la qualit√© technique des livrables de l‚Äô√©quipe en s‚Äôassurant du respect des normes de l‚Äôentreprise. Participer activement aux guildes Backend-Java & Data. Notre ambition, faire de la technologie un atout pour notre croissance. Nos valeurs : Bienveillance, Curiosit√©, Excellence et Esprit d‚Äô√©quipe Tu as travaill√© au moins 5 ans dans le d√©veloppement logiciel et le domaine de la Data et tu as une premi√®re exp√©rience en management. Tes comp√©tences sont : La gestion et le management d‚Äô√©quipe IT dans un contexte multi-projets La mise en place et l‚Äôapplication de processus et de bonnes pratiques Une expertise technique Java et dans au moins un domaine de la Data Une facilit√© de la compr√©hension du m√©tier Tu es un facilitateur capable d‚Äô√©coute et d‚Äôassertivit√©, tu sais trouver rapidement des solutions et recherche constamment l‚Äôam√©lioration. Proactif et bon communicant, tu d√©montres un r√©el leadership et tu es reconnu comme un interlocuteur exigeant et fiable. Nous offrons Poste bas√© √† Lille, tu b√©n√©ficieras de l‚Äôenvironnement stimulant d‚ÄôEuratechnologies au c≈ìur de la French Tech‚Äô Lilloise ! Le t√©l√©travail peut faire partie de ton quotidien. Enfin, tu travailleras au sein d‚Äôune √©quipe o√π la bienveillance est une Valeur Essentielle. 1. Un entretien de pr√©-qualification de 15 minutes pour valider l‚Äôad√©quation de ton profil au poste recherch√© 2. Un entretien avec notre VP of Engineering 3. Un call avec notre CEO","Everysens, a SaaS software publisher specializing in railway and multimodal flow optimization, is seeking a Data Engineering Manager. The successful candidate should have over five years of experience in software development and data management with previous management experience. The position requires technical knowledge of Java and at least one domain of data, as well as experience in IT team management. Responsibilities include organizing and leading a team, overseeing processes, and ensuring the quality of deliveries while focusing on improving performance. The company offers a position based in Lille with the possibility of telecommuting and a stimulating environment at the heart of French Tech.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 5 ans,2,1,0.04154662416233763
311,56302,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-snowflake-h-f_lyon,Data Engineer snowflake,CGI,"{Talend,Scala,GitLab,Tibco,jenkins,AWS,Snowflake,Informatica,Spark,SQL,Python}",T√©l√©travail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous travaillerez en partenariat avec nos clients pour la livraison de leur parcours de transformation digitale sur des projets √† la fine pointe de la technologie, au d√©veloppement de plateformes analytiques ¬´ nouvelle g√©n√©ration ¬ª dans le cloud. A ce titre vous serez amen√© √† : ‚Ä¢ Appr√©hender le contexte et les enjeux M√©tier du client ; ‚Ä¢ Analyser les besoins fonctionnels et d√©terminer le mod√®le de donn√©es n√©cessaire ; ‚Ä¢ Participer aux conceptions d‚Äôarchitecture de base de donn√©es relationnelles et non-relationnelles, les entrep√¥ts de donn√©es et les lacs de donn√©es ¬´ big data ¬ª. ‚Ä¢ D√©ployer en production des solutions analytique de donn√©es, enti√®rement op√©rationnelle sur une plateforme Snowflake. ‚Ä¢ Accompagner √† l'optimisation de stockage, la r√©plication et transformation des donn√©es, et l‚Äôoptimisation de performance. ‚Ä¢ Participer √† la vie de la communaut√© Data. ‚Ä¢ De formation Bac +5, sp√©cialis√©e en informatique, vous justifiez d'une premi√®re exp√©rience d'au moins 2 ans au sein d'une √©quipe client ou un projet dans la mise en ≈ìuvre de solutions autour de la Data. ‚Ä¢ Ma√Ætrise des m√©thodes d‚Äôint√©gration de donn√©es ETL et ELT ‚Ä¢ Ma√Ætrise d‚Äôun ou plusieurs outils d‚Äôint√©gration de donn√©es serait un plus (Talend, Informatica cloud, Tibco, etc.) ‚Ä¢ Exp√©rience pratique sur Snowflake, Snowpipe, SnowSQL. ‚Ä¢ Solide connaissance dans le cloud AWS. ‚Ä¢ Exp√©rience en programmation avec Python, SQL, Scala ou Spark. ‚Ä¢ Exp√©rience Devops (GitLab, jenkins, etc.) ‚Ä¢ Vous aimez √©voluer dans des contextes internationaux, avec une tr√®s bonne maitrise du fran√ßais et de l'anglais √† l‚Äô√©crit comme √† l‚Äôoral. Atouts pour ce poste : ‚Ä¢ Certifications Snowpro, AWS. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, is looking for a Data Integration Consultant to work with clients on cutting-edge technology projects. The ideal candidate should have experience in data integration and modeling, cloud technologies (particularly AWS), programming languages (Python, SQL, Scala, or Spark), and DevOps practices. Certifications in Snowflake and AWS would be advantageous. Fluency in both French and English is mandatory, and CGI is an inclusive employer attentive to the well-being and career development of all employees, including those with disabilities and LGBT+ individuals.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
250,56996,https://www.welcometothejungle.com/fr/companies/dgse/jobs/data-engineer-h-f_paris,Data engineer,Direction G√©n√©rale de la S√©curit√© Ext√©rieure,"{Jenkins,Scala,bash,Storm,Kafka,Spark,Git,Java,Python}",T√©l√©travail partiel possible,"Paris, 75001","Strat√©gie, Cybers√©curit√©, Administration publique",CDD / Temporaire,2023-03-26,"La DGSE est le service secret fran√ßais. Sa mission ? Recueillir des renseignements dans le monde afin de fournir aux autorit√©s politiques la meilleure compr√©hension possible des situations qu‚Äôelles ont √† traiter. Ses 7 000 agents ≈ìuvrent dans l‚Äôombre pour connaitre et anticiper les menaces venant de l‚Äô√©tranger. Du contre-terrorisme √† la cybers√©curit√©, ils agissent pour prot√©ger la France et les fran√ßais. La Direction G√©n√©rale de la S√©curit√© Ext√©rieure, DGSE, recrute un Data engineer (H/F). Le poste est situ√© √† Paris. La nationalit√© fran√ßaise est obligatoire. Domaine m√©tier Sciences et Technologies Votre environnement de travail Int√©gr√© au sein d‚Äôune √©quipe d‚Äôune dizaine de personnes, organis√©e en projets avec une gestion agile, vous d√©veloppez et d√©ployez des algorithmes de traitement en streaming et en batch, construits autour des technologies Big Data open-source majeures (Kafka, Spark, Storm). Les volum√©tries trait√©es imposent d‚Äôexploiter pleinement les capacit√©s offertes par ce type de technologie, notamment en cherchant √† optimiser leur fonctionnement de base pour passer √† l‚Äô√©chelle. L‚Äô√©quipe ma√Ætrise int√©gralement le d√©veloppement, le d√©ploiement, l‚Äôoptimisation et l‚Äôexploitation des clusters. Vos missions Vous serez en charge de plusieurs activit√©s parmi les suivantes : ‚Ä¢ impl√©menter, optimiser et maintenir des algorithmes de traitement de donn√©es distribu√©s (Scala, Spark, Java), ‚Ä¢ participer √† l‚Äô√©volution de l‚Äôarchitecture, en int√©grant de nouveaux composants (frameworks, biblioth√®ques, ‚Ä¶) permettant de mieux r√©pondre aux besoins, ‚Ä¢ assurer une veille technologique constante pour rester au plus haut niveau et garantir une ad√©quation des clusters existants avec l‚Äô√©tat de l‚Äôart du domaine, ‚Ä¢ interagir avec l‚Äô√©quipe SRE/Devops pour am√©liorer la fiabilit√© des architectures et l‚Äôautomatisation des d√©ploiements. Les plus de l‚Äôoffre ‚Ä¢ Diversit√© des projets ‚Ä¢ Absence de routine ‚Ä¢ Contexte d‚Äôactivit√©s unique Titulaire d‚Äôun dipl√¥me informatique, niveau master universitaire ou √©cole d‚Äôing√©nieur. Data engineer junior, senior ou lead d‚Äô√©quipe. Vous devez poss√©der les comp√©tences et qualit√©s suivantes : ‚Ä¢ bonnes connaissances fondamentales logicielles (Structures de donn√©es, algorithmique, architecture), ‚Ä¢ ma√Ætrise d‚Äôau moins un langage parmi : Scala, Java, Python, ‚Ä¢ connaissances des bonnes pratiques de l‚Äôint√©gration continue (Jenkins/Travis) et des processus de d√©veloppement (Git, code review, ‚Ä¶), ‚Ä¢ connaissances suppl√©mentaires appr√©ci√©es : scripting bash, gestion de configuration (Puppet, Ansible, Chef), ‚Ä¢ passion pour les nouvelles technologies. Envoyez-nous votre candidature √† l‚Äôadresse : recrutement.scientifique01@intradef.gouv.fr Plus d‚Äôinformation sur www.dgse.gouv.fr > Nous rejoindre. RESTER DISCRET SUR VOTRE CANDIDATURE A LA DGSE","The DGSE is recruiting a data engineer in Paris to develop and deploy streaming and batch processing algorithms using open-source Big Data technologies such as Kafka, Spark, and Storm. The successful candidate will implement, optimize, and maintain distributed data processing algorithms and remain up-to-date with the latest technological developments. The ideal candidate should have a university master's degree or engineering degree, competence in Scala, Java, or Python, proficiency in continuous integration (Jenkins/Travis), and a passion for new technologies. The role requires French nationality and offers the opportunity to work on diverse projects within a unique context of activities.",Bac +5 / Master,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
312,56723,https://www.welcometothejungle.com/fr/companies/hove/jobs/data-engineer-lyon-h-f_paris,Data Engineer - Lyon -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilit√©, SaaS / Cloud Services",CDI,2023-03-26,"Hove est un acteur incontournable de la data-mobilit√©, en plus d‚Äô√™tre une filiale de Keolis. Depuis sa cr√©ation il y a 24 ans, Hove est un acteur cl√© dans ce domaine et l‚Äôun des premiers experts. Il occupe une place consid√©rable dans l‚Äô√©cosyst√®me de la mobilit√© et fait partie d‚Äôune communaut√© de 20 000 d√©veloppeurs, qui participent √† leur strat√©gie d‚Äôinnovation ouverte et collaborative. Acteur de la Greentech, Hove porte une vision √©volutive des mobilit√©s douces, pour un impact plus positif et plus responsable de notre environnement gr√¢ce √† ses 2 produits et m√©tiers : Avec Navitia , Hove travaille continuellement √† l‚Äôam√©lioration des algorithmes qui permettent de calculer les meilleures solutions d‚Äôitin√©raire, tout en tenant compte du contexte et des pr√©f√©rences du voyageur. L‚Äôobjectif ? permettre √† chacun de se d√©placer plus facilement, plus agr√©ablement et avec le moins d‚Äôimpact possible sur la plan√®te. Avec Patterns , Hove analyse les motifs que dessinent les mobilit√©s sur un territoire cibl√©. L‚Äôobjectif ? Suivre la fr√©quentation, √† travers des matrices origine ‚Äì destination, les parts modales‚Ä¶ √Ä partir du recueil et de l‚Äôanalyse des traces GPS et WiFi, entre autres. En tant que Data engineer Hove, vous √™tes int√©gr√© √† une √©quipe pluridisciplinaire m√™lant d√©veloppeurs, Product Owner, Architectes dont l‚Äôobjectif est de cr√©er des services √† fortes valeur ajout√© dans le domaine du transport. Vous avez la charge de d√©finir et mettre en ≈ìuvre le pipeline d‚Äôacquisition des donn√©es (datahub) global pour Hove, d‚Äôorganiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Cr√©er et faire √©voluer le moteur d‚Äôingestion des donn√©es (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilit√© des flux de donn√©es Travailler en collaboration avec les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©grations continues, scalabilit√© des mod√®les, craftsmanship, etc‚Ä¶) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners D√©ployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des donn√©es Superviser et monitorer le d√©ploiement et la robustesse des composants mis en production Participer activement √† la qualit√© de l‚Äôing√©nierie logicielle (Relecture de code, test, int√©gration continue, d√©ploiement, etc.) Participer aux √©v√®nements internes √† la communaut√© data interne et externes (AWS Summit, workshops, meetups‚Ä¶) Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.* Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 2 ans en tant que Data engineer Vous op√©rez dans le conseil et pouvez justifier de vos missions Vous maitrisez l‚Äôanglais professionnel Vous maitrisez au moins : Un framework de calcul distribu√© tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala‚Ä¶). Diff√©rents syst√®mes de base de donn√©es (SQL et NoSQL) et le langage SQL. Un framework de streaming de donn√©es tel que Kafka, Kinesis, ‚Ä¶ Une exp√©rience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks‚Ä¶ Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez √™tre capable de livrer du code de qualit√© dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l‚Äô√©quipe tech Un entretien avec notre CTO","Hove, a subsidiary of Keolis and a key player in data-mobility, is seeking a Data Engineer to define and implement a global datahub pipeline, organize data storage and support data scientists and analysts. The role involves creating and evolving data ingestion engines, working with product managers and business owners to understand client needs, deploying cloud infrastructures, participating in internal and external data events, and delivering quality code on time and within budget. Applicants should have over two years of experience, be fluent in English and have knowledge of distributed calculation frameworks, programming languages, streaming data frameworks, and SQL and NoSQL databases.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
1,56620,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_5lgyYxK,Data Engineer,TotalEnergies Digital Factory,"{Databricks,AWS,Spark,Azure,SQL,Python}",T√©l√©travail total possible,"Rue des jeuneurs, Paris 02, 75002","Logiciels, Big Data, Energie",CDI,2023-03-26,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. La Digital Factory de TotalEnergies est compos√©e de 300 personnes, 30 Squads, 39% de femmes et 25 nationalit√©s. Elle offre un environnement de travail international et interculturel en plein c≈ìur de Paris, engag√© dans la diversit√© et l'inclusion. Elle permet d' acc√©l√©rer la production interne de solutions digitales pour les activit√©s de la Compagnie dans les 130 pays o√π elle est pr√©sente. Elle allie l' agilit√© et l' esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Elle cr√©e et d√©ploie des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. Rejoins-nous en plein coeur de Paris en tant que Data Engineer et int√®gre une de nos 30 squads qui r√©unit 8 √† 10 personnes (data scientist, data engineer, software engineers‚Ä¶). Chacune des squads est d√©di√©e √† un projet m√©tier et intervient dans la production des Minimum Viable Products (MVPs). Tu √©volueras dans un contexte agile (scrum/scrumban), en mode it√©ratif et co-constructif, en t'appuyant sur l'intelligence collective. En tant que Data Engineer, tu garantis la qualit√© des pipelines data du produit, tu assures le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es. En tant Data Engineer, nous attendons techniquement de toi que tu : Con√ßoives, construises et int√®gres des donn√©es au sein de la Squad et en collaboration avec les autres Squads. Assures le stockage, la consommation, l'int√©gration et la gestion des donn√©es des cas d'utilisation. Fasses l'analyse de l'analyse de l'accessibilit√© des donn√©es et que tu recommandes des solutions pour leur int√©gration. Coordonnes la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de donn√©es. Tu int√®gres √©galement les donn√©es dans le data lake. Collabores avec les data scientists pour la r√©alisation des mod√®les de pr√©diction. Produises un code de qualit√©, mettes en place des tests automatis√©s et syst√®matiques pour le contr√¥ler. Interagisses avec les architectes et les autres Data Engineers pour s'assurer de l'efficacit√© des solutions et apporter des pr√©conisations techniques. En parall√®le, tu auras √©galement des missions tranverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies. Coaches et accompagnes la communaut√© des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Tu as une exp√©rience d'au moins 4 ans en data engineering, tu es dipl√¥m√© d'un master ou d'une √©cole d'ing√©nieur sp√©cialis√©e en informatique ou math√©matiques. Les comp√©tences qui sont attendues de toi en tant que Data Engineer : La maitrise de Python, Spark et SQL. Une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles. La capacit√© √† concevoir et √† mettre en oeuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle. Ma√Ætrise des bonnes pratiques de monitoring des flux de donn√©es. Une bonne compr√©hension du machine learning. Une premi√®re exp√©rience sur un provider de Cloud, AWS de pr√©f√©rence. Ce que nous t'offrons : Le d√©veloppement de tes comp√©tences avec le support de la Digital Academy et une enveloppe √©quivalente √† 10 jours de formations par an que tu peux choisir en toute autonomie. La possibilit√© de te certifier AWS et Azure, Databricks... Un programme de mentorat. Un √©quilibre vie professionnelle et vie personnelle avec le recours possible aux horaires flexibles et au t√©l√©travail.","TotalEnergies is looking for a Data Engineer with at least 4 years of experience in data engineering and a degree in computer science or mathematics. The ideal candidate should have expertise in Python, Spark, SQL, relational and non-relational databases, data loading, manipulation, processing, analysis, and exploration at a large scale. The candidate must also have a strong understanding of machine learning and experience with AWS. The role involves working in an agile environment with a team of 8-10 people, developing Minimum Viable Products (MVPs), ensuring the quality of data pipelines, coordinating the implementation, industrialization, and maintenance of data architecture, and collaborating with data scientists. The company offers flexible working hours, telecommuting, and an allowance for ten days of training annually.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,3,0,0.04154662416233763
233,57116,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_lyon_CGI_W1K5QmG,Data Engineer,CGI,"{Azure,GITLAB,Jenkins,Talend,Shell,Kubernetes,AWS,Snowflake,Docker,Kafka,Linux,GCP,Java,Python}",T√©l√©travail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Au sein de l‚Äô√©quipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux √©quipes d‚Äôexpert et de d√©ploiement des solutions. Vous participerez au d√©veloppement strat√©gique d‚Äôun projet d‚Äôun client et vous √©voluerez dans un contexte international, et b√©n√©ficierez de l‚Äôexpertise de consultants CGI, en immersion chez le client. A ce titre vos principales responsabilit√©s seront : ‚Ä¢ Appr√©hender le contexte et les enjeux M√©tier du client ; ‚Ä¢ Comprendre et exp√©rimenter le cadre Agile et Lean ; ‚Ä¢ Analyser les besoins fonctionnels et d√©terminer le mod√®le de donn√©es n√©cessaire avec l‚Äôaccompagnement de Consultant senior ; ‚Ä¢ Participer au d√©veloppement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; ‚Ä¢ √âtablir et d√©rouler des sc√©narios de tests ; ‚Ä¢ Participer √† la vie de la communaut√© Data. Environnement technique : ‚Ä¢ Cloud provider : AWS, GCP , Azure ‚Ä¢ Data Acquisition : Kafka, Kafka Connect , Talend, Snowflake ‚Ä¢ Script : Java, Angular, Python, Shell, ‚Ä¢ Environnement : Linux, Docker, Kubernetes ‚Ä¢ Outils : Jenkins, GITLAB CI ‚Ä¢ Ticketing : JIRA ‚Ä¢ Reporting: Power BI, Qliksense De formation bac+5 ou de formation sup√©rieure en informatique, vous disposez de 2 ans exp√©riences r√©ussie dans le d√©ploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP. Des connaissances m√©tiers dans le domaine du manufacturing ou ses m√©tiers de la sant√© , alli√©s √† des comp√©tences techniques fortes sont √©galement des atouts pour la r√©ussite de ce projet. Votre capacit√© d'adaptation, votre autonomie, votre sens du service ainsi que vos qualit√©s relationnelles seront vos atouts pour r√©ussir et √©voluer. Vous aimez √©voluer dans des contextes internationaux, avec une tr√®s bonne maitrise du fran√ßais et de l'anglais √† l‚Äô√©crit comme √† l‚Äôoral ; CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, is seeking a candidate with experience in deploying Kafka, Datalake AWS, and Datalake CGP platforms. The ideal candidate should have strong technical skills and knowledge in manufacturing or healthcare industries. They should be adaptable, independent, customer-oriented, and have excellent communication skills. Fluency in French and English is required, and working in an international environment will be required. CGI encourages applications from people with disabilities and supports career advancement for women and LGBT+ employees.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
231,56451,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer_villeurbanne,Data Engineer,Micropole,"{Microsoft,durable,GCP,Talend,Scala,AWS,R,Spark,Azure,Python,Tableau}",T√©l√©travail partiel possible,"131 Bd de Stalingrad, Villeurbanne, 69100",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. Enr√©sum√© : Poste: Data Engineer F/H Secteur de l'entreprise :experts conseil dans les secteurs de la banque-assurance, le luxe-retail etl‚ÄôIndustrie Localit√© : Lyon Type de contrat : CDI Niveau d‚Äôexp√©rience :au moins 3 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tesconvaincus que l‚Äôoptimisation du patrimoine data des entreprises est lacl√© de leur performance ? Vous voulez rendre les entreprises data driven et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveauxterritoires ? Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de cesquestions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/services. Alors,pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! EN TANT QUE DATA ENGINEER : Vous rejoignez notre entit√© Data Analytics bas√©e √† Lyon, o√πvous interviendrez sur l‚Äôint√©gralit√© de plusieurs projets avec une vision¬´ Data 360¬∞ ¬ª, m√™lant Conseil, Architecture, Int√©gration et DataScience. En tant que Data Engineer, vous accompagnerezles directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus etdans leur strat√©gie pour optimiser leur performance. Vous serez rattach√©(e) √† l‚Äô√©quipe Data Analytics,compos√©e de 50 #InnovativePeople. Dans vos missions quotidiennes , vous serezamen√©s : A comprendrele besoin de nos clients au travers de missions de type : aide aux choixd‚Äôoutils, cadrage des besoins, Proof Of Concept ; Accompagnerles √©quipes commerciales sur des rendez-vous client et en phase d‚Äôavant-vente ; Recueilliret analyser les besoins et proposer une architecture technique adapt√©e aux casd‚Äôusage des clients ; A r√©alisernos projets de construction de Data Platform au travers des activit√©s : refonte,migration ou d√©veloppement de tableaux de bord dans le respect des exigences dequalit√© et s√©curit√© ; R√©diger ladocumentation des livrables pour rendre les utilisateurs autonomes et lesformer ; R√©diger ladocumentation permettant √† l'IT d'assurer la maintenance ; Accompagnerles consultants moins exp√©riment√©s dans leur mont√©e en comp√©tence ; Capitaliseret partager les bonnes pratiques, connaissances et retours d‚Äôexp√©rience ; Vos comp√©tences techniques : Vous avez un minimum de 3ann√©es d‚Äôexp√©rience sur des projets Data sur les outils ETL (Talend, SQLServer) et Reporting (Power BI, Tableau Software). Id√©alement au moins unepremi√®re exp√©rience sur des projets Cloud AWS ou Azure Vous ma√Ætrisez au minimumun langage de programmation (Python, Spark, Scala, R)‚ÄØ; Vous avez une maitrise desth√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des conceptsd‚Äôindustrialisation, Ia C, CI/CD et/ou gestion de version, Vos atouts : V√©ritableco√©quipier, vous avez √† c≈ìur de contribuer √† la mont√©e en comp√©tence de votre√©quipe, Vousrecherchez la vari√©t√© et l‚Äôexcellence dans votre travail. Autonome et impliqu√©(e),vous avez le go√ªt du challenge, Dot√©(e) d‚Äôunexcellent relationnel et du sens du service, vous avez la capacit√© de g√©rer unerelation client, Vousd√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veilletechnologique accrue qui vous permettra de challenger les besoins de vosclients. Voussouhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniquesautour du Cloud et des solutions Data Enfin, vousdisposez d‚Äôun bon niveau de fran√ßais et d‚Äôanglais, √† l‚Äôoral comme √† l‚Äô√©crit. Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg,la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble lessolutions strat√©giques et innovantes de demain pour accompagner nos clientsdans leur transformation data et digitale. Participer au d√©veloppementde nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement autravers de formations et de certifications sur les plus grandes technologiesgr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovationcontinue gr√¢ce : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et deco-construction avec les clients ; anagement par les talents naturels (regarder le mot de laDRH) Processus de recrutement : Chez Micropole, le processus de recrutement estr√©actif et transparent. Etape 1 ‚Äì Si votre profilcorrespond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suiventvotre candidature par Justine ou Nathan nos Talent Specialist d√©di√©s √† l'agencede Lyon pour une qualification t√©l√©phonique ; Etape 2 - Un premierentretien est programm√© avec Justine ou Nathan en physique ou visio ; Etape 3 ‚Äì Vous rencontrez Matthieu,un manager technique avec l‚Äôun de nos experts Data Analytics En fonction du poste, vous pouvez passer des √©tapessuppl√©mentaires (entretien suppl√©mentaire ou test technique) LAVIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©epour se familiariser √† la culture d‚Äôentreprise et aux valeurs deMicropole ; Des √©v√®nements internesr√©guliers pour partager les connaissances aussi bien techniques quefonctionnelles ; Une politique de formationattractive et √©clectique (certifications prises en charge) ; Un travail en √©quipevaloris√© pour une meilleure coh√©sion ; Participation √† des projetsinternes sur la base du volontariat. √ÄPROPOS DU GROUPE MICROPOLE Groupe international deconseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domainesde la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine,les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists,architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leursclients partout dans le monde sur l'ensemble des phases de leurs projets, duconseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% deson chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolistcompartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole A PROPOS DE L'AGENCE MICROPOLE LYON L‚Äôagence Micropole Lyons‚Äôappuie sur son implantation strat√©gique et son expertise technique pourporter et accompagner les ambitions de croissance du groupe Micropole. Sousl‚Äôimpulsion de notre Directrice d‚ÄôAgence, Armelle Descaillot, nous souhaitonscr√©er une synergie entre la data et le digital afin d‚Äôapporter une r√©ellevaleur ajout√©e √† nos clients et les accompagner sur les d√©fis technologiques dedemain. Les marques fortes du groupetelles que Wide (agence digitale int√©gr√©e au groupe Micropole) etLucy in the Cloud (entit√© conseil du groupe Micropole d√©di√©e √† AWS) noussoutiennent et nous permettent de nous positionner comme acteur conseil de r√©f√©rencedans la r√©gion Centre-Est. V√©ritable agence √† taillehumaine o√π r√®gnent esprit d‚Äô√©quipe et convivialit√©, nos talents allientsavoir-faire et expertise pour r√©pondre aux besoins de transformation desentreprises. #LI-JHE","Micropole seeks a Data Engineer in Lyon to work on a variety of projects with a ""Data 360¬∞"" vision,¬†consulting, architecture, integration and data science. Ideal candidates should have a minimum of three years of experience in projects relating to ETL tools and reporting, with at least one experience working on AWS or Azure projects. Candidates should possess communication skills, problem-solving ability, and a desire to develop themselves and others through constant growth, learning and sharing their knowledge.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
313,56615,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/big-data-engineer-f-h_la-defense_INGNI_ko6eQmz,BIG DATA ENGINEER-,Ing√©niance,"{Jenkins,Git,HDFS,Linux,Hive,Spark,Docker,Java,Hadoop,Python}",T√©l√©travail partiel possible,La D√©fense,IT / Digital,CDI,2023-03-26,"Ing√©niance, est une soci√©t√© de conseil sp√©cialis√©e dans des projets li√©s aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajout√©e en associant innovation technologique, transformation digitale, expertise m√©tier (Banque, Finance et Assurance) & m√©thodes agiles. Technology-oriented, elle offre une r√©elle expertise √† ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l‚ÄôAgilit√©. Son projet d‚Äôentreprise s‚Äôappuie aussi sur des valeurs humaines, soci√©tales et environnementales (Label EcoVadis Gold). La proximit√©, la performance, la convivialit√© et le progr√®s sont des atouts sur lesquels elle b√¢tit son√©volution collective au quotidien. Missions : Rattach√© √† nos experts, au sein de notre lab ¬´ Big Data ¬ª , vous : aurez en chargela r√©alisation d'un prototype Big Data(technologies Hadoop HDFS, Hive, Spark, etc) participerez aux activit√©s de veille technologique sur le domaine du Big Data (recherches, exp√©rimentations, etc) participerez √† la r√©daction d'articles et √† l'animation de nos r√©seaux sociaux sur le domaine du Big Data √©voluerez dans des √©quipes fonctionnant en m√©thode Agile utiliserez les outilsDevOpsd√©ploy√©s sur nos cha√Ænes d'int√©gration continue (Jenkins, Docker, Git, etc) Ce poste sera l'occasion d'int√©grer notre programme de formation interne avec pour objectif d'acqu√©rir les comp√©tences fonctionnelles de base sur nos secteurs d'activit√© (finance de march√©, banque et assurances) mais aussi de solides connaissances techniques. Profil recherch√© : Vous √™tes dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent. Une sp√©cialisation dans le g√©nie logiciel sera vivement appr√©ci√©e. R√©actif, avec le sens du service, vous justifiez de bonnes capacit√©s d'√©coute, d'un bon relationnel et une bonne gestion du stress. Curieux, autonome, et proactif, vous avez les qualit√©s n√©cessaires √† ce projet. Vous √™tes int√©ress√© par le conseil , les syst√®mes d'informations et le secteur de la Banque/ Finance/ Assurance Comp√©tences requises : Des comp√©tences en d√©veloppement : Java ou Python. Des comp√©tences des OS Linux et Windows ; Des comp√©tences sur le framework Hadoop ; Une connaissance th√©orique et id√©alement pratique de la gestion d'un projet informatique; A minima une connaissance th√©orique des m√©thodes Agile (Scrum par exemple).","Ing√©niance seeks a Big Data Prototype Developer with expertise in Craft Development, Big Data, Cloud/DevOps, and Agile methods to join their Big Data lab. Candidates must be engineering graduates with knowledge in Java/Python for coding, and experience with Hadoop framework, Linux and Windows OS. Along with developing a Big Data prototype, consultants will also participate in technology watch activities, social media campaigns, and agile teams. The role will allow for continued professional development.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
314,56334,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-software-engineer-m-f-d_paris,Data & Software Engineer,Artefact,{},T√©l√©travail partiel possible,"19 rue Richer, Paris, 75009","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that‚Äôs why we identify as ‚Äúmarketing engineers‚Äù. In order to improve the performance and impact of brands, and consumers‚Äô experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). From design to deployment , you manage your solution end-to-end, while also optimising the performance, security and scalability. Our working language is in English and preferably the local language of the office. The team The most tech people of our Data & Consulting division, the title of ""Data engineer"" or ""Software engineer"" does not describe everything our amazing women and men can do: data engineering, operation management, security, cloud architecture, MLOps, and more. Presenting in each and every office of Artefact, working seamlessly with our consultants and data experts, our Data & Software engineers are the ones who make our data projects come true. Mission You will work with the team to identify your clients' needs and define innovative solutions of which you will be ownership from start to end. You manage both its conception and implementation, while also optimising the performance and scalability. You will also coach others, keep abreast of industry news/updates and get stuck into training sessions with our business partners and suppliers, such as Google & Amazon. You share your knowledge, learnings and success, with the capability of presenting and communicating. Desirable skills You are the master of several, or all the value chain's activities of the projects: cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, continuous integration and deployment; You have no problem popularizing technical terms or solutions to more business-oriented profiles, you can work in a team with very diversified profiles. You know how to prioritize your tasks, respect deadlines, and anticipate projects' risks. ... or soon you will be, contact us! Why should you join us Artefact is the place to be: come and build the future of data and marketing Innovation: We have a passion for creating impacting projects, and believe innovation can come from anyone. Action: We make things rather than telling people how to make them. Collaboration: We believe in bringing talented people together, in winning together, and in learning from each other. Come join us!","Artefact, a consulting firm specialized in AI and Data, is seeking a Data or Software Engineer with skills in cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, and continuous integration and deployment. The ideal candidate should have the ability to communicate sophisticated solutions to business-oriented profiles and work in a team with diversified profiles while prioritizing tasks and anticipating project risks. Artefact offers a collaborative work environment where innovation and action are encouraged.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
229,56508,https://www.welcometothejungle.com/fr/companies/ekinox/jobs/data-scientist-machine-learning-engineer_paris,Data Scientist / Machine Learning Engineer,Ekinox,"{PyTorch,TensorFlow}",T√©l√©travail partiel possible,"Paris, 75001","Logiciels, Intelligence artificielle / Machine Learning, Incubateur / Acc√©l√©rateur",CDI,2023-03-26,"Ekinox est une jeune entreprise ayant deux activit√©s distinctes : le service aux entreprises d‚Äôune part et la Startup Factory d‚Äôautre part. Sur ces deux activit√©s, Ekinox a deux moteurs principaux : La culture de l‚Äôexcellence, synonyme de beaut√©, de simplicit√© et d‚Äôune qu√™te de perfectionnement continue, gr√¢ce notamment √† des sessions d‚Äôentrainement et de partages de connaissances. la data et l‚ÄôIA, qui permettent d‚Äôatteindre un niveau de valeur ajout√©e sup√©rieur, lorsqu‚Äôutilis√©es √† bon escient Le poste: Data Scientist/Machine Learning Engineer Vous travaillerez main dans la main avec d‚Äôautres personnes aux profils vari√©s (Data Ing√©nieurs, Data Scientists, Machine Learning Engineers, Product Owners, Scrum Masters, ‚Ä¶), au sein d‚Äôune √©quipe multidisciplinaire et soud√©e, avec des automatismes et des pratiques de travail avanc√©es. Ensemble, vous vous focaliserez sur la meilleure mani√®re de g√©n√©rer de la valeur, ce qui selon nous passe g√©n√©ralement par des solutions simples. Vos principales missions Participer √† la r√©alisation des produits de Data Science de bout en bout dans le cadre la Startup Factory et de la prestation de services Apporter votre expertise et savoir-faire en Data Science et en intelligence artificielle √† l‚Äôensemble de l‚Äôentreprise et √† ses partenaires Participer au d√©veloppement de la strat√©gie et de l‚Äôexpertise Data Science de l‚Äôentreprise Aider √† d√©velopper l‚Äôimage de marque Ekinox sur la Data Science et l‚ÄôIntelligence Artificielle Profil recherch√© Vous avez une bonne connaissance des principaux algorithmes et biblioth√®ques de Machine Learning (parmi scikit-learn, TensorFlow, PyTorch, etc.) Vous √™tes curieux, et aimez exp√©rimenter de nouvelles approches De pr√©f√©rence, vous avez d√©j√† particip√© √† des projets √† base de Machine Learning en production, et avez du recul sur ce que cela implique Vous avez une app√©tence forte pour le d√©veloppement logiciel et les bonnes pratiques associ√©es Vous √™tes p√©dagogue, et savez expliquer des concepts complexes √† des audiences non-techniques D√©marrage ASAP","Ekinox is seeking a Data Scientist/Machine Learning Engineer with expertise in data science and artificial intelligence. The ideal candidate will have knowledge of major ML algorithms and libraries (such as TensorFlow and PyTorch), experience with ML projects in production, and a strong interest in software development and pedagogy. They will work within a multidisciplinary team to generate value through simple solutions, participate in end-to-end data science product creation, develop the company's data science strategy and expertise, and promote Ekinox's brand in the field. The position is available as soon as possible.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 5 ans,2,1,0.04154662416233763
305,57144,https://www.welcometothejungle.com/fr/companies/ornikar/jobs/data-engineer_paris_ORNIK_4Jq2W8W,Data Engineer,Ornikar,"{Jenkins,Airbyte,Metabase,Airflow,dbt,scale,moderne,via,BigQuery,GCP,Mixpanel,Python}",T√©l√©travail partiel possible,"France, Paris, 23230","Mobilit√©, FinTech / InsurTech, EdTech",CDI,2023-03-26,"Ornikar √©toffe son offre historique d‚Äôauto-√©cole et devient une plateforme d‚Äôacc√®s √† la mobilit√© pour les jeunes ! Leur volont√© : r√©inventer l‚Äôexp√©rience des jeunes g√©n√©rations autour de l‚Äôapprentissage de la conduite, et les accompagner gr√¢ce √† un √©cosyst√®me de services tels que l‚Äôassurance automobile. Fond√©e en 2013 et leader sur la modernisation du permis de conduire, l‚Äô√©quipe Ornikar continue d‚Äô√©voluer et de militer pour l‚Äô√©mancipation des jeunes et la transition vers leur ind√©pendance ! Aujourd‚Äôhui constitu√©e de 260 collaborateurs, leur √©quipe conna√Æt une croissance continue construite sur de solides fondations : leur produit permis de conduire (plateforme d‚Äôe-learning et marketplace de mise en relation avec nos enseignants de la conduite) d‚Äôune part, mais √©galement leur connaissance utilisateur approfondie qui leur permet d‚Äôoffrir une assurance auto plus proche des besoins des jeunes assur√©s : modulable, simplifi√©e, adapt√©e √† tous avec un prix et des options personnalis√©es. √Ä propos de l'√©quipe Data ü¶∏ L‚Äô√©quipe Data chez Ornikar existe depuis plus de 3 ans et est compos√©e d'une vingtaine de personnes (Data Analysts, Data Engineers, Machine Learning Engineers). Nous avons principalement 3 missions : L‚Äôaide √† la d√©cision : on accompagne les √©quipes √† tous les niveaux de management, que ce soit pour des objectifs strat√©giques, de d√©veloppement produit, de m√©tier‚Ä¶ Nous menons des analyses complexes pour permettre aux √©quipes de prendre les d√©cisions bas√©es sur des chiffres qui nous permettront d‚Äôatteindre nos objectifs ou d‚Äôidentifier de nouveaux leviers de croissance. L‚Äôefficacit√© op√©rationnelle : Les √©quipes chez Ornikar sont tr√®s sensibles aux enjeux data, ce qui nous a permis de mettre en place d‚Äôune part le self-service BI pour leur permettre d‚Äôeffectuer leurs recherches quantitatives en parfaite autonomie, et d‚Äôautre part nous r√©pondons √† des probl√©matiques d‚Äôautomatisation de flux de donn√©es pour enrichir leurs outils et acc√©l√©rer leur quotidien. Le d√©veloppement de features data et d‚Äôalgorithmes pour apporter encore plus de valeur diff√©renciante √† nos produits. Nous recherchons un.e Data Engineer üåã Pour soutenir ces missions, toute l‚Äô√©quipe participe √† la construction d‚Äôune stack Data de pointe r√©pondant aux enjeux d‚Äôune √©quipe Data moderne. Afin de faire grandir encore l‚Äô√©quipe, nous cherchons notre prochain(e) Data Engineer. Nous recherchons un profil confirm√© pour aider au d√©veloppement data d‚ÄôOrnikar, notamment : Construire une vision unifi√©e du parcours utilisateur sur toutes nos plateformes Cr√©er, mod√©liser, enrichir et faire √©voluer nos Datamarts Travailler √† la robustesse de flux de donn√©es , de la collecte √† la transformation S‚Äôassurer de la qualit√© de la donn√©e en interne pour une confiance toujours plus forte dans les productions de l‚Äô√©quipe Data Impl√©menter et am√©liorer les diff√©rentes briques de notre socle technique, pour nous faire gagner en efficacit√© et en qualit√© de service : ELT & reverse ELT, reporting & self-service BI‚Ä¶ Notre stack en quelques mots : Airbyte, Mixpanel, Airflow, GCP (BigQuery), dbt, Periscope, Metabase and so on ^^ Aussi, nous restons tr√®s ouverts aux initiatives (technos / outils / etc.) Nous rejoindre, c‚Äôest la garantie de travailler dans un environnement stimulant, d‚Äôavoir de l‚Äôimpact dans la structuration de l‚Äô√©quipe et de ses process et de participer √† la croissance d‚Äôun super projet. Tu es notre candidat.e id√©al.e si tu‚Ä¶ ü§© Tu as au moins 4 ans d‚Äôexp√©rience en tant que Data Engineer Tu poss√®des de solides connaissances dans les stacks Data modernes Tu poss√®des de solides connaissances en bases de donn√©es et mod√®les de donn√©es Tu ma√Ætrises parfaitement Python ou un autre langage de programmation Tu es curieux¬∑se, enthousiaste, et tu as une d√©marche proactive Tu as un profil technique et es capable de travailler avec l‚Äô√©quipe Tech/Produit Tu aimes travailler en √©quipe et communiquer avec des audiences pas n√©cessairement techniques Si tu as des connaissances sur les sujets suivants, c‚Äôest bonus : Mise en production de mod√®les de Machine Learning Outils d‚Äô int√©gration continue (Jenkins) Collecte et flux de donn√©es en temps r√©el Le process de recrutement pour ce poste üí™ Un premier √©change t√©l√©phonique avec Romane, notre Talent Acquisition Specialist Entretien avec Joris , VP Engineering assurance (ton futur manager) pour vous pr√©ciser les contours du poste et les enjeux de la team Une √©tude de cas √† pr√©parer √† la maison, puis √† restituer autour d'un √©change d'1h avec Thibault et Nicolas , nos deux Head of Data sur nos produits Assurance et Education pour vous projeter sur des missions du poste en conditions r√©elles Une rencontre avec notre CTO, C√©dric, parce qu‚Äôil est cool Un entretien de culture fit avec les membres actuels de l'√©quipe pour partager sans pression sur nos valeurs et notre quotidien. Ce qu‚ÄôOrnikar a √† vous offrir‚Ä¶ üéÅ Une r√©mun√©ration fixe entre 60k‚Ç¨ et 70k‚Ç¨, en fonction de votre profil La possibilit√© de travailler en remote depuis n‚Äôimporte o√π en France Nous sommes votre entreprise id√©ale si vous recherchez‚Ä¶ üîç Une start-up fran√ßaise devenue scale-up qui se structure, d√©veloppe de nouveaux produits et s‚Äôexporte √† l‚Äôinternational üåé La possibilit√© de passer votre permis gratuitement üòâ Un environnement de travail respectueux de tous et toutes. En tant que membre fondateur du pacte IDEA, nous nous engageons pour la diversit√©, l'√©quit√© & l‚Äôinclusion Une aventure dans laquelle vous pourrez apprendre et sortir de votre zone de confort, avec une grande vari√©t√© de missions et beaucoup d‚Äôautonomie Beaucoup de place pour des initiatives innovantes et cr√©atives, nous adaptons nos process et m√©thodes sans cesse Parmi nos avantages collectifs üôå Un abonnement sport et bien-√™tre Gymlib üèë Une assurance sant√© compl√©mentaire avec Alan Une Swile pour vos tickets restaurants (11‚Ç¨ par jour) Les frais de gestion pour votre √©pargne salariale avec Epsor Des centaines de r√©ductions et avantages via Leeto, partenaire de notre Comit√© Social √âconomique Le remboursement des frais de transport en commun √† 50% ou le forfait mobilit√©s durables jusqu'√† 450‚Ç¨/an avec la carte Worklife üå≥ Et si vous nous rejoignez en remote‚Ä¶ Une carte de d√©penses Spendesk pour assurer vos d√©placements et nuits d'h√¥tels lors de vos s√©jours au bureau √† Paris La prise en charge de la carte SNCF Libert√© utilisable pour vos d√©placements personnels √©galement","Ornikar, a platform providing driving courses and related services, is seeking an experienced data engineer to join its data team. The successful candidate will be responsible for improving the quality of data, constructing unified user journeys, and building data models and new features to boost efficiency and service quality. The platform uses a stack that includes Airbyte, Mixpanel, Airflow, GCP (BigQuery), dbt, Periscope, Metabase, and others. The ideal candidate should possess more than four years of experience, be proficient in Python and other programming languages, and demonstrate a proactive and communicative approach. The platform offers a respectful, diverse, and inclusive work environment, free driving courses, and a range of benefits.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
255,56345,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_639bXKJ,Data Engineer,FACILECOMM (SHIPPINGBO),"{Redis,MongoDB,Pandas,PostgreSQL,Redshift,Airflow,AWS,R,SQL}",T√©l√©travail partiel possible,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-03-26,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait men√©(e) jusqu‚Äô√† cette annonce ! Peut-√™tre est-ce toi, le/la futur(e) Data Engineer que nous attendons‚Ä¶ En tout cas, nous l‚Äôesp√©rons. Dans un premier temps, permets nous de nous pr√©senter. Qui est Shippingbo ? La premi√®re chose que tu dois te demander c‚Äôest ‚Äúqui est Shippingbo‚Äù et c‚Äôest une tr√®s bonne question ! Shippingbo est une technologie logistique e-commerce fond√©e en 2016, par la soci√©t√© facilecomm. Nous mettons √† disposition des vendeurs en ligne une technologie qui leur permet d‚Äôoptimiser toute leur cha√Æne logistique : depuis la r√©cup√©ration des commandes, jusqu‚Äô√† leur exp√©dition, en passant par la pr√©paration. Pour la faire tr√®s simple, on est la technologie de l‚Äôombre qui permet √† ton site favori de te livrer dans les meilleurs d√©lais, tout en te notifiant de l‚Äôavanc√©e de ta commande. Pas mal, non ? Notre ambition : permettre √† nos clients de proposer aux consommateurs un parcours d‚Äôachat au top, digne des g√©ants du e-commerce ! Aujourd‚Äôhui, nous comptons pas moins de 1000 clients aux activit√©s e-commerce assez vari√©es : e-commer√ßants, retailers, fournisseurs, grossistes‚Ä¶. mais dont le point commun reste la vente en ligne ! Avec pr√®s de 72% de croissance en 2021 et plus d‚Äô1 milliard d‚Äôeuros de GMV, nous sommes bien d√©cid√©s √† poursuivre sur cette lanc√©e pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage europ√©en d‚Äôici 3 ans ! Shippingbo cherche aujourd‚Äôhui √† d√©velopper les outils d‚Äôanalyse qu‚Äôelle met √† disposition de ses clients ainsi qu‚Äô√† d√©velopper de nouvelles fonctionnalit√©s se fondant sur l‚Äôanalyse des donn√©es. En tant que data engineer, votre r√¥le sera de construire et maintenir les entrep√¥ts et pipelines de donn√©es. Vos missions principales consisteront √† : Participer √† la d√©finition des sch√©mas de donn√©es et aux choix d‚Äôarchitecture ; D√©finir et optimiser les requ√™tes fa√Ætes par l‚ÄôAPI et celles au c≈ìur des pipelines ; Pr√©parer des datasets exploitables √† des fins d‚Äôanalyse ; Identifier de facon plus g√©n√©rale les moyens optimaux de r√©pondre √† l‚Äôensemble des requ√™tes de donn√©es ; Optimiser √©galement le fonctionnement des pipelines et maintenir les syst√®mes surveillant leur bon fonctionnement et la qualit√© des donn√©es ; Participer √† l‚Äôadministration, la configuration et le param√©trage des bases de donn√©es. - Vous avez au moins 2 ans d‚Äôexp√©rience comme data engineer (ou des r√¥les similaires) et dans la construction et la maintenance de pipelines de donn√©es ; - Vous avez une connaissance approfondie de SQL , de l‚Äôoptimisation de requ√™tes et des entrep√¥ts de donn√©es ; - Vous avez une exp√©rience avec au moins une base de donn√©e orient√©e colonnes ; - Id√©alement vous avez √©galement une exp√©rience avec une base de donn√©e orient√©e documents et une base de donn√©e cl√©-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en m√©tro, arr√™t Ramonville) Rattach√© au d√©partement R&D de l'entreprise Mise √† disposition d‚Äôoutils informatiques Tickets restaurant >>> Venez d√©couvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversit√© occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'√©galit√© professionnelle et l'emploi des travailleurs en situation de handicap. A comp√©tences √©quivalentes, ce poste est ouvert √† tous.","Shippingbo, a logistics technology company, is seeking a data engineer to build and maintain data warehouses and pipelines, optimize queries, and prepare data for analysis. Requirements include at least 2 years of data engineer experience, expertise in SQL, data warehousing, and experience with column-oriented, document-oriented, and key-value databases. The position is a full-time contract and located in Toulouse, France. Shippingbo values diversity and encourages applications from individuals with disabilities.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
252,56635,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-science-engineering-manager-f-h_massy_CARRE_e3jl00Z,Data science Engineering manager,Carrefour,"{durable,Kubernetes,Airflow,R,Spark,BigQuery,SQL,Python,Tableau}",T√©l√©travail partiel possible,"AUDREY ALLIEN, Massy","Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux d√©fis de notre √©poque, Carrefour a pour ambition de rendre le meilleur accessible √† tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos √©quipes. Nous nous √©panouissons en √©quipe : M√©tiers du commerce, m√©tiers d'expertise, entrepreneurs unissent leurs comp√©tences et leurs efforts pour construire ensemble une cha√Æne de valeur au service des consommateurs. Au plus pr√®s de nos clients ou en coulisses, chacun a un r√¥le √† jouer mais peut compter sur les autres pour r√©ussir. Nous veillons √† ce que chacun puisse aller loin : L'envie et le m√©rite sont les seuls pr√©-requis pour nous rejoindre, acc√©der √† une formation, changer de m√©tier, √™tre promu ou cr√©er son entreprise. Nous partageons la victoire : nos collaborateurs sont engag√©s et nous nous engageons en retour. En offrant des r√©mun√©rations et des avantages parmi les meilleurs de notre secteur, en permettant √† chacun d'√™tre associ√© aux r√©sultats, en veillant √† la sant√© de tous. Cr√©ateur de l'hypermarch√© et pionnier de la consommation de masse, Carrefour reste fid√®le √† ses racines mais se r√©invente pour permettre √† chacun, chaque jour, de manger mieux : plus sain, plus local, plus responsable. Nos atouts pour y parvenir ? Un r√©seau multiformat de + 5 300 magasins, la cr√©ation de services et d'une offre digitale de r√©f√©rence, une coop√©ration renforc√©e avec les acteurs du monde agricole, de la cha√Æne alimentaire, de la Tech... En pleine transformation, la DATA France se renforce et recherche un(e) : Data science Engineering manager F/H BON A SAVOIR: CDI/ ASAP/ CADRE N8/MASSY L'utilisation de la data et le d√©veloppement des capacit√©s analytiques sont un axe majeur du plan strat√©gique du Groupe Carrefour √† horizon 2027. Directement rattach√©e au COMEX France, l'Analytics Factory de Carrefour France est le pilier de cette transformation analytique, au service des clients et de l'ensemble des √©quipes m√©tier de Carrefour France - Marketing, Marchandises, Exploitation, E-commerce, Supply Chain, Services Financiers, etc‚Ä¶ √Ä propos du poste Au sein du p√¥le de data science de l'Analytics Factory, vous m√®nerez une √©quipe rassemblant data scientists et data engineers sur des projets de science des donn√©es, au service de la d√©finition de l'offre. L'objectif de cette √©quipe est de construire les solutions automatis√©s, fond√©es sur les donn√©es, pour choisir quels produits vendre, dans quel magasin, √† quel prix, en ad√©quation avec les objectifs strat√©giques de Carrefour. Ces solutions reposent notamment sur des algorithmes de machine learning et operation research. Vos missions seront de : suivre, conseiller, guider, former les diff√©rents ing√©nieurs de l'√©quipe planifier et organiser l'ex√©cution de projets techniques complexes en collaborant activement avec les product owners, les √©quipes m√©tiers et les autres √©quipes techniques de Carrefour recruter pour assurer l'ad√©quation des effectifs de l'√©quipe aux besoins actuels et futurs √™tre garant des m√©thodologies de science des donn√©es et de d√©veloppement logiciel agile de l'√©quipe contribuer √† la conception d'architectures de services s√©curis√©es, fiables, facilitant la maintenance √©volutive Vous √©voluerez dans un environnement agile et collaboratif. Vous pourrez √©galement participer aux √©changes r√©guliers de notre communaut√© d'une trentaine d'ing√©nieurs (data scientists, engineers, devops) : retour d'exp√©rience, d√©bats sur les probl√©matiques ML, de d√©veloppement logiciel, ... En tant que Engineering Manager , vous rapporterez √† l' Engineering Director du d√©partement. √Ä propos de vous Dipl√¥m√© en informatique ou math√©matique appliqu√©e, au moins au niveau master, ou justifiant d'une exp√©rience professionnelle √©quivalente, vous disposez de tr√®s solides connaissances sur les algorithmes d'apprentissage statistique. √Ä l'issue d'au moins 5 ann√©es d'exp√©rience professionnelle, vous avez d√©velopp√© une solide expertise et un recul sur chaque √©tape du cycle de vie d'un projet de data science et la manipulation de base de donn√©es √† grande √©chelle. Vous √™tes d√©sormais capable d'aborder n'importe quel champ de la data science, et √©galement de conseiller et guider des data scientists et data engineers juniors sur ces projets. Vous avez √©galement particip√© √† l'industrialisation de solutions fond√©es sur du machine learning, id√©alement dans un contexte cloud, et ma√Ætrisez les bonnes pratiques architecturales. Vous avez d√©j√† manag√© des profils techniques, avec diff√©rents niveaux d'exp√©rience, et vous souhaitez continuer de vous sp√©cialiser sur ce r√¥le d'encadrement. Vous √™tes motiv√©s par les probl√©matiques op√©rationnelles tr√®s concr√®tes, que l'on peut notamment rencontrer dans l'univers de la grande distribution. Pour cela, vous aimez interagir avec des professionnels, d'horizons diff√©rents. Gr√¢ce √† d'excellentes qualit√©s relationnelles et de communication, vous √™tes en mesure de communiquer vos id√©es complexes √† diff√©rents publics non-techniques.. Vous avez pris part √† des projets de d√©veloppement collaboratifs, et la qualit√© et la simplicit√© du code vous tiennent √† c≈ìur. Vous ma√Ætrisez le fran√ßais et √™tes en mesure de mener des discussions avec les op√©rationnels de Carrefour France. Vous ma√Ætrisez un anglais technique a minima. Environnement technique Python, BigQuery, Spark, Kubernetes, Terraform, Airflow Informations compl√©mentaires Si√®ge mondial du groupe Carrefour, Massy Possibilit√© de t√©l√©travail plusieurs fois par semaine. Avantage 10% Carte Pass pour le collaborateur et PEE (plan √©pargne entreprise) R√©mun√©ration sur 13,5 mois L'acc√®s aux Services exclusifs √† Massy : Salle de sport, cr√®che, plusieurs options de restauration au sein du si√®ge avec participation CE, infirmerie, t√©l√©consultation m√©dicale, conciergerie, Coiffeur Chez Carrefour, nous avons √† c≈ìur de ne passer √† c√¥t√© d'aucun talent et sommes fiers de compter des √©quipes repr√©sentatives de la soci√©t√© dans son ensemble. Nous encourageons ainsi tous types de profils √† postuler √† cette offre et garantissons un processus de recrutement d√©nu√© de toutes formes de discriminations. Vos comp√©tences : Compr√©hension du business et go√ªt du commerce ; la connaissance du retail, en particulier alimentaire, est un plus Excellentes capacit√©s analytiques et statistiques, capacit√© √† comprendre les principes de mod√®les data science Tr√®s bonnes capacit√©s dans la manipulation de grandes volum√©tries de donn√©es ; ma√Ætrise d'un langage de requ√™tage des donn√©es (SQL , Big Query), d'outils de datavisualisation (Tableau, Google Data Studio) ; la ma√Ætrise de Python / R est un plus Bon relationnel et capacit√©s de synth√®se √©crite et orale.","Carrefour is looking for a Data Science Engineering Manager to lead a team of data scientists and engineers in developing automated data solutions to inform product pricing and selection. The ideal candidate will have a master's degree in computer science or applied mathematics, at least five years of experience in data science, and expertise in statistical learning algorithms, database manipulation, and machine learning industrialisation. The role involves mentoring team members, collaborating with different teams, and advocating for best practices in software development and data science methodologies. The position reports to the Engineering Director and requires excellent communication skills and fluency in French and technical English. The role is based in Massy, France, but teleworking is possible. Carrefour is an equal opportunity employer and encourages candidates from all backgrounds to apply.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
283,56628,https://www.welcometothejungle.com/fr/companies/ekinox/jobs/data-engineer_paris,Data engineer,Ekinox,"{GCP,Azure,Jupyter,Kubeflow,Tensorflow,Git,Scala,Gitlab,Kubernetes,AWS,Kafka,Hadoop,Spark,Docker,Java,Github,Python}",T√©l√©travail partiel possible,"Paris, 75001","Logiciels, Intelligence artificielle / Machine Learning, Incubateur / Acc√©l√©rateur",CDI,2023-03-26,"Qui sommes-nous ? Ekinox, jeune entreprise √† taille humaine (<30 collaborateurs) fond√©e par des ing√©nieurs, pour les ing√©nieurs. Nous exer√ßons deux activit√©s principales: D‚Äôun c√¥t√©, le service num√©rique , notamment dans la Data, le Machine Learning et le Cloud. De l‚Äôautre c√¥t√©, la ‚ÄúStart-up Factory‚Äù, espace de cr√©ation des p√©pites num√©riques d‚Äôaujourd‚Äôhui et de demain. Exemple d‚Äôentreprise fra√Æchement sortie de notre factory : Moovance [L‚Äôapp qui r√©compense ta mobilit√© - Moovance] Ce qui nous fait avancer ? La culture de l‚Äôexcellence et de la simplicit√©, dans une qu√™te de perfectionnement continue. Vous trouverez chez nous : Une journ√©e par mois d√©di√©e au partage de connaissances Une autre journ√©e par mois d√©di√©e √† la Startup Factory et √† l‚Äôentra√Ænement de nos √©quipes Deux journ√©es par mois, la possibilit√© de participer √† l‚Äô√©laboration et au d√©veloppement de nos OKRs (objectifs d‚Äôentreprise) Le parti pris de ne pas faire de choix entre l‚Äôindividu et le collectif. Les deux √©tant, selon nous, essentiels et compl√©mentaires. Qu‚Äôest-ce qui nous anime ? Nous sommes en qu√™te de sens permanente. Notre objectif est de cr√©er des produits qui r√©pondent aux vrais besoins de notre monde en mettant en ≈ìuvre des technologies de pointe qui s‚Äôappuient sur les connaissances tir√©es ing√©nieusement de la Data. Nous aspirons √† d√©velopper des √©quipes d‚Äôexperts soud√©es. √Ä terme, nous souhaitons n‚Äôavoir plus aucune mission individuelle. Les consultants interviendront en √©quipe chez nos clients pour favoriser le collectif Ekinox. Et, dans cette m√™me id√©e de recherche de l‚Äôexcellence, nous guidons celles et ceux qui en ont envie √† devenir les entrepreneurs de demain gr√¢ce √† la Startup Factory. A propos de votre mission : Avec nous, vous travaillerez en √©quipe. Vous vous entra√Ænerez avec des co√©quipiers √† votre image (et donc √† notre image) dans un cadre agile (souvent Scrum), jusqu‚Äô√† entrer en r√©sonance avec eux. Lorsque vous travaillez pour votre client, votre sens de l‚Äôempathie vous pousse √† toujours mieux comprendre ses probl√©matiques de fond. Votre socle m√©thodologique sera s√©rieusement constitu√© de TDD, BDD, pair programming et autres principes √©tablis de qualit√© tir√©es notamment des pratiques pr√¥n√©es par Extreme Programming ou du Craftsmanship Manifesto. Fortement impliqu√© dans la vision produit, vous consid√©rez le Product Manager au m√™me titre que n‚Äôimporte quel autre de vos co√©quipiers. Ce qu‚ÄôEkinox recherche chez vous : Vous avez une exp√©rience de 2 ans ou plus (mais on peut toujours en discuter) Vous vous sentez concern√©¬∑e par le software craftsmanship et faites de la veille technologique Vous aimez travailler en √©quipe et partager vos connaissances Vous √™tes ouvert¬∑e aux autres et acceptez leurs points de vue avec bienveillance Vous contribuez √† la progression des personnes qui vous entourent Comp√©tences techniques : Voici une liste non-exhaustive des technologies que nous utilisons. Vous aurez pour mission de produire de la valeur avec un certain nombre d‚Äôentre elles: Langages de programmation suivants : Python, Java, Scala Outils d‚Äôindustrialisation : Gitlab CI / Github Actions / Google Cloud Build Infrastructure et d√©ploiement : Docker / Kubernetes, Terraform Travail en √©quipe : Git Web : Spring et autres frameworks Services cloud : AWS / GCP / Azure Big Data: Spark, Hadoop, Kafka, Terraform, Jupyter Machine Learning : Tensorflow, Scikit learn, Kubeflow et toutes les autres technologies que vous viendrez ajouter √† la liste D√©roulement du processus de recrutement: Etape 1: Premi√®re rencontre RH en visio (1 h) Etape 2: Test technique (rapide et √† r√©aliser sans pression chez vous, 30-45 minutes) √âtape 3: Rencontre avec 1 ou 2 data ing√©nieurs de chez Ekinox (environ 2 h) √âtape 4: Rencontre avec l‚Äôun des co-fondateurs d‚ÄôEkinox (30 minutes)","Ekinox, a small-scale digital service company, is seeking a Data Engineer with a minimum of 2 years' experience. The candidate must have expertise in programming languages like Python, Java, and Scala, and tools such as Docker/Kubernetes, Terraform, Gitlab CI/Github Actions/Google Cloud Build, AWS/GCP/Azure, and Spring frameworks. The company values teamwork, sharing knowledge, and continuous self-improvement. The recruitment process includes virtual interviews, technical assessments, and meetings with data engineers and cofounders.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
315,56355,https://www.welcometothejungle.com/fr/companies/agaetis/jobs/data-engineer_aubiere,Data Engineer,Agaetis,"{Hive,Elasticsearch,Docker,Azure,tensorflow,MySQL,Nosql,MongoDB,Databricks,Kafka,hadoop,Flink,Kubernetes,AWS,Akka,Storm,Hadoop,SQL,Tensorflow,spark,Mongo,k8s,Scala,Spark,kafka,sql,Python,AirFlow}",T√©l√©travail partiel possible,"9 All√©e Evariste Galois, Aubi√®re, 63170","Intelligence artificielle / Machine Learning, Big Data, Cybers√©curit√©",CDI,2023-03-26,"Depuis 2017, Agaetis est une filiale du groupe Novencia. Ils apportent leur expertise technologique et leur savoir-faire pour lever les freins √† l‚Äôinnovation. Bas√©e √† Clermont-ferrand, Lyon et Paris, Agaetis apporte √† ses clients une vraie r√©ponse bas√©e sur l‚Äôanalyse du besoin et la compr√©hension de leurs enjeux. Ils mettent le conseil, l‚Äôexpertise technologique, l‚Äôintelligence collective et l‚Äôengagement humain au service de leurs clients, afin d‚Äôapporter la meilleure solution. Ils capitalisent √©galement sur de la Recherche D√©veloppement Innovation (RDI) pour fournir des solutions cl√©s en main et r√©pondre aux enjeux de demain. Depuis 2007, la croissance de Agaetis a √©t√© progressive et ma√Ætris√©e afin de garantir la continuit√© d‚Äôun √©cosyst√®me passionnant. Leur organisation permet √† chaque membre de Agaetis, de participer et de partager ses id√©es pour d√©finir ce que sera l‚ÄôAgaetis de demain. Ce qu‚Äôils proposent √† leurs clients, ils se l‚Äôappliquent aussi en interne. Chez Agaetis, il ne faut pas avoir peur du changement, leur mot d‚Äôordre : L‚Äôam√©lioration continue, que ce soit pour leur bien-√™tre mais aussi pour la satisfaction de leurs clients. Ils sont maintenant une √©quipe compl√©mentaire et d√©sireux d‚Äôen apprendre tous les jours. Ils travaillent dans un √©cosyst√®me vari√© entour√© de start-ups, PME et grands groupes issues de diff√©rents secteurs : Industrie, Agriculture, B√¢timent, Sant√©, Finance, Assurance, E-commerce. Vous √™tes passionn√©, cr√©atif, savez imaginer et concevoir des solutions permettant le traitement de volumes importants de donn√©es, tout en garantissant la s√©curit√© de celles-ci ? Ce poste est peut-√™tre pour vous ! Le Data Engineer est un pilier pour les projets data . Il construit les structures de donn√©es et met en place les briques technologiques n√©cessaires pour l‚Äôacquisition, l‚Äôanalyse et l‚Äôimpl√©mentation des mod√®les qui utilisent les donn√©es dans un contexte massif de donn√©es. Son r√¥le est de choisir les bonnes technologies selon les besoins en collaboration avec diff√©rents m√©tiers/projets. Le Data Engineer travaille avec les Data Scientist pour savoir quelle architecture est n√©cessaire au d√©veloppement des mod√®les scientifiques afin d‚Äôaider √† industrialiser son mod√®le et de garantir la mont√©e √† l‚Äô√©chelle. Le Data Engineer chez Agaetis est en charge de : S‚Äôassurer que les donn√©es de nos clients soient facilement accessibles afin qu‚Äôelles puissent √™tre exploit√©es par les diff√©rents m√©tiers (DS, BI, applicatifs‚Ä¶) Veiller √† la performance des mod√®les et applicatifs cr√©√©s √† partir des donn√©es Extraire, uniformiser et structurer les donn√©es depuis les datalakes de nos clients Maitriser la mod√©lisation des donn√©es dans un datalake pour assurer la bonne ex√©cution de ses traitements S‚Äôassurer de la fiabilit√© des donn√©es utilis√©es Mettre en place des flux de donn√©es entre les syst√®mes en ingestion et en exposition (batch, API, temps r√©el ‚Ä¶) Explorer de nouvelles technologies, faire de la veille technologique Comprendre l‚Äôarchitecture Datalake dans son ensemble et pr√©coniser des adaptations pour le d√©ploiement et le traitement de ses mod√®les Le Data Engineer que nous recherchons pour int√©grer notre √©quipe Clermontoise, devra disposer d‚Äôau moins deux ans d‚Äôexp√©rience √† un poste similaire. De formation Bac + 5 ou √âcole d‚ÄôIng√©nieur, vous disposez d√©j√† de comp√©tences sur les diff√©rentes technologies autour du flux de donn√©es (Nosql, sql, ETL, hadoop, kafka‚Ä¶) et vous connaissez l‚Äôenvironnement de Machine Learning (sklearn, spark ml, tensorflow..). Connaissances recherch√©es : Rest-API (Flask, FastAPI), Databricks, Ma√Ætrise de Python Ma√Ætrise de diff√©rentes technologies autour du flux de donn√©es : Mongo, Nosql, SQL ETL, Hadoop, Kafka, Databricks, ‚Ä¶ Conna√Ætre l‚Äôenvironnement de Machine Learning : Sklearn, Spark ml, Tensorflow‚Ä¶ Azure, Docker, k8s Rest-API (Flask, FastAPI) Autres connaissances souhait√©es : Ecosyst√®me Apache Hadoop : Spark, Hive, Kafka streaming, AirFlow Cloud : Azure, AWS, Google Cloud‚Ä¶ Langages Big Data : Scala, Python Outils de virtualisation et container : Docker, OCI, ‚Ä¶ Orchestrateurs : Kubernetes‚Ä¶ Base de donn√©es : SQL Server, MySQL, MongoDB, Elasticsearch Conception de pipeline d‚Äôingestion de donn√©es sur des frameworks de calcul distribu√©s (Spark, Akka, Flink, etc.) temps r√©el (Kafka, Storm, Spark Streaming). Les qualit√©s requises sont : La cr√©ativit√© L‚Äôesprit d‚Äô√©quipe La rigueure La communication L‚Äôadaptabilit√© La curiosit√© Veille technologique Trois entretiens : Entretien de pr√©qualification Entretien technique Entretien posture et int√©gration","Agaetis, a subsidiary of Novencia Group, is seeking a Data Engineer to join their team in Clermont-Ferrand. The role involves building data structures and implementing technological components to handle data acquisition, analysis, and model implementation in the context of massive data. The ideal candidate should have at least 2 years of experience and expertise in different data flow technologies, as well as knowledge of machine learning environments, Rest-API, and cloud computing. Qualities needed for the role include creativity, teamwork, communication, adaptability, attention to detail, and curiosity. Three interviews are involved, including a pre-qualification interview, technical interview, and a posture and integration interview.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
274,58072,https://www.welcometothejungle.com/fr/companies/safran-aircraft-engines/jobs/data-engineer-projets-industriels-f-h_gennevilliers,Data Engineer - Projets industriels,Safran Aircraft Engines,"{via,SQL,Mirage,python}",T√©l√©travail partiel possible,"91 avenue d'Argenteuil, Gennevilliers, 92230",A√©ronautique / Spatiale,CDI,2023-03-26,"Safran est un groupe international de haute technologie op√©rant dans les domaines de l'a√©ronautique (propulsion, √©quipements et int√©rieurs), de l'espace et de la d√©fense. Sa mission : contribuer durablement √† un monde plus s√ªr, o√π le transport a√©rien devient toujours plus respectueux de l'environnement, plus confortable et plus accessible. Implant√© sur tous les continents, le Groupe emploie 79 000 collaborateurs pour un chiffre d'affaires de 16,5 milliards d'euros en 2020, et occupe, seul ou en partenariat, des positions de premier plan mondial ou europ√©en sur ses march√©s. Safran s'engage dans des programmes de recherche et d√©veloppement qui pr√©servent les priorit√©s environnementales de sa feuille de route d'innovation technologique. Safran est class√© meilleur employeur mondial 2020 dans son secteur par le magazine Forbes. Safran Aircraft Engines con√ßoit, produit et commercialise, seul ou en coop√©ration, des moteurs a√©ronautiques civils et militaires aux meilleurs niveaux de performance. La soci√©t√© est notamment, √† travers CFM International*, le leader mondial de la propulsion d'avions commerciaux courts et moyen-courriers. Dans le domaine de la propulsion militaire, la soci√©t√© a int√©gralement con√ßu d√©velopp√© et produit le M88 et le M53 qui √©quipent respectivement le Rafale et le Mirage 2000 et sera int√©grateur du moteur du futur avion de combat europ√©en. *CFM International est une soci√©t√© commune 50/50 de Safran Aircraft Engines et GE. Partie 1 : Data Engineer/Scientist Manufacturing Explorer les donn√©es et en extraire des tendances via des m√©thodes de visualisation et des m√©thodes statistiques d'analyse de donn√©es (outils power BI, BrainCube, script python, extraction de base SQL ‚Ä¶), notamment en support en cas de crises et dans l'exploitation de liens produit-process forge, ainsi que sur l'√©valuation de la pertinence de certains contr√¥les Contribuer √† la cr√©ation et l'enrichissement d'un r√©f√©rentiel d'outils facilement r√©utilisables, de m√©thodes d'analyse et les d√©ployer aupr√®s des √©quipes Partie 2 : Chef de projet Maitrise des Proc√©d√©s (MdP) Anime le d√©ploiement de la Maitrise des Proc√©d√©s au sein de IBG - Recueillir aupr√®s des responsables hi√©rarchiques de l'Unit√© Forge les besoins et propositions de mise en oeuvre des m√©thodes de MdP, et participer √† la d√©finition des projets de MdP - Coordonner l'ensemble des projets de MdP de l'Unit√©, et rendre compte de leur avancement en copil - Piloter le plan de formation des personnels impliqu√©s ou destin√©s √† √™tre impliqu√©s dans des projets de MdP, et assurer le coaching et le soutien m√©thodologique des pilotes de projets MdP Participation au r√©seau Maitrise des Proc√©d√©s Safran Aircraft Engines Point focal avec Informatique Industrielle pour la partie projet (mise en place nouvelles solutions, probl√®mes r√©currents etc‚Ä¶). Faire le lien entre la partie m√©tier forge et l'informatique industriel. Ing√©nieur g√©n√©raliste ou syst√®mes informatiques Autonome, rigoureux Gout pour l'industrie, la digitalisation et le pilotage de projets Force de proposition Fait preuve de leadership","Safran Aircraft Engines is looking for a Data Engineer/Scientist Manufacturing and a Chef de projet Maitrise des Proc√©d√©s. The Data Engineer/Scientist Manufacturing will explore data trends and statistical analysis using tools such as Power BI, BrainCube, Python scripts, SQL, etc., and contribute to the creation and deployment of reusable analysis methods. The Chef de projet Maitrise des Proc√©d√©s will oversee the implementation of manufacturing process methods through coordinating projects, providing training and support, and serving as a liaison between the forge business and industrial IT. The ideal candidates should be autonomous, rigorous, proactive, and have a passion for industry, digitalization, and project management.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
275,57057,https://www.welcometothejungle.com/fr/companies/exotec/jobs/data-engineer-3d-simulation_lille,R&D Data Engineer,Exotec,"{Docker,Kubernetes,Python}",T√©l√©travail partiel possible,Lille,"Logistique, Objets connect√©s, Robotique",CDI,2023-03-26,"Exotec met l‚Äôexcellence technologique au service de la red√©finition des relations entre humains et robots. A travers le monde, leurs solutions r√©volutionnent la fa√ßon dont leurs clients d√©livrent leurs produits aux consommateurs finaux. Ils contribuent au succ√®s des plus grandes marques du commerce et de l‚Äôindustrie, tout en am√©liorant les conditions de travail de leurs salari√©s. Par l‚Äôalliance de l‚Äôintelligence artificielle et d‚Äôun hardware performant, leurs robots sont d√©sormais d√©ploy√©s dans le monde entier et leur succ√®s a fait d‚ÄôExotec la premi√®re licorne industrielle fran√ßaise. Rejoindre Exotec, c‚Äôest l‚Äôopportunit√© de donner du sens √† vos comp√©tences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos id√©es, des r√©alit√©s. La r√©volution robotique port√©e par Exotec ne fait que commencer, vous en √™tes ? En rejoignant Exotec, vous ferez partie d‚Äôune √©quipe grandissante d‚Äôune dizaine de personne et vous contribuerez √† l‚Äôam√©lioration de nos syst√®mes. Vous aurez l‚Äôopportunit√© de travailler avec un large √©ventail de sp√©cialit√©s diff√©rentes et sur plusieurs projets faisant usage du deep learning et d‚Äôalgorithmes de pointe. En tant d‚Äôing√©nieur software vous participerez au d√©veloppement de nos outils de g√©n√©ration, d‚Äôannotation et de traitements des donn√©es utilis√©es pour entra√Æner nos syst√®mes de vision. Vos missions : Outils d‚Äôannotation de donn√©es Concevoir et impl√©menter des outils permettant de collecter et annoter les donn√©es d‚Äôentra√Ænement Automatiser les taches r√©p√©titives li√©es √† l‚Äôannotation et √† la v√©rification des donn√©es G√©n√©ration de donn√©es synth√©tiques Contribuer √† la conception et l‚Äôam√©lioration de notre syst√®me de g√©n√©ration de donn√©es 3D synth√©tiques Impl√©mentation de scripts de g√©n√©ration proc√©durale Performance et qualit√© Travailler en collaboration sur du code en Python Proposer et mettre en ≈ìuvre de bonnes pratiques de d√©veloppement Optimiser les algorithmes et les faire passer √† l‚Äô√©chelle sur le cloud Requirements Vous √™tes dipl√¥m√© d‚Äôune grande √©cole d‚Äôing√©nieur ou d√©tenteur d‚Äôun doctorat Vous avez de l‚Äôapp√©tence pour le Deep Learning et la Computer Vision Vous √™tes √† l‚Äôaise en d√©veloppement avec Python et/ou C++ Vous avez des connaissances en mod√©lisation 3D et rendu photor√©aliste avec un logiciel tel que Blender Vous ma√Ætrisez Docker et Kubernetes Vous savez prendre des initiatives et collaborer dans une ambiance d√©contract√©e au sein d‚Äôune √©quipe jeune et dynamique Un niveau d‚ÄôAnglais op√©rationnel, √† l‚Äôoral comme √† l‚Äô√©crit, est n√©cessaire","Exotec, a leading robotics company, is seeking a software engineer with experience in deep learning, computer vision, Python, and C++ to join their growing team. The successful candidate will work on developing tools for data generation and annotation, collaborate on Python code, optimize algorithms, and contribute to various projects using cutting-edge technology such as Kubernetes and Docker. Applicants should have a degree from a top engineering school or hold a Ph.D., as well as an operational level of English.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
271,61325,https://www.welcometothejungle.com/fr/companies/air-liquide/jobs/alit-bi-data-engineer-f-h_paris,ALIT - BI Data Engineer,Air Liquide,"{Azure,Dax,SQL}",NaN,"Paris, 74000","Environnement / D√©veloppement durable, Sant√©, Energie, Digital",CDI,2023-03-29,"Air Liquide a entam√© avec succ√®s sa transformation Digitale et IT , centr√©e sur l'exp√©rience client et l'am√©lioration de de la profitabilit√© des op√©rations, deux piliers majeurs de notre programme NEOS. Cette transformation impacte notre fa√ßon de r√©aliser, g√©rer et monitorer nos op√©rations. Elle implique aussi la d√©finition de nouveaux modes de collaborations, la cr√©ation de nouvelles comp√©tences et de nouveaux postes. Aujourd'hui, le d√©partement Digital & IT poursuit cette transformation tant au niveau de l'infrastructure (GIO), des plateformes data (GDO), que des applications m√©tiers (DSI ou BIS) et des dispositifs cr√©√©s autour de l'innovation, des m√©thodes d'innovation et de la data (Fabs et Factory). Le d√©partement Global Data Operations (GDO) a √©t√© cr√©√© dans l'entit√© Air Liquide IT pour supporter les ambitions du Groupe en mati√®re de gestion des donn√©es, apporter l'expertise technologique pour le d√©veloppement de nouvelles solutions diff√©renciantes pour le business Air Liquide, avec un focus particulier sur les sujets autour de la data dans un premier temps. GDO dans sa phase initiale op√®re trois plateformes : Business Intelligence, Data Lake et API. Au sein de GDO, et rapportant au Product Line Manager BI Group le ou la Technical Lead d√©fini la roadmap technique pour la Product Line en coh√©rence avec la strat√©gie et les besoins exprim√©s par le Solution Owner et le Product Line manager. Il agit en r√©f√©rent pour l'ensemble des d√©veloppeurs et data engineers de l'√©quipe mais aussi des parties externes, en particulier les BIS et entit√©s GDO internationales, requ√©rant son expertise. Il ou elle est int√©gr√©.e sur les projets structurants et travaille en coordination avec les product managers et le m√©tier afin de s'assurer de la bonne r√©ponse technologique face aux besoins exprim√©s. En tant que BI Data Engineer vous aurez les responsabilit√©s suivantes : Concevoir, d√©velopper, tester et mettre en production des traitements de donn√©es dans diff√©rents contextes m√©tier et applicatifs Concevoir, mettre en oeuvre et optimiser, avec les data architects et devops, les pipelines de traitement de la donn√©e permettant l'alimentation des applications data depuis les sources de donn√©es du Groupe Assurer le support des traitements de donn√©es mis en oeuvre Contribuer √† la d√©finition des processus, standards et m√©thodes techniques permettant d'assurer un haut niveau de qualit√© de service et de livrables R√©aliser et partager avec l'√©quipe la veille technologique/l'√©tat de l'art des technologies utilis√©es et √™tre force de proposition S'assurer de la bonne application des r√®gles de s√©curit√© et de confidentialit√© du Groupe au sein de la plateforme, et des traitements de donn√©es (security by design, privacy by design) Assurer le r√¥le de r√©f√©rent technique aupr√®s des data engineer junior intervenant dans l'√©quipe Comp√©tences techniques Exp√©rience minimum de 3-5 ans dans le design et l'impl√©mentation de solution Azure BI de grande envergure Certification sur les produits Data Azure n√©cessaires ( e.g. AZ-900, DP-200, DP-201 ) Excellente ma√Ætrise SQL & Dax Connaissance des m√©thodologies de d√©veloppement Comp√©tences non techniques Faire preuve d'autonomie, d'esprit d'initiative et de motivation Exp√©rience pass√©e de larges projets de BI en connexion directe avec le m√©tier Capacit√© √† travailler dans un environnement matriciel international (BIS, GIO, Fabs Digitales, IT industriel, entit√©s business) Esprit critique, analyse et r√©solution des probl√®mes Capacit√©s de communication √©crites et orales, en particulier pour vulgariser les sujets techniques L'anglais et le fran√ßais lus, √©crits et parl√©s sont indispensables. Localisation g√©ographique : France / Ile de France / Paris - Le poste est bas√© √† Paris XIe sur le Campus de La Digital Factory. Des d√©placements occasionnels pourront √™tre n√©cessaires en France ou √† l'√©tranger. Astreintes √† pr√©voir T√©l√©travail 3jrs/semaine","Air Liquide is seeking a Technical Lead for Global Data Operations (GDO) to define the technical roadmap for the Product Line, act as a reference for developers and data engineers, and work with product managers and business stakeholders to ensure the right technological response to evolving requirements. The position is based at the Digital Factory Campus in Paris and requires an extensive knowledge of Azure BI solutions and relevant certification, as well as excellent SQL and Dax mastery, project management experience, and strong communication skills in English and French.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,0,3,0.04154662416233763
270,61466,https://www.welcometothejungle.com/fr/companies/linxea/jobs/data-engineer_paris,Data Engineer,Linxea,"{PostgreSQL,SQL,DataBricks}",T√©l√©travail partiel possible,"58, Avenue Hoche, Paris, 75008","Banque, FinTech / InsurTech, Finance",CDI,2023-03-29,"Linxea, c‚Äôest le leader ind√©pendant de l‚Äô√©pargne en ligne pour les particuliers et depuis plus de 20 ans nous ≈ìuvrons √† ce que l‚Äô√©pargne soit toujours plus simple √† placer et √† g√©rer pour tous. Linxea est n√© de la conviction qu‚Äôune √©pargne id√©ale passe par une gamme de produits s√©curis√©s, √† bas frais, et un conseil adapt√© au profil de chacun. Au sein d‚Äôune √©quipe agile aux multiples comp√©tences et de taille humaine, tu travailleras en tant que Data Engineer sur l‚Äôinfrastructure Linxea. Ce que l‚Äôon attend de toi : Assurer le run et le monitoring de nos bases de donn√©es : Etre garant(e) de l‚Äôint√©grit√© de la donn√©e et du bon fonctionnement des syst√®mes Etre force de proposition sur l‚Äôam√©lioration des requ√™tes en production Mise en place de l‚Äôalerting et du profiling des requ√™tes Porter la connaissance data aupr√®s de l‚Äôensemble des √©quipes de Linxea Participer au sprint sur les probl√©matiques de mod√©lisation des donn√©es et tests de performances Mettre √† disposition et maintenir √† jour les environnements de recette et production de donn√©es Anonymiser les donn√©es en fonction des environnements Faire √©voluer le syst√®me actuel avec la construction d‚Äôun nouveau r√©f√©rentiel data Fiabiliser les sources de donn√©es Mettre √† disposition la donn√©e √† tous les services de Linxea Construire un datalake Int√©grer des outils de data visualisation et d‚Äôanalytique Tes comp√©tences : Pr√© requis = la ma√Ætrise SQL Server 2019 Capacit√© √† √©voluer vers d‚Äôautres syst√®mes de bases de donn√©es (PostgreSQL, DataBricks, ‚Ä¶) 4 √† 5 ans d‚Äôexp√©rience avec une visibilit√© assez globale sur un projet data dans des environnements de PME, startup et/ou scaleup Mise en place d‚Äôalerting et de profiling des requ√™tes Ma√Ætrise de la programmation SQL, T-SQL Orient√©(e) r√©sultat Esprit d‚Äô√©quipe, autonomie, pragmatisme et positivit√© ! Une visio/un appel t√©l√©phonique avec Anne-Charlotte, notre Talent Acquisition Manager Un entretien tech en visio avec Islem, l‚Äôun de nos D√©veloppeurs Un entretien tech avec Vincent, notre CTO Un entretien RH avec Anne-Charlotte et Laure, notre DRH, avant - on l‚Äôesp√®re - une proposition finale !","Linxea is seeking a data engineer with 4-5 years of experience in managing databases and a strong command of SQL Server 2019, as well as proficiency in query optimization, data integrity, and data visualization tools. The role involves ensuring data accuracy and system efficiency, proposing improvements, and collaborating with Linxea's teams towards achieving the company's objectives. The ideal candidate should be a team player, results-oriented, self-sufficient, and pragmatic. An interview process includes a discussion with Linxea's Talent Acquisition Manager, a technical interview with a developer, and an HR interview with the HR Director.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
269,61606,https://www.welcometothejungle.com/fr/companies/ascor-communication/jobs/data-engineer-h-f_rennes,Data Engineer,Ascor Communication,"{Talend,SAP,Informatica,tableau,SQL,Qlik,Tableau}",T√©l√©travail partiel possible,"31, Rue Guy Ropartz, Rennes, 35700",Formation,CDI,2023-03-29,"Ascor Communication est une entreprise familiale rennaise, en forte croissance, co-dirig√©e par un trin√¥me femmes/homme, parfaitement compl√©mentaire. Ascor Communication est l‚Äôune des r√©f√©rences fran√ßaise dans le secteur du digital learning. Premi√®re entreprise en France dans son secteur √† √™tre certifi√©e Qualiopi, Ascor Communication a un haut niveau d‚Äôexigence de la satisfaction client qui repose sur l‚Äôimplication et l‚Äôadh√©sion de tous les salari√©s √† cet objectif. Dans le cadre d‚Äôune cr√©ation de poste et de la mise en place de notre entrep√¥t de donn√©es, nous recherchons un Data Engineer H/F. Rattach√© au Directeur des Syst√®mes d‚ÄôInformation (DSI), vous aurez la responsabilit√© de ce projet. Vous aurez notamment pour missions de : Mettre en ≈ìuvre un projet Data/Business Intelligence ; Participer au recueil du besoin aupr√®s des directions m√©tiers ; R√©diger des sp√©cifications fonctionnelles, applicatives, et techniques ; Collecter les donn√©es depuis diverses sources et les traiter dans un entrep√¥t de donn√©es ; Accompagner les services m√©tiers dans l‚Äô√©laboration de tableau de bord ; Pr√©parer et d√©rouler les tests ; Accompagner dans la validation de livrables, l‚Äôassistance √† la recette et la conduite du changement sur le projet ; Participer √† la maintenance corrective et √©volutive de l‚Äôentrep√¥t de donn√©es. De formation sup√©rieure, vous justifiez d‚Äôune exp√©rience de 5 ans. Vous ma√Ætrisez les sujets de construction d‚Äôentrep√¥t de donn√©es et √™tes capable d‚Äôen √©changer avec des interlocuteurs m√©tiers. Vous b√©n√©ficiez d‚Äôune expertise sur des outils ETL du march√© (Informatica, Talend, Big Query, Data Factory, etc) et sur la cr√©ation de tableau de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI‚Ä¶). SQL n‚Äôa plus de secrets pour vous. Votre esprit d‚Äôanalyse et de synth√®se sont souvent reconnus. Vous √™tes autonome et organis√©, et vous savez piloter des projets. Vous appr√©ciez travailler en √©quipe, dans un contexte multi-projets. Nous vous proposons : Une formation interne de plusieurs jours (produits, outils, process‚Ä¶) et un accompagnement tout au long de la collaboration ; Un cadre de travail √† taille humaine ; Une forte dynamique du fait de notre croissance ; Des bureaux desservis par les transports en commun ; 6 semaines de cong√©s. Processus de recrutement : 1. Merci de nous faire parvenir un CV ainsi que quelques lignes de votre motivation pour ce poste ; 2. Vous recevrez un accus√© de r√©ception de votre candidature ; 3. Si votre candidature est retenue, un premier √©change t√©l√©phonique sera r√©alis√© ; 4. Si ce dernier est concluant il aboutira √† second entretien.","Ascor Communication, a French digital learning reference, is seeking a Data Engineer to implement a Data/Business Intelligence project. The ideal candidate should have at least 5 years of experience with data warehouse construction, ETL tools, dashboard creation, SQL, and project management skills. The company offers an internal training, a small working environment, and six weeks of holiday per year. The recruitment process includes CV submission, a reception confirmation, two telephone interviews, and final approval.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
267,56755,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-azure-h-f_levallois-perret,Data Engineer / Azure,Micropole,"{Microsoft,durable,GCP,Databricks,Scala,SPARK,AWS,Synapse,R,Spark,Azure,Java,SQL,Python}",T√©l√©travail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√© : Poste : Data Engineer /Azure Localit√© : Levallois-Perret Type de contrat : CDI Niveau d‚Äôexp√©rience : au moins 2 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services. Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! Vous accompagnez nosclients √† travers toutes les √©tapes de leur transformation num√©rique dans unenvironnement Microsoft Azure : De la d√©finition des axes strat√©giquesd'adoption du cloud, du design, au d√©ploiement des outils, √† la migration desapplications et services. Vous aidez nos clients √† gagner en performance,agilit√©, flexibilit√© du SI et √† int√©grer les Innovations les plus avanc√©es. Dans vos missions quotidiennes , vous serez amen√©(e) √†‚ÄØ: Apporter votre expertise √† nos clients pour garantir une valeur ajout√©e rigoureuse et innovante Participer activement √† la r√©alisation technique des projets de nos clients Accompagner et conseiller les clients sur les meilleures pratiques, les technologies et outils les plus adapt√©s au contexte. R√©aliser des pr√©sentations, d√©monstrations, POC ou Pilotes pour mettre en lumi√®re les recommandations technologiques. √ätre constamment en veille technologique Transf√©rer des comp√©tences sp√©cifiques aux √©quipes techniques de nos clients Vous avez un minimum de 2 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Cloud Microsoft Azure ou √† d√©faut une certification Azure avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Solide Exp√©rienceTechnique Dans Les Domaines Suivants Azure Data Factory Azure Synapse Pipeline Spark/Scala pyspark Python SQL, PL-SQL Azure Databricks Les plus selon l‚Äôexp√©rience Connaissancede Azure DevOps (Repos, Pipeline, Test) ou autres outils de gestion CI/CD Connaissancede la m√©thodologie Agile Scrum Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ; Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visio Etape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) LA VIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ; Participation √† des projets internes sur la base du volontariat. √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en savoir plus : https://www.linkedin.com/company/micropole #LI-DM1 Comp√©tences Python SPARK Scala Azure/AWS/GCP Data Services PYSPARK","Micropole is seeking a Data Engineer with at least 2 years of experience on data projects, including at least one on Microsoft Azure cloud or an Azure certification. The candidate must have a solid technical background in Azure Data Factory, Azure Synapse Pipeline, Spark/Scala, Python, SQL, PL-SQL, and Azure Databricks. The successful candidate will be responsible for providing expertise to clients, participating in technical project implementation, advising clients on the best practices, creating demonstrations, and staying updated on technological developments.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
276,58083,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont_NATIX_o09wgpL,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"avenue de la libert√© , Charenton-Le-Pont, 94018","Banque, Transformation, Assurance",CDI,2023-03-26,"Natixis fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France. Fort d‚Äôun portefeuille de marques comprenant notamment Natixis Investment Managers et Natixis Corporate and Investment Banking, Global Financial Services est compos√© de deux m√©tiers ‚Äì la gestion d‚Äôactifs et de fortune et la banque de grande client√®le. Avec plus de 12 000 collaborateurs dans 35 pays, nos experts accompagnent leurs clients, partout dans le monde, en leur proposant des solutions de financement et d‚Äôinvestissement innovantes et durables. Engag√©s en faveur de la transition environnementale, technologique et soci√©tale, ils se distinguent par un fort esprit entrepreneurial. Au sein de la direction CIO CIB Risks, dans le d√©partement Data Processing and Metrics, vous rejoignez l'√©quipe Metric Services P&L Explain qui est compos√©e de 5 personnes. Dans cette √©quipe nous travaillons √† calculer l'explication du P&L (profit and loss) par les sensibilit√©s. Notre application est √©galement partie prenante des calculs de Stress Tests et IPV (ind√©pendance price validation). Nous intervenons donc sur plusieurs cha√Ænes de valeurs, aupr√®s de notre client : le d√©partement des risques de march√©. Au quotidien vous avez pour missions de : Contribuer aux sp√©cifications techniques et fonctionnelles ; Intervenir de la phase de conc√©ption aux tests : d√©veloppement de nouvelles fonctionnalit√©s, revue de code, documentation, ... ; Travailler sur des probl√©matiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et am√©liorer la software factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 pour avoir une production ponctuelle, de qualit√© et ma√Ætris√©e. Nos principaux interlocuteurs sont : le d√©partement des risques de march√© (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk) et les √©quipes support et production √† Porto. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Vous travaillez dans un environnement international, au sein d'une communaut√© d'experts qui place l'excellence, l'impact et l'action collective au c≈ìur de tout ce qu'elle entreprend. Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en finance et/ou en informatique avec une sp√©cialisation en big data, vous avez une exp√©rience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous ma√Ætrisez : * La finance de march√©, et plus pr√©cis√©ment le march√© des risques et PNL (m√©thode d'explication du PNL) ; * Les sp√©cifications des besoins de l'√©quipe et vous √™tes capable de proposer des maquettes aux utilisateurs en autonomie. Vous √™tes : * P√©dagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des am√©liorations continues. Vous ma√Ætrisez l'anglais avec un niveau B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis, a leading financial services company, is seeking a Data Engineer with at least 2 years of experience in Hadoop, Spark, and Scala. The role involves contributing to technical and functional specifications, developing new functionalities, optimizing performance, and maintaining software and development environments. The successful candidate must have a background in finance and/or computer science with expertise in finance market and PNL explanation, and possess pedagogical, autonomous, and improvement-oriented skills. The position is based in Charenton-le-Pont, France with 10 days of telework per month and a comprehensive benefits package.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
265,56955,https://www.welcometothejungle.com/fr/companies/cenova/jobs/data-engineer-retail-h-f_marcq-en-baroeul,Data Engineer | Retail ‚Äì,Cenova,"{PowerBI,Kafka,GCS,BigQuery,GCP,SQL,Github}",T√©l√©travail partiel possible,"869 Avenue de la R√©publique, Marcq-En-Baroeul, 59700",IT / Digital,CDI,2023-03-26,"Cabinet √† forte croissance, Cenova accompagne ses clients du #Luxe, du #Retail et du #Tourisme/Loisirs dans leurs projets de transformation digitale et data. Pr√©sent √† Paris et Lille, Cenova c‚Äôest avant tout un cabinet √† taille humaine avec : ‚úÖ Un respect de vos attentes concernant vos missions et une r√©elle proximit√© manag√©riale pour vous accompagner, ‚úÖ La CenoLife pour vous apporter une vie de cabinet stimulante (afterworks, s√©minaires, √©v√®nements sportifs‚Ä¶), ‚úÖ La CenoAcademy pour vous former et nos CenoTalk pour partager nos expertises et connaissances, ‚úÖ De multiples avantages en compl√©ment d‚Äôune r√©mun√©ration attractive : la mutuelle Alan, un CSE, des titres restaurants - Swile, des primes vacances, le t√©l√©travail et plein d‚Äôautres jolis avantages‚Ä¶ Ces quelques mots suscitent votre curiosit√© ? Candidatez ! Votre personnalit√© et votre savoir-faire feront le reste. Notre processus se d√©roule en 3 entretiens : RH, Manager et rencontre avec un associ√© ! Vous travaillerez chez l‚Äôun de nos clients, sp√©cialiste du retail, au sein de l‚Äô√©quipe Data sur le d√©veloppement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes : ‚Ä¢ Participer aux rituels agiles de l‚Äô√©quipe, ‚Ä¢ Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de l‚Äôentreprise, ‚Ä¢ D√©velopper les solutions data (Alimentation, stockage, mod√©lisation, restitution), ‚Ä¢ Valider la qualit√© des d√©veloppements de votre √©quipe, ‚Ä¢ Am√©liorer et optimiser le patrimoine actuel de votre √©quipe, ‚Ä¢ Maintenir les solutions existantes (Run), ‚Ä¢ Contribuer √† la construction du nouveau socle et des services sur GCP (Google Cloud Platform), ‚Ä¢ Accompagner les m√©tiers sur les bonnes pratiques de l‚Äôexploitation de la Data. Cela fait au moins 2 ans que vous travaillez sur des missions de Data Engineer et vous disposez d‚Äôune grande app√©tence technique. Vous appr√©ciez comprendre le cycle de vie de la donn√©e et vous √™tes √† l‚Äôaise avec les concepts de data lineage, data gouvernance, data privacy. Vous √™tes amateur.e de datavisualisation, id√©alement avec PowerBI. Travailler en mode agile ? Vous adorez ! Bien √©videmment, vous avez le contact facile et vous comprenez les enjeux Business et adaptez vos analyses en ce sens. Vous √™tes proactif(ve), autonome, bon(ne) communiquant(e), fluent in english et √† l‚Äôaise dans un environnement matriciel et challengeant. Environnement technique : SQL, ETL Power BI, Data Studio CI/CD, Github, Terraform, Kafka Google Cloud Platform (GCS, BigQuery) 3 entretiens! C‚Äôest rapide et efficace! Le 1er avec l‚Äô√©quipe RH, le 2d avec un manager et le 3√®me avec l‚Äôun de nos associ√©s.","Cenova, a growing company serving clients in luxury, retail, and tourism sectors in their digital and data transformation projects, seeks a data engineer with at least two years of experience. The ideal candidate must possess technical expertise in data lineage, governance, and privacy, have excellent communication skills, and be comfortable working in an agile environment. Fluency in English is essential, as is familiarity with SQL and ETL, Power BI, Data Studio, CI/CD, GitHub, Terraform, Kafka, and Google Cloud Platform.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
278,56699,https://www.welcometothejungle.com/fr/companies/devoteam-creative-tech/jobs/creative-tech-fimakers-data-engineer-f-h_levallois-perret,Creative Tech - FIMAKERS - Data engineer,Devoteam Creative Tech,"{GCP,Microsoft,Azure,Scala,DataStudio,Looker,TensorFlow,AWS,QlikView,R,Keras,Python,Tableau}",T√©l√©travail partiel possible,"73 Rue Anatole France, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"La tribu Tech, est l‚Äô√©quipe experte en technologie de Devoteam Creative Tech. Au sein d‚Äôun collectif de 800 professionnels experts du digital, ils imaginent et concr√©tisent des produits & services performants dans la dur√©e aux c√¥t√©s de designers, product owners/managers et d‚Äôexperts data. Leur engagement ? Agir positivement sur la transformation de la culture et de l‚Äôorganisation de leurs clients par la transmission de leurs savoir faire. L‚Äôagilit√© et les bonnes pratiques de d√©veloppement sont au c≈ìur de leur ADN, qu‚Äôils interviennent au sein des √©quipes de leurs clients ou en feature teams depuis leur studio parisien. Tu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©. Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de : Analyser les besoins clients Animer des ateliers afin d‚Äô√©tudier et cadrer les besoins clients Pr√©coniser les solutions et architectures cibles D√©finir les m√©thodologies de d√©ploiement et plans de migration R√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniques Construire les architectures de donn√©es Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) Construire et d√©ployer les pipelines de donn√©es (ETL) Assurer la migration des donn√©es vers les nouveaux environnements Analyser les donn√©es Analyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio‚Ä¶) S√©lectionner, entra√Æner, √©valuer et d√©ployer des mod√®les pr√©dictifs en s‚Äôappuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les √©quipes clients aux m√©thodes et concepts du cloud Tu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif de devenir certifi√© Google sur ta practice. Dipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou d'un Master 2 en Informatique, tu disposes d'une exp√©rience significative au sein de projets Data : architecture, traitement ou analyse de donn√©es. Tu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python). Tu as de bonnes comp√©tences dans de l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚Äôanalyse Tu es passionn√©(e) par la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine Learning Une connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, ‚Ä¶) est un plus. Tu as une solide compr√©hension de la dimension technique et fonctionnelle des projets IT Curieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚Äôanalyse Ta ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte international","The La Tribu Tech team at Devoteam Creative Tech is seeking a Data Engineer to assist clients with digital transformation through the implementation of data projects with Google Cloud Platform and associated open source solutions. The ideal candidate should have experience in data architecture, as well as knowledge of programming languages like Scala, Python, or R. Additionally, proficiency in cloud provider data tools and a strong understanding of IT project technical and functional dimensions are preferred.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
281,56466,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret,Data Engineer / GCP,Micropole,"{Microsoft,durable,Scala,AWS,R,Spark,GCP,Java,Python}",T√©l√©travail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√© : Poste : Data Engineer / GCP Localit√© : Levallois-Perret Type de contrat : CDI Niveau d‚Äôexp√©rience : au moins 2 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services. Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! Au sein de notre agence bas√©e √† levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer GCP (F/H) , vousaccompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leurprocessus et dans leur strat√©gie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amen√©(e) √†‚ÄØ: D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence GCP. Vos comp√©tences techniques : Vous avez un minimum de 2 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ; Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visio Etape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) LA VIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ; Participation √† des projets internes sur la base du volontariat. #LI-DM1 Comp√©tences GCP","Micropole is seeking a Data Engineer, with a minimum of 2 years of experience on Cloud GCP, to develop and maintain customer use cases, model and analyze data in the cloud, and ensure data security/compliance. The successful candidate should have programming skills, knowledge of data modeling tools and industrialization, and be passionate, rigorous, curious, and able to work as part of a team. Micropole offers opportunities for personal and professional development, as well as a dynamic internal life with regular knowledge-sharing events and the opportunity to participate in internal projects.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
285,56660,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_paris,DATA ENGINEER,ACTINVISION,"{Microsoft,MySQL,GCP,Talend,Matillion,AWS,Snowflake,Alteryx,Azure,Java,SQL,Python,Tableau}",T√©l√©travail partiel possible,"64-66 Rue des Archives, Paris, 75003","Intelligence artificielle / Machine Learning, Transformation, Big Data",CDI,2023-03-26,"Fond√©e en 2014, Actinvision est un regroupement de Data Heroes accompagnant diff√©rents acteurs dans leur transformation vers une culture data. Cr√©ant un lien de confiance avec ses clients, elle donne √† ces derniers les moyens d‚Äôanalyser leurs innombrables donn√©es. M√™lant expertise technique de haut niveau et cr√©ativit√© sans limites, elle d√©veloppe des approches personnalis√©es destin√©es √† valoriser les donn√©es de l‚Äôorganisation. Actinvision, c‚Äôest aujourd‚Äôhui plus de 300 clients en France et √† l‚Äôinternational dans divers secteurs, allant de l‚Äôindustrie √† la grande distribution en passant par le secteur financier. Son fief se trouve dans la r√©gion Grand Est et plus pr√©cis√©ment en Alsace, √† Strasbourg. C‚Äôest de l√† qu‚Äôest dirig√© l‚Äôensemble des op√©rations, notamment men√© √† travers un second bureau, positionn√© √† Paris. Actinvision est, en interne, une communaut√© multiculturelle ‚Äúfun‚Äù orient√©e autour de la data et, en externe, un partenaire reconnu et privil√©gi√© par de nombreuses entreprises leaders du march√© : Tableau, Alteryx, Snowflake, Microsoft, Talend, etc. Entreprise accr√©dit√©e ‚ÄúHappy at Work‚Äù par ChooseMyCompany Vous serez amen√©(e) √† travailler sur diff√©rents projets innovants , pour des clients de toute taille , dans des secteurs divers et vari√©s tels que l‚Äôagroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l‚Äô√©nergie, l‚Äôindustrie, la pharma/chimie ou encore la sant√©. En tant que Data Engineer passionn√©(e), vous aiderez nos clients √† relever les challenges d‚Äôaujourd‚Äôhui et de demain en int√©grant leurs donn√©es au sein d‚Äôinfrastructures, On-Premise et Cloud. A la suite d‚Äôune p√©riode d‚Äôint√©gration destin√©e √† vous familiariser avec la m√©thodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l‚Äôanalyse du besoin client √† la livraison de la solution technique en passant par le chiffrage et les d√©veloppements. Vous √©voluerez en √©quipe mais √©galement de mani√®re autonome dans un environnement technique porteur d‚Äôinnovations incluant par exemple la mod√©lisation et la construction d‚Äôentrep√¥ts de donn√©es (Data Warehouses), le design de flux d‚Äôint√©gration au moyen d‚Äôoutils (e.g. Talend ou ADF, Matillion etc. ) permettant l‚Äôalimentation de ces derniers, ou encore la mise en place et l‚Äôoptimisation dans le respect des bonnes pratiques d‚Äôarchitectures Data, notamment Cloud (e.g. Snowflake ou Azure). Le d√©veloppement des comp√©tences est un aspect primordial. Ce d√©veloppement continu est appuy√© par les ressources officielles mises √† disposition par l‚Äôensemble des √©diteurs partenaire d‚ÄôActinvision et compl√©t√© par des ressources internes. Les comp√©tences acquises pourront √™tre valoris√©es aux travers de certifications √©diteurs hautement qualifiantes. MISSIONS PRINCIPALES : ‚Ä¢ Participer en √©quipe ou de fa√ßon autonome √† la mise en ≈ìuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie int√©gration et stockage de la donn√©e ‚Ä¢ Recueil du besoin client technico-fonctionnel permettant la mise en place d‚Äô architectures pour la collecte et l‚Äôextraction de donn√©es depuis diverses sources (bases de donn√©es Cloud, applications m√©tier, API, etc.), la manipulation et la transformation de ces donn√©es, puis le chargement de ses derni√®res au sein de base de donn√©es de type Data Warehouses (DWH) ‚Ä¢ Design des infrastructures/architectures Data et mod√©lisation des DWH cibles, lesquels seront principalement utilis√©s dans le cadre d‚Äôop√©rations de Reporting et/ou de Data Visualisation ‚Ä¢ R√©alisation de flux d‚Äôint√©gration et transformation de donn√©e De formation Bac+5 en informatique, vous disposez de minimum 1 an d‚Äôexp√©rience sur un poste similaire. Savoir-faire, comp√©tences techniques requises : ‚Ä¢ Langage SQL et mod√©lisation DWH ‚Ä¢ Pratique d‚Äôun outil d‚Äôint√©gration ETL / ELT ‚Ä¢ Connaissances en bases de donn√©es relationnelles (e.g. SQL Server ou MySQL) ‚Ä¢ Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP) ‚Ä¢ Connaissances de la cha√Æne de valeur de la Data, et particuli√®rement de la BI Savoir-faire, comp√©tences techniques appr√©ci√©es : ‚Ä¢ Connaissances en architectures Cloud (s√©curit√©, performances, ma√Ætrise des co√ªts, etc.) ‚Ä¢ Programmation proc√©durale, e.g. T-SQL ou PL/SQL ‚Ä¢ Un langage de programmation orient√© objet, e.g. Java ou Python ‚Ä¢ A l‚Äôaise avec l‚Äôutilisation d‚ÄôAPI / de Web Services ‚Ä¢ Notions sur l‚ÄôESB Savoir-√™tre, comp√©tences fonctionnelles : ‚Ä¢ Passion pour la Data ‚Ä¢ Autonomie / Travail et esprit d‚Äô√©quipe (incluant le partage des connaissances) ‚Ä¢ Force de proposition / Capacit√© √† rechercher et trouver des solutions ‚Ä¢ Cr√©ativit√© et curiosit√© ‚Ä¢ Dynamisme et r√©activit√© ‚Ä¢ Sens du service ‚Ä¢ Capacit√© √† participer √† l‚Äôanimation de la communaut√© (interne et externe) ‚Ä¢ Anglais technique ‚Ä¢ Pour un poste confirm√© : Exp√©rience probante dans les domaines du DWH et de l‚Äôint√©gration de donn√©es (cloud et/ou on-prem) Moyenne de temps du process de recrutement chez Actinvision : 15 jours Pr√© qualification t√©l√©phonique : 15 √† 20 minutes Entretien technique : 1h00 Entretien RH : 1h00","Actinvision, a Data Heroes group, seeks a passionate Data Engineer with at least one year of experience to help clients integrate their data into On-Premise and Cloud infrastructures. The role involves working on innovative projects across various sectors, participating in all project phases, and designing data architecture and models. Required skills include SQL, DWH modeling, ETL/ELT tools, and Cloud Data platforms. Knowledge of BI and familiarity with Cloud architectures, procedural programming, Web Services, and ESB is desirable. The position requires autonomy, teamwork, creativity, and a service-oriented mindset.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,2,1,0.04154662416233763
304,57109,https://www.welcometothejungle.com/fr/companies/learning_planet_institute/jobs/data-engineer_paris,Data Engineer,Learning Planet Institute,"{Microsoft,Azure,Grafana,PostgreSQL,Airflow,Kubernetes,Docker,via,R,Spark,Git,NoSQL,SQL,Python,Bash}",T√©l√©travail partiel possible,"Rue Charles V, Paris, 75004",Association,CDI,2023-03-26,"Depuis 2006, en s‚Äôappuyant sur l‚Äôintelligence collective, l‚Äôassociation Learning Planet Institute r√©invente l‚Äôapprentissage √† tous les √¢ges de la vie afin de construire des soci√©t√©s apprenantes, durables et inclusives, aptes √† relever les d√©fis complexes auxquels nous sommes confront√©s. L‚ÄôInstitut a pour mission d‚Äôexplorer, d‚Äôexp√©rimenter et de partager des nouvelles mani√®res d‚Äôapprendre et de coop√©rer afin de r√©pondre aux besoins de la jeunesse et de la plan√®te. Il encourage et essaime une culture, des m√©thodes et des outils d‚Äôempowerment pour transformer les organisations. Enfin, il anime des communaut√©s et accompagne des ¬´ Learning Planetizens ¬ª √† prendre soin d‚Äôeux, des autres et de la plan√®te. Pour atteindre ses objectifs, le Learning Planet Institute cr√©e des programmes de recherche et d‚Äôenseignement bas√©s sur l‚Äôinterdisciplinarit√©, la diversit√© et l‚Äôinitiative. Il s‚Äôappuie sur les synergies entre ses activit√©s : R&D (chercher), √âducation (former), Alliance internationale (f√©d√©rer), Transformation des organisations (transformer) et √âcosyst√®mes num√©riques (outiller). Con√ßu et d√©velopp√© au Learning Planet Institute, WeLearn est une plateforme num√©rique de navigation au sein des ressources d‚Äôapprentissage. Elle est propuls√©e par des algorithmes √† l‚Äô√©tat de l‚Äôart de Intelligence Artificielle. √Ä partir d‚Äôun texte fourni par l‚Äôutilisateur, WeLearn recommande des ressources pertinentes de grande qualit√© lui permettant de d√©couvrir des informations, d‚Äôacqu√©rir des connaissances et d‚Äôidentifier des experts. Le Learning Planet Institute travaille actuellement avec des organisations partenaires pour adapter WeLearn √† leurs utilisateurs et √† leurs ressources sp√©cifiques et recrute , dans ce cadre, un Product manager pour renforcer l‚Äô√©quipe. Sous la responsabilit√© du Directeur R&D, vous aurez ainsi pour missions: Concevoir/am√©liorer l‚Äôarchitecture technique autour de services de Machine Learning (syst√®me de recommandation) Concevoir/am√©liorer les pipelines en alimentant ces services Pr√©parer le passage √† l‚Äô√©chelle de ces services Ma√Ætrise des outils ‚Äúclassiques‚Äù : Python, SQL, Bash et Git Exp√©rience des bases de donn√©es relationnelles (PostgreSQL) Exp√©rience des technologies Big Data, comme les bases de donn√©es NoSQL et le traitement distribu√© via Spark Exp√©rience d‚Äôune plateforme cloud, de pr√©f√©rence Microsoft Azure Exp√©rience des outils de gestion des flux de donn√©es (Airflow) Exp√©rience avec les m√©caniques de travail et les outils li√©es √† la CI/CD (Airflow Connaissances des outils Ops (Docker, Kubernetes, Grafana‚Ä¶) Connaissances en Machine Learning Excellence op√©rationnelle et sens du d√©tail Nous nous engageons √† effectuer des recrutements aussi inclusifs que possible. Nous nous basons donc uniquement sur votre personnalit√© et vos comp√©tences pour la s√©lection. Ce recrutement est assur√© par notre partenaire The Allyance, cabinet de recrutement. Vous pouvez √©galement envoyer votre candidature √† l‚Äôadresse mail suivante : morgane@theallyance.one","The Learning Planet Institute is seeking a Product Manager to strengthen its team's adaptation of WeLearn, a digital learning resources platform, to partner organizations. The role includes improved architecture and pipelines for Machine Learning services, and proficiency in Python, SQL, Bash, Git, PostgreSQL, Airflow, CI/CD, and Docker/Kubernetes necessary. The ideal candidate also possesses knowledge of Ops tools and Machine Learning. Furthermore, the Learning Planet Institute is committed to inclusive hiring based on personality and skills alone.",N,N,N,2,1,0.04154662416233763
264,57156,https://www.welcometothejungle.com/fr/companies/stoik/jobs/senior-software-engineer_paris,Data Engineer,Sto√Øk,"{Metabase,SQL,python,AWS}",T√©l√©travail partiel possible,"4 Rue Euler, Paris, 75008","FinTech / InsurTech, SaaS / Cloud Services, Cybers√©curit√©",CDI,2023-03-26,"Sto√Øk est la premi√®re insurtech sp√©cialis√©e sur le risque cyber en Europe. Notre mission est de prot√©ger les PME des cyberattaques en associant une couverture d‚Äôassurance avec des outils de monitoring du risque dans un seul et m√™me produit simple, digital, et distribu√© principalement √† travers notre r√©seau de courtiers partenaires. En quelques mois, nous avons construit une √©quipe de pr√®s de 30 talents, cr√©√© et lanc√© notre produit sur le march√© fran√ßais, fait signer plus d‚Äôune centaine de clients et lev√© quelques millions d‚Äôeuros avec les meilleurs fonds d‚Äôinvestissement de la plan√®te. √Ä l‚Äôorigine de Sto√Øk, un √©tonnement : comment les petites entreprises peuvent-elles rester si vuln√©rables face √† une menace aussi d√©vastatrice que les cyberattaques ? Aujourd‚Äôhui, les dirigeants de TPE et PME ont conscience de ce risque. Mais la plupart manque de connaissances techniques et de ressources financi√®res pour s‚Äôen pr√©munir convenablement. Sto√Øk offre la possibilit√© aux entreprises de r√©duire fortement leur risque gr√¢ce √† un ensemble de bonnes pratiques. Et comme le risque z√©ro n‚Äôexiste pas, nous les assurons ! Nous avons lev√© pr√®s de 15 millions d‚Äôeuros avec certains des meilleurs investisseurs au monde (Andreessen Horowitz, Alven & Anthemis) et d‚Äôincroyables Business Angels (CEO de wefox, Luko, Dashlane, KKR, etc.), et nous avan√ßons rapidement pour devenir les leaders europ√©ens sur le march√© en plein essor de la cyber-assurance. Trouver des solutions simples a des probl√®mes complexes / capacit√© √† expliquer et convaincre. Comprendre le risque cyber. Vous travaillerez en √©troite collaboration avec nos experts cyber et backend pour identifier, collecter et synth√©tiser les donn√©es utiles, obtenues ou non √† travers nos outils, pour la quantification du risque cyber. Le but final est de comprendre finement l‚Äôexposition d‚Äôune entreprise donn√©e afin de l‚Äôaider √† am√©liorer sa posture de s√©curit√©. Structurer l‚Äôentreprise. Vous travaillerez au maintien et √† l‚Äôam√©lioration de nos pipelines, de notre data lake et de nos dashboards. Faire partie d‚Äôune √©quipe. Nous avons l‚Äôambition de cro√Ætre rapidement. Chacun chez Sto√Øk y participera, notamment en recrutant des personnes, en am√©liorant nos processus et en nous aidant √† nous d√©velopper en tant qu‚Äôentreprise. Must-haves Maitrise avanc√©e de python (notamment web scrapping) et de SQL Exp√©rience en stockage de donn√©es et pipelines ETL Exp√©rience en architecture de donn√©es dans le cloud (AWS id√©alement) App√©tence pour la cybers√©curit√© Nice to have Comp√©tence en cybers√©curit√© (OSCP, exp√©riences pass√©es, etc) Exp√©rience sur Metabase Notre offre Un projet ambitieux. Une √©quipe hautement qualifi√©e avec laquelle travailler au quotidien. La propri√©t√©, la libert√© et l‚Äôautonomie. Un package attractif et des BSPCEs. Un lieu de travail agr√©able dans le centre de Paris. Le t√©l√©travail partiel est possible. Nous avons besoin de vous d√®s que possible. Screening (30 min) Test techniques (chez vous) Rencontre de l‚Äô√©quipe (2h)","Sto√Øk, Europe's first insurtech specializing in cyber risk, seeks a cybersecurity data analyst to work closely with their expert cyber and backend teams to collect and synthesize critical data. The ideal candidate must have advanced proficiency in Python (particularly web scraping) and SQL, experience in data storage and ETL pipelines, and proficiency in cloud data architecture (preferably AWS). Additional cybersecurity competency and experience with Metabase are desirable. Sto√Øk offers a highly skilled team, autonomy, an attractive package, partial telecommuting, and an ambitious project.",Bac +3,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
286,56677,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-f-h_nantes,Data Engineer GCP,Micropole,"{Microsoft,durable,Azure,Scala,AWS,R,Spark,GCP,Java,Python}",T√©l√©travail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. Comme nous vous √™tes convaincu(e) que l‚Äôoptimisation du‚ÄØpatrimoine data des entreprises est la cl√© de leur performance ?‚ÄØVous voulez aider les entreprises‚ÄØ√† devenir plus agiles, et √† am√©liorer leur niveau de performance‚ÄØgr√¢ce √†‚ÄØla puissance du Cloud‚ÄØ?‚ÄØVous voulez rendre les entreprises‚ÄØdata intelligentes et les aider √† se transformer au travers des nouvelles technologies qu‚Äôam√®ne le‚ÄØcloud‚ÄØ?‚ÄØVous souhaitez rejoindre un groupe pionnier des grandes innovations data, cloud et digitales‚ÄØ? Si vous avez‚ÄØr√©pondu ¬´‚ÄØOui‚ÄØ¬ª‚ÄØ√† chacune de ces questions et √™tes pr√™t(e) √† rejoindre l‚Äôaventure‚ÄØMicropole en tant que Data Engineer GCP (F/H). N'attendez plus ! devenez un(e) innovativePeople pour l‚Äôun de nos‚ÄØclients grands-comptes. Micropole accompagne les entreprises √† devenir ‚ÄúData-centric‚Äù gr√¢ce √† la puissance du Cloud. Forte de consultants, d‚Äôexperts techniques et d‚Äôarchitectes sp√©cialis√©s dans les solutions AWS, Azure et GCP, Micropole aide les entreprises √† devenir plus agiles, et √† am√©liorer leur niveau de performance. En tant que Data Engineer GCP (F/H): Au sein de notre agence bas√©e √† Nantes, vous rejoindrez nos experts Cloud & DevOps. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus et dans leur strat√©gie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amen√©(e) √†‚ÄØ: D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence GCP. Vos comp√©tences techniques : Vous avez un minimum de 3 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts : Vous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud GCP et des solutions Data. DEVENIR #INNOVATIVEPEOPLE, C'EST‚ÄØ: Int√©grer une communaut√© de 1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine‚ÄØ; Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale‚ÄØ; Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud‚ÄØ: AWS, Microsoft Azure, Salesforce, GCP‚ÄØ; Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √†‚ÄØ: notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. PROCESSUS DE RECRUTEMENT: Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì Si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par C√©line notre Talent Specialist ; Etape 2 - Un premier entretien est programm√© avec C√©line en physique ou visio ; Etape 3 ‚Äì Un Codin‚ÄôGame vous sera envoy√© √† la fin de votre entretien‚ÄØ; Etape 4 ‚Äì Vous rencontrez nos managers et porteurs d‚Äôoffres Samuel et St√©phanie. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien ou test technique). LA VIE CHEZ MICROPOLE, C'EST: Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole‚ÄØ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles‚ÄØ; Une politique de formation attractive et √©clectique ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion‚ÄØ; La participation √† des projets internes sur la base du volontariat. √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, Data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un d√©veloppement rapide sur le Data, le Digital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur du Groupe. Pr√©sent au plus pr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs du d√©veloppement √©conomique, nous accompagnons nos clients des secteurs de l‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et du public dans leur transformation data et digitale, notamment au travers de m√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ. L‚Äôagence Grand Ouest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit et met en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôun num√©rique responsable au sein des organisations. Pour en savoir plus‚ÄØ: https://www.linkedin.com/company/micropole/ #LI-CB1","Micropole is seeking a data engineer with a minimum of three years' experience in data projects, including at least one project on GCP, or a GCP certification. The ideal candidate should be skilled in developing and maintaining client use cases with big data/cloud GCP infrastructure and be knowledgeable in modelling and analysing data in the cloud. Good problem-solving skills and the ability to identify the most relevant data sources are also required, as is an ability to provide concise and visual results. The role includes the responsibility for ensuring the security and compliance of data.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
287,56822,https://www.welcometothejungle.com/fr/companies/klanik/jobs/ingenieur-big-data-h-f_lyon,Ing√©nieur Big Data üíª,KLANIK,"{python,Jenkins,PostgreSQL,via,R,Teradata,Hadoop,Git,NoSQL,SQL,Python}",T√©l√©travail partiel possible,Lyon,"Logiciels, IT / Digital, Formation",CDI,2023-03-26,"KLANIK est une soci√©t√© de conseil en Ing√©nierie IT qui accompagne ses clients dans leurs projets digitaux et technologiques. Le groupe KLANIK compte d√©sormais plus de 750 talents, √©voluant dans 16 agences en Europe, Am√©rique du Nord, Afrique et Moyen-Orient. Des experts engag√©s, atypiques et passionn√©s, impliqu√©s dans des projets strat√©giques gr√¢ce √† leur haut niveau de comp√©tences en Software, DevOps, Cloud, Agilit√©, Cybers√©curit√©, Big Data & IA. En parall√®le de leurs m√©tiers, les collaborateurs du groupe KLANIK sont accompagn√©s au quotidien dans leur d√©veloppement personnel et professionnel, via diff√©rentes initiatives engageantes et innovantes : KONSCIOUS : communaut√© interne engag√©e dans les enjeux √©cologiques, sociaux et environnementaux KAMPUS : institut de formation technique certifi√© KORNER : incubateur de start-ups technologiques KLANIK ESPORT : club professionnel e-sport ouvert aux collaborateurs Klanik recrute pour l‚Äôun de ses grands partenaires du secteur de l‚ÄôEnergie, un Ing√©nieur Big Data (H/F) sur Lyon. Vos missions tournent autour de 4 axes : o Apporter une expertise en Big Data pour faciliter la manipulation des donn√©es o D√©finir les solutions techniques permettant le traitement massif de donn√©es o Mettre en place des solutions de stockage de donn√©es (SQL, NoSQL, etc.) o Veiller la s√©curisation et la clart√© des pipelines de donn√©es pour faciliter l‚Äôanalyse et la transformation Si n√©cessaire, vous pouvez vous appuyer sur les r√©f√©rents techniques des diverses briques si ces derni√®res sortent du cadre de votre mission. Activit√© principale : A ce titre, vous serez amen√©(e) √† assurer les activit√©s suivantes : ‚Ä¢ Participation √† des ateliers avec des experts m√©tiers pour collecter le besoin et comprendre les donn√©es ‚Ä¢ Conception et d√©veloppement de traitements de donn√©es, ‚Ä¢ R√©alisation d‚Äô√©tudes statistiques ‚Ä¢ Pr√©sentation de r√©sultats sous la forme de rapports d‚Äô√©tude ou de tableaux de bord ‚Ä¢ D√©veloppement d‚Äôoutils de visualisation de donn√©es pour faciliter les analyses ‚Ä¢ Documentation des traitements en vue d‚Äôune industrialisation ‚Ä¢ Participation aux c√©r√©monies agiles de l‚Äô√©quipe ‚Ä¢ Diffusion et vulgarisation des r√©sultats d‚Äô√©tude Activit√© secondaire : o Veille technologique sur les outils utilis√©s au sein du projet o Partage et formation sur les guides de bonnes conduites Stack technique du projet : L‚Äôenvironnement technique du projet est le suivant : ‚Ä¢ Python ‚Ä¢ R ‚Ä¢ PostgreSQL ‚Ä¢ Teradata ‚Ä¢ Hadoop ‚Ä¢ Jenkins ‚Ä¢ Ansible ‚Ä¢ Jira / Confluence / Bitbucket ‚Ä¢ Git Forte comp√©tence python avec connaissance de R. Bonne qualit√© en d√©veloppement logiciel. Comp√©tence de data science (stat / machine learning / programmation). 4 - 5 ans d‚Äôexp√©rience.","Klanik, an IT engineering consultancy, is seeking to hire a Big Data Engineer with expertise in Python, R, PostgreSQL, Teradata, Hadoop, Jenkins, Ansible, Jira/Confluence/Bitbucket, and Git, and a strong software development background. The ideal candidate should have 4-5 years of experience in data science, statistics, machine learning, and data programming. The job responsibilities include participating in workshops with subject matter experts to collect information, designing and developing data processing, conducting statistical studies, and creating data visualization tools.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
288,56852,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_5waAL8r,Data Engineer,EXTIA,"{GCP,git,Jenkins,Git}",T√©l√©travail partiel possible,Paris,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-03-26,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. DESCRIPTION DU POSTE ‚Ä¢ Analyse et Conception de l‚Äôarchitecture ‚Ä¢ Industrialisation et automatisation des d√©ploiements ‚Ä¢ Expertise sur le d√©ploiement de la solution ‚Ä¢ Exp√©rience du d√©veloppement logiciel agile avec multiples contributeurs ( git, code review, CI/CD ) ‚Ä¢ Exp√©rience du cloud, id√©alement GCP PROFIL RECHERCH√â ‚Ä¢ Niveau Bac+5, vous justifiez au minimum d‚Äôune premi√®re d‚Äôexp√©rience significative en tant que Data Engineer d'au moins 2 ans ‚Ä¢ Bonne connaissance des outils et pratiques DEVOPS : Industrialisation de l‚Äôint√©gration et du d√©ploiement de la solution : Git/Jenkins/Artifactory/Ansible ‚Ä¢ Application des m√©thodes Agile : Scrum et Kanban : JIRA/Confluence #LI-PRZ Curieux(se) , vous adorez partager les derni√®res id√©es innovantes que vous avez d√©couvertes, Analytique , vous avez une √¢me d‚Äôenqu√™teur et les √©nigmes n‚Äôont aucun secret pour vous , Proactif(ve) , vous aimez les projets qui avancent vite et bien.","Extia, a specialized consulting company in IT, digital, and engineering, is seeking a Data Engineer with at least 2 years of experience. The ideal candidate should have expertise in agile software development, cloud platforms (preferably GCP), and practice in DevOps tools such as Git, Jenkins, Artifactory, and Ansible. Candidates should have good knowledge of agile methodologies (Scrum and Kanban) and the ability to analyze and design architecture, automate deployments, and deploy solutions. A curious, analytical, and proactive approach is preferred.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
263,57001,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris,Data engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,Spark,GCP,Java,Hadoop,Python}",T√©l√©travail partiel possible,Paris,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-03-26,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶ Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes. Vous serez en charge de : ‚óè Participer √† la d√©finition des besoins et √† la r√©daction des User Stories, ‚óè Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e, ‚óè Concevoir et construire des architectures de donn√©es, ‚óè Int√©grer des sources de donn√©es, ‚óè Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives, ‚óè Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux #LI-GG1 ‚óè Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple, ‚óè Vous maitrisez les bases de l‚Äôanalyse statistique, ‚óè Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, ‚óè Vous maitrisez Spark et Hadoop ‚óè Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, ‚óè Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.","The role involves providing technical support to analysis teams by structuring data, conducting statistical and technical data analysis, developing analysis tools, and evaluating new technologies in Big Data, Data Mining, and Machine Learning. The ideal candidate should have expertise in ETL, data mining, machine learning, big data, graph theory, statistical analysis, and scripting languages like Python and/or R, as well as experience with Spark, Hadoop, Linux, cloud infrastructure, and real-time streaming tools.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
259,56910,https://www.welcometothejungle.com/fr/companies/neolynk/jobs/data-engineer-h-f_paris,Data Engineer 3 ans d'exp√©riences,NeoLynk,"{Python,SQL,Spark,AWS}",T√©l√©travail partiel possible,"91 rue du faubourg saint honore, Paris, 75008",IT / Digital,CDI,2023-03-26,"Une mani√®re innovante de r√©pondre aux challenges digitaux de nos clients, une mani√®re diff√©rente de valoriser nos consultants. Depuis plus de 6 ans, NeoLynk √©volue dans le domaine de l‚ÄôOpen Source, passionn√©ment ! Au travers de notre Tribu JVM et de nos projets innovants, nous conduisons nos consultants vers une maturit√© technologique toujours plus forte ! Passionn√©(e) par le Big Data ? Int√®gre notre Tribu et participe √† son √©volution, le tout en contribuant √† des projets clients challengeants au sein d‚Äô√©quipes exp√©riment√©es ! Quelques clients : Rakuten, Soci√©t√© G√©n√©rale, Saint Gobain, Kering ‚Ä¶ Vous √©voluez au quotidien au sein de la tribe transverse Data Tools and Services, constitu√©e de 7 p√¥les : Data Science, Data Engineering, BI/DATAVIZ, Data Analysis, Product Analysis, Data Quality, Data discovery. Vous aurez le soutien de l‚Äôentreprise qui a une ambition de r√©volutionner l‚Äôusage et le business model gr√¢ce aux nouvelles technologies. Vous travaillerez conjointement avec l‚Äô√©quipe Data Science et l‚Äô√©quipe data engineering. Vos missions: Vous travaillerez sous la responsabilit√© conjointe des deux managers Data Engineer & Data Science. Vous participerez √† la mise en place d‚Äôun important chantier data au sein du client ‚Äúla Data Plateform (DP)‚Äù qui permettra la centralisation, la creation et la mise √† disposition de segments d‚Äôutilisateurs. Cette DP permettra d‚Äôalimenter diff√©rents use cases produit du client (Pub, CRM,Premium, Service Client, ‚Ä¶). Vous serez en charge d‚Äôapporter votre expertise et votre support sur 3 principaux composants de cette DP : ÔÉò La librairie de cr√©ation de segment existante : qui permet l‚Äôint√©gration et la gestion des tables de r√©f√©rencement et d‚Äôarchivage de segments. Des modifications seront apport√©es √† cette librairie pour s‚Äôadapter √† la DP ÔÉò La table de r√©f√©rencement des segments : Changement de la table permettant de r√©pertorier les segments disponibles dans la DP. ÔÉò Les notebooks permettant de cr√©er les segments existants : o Refactoring de ces notebooks en tenant compte des nouveaux changements de la librairie et des nouvelles bases de donn√©es (Xiti) ‚Ä¢ Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 3 ans dans le domaine de la data ‚Ä¢ Une exp√©rience dans des environnements cloud avec des connaissances en Spark et AWS est tr√®s souhait√©e. ‚Ä¢ Une bonne maitrise du langage Python et du SQL. ‚Ä¢ Capacit√© de synth√®se, de vulgarisation de communication. ‚Ä¢ √ätre force de proposition. ‚Ä¢ Sens du partage et esprit d‚Äô√©quipe. ‚Ä¢ Prise d‚Äôinitiative. Entretien t√©l√©phonique Test technique Entretien physique","NeoLynk is seeking a passionate Big Data specialist with at least 3 years of experience in data management, cloud environments, Spark and AWS, Python, and SQL. The candidate will work on a data development project for a client's Data Platform, collaborating with Data Science, data engineering teams, and contributing to changing libraries, referencing tables, and creating existing segments. The ideal candidate is a team player, proactive, with excellent communication skills, and willing to learn and grow.",Bac +5 / Master,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
256,56414,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_lyon,Data engineer,EXTIA,"{SAS,Scala,HDFS,S3,AWS,R,Linux,GCP,Java,Python}",T√©l√©travail partiel possible,"129 rue Servient, Lyon, 69003","Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-03-26,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Ensuite quoi Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶ Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes. Vous serez en charge de : Participer √† la d√©finition des besoins et √† la r√©daction des User Stories, Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e, Concevoir et construire des architectures de donn√©es, Int√©grer des sources de donn√©es, Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives, Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux. Profil : Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple, Vous maitrisez les bases de l‚Äôanalyse statistique, Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts. #LI-YKH Curieux , vous adorez partager les derni√®res id√©es innovantes que vous avez d√©couvertes, Analytique , vous avez une √¢me d‚Äôenqu√™teur et les √©nigmes n‚Äôont aucun secret pour vous , Proactif , vous aimez les projets qui avancent vite et bien.","Extia, a consulting firm specialized in IT, digital, and engineering, is seeking a Technical Support Analyst with expertise in ETL, data mining, machine learning, big data, and graph theory, and familiarity with statistical analysis and Python or R scripting. Experience with Linux, large file storage tools, AWS or GCP cloud infrastructure, and real-time streaming is also valued. The ideal candidate will be curious, analytical, and proactive.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
298,56959,https://www.welcometothejungle.com/fr/companies/energisme/jobs/data-integration-engineer-etl-iot_boulogne-billancourt,Data Integration Engineer (ETL/IOT),Energisme,"{NIFI,via,SQL}",T√©l√©travail partiel possible,"88 Avenue du G√©n√©ral Leclerc, Boulogne-Billancourt, 92100","Logiciels, Big Data, Energie",CDI,2023-03-26,"Nous d√©veloppons une solution logicielle SaaS visant √† acc√©l√©rer la performance √©nerg√©tique des entreprises (prestataires de services √† l‚Äô√©nergie, fournisseurs et distributeurs d‚Äô√©nergie, industriels et gestionnaires de patrimoines immobiliers) gr√¢ce √† l‚Äôintelligence des donn√©es, ainsi qu‚Äôune plateforme PaaS d√©di√©e au traitement en temps r√©el des donn√©es massives et h√©t√©rog√®nes. Forts des atouts technologiques et op√©rationnels d√©cisifs de notre plateforme, nous comptons plus de 170 clients grands comptes. Au sein de l‚Äô√©quipe Data Acquisition, constitu√©e de 3 personnes, tu auras la charge de la conception et du d√©veloppement des connecteurs d‚Äôacquisition des donn√©es de nos clients. Orient√©(e) sur les donn√©es de consommation √©nerg√©tique avec des volum√©tries type Big Data, tu travailleras via une solution low code (Apache NIFI) sur des flux de donn√©es de type IOT, API, fichiers plats‚Ä¶ Tes missions Sp√©cification & conception des flux de donn√©es (30%) Comprendre les besoins d‚Äôint√©gration des flux Accompagner nos chefs de projet dans la sp√©cification des besoins de flux de donn√©es client Les orienter sur les informations √† r√©cup√©rer chez les clients Leur pr√©senter les choix possibles d‚Äôimpl√©mentation Les accompagner, si besoin, en r√©union client Prioriser avec eux les diff√©rents besoins D√©veloppement des flux (50%) Cr√©ation et param√©trage de flux sur la solution Apache NIFI D√©veloppement de script en Groovy ou JS Interrogation de bases de donn√©es (SQL) Appels d‚ÄôAPI REST/SOAP Manipulation de donn√©es (JSON, XML, CSV, ‚Ä¶) Code Review Communication sur l‚Äôavanc√©e des d√©veloppements Validation & d√©ploiement (20%) Test de chaque flux d√©velopp√© Documentation Mise √† disposition d‚Äôun environnement de test au Chef de projet pour validation Mise √† disposition de jeux de donn√©es Ex√©cution du flux D√©ploiement et maintenance des flux en production Tu poss√®des une exp√©rience dans le domaine des ETL et de l‚Äôacquisition de donn√©e. Tu es issu(e) d‚Äôune formation Bac + 4/5, Dipl√¥me d‚Äôing√©nieur ou √©quivalent en informatique. Tu es sensibilis√©(e) aux environnements Big Data & IOT et as un int√©r√™t pour le march√© de l‚Äô√©nergie. R√©mun√©ration selon profil. Tu h√©sites encore ? Travailler chez Energisme c‚Äôest √©galement : Rejoindre un collectif engag√©, avec un v√©ritable esprit d‚Äô√©quipe Une ambiance jeune et dynamique, des afterworks r√©guliers Une mutuelle avantageuse prise en charge √† 100% par l‚Äôemployeur 13 jours de RTT par an et un compte √©pargne-temps Une r√©elle flexibilit√© d‚Äôorganisation gr√¢ce au t√©l√©travail Si le poste t‚Äôint√©resse et que tu recherches une entreprise √† fort impact sur la transition √©nerg√©tique qui a √† c≈ìur d‚Äôaccompagner ses clients dans la r√©duction de leur impact environnemental, nous attendons ta candidature ! 1 entretien t√©l√©phonique (environ 45 min) 1 entretien avec √©tude de cas (environ 2h)","Energisme is seeking a Data Acquisition Developer with experience in ETL and data acquisition to design and develop data acquisition connectors for their clients, using low code solutions like Apache NIFI, SQL databases, and APIs. The ideal candidate should be familiar with Big Data and IOT environments and possess a Bachelor's or Master's degree in Computer Science or a related field. Energisme offers a dynamic team, flexible work schedule, generous benefits, and a genuine commitment to environmental impact reduction.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
299,56920,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-scientist-data-engineer-confirme-f-h_le-plessis-robinson,Data Scientist / Data Engineer confirm√© -,CS GROUP,"{git,python,tensorflow,mlflow,R,kafka,numpy}",T√©l√©travail partiel possible,"22 Avenue Galil√©e, Le Plessis-Robinson, 92350","Ing√©nieries Sp√©cialis√©es, A√©ronautique / Spatiale, Energie",CDI,2023-03-26,"La mission de CS GROUP : √™tre √† la pointe des technologies pour garantir la s√©curit√© de tous dans un monde en pleine mutation. L‚Äôexpertise reconnue de CS GROUP lui permet d‚Äôintervenir l√† o√π les enjeux de s√©curit√© sont les plus sensibles : d√©fense, spatial, a√©ronautique, √©nergie‚Ä¶ Et, aussi, l√† o√π les r√©ponses sont √† inventer ou √† r√©inventer: lutte anti-drone, cybers√©curit√©, traitement de donn√©es satellitaire‚Ä¶ Le positionnement de CS GROUP en fait un acteur unique sur son march√© : son expertise technique se combine avec une forte affinit√© avec les m√©tiers de ses clients. √Ä la cl√©, un capital confiance qui lui ouvre les portes d‚Äôun fort d√©veloppement partout dans le monde pour des interventions tout au long de la cha√Æne de valeur. Conseil, conception, d√©veloppement, int√©gration, maintenance et support aux op√©rations‚Ä¶ Rattach√© au manager ¬´ projets IA / R&D ¬ª au sein d‚Äôune √©quipe en croissance, le Data Scientist / Data Engineer participera au d√©veloppement d‚Äôun nouveau produit alliant IA et cybers√©curit√©, qui s‚Äôint√©grera dans un contexte de SIEM. Vous contribuez √† la r√©alisation de nos projets de Cybers√©curit√© et de R&D dans des contextes nationaux et internationaux. D√©tails des missions : En tant que Data Scientist : Analyser des donn√©es de syst√®mes de s√©curit√© cyber et physique pour construire des mod√®les D√©velopper des mod√®les IA en python En tant que Data Engineer : Participer √† l‚Äôarchitecture globale du syst√®me D√©veloppement des pipelines d‚Äôentr√©e et de sortie et du moteur d‚Äôex√©cution R√©diger de la documentation Participer aux √©v√©nements et projets IA Vous √™tes issu(e) d‚Äôune formation universitaire bac +5 ou d‚Äôune √©cole d‚Äôing√©nieur et vous souhaitez rejoindre une √©quipe exp√©riment√©e et dynamique au sein d‚Äôune entreprise en forte croissance. Vous avez une exp√©rience significative (5 ans) sur un poste de Data Scientist / Data Engineer, sur des syst√®mes de Machine Learning en production avec des √©volutions majeures et impliquant un suivi de la production. Comp√©tences techniques requises : Connaissances avanc√©es et op√©rationnelles des algorithmes et traitement de Machine Learning Bonnes connaissances en programmation python et librairies ML (numpy, scikit-learn, tensorflow‚Ä¶) Connaissances en architecture de Machine Learning et middleware support (kafka, mlflow‚Ä¶) Connaissances g√©n√©rales des outils de d√©veloppement (git ‚Ä¶) Savoir-√™tre et savoir-faire attendus : Capacit√© de conception de logiciel de Machine Learning Capacit√© √† d√©velopper et impl√©menter une vision de solution logicielle Rigueur Bonne expression orale et √©crite et id√©alement en anglais","CS GROUP is seeking a Data Scientist/Data Engineer with 5 years‚Äô experience in machine learning algorithms, python programming, and ML libraries to develop a new product in the field of AI and cybersecurity that will integrate with SIEM. The ideal candidate should possess advanced knowledge and operational skills in ML algorithms and treatment, programming python and ML libraries, and development tools (git, MLflow) along with the ability to design/implement a solution software and exhibit strong communication skills.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
303,57060,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech_london,DataOps Engineer - Big Data & Analytics Fintech LONDRES,Opensee,"{python,bash,lambda,Docker,go,pandas,Bash,linux,docker,azure,Kubernetes,AWS,scale,golang,kubernetes,SQL,numpy,aws,Unix,Python}",T√©l√©travail partiel possible,"London, EC2V 7NA","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-03-26,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee‚Äôs commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What‚Äôs in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client‚Äôs internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Duration : permanent contract Salary : Competitive, profile based Location : London (the City) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!","Opensee is seeking an Ops/DevOps professional with a problem-solving mindset, creativity, and autonomy to install the company's solutions in clients' infrastructure, help them integrate the product in their ecosystem, and ingest and analyze data. The ideal candidate should have experience with Unix systems, Bash, networks, Terraform, Golang, Docker, Kubernetes, big data, distributed databases, SQL, and Python. Good written and verbal communication skills in English are required, while proficiency in French is a plus. The position offers a permanent contract, a competitive salary, and opportunities to develop skills and grow within the company.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
253,59932,https://www.welcometothejungle.com/fr/companies/securitesociale/jobs/data-engineer-f-h_rennes,Data Engineer,La S√©curit√© Sociale,"{durable,Databricks,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,"Rue de Ch√¢teaugiron, Rennes, 35000",Administration publique,CDI,2023-03-28,"Vous souhaitez vous engager dans une entreprise aux valeurs humaines, sociales et solidaires ? Vous souhaitez prendre part √† la construction d'un SI de premier plan en France ? Pour vous, le travail d'√©quipe et le partage de comp√©tences sont sources d'√©mulation ? Les nouvelles technologies vous inspirent ? Vous avez r√©pondu ¬´ Oui ¬ª √† chacune de ces questions, ne cherchez plus votre futur job ! Vous l'avez trouv√© ! Devenez Data engineer F/H en CDI au sein de notre DSI. Qui sommes-nous ? L'entreprise : La CNAF (Caisse Nationale des Allocations Familiales), t√™te de r√©seau des 101 CAF, repr√©sente la branche famille de la S√©curit√© Sociale et a pour mission de piloter la politique familiale et l'aide aux populations en situation de pr√©carit√© ainsi que la politique d'action sociale. Votre futur service : Au sein de la DSI, comptant environ 800 collaborateurs, la direction ¬´ Prestations Individuelles et R√©f√©rentiels M√©tiers ¬ª a pour mission principale de concevoir, d√©velopper et maintenir le syst√®me d'information li√© aux prestations individuelles (prestations vers√©es aux allocataires telles que l'allocation familiale, l'allocation logement, la prime √† la naissance, le RSA, la prime d'activit√©, ‚Ä¶). Le d√©partement D√©cisionnel et Big Data collecte, consolide, mod√©lise, et met √† disposition les donn√©es de la branche aux directions m√©tiers de la CNAF ainsi qu'√† l'ensemble des CAFs. Il comporte 3 services r√©partis sur Rennes et Lyon/Macon. Vous rejoindrez le service ""Architecture et d√©veloppement Restitutions"" bas√© √† Rennes. Actuellement en pleine refonte de notre syst√®me D√©cisionnel, nous migrons vers une solution D√©cisionnel et Big Data (Lakehouse) innovante. Cette nouvelle plateforme va nous permettre √† la fois de g√©rer les besoins purement BI et √©galement Big Data (Machine Learning, IA..). Parmi les futurs th√®mes de d√©veloppement identifi√©s, citons la connaissance Client (CRM) adapt√©e √† notre population d'allocataire, la lutte contre la fraude, la fiabilisation de certains stocks de donn√©es‚Ä¶ Mission/Activit√©s Concr√®tement votre futur quotidien ? Int√©gr√©(e) au service ¬´ Architecture et D√©veloppement Restitutions ¬ª, vous √™tes en charge de : Participer au projet de migration de notre syst√®me D√©cisionnel vers un √©cosyst√®me Big Data ; Construire des solutions dans un environnement Big Data sur des technologies telles que Spark, Python, Databricks, Azure, Power BI ; Participer √† la r√©alisation de cas d'usage Big Data d√©finis en collaboration avec les Data Scientists. Des d√©placements occasionnels sont √† pr√©voir sur Paris et √† Lyon. Conditions particuli√®res Votre futur environnement de travail ? Vous √©voluerez au sein d'un environnement de travail collaboratif, engageant et en mouvement ! Int√©grer la CNAF, c'est aussi pouvoir b√©n√©ficier de nombreux avantages : T√©l√©travail possible, Flexibilit√© des horaires , Cong√©s / RTT : le b√©n√©fice de + ou - 9 semaines par ann√©e pleine, Transport : remboursement √† 50% de votre abonnement, b√©n√©fice d'un forfait mobilit√© durable d'un maximum de 500‚Ç¨/an si vous utilisez des modes de transport alternatifs √† la voiture individuelle, Tickets restaurant (prise en charge √† hauteur de 60%), R√©mun√©ration fixe : n√©gociable selon profil et r√©mun√©ration actuelle / √† partir de 37,5 K‚Ç¨ (sur 14 mois) + prime de r√©sultats + prime d'int√©ressement CSE avec des ≈ìuvres sociales avantageuses (sport, loisirs, voyages, ‚Ä¶). Alors n'h√©sitez plus, rejoignez-nous ! Dans le cadre de sa politique de diversit√©, la CNAF ouvre ses offres d'emploi √† toutes les candidatures. Etes-vous notre prochain(e) Data engineer ? Vous avez une formation sup√©rieure de type Bac +3 √† Bac+5, id√©alement en informatique d√©cisionnelle ou Big Data, compl√©t√©e par une exp√©rience de 2 ou 3 ans dans le Big Data souhait√©e. Une exp√©rience dans les environnements Big Data ou/et Cloud sera tr√®s appr√©ci√©e. Vos comp√©tences : Excellente aptitude au d√©veloppement informatique Capacit√© √† appr√©hender des environnements complexes techniquement Capacit√© √† concevoir des solutions dans un souci d'industrialisation en Production Capacit√© √† promouvoir les solutions d√©velopp√©es et √† les pr√©senter devant divers publics Capacit√© √† travailler en √©quipe avec des interlocuteurs vari√©s Excellent relationnel Vos comp√©tences techniques : Indispensables : Spark, PySpark, SQL Souhait√©es : Power BI, Databricks, Cloud Azure","The Caisse Nationale des Allocations Familiales (CNAF) is seeking a data engineer to join their Decisional and Big Data department in Rennes, France. The ideal candidate should have a degree in decisional IT or big data, along with two to three years of experience in the field. The role requires extensive expertise in Spark, PySpark, and SQL, with desirable skills in Power BI, Databricks, and Cloud Azure. Benefits include flexible working hours, telecommuting options, and an attractive salary package.",Bac +3,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
273,60622,https://www.welcometothejungle.com/fr/companies/edf/jobs/ingenieure-ingenieur-data-h-f_lyon,Ing√©nieure / Ing√©nieur Data,EDF,"{Oracle,Jenkins,Git,PostgreSQL,Kubernetes,AWS,Docker,elastic,GCP,Java,SQL,Python}",T√©l√©travail partiel possible,"Lyon, 92400","Environnement / D√©veloppement durable, Energie",CDI,2023-03-28,"Au croisement d'enjeux essentiels et captivants, rejoignez un groupe √† la dimension internationale, champion de la croissance bas carbone et activement engag√© dans la lutte contre le r√©chauffement climatique‚ÄØ!‚ÄØRejoindre EDF, c'est √©galement travailler dans un Groupe porteur de valeurs fortes,‚ÄØqui innove avec de solides actifs industriels et vous confie des missions qui ont du sens. Au sein du Groupe EDF, si vous souhaitez travailler dans le domaine du SI & des T√©l√©communications en lien avec les centrales de productions d'√©lectricit√©, alors rejoignez l'UNITEP, l'op√©rateur num√©rique industriel d'EDF !) Avec pr√®s de 800 collaborateurs, l'UNITEP contribue √† la num√©risation, √† la performance des centrales de production d'√©lectricit√© nucl√©aires, thermiques et hydrauliques. En tant qu'Ing√©nieur Data, vous rejoindrez la Manufacture Digitale de l'UNITEP. Au sein d'une √©quipe agile, organis√©e sur les bases de Scrum, d'une quinzaine de personnes, vous contribuerez √† l'utilisation de donn√©es m√©tier pour le d√©veloppement de solutions digitales ainsi qu'au choix et √† la mise en oeuvre des diff√©rents composants SI (progiciel, bases de donn√©es, d√©veloppements sp√©cifiques‚Ä¶). Vos missions seront riches et vari√©es : Apporter votre expertise sur le patrimoine de donn√©es disponible dans le Datalake EDF et les solutions SI Apporter vos connaissances de tous les moyens d'obtenir, stocker et g√©rer de la donn√©e (pipelines, bases de donn√©es, cloud) Participer √† l'√©laboration des mod√®les de donn√©es des applications d√©velopp√©es Etre tr√®s connect√© avec les personnes en lien avec le Datalake EDF Etre force de proposition dans l'approche et les √©changes avec le m√©tier Vous contribuerez √† l'assurance du respect des exigences techniques de r√©alisation tout au long du cycle de vie d'un projet : cyber-s√©curit√©, architecture retenue pour le projet, coh√©rence des flux inter-applications, int√©grit√© des donn√©es... Type de sujets trait√©s : D√©veloppement d'applications √† destination des m√©tiersMod√©lisation des bases de donn√©es, injection de donn√©es existantes, traitements en batch Gestion des donn√©es de l'√©quipeBackup de donn√©es, gestion d'instances et config des bases de donn√©es Bas√©s sur les solutions cloud (AWS, GCP)Migration sur une infrastructure cloud, mise en place de pipeline, PoC Participer √† la strat√©gie Data de l'unit√©Elaboration de solutions de mise √† disposition et d'acc√®s √† la donn√©e Faire vivre la communaut√© Data et acculturer les profils non techniques Donn√©es : PostgreSQL, API-Rest (webservice), elastic search, Oracle Langages : Python, SQL, Java Autres : Docker, Jenkins, Openshift, Kubernetes, Git, AWS, GCP Alors pr√™te/pr√™t pour l'aventure ? Titulaire d'un dipl√¥me Bac+5 (formation universitaire ou √©cole d'ing√©nieur) avec sp√©cialisation en informatique / syst√®me d'informations, num√©rique et DATA, vous disposez d'une exp√©rience minimale de 2 ans en tant qu'Ing√©nieure / Ing√©nieur Data. Vous disposez de solides comp√©tences techniques sur les bases de donn√©es et leurs utilisations Votre esprit d'analyse et votre sens critique vous permettront d'appr√©hender la complexit√© des syst√®mes SI et d'optimiser les solutions propos√©s Votre curiosit√© et sens du client vous permettront de comprendre les enjeux et besoins de partenaires m√©tiers et de les challenger Vous avez le sens du collectif et saurez travailler en coop√©ration tant en interne UNITEP avec vos coll√®gues EDF (et prestataires) qu'en externe UNITEP avec nos partenaires m√©tiers Si ces talents sont les v√¥tres, alors rejoignez-nous ! R√©mun√©ration : R√©mun√©ration attractive selon profil et exp√©rience qui s'inscrit dans un package global de r√©mun√©ration int√©grant notamment : 13√®me mois Int√©ressement Prime individuelle Tarifs pr√©f√©rentiels pour l'√©lectricit√© et le gaz Une politique familiale d√©velopp√©e (prime mariage, naissance, sursalaire, aide aux √©tudes des enfants, jours de cong√©s pour √©v√©nements familiaux, ‚Ä¶). Avantages √† nous rejoindre : Un job vari√© et int√©ressant, riche en interactions Un domaine d'activit√© en plein essor Une √©quipe √† taille humaine Un package de r√©mun√©ration attractif Des possibilit√©s de professionnalisation et d'√©volution en interne UNITEP ou au sein du Groupe EDF Politique d'accueil et d'int√©gration des nouveaux arrivants. Vous voulez en savoir plus ? D√©couvrez l'UNITEP : https://www.linkedin.com/posts/cedric-chabert-623908a0_unitep-maeztiers-it-activity-6909408356776513536-Q1Bb?utm_source=linkedin_share&utm_medium=member_desktop_web Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","The UNITEP, EDF's industrial digital operator, is seeking a data engineer with at least two years of experience in data engineering and a degree in computer science or digital technology to join their agile team of 15 people. The successful candidate will have strong technical skills with databases and their uses, the ability to understand complex IT systems and propose solutions, and a strong focus on collaboration with internal and external stakeholders. EDF offers an attractive compensation package and opportunities for professional development and internal growth. The position is open to all candidates, including those with disabilities.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
0,56433,https://www.welcometothejungle.com/fr/companies/matera/jobs/data-engineer_paris,Data Engineer,Matera,"{python,Kubernetes,Airflow,CSM,DBT,Meltano,Fivetran,Looker,Stitch,BigQuery,Docker,SQL}",T√©l√©travail partiel possible,"10, Rue Treilhard, Paris, 75008","SaaS / Cloud Services, Immobilier particulier",CDI,2023-03-26,"Cr√©√©e en 2017, Matera est une start-up √† forte croissance qui r√©volutionne le secteur bien poussi√©reux des syndics de copropri√©t√©. Matera permet aux copropri√©taires de se passer d‚Äôun syndic professionnel pour la gestion de leur immeuble en remettant au go√ªt du jour un mod√®le laiss√© aux oubliettes : le syndic coop√©ratif. Gr√¢ce √† Matera, les copropri√©taires g√®rent eux-m√™me leur immeuble rapidement et sereinement. Concr√®tement, la start-up met √† disposition des syndics coop√©ratifs un logiciel SaaS intuitif et cl√© en main qui automatise les t√¢ches de la gestion de copropri√©t√© ainsi que des experts en interne qui prennent le relai sur des sujets complexes : juristes, comptables, experts en b√¢timent‚Ä¶ Matera a d√©j√† s√©duit plus 6 500 copropri√©t√©s partout en France et en Allemagne ! En tant que Data Engineer de l‚Äô√©quipe, tu √©pauleras Hugo, notre Head of Data et les 4 Data Analysts pour construire la plateforme centrale de donn√©es. Au programme : Gestion de la data plateforme (d√©veloppement, maintenance et s√©curit√©) D√©veloppement de pipelines d‚ÄôETL et de reverse ETL Analyse des besoins d‚Äôacc√®s aux donn√©es en collaboration avec les Data Analysts des √©quipes Sales, CSM, Acquisition, Finance. Mise en place de contr√¥les automatiques de la qualit√© des donn√©es Tests et int√©grations de nouveaux outils d‚Äôacc√®s et de transformation des donn√©es Notre stack : Data warehouse : BigQuery Orchestrateur : Airflow et Kubernetes Infrastructure: Terraform Transformation de donn√©es : SQL / DBT Outils d‚Äôextraction et de chargement de donn√©es : python / Meltano Singer-SDK, Stitch, Fivetran BI : Looker Id√©alement, Tu as obtenu un dipl√¥me d‚Äôing√©nieur Tu as au moins 2 ans d‚Äôexp√©rience en data engineering Tu ma√Ætrise parfaitement python et SQL Nice to have : Exp√©rience sur Airflow, DBT et BigQuery Exp√©rience sur Docker et Kubernetes Exp√©rience sur Looker On √©tudie ta candidature Entretien t√©l√©phonique avec Maurine, Talent Acquisition (30 min) Rencontre avec Hugo et mise en situation (1h) Final Round avec Laurent (CFO) Rencontre avec les √©quipes, puis offre üéâ Pourquoi nous rejoindre Un onboarding aux petits oignons pour te permettre de d√©couvrir le monde de la copropri√©t√©, notre organisation et te donner toutes les cl√©s pour r√©ussir ton int√©gration; Un environnement stimulant, o√π tout est √† construire! Un produit r√©pondant aux probl√®mes des copropri√©taires qui est minutieusement con√ßu et bichonn√© par nos √©quipes; Travailler sur d‚Äôautres projets en parall√®le pour faire briller Matera et developper tes skills; Apprendre & √©voluer: culture du feedback et un suivi pendant tout le long de ton stage; Des fondateurs qui ont √† coeur le bien-√™tre et le rayonnement de toute la team; Si tu as une passion pour les jeux de soci√©t√© en tout genre (et les ap√©ros qui vont avec), tu seras combl√©¬∑e tous les vendredis! D√©tails Locaux: 10 rue treilhard 75008 Paris Remote: Hybrid Type de contrat: CDI D√©but: ASAP Sache que chez Matera, nous garantissons l‚Äô√©galit√© des chances et la diversit√©, c‚Äôest pourquoi tous nos postes sont ouverts aux personnes en situation de handicap, seules les comp√©tences et la motivation font la diff√©rence !","Matera, a rapidly growing start-up revolutionizing traditional property management, seeks a Data Engineer to join their team. The successful candidate will be responsible for developing, maintaining and securing the central data platform, streamlining ETL and reverse ETL pipelines, analyzing data access needs and implementing automated data quality checks. Ideal qualifications include a degree in engineering, at least two years of data engineering experience, proficiency in Python and SQL, and experience with Airflow, DBT, and BigQuery. The position is a CDI with the option for hybrid remote work.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
316,56829,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-databricks-h-f_levallois-perret,Data Engineer / Databricks,Micropole,"{Microsoft,durable,Azure,AZURE,Databricks,Scala,AWS,R,Spark,GCP,SQL}",T√©l√©travail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√© : Poste : Data Engineer Databricks Localit√© : Levallois-Perret Type de contrat : CDI Niveau d‚Äôexp√©rience : au moins 2 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services. Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! Au sein de notre agence bas√©e √† levallois-Perret, vous rejoindreznos experts Cloud. En tant que Data Engineer Databricks (F/H) , vousaccompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leurprocessus et dans leur strat√©gie pour optimiser leur performance. Dans vos missions quotidiennes , vous serez amen√©(e) √†‚ÄØ: D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data / Databricks. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence. Vos comp√©tences techniques : Vous avez un minimum de 2 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Databricks (sur GCP et/ou Azure), ou √† d√©faut une certification Databricks avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala ou SQL)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ; Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visio Etape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) LA VIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ; Participation √† des projets internes sur la base du volontariat. #LI-DM1 Comp√©tences Databricks Spark Scala SQL AZURE GCP","Micropole is seeking a Data Engineer Databricks to join their team in Levallois-Perret. The successful candidate will have at least two years of data project experience (including Databricks projects or certification) and will work closely with business leaders to evaluate efficiency of processes while optimizing performance. Key responsibilities include developing and maintaining customer use cases with Big Data/Databricks tools and frameworks, modeling and analyzing data in the cloud, ensuring data security and compliance, and identifying relevant data sources. The ideal candidate will be passionate, detail-oriented, curious, and have a strong command of at least one programming language (Spark, Scala, or SQL).",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
396,39822,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineer-confirme-e-python-scala-aws-stack-f-m-d_nantes,Data Engineer Confirm√©.e - Python / Scala & AWS Stack,Decathlon Technology,"{Databricks,Talend,Scala,Redshift,Airflow,Logstash,Lambda,S3,Kibana,Druid,AWS,GitHub,Spark,BigQuery,GCP,Java,Python,Elastic}",T√©l√©travail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2022-11-29,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOIGNEZ LES EQUIPES DATA DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour accompagner cette transformation digitale internationale de Decathlon, les √©quipes Data √©voluent et mettent au coeur de leurs enjeux : La qualit√© et l‚Äôaccessibilit√© de la donn√©e La scalabilit√© des processus associ√©s au cycle de vie de la donn√©e (ingest, store, transform, expose) L‚Äô√©lasticit√© des infrastructures et des services Si tu as envie de contribuer √† cette transformation et de co-construire la plateforme data de demain, alors tu seres int√©gr√©¬∑e dans une √©quipe data domain centric : Stock / supply chain Products Forecast Pricing Users Finance Performance Economique Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e Data Engineer, bas√©-e, au choix √† Paris, Lille, Lyon ou Nantes. TES RESPONSABILITES Tu seras en charge de: Construire des pipelines scalables de donn√©es structur√©es et non structur√©es ; D√©finir la strat√©gie de nos stacks techniques et garantir la CI/CD ; Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases ; Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ; Contribuer activement √† notre communaut√© de data engineers ; Le p√©rim√®tre technique : Big Data : Amazon Web Services, Lambda, Redshift, S3 Code Programming : Python, Scala, Java Data Science / ML : Spark, Databricks Data Pipeline : Airflow Real Time Database : Druid Big data analytics : Stack ELK (Elastic Search, Logstash, Kibana) Environnement Google GCP : BigQuery, Composer, Data Studio Data integration : Talend CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as au moins 2 ans d‚Äôexp√©rience comme Data Engineer, sur l'environnement Big Data d‚ÄôAWS, sachant utiliser ses composants (Lambda, Redshift, S3) ainsi qu‚Äôoptimiser leurs performances ; Tu ma√Ætrises l‚Äôun des langages suivants : Python, Scala, Java ; Tu maitrises la mise en oeuvre de pipeline de processing de donn√©es ; Tes pairs te reconnaissent pour ta grande app√©tence technique ; Tu comprends le cycle de vie de la donn√©e et tu es √† l‚Äôaise avec les concepts de data lineage, data gouvernance et data privacy ; Tu as un bon niveau d‚Äôanglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu aimes travailler en agilit√© dans un environnement collaboratif ( GitHub , Mob programming). Tu as un sens du service d√©velopp√©. Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et la vie d'√©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) Cerise sur le g√¢teau : Tu d√©j√† travaill√© avec les technologies comme Spark, Databricks, Airflow, Druid, Stack ELK (Elastic Search, Logstash, Kibana), Environnement Google GCP ( BigQuery, Composer, Data Studio), Talend. CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a Data Engineer to join their Data team in Paris, Lille, Lyon or Nantes. The role involves working on building scalable data pipelines and defining the technical stacks strategy, as well as working with AWS Big Data components, Python, Scala and Java programming languages, data pipeline implementation, and data lineage, governance, and privacy concepts. The ideal candidate should have at least 2 years of experience as a Data Engineer and be comfortable working in an agile and collaborative environment. Decathlon offers a range of benefits including teleworking, international projects, and training and certification opportunities.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
432,49754,https://www.welcometothejungle.com/fr/companies/ioda/jobs/consultant-data-engineer-h-f-paris-bordeaux-barcelone-ile-de-la-reunion-barcelone,Consultant(e) Data Engineer - Paris - Bordeaux - Barcelone - Ile de la R√©union - Barcelone.,IODA Group,"{Azure,Javascript,PHP,AWS,Spark,GCP,Java,SQL,Python}",T√©l√©travail partiel possible,Paris,"Digital Marketing / Data Marketing, IT / Digital, Strat√©gie",CDI,2023-02-07,"Acteur √† taille humaine et orient√© business, IODA, cabinet de conseil mixe, la Technologie, la Data & IA, le CRM & Digital. IODA accompagne ses Clients avec Intelligence et pragmatisme dans l‚ÄôOptimisation de la transformation Digitale et son Acc√©l√©ration. Fort de plus de 10 ans d‚Äôexp√©rience et de passion, IODA r√©serve un service personnalis√© et adapt√© √† chaque client et partage son savoir-faire et son professionnalisme autour d‚Äô√©changes sinc√®res et humains. Travailler ensemble rel√®ve davantage du partenariat que de la simple collaboration. Nous avons 4 bureaux, Paris, Bordeaux, Ile de la R√©union, Barcelone En pleine acc√©l√©ration de son d√©veloppement en France et √† l‚Äôinternational, IODA Group , cabinet de conseil √† taille humaine et orient√© business, mixant la Data, le CRM, le Digital & la Technologie, recherche des collaborateurs de talents. Dans ce cadre, IODA Group recrute un(e) Consultant(e) Data Engineer H/F- Paris - Barcelone - Ile de la R√©union - Barcelone. Poste et missions Participer √† la conception de solutions : choix d‚Äôoutils, proposition de solutions alternatives Assister le client au cadrage du projet, et participer au design fonctionnel et technique Structurer et planifier la r√©alisation des d√©veloppements Collaborer √† l‚Äôint√©gration des produits dans le SI avec l‚Äôarchitecte technique. Participation √† la r√©alisation de d√©veloppements complexes Assurer le suivi et la qualit√© des d√©veloppements ainsi que la r√©alisation du projet Ma√Ætriser les techniques et les m√©thodes Agiles Planifier et garantir les mises en production : industrialisation, package‚Ä¶. Assurer le r√¥le de r√©f√©rent et coacher les consultants juniors, faire progresser les √©quipes Faire de la veiller technologique o Comp√©tences techniques Le poste √† pourvoir n√©cessite une forte polyvalence, une capacit√© d‚Äôadaptation afin de pouvoir r√©pondre √† l‚Äôenvironnement technique des diff√©rents Clients : Prise en main de nouveaux progiciels, r√©alisation de param√©trages avanc√©s, d√©veloppement de briques applicatives fortement int√©gr√©es dans un environnement existant. Capacit√© √† s‚Äôapproprier les concepts de progiciels du march√© sur l‚Äôensemble des briques applicatives (CRM, BI, E-commerce ‚Ä¶) et big data avec une exp√©rience sur un ou plusieurs environnements cloud (GCP, Azure, AWS‚Ä¶) Le candidat devra pouvoir justifier de solides connaissances sur : Python et Spark Les bases de donn√©es (langage SQL), tant en conception (MCD, MPD) qu‚Äôen utilisation (SQL, proc√©dures stock√©es) et la connaissance d‚Äôun ETL La connaissance des langages courants, plut√¥t orient√©s Web : HTML 5, CSS, Java / Javascript, C#, PHP, Ajax‚Ä¶est un plus o Profil De formation sup√©rieure en informatique BAC+4/5, vous disposez de solides exp√©riences dans le d√©veloppement de solutions dans le domaine du CRM et le Digital. Vous √™tes attir√©s par l‚Äôactivit√©ÃÅ de Conseil et vous poss√©dez de solides comp√©tences techniques avec une facult√© √† proposer des solutions op√©rationnelles √† forte valeur ajout√©e ? Si vous souhaitez : Int√©grer une √©quipe dynamique et motiv√©e ou vos talents, id√©es et proactivit√© seront reconnus et encourag√©s, D√©couvrir une diversit√© de projets et plusieurs secteurs d‚Äôactivit√©/m√©tiers en France ou √† l‚Äôinternational Avoir de r√©elles perspectives d‚Äô√©volution Vous aurez la possibilit√© de pourvoir travailler √† Paris, Bordeaux, Barcelone ou l‚ÄôIle de la R√©union CDI - R√©mun√©ration Fixe attractive + Variable selon le profil. Alors REJOIGNEZ NOUS! 1er entretien avec l‚Äô√©quipe RH 2√®me entretien avec les Consultants 3√®me entretien avec la Directrice G√©n√©rale","Consulting firm IODA Group is seeking a Data Engineer with strong skills in Python and Spark, as well as knowledge of SQL, ETL and web languages, to work on the company's data, CRM, digital and technology projects in Paris, Bordeaux, Ile de la R√©union or Barcelona. The role involves developing and integrating products into existing systems, coaching junior consultants, ensuring project quality and following Agile methodologies. The position requires adaptability and versatility in mastering new systems, while offering real opportunities for skill development and career progression.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
426,40475,https://www.welcometothejungle.com/fr/companies/cgi/jobs/consultant-data-ingenieur-big-data-h-f_bordeaux,Data Engineer,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",T√©l√©travail partiel possible,"Bordeaux, 33000","IT / Digital, Transformation, Big Data",CDI,2023-01-29,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. - Conseil, Audit et Maitrise d‚Äô≈ìuvre. - Etudes d‚Äôopportunit√©, cadrage de projet d‚Äôint√©gration de donn√©es et aide au choix de solution. - Accompagnement √† la mise en place de DataLake/Big Data. - Conception et d√©veloppement de flux d‚Äôint√©gration des donn√©es (ETL,ELT, streaming ,API ‚Ä¶ ). - Conception et mise en ≈ìuvre de plateformes On Premise ou Cloud de stockage des donn√©es dans un Data Lake (Big Data). - Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.). - Migration des donn√©es. - Move to Cloud. - Comp√©tences av√©r√©es en Gouvernance des donn√©es, qualit√© des donn√©es et catalogue des donn√©es. - Minimum 2-5 ans d‚Äôexp√©rience dans le domaine. - Animation d‚Äôateliers M√©tier/ IT de d√©finition des processus d‚Äôint√©gration des donn√©es. - Animation d‚Äôatelier de d√©finition de plateforme d‚Äôint√©gration et de stockage des donn√©es. - Proposition de type d‚Äôarchitecture de gouvernance (Centrale, d√©centralis√©e, etc.). - Capacit√© √† int√©grer une √©quipe d‚Äôint√©gration des donn√©es. - Capacit√© √† proposer des solutions & architectures de donn√©es. - Capacit√© √† configurer des outils d‚Äôint√©gration et de Reporting des donn√©es. - Formation et pratique d‚Äôoutils de Data Int√©gration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. ). CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, seeks experienced professionals for its Data Integration team. The role requires proven competency in data governance, quality, and cataloging. Key responsibilities include designing and developing data integration workflows, conceiving and implementing Cloud storage platforms, and coordinating with business and IT teams on data integration processes. The company provides a supportive work environment and is committed to diversity and inclusion.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
425,43941,https://www.welcometothejungle.com/fr/companies/ba-sh-1/jobs/data-engineer-f-h_paris_BASH_1ZqxpLP,data engineer f/h,ba&sh,"{durable,Azure,RedShift,Talend,DBT,AWS,Snowflake,Synapse,GCP,Java,Python}",T√©l√©travail partiel possible,"67 Av. Raymond Poincar√©, Paris, 75116",Mode,CDI,2023-02-01,"En 2003, Barbara Boccara & Sharon Krief, entrepreneuses et cr√©atives, se lancent pour cr√©er ba&sh et son vestiaire id√©al o√π toutes les femmes pourraient s‚Äôexprimer, avec modernit√©, simplicit√© et chic. Elles offrent la possibilit√© d‚Äô√™tre libres, belles et bien. Puis, en 2015, L Catterton, le fonds d‚Äôinvestissement de LVMH, accompagne ba&sh dans son expansion internationale et son d√©veloppement en hyper-croissance, dans un environnement transform√© par la r√©volution digitale. ba&sh est une maison innovante, dynamique et tourn√©e vers les probl√©matiques de demain. Elle lance officiellement en 2021, son programme de d√©veloppement durable BLOSSOM et √©tablit un plan d‚Äôaction concret tourn√© vers une profonde transformation ambitieuse. Bien plus qu‚Äôune marque, ba&sh souhaite couvrir les th√©matiques sociales, environnementales et soci√©tales par le choix de mati√®res √©co responsables, transparence & tra√ßabilit√© dans la chaine de valeur, accompagnement des fournisseurs, suivi et r√©duction des √©missions de gaz √† effet de serre, √©conomie circulaire et innovations durables. Au sein de l‚Äô√©quipe de la DSI, vous serez int√©gr√© dans le cadre de la cr√©ation d‚Äôune √©quipe Data ayant pour but de centraliser l‚Äôensemble des silos de donn√©es de l‚Äôentreprise et proposer √† ses m√©tiers des vues d‚Äôensemble. La plateforme technique et les premiers USE CASE sont en cours de r√©alisation. Vous serez en charge de l‚Äôensemble des d√©veloppements d‚Äôextraction, mod√©lisation, transformations et optimisation des donn√©es en collaboration avec le Responsable de projets IT. Vous serez assist√© d‚Äôun consultant Data visualisation afin de proposer aux diff√©rents acteurs de ba&sh les analyses et les rendus les plus performant possible. La plateforme Snowflake sera votre outil principal coupl√© √† Talend pour r√©aliser l‚Äôensemble des extractions et modifications. A ce titre, vos missions sont les suivantes : Impl√©menter et am√©liorer les diff√©rentes briques de notre socle technique Data dans un environnement Snowflake / Tableaux Travailler √† la robustesse de flux de donn√©es, de la collecte √† la transformation Talend Cr√©er, mod√©liser, enrichir et faire √©voluer nos Datamarts Transformer les donn√©es brutes en informations organis√©es et utilisables par les Data Analystes Optimiser et √™tre force de propositions sur nos solutions existantes de traitement des donn√©es Identifier les manques et d√©pendances √† faire √©voluer c√¥t√© Data (donn√©es sources, process, mod√©lisation) Int√©grer de nouvelle source de donn√©e au sein de l‚Äô√©cosyst√®me Data Cette liste n‚Äôest pas exhaustive et sera susceptible d‚Äô√©voluer avec le d√©veloppement de ba&sh. Vous vous reconnaissez dans ce parcours : Formation sup√©rieure en √©cole d‚Äôing√©nieur ou √©cole sp√©cialis√©e en informatique Int√©r√™t prononc√© pour le domaine de la Data Au moins 4 ann√©es d‚Äôexp√©rience dans un environnement Data √©volu√©e Une premi√®re exp√©rience dans le monde du Retail est appr√©ci√©s mais non obligatoire Vous vous d√©marquez pour votre : Autonomie, proactivit√©, rigueur et organisation Force de proposition technique et structurelle Capacit√© de restitution technique Bon relationnel et go√ªt pour le travail en √©quipe App√©tence pour faire de la veille technique et suivre les sujets li√©s √† la data Vous maitrisez : L‚Äôunivers Data Cloud (AWS,GCP,Azure) La connaissance d‚Äôune plateforme de gestion datawarehouse (Synapse, Snowflake, RedShift), Snowflake serait un plus Un langage de programmation type Python, Java Les mod√®les de donn√©es relationnelles Une exp√©rience approfondie en ETL et ELT (Talend, DBT) est requise ba&sh n‚Äôattend plus que vous ! Chez ba&sh, nous croyons que la diversit√© est une force, et nous nous engageons √† la cultiver. La diversit√© sous toutes ses formes (genre, √¢ge, nationalit√©, culture, croyances religieuses, orientation sexuelle, ‚Ä¶) enrichit les √©changes et le cadre de travail, favorisant ainsi le d√©veloppement de l‚Äôentreprise & de chacun des individus qui la composent. En tant qu‚Äôemployeur qui positionne l‚Äô√©galit√© des chances au c≈ìur de son syst√®me de valeurs, nous accueillons et consid√©rons les candidatures de l‚Äôensemble des candidats qualifi√©s et comp√©tents. Nous nous engageons √† continuer √† avancer vers un ba&sh toujours plus inclusif, o√π chaque employ√© d√©veloppe un fort sentiment d‚Äôappartenance. Si vous souhaitez rejoindre une marque en pleine expansion avec une vraie philosophie, faites-nous parvenir votre candidature.","Ba&sh, a fast-growing fashion brand, is seeking an experienced Data Engineer to join its team in centralizing the data silos and proposing an overview to its business. The ideal candidate will have at least 4 years of experience in an advanced Data environment, a strong interest in Data, and familiarity with Snowflake, Talend, Python, and Cloud Data Warehousing. The position's responsibilities include creating, modeling, enriching, and evolving Datamarts to transform raw data into organized information that can be used by Data Analysts, optimizing existing data processing solutions, and identifying gaps and dependencies to evolve the data environment further.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
424,43614,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_lyon,Data Engineer,CGI,"{Azure,GITLAB,Jenkins,Talend,Shell,Kubernetes,AWS,Snowflake,Docker,Kafka,Linux,GCP,Java,Python}",T√©l√©travail partiel possible,"Lyon, 69002","IT / Digital, Transformation, Big Data",CDI,2023-01-30,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Au sein de l‚Äô√©quipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux √©quipes d‚Äôexpert et de d√©ploiement des solutions. Vous participerez au d√©veloppement strat√©gique d‚Äôun projet d‚Äôun client et vous √©voluerez dans un contexte international, et b√©n√©ficierez de l‚Äôexpertise de consultants CGI, en immersion chez le client. A ce titre vos principales responsabilit√©s seront : ‚Ä¢ Appr√©hender le contexte et les enjeux M√©tier du client ; ‚Ä¢ Comprendre et exp√©rimenter le cadre Agile et Lean ; ‚Ä¢ Analyser les besoins fonctionnels et d√©terminer le mod√®le de donn√©es n√©cessaire avec l‚Äôaccompagnement de Consultant senior ; ‚Ä¢ Participer au d√©veloppement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; ‚Ä¢ √âtablir et d√©rouler des sc√©narios de tests ; ‚Ä¢ Participer √† la vie de la communaut√© Data. Environnement technique : ‚Ä¢ Cloud provider : AWS, GCP , Azure ‚Ä¢ Data Acquisition : Kafka, Kafka Connect , Talend, Snowflake ‚Ä¢ Script : Java, Angular, Python, Shell, ‚Ä¢ Environnement : Linux, Docker, Kubernetes ‚Ä¢ Outils : Jenkins, GITLAB CI ‚Ä¢ Ticketing : JIRA ‚Ä¢ Reporting: Power BI, Qliksense De formation bac+5 ou de formation sup√©rieure en informatique, vous disposez de 2 ans exp√©riences r√©ussie dans le d√©ploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP. Des connaissances m√©tiers dans le domaine du manufacturing ou ses m√©tiers de la sant√© , alli√©s √† des comp√©tences techniques fortes sont √©galement des atouts pour la r√©ussite de ce projet. Votre capacit√© d'adaptation, votre autonomie, votre sens du service ainsi que vos qualit√©s relationnelles seront vos atouts pour r√©ussir et √©voluer. Vous devrez √™tre en capacit√© de participer / animer des ateliers en anglais. A propos de CGI: Chez CGI, leader mondial du conseil et des services num√©riques, nous sommes convaincus que le digital et l‚Äôinnovation sont de formidables leviers pour acc√©l√©rer la transformation de la soci√©t√© et mettre la technologie au service du plus grand nombre. Nos 78 000 experts dans le monde, dont 11 000 en France, accompagnent au quotidien les entreprises et les administrations de la strat√©gie √† la mise en ≈ìuvre de leur transformation IT pour les rendre plus performantes, autant d‚Äôenjeux qui rythmeront votre quotidien aux c√¥t√©s de nos professionnels.","CGI, a global leader in digital consulting and services with a presence in 30 locations across France, is seeking a candidate for the role of Data Engineer with a background in Kafka, Datalake AWS, and Datalake CGP. The role involves working with stakeholders from all levels of the organization and participating in strategic project development. The ideal candidate should have strong technical skills, business acumen, and communication abilities. The position offers a chance to work with cutting-edge technologies such as Cloud providers AWS, GCP, and Azure, and participate in the development of the Data community.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
418,39830,https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-h-f-lyon_lyon_EVOTE_RyRO0eA,Data Engineer (H-F) - Lyon,evoteo,"{GIT,shell,Jenkins,Scala,GitHub,Glue,AWS,S3,Spark,Java,Python}",T√©l√©travail partiel possible,"23, Rue Cr√©pet, Lyon, 69007","Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2022-11-29,"evoteo est une entreprise de prestation sp√©cialis√©e en #DATA. L‚Äô√©volution des structures, √©tablies depuis plusieurs ann√©es, voire plusieurs d√©cennies, est en marche et evoteo accompagne ses partenaires pour y faire face. Les √©quipes d‚Äôevoteo sont compos√©es d‚Äôing√©nieurs, de chefs de projets et de transformations managers tous passionn√©s par ce changement technologique. La r√©ussite de l‚Äôentreprise repose sur un management de carri√®re simple et efficace de ses collaborateurs dont les axes principaux sont : L‚Äô√©volution La curiosit√© L‚Äôexigence La collaboration Dans le cadre de notre croissance et pour r√©pondre aux besoins √©volutifs de nos clients, nous recherchons un #DATA Engineer afin d‚Äôint√©grer nos √©quipes. Missions : Analyser les besoins avec les √©quipes m√©tiers et #DATA analystes Participation aux choix des solutions √† mettre en place Concevoir, d√©velopper et garantir la qualit√© des traitements de donn√©es et r√©aliser les tests de validation Collecte, sauvegarde et traitement des donn√©es Administration du cluster AWS R√©aliser les ordonnancements des traitements Industrialiser les traitements #DATA science au sein du #DATA lake Travailler sur la mise en place du d√©ploiement Assurer la mise en ≈ìuvre, le suivi, l‚Äôexploitation et la mise √† jour des diff√©rents outils d√©ploy√©s Nous recherchons avant tout des personnalit√©s : curieuses, habiles, sociales, adaptables et passionn√©es. De formation BAC+5 (Master 2,DESS,DEA), formation ing√©nieure ou informatique, tu as une exp√©rience d‚Äôau moins 2 ans en engineering des environnements Big #DATA Les technos : D√©veloppement (Python - pyspark, Scala, Java, Script shell) Int√©gration continue (GIT, Jenkins, Ansible) Connaissances du Cloud AWS (S3, Glue, Stepfunction‚Ä¶) Technologies Big #DATA (Spark) Outils DevOps et d√©ploiement automatis√© : Jenkins, Ansible, Cloudformation, GitHub Nous insistons sur les comp√©tences Spark/scla en ecosysteme AWS. Ce poste en CDI est √† pourvoir d√®s que possible sur la r√©gion lyonnaise. Tu es un futur collaborateur acteur, en qu√™te de perspectives d‚Äô√©volution, capable de rigueur et d‚Äôesprit d‚Äôanalyse ? Rejoins-nous ! Comme √©voqu√©, nous aimons les choses simples ‚Äì envoie-nous ta page Linkedin ou bien un CV, ensuite nous te proposerons : Un √©change t√©l√©phonique permettant de cibler parfaitement tes souhaits Un entretien de d√©couverte mutuelle afin de savoir si nous avons envie de travailler ensemble Tu reviens vers nous si tu es int√©ress√© pour un dernier √©change avec le PDG pour partager la vison, parler de ta carri√®re et valider ta candidature.","Evoteo is seeking a Data Engineer with at least two years of experience in engineering Big Data environments. The successful candidate will analyze business needs, participate in the selection of solutions, develop high-quality data processing, and ensure successful testing and validation. Experience with Spark, Scala, AWS, and DevOps is required. The company values individuals who are curious, adaptable, and passionate, with strong collaboration skills. The position is based in Lyon, France.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
415,39750,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-paris-h-f_paris,Data Engineer - Paris -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilit√©, SaaS / Cloud Services",CDI,2022-11-29,"Avec plus de 15 milliards de requ√™tes par an, Kisio Digital business unit de Kisio et filiale num√©rique du Groupe Keolis est un acteur majeur de la mobilit√©. Les trois grands domaines d‚Äôintervention de Kisio Digital portent sur les syst√®mes d‚Äôinformation-voyageur (recherche d‚Äôitin√©raire multimodal, porte-√†-porte et temps-r√©el) ; l‚Äôachat de titres de transport d√©mat√©rialis√©s et le mobile-ticketing. Sa vision de la mobilit√© : permettre √† chacun de se d√©placer plus facilement, plus agr√©ablement et avec le moins d‚Äôemprise possible sur la plan√®te. C‚Äôest ce qu‚Äôon appelle la ¬´ responsive locomotion ¬ª ! Kisio Digital travaille continuellement √† l‚Äôam√©lioration des algorithmes qui permettent de calculer les meilleures solutions d‚Äôitin√©raire en tenant compte du contexte et des pr√©f√©rences du voyageur. Pour r√©pondre aux enjeux d‚Äôune mobilit√© plus intelligente, plus ouverte et plus √©cologique, Kisio Digital r√©alise des applications mobiles, des sites web et des SDK bas√©s sur notre API www.navitia.io. Cette plateforme propose des services num√©riques de mobilit√© dans le monde entier. Elle rassemble une communaut√© de 20 000 d√©veloppeurs et participe √† leur strat√©gie d‚Äôinnovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, v√©lomanes, bussophiles, et autres passionn√©s de montgolfi√®re ou de transports pas toujours tr√®s communs. Curieux et ouverts d‚Äôesprit, ils sont passionn√©s par la mobilit√© au sens large, les nouvelles technologies et les communs num√©riques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communaut√© Open transport. Si vous souhaitez vous √©panouir dans un environnement multiculturel, sachez que Kisio Digital va d√©sormais lancer des services √† l‚Äô√©tranger. Rejoignez-les ! En tant que Data engineer Hove, vous √™tes int√©gr√© √† une √©quipe pluridisciplinaire m√™lant d√©veloppeurs, Product Owner, Architectes dont l‚Äôobjectif est de cr√©er des services √† fortes valeur ajout√© dans le domaine du transport. Vous avez la charge de d√©finir et mettre en ≈ìuvre le pipeline d‚Äôacquisition des donn√©es (datahub) global pour Hove, d‚Äôorganiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Cr√©er et faire √©voluer le moteur d‚Äôingestion des donn√©es (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilit√© des flux de donn√©es Travailler en collaboration avec les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©grations continues, scalabilit√© des mod√®les, craftsmanship, etc‚Ä¶) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners D√©ployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des donn√©es Superviser et monitorer le d√©ploiement et la robustesse des composants mis en production Participer activement √† la qualit√© de l‚Äôing√©nierie logicielle (Relecture de code, test, int√©gration continue, d√©ploiement, etc.) Participer aux √©v√®nements internes √† la communaut√© data interne et externes (AWS Summit, workshops, meetups‚Ä¶) Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.* Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 2 ans en tant que Data engineer Vous op√©rez dans le conseil et pouvez justifier de vos missions Vous maitrisez l‚Äôanglais professionnel Vous maitrisez au moins : Un framework de calcul distribu√© tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala‚Ä¶). Diff√©rents syst√®mes de base de donn√©es (SQL et NoSQL) et le langage SQL. Un framework de streaming de donn√©es tel que Kafka, Kinesis, ‚Ä¶ Une exp√©rience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks‚Ä¶ Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez √™tre capable de livrer du code de qualit√© dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l‚Äô√©quipe tech Un entretien avec notre CTO","Kisio Digital, a major player in mobility with over 15 billion queries per year, is seeking a Data Engineer with at least two years of experience to create and implement a global data acquisition hub and storage solution for the Hove team. The successful candidate will work with a multidisciplinary team to create high-value services in the transport sector, and must have knowledge of at least one distributed computing framework, multiple programming languages, and SQL and NoSQL databases. Fluency in professional English is also required.",N,N,N,2,1,0.04154662416233763
413,37249,https://www.welcometothejungle.com/fr/companies/bcg-gamma/jobs/forward-deployed-data-engineer_paris,Data Engineer,BCG Gamma,"{React,python,spark,Pandas,JavaScript,Kubernetes,AWS,Docker,scale,Hadoop,Spark,TypeScript,Azure,GraphQL,SQL,SCALA}",T√©l√©travail partiel possible,N,"Intelligence artificielle / Machine Learning, IT / Digital, Organisation / Management",CDI,2022-10-18,"Location: PARIS Amsterdam, Barcelona, Berlin, Cologne, Copenhagen, Dusseldorf, Frankfurt, Helsinki, London, Madrid, Milan, Munich, Oslo, Sao Paulo, Stockholm, Vienna, Warsaw, Zurich Geography: Central & South America, Europe & The Middle East Capabilities: Big data & advanced analytics, Innovation & product development, Technology & digital Industries: Automotive & Mobility, Biopharmaceuticals, Consumer products, Education, Energy & environment, Engineered products & infrastructure, Financial institutions, Health care payers & providers, Insurance, Media & entertainment, Medical devices & technology, Metals & mining, Private equity and principal investment, Process industries & building materials, Public sector, Retail, Social sector, Technology industries, Telecommunications, Transportation, travel & tourism Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we work closely with clients to embrace a transformational approach aimed at benefiting all stakeholders‚Äîempowering organizations to grow, build sustainable competitive advantage, and drive positive societal impact. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives that question the status quo and spark change. BCG delivers solutions through leading-edge management consulting, technology and design, and corporate and digital ventures. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, fueled by the goal of helping our clients thrive and enabling them to make the world a better place. Practice Area Profile BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you‚Äôll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology. What You‚Äôll Do As a forward-deployed Data Engineer, you‚Äôll be part of our rapidly growing engineering team and help build the next generation of AI solutions. You‚Äôll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions. Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG GAMMA. WHO YOU ARE We are looking for talented individuals with a passion for data engineering, software development and transforming organizations into AI led innovative companies Apply data engineering practices and standards to develop robust and maintainable solutions Actively involved in every part of the software development life cycle Experienced at guiding non-technical teams and consultants in best practices for large-scale data engineering Motivated by a fast-paced, service-oriented environment and interacting directly with clients on new features for future product releases Enjoy collaborating in teams to share software design and solution ideas A natural problem-solver and intellectually curious across a breadth of industries and topics What You‚Äôll Bring (Experience & Qualifications) Master‚Äôs Degree in Computer Science or relevant field Experience in data engineering and working with global and remote agile squads Proficiency with analytic software programming ideally in python, C++, or SCALA Fluency with the storage, manipulation, and management of relational, non-relational and streaming data structures, specifically SQL, Spark, and Hadoop Proficiency with infrastructure as code principles Experience working on AWS, Azure, or Google cloud infrastructure NICE TO HAVE DevOps: Docker, Kubernetes, CI/CD, Terraform Understanding of parallel computing Full stack development: GraphQL, React, JavaScript, TypeScript Data Science and machine learning (Pandas, Scikit learn) WORK ENVIRONMENT Fluency in English is required as well as fluency in the local language for most locations Ability to travel based on client and business needs. Expect 30-50%","BCG GAMMA seeks forward-deployed data engineers with a master's in computer science to help build new AI solutions, partner with clients in various industries, and deliver thought leadership in scientific communities. The ideal candidate can use data engineering practices to create robust solutions, work on global remote agile squads, and fluently work with relational, non-relational, and streaming data structures. Preference will be given to candidates with proficiency in Python, C++, or Scala, and knowledge of Docker, Kubernetes, CI/CD, Terraform, parallel computing, full-stack development, and data science and machine learning. Travel between 30-50% for client and business needs is expected.",N,N,N,2,1,0.04154662416233763
411,37148,https://www.welcometothejungle.com/fr/companies/leboncoin/jobs/data-engineer-team-bi-engineering-f-h_paris_LEBON_We2V3W,"Data Engineer, team BI Engineering -",leboncoin,"{Athena,Airflow,Redshift,Kubernetes,AWS,S3,PostgreSQL,Kafka,R,Spark,Unix,Docker,Java,Github,SQL,Python}",T√©l√©travail partiel possible,N,"√âconomie collaborative, E-commerce",CDI,2022-10-18,"Cr√©√© en 2006, leboncoin.fr est une plateforme d‚Äô√©changes d‚Äôun nouveau genre, qui simplifie l‚Äôacc√®s √† la consommation, privil√©gie la relation locale et fait du digital un outil au service de tous. En facilitant le rapport des individus √† l‚Äô√©change et √† la consommation, leboncoin a su s‚Äôimposer en quelques ann√©es comme ph√©nom√®ne de soci√©t√© fran√ßais et faire du bonheur des uns le bonheur des autres. En France, nous nous positionnons comme un acteur num√©rique, √©conomique, soci√©tal, innovant, avec toujours le m√™me objectif : faciliter tous les √©changes au quotidien de l‚Äôensemble de nos utilisateurs. Gr√¢ce √† notre plateforme de petites annonces, nous donnons une seconde vie √† des milliers de biens. L‚Äôimpact positif de ces √©changes a √©t√© √©valu√© √† 5,8 millions de tonnes de C02 √©conomis√©s sur une ann√©e. Derri√®re cette apparente simplicit√©, se trouve une entreprise en forte croissance de plus de 1500 salari√©s, o√π il fait bon travailler, une entreprise qui cultive une d√©marche RH responsable et collective. Leboncoin r√©unit √©galement les sites Agriaffaires, MachineryZone, Truckscorner, AvendreAlouer, Paycar, Locasun, Videdressing, L‚Äôargus et Pilgo Vous aimez travailler en √©quipe , faites preuve de r√©elles qualit√©s humaines et vous √™tes fortement motiv√© pour rejoindre une entreprise innovante , o√π vous pourrez proposer vos id√©es et les mettre en pratique: nous vous attendons ! En tant que Data Engineer, vous occuperez un poste cl√© entre les analystes et l‚Äôinfrastructure data, dans un contexte o√π la donn√©e joue un r√¥le capital. La data chez leboncoin, c‚Äôest : Des centaines de milliers d‚Äôannonces d√©pos√©es chaque jour Des centaines de t√©raoctets de donn√©es √† valoriser Le contexte : Vous √©voluerez au quotidien au sein de l‚Äô√©quipe BI Engineering compos√©e de data engineers et d‚Äôun engineering manager. La principale mission de l‚Äô√©quipe est d‚Äôassurer la tuyauterie technique permettant l‚Äôexploitation des donn√©es par les √©quipes business du groupe Leboncoin, en √©troite collaboration avec l‚Äô√©quipe Data Visualisation. Vous serez un r√©f√©rent data aupr√®s de plusieurs feature teams pour les conseiller sur les contrats d‚Äôinterface des donn√©es et √©vang√©liser sur les usages de donn√©es qu‚Äôils produisent. Dans un environnement √† la pointe des technologies data engineering actuelles: Airflow, Spark, Kafka, AWS (S3, Redshift, Athena), JupyterHub, Kubernetes. Cet environnement et ses bonnes pratiques sont partag√©es lors de d√©mos et lors de journ√©e de guilde (communaut√© de pratique) data engineering. D√©veloppement sous Ubuntu en Java, Python et SQL avec IntelliJ, Travis, Docker, Github, Terraform. Ce que vous ferez : Analyser et formaliser les besoins utilisateur afin de les int√©grer aux √©volutions D√©velopper des data pipelines complexes assurant une circulation optimale des donn√©es Accompagner la conception de nouvelles sources de donn√©es en temps r√©el (Kafka / Avro) √ätre au contact et coordonner les m√©tiers fonctionnels et techniques concern√©s par la mise en place d'un projet BI Participer activement √† la veille technologique et √† l'effort de R&D Garantir le bon fonctionnement, la disponibilit√©, l‚Äô√©volution et la performance des outils Poste bas√© √† Paris (75010) Disponibilit√© : d√®s que possible Processus de recrutement : Entretien t√©l√©phonique avec M√©lody (RH) Entretien avec C√©line (manager) et un membre de l'√©quipe Entretien avec deux membres de l'√©quipe data engineer Entretien avec Julien (directeur technique) + M√©lody (RH) Id√©alement de formation type Bac +4/5 √©cole d‚Äôing√©nieur, vous justifiez d‚Äôune exp√©rience d‚Äôau moins 2 ans sur ce type de poste. Vous connaissez les environnements Unix, poss√©dez un niveau avanc√© en SQL et un bon niveau en d√©veloppement, id√©alement Python (ou volont√© de monter en comp√©tences). Vous √™tes familier de la mod√©lisation d√©cisionnelle, de la conception et/ou de l'impl√©mentation d'un data warehouse. La connaissance de PostgreSQL / Redshift et d‚ÄôApache Spark serait un plus. Autres qualit√©s recherch√©es : Excellent sens du r√©sultat et de la qualit√© Aptitudes √† communiquer , en particulier avec les directions m√©tiers Sens du travail en √©quipe Curiosit√© technique en g√©n√©ral Aptitudes r√©dactionnelles","Leboncoin is looking for a data engineer to join their BI Engineering team responsible for the technical pipeline that enables exploitation of data by the Leboncoin business teams. The ideal candidate will be working in a cutting-edge data engineering environment, developing data pipelines, and ensuring optimal circulation of data across hundreds of thousands of ads posted daily on the Leboncoin platform. The candidate should have at least 2 years of experience in a similar role, with advanced SQL, UNIX and development skills.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
408,37184,https://www.welcometothejungle.com/fr/companies/thales/jobs/dataengineer-departement-ia-bigdata_sophia-antipolis,DataEngineer - D√©partement IA & BigData,Thales,"{Oracle,PostgreSQL,Cassandra,Hive,Nvidia,Microsoft,MongoDB,Kafka,NoSQL,Flink,AWS,HBase,Storm,Java,SQL,Hadoop,GCP,MinIO,Scala,HDFS,S3,Spark,Pig,AZURE}",T√©l√©travail partiel possible,N,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2022-10-18,"Ceux qui font avancer le monde s‚Äôappuient sur Thales. Dans un monde en constante mutation, √† la fois impr√©visible et riche d‚Äôopportunit√©s, ils sont aux c√¥t√©s de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus s√ªr. Riches de la diversit√© de leurs expertises, de leurs talents, de leurs cultures, leurs √©quipes d‚Äôarchitectes con√ßoivent un √©ventail unique de solutions technologiques d‚Äôexception, qui rendent demain possible d√®s aujourd‚Äôhui. Du fond des oc√©ans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients √† ma√Ætriser des environnements toujours plus complexes pour prendre des d√©cisions rapides, efficaces, √† chaque moment d√©cisif. Quel que soit l‚Äôenjeu. QUI SOMMES-NOUS ? Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces. QUI SOMMES-NOUS ? Rejoignez Thales, leader mondial des technologies de s√ªret√© et de s√©curit√© pour les march√©s de l‚ÄôA√©rospatial, du Transport, de la D√©fense, de la sant√©, de l‚Äô√©nergie et de la S√©curit√© . Fort de 80 000 collaborateurs dans 56 pays , le Groupe b√©n√©ficie d‚Äôune implantation internationale qui lui permet d‚Äôagir au plus pr√®s de ses clients, partout dans le monde . Nos √©quipes de la Direction de l‚ÄôIng√©nierie Logicielle ( DIL ) fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces . Le d√©partement IA & Big Data recherche plusieurs Ing√©nieurs DataEngineer (H/F) bas√©s √† Sophia Antipolis (06). QUI ETES-VOUS ? De formation Bac+4 ou Bac +5 (type √©cole d‚Äôing√©nieur), vous poss√©dez de bonnes connaissances dans le domaine de la donn√©e (Data Science, Data Engineering, Stockage), en ing√©nierie logicielle globalement. Une connaissance cloud serait un r√©el atout, qu‚Äôil soit public (AWS, GCP, AZURE) ou priv√©. Principales activit√©s que vous r√©aliserez : Mise en place de pipelines de traitement de donn√©es Utilisation de l‚Äô√©tat de l‚Äôart des technologies actuelles d√©di√©es √† ces activit√©s : Kafka / Spark / Spark Streaming / Flink / Storm D√©veloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie) Utilisation de tous les types de stockage actuels SQL : Oracle, SQLServer, PostgreSQL NoSQL : Cassandra / MongoDB / HBase Objet : S3 / MinIO Vous avez de bonnes exp√©riences en d√©veloppement logiciel et/ou scripting (principalement Scala & Java). Vous √™tes √† l‚Äôaise en Anglais. Vous √™tes curieux(se) et rigoureux(se). Vous aimez travailler en √©quipe au quotidien. Pour vous le succ√®s n‚Äôest que collectif. Vous vous reconnaissez ? Alors parlons missions ‚Ä¶ CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Le d√©partement IA & Big Data f√©d√®re et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d‚Äôune structure permettant d‚Äôacc√©l√©rer la transformation des enjeux Data de nos clients. Nos savoir-faire : Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie Projets d‚Äôint√©gration syst√®me Nos domaines m√©tier : Maintenance pr√©dictive, Traitement d‚Äôimage pour la sant√© Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de r√©ponse Aerospace : Centre de Mission et de Contr√¥le, Dynamique du Vol, Qualit√© Image, Occupation des sols, Sondage Atmosph√©rique Nos partenaires : Recherche : INRIA, CNRS, 3IA Externes : Nvidia, Microsoft En collaboration avec les membres de notre d√©partement : Vous contribuerez au d√©veloppement et √† la scalabilit√© de nos plateformes au travers d‚Äôactivit√©s d‚Äôautomatisation, de cr√©ation de services manag√©s et d‚ÄôAPI. Vous accompagnerez nos clients dans leurs projets de valorisation de donn√©es en proposant des solutions techniques et fonctionnelles, √©valu√©es, choisies et opportunes. Vous participerez √† l‚Äôint√©gration des plateformes techniques s√©curis√©es d√©velopp√©es par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com) Vous collaborerez √† nos publications, conf√©rences et webinars. Vous serez partie prenante de la 3√®me r√©volution industrielle impactant tous les secteurs d‚Äôactivit√©, √©nergie, sant√©, industrie, ‚Ä¶ La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant √† cette offre . Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is seeking multiple Data Engineers to join their team in Sophia Antipolis, France. The ideal candidates will have a degree in engineering or related field, experience in data engineering, software engineering, and cloud knowledge. Responsibilities include designing data processing pipelines, developing on Hadoop stacks, and utilizing a variety of storage types. Successful candidates will contribute to the scalability of platforms, coordinate AI and Big Data operations, and participate in the integration of secure technical platforms.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
407,37125,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_6XzD6Lx,Data Engineer,TotalEnergies Digital Factory,"{Kafka,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,N,"Logiciels, Big Data, Energie",CDI,2022-10-18,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. TotalEnergies a d√©cid√© d'acc√©l√©rer la production interne de solutions digitales pour ses activit√©s en cr√©ant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilit√© et l'esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Nous cr√©ons et d√©ployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. Nous consid√©rons les personnes comme la ressource la plus pr√©cieuse pour r√©ussir, c'est pourquoi nous tenons non seulement √† recruter les meilleurs talents, mais aussi √† cr√©er des liens uniques entre nos employ√©s. En accord avec les politiques HSE de la compagnie et celles de la Digital Factory, le/la Data Engineer int√©grera l'√©quipe ¬´ Delivery ¬ª, qui intervient dans la production des Minimum Viable Products (MVPs). En soutien de la Squad dans l'organisation des donn√©es, cette √©quipe √©volue dans un contexte agile (scrum/scrumban), en mode it√©ratif et co-constructif, en s'appuyant sur l'intelligence collective. Votre r√¥le est de garantir la qualit√© des pipelines data du produit, assurer le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es. Missions : Concevoir, construire et int√©grer des donn√©es, au sein de la squad et en collaboration avec les autres squads Assurer le stockage, la consommation, l'int√©gration et la gestion des donn√©es des cas d'utilisation. Faire l'analyse de l'accessibilit√© des donn√©es et recommander des solutions pour leur int√©gration. Coordonner la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de donn√©es. Int√©grer les donn√©es dans le data lake. Collaborer avec les data scientists pour la r√©alisation des mod√®les de pr√©diction. Produire un code de qualit√©, mettre en place des tests automatis√©s pour le contr√¥ler. Interagir avec les architectes et les autres data engineers, pour s'assurer de l'efficacit√© des solutions et apporter des pr√©conisations techniques Ma√Ætriser les bonnes pratiques de monitoring des flux de donn√©es. Assurer la veille technologique sur les architectures data et les nouvelles technologies. Coacher et accompagner la communaut√© des Data Engineers de la Digital Factory. Vous √™tes dipl√¥m√©/e d'un Master ou d'une √©cole d'ing√©nieur sp√©cialis√©e en informatique ou math√©matiques. Vous avez au minimum 2 ans d'exp√©rience en data engineering. Vos comp√©tences techniques sont reconnues en Python, Spark et SQL. Vous avez une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles Vous mettez en place des pratiques de test syst√©matiques pour v√©rifier la qualit√© de votre code. Vous avez la capacit√© √† concevoir et √† mettre en uvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle. Vous avez une premi√®re exp√©rience sur un provider de Cloud, Azure de pr√©f√©rence et ma√Ætrisez la scalabilit√© en temps r√©el (Kafka). Vous comprenez le machine learning. Vous avez un niveau de fran√ßais et d'anglais courant.","TotalEnergies is seeking a Data Engineer with at least 2 years of experience in data engineering to join its Digital Factory team responsible for producing Minimum Viable Products. The successful candidate will be responsible for designing, building, and integrating data, ensuring the quality of data pipelines, developing programs to collect, prepare, transform, and disseminate data, and collaborating with data scientists to produce prediction models. The candidate must have experience with Python, Spark, SQL, and cloud providers like Azure, an understanding of machine learning, and the ability to implement large-scale data loading, manipulating, processing, analyzing, and exploring solutions.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 1 an,2,1,0.04154662416233763
406,36869,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-f-h_lille,Data Engineer,Atos,"{GCP,AWS,Talend}",T√©l√©travail partiel possible,N,IT / Digital,CDI,2022-10-12,"Atos est un leader international de la transformation digitale avec plus de 110 000 collaborateurs dans 73 pays et un chiffre d‚Äôaffaires annuel de plus de 11 milliards d‚Äôeuros. Num√©ro un europ√©en du Cloud, de la cybers√©curit√© et des supercalculateurs, le groupe fournit des solutions int√©gr√©es de Cloud Hybride Orchestr√©, Big Data, Applications M√©tiers et Environnement de Travail Connect√©. Partenaire informatique mondial des Jeux Olympiques et Paralympiques, le Groupe exerce ses activit√©s sous les marques Atos, Atos Syntel, et Unify. Atos est une SE (Soci√©t√© Europ√©enne) cot√©e sur Euronext Paris et fait partie de l‚Äôindice CAC 40. La raison d‚Äô√™tre d‚ÄôAtos est de contribuer √† fa√ßonner l‚Äôespace informationnel. Avec ses comp√©tences et ses services, le groupe supporte le d√©veloppement de la connaissance, de l‚Äô√©ducation et de la recherche dans une approche pluriculturelle et contribue au d√©veloppement de l‚Äôexcellence scientifique et technologique. Partout dans le monde, Atos permet √† ses clients et √† ses collaborateurs, et plus g√©n√©ralement au plus grand nombre, de vivre, travailler et progresser durablement et en toute confiance dans l‚Äôespace informationnel. La Mission : Au sein de l'√©quipe Data, en tant que Data Engineer, vous participez √† la r√©alisation de divers projets et vos missions sont : Apporter votre connaissance en Big Data permettant la manipulation des donn√©es Concevoir les plateformes permettant de traiter des volumes de donn√©es importants Mettre en place des bases de donn√©es Pr√©parer le pipeline de donn√©es pour que les donn√©es d√©ploy√©es soient s√©curis√©es et claires afin d'√™tre analys√©es et transform√©es Environnement technique : Stambia, ODI, Talend, AWS, GCP Nous rejoindre c‚Äôest : Faire partie d‚Äôune √©quipe √† taille humaine en fort d√©veloppement dans la r√©gion Hauts de France Echanger directement avec ton manager de proximit√© T‚Äôouvrir √† de belles perspectives de carri√®re dans le groupe : priorit√© √† la mobilit√© interne Construire ta trajectoire professionnelle : certifications & formations, missions B√©n√©ficier d‚Äôun bon environnement de travail : t√©l√©travail, locaux neufs et faciles d‚Äôacc√®s dans le centre-ville de Lille, afterworks, ‚Ä¶ Un package salarial attractif : CDI, R√©mun√©ration selon profil, Frais de transport, Tickets Restaurants, Mutuelle int√©ressante, Prime de vacances, Plans Entreprise (√©pargne, actionnariat), CET, avantages CSE (billetterie, vacances, ‚Ä¶) #TheFutureIsOurChoice#JoinAtosTeam #Atos Profil recherch√© : Qui √™tes-vous ? De formation ing√©nieure en informatique Bac + 5 informatique ou scientifique vous justifiez d'une exp√©rience r√©ussie en tant que scrum master. Une bonne communication orale et √©crite en fran√ßais est fortement recommand√© ainsi qu'un niveau d‚Äôanglais professionnel . Savoir- √™tre : Bon esprit d'analyse et de synth√®se, sens de l'organisation et de la qualit√©, force de proposition, rigueur, travail en √©quipe, adaptabilit√©.","Atos, a global leader in digital transformation, is seeking a Data Engineer with strong skills in Big Data, database design, and data security. The ideal candidate must have a degree in computer science or a related field, along with experience working on large data projects. The role involves designing platforms to handle large volumes of data, creating databases, and setting up data pipelines. Atos offers an attractive salary package, opportunities for career growth, and a supportive work environment with new, easy-to-access offices in Lille. Candidates should have strong communication skills, both written and verbal in French and English, and possess analytical, organizational, and teamworking skills.",Bac +3,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
405,36688,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-tableau-dataviz-bi-factory-f-m-d_paris,BI Engineer Tableau / DataViz - BI Factory,Decathlon Technology,"{AWS,dataset,github,GCP,SQL,Tableau}",T√©l√©travail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-10-12,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour r√©pondre aux mieux a son ambition de pilotage par la data, Decathlon a organis√© une DATA UNIT √† laquelle la BI Factory est rattach√©e. TA RESPONSABILITE : Ta mission principale consiste √† : R√©pondre √† des demandes d‚Äôanalyses r√©currentes de KPIs en mettant √† disposition des m√©tiers, de mani√®re automatique et r√©guli√®re, des outils de data visualisation performants. Intervenir d√®s la finalisation du cadrage projet par le Project Manager jusqu‚Äô√† la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : Project Manager, les autres BI Engineers, les m√©tiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e BI Engineer, bas√©-e, au choix √† Paris, Lille, Lyon ou Nantes. Le p√©rim√®tre technique : ma√Ætrise du SQL ma√Ætrise d‚Äôune BDD ma√Ætrise d‚Äôun ETL ma√Ætrise d‚Äôun outil de datavisualisation (id√©alement Tableau software) R√©daction de documentation dans github et/ou wiki M√©thodologie AGILE CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience d‚Äôau moins 3 ans en d√©veloppement BI et parle un Anglais courant (relation avec des √©quipes √† l'international). Tu as d√©j√† produit de la data visualisation performant avec Tableau Software ; Pour r√©ussir, tu dois savoir: Comprendre le besoin m√©tier / interagir avec les interlocuteurs fonctionnels Comprendre un mod√®le de donn√©es et t'en servir. Mod√©liser un dataset afin de d√©velopper des visualisations en assurant les performances techniques D√©velopper le flux d‚Äôextraction des data n√©cessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages m√©tiers exprim√©s lors du cadrage Ma√Ætriser les technologies utilis√©es et les bonnes pratiques de d√©veloppement Partager ton avancement et les difficult√©s rencontr√©es lors des instances AGILE d√©di√©es. R√©diger la documentation technique permettant d‚Äôassurer un run efficace Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et la vie en √©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a BI Engineer to provide automated and regular data visualization tools to the company's departments. The successful candidate must have at least three years of experience in the development of BI and be able to develop data extraction flows, understand business requirements, deal with technical performance issues, and be fluent in English. The position is based in Paris, Lille, Nantes, or Lyon, and offers two days of remote work per week, flexible work locations, and internal and external training opportunities, among other benefits. Decathlon is committed to inclusion and non-discrimination, such as promoting diversity, innovation, and performance.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
404,36585,https://www.welcometothejungle.com/fr/companies/thefork/jobs/data-analytics-engineer_paris,Data Analytics Engineer,TheFork,"{dbt,SQL,Airflow,Python}",T√©l√©travail partiel possible,N,"Application mobile, Tourisme, FoodTech",CDI,2022-10-12,"TheFork, a TripAdvisor¬Æ Company is the leading online restaurants reservation platform in Europe, Australia and Latin America, with a network of more than 80,000 restaurants worldwide, more than 30.5 million monthly visits and present in 22+ countries around the globe. TheFork connects restaurants and diners. Through TheFork (website and application), as well as through TripAdvisor, users can easily select a restaurant according to preference criteria (such as the localisation, type of cuisine, restaurant type and average price), consult user reviews, check real-time availability and instantly book online. From the restaurants‚Äô side, TheFork provides them with a software solution, TheFork Manager, which enables restaurants to optimize reservations management, streamline operations and ultimately improve service and revenues. TheFork team aims to inspire and enable people to confidently discover, experience and share food. We operate under a shared set of values that define how we do business and how we interact with our colleagues, our partners, our customers and our food community. We strongly believe that building a diverse workforce of people from all walks of life helps us have a richer, more vibrant, more successful workplace. W elcome to our fabulous world. üç¥ We are TheFork . Our mission is to bring happiness through amazing dining experiences, thanks to our 3 main products : üì± TheFork App : the restaurant discovery and booking app for every occasion üñ•Ô∏è TheFork Manager : the tool to digitize restaurant operations and be in full control of your business üí≥ TheFork Pay & gift cards : the new and amazing dining payment experience Creator of a unique model that disrupted the restaurant industry 15 years ago, we are now the leading dining platform across Europe and Australia. We are experiencing an exciting period of growth, and we need the greatest folks onboard. Together, we will make our wildest dreams come true! We strongly believe that our mission can only be achieved if we also bring happiness to our working environment. We do this by providing a flexible, multicultural and positive environment where each individual has the space to grow. We nurture this happy culture through our core values : We are better together - We act like an owner - We genuinely care for our users and customers - We believe in transparency - We never stop learning - Speed wins Oh! And we are also part of the big Tripadvisor family ‚ù§Ô∏è With love, Your future buddies, the Forkies. Data / Analytics Engineer @ TheFork What You Will Do: As a Data / Analytics Engineer, you will be part of the Business Intelligence Factory (itself part of the Data team, a transverse organization supporting our Business) The Data Team has 3 missions : Accelerate the Business thanks to data and insights Support company transformation towards a Data-driven Culture Develop a valuable and actionable data asset As a member of the BI FactoryBI @ TheFork, you will help the company leverage its data asset to make the right business decisions thanks to modern and cutting-edge business intelligence solutions. You will deliver quality products conforming to business requirements, data quality, data management and business intelligence best practices using an agile methodology. You will report to the BI Factory Manag and be part of a team of ~40 People including Analytics, BI and Data Engineers Data Scientists Web Analysts Data Analysts Product owners & product managers Role As Analytics Engineer, you will be part of a team of data integration and BI experts which role is to Gather and understand business requirements (autonomously or teamed up with data analysts) Design and develop robust, scalable and industrialized BI assets (data integration flows / ETL, dimension and fact tables, datamarts, metrics, KPIs,‚Ä¶) aiming to facilitate and make consistent the data consumption supporting Business teams in the monitoring of their performance and goals achievement Help the team leverage moden data stack tools and setup best practices in order to bring the BI Factory to the next level Help other analytics engineers upskill on technical aspects of the data platform as Airflow, dbt, Python Develop support approaches (documentation, communication, tooling, training, etc.) towards technical & business teams to ensure progressive acceleration of the organization towards an easier and more systematic usage of BI assets in their day-to-day activities Play a temple keeper role to ensure that TheFork BI ecosystem develops in an optimal and consistent way (efficient, optimized, consistent overall metrics and KPIs, etc.) You will mainly have a technical role with a foot in the business. You will partner with various functional (data analysts) and technical (data engineers, data scientists, product engineers, ...) teams in order to turn technical issues into user friendly, business oriented BI solutions. You will be continuous-improvement-oriented You will identify areas of improvement to make existing ETL and reporting processes more efficient You will work with data and business teams to identify bottlenecks, possible solutions, and determine resource requirements You will bring to TheFork your knowledge of the State-of-the-art for data integration / ETL development (methodology, tooling, etc.) Who You Are: You are working in an autonomous, proactive, accountable and solution-oriented way: you don‚Äôt wait to be told what to do. You deliver high in-depth and reliable analysis in a fast-paced environment, with excellent organization and time management You demonstrate an obsession towards excellence: you systematically consider that good is not enough and constantly consider how to improve and reach the next level of quality, performance and impact You play agile and fast: delivering in a fast-paced environment is an easy business for you. You are comfortable to manage several topics in parallel, with different stakeholders involved. You are familiar with agile methodologies. You bring the outside in: seeking excellence, you have developed habits to benchmark and consider how other companies are doing, what best practices could be source of inspiration and systematically consider how they can apply in your specific business context You have a Master‚Äôs Degree from a Engineering School You have 4 to 8 years of experience in the Data domain You master data transformation patterns (ELT), ideally on a modern tool (example: dbt) You have experience in Airflow and Python You master SQL You have a sharp knowledge of BI practices Dimensional data modeling techniques ETL design Reporting / Data visualization techniques You are able to challenge the data integration flows architecture Your soft skills are a key personal asset to develop partnership interactions with other departments Excellent French & English verbal and written communication skills (Spanish or other European language is a plus) The position is based in Paris What we offer you: üòÑ An awesome team (not everybody like our jokes, but we try our best) üè† A Permanent contract (that can be useful in life) ‚öñÔ∏è Flexible working environment (2 days home office per week) üíö Complementary time off to spend with your loved ones üí∏ Competitive fixed salary, bonus and equity (yes, equity!) üçï Lunch vouchers available for each working day (because yes, we like to try our best restaurants ) üåé International teams - More than 30 nationalities and 16 offices worldwide üè≥Ô∏è‚Äçüåà Highly inclusive working environment ü§∏‚Äç‚ôÄÔ∏è Lifestyle benefits that can be used to reimburse physical, leisure activities, family support, travel etc üéì Continuous learning and development programs (with full access to LinkedIn Learning!) üë∂ Financial benefits in the events of a birth, adoption, pacs, or wedding üòå Free access to the Calm app üè° Housing assistance plan to help find accommodations, or with repairs for your home üè• 72% of health insurance fully covered by the company üë©‚Äçü¶Ω Life Insurance and Disability at no cost to the employee üç¥ Amazing offices with dining, coffee point on each floor, and leisure area üé§ Team building events (we love karaoke. A lot. A lot.) #LI-AD1","The Fork, a leading online restaurant reservation platform, is seeking a Data/Analytics Engineer to help accelerate its business with data and insights, as well as support the company's transformation towards a data-driven culture. The ideal candidate will be proactive, solution-oriented, demonstrate an obsession towards excellence, and have experience with data transformation patterns, Airflow, Python, SQL, and BI practices. The position is based in Paris and offers a flexible, multicultural, and positive environment, as well as competitive compensation and benefits.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
403,35937,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-engineer-data-science-team_barcelone,Data Science Engineer,Veepee,"{Azure,Flink,Beam,Git,Kubernetes,HDFS,HBase,AWS,scale,Kafka,dbt,Spark,BigTable,BigQuery,GCP,Java,SQL,Python}",T√©l√©travail partiel possible,N,E-commerce,CDI,2022-09-28,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire europ√©enne avec la convergence des diff√©rentes soci√©t√©s qui le composent et leurs 6 000 collaborateurs vers une seule et m√™me marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd‚Äôhui pr√©sent dans 14 pays et devient un acteur majeur du commerce digital europ√©en, avec 72 millions de membres et un volume d‚Äôaffaires de 3,7 milliards d‚Äôeuros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour r√©veiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos strat√©gies, afin de proposer la meilleure exp√©rience possible √† nos clients. Vous avez soif d‚Äôapprendre ? Veepee vous permet de construire votre parcours parmi une pluralit√© de m√©tiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes‚Ä¶ prenez part √† une aventure humaine au c≈ìur d‚Äôenjeux digitaux. Impatients de les rencontrer ? Ils ont h√¢te aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a data engineer, you will join one of our Data Science Teams, which is fully cloud-native and distributed between Paris, Barcelona and Brussels. The team‚Äôs responsibility lies in providing forecasts to operational and business entities within Veepee. Your mission will be to support the team in building data pipelines, deploying machine learning models on GCP and developing microservices to expose ML-based predictions to customer-facing products. Responsibilities: Develop, deploy and maintain high-load API‚Äôs on Kubernetes with strong SLA requirements and high business value; Version and deploy machine learning models at scale in a cloud environment; In the context of machine learning projects, develop and maintain data pipelines and ensure data quality; Identify, design, and implement internal process improvements: automating manual processes, optimizing code and data delivery, re-designing infrastructure for greater scalability etc; Keep improving your technical knowledge and expertise by animating the Veepee data engineering community, attending conferences, contributing to open-source projects, organizing and attending meetups. Requirements: At least 3 to 5 years experience in software engineering, preferably in the data field; Strong knowledge of Java, SQL, and Python; Experience with data processing technologies like Apache Beam (or Flink), Spark, Kafka, etc; Experience with distributed data systems: No-SQL databases (HBase, BigTable), data lakes (BigQuery), storage (HDFS); Used to work in a cloud environment (GCP, AWS, Azure,...); Familiar with the concepts of a microservice architecture. Prior experience with deploying containers on a platform like Kubernetes and its ecosystem is a big plus; Proficiency with version control Git; Experience with tools like dbt is a plus; Interest in machine learning and data analytics; A strong team player, willing to share knowledge with other team members and help out where needed; Strong verbal and written English language skills. What we offer: The dynamic and creative environment within international teams; Opportunity to work on a large-scale e-commerce platform with tens of millions of users across Europe; Be part of our vpTech IT community of >800 tech enthusiasts; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences sponsored by vpTech locally and internationally; 3 days of remote work per week or remotely if you prefer so; Excellent team spirit and thriving after-work atmosphere. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you‚Äôll be sure to find your place, no matter the technology you want to work with. If you love to try things why don‚Äôt you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, the conglomerate made up of Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic, and vente-privee, achieved a ‚Ç¨3.7bn ($4.4bn) turnover in 2018. The company is now taking a leading role in European digital commerce, with more than 72 million members in 14 countries. As a data engineer, the successful candidate will join one of the Data Science Teams, working on responsibilities that include developing, deploying and maintaining high-load APIs on Kubernetes, versioning and deploying machine learning models in a cloud environment, and automating manual processes.
",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
402,35839,https://www.welcometothejungle.com/fr/companies/veepee/jobs/data-science-engineer_nice,Data Science Engineer,Veepee,"{Azure,Flink,Beam,Git,Kubernetes,HDFS,HBase,AWS,scale,Kafka,dbt,Spark,BigTable,BigQuery,GCP,Java,SQL,Python}",T√©l√©travail partiel possible,N,E-commerce,CDI,2022-09-28,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire europ√©enne avec la convergence des diff√©rentes soci√©t√©s qui le composent et leurs 6 000 collaborateurs vers une seule et m√™me marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd‚Äôhui pr√©sent dans 14 pays et devient un acteur majeur du commerce digital europ√©en, avec 72 millions de membres et un volume d‚Äôaffaires de 3,7 milliards d‚Äôeuros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour r√©veiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos strat√©gies, afin de proposer la meilleure exp√©rience possible √† nos clients. Vous avez soif d‚Äôapprendre ? Veepee vous permet de construire votre parcours parmi une pluralit√© de m√©tiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes‚Ä¶ prenez part √† une aventure humaine au c≈ìur d‚Äôenjeux digitaux. Impatients de les rencontrer ? Ils ont h√¢te aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a data engineer, you will join one of our Data Science Teams, which is fully cloud-native and distributed between Paris, Barcelona and Brussels. The team‚Äôs responsibility lies in providing forecasts to operational and business entities within Veepee. Your mission will be to support the team in building data pipelines, deploying machine learning models on GCP and developing microservices to expose ML-based predictions to customer-facing products. Responsibilities: Develop, deploy and maintain high-load API‚Äôs on Kubernetes with strong SLA requirements and high business value; Version and deploy machine learning models at scale in a cloud environment; In the context of machine learning projects, develop and maintain data pipelines and ensure data quality; Identify, design, and implement internal process improvements: automating manual processes, optimizing code and data delivery, re-designing infrastructure for greater scalability etc; Keep improving your technical knowledge and expertise by animating the Veepee data engineering community, attending conferences, contributing to open-source projects, organizing and attending meetups. Requirements: At least 3 to 5 years experience in software engineering, preferably in the data field; Strong knowledge of Java, SQL, and Python; Experience with data processing technologies like Apache Beam (or Flink), Spark, Kafka, etc; Experience with distributed data systems: No-SQL databases (HBase, BigTable), data lakes (BigQuery), storage (HDFS); Used to work in a cloud environment (GCP, AWS, Azure,...); Familiar with the concepts of a microservice architecture. Prior experience with deploying containers on a platform like Kubernetes and its ecosystem is a big plus; Proficiency with version control Git; Experience with tools like dbt is a plus; Interest in machine learning and data analytics; A strong team player, willing to share knowledge with other team members and help out where needed; Strong verbal and written English language skills. What we offer: The dynamic and creative environment within international teams; Opportunity to work on a large-scale e-commerce platform with tens of millions of users across Europe; Be part of our vpTech IT community of >800 tech enthusiasts; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences sponsored by vpTech locally and internationally; 3 days of remote work per week or remotely if you prefer so; Excellent team spirit and thriving after-work atmosphere. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you‚Äôll be sure to find your place, no matter the technology you want to work with. If you love to try things why don‚Äôt you jump on this new adventure? Need more info > https://careers.veepee.com/vptech/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, the newly unified conglomerate comprising of Privalia, vente-exclusive, Designer & Friends, Eboutic, and vente-privee, is looking for a data engineer to join one of its data science teams distributed between Paris, Barcelona, and Brussels. The team is responsible for developing machine learning models and providing operational forecasts. The ideal candidate should have experience in software engineering and a strong knowledge of Java, SQL, and Python. Experience with data processing technologies, distributed data systems, and cloud environments is preferred. Additionally, the candidate should be interested in machine learning and data analytics and have strong communication skills.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
401,35742,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineer-confirme-e-h-f_croix,Data Engineer Confirm√©¬∑e -,Decathlon Technology,"{Databricks,Talend,Scala,Redshift,Airflow,Logstash,Lambda,S3,Kibana,Druid,GitHub,github,Spark,BigQuery,GCP,Java,Python,Elastic}",T√©l√©travail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-09-28,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. Mission DECATHLON acc√©l√®re sa transformation digitale avec pour ambition de devenir LA plateforme num√©rique du sportif qui permettra aux utilisateurs d'acc√©der √† tout l'univers du sport en un clic ( Equipement , Activities , Coaching ). Pour accompagner cette transformation, les √©quipes Data √©voluent et mettent au coeur de leurs enjeux: La qualit√© et l‚Äôaccessibilit√© de la donn√©e La scalabilit√© des processus associ√©s au cycle de vie de la donn√©e (ingest, store, transform, expose) L‚Äô√©lasticit√© des infrastructures et des services Si vous avez envie de contribuer √† cette transformation et de co-construire la plateforme data de demain, alors vous serez int√©gr√©¬∑e dans une √©quipe data domain centric. Vos responsabilit√©s Vous serez en charge de: Construire des pipelines scalables de donn√©es structur√©es et non structur√©es D√©finir la strat√©gie de nos stacks techniques et garantir la CI/CD. Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases. Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents. Contribuer activement √† notre communaut√© de data engineers. Comp√©tences techniques souhait√©es: Vous comptez d√©j√† une exp√©rience sur l'environnement Big Data d‚ÄôAmazon Web Services. Vous savez utiliser ses composants (Lambda,Redshift, S3) ainsi qu‚Äôoptimiser leurs performances. Vous ma√Ætrisez l‚Äôun des langages suivants : Python, Scala, Java. Vous maitrisez la mise en oeuvre de pipeline de processing de donn√©es. Avoir d√©j√† travaill√© avec les technologies suivantes est un plus : Spark Databricks Airflow Druid Stack ELK (Elastic Search, Logstash, Kibana) Environnement Google GCP ( BigQuery, Composer, Data Studio) Talend <<<<<<<<<< english version >>>>>>>>>> DECATHLON is accelerating its digital transformation, with the ambition to become THE sports digital platform that will enable users to reach the sports universe with one click ( Equipment , Activities , Coaching ). The Data teams are evolving to support this transformation and put a special emphasis on the following topics: Data quality and accessibility Scalability of processes associated with the data lifecycle (ingestion, storage, transformation, exposure) Infrastructure and service scalability/elasticity Join the data-domain centric teams if you would like to contribute to the digital transformation and collaborate in the building of the data platform of tomorrow. Your accountability You will be in charge of: Building structured and unstructured, scalable data pipelines Defining the strategy of our technology stacks and guaranteeing CI/CD Maintaining and improving existing data sets and pipelines, in order to serve a wider variety of use cases Enabling smart analytics by building robust and relevant data sets Actively contributing to our data engineer community Required technical skills: You have extensive experience with the Amazon Web Services big data environment. You have excellent knowledge of its components (Lambda, Redshift, S3) and of how to optimize their performance. You have extensive knowledge of and experience with at least one of the following languages: Python, Scala, Java. You have extensive experience in setting up data processing pipelines Knowledge or experience of the following technologies a plus: Spark Databricks Airflow Druid Stack ELK (Elastic Search, Logstash, Kibana) Google GCP environment ( BigQuery, Composer, Data Studio) Talend Profil Fort d‚Äôau moins 2 ans d‚Äôexp√©rience sur le m√©tier, vous poss√©dez une grande app√©tence technique. Vous comprenez le cycle de vie de la donn√©e et vous √™tes √† l‚Äôaise avec les concepts de data lineage, data gouvernance et data privacy. Votre bon niveau d‚Äôanglais vous permet de communiquer avec nos clients et partenaires. Vous aimez travailler en agilit√© dans un environnement collaboratif ( GitHub , ,Mob programming). Vous avez un sens du service d√©velopp√©. Sportif¬∑ve, passionn√©¬∑e et exp√©riment√©¬∑e Les √©tapes de recrutement: Votre candidature est √©valu√©e. Peu importe le r√©sultat, vous recevrez une r√©ponse de notre part. Si vous √™tes s√©lectionn√©¬∑e, nous vous contacterons dans les deux semaines qui suivent votre candidature. Le processus de recrutement contiendra √† minima deux entretiens avec des leaders / RH ainsi qu‚Äôun entretien technique. Ce que nous vous proposons: Flexibilit√© de l‚Äôorganisation de travail (lieu, rythme) Libert√© de choix de l'outil de travail (Mac, Windows) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tence (diversit√© de projets, langages et technologies) Formations internes et externes Actionnariat Primes mensuelles et trimestrielles Nous √©tudions aussi les candidatures √† temps partiel. Decathlon est engag√© dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien . <<<<<<<<<< english version >>>>>>>>>> Profile You have a strong technology/technical interest. You have at least two years of data engineering experience. You understand the data lifecycle and are familiar with concepts of data lineage, data governance and data privacy. You are comfortable communicating with customers and partners in English You value working in an agile and collaborative environment (github, mob programming, etc) You have a strong sense of service You are passionate about sports Recruitment steps: Following the evaluation of your application, you will receive an answer from us, no matter if positive or negative. If you are selected, we will contact you within two weeks of your application, to setup at least two interviews with leaders/HR, as well as a technical interview. We consider also application for a part time job. What we propose: Flexibility in the organization of your work (location, time) Choice of your preferred laptop (Mac, PC) Local project team International mobility Training and development (project diversity, languages, technology; on-the-job and formal trainings) Company share plans Monthly and quarterly bonus scheme Decathlon commits to inclusion and non-discrimination, and acts daily in favor of people with disabilities, seniors, social diversity, and gender equality. We recruit mainly based on personality, and diversity within our teams is a major objective, since it brings innovation and performance. If you would like to know more about our commitments, please follow this link .","Decathlon is seeking a Data Engineer to contribute to the company's digital transformation and collaborate in the building of the data platform of tomorrow. The successful candidate will be responsible for building structured and unstructured, scalable data pipelines, defining the strategy of technology stacks, and actively contributing to the data engineer community. They should have at least two years of data engineering experience, a strong technical interest, and knowledge of data lineage, governance, and privacy. Experience with AWS components, such as Lambda, Redshift, and S3, as well as experience with Python, Scala, or Java, is required. Knowledge or experience with Spark, Databricks, Airflow, Druid Stack, ELK, Google GCP, or Talend is a plus.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
399,34932,https://www.welcometothejungle.com/fr/companies/hellofresh/jobs/data-engineer-bi-m-f-x_paris,Data Engineer & BI (m/f/x),HelloFresh,"{durable,color,Airflow,scale,Docker,Github,SQL,Python,Tableau}",T√©l√©travail partiel possible,Paris,"Application mobile, E-commerce, FoodTech",CDI,2022-08-08,"La mission HelloFresh ? Changer notre fa√ßon de manger. Pour toujours. Leader mondial des Box √† Cuisiner, HelloFresh a distribu√© plus de 280 millions de repas en 2019 et atteint pr√®s de 3 millions de clients actifs au quatri√®me trimestre 2019. Pr√©sente dans 14 pays, la start-up berlinoise cr√©√©e il y 8 ans a d√©pass√© tous ses objectifs. Le Financial Times la place en t√™te de son classement Europe‚Äôs Fastest Growing Companies de 2017. HelloFresh compte aujourd‚Äôhui plus de 5,000 collaborateurs. Quel est leur ingr√©dient secret ? Des recettes inspirantes et savoureuses, un menu complet et vari√©, des ingr√©dients frais et de saison, le tout livr√© chez vous et pens√© pour vous faciliter la vie. Adieu courses, listes et tracas. HelloFresh challenge la supply chain de l‚Äôindustrie agroalimentaire en alliant excellence op√©rationnelle, souci du client et conduite du business au plus pr√®s des datas. En 2021, ils cherchent √† renforcer rapidement leur pr√©sence en France et d√©veloppent une √©quipe et des bureaux au c≈ìur de Paris. At HelloFresh, we want to change the way people eat forever by offering our customers high quality food and recipes for different meal occasions. Over the past 10 years, we've seen this mission spread around the world and beyond our wildest dreams. Now, we are a global food solutions group and the world's leading meal kit company, active in 17 countries across 3 continents. So, how did we do it? Our weekly boxes full of exciting recipes and fresh ingredients have blossomed into a community of customers looking for delicious, healthy and sustainable options. The HelloFresh Group now includes our core brand, HelloFresh, as well as: GreenChef, EveryPlate, Chef's Plate, Factor, and Youfoodz. Rejoins une superstar de la foodtech en France Chez HelloFresh, nous bousculons les habitudes alimentaires des fran√ßais gr√¢ce √† nos Box √† cuisiner ! Notre ambition ? R√©volutionner le quotidien de nos abonn√©s, en promouvant une fa√ßon plus durable de cuisiner et en leur faisant d√©couvrir de d√©licieuses recettes, cr√©atives et √©quilibr√©es. L‚Äôalliance parfaite entre technologie et gastronomie, pour un maximum de gourmandise. HelloFresh est pr√©sent dans plus de 17 pays en 2022. La France, un jeune march√© lanc√© en 2019, conna√Æt une ascension fulgurante : nous y sommes d√©j√† leaders depuis 2021. Le moment parfait pour rejoindre notre √©quipe et avoir un impact fort dans l'une des scales up fran√ßaises les plus prometteuses ! Comment rendre tout cela possible ? Gr√¢ce √† une √©quipe d√©bordante de talents et de dynamisme et une ambition commune de conqu√©rir le march√© de la food. Le tout associ√© √† une culture d‚Äôentreprise et un ADN uniques. Si tu souhaites prendre part √† cette incroyable aventure humaine, internationale et entrepreneuriale, rejoins-nous ! Le poste : En tant que Data Engineer & Business Intelligence (BI) dans l'√©quipe Ops Tech et Data, reportant au Senior Ops Tech Product Manager France , tu seras au coeur de la strat√©gie B.I et Tech pour les op√©rations France. Ton r√¥le sera : d'analyser des donn√©es et produire des analyses strat√©giques pour l‚Äô√©quipe Op√©rations France. de contribuer √† construire le stack tech pour les Op√©rations de HelloFresh France (outils, scripts, algorithmes, optimisation, api). Tu auras un impact direct sur notre performance et les milliers de clients qui vont compter sur toi pour recevoir leur d√©licieuse Box HelloFresh chaque semaine ! Ce que tu feras : Identifier les KPIs cl√©s de notre business et construire des dashboards pour les √©quipes Op√©rations Animer le processus de pr√©visions op√©rationnelles par la cr√©ation de rapports et tableaux de bord (estimation vs. r√©el) Adapter, d√©finir et d√©velopper nos outils tech, notamment sur la base d‚Äôoutils d√©j√† existants dans le groupe HelloFresh Coordonner les sujets Tech et BI avec les √©quipes internationales et locales HelloFresh Construire la projection long terme de notre capacit√© supply-chain, identifier les points d‚Äôam√©lioration et lancer les projets d‚Äôaugmentation de nos capacit√©s Ce qu‚Äôon recherche chez un.e candidat.e : Tu es issu.e d‚Äôune top √©cole d‚Äôing√©nieur ou commerce Tu as 2 √† 3 ans d‚Äôexp√©rience, en pr√©f√©rence dans une scale up/start up, et id√©alement dans une √©quipe tech ou data. Tu as une passion pour la programmation et tu adores construire ou r√©soudre des algorithmes Tu as une excellente ma√Ætrise de Python, Excel/ Gsheet, SQL et un fort attrait d‚Äôanalyse Tu connais (ou tu as envie d‚Äôapprendre) Docker, Airflow, Tableau, Jira et/ou Github Tu es logique et structur√©.e Tu parles couramment fran√ßais et l‚Äôanglais (√©crit et oral) Ce que nous t‚Äôoffrons ? Un environnement dynamique et international, avec une culture d'entreprise et un ADN forts De d√©licieuses r√©ductions sur nos Box HelloFresh Une √©quipe fran√ßaise bienveillante, passionn√©e, proactive et dynamique Des bureaux au coeur de Paris Avantages employ√©s (mutuelle Alan Blue, r√©duction sur le transport, Gymlib, carte SWILE, budget de training) Voil√† le d√©roul√© du process de recrutement : Nous examinons ton CV et ta lettre de motivation. Si c‚Äôest un match, nous t‚Äôinvitons √† une s√©rie d‚Äôentretiens et un case study. Nous nous engageons √† encha√Æner rapidement les entretiens, afin de t‚Äôaccueillir chez HelloFresh au plus vite ! About HelloFresh We believe that sharing a meal brings people of all identities, backgrounds, and cultures together. We are committed to celebrating all dimensions of diversity in the workplace equally and ensuring that everyone feels a sense of inclusion and belonging. We also aim to extend this commitment to the partners we work with and the communities we serve. We are constantly listening, learning, and evolving to deliver on these principles. We are proud of our collaborative culture. Our diverse employee population enables us to connect with our customers and turn their feedback into meaningful action - from developing new recipes to constantly improving our process of getting dinner to our customers‚Äô homes. Our culture attracts top talent with shared values and forms the foundation for a great place to work! At HelloFresh, we embrace diversity and inclusion. We are an equal opportunity employer and do not discriminate on the basis of an individual's race, national origin, color, gender, gender identity, gender expression, sexual orientation, religion, age, disability, marital status or any other protected characteristic under applicable law, whether actual or perceived. As part of the Company‚Äôs commitment to equal employment opportunity, we provide reasonable accommodations, up to the point of undue hardship, to candidates at any stage, including to individuals with disabilities. We want to do adapt our processes and create a safe space that welcomes everyone so please let us know how we can accommodate our process. In case you have any accessibility requirements you can share that with us in the application form. To learn more about what it's like working inside HelloFresh, follow us on Instagram and LinkedIn","HelloFresh, a global food solutions group and the world's leading meal kit company, is seeking a Data Engineer & Business Intelligence (BI) to join its team in Paris, France. The ideal candidate should have experience working in a tech or data team in a start-up or scale-up and have a passion for programming. The role will involve analyzing data and producing strategic analysis for the Operations team, building the tech stack for HelloFresh France's operations, and coordinating tech and BI with international and local teams. HelloFresh offers a dynamic and international environment, employee benefits, and opportunities for growth. The company is committed to diversity and inclusion and welcomes candidates from all backgrounds.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
433,49602,https://www.welcometothejungle.com/fr/companies/atawiz/jobs/data-engineer_paris,Data Engineer,Atawiz,"{Microsoft,NoSQL,Databricks,Scala,Spark,Azure,SQL,Hadoop,Python}",T√©l√©travail partiel possible,"6, Rue de la Victoire, Paris, 75009","Application mobile, Logiciels, SaaS / Cloud Services, Big Data",CDI,2023-02-07,"Pour la petite histoire, Atawiz a √©t√© cr√©√© en 2016, pour devenir le cabinet d‚Äôexpertise sp√©cialis√© dans le web, la data et le cloud que l‚Äôon conna√Æt aujourd‚Äôhui. Pure Player Microsoft d√®s l‚Äôorigine, nous sommes Microsoft Gold Partner dans plusieurs domaines de comp√©tences et partenaire Databricks. Les domaines d‚Äôexpertise d‚ÄôAtawiz s‚Äôadaptent aux nouveaux enjeux des entreprises Au-del√† d‚Äôun groupe d‚Äôexperts, nous sommes des passionn√©s qui collaborent ensemble dans diff√©rents domaines d‚Äôexpertises r√©pondant √† des enjeux majeurs pour nos diff√©rents clients : Le Cloud, sp√©cialement Azure Le DevOps Le Big Data Le d√©veloppement d‚Äôapplication mobile et web Les architectures micro-services Aliment√© par une forte culture d‚Äôentreprise, chaque salari√© est l‚Äôacteur d‚Äôun environnement de travail qui se veut convivial et respectueux des valeurs de tous. Entre esprit de challenge, bon sens, pragmatisme et communication, Atawiz a su regrouper en son sein des personnalit√©s aussi diff√©rentes qu‚Äôexpertes dans leurs domaines. Votre r√¥le au sein d‚ÄôATAWIZ Int√©gr√©(e) √† nos √©quipes agiles, vous participez √† la mise en place de plateformes data selon les meilleures pratiques. En qualit√© de Sp√©cialiste, vous int√©grez la squad Data sur de vastes projets de strat√©gie de donn√©es. Vous √©voluez dans un environnement Cloud principalement Microsoft Azure mais √©galement dans un environnement Big Data (Databricks, Spark, Ecosyst√®me Hadoop) Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d‚Äôacquisition et d‚Äôint√©gration de donn√©es Vous participez √† la d√©finition de l‚Äôarchitecture permettant de r√©pondre aux use cases business Vous participez au design de la solution et √† la construction d‚Äôun datalake / lakehouse Vous impl√©mentez des r√©f√©rentiels de donn√©es dans des environnements distribu√©s sur le cloud. Vous construisez des pipelines de donn√©es pour l‚Äôingestion, le nettoyage et la transformation de la donn√©e afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d‚Äôanalyse avanc√©e. Vous mettez √† disposition la donn√©e pour l‚Äôanalyse et la dataviz Vous participez √† la mise en place de la gouvernance des donn√©es, notamment avec la Compliance (RGPD). Nous recherchons une personne dynamique, ambitieuse, rigoureuse et aimant le travail en √©quipe. Votre environnement technique : Python/Scala/SQL Spark Azure Data Factory Azure Databricks Azure Synape Analytics DevOps (CI/CD) Hadoop Base de donn√©es (SQL / NoSQL) La ma√Ætrise de l‚Äôanglais est un plus Vous √™tes sensible √† la qualit√© du code et √† l‚Äôoptimisation des structures de donn√©es et des algorithmes (sorting, indexation, etc.) En tant qu‚Äôing√©nieur d√©veloppeur (BAC+5) avec une exp√©rience professionnelle de 4 ans minimum dans le data engineering, nous attendons de vous une connaissance de tout ou partie des technologies pr√©cit√©es (ou √©quivalentes). Un premier √©change t√©l√©phonique avec notre Senior Talent Acquisition Specialist pour faire connaissance. Un entretien teams avec l‚Äôun de nos experts techniques pour vous challenger techniquement. Pour finir un entretien avec le CEO pour d√©couvrir nos projets futurs.","Atawiz, a web, data, and cloud specialist company, is looking for a dynamic, ambitious, and collaborative data engineer to join their Agile team. The ideal candidate should have at least 4 years of experience in data engineering and expertise in technologies such as Azure, Databricks, Spark, Hadoop, SQL/NoSQL databases, Python/Scala/SQL, and DevOps. Responsibilities include implementing secure data acquisition and integration strategies, designing solution architecture, constructing datalakes, creating data pipelines, ensuring data governance compliance, and providing data analysis and visualization. Fluency in English is a plus.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 4 ans,2,1,0.04154662416233763
435,49914,https://www.welcometothejungle.com/fr/companies/antler-france/jobs/startup-founder-i-software-engineer-developer-data-scientist_paris,Startup Founder I Software Engineer/Developer/Data Scientist,Antler,{scale},T√©l√©travail partiel possible,"45, Rue des Petites √âcuries, Paris, 75010","Incubateur / Acc√©l√©rateur, Finance, Accompagnement d'entreprises",Autres,2023-02-07,"Antler is the investor backing the world‚Äôs most driven founders, from day zero to greatness. Founded on the belief that people innovating is the key to building a better future, we partner with people across six continents to launch and scale high-potential startups that address meaningful opportunities and challenges. Knowing that exceptional founders can come from anywhere with any background, we have offices in 25 cities, including New York, London, Berlin, Jakarta, Singapore, Tokyo & Sydney. APPLY HERE üëâ https://www.antler.co/location/france üëà Are you a full-stack software developer, data scientist, machine learning engineer, or DevOps engineer with excellent programming skills, strong problem-solving abilities, a leadership track record, and a passion for developing tech solutions using cutting-edge technologies? Have you spent your career building game-changing software/hardware? Most importantly, are you looking to build a disruptive tech venture in the vibrant ecosystem of Paris? If so, we would like to hear from you! Antler is a start-up generator and an early-stage VC. Our programs bring together experienced and driven professionals from diverse backgrounds to build strong founding teams to launch their own companies. We are present in 14 locations worldwide, have supported 2,000+ founders through our program, invested in 400+ startups, and received over 50,000+ applications. Antler provides an unrivaled setting for the world‚Äôs brightest minds looking to make a mark on the world to make it a better place. It‚Äôs where the top 1% of talent comes together, pursues purpose, and works on some of the greatest opportunities and problems of today. Whether you have built your own company before or are looking to found a company for the first time, tomorrow‚Äôs disruptive tech could be built by you. Details of the program: The program runs for an initial 10 weeks, full-time in Paris (France) and starting on the 17th of April 2023. In the first phase (10 weeks), you are required to ideate and find your co-founder(s) from the cohort of 50-70 founders. After two months you will present your team and business idea to the Antler Investment Committee. If accepted, you will receive a pre-seed investment of ‚Ç¨150k for 10% equity with ‚Ç¨40k program fees. If you get an investment, you will continue to be part of the program for another 3 months throughout which Antler will work closely with you to accelerate your growth. At the end of this period, Antler arranges a demo day where we invite VCs, institutional investors, and local angel investors to help you connect with investors and raise your seed round. Who are we looking for? Startup founders, serial entrepreneurs, and strong business leaders that love building new products and teams CTO‚Äôs, engineering leaders, tech leads, developers, software architects, growth hackers, product managers, designers, and anyone who has built and scaled products from scratch Experts in their field Excellent communicators People who are always on top of the latest tech trends and have a genuine passion to build next-generation products Driven and hungry individuals that want to build a successful company Life at Antler: Our ten-week, full-time program is designed to give you the best possible start for your entrepreneurial journey. Whether you have founded a company before or are just getting started, we will help you find a co-founding team among the 50-70 people that will be joining the program. Founders that join our programs come from a variety of backgrounds and have an assortment of skills and expertise. Our program will facilitate you and your co-founder to quickly build on an idea (either you come with an idea or you will be defining it with your team). If you enjoy a fast-paced, diverse, demanding, and incredibly engaging environment, join us! Benefits Potential investment at the pre-seed stage Help finding your co-founder(s) Personalized coaching sessions with business experts Shared office space at a premium co-working space with access to various amenities Access to a global network of start-up advisors and experts in their field Who are we looking for? Startup founders, serial entrepreneurs, and strong business leaders that love building new products and teams CTO‚Äôs, engineering leaders, tech leads, developers, software architects, growth hackers, product managers, designers, and anyone who has built and scaled products from scratch Experts in their field Excellent communicators People who are always on top of the latest tech trends and have a genuine passion to build next-generation products Driven and hungry individuals that want to build a successful company","Antler is seeking full-stack software developers, data scientists, machine learning engineers, or DevOps engineers with strong programming skills and leadership abilities to join their accelerator program in Paris. The program runs for 10 weeks, during which participants will ideate and find co-founders, build their businesses, and present to the Antler Investment Committee. Accepted teams receive a pre-seed investment of ‚Ç¨150k for 10% equity with ‚Ç¨40k program fees. Ideal applicants are startup founders or entrepreneurs, excellent communicators, and experts in their field with a passion for building next-generation products.",Bac +5 / Master,< 15 salari√©s,> 5 ans,2,1,0.04154662416233763
437,49709,https://www.welcometothejungle.com/fr/companies/prismic/jobs/analytics-engineer_paris_PRISM_K5ZjOke,Analytics Engineer,Prismic,"{Amplitude,Athena,AWS,dbt,Lambda,snowflake,SQL,Python}",T√©l√©travail total possible,"9 Rue de la Pierre Lev√©e, Paris, 75011","Logiciels, SaaS / Cloud Services",CDI,2023-02-07,"Hello. We are Prismic, a headless CMS with an API. We aim to simplify editing content on your website and make work enjoyable for developers, marketers, and content teams. We‚Äôve built in the past four years one of the leaders in the Headless CMS market. It means that more than 10000 teams around the world store the content of their websites in Prismic. We made our mission to deliver their content in a stable and reliable way. To give you an idea, we are now serving content for dozens of thousands of Websites through our APIs and serving more than 20B of API calls every month. We managed to grow thanks to our background in architecture, our talented team, and our love for well-mastered technologies. Understanding deeply what‚Äôs happening in our system is at the core of our engineering process and we want to guarantee that this will stay true while growing our team. Because yes, we‚Äôll grow a lot and that‚Äôs where you come into play. Prismic is a rapidly growing website builder and platform. We use data to determine the direction of the business and need help from a creative and flexible analytics engineer (you will be our first analytics engineer and will report to our head of Engineering). You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth. Prismic has already built a Customer Data Platform (using segment.com ), and we're ready to expand and move to a full fledged data warehouse architecture (including dbt, snowflake and more). You will collaborate with our platform team to build data pipelines and warehouse architecture, to process data and to build and deploy infrastructure that supports all of our data needs. We have a strong desire to gravitate our architecture toward the state of the art, and will rely on you to help us get there. What will you be doing?üîß Your insights will help us improve our technical stack and also combine effectively with Usability Research. Your business savviness will be fueled by automated data models and confirmed through dashboard communications to keep us all aware of the status of our data and avoiding compromises in data quality. Growth will be based on pinpointing with confidence our challenges and opportunities: ‚Äì Marketing: Helping in identifying the right audience, the most effective channel to communicate our promise, and properly onboard our prospect into our product. Evaluate the impact of marketing initiatives on conversion and word of mouth. ‚Äì Revenue: help lead growth hypotheses and sales decisions by detecting decision makers, and communicate macro trends and patterns to drive total customer success ‚Äì Product: helping our outcome-oriented product team to set their goals, evaluate the delivered value, improve user satisfaction, reduce churn, improve usage and upsell. You are motivated to use your creativity to enable us to make strategic decisions and you will challenge us in the ways we need to grow, with a say in our prioritisation, helping us to ensure Acquisition, Revenue and Product attend to all of the opportunities on the table. You are central to our future growth. You‚Äôre a master communicator who wants broad technical and business exposure. You‚Äôll help to enable our business teams, our most important stakeholders, to understand and satisfy their own needs through analytics. In turn, this will help support our customers and their growing set of needs, and thus help us to grow and run our business. Your fresh ideas will be warmly welcomed. Are you the one? üß† ‚Äì 3+ years of experience as a data analyst, analytics engineer or data engineer, mastery of data libraries ‚Äì Coding (Python; SQL) ‚Äì Customer data (dbt) ‚Äì Leadership (rapid and autonomous assumption of new topics or tools among many teams in a new frontier) ‚Äì Communication (understanding and reflection of business initiatives, including transforming needs into insights) ‚Äì Data visualisation (analysis, synthesis, critical thinking, presentation, storytelling) It would be super cool (but not required) if you had experience with SaaS solutions like Segment, Amplitude, Hubspot, Google Tag Manager, and also AWS Services like Athena, Step Functions or even Lambda. If you have a tester‚Äôs mindset, all the better. A dream candidate would be a strong contributor and have all of these. What are the perks? üéâ ‚Äì Latest Macbook; ‚Äì A budget for you to equip your home-office setup; ‚Äì English classes for all levels; ‚Äì Solving challenging problems, while building cutting-edge technology; ‚Äì Working in a super culturally-diverse team, with fun and curious folks. (also other benefits, that may depend on the country you‚Äôre based in) When you come to the office, indulge! ‚Äì Healthy snacks and drinks; ‚Äì Yoga classes 3x/week. Afraid of missing out if you‚Äôre remote? üåç Worry not! You get the chance to visit us every once in a while and spend some days at the office, in Paris; We have virtual initiatives and events, for us to stay connected with each other and be able to have the precious water-cooler conversation. We also have regular global meetings, where every team member is free to raise their hand and discuss any topic with the whole company - we do our best to nurture a relaxed and informal atmosphere, where you can have the conditions to feel supported, thrive at your job and keep learning. So, no matter where you are, it‚Äôs important for us to make you a part of that culture.","Prismic, a leading headless CMS with an API, is seeking an analytics engineer to join its team. The successful candidate will be responsible for building data pipelines and warehouse architecture, processing data, and deploying infrastructure to meet the company's data needs. They will use their creativity to help the company make strategic decisions, challenge the team in growth, report to the head of Engineering, and have a strong background in data analytics, data engineering, and data visualisation. Prismic is offering a range of perks, including a budget for home-office setup, English classes, yoga classes, and healthy snacks and drinks.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 3 ans,3,0,0.04154662416233763
454,57128,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-science-engineering-manager-f-h_massy_CARRE_l3lyyWV,Data science Engineering manager,Carrefour,"{durable,Kubernetes,Airflow,R,Spark,BigQuery,SQL,Python,Tableau}",T√©l√©travail partiel possible,"93 Avenue de Paris , Massy, 91300","Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux d√©fis de notre √©poque, Carrefour a pour ambition de rendre le meilleur accessible √† tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos √©quipes. Nous nous √©panouissons en √©quipe : M√©tiers du commerce, m√©tiers d'expertise, entrepreneurs unissent leurs comp√©tences et leurs efforts pour construire ensemble une cha√Æne de valeur au service des consommateurs. Au plus pr√®s de nos clients ou en coulisses, chacun a un r√¥le √† jouer mais peut compter sur les autres pour r√©ussir. Nous veillons √† ce que chacun puisse aller loin : L'envie et le m√©rite sont les seuls pr√©-requis pour nous rejoindre, acc√©der √† une formation, changer de m√©tier, √™tre promu ou cr√©er son entreprise. Nous partageons la victoire : nos collaborateurs sont engag√©s et nous nous engageons en retour. En offrant des r√©mun√©rations et des avantages parmi les meilleurs de notre secteur, en permettant √† chacun d'√™tre associ√© aux r√©sultats, en veillant √† la sant√© de tous. Cr√©ateur de l'hypermarch√© et pionnier de la consommation de masse, Carrefour reste fid√®le √† ses racines mais se r√©invente pour permettre √† chacun, chaque jour, de manger mieux : plus sain, plus local, plus responsable. Nos atouts pour y parvenir ? Un r√©seau multiformat de + 5 300 magasins, la cr√©ation de services et d'une offre digitale de r√©f√©rence, une coop√©ration renforc√©e avec les acteurs du monde agricole, de la cha√Æne alimentaire, de la Tech... En pleine transformation, la DATA France se renforce et recherche un(e) : Data science Engineering manager F/H BON A SAVOIR: CDI/ ASAP/ CADRE/MASSY L'utilisation de la data et le d√©veloppement des capacit√©s analytiques sont un axe majeur du plan strat√©gique du Groupe Carrefour √† horizon 2027. Directement rattach√©e au COMEX France, l'Analytics Factory de Carrefour France est le pilier de cette transformation analytique, au service des clients et de l'ensemble des √©quipes m√©tier de Carrefour France - Marketing, Marchandises, Exploitation, E-commerce, Supply Chain, Services Financiers, etc‚Ä¶ √Ä propos du poste Au sein du p√¥le de data science de l'Analytics Factory, vous m√®nerez une √©quipe rassemblant data scientists et data engineers sur des projets de science des donn√©es, au service de la d√©finition de l'offre. L'objectif de cette √©quipe est de construire les solutions automatis√©s, fond√©es sur les donn√©es, pour choisir quels produits vendre, dans quel magasin, √† quel prix, en ad√©quation avec les objectifs strat√©giques de Carrefour. Ces solutions reposent notamment sur des algorithmes de machine learning et operation research. Vos missions seront de : suivre, conseiller, guider, former les diff√©rents ing√©nieurs de l'√©quipe planifier et organiser l'ex√©cution de projets techniques complexes en collaborant activement avec les product owners, les √©quipes m√©tiers et les autres √©quipes techniques de Carrefour recruter pour assurer l'ad√©quation des effectifs de l'√©quipe aux besoins actuels et futurs √™tre garant des m√©thodologies de science des donn√©es et de d√©veloppement logiciel agile de l'√©quipe contribuer √† la conception d'architectures de services s√©curis√©es, fiables, facilitant la maintenance √©volutive Vous √©voluerez dans un environnement agile et collaboratif. Vous pourrez √©galement participer aux √©changes r√©guliers de notre communaut√© d'une trentaine d'ing√©nieurs (data scientists, engineers, devops) : retour d'exp√©rience, d√©bats sur les probl√©matiques ML, de d√©veloppement logiciel, ... En tant que Engineering Manager , vous rapporterez √† l' Engineering Director du d√©partement. √Ä propos de vous Dipl√¥m√© en informatique ou math√©matique appliqu√©e, au moins au niveau master, ou justifiant d'une exp√©rience professionnelle √©quivalente, vous disposez de tr√®s solides connaissances sur les algorithmes d'apprentissage statistique. √Ä l'issue d'au moins 5 ann√©es d'exp√©rience professionnelle, vous avez d√©velopp√© une solide expertise et un recul sur chaque √©tape du cycle de vie d'un projet de data science et la manipulation de base de donn√©es √† grande √©chelle. Vous √™tes d√©sormais capable d'aborder n'importe quel champ de la data science, et √©galement de conseiller et guider des data scientists et data engineers juniors sur ces projets. Vous avez √©galement particip√© √† l'industrialisation de solutions fond√©es sur du machine learning, id√©alement dans un contexte cloud, et ma√Ætrisez les bonnes pratiques architecturales. Vous avez d√©j√† manag√© des profils techniques, avec diff√©rents niveaux d'exp√©rience, et vous souhaitez continuer de vous sp√©cialiser sur ce r√¥le d'encadrement. Vous √™tes motiv√©s par les probl√©matiques op√©rationnelles tr√®s concr√®tes, que l'on peut notamment rencontrer dans l'univers de la grande distribution. Pour cela, vous aimez interagir avec des professionnels, d'horizons diff√©rents. Gr√¢ce √† d'excellentes qualit√©s relationnelles et de communication, vous √™tes en mesure de communiquer vos id√©es complexes √† diff√©rents publics non-techniques.. Vous avez pris part √† des projets de d√©veloppement collaboratifs, et la qualit√© et la simplicit√© du code vous tiennent √† c≈ìur. Vous ma√Ætrisez le fran√ßais et √™tes en mesure de mener des discussions avec les op√©rationnels de Carrefour France. Vous ma√Ætrisez un anglais technique a minima. Environnement technique Python, BigQuery, Spark, Kubernetes, Terraform, Airflow Informations compl√©mentaires Si√®ge mondial du groupe Carrefour, Massy Possibilit√© de t√©l√©travail plusieurs fois par semaine. Avantage 10% Carte Pass pour le collaborateur et PEE (plan √©pargne entreprise) R√©mun√©ration sur 13,5 mois Chez Carrefour, nous avons √† c≈ìur de ne passer √† c√¥t√© d'aucun talent et sommes fiers de compter des √©quipes repr√©sentatives de la soci√©t√© dans son ensemble. Nous encourageons ainsi tous types de profils √† postuler √† cette offre et garantissons un processus de recrutement d√©nu√© de toutes formes de discriminations. Vos comp√©tences : Compr√©hension du business et go√ªt du commerce ; la connaissance du retail, en particulier alimentaire, est un plus Excellentes capacit√©s analytiques et statistiques, capacit√© √† comprendre les principes de mod√®les data science Tr√®s bonnes capacit√©s dans la manipulation de grandes volum√©tries de donn√©es ; ma√Ætrise d'un langage de requ√™tage des donn√©es (SQL , Big Query), d'outils de datavisualisation (Tableau, Google Data Studio) ; la ma√Ætrise de Python / R est un plus Bon relationnel et capacit√©s de synth√®se √©crite et orale.","Carrefour is seeking a Data Science Engineering Manager with a strong background in statistical learning algorithms and machine learning industrialisation. The successful applicant will lead a team of data scientists and data engineers in producing automated data-based solutions to contribute to the definition of Carrefour's products, in accordance with the firm's strategic goals. The ideal candidate should have at least five years of paid work experience, excellent analytical and statistical abilities and good knowledge of big data handling. Excellent communication and business comprehension skills are a must.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
469,56895,https://www.welcometothejungle.com/fr/companies/aqemia/jobs/data-engineer_paris_AQEMI_qRy8e1y,Data engineer,Aqemia,"{python,regard,color,Kubernetes,AWS,scale,K8s,instrumental,SQL}",T√©l√©travail partiel possible,"1, Boulevard Pasteur, Paris, 75015","Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, Sant√©",CDI,2023-03-26,"Aqemia is a next-gen pharmatech company generating one of the world‚Äôs fastest-growing drug discovery pipeline. Their mission is to design fast innovative drug candidates for dozens of critical diseases. What sets them apart is their unique quantum and statistical mechanics algorithms fueling a generative AI to design novel drug candidates. The disruptive speed and accuracy of their technology platform allows them to scale drug discovery projects as technology projects. At Aqemia you will work in a multi-disciplinary team of passionate drug hunters, AI engineers and developers who are committed to our mission of finding many drugs, at high pace, to cure diseases. As part of our growing team, you will enjoy a fast-paced, challenging, science-driven and creative environment, working at the very forefront of AI & Deep physics-powered drug discovery. This is a tremendous opportunity to bring your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team. We are looking for highly skilled and collaborative individuals who are naturally curious, have a passion for learning and solving complex problems with a ‚Äúcan-do‚Äù mindset. If this sounds exciting to you, come and join us! The difference you‚Äôll make As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia's engineering teams. You will also support engineering Teams to build their Data pipeline and assets. This way, you will be instrumental in all engineering teams' success. What you'll do Contribute in defining the relevant Data Architecture and stack for Aqemia Contribute to build the relevant Data infrastructure for Aqemia in AWS In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets Support engineering team in designing their Data pipelines and assets Bring the Data Engineering expertise in engineering projects from design to delivery Your profile 2+ years experience as a Data or Software engineer in an engineering team of 4+ engineers Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus) Good knowledge of Data Engineering building blocks (storage, orchestrator) Fluent in object-oriented language development (ideally python) Experience in delivering technical projects from start to finish Preferred skills Proficient in SQL Experience in backend engineering Experience in infrastructure-as-code techniques (ideally Terraform) Knowledge in ML Ops and DevOps Knowledge of Kubernetes, K8s administration You know how to interact with technical stakeholders Who you are You are eager to play an active role in contributing to Aqemia‚Äôs strategy to develop drugs for patients. You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds. You are keen to solve tough problems on issues that truly matter. You are inquisitive, and proactive with a can-do attitude. You are excited to join a small team and make your mark on drug discovery. You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track. Our Workplace Environment - Fast-paced, intellectually and scientifically demanding, results-driven. - Our Founders boast : 10+ years experience in research at Ecole Normale Sup√©rieure in Paris, not to mention a stint in Oxford and Cambridge / 10+ years experience in strategy consulting at BCG. - Aqemia has a rapidly growing team of +40 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale Sup√©rieure, Ecole Polytechnique, BCG) - Our premises are conveniently located in center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work. - Working language: English We are growing fast, if you feel that you don't fit this job description but you‚Äôre still excited to join, then please get in touch! ‚Äç Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law.","Aqemia, a next-gen pharmatech company, is looking for a data engineer with AWS and data engineering building blocks knowledge to build a modern, reliable, and scalable data platform for engineering teams. The ideal candidate should have experience in delivering technical projects from start to finish, experience in backend engineering, knowledge of infrastructure-as-code techniques, and the ability to interact with technical stakeholders. Aqemia offers a challenging, science-driven and creative environment, working at the forefront of AI and deep physics-powered drug discovery in a fast-paced, interdisciplinary team.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
467,56548,https://www.welcometothejungle.com/fr/companies/bureau-veritas/jobs/wind-data-analyst-ila-engineer-f-h-x_la-defense,Wind Data Analyst ILA Engineer (F-H-X),Bureau Veritas,{},T√©l√©travail partiel possible,"La D√©fense, 92060","Environnement / D√©veloppement durable, Energie",CDI,2023-03-26,"D√©couvrez un projet qui vous correspond vraiment Agir et d√©velopper vos talents ? Cr√©er votre carri√®re ? Oser, proposer, inventer et transformer le monde dans lequel nous vivons ? Oui, oui et oui ? Alors, rejoignez Bureau Veritas, en tant que Wind Data Analyst ILA Engineer (F-H-X), en CDI, pour notre d√©partement √©olien en mer, dans nos bureaux de La D√©fense (92) ou de Nantes (44), avec possibilit√© de t√©l√©travail partiel. Nous sommes acteurs du quotidien et un des leaders mondiaux du testing, de l‚Äôinspection et de la certification depuis pr√®s de 200 ans. Acteurs de la transformation du monde, aux c√¥t√©s de nos clients, avec rire, passion et ambition. Nous aimons relever des d√©fis, r√©v√©ler les talents, faire bouger les lignes et √©largir les horizons. Notre culture ? La confiance ! Exprimez vos talents ! Rattach√©(e) √† J√©r√¥me, Manager Op√©rationnel de l‚Äô√©quipe en charge de la certification des projets √©oliens offshore, vous participez √† l‚Äô√©valuation de conformit√© des projets √©oliens en mer. Vous : Intervenez majoritairement sur l‚Äô√©valuation des conditions de vent et le calcul des chargements dans le cadre de certification des champs d‚Äô√©oliennes offshore pos√©es ou flottantes, Contribuez de mani√®re transverse aux d√©veloppements techniques internes, groupes de travail de standardisation ou dimensionnement structurel des fondations d‚Äô√©oliennes. On continue ? Description du profil : B√¢tissons ensemble un monde de confiance ! De formation Bac +5 en M√©canique des structures/Mat√©riaux ou ing√©nierie offshore, vous poss√©dez une exp√©rience de 2 √† 3 ans acquise en ing√©nierie de structures en mer, id√©alement sur des projets √©oliens en mer. Vous : Avez une bonne connaissance de l‚Äô√©olien, du calcul des chargements et des standards utilis√©s en √©olien offshore (IEC 61400, DNV, etc), Avez une bonne maitrise d‚Äôun logiciel aero-elastique pour calcul des chargements √©olien (Bladed, DeepLines Wind, Hawc2, etc), et de l‚Äôanalyse des donn√©es des m√¢ts de mesures ou autres syst√®mes de mesure du vent sur site (LIDAR). La connaissance en sciences de la mesure, mod√©lisation m√©t√©o-oc√©anique et sciences statistiques serait un plus, ainsi que l‚Äôexp√©rience sur outil de mod√©lisation du vent et/ou de calcul de sillage et/ou du productible des parcs d‚Äô√©oliennes. Anglais courant obligatoire. Autonome, rigoureux et poss√©dant un bon relationnel, vous portez un int√©r√™t pour les √©nergies renouvelables et l‚Äô√©olien en particulier. Pourquoi nous rejoindre ? Vous b√©n√©ficiez d‚Äôun salaire fixe (‚Ç¨40 000,00-‚Ç¨50 000,00 selon profil) + ticket restaurant + int√©ressement/participation + PEG. Travailler chez Bureau Veritas, c‚Äôest oser voir grand et avoir les moyens de ses ambitions. C‚Äôest enfin conjuguer sens et performance, pour nos clients et pour la soci√©t√© dans son ensemble. Vous √™tes √† un clic de votre carri√®re ! Bureau Veritas est aussi engag√© en faveur de l‚Äô√©galit√© des chances, c‚Äôest pourquoi nous soutenons l‚Äô√©galit√© entre les femmes et les hommes et favorisons l‚Äôinsertion professionnelle, l‚Äôacc√®s et le maintien dans l‚Äôemploi des personnes en situation de handicap.","Bureau Veritas is seeking a Wind Data Analyst ILA Engineer with 2-3 years of experience in offshore engineering for certification of offshore wind projects. The candidate should have knowledge of wind, wind load calculations, and standards used in offshore wind, and must be proficient in aeroelastic software for wind load calculations and the analysis of measurement data. A master's in offshore engineering, materials or structure mechanics is required, and a background in weather-ocean modeling, statistical sciences or wind modeling would be an added advantage. A professional working proficiency in English is mandatory. The position offers a fixed salary, meal vouchers, and company benefits.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
465,56308,https://www.welcometothejungle.com/fr/companies/leroy-merlin/jobs/data-engineer-f-h_lille,DATA ENGINEER,Leroy Merlin,"{Qlikview,omni,Qlik,Looker,PowerBI,Kafka,Merlin,GCS,Linux,BigQuery,SQL,Github,Python}",T√©l√©travail partiel possible,"rue de chanzy, Lille, 59000","Grande distribution, E-commerce",CDI,2023-03-26,"Notre mission chez Leroy Merlin ? Construire avec tous les nouvelles fa√ßons d‚Äôhabiter, pour mieux vivre demain. Pour poursuivre cette grande ambition, nous nous appuyons sur la force du groupe international dont on fait partie : le groupe Adeo. Mais ce qui fait notre originalit√©, c‚Äôest de r√©ussir √† garder une culture d‚Äôentreprise √† taille humaine, en √©tant une (tr√®s) grosse bo√Æte. Chez nous, vous exp√©rimentez des relations tr√®s simples, on vous fait confiance, et chacun participe ‚Äì vraiment- √† l‚Äô√©criture de la strat√©gie d‚Äôentreprise. Oser et avancer, c‚Äôest notre √©tat d‚Äôesprit au quotidien : des milliers de projets sont men√©s simultan√©ment par nos √©quipes. Leroy Merlin est une entreprise en pleine croissance (et √ßa dure depuis pr√®s de 100 ans üòÉ). Et comme nous sommes leader sur le march√© de l‚Äôam√©lioration de l‚Äôhabitat et qu‚Äôon entend bien le rester, on fait tout pour garder un temps d‚Äôavance. Chez Leroy Merlin, nous sommes convaincus que travailler sur des projets passionnants est la cl√© d'un parcours professionnel r√©ussi ! Vous √™tes un.e passionn√©.e de la donn√©e, et de la conception de solutions avanc√©es ? Nous avons peut-√™tre le poste qu‚Äôil vous faut ! Organis√©e en p√¥les de comp√©tences techniques DATA (ing√©nierie, analyse et science), notre direction DATA Leroy Merlin France compte aujourd'hui plus de 100 talents. Nous recrutons un.e Ing√©nieur.e Data pour rejoindre le p√¥le Data Engineering, constitu√© d‚Äôune 40√®ne de personnes. En tant que Data Engineer, vous serez charg√©.e de concevoir, de d√©velopper et de maintenir les infrastructures de traitement de donn√©es. Vous travaillerez au sein de l‚Äôune de nos 8 squads, qui adressent les enjeux de l'omni-commerce, la performance, les ressources humaines, le RSE, la supply et l'offre. En √©troite collaboration avec les Data Scientists, Data Analysts et les autres membres de l'√©quipe pour trouver des solutions innovantes √† des probl√®mes de donn√©es complexes. Vous serez √©galement impliqu√©(e) dans la conception et le d√©veloppement de nouvelles fonctionnalit√©s et de nouveaux produits. ‚ö° Votre futur m√©tier : En collaboration forte avec nos diff√©rents m√©tiers, l‚Äô√©quipe Data Engineering est charg√©e de proposer des solutions adapt√©es aux besoins clients, et de d√©livrer des produits de mani√®re agile. Comment ? En mettant l'accent sur le d√©veloppement de nos solutions data. Vous serez par exemple amen√©.e √† travailler sur : La mise en ≈ìuvre de pipelines de donn√©es pour la diffusion de statistiques, permettant le pilotage et la prise de d√©cision, La mod√©lisation de notre patrimoine de donn√©es afin d'en faciliter son acc√®s et ses usages, La projection de la croissance de l'activit√© de Leroy Merlin France, et de ses impacts sur les activit√©s de la Supply Chain, Le suivi et pilotage des activit√©s dans les centres d'appels, L'am√©lioration de notre parcours client et de sa relation avec la marque Leroy Merlin. Le Data Engineer est √©galement responsable de : L'analyse des besoins des m√©tiers et la proposition de solutions innovantes, La d√©finition, le d√©ploiement et l'industrialisation des flux de donn√©es au sein de son p√©rim√®tre, La qualit√© et l'efficience des d√©veloppements de son √©quipe et le maintien des solutions existantes (RUN), La mise en place de rituels agiles au sein de son √©quipe, et la veille technologique, Contribuer √† la construction de la plateforme data et des services, L'accompagnement et l'acculturation des m√©tiers sur les bonnes pratiques de l'exploitation de la data. ‚≠ê Votre profil : Vous avez une premi√®re exp√©rience significative dans la data engineering (minimum 5 ans), Vous ma√Ætrisez le langage SQL, les ETL, et les ELT, Vous aimez automatiser, mettre en place vos data pipelines et en ma√Ætriser les technologies : CI/CD, Terraform, Github, Python, Kafka, Vous poss√©dez des comp√©tences en data visualisation, id√©alement sur Business Objects, Qlikview, Qlik Sense, PowerBI ou Data Studio, Vous √™tes sensible √† l‚Äôapproche Data-Driven des produits, Vous connaissez Google Cloud Platform (GCS, BigQuery), Vous √™tes √† l‚Äôaise sous Linux et ma√Ætrisez les commandes avanc√©es. ‚ú® Comment r√©ussir sur ce poste : En ayant un fort esprit d‚Äô√©quipe, et la culture du partage : vous aimez collaborer avec les √©quipes op√©rationnelles, et vous int√©resser √† leurs sujets et probl√©matiques, En √©tant autonome, curieux et proactif : vous aimez innover, proposer des initiatives et tester de nouvelles choses ! En affirmant votre esprit de synth√®se et d‚Äôanalyse, En mettant l‚Äôaccent sur votre p√©dagogie : vous savez vulgariser des notions techniques en les connectant aux besoins m√©tiers. ‚õî Ce qui ne fonctionne pas sur ce poste : Penser qu‚Äôam√©liorer en continue des solutions est inutile, et ne pas vouloir s‚Äôinscrire dans une d√©marche Agile, Ne pas savoir s‚Äôadapter √† un environnement complexe et changeant, Manquer de communication et d‚Äôouverture aux autres, ne pas aimer partager. ‚úã Ce que vous retirerez de ce m√©tier ? Le plaisir de pouvoir innover et d‚Äôessayer beaucoup choses, dans un environnement technologique riche : Google Cloud Platform, BigQuery, Github, Looker, PowerBI, Un accompagnement et une √©volution continues dans votre domaine d‚Äôexpertise et sur votre projet professionnel Et aussi, parce que nous sommes Leroy Merlin : une qualit√© de vie au travail, dans une √©quipe soud√©e et fi√®re de travailler ensemble ! ‚è≥ Et si on regarde plus loin ? Selon vos attentes, la r√©ussite √† ce poste vous permettra de continuer sur un poste de MLOPS Engineer ou Data Product Leader. üì£ Quelles √©tapes lors du process de recrutement ? Un premier √©change de 30min avec notre Talent Recruiter, Une rencontre d‚Äô1h avec le Manager Op√©rationnel du poste, Un entretien technique, men√© par l‚Äôun de nos Data Engineer (1h), Un entretien RH avec questionnaire de personnalit√© (Predictive Index), d√©brief√© par le Talent Recruiter (1h). Conditions du poste CDI √† temps plein. 2 jours de T√©l√©travail / Semaine Localisation : Lezennes (59) Postulez : l'aventure Leroy Merlin commence maintenant !","Leroy Merlin, a leading home improvement company, is looking for an experienced Data Engineer to join its Data Engineering team. The successful candidate will be responsible for designing, developing, and maintaining data processing infrastructures, working closely with Data Scientists, Data Analysts, and other team members to find innovative solutions to complex data problems. The ideal candidate should have at least five years of experience in data engineering and be proficient in SQL, ETL, ELT, and automation. Additionally, they should possess knowledge of data visualization and Google Cloud Platform. The position offers a chance to work with a diverse range of projects and technologies, with opportunities for professional growth and development.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
461,56362,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer_paris_CONTE_KlRVNqe,Data Engineer,Contentsquare,"{regard,Go,color,Scala,Akka,Contentsquare,Kafka,scale,Elasticsearch,Spark,R,ClickHouse,Java}",T√©l√©travail partiel possible,"7, Rue de Madrid, Paris, 75008","SaaS / Cloud Services, E-commerce",CDI,2023-03-26,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team ‚Äì known as the CSquad ‚Äì representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of hard-working and dedicated developers, crafting and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at Contentsquare ! We collect several billion events per day and query hundreds of terabytes in real time. Your daily work will consist of: Crafting efficient architectures to store and analyze petabytes of data Leading large-scale projects and mentoring developers Implementing sophisticated acquisition workflows Thinking of inventive data formats to serve the functionalities of the product, while minimizing the cost Developing tools to help data-scientists ....by using some open-source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum of 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have curiosity about functional programming and seek to develop your skills in Data engineering programming languages. Ideally, you have experience with a wide range of databases and are interested in streaming. You would like to challenge yourself, developing distributed infrastructure with a real-time and data-intensive environment. You would like to share your skills and take part in technical choices. Why you should join our R&D department? Here is our R&D Manifesto We write our own story. We think for ourselves, keeping an open mind and engaging in constructive criticism. We are transparent in what we do and why we do it. We build and leverage tech expertise to answer business challenges. Learning from all experiences, we deliver continuous improvements in production. We empower all team members to have an end-to-end impact, take initiative, and bring new ideas to life. We stand together and thrive together; team spirit and solidarity matter even more than strong expertise. We live a human adventure. Why you should join Contentsquare: ‚ñ™Ô∏è We‚Äôre humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ‚ñ™Ô∏è We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ‚ñ™Ô∏è We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ‚ñ™Ô∏è Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ‚ñ™Ô∏è Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ‚ñ™Ô∏è Work flexibility: hybrid and remote work policies. ‚ñ™Ô∏è Generous paid time-off policy (every location is different). ‚ñ™Ô∏è Immediate eligibility for birthing and non-birthing parental leave. ‚ñ™Ô∏è Wellbeing allowance. ‚ñ™Ô∏è Home Office Allowance. ‚ñ™Ô∏è A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ‚ñ™Ô∏è Every full-time employee receives stock options, allowing them to share in the company‚Äôs success. ‚ñ™Ô∏è We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don‚Äôt meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is hiring a Data Engineer to join their global and distributed team. The Data Engineer will be responsible for crafting and developing a new data architecture, leading large-scale projects, and mentoring developers. The ideal candidate should possess 2-3 years of experience with a proficiency in Scala, Java, or Go, and have an interest in functional programming and data engineering programming languages. The company offers a range of benefits, including remote work policies, wellbeing allowances, home office allowances, and the opportunity for every full-time employee to receive stock options. Contentsquare is an equal opportunity employer.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
460,57006,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/ingenieur-e-data-experimente-e-cdi,Ing√©nieur¬∑e Data Exp√©riment√©¬∑e - CDI - Caen ou Paris,SoyHuCe,"{PostgreSQL,Snowflake,Azure,Docker,Dataiku,Shell,Gitlab,Kafka,GCS,Git,NoSQL,PyTorch,Kubernetes,AWS,RabbitMQ,Java,SQL,Github,regard,Minio,Tensorflow,Scala,Pandas,S3,MXNet,via,R,Spark,BigQuery,GCP,Python,Tableau}",T√©l√©travail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Transformation",CDI,2023-03-26,"Tech Lab sp√©cialis√© en algorithmes et en IA, SOYHUCE accompagne ses clients en proposant une offre ad√©quate et compl√®te avec ses √©quipes Parisienne et Caennaise. La d√©marche de SOYHUCE se d√©cline en 3 expertises : Une usine digitale ; Un laboratoire R&D en algorithmie & IA ; La data factory SOYHUCE se positionne sur le march√© du digital et de la Data comme un ¬´ valorisateur de donn√©es ¬ª. Elle se repose sur des logiciels et des algorithmes personnalisables, centr√©s sur les m√©tiers, et sur sa capacit√© √† faire ressortir les besoins au-del√† de ceux exprim√©s au travers d‚Äôune approche analytique fine. Cr√©√©e en 2013, SOYHUCE souhaite apporter un nouveau regard dans les innovations. Tout en pla√ßant l‚Äôhumain au c≈ìur des entreprises, nos solutions sont adapt√©es aux enjeux √©conomiques, sociales et soci√©tales d‚Äôaujourd‚Äôhui. Leurs produits : OctoData : La plateforme d‚Äôorchestration de technologies Big Data, pr√™te √† l‚Äôemploi et d√©di√©e au traitement et √† la valorisation de vos donn√©es massives. iStoryPath : La webapp de g√©n√©ration de parcours touristiques et √©v√©nementiels personnalis√©s. AlgoRH : L‚Äôoutil de gestion de planning intelligent √† destination des Centres de Relation Clients. Vous travaillerez conjointement avec les Data Scientists, Data Ing√©nieurs et le Data Architect d√©j√† en poste et vous serez impliqu√©.e dans la prise de d√©cisions li√©e √† notre solution Big Data et √† son √©volution. Vous participerez √©galement √† la construction d‚Äôun p√¥le Data au sein de l‚Äôentreprise. Vos missions au quotidien : Contribuer au d√©veloppement de notre offre Big Data, Comprendre, analyser et proposer des solutions techniques r√©pondant aux besoins des Plateformes digitales et des projets des BUs, D√©finir l‚Äôarchitecture logiciel en collaboration avec vos pairs Travailler la donn√©e sous toutes ses formes (stockage, √©laboration de mod√®les, structuration, nettoyage), R√©diger de la documentation technique, Partager votre savoir-faire entre les diff√©rents membres de l‚Äô√©quipe, Concevoir et d√©velopper des connecteurs entre les sources de donn√©es (internes et/ou externes) et la plateforme, Concevoir et d√©velopper des pipelines de traitements de donn√©es (batch et/ou temps r√©el) dans un environnement Big Data, Assurer une veille technologique. Comp√©tences attendues : Exp√©rience en d√©veloppement : Python, Java, Scala (notions) Spark, Pandas Git Connaissance en bases de donn√©es : SQL (DataWarehouse Snowflake / Big Query, Bases de donn√©es PostgreSQL) NoSQL (orient√©e documents, timeseries) Connaissance message broker RabbitMQ Kafka Comp√©tences cloud : Kubernetes, Conteneurisation Fournisseur cloud (AWS, GCP ou Azure) Infrastructure As Code (Terraform) Exp√©rience d‚Äôarchitecture et de dimensionnement d‚Äôune architecture cloud via des services manag√©s Cartographie des donn√©es Notre stack : Stockage de donn√©es: AWS S3, Google GCS, Minio ; Cloud: AWS, GCP, Azure, OVH ; Message Broker: RabbitMQ, Kafka ; Orchestrateurs: Kubernetes, Docker Compose ; Technologies Big Data : Spark ; Bases de donn√©es : PostgreSQL, Snowflake, BigQuery ; Machine learning: Tensorflow, PyTorch, MXNet, Scikit-Learn ; Recherche op√©rationnelle: Optaplanner, OrTools ; Langages: Python, Java, Scala, Shell ; Outils : Dataiku, Power BI, Tableau ; IAAS : Terraform ; Versioning : Gitlab, Github ; Dipl√¥m√©¬∑e d‚Äô√©tudes sup√©rieures dans le syst√®me d‚Äôinformation, computer sciences, big data (√©cole d‚Äôing√©nieurs, √©cole sp√©cialis√©e ou √©quivalent universitaire), vous justifiez d‚Äôau moins 5 ans en Data engineering. Vous avez une expertise reconnue sur la mise en place de pipelines complets de valorisation de donn√©es massives, de la collecte √† la mise √† disposition d‚Äôapplications en passant par le traitement. D‚Äôun naturel curieux et cr√©atif, vous aimez √©voluer dans des environnements innovants. Vous √™tes un¬∑e bon¬∑ne communiquant¬∑e et poss√©dez une vraie culture de services et de succ√®s client. Anim√©.e par votre m√©tier et proactif.ve, vous aimez apprendre en permanence. L‚Äôinnovation, l‚Äôacquisition de nouvelles technologies et le partage sont au c≈ìur de votre ADN tout comme le n√¥tre. Vous √™tes autonome, rigoureux, vous apprenez en permanence. Vous avez l‚Äôesprit d‚Äô√©quipe mais √©galement des opinions et savoirs √† faire valoir. Vous exprimez clairement vos analyses. Vous √™tes passionn√©¬∑e par votre m√©tier, aimez le faire partager, m√™me √† des personnes qui ne le connaissent pas. Un pr√©-qualification avec notre Talent Acquisition Senior Un entretien avec un R√©f√©rent Technique M√©tier Un challenge technique Un entretien avec notre CEO","Soyhuce, a tech lab specialized in algorithms and AI, is seeking a Data Engineer with at least 5 years of experience in data engineering. The ideal candidate should have expertise in implementing complete pipelines, from data collection to application development, and possess skills in Python, Java, Scala, Spark, Pandas, SQL, NoSQL, RabbitMQ, Kafka, Kubernetes, and Terraform. They should also be innovative, proactive, communicative, and have a passion for learning and sharing knowledge. The role involves contributing to the development of Soyhuce's big data offerings, architecting software, developing data connectors and pipelines, and conducting research and development work in data science.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 5 ans,2,1,0.04154662416233763
458,50445,https://www.welcometothejungle.com/fr/companies/m13h/jobs/analytics-engineer-france-europe-f-h_paris,Analytics Engineer - (France / Europe) -,M13h,"{Azure,OneTrust,Fivetran,AWS,dbt,Snowflake,Contentsquare,via,Adverity,BigQuery,GCP,SQL,Python}",T√©l√©travail partiel possible,"3 rue d'Uz√®s, Paris, 75002","Digital Marketing / Data Marketing, Strat√©gie, Big Data",CDI,2023-02-07,"A propos de M13h üëã M13h est une √©quipe de consultant¬∑e¬∑s passionn√©¬∑e¬∑s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Strat√©gique et expertises Data, Marketing & Technologies pour acc√©l√©rer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous ma√Ætrisons toute la cha√Æne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, ‚Ä¶ √† accro√Ætre leurs performances, au travers de missions vari√©es : Strat√©gie Data : d√©finir sa strat√©gie, ses cas d‚Äôusage data et le socle technologique pour la d√©ployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donn√©e pour cr√©er de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et am√©liorer les taux de conversion Privacy : s‚Äôadapter aux √©volutions technologiques et r√®glementaires tout en d√©veloppant ses performances marketing Modern Data Platforms : construire des plateformes de donn√©es sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des donn√©es pour prendre des d√©cisions √©clair√©es (dashboards, data analyse, data science, mod√©lisation avanc√©e, ‚Ä¶) M13h est membre du Groupe Labelium et met ses comp√©tences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure √† taille humaine o√π il fait bon travailler ! En plein mouvement de r√©gionalisation et d‚Äôinternationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l‚ÄôEurope (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N‚Äôh√©sitez pas √† en discuter en entretien. Description du poste üì¢ En tant qu‚Äô Analytics Engineer , tu interviens sur des probl√©matiques √† la crois√©e de la data science, de la data analyse et de la data ing√©nierie et ton r√¥le est de mettre en place pour nos clients ou nos besoins internes des datasets pertinents : bien mod√©lis√©s, document√©s, fiables en termes de qualit√© et de disponibilit√©, r√©pondant aux besoins des usages ult√©rieurs. Pour cela, tu interviens √† diff√©rents stades des projets : Analyse des besoins d‚Äôacc√®s aux donn√©es , en collaboration avec les utilisateurs business, data analysts et dataviz engineers Mise en place des flux et mod√®les de donn√©es , en se basant sur des stacks data modernes (SQL, dbt, outils ELTs, GCP/Azure/AWS/Snowflake, ‚Ä¶) Exposition des donn√©es dans les outils BI & visualisation Maintenance des pipelines et mise en place d‚Äôalertes & tests de qualit√© de donn√©es Quelques exemples de missions √† titre d‚Äôillustration : Construction d‚Äôune Customer Data Platform pour un grand retailer (8 marques / 30+ pays) Migration d‚Äôune large infrastructure de dashboards bas√©s sur un stack Supermetrics vers un stack Adverity+BigQuery Mise en place d‚Äôoutils de pilotage de bout en bout pour plusieurs startups en forte croissance Packaging d‚Äôoutils internes sur l‚Äôattribution custom Polyvalent¬∑e , tu as √† c≈ìur de comprendre les besoins de tes interlocuteurs pour les traduire en structures de donn√©es exploitables et de bonne qualit√© . En tant que Junior , tu seras encadr√© par des profils plus s√©niors te permettant de progresser rapidement dans notre environnement et sur les stacks data modernes. Profil recherch√© üë®üë© Issu¬∑e d‚Äôune grande √©cole de commerce, d‚Äôing√©nieurs ou √©quivalent , tu souhaites t‚Äôorienter vers un r√¥le √† la crois√©e des m√©tiers de la data. Tu ma√Ætrises tr√®s bien SQL et souhaites travailler sur les modern data stacks : plateformes cloud (Google Cloud, AWS, Azure, Snowflake), outils ELTs, dbt, ‚Ä¶ La ma√Ætrise de Python est un plus. Tu as de bonnes capacit√©s d‚Äôanalyse et souhaite travailler sur des projets analytique de bout en bout en faisant preuve d‚Äôautonomie et de rigueur. Pourquoi nous rejoindre ‚ùì M13h, c‚Äôest avant tout une √©quipe qui aime les challenges et porte des valeurs de bienveillance et de progr√®s collectif . Tu as d√©j√† lu √ßa ailleurs ? Contactes nos consultant¬∑e¬∑s sur LinkedIn pour v√©rifier directement :) D√©marrer chez M13h, c‚Äôest aussi une belle opportunit√© de d√©velopper tes comp√©tences conseil et ton expertise rapidement sur des missions vari√©es, au sein d‚Äôune structure √† taille humaine tout en profitant des avantages d‚Äôun groupe international. Tu es accompagn√© par un parrain ou une marraine d√®s ton arriv√©e en plus de ton manager, profites de formations, acc√®des √† de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, ‚Ä¶ Et puis M13h, c‚Äôest aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d‚Äôarriv√©e pour s‚Äô√©quiper pour le t√©l√©travail Une politique souple de t√©l√©travail Un abonnement gratuit √† des salles de sport 2 s√©minaires par an et de nombreux moments de coh√©sion d‚Äô√©quipe Des locaux au coeur de grandes villes fran√ßaises (Paris, Bordeaux, Lyon) et europ√©ennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge √† 100% et bien d‚Äôautres‚Ä¶ Comment postuler üôã Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontan√©e √† recrutement@m13h.com","M13h is seeking an Analytics Engineer to work on data science, data analysis, and data engineering projects, creating relevant, well-modeled, documented, reliable, and available datasets. The successful candidate will analyze data access requirements, develop data pipelines, and create dashboards, as well as maintain pipelines and data quality testing. The ideal candidate has a strong SQL background and desires to work with modern data stacks, including cloud platforms (Google Cloud, AWS, Azure, Snowflake) and ELT tools. They should possess excellent analytical skills and a desire to work autonomously and rigorously. M13h is a growing consulting firm that helps companies become data-driven and offers a fun, international work environment with opportunities for professional development.",Bac +5 / Master,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
456,57162,https://www.welcometothejungle.com/fr/companies/leboncoin/jobs/data-engineer-team-data-platform-f-m_paris,Data Engineer team Data Platform,leboncoin,"{DynamoDB,Glue,Elasticsearch,Docker,Hudi,Athena,Kafka,Kubernetes,AWS,Java,SQL,Jupyter,Github,Airflow,Redshift,S3,R,Spark,Unix,Python,MLFlow}",T√©l√©travail partiel possible,"85-87, rue du Faubourg Saint-Martin, 75010, Paris","√âconomie collaborative, E-commerce",CDI,2023-03-26,"Cr√©√© en 2006, leboncoin.fr est une plateforme d‚Äô√©changes d‚Äôun nouveau genre, qui simplifie l‚Äôacc√®s √† la consommation, privil√©gie la relation locale et fait du digital un outil au service de tous. En facilitant le rapport des individus √† l‚Äô√©change et √† la consommation, leboncoin a su s‚Äôimposer en quelques ann√©es comme ph√©nom√®ne de soci√©t√© fran√ßais et faire du bonheur des uns le bonheur des autres. En France, nous nous positionnons comme un acteur num√©rique, √©conomique, soci√©tal, innovant, avec toujours le m√™me objectif : faciliter tous les √©changes au quotidien de l‚Äôensemble de nos utilisateurs. Gr√¢ce √† notre plateforme de petites annonces, nous donnons une seconde vie √† des milliers de biens. L‚Äôimpact positif de ces √©changes a √©t√© √©valu√© √† 5,8 millions de tonnes de C02 √©conomis√©s sur une ann√©e. Derri√®re cette apparente simplicit√©, se trouve une entreprise en forte croissance de plus de 1500 salari√©s, o√π il fait bon travailler, une entreprise qui cultive une d√©marche RH responsable et collective. Leboncoin r√©unit √©galement les sites Agriaffaires, MachineryZone, Truckscorner, AvendreAlouer, Paycar, Locasun, Videdressing, L‚Äôargus et Pilgo Vous √™tes rattach√©.e √† l‚Äô√©quipe Data Engineering , compos√©e de data engineers et de SRE. Cette √©quipe vous accompagne sur la stack technique data, vous permet d‚Äô√©changer sur des sujets transverses et de participer aux rituels data engineering (guilde, r√©tro‚Ä¶). Cette √©quipe appartient √† la tribe ‚ÄúData Tools & Services‚Äú, qui regroupe les services data centraux La stack : D√©veloppement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm Dans un environnement √† la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi Ce que vous ferez : D√©velopper des applicatifs complexes assurant une circulation optimale des donn√©es, et assurer leur fiabilit√© : API d‚Äôexposition de donn√©es, applications de streaming, industrialisation de mod√®les de machine learning Optimiser notre architecture et notre environnement AWS : stockage, s√©curit√©, automatisation, scalabilit√© Assurer la s√©curit√© des donn√©es de nos utilisateurs sur la data platform, dans le respect de la r√©glementation en vigueur (GDPR, e-privacy) Participer activement √† la veille technologique et √† l'effort de R&D Garantir le bon fonctionnement, la disponibilit√©, l‚Äô√©volution et la performance des outils Assurer l‚Äôinterface avec les √©quipes techniques du produit Poste bas√© √† Paris 10 Les √©tapes : Premier √©change avec Simon (RH) Entretien manag√©rial avec Thomas (Engineering Manager) Entretien technique avec deux membres de l'√©quipe (Data Eng) Entretien Fit/RH avec Julien (directeur data) et Simon (RH) Vous avez au moins 5 ans en tant que Data Engineer Vous connaissez les environnements Unix, et poss√©dez un niveau avanc√© en Java / Python . Vous √™tes familier avec l'environnement cloud AWS , et avez de solides notions d‚Äôarchitecture distribu√©e et de gestion de data platform √† forte volum√©trie. Vous √™tes √† l‚Äôaise en anglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral.","Leboncoin.fr is looking for a Data Engineer with at least 5 years of experience in Java/Python, Unix and AWS. The successful candidate will develop complex applications for data optimization, ensure data security, and participate in R&D efforts. The job is based in Paris and requires fluency in English.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
452,56932,https://www.welcometothejungle.com/fr/companies/exotec/jobs/data-engineer_lille,Data Engineer,Exotec,"{Microsoft,durable,Oracle,Beam,PostgreSQL,SAP,BigQuery,SQL,DataFlow,Python}",T√©l√©travail partiel possible,Lille,"Logistique, Objets connect√©s, Robotique",CDI,2023-03-26,"Exotec met l‚Äôexcellence technologique au service de la red√©finition des relations entre humains et robots. A travers le monde, leurs solutions r√©volutionnent la fa√ßon dont leurs clients d√©livrent leurs produits aux consommateurs finaux. Ils contribuent au succ√®s des plus grandes marques du commerce et de l‚Äôindustrie, tout en am√©liorant les conditions de travail de leurs salari√©s. Par l‚Äôalliance de l‚Äôintelligence artificielle et d‚Äôun hardware performant, leurs robots sont d√©sormais d√©ploy√©s dans le monde entier et leur succ√®s a fait d‚ÄôExotec la premi√®re licorne industrielle fran√ßaise. Rejoindre Exotec, c‚Äôest l‚Äôopportunit√© de donner du sens √† vos comp√©tences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos id√©es, des r√©alit√©s. La r√©volution robotique port√©e par Exotec ne fait que commencer, vous en √™tes ? Exotec multiplie les usages de ses donn√©es et souhaite structurer ses outils et m√©thodes : collecte, stockage, transformation, exposition et partage des donn√©es. Exotec con√ßoit des syst√®mes robotis√©s permettant l'optimisation des cha√Ænes d'approvisionnement. Nous proposons une valeur ajout√©e claire : une collaboration √©l√©gante entre les travailleurs humains et les robots pour une productivit√© durable des entrep√¥ts. Pour accompagner la forte croissance de l‚Äôentreprise dans le monde entier (Japon, USA), l'√©quipe IT s‚Äô√©toffe et cr√©e de nouveaux postes en Data. En int√©grant Exotec, vous rejoignez la premi√®re licorne industrielle fran√ßaise et vous prenez part √† la forte croissance d‚Äôune √©quipe IT de 30 personnes aujourd‚Äôhui. En tant que Data Engineer : Vous participez √† la mise en ≈ìuvre des composants techniques de la plateforme de donn√©es d'Exotec Vous travaillez sur la collecte dans la plateforme de donn√©es provenant de sources multiples : Salesforce, ERP, logiciels d√©velopp√©s en interne Vous nettoyez, mettez en qualit√© et pr√©parez les donn√©es afin de les rendre disponibles pour les diff√©rents cas d'usage qui en ont besoin Vous migrez des reportings existants vers la plateforme de donn√©es et mettez en ≈ìuvre de nouveaux cas d'usage pour r√©pondre aux besoins de l'entreprise Vous travaillerez au sein de l'√©quipe data et en √©troite collaboration avec la software factory, ainsi qu‚Äôavec les utilisateurs des m√©tiers qui ont besoin de rendre intelligibles les donn√©es disponibles Requirements Dipl√¥me d'ing√©nieur ou √©quivalent Vous justifiez d'au moins 5 ans d'exp√©rience en Data Engineering ou Data Science Vous avez de bonnes capacit√©s d‚Äôanalyse, aimez r√©soudre les probl√®mes et faites preuve d‚Äôun fort esprit critique Vous avez une bonne connaissance des solutions Google BigQuery et DataFlow et avez de l'exp√©rience en programmation : Python et Apache Beam Vous √™tes form√©(e) aux bases de donn√©es de type SQL server et PostgreSQL Vous ma√Ætrisez l‚ÄôETL et avez une exp√©rience des requ√™tages sur des API REST Une certification sur les technologies Google et Microsoft serait un plus Vous avez une app√©tence √† comprendre les m√©tiers, et id√©alement une exp√©rience de travail avec des ERP de type SAP, Microsoft Dynamics ou Oracle, ou des outils tels que Salesforce ou Workday. Vous √™tes √©conomes de vos moyens et mettrez cette qualit√© en ≈ìuvre dans la recherche de solutions simples et efficaces (¬´ sans couture ¬ª) Vous vous positionnez dans une recherche d'am√©lioration et d'automatisation constante de l'existant Vous avez un bon niveau d‚Äôanglais Vos softs skills sont : Bonne aisance relationnelle, proactivit√©, force de propositions, rigueur, esprit d'analyse et de synth√®se, organisation et respect des √©ch√©ances Pourquoi nous rejoindre Parce que nous avons une forte culture d'entreprise qui favorise l'√©panouissement pro et perso Parce que nous aimons travailler dur, et aussi f√™ter nos succ√®s Parce que nous avons √©t√© √©lus champion de la croissance en 2022 et que nous sommes la 1√®re licorne industrielle fran√ßaise Parce que nous avons de nombreux avantages : prime d'int√©ressement, ticket-restaurant, mutuelle, primes mobilit√© durable, jours de cong√©s suppl√©mentaires, politique famille... Parce que nous travaillons sur des projets innovants, et surtout des produits Processus de recrutement Si votre candidature est retenue, nous vous proposons : Un premier √©change t√©l√©phonique Un entretien technique en visio avec un membre d'Exotec Un entretien final √† notre si√®ge afin de vous pr√©senter nos √©quipes et nos syst√®mes Si votre candidature n'est pas retenue, nous nous engageons √† vous communiquer un retour dans un d√©lai de 2 √† 3 semaines maximum. Chez Exotec, nous garantissons l‚Äô√©galit√© des chances dans notre processus de recrutement. L‚Äôensemble des candidatures re√ßues sont √©tudi√©es ind√©pendamment de l‚Äô√¢ge, du genre, de l‚Äôorigine, de la religion, de la couleur de peau, de la nationalit√©, du sexe, du handicap, de l‚Äôorientation sexuelle ou de toute autre distinction prot√©g√©e par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les diff√©rences. En rejoignant le Pacte Parit√©, Exotec s‚Äôengage pour un √©cosyst√®me French Tech plus paritaire.","Exotec, the first French industrial unicorn, is seeking a Data Engineer with at least 5 years of experience in Data Engineering or Data Science. The successful candidate should have a degree in engineering or equivalent, skills in programming languages such as Python and Apache Beam, and experience with Google BigQuery and DataFlow. Experience in ETL and queryings on REST APIs and SQL servers and PostgreSQL is also required. The Data Engineer will work collaboratively with the data team and software factory while collaborating closely with the business users. Exotec offers a range of benefits, including additional days off, a sustainable mobility allowance, and a family policy.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
438,50061,https://www.welcometothejungle.com/fr/companies/pwc/jobs/consultant-experimente-data-engineer-cdi-f-h_neuilly-sur-seine_PF_KWAjldY,Consultant exp√©riment√© Data Engineer | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",T√©l√©travail partiel possible,"63 Rue de villiers, Neuilly-Sur-Seine, 92200","Strat√©gie, Audit",CDI,2023-02-07,"PwC poursuit sa strat√©gie mondiale The New Equation, port√©e par l'humain, nos engagements responsables, soci√©taux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la r√©alit√© virtuelle et de technologies √©mergentes. Notre communaut√© Data et IA r√©unit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la cha√Æne de valeur, de la strat√©gie √† l'ex√©cution, afin d'accompagner nos clients sur l'ensemble de leurs m√©tiers et de leurs entit√©s, dans leur ""data transformation. Ce que vous pouvez attendre de nous En tant que Data engineer dans les √©quipes Data & IA de PwC votre mission sera de: - Contribuer √† la d√©finition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en √©troite collaboration avec les data architects - Mettre en ≈ìuvre ces solutions en mode Agile en optimisant : - La performance et le passage √† l'√©chelle - La qualit√© des donn√©es et des mod√®les au fil du temps - La coh√©rence avec les outils et les frameworks existants - La qualit√© et conformit√© (revue cyber, Cloud, auditabilit√© des traitements, RGPD) - Mise en place de CI/CD pour le d√©ploiement des solutions chez les clients Notre boite √† outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ce que nous attendons de vous Vous √™tes dipl√¥m√©(e) ou futur(e) dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√© (type Master2..) avec une majeure en syst√®me d'information, en Data ou en Datascience. Vous √™tes particuli√®rement int√©ress√© par la mise en oeuvre de solutions data compl√®te et par la gestion des flux et leur orchestration (notamment √©v√©nementielle) tout cela dans des environnements cloud Vous avez pu exercer cet int√©r√™t et vos talents dans vos exp√©riences pass√©es sur une ou plusieurs composantes de la cha√Æne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD‚Ä¶ Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte √©cologique","PwC is seeking a Data Engineer to join its Data & AI team in France to contribute to the design and implementation of innovative Data Analytics/Big Data solutions in cloud environments. The ideal candidate should have a degree in Data or Data Science, experience in cloud infrastructure, data pipelines, machine learning algorithms using tools such as Python and familiarity with Microsoft Azure, Google Cloud Platform and Amazon Web Services.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
450,56737,https://www.welcometothejungle.com/fr/companies/pwc/jobs/consultant-experimente-data-engineer-cdi-f-h_neuilly-sur-seine_PF_QggKwLY,Consultant exp√©riment√© Data Engineer | CDI |,PwC France,"{PostgreSQL,GitHub,Cassandra,Hive,Docker,Azure,Celery,Zeppelin,Microsoft,durable,MongoDB,Dataiku,Django,Dask,Hbase,Kafka,Git,Qlik,Python,ElasticSearch,Kubernetes,Storm,D3,Jupyter,Kibana,HDFS,Spark,Neo4j,Tableau}",T√©l√©travail partiel possible,"rue de villiers, Neuilly-Sur-Seine, 92208","Strat√©gie, Audit",CDI,2023-03-26,"PwC poursuit sa strat√©gie mondiale The New Equation, port√©e par l'humain, nos engagements responsables, soci√©taux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la r√©alit√© virtuelle et de technologies √©mergentes. Notre communaut√© Data et IA r√©unit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la cha√Æne de valeur, de la strat√©gie √† l'ex√©cution, afin d'accompagner nos clients sur l'ensemble de leurs m√©tiers et de leurs entit√©s, dans leur ""data transformation. PwC poursuit sa strat√©gie mondiale The New Equation, port√©e par l'humain, nos engagements responsables, soci√©taux et soutenus par la technologie. Dans ce contexte, nous investissons sur l'utilisation du cloud, de l'IA, des alliances technologiques, de la r√©alit√© virtuelle et de technologies √©mergentes. Notre communaut√© Data et IA r√©unit actuellement 300 experts (Data Strategists, Data Analysts, Data Scientists, Data Engineers, PO Data, etc.) en France, couvrant ainsi toute la cha√Æne de valeur, de la strat√©gie √† l'ex√©cution, afin d'accompagner nos clients sur l'ensemble de leurs m√©tiers et de leurs entit√©s, dans leur ""data transformation. Ce que vous pouvez attendre de nous En tant que Data engineer dans les √©quipes Data & IA de PwC votre mission sera de: - Contribuer √† la d√©finition et conception de solutions innovantes Data Analytics / Big Data et industrialisation des solutions sous forme d'applications en environnement cloud en √©troite collaboration avec les data architects - Mettre en ≈ìuvre ces solutions en mode Agile en optimisant : - La performance et le passage √† l'√©chelle - La qualit√© des donn√©es et des mod√®les au fil du temps - La coh√©rence avec les outils et les frameworks existants - La qualit√© et conformit√© (revue cyber, Cloud, auditabilit√© des traitements, RGPD) - Mise en place de CI/CD pour le d√©ploiement des solutions chez les clients Notre boite √† outils et technologies: Microsoft Azure, Google Cloud Platform, Amazon Web Services Docker, Kubernetes Python, Kafka, Storm, Spark HDFS, Hive, Hbase, MongoDB, Cassandra, ElasticSearch, Neo4j Tableau, Qlik, Spotfire, Dataiku, Kibana, D3 JS, Zeppelin, Graffana, Rshiny, Jupyter Ces avantages que nous vous offrons : Flexibilit√© avec la charte FlexWork : t√©l√©travail √©tendu, mobilit√© g√©ographique, FlexTime , Dress for your day Pass mobilit√© durable pour couvrir vos d√©penses de mobilit√© durable Programme Be Well, Work Well pour prendre soin de sa sant√© (partenariat Gymlib, application United heroes, associations sportives, formations mindfulness‚Ä¶) Programme Family Care pour vous accompagner dans vos projets de parentalit√© comme dans les moments difficiles √âcosyst√®me de sant√© pour trouver √† qui parler, √™tre √©cout√© et aid√© quelles que soient vos difficult√©s professionnelles ou personnelles Cr√©dit de 3 jours par an sur le temps de travail pour des missions d'engagement soci√©tal Mobilit√© interne et internationale possible √† partir de 18 mois d'anciennet√© Crystal Park (site de Neuilly-sur-Seine) : parc privatif de 2 hectares, conciergerie, salle de musique, salle de sport, Caf√© Joyeux‚Ä¶ Programme New World. New Skills pour monter en comp√©tences sur les enjeux de demain (ESG, technologies, inclusion des diversit√©s) et plateforme Vantage de formation √† la demande Et aussi : RTT, mutuelle sant√© et pr√©voyance, restaurants d'entreprise et titres-restaurants, avantages du Comit√© Inter-Entreprises‚Ä¶ Toutes nos offres sont ouvertes aux personnes en situation de handicap Ce que nous attendons de vous Vous √™tes dipl√¥m√©(e) ou futur(e) dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√© (type Master2..) avec une majeure en syst√®me d'information, en Data ou en Datascience. Vous √™tes particuli√®rement int√©ress√© par la mise en oeuvre de solutions data compl√®te et par la gestion des flux et leur orchestration (notamment √©v√©nementielle) tout cela dans des environnements cloud Vous avez pu exercer cet int√©r√™t et vos talents dans vos exp√©riences pass√©es sur une ou plusieurs composantes de la cha√Æne de valeur Data: Infrastructure cloud, data pipelines, data lakes, algorithmes de machine learning, API en utilisant des outils ou technologies comme Python / Dask / Spark, Angular, Django REST Framework, PostgreSQL, Celery, Websocket et Git, GitHub, Azure, Docker, Kubernetes, CI/CD‚Ä¶ Vous savez prendre du recul et penser globalement pour concevoir des solutions durables, en prenant en compte l'empreinte √©cologique","PwC seeks a data engineer to contribute to the definition and design of innovative data analytics/big data solutions and their deployment in cloud environments. The candidate should have experience in data pipelines, data lakes, machine learning algorithms, and cloud infrastructure, as well as knowledge of Python, Docker, Kubernetes, and CI/CD practices. PwC offers several benefits, including teleworking, flexible work hours, mobility, health and well-being programs, and professional development opportunities. The company seeks candidates with a degree in information systems or data science and an interest in developing complete data solutions and managing data flows in cloud environments.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
447,56407,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"5 Avenue de la liert√©, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de votre √¢ge, origine, orientation sexuelle, handicap... Au sein du d√©partement CIO CIB, vous rejoignez l'√©quipe de Sensitivities, au sein de l'IT Risks, compos√©e de 10 personnes. En nous rejoignant, vous prenez part √† plusieurs programmes de transformation de notre syst√®me d'information afin de r√©pondre aux besoins du d√©partement des risques, des r√©gulateurs, tout en accompagnant les front offices dans leurs nouvelles activit√©s. L'√©quipe est en charge de la maintenance et des √©volutions de deux applications cl√©s pour la gestion des risques de march√©s : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities r√©pondant √† la r√©glementation FRTB). Nos principaux interlocuteurs sont le d√©partement des risques de march√©s (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk), les √©quipes support/production √† Porto et les √©quipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques √† mettre en ≈ìuvre et estimer le co√ªt avec l'√©quipe ; D√©velopper de nouvelles fonctionnalit√©s de la phase de conception aux tests, dans une d√©marche durable (haute qualit√© du code, respect des principes d'architecture et de s√©curit√© informatique, documentation, automatisation des tests, utilisation maitris√©e de l'infrastructure) ; Travailler sur des probl√©matiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et am√©liorer la Software Factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 et les d√©veloppements n√©cessaires pour maintenir une production ponctuelle, de qualit√© et ma√Ætris√©e. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Paris et √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en informatique avec une sp√©cialisation en big data, vous avez au moins 3 ans d'exp√©rience en tant que data engineer. Vous ma√Ætrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La pr√©conisation de solutions techniques. Vous √™tes : - Reconnu pour votre leadership ; - Capable de proposer des am√©liorations continues ; - Rigoureux, autonome et p√©dagogue. Vous ma√Ætrisez l'anglais avec un niveau minimum B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis Corporate & Investment Banking is seeking a data engineer with at least three years of experience in big data, who is proficient in Spark, Scala and Hadoop. The successful candidate will be responsible for developing new functionalities, optimizing performance, and proposing innovative solutions within an agile development process. They must be autonomous, pedagogical, and have a strong leadership aptitude. The position is based in Paris and Charenton-le-Pont, offers ten days of telework per month, and includes a variety of benefits such as on-site services, RTT days, and an employee savings plan.",Bac +4,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
446,56402,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"AVENUE DE LA LIBERTE, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-03-26,"Natixis fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France. Fort d‚Äôun portefeuille de marques comprenant notamment Natixis Investment Managers et Natixis Corporate and Investment Banking, Global Financial Services est compos√© de deux m√©tiers ‚Äì la gestion d‚Äôactifs et de fortune et la banque de grande client√®le. Avec plus de 12 000 collaborateurs dans 35 pays, nos experts accompagnent leurs clients, partout dans le monde, en leur proposant des solutions de financement et d‚Äôinvestissement innovantes et durables. Engag√©s en faveur de la transition environnementale, technologique et soci√©tale, ils se distinguent par un fort esprit entrepreneurial. Au sein de la direction CIO CIB Risks, dans le d√©partement Data Processing and Metrics, vous rejoignez l'√©quipe Metric Services P&L Explain qui est compos√©e de 5 personnes. Dans cette √©quipe nous travaillons √† calculer l'explication du P&L (profit and loss) par les sensibilit√©s. Notre application est √©galement partie prenante des calculs de Stress Tests et IPV (ind√©pendance price validation). Nous intervenons donc sur plusieurs cha√Ænes de valeurs, aupr√®s de notre client : le d√©partement des risques de march√©. Au quotidien vous avez pour missions de : Contribuer aux sp√©cifications techniques et fonctionnelles ; Intervenir de la phase de conc√©ption aux tests : d√©veloppement de nouvelles fonctionnalit√©s, revue de code, documentation, ... ; Travailler sur des probl√©matiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et am√©liorer la software factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 pour avoir une production ponctuelle, de qualit√© et ma√Ætris√©e. Nos principaux interlocuteurs sont : le d√©partement des risques de march√© (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk) et les √©quipes support et production √† Porto. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Vous travaillez dans un environnement international, au sein d'une communaut√© d'experts qui place l'excellence, l'impact et l'action collective au c≈ìur de tout ce qu'elle entreprend. Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en finance et/ou en informatique avec une sp√©cialisation en big data, vous avez une exp√©rience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous ma√Ætrisez : * La finance de march√©, et plus pr√©cis√©ment le march√© des risques et PNL (m√©thode d'explication du PNL) ; * Les sp√©cifications des besoins de l'√©quipe et vous √™tes capable de proposer des maquettes aux utilisateurs en autonomie. Vous √™tes : * P√©dagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des am√©liorations continues. Vous ma√Ætrisez l'anglais avec un niveau B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis is seeking a Data Engineer with at least 2 years of experience in Hadoop, Spark, and Scala, specialized in big data with a background in finance and/or computer science. The ideal candidate must have a strong understanding of market finance, specifically risk and PNL, and be able to propose models to users independently while maintaining a flexible and innovative approach. The position is remote with 10 days of telework per month, offering a fixed salary, annual bonus, employee savings plan, career development opportunities, and work benefits such as onsite catering, sports facilities, and a concierge service.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
444,56406,https://www.welcometothejungle.com/fr/companies/elevate/jobs/manager-data-analysis-engineering-science_paris,"Manager Data Analysis, Engineering & Science",Elevate,"{GCP,R,SQL,Python}",T√©l√©travail partiel possible,Paris,"Digital Marketing / Data Marketing, IT / Digital, Recrutement",CDI,2023-03-26,"Elevate est la nouvelle agence de conseil d√©di√©e 100% √† la data. Nous intervenons √† la crois√©e du conseil et de la mise en ≈ìuvre op√©rationnelle sur des projets Digital & Data en d√©livrant un accompagnement bout-en-bout. Chez Elevate nous nous positionnons en tant que partenaire strat√©gique data de nos clients et rendons possible leur transformation customer-centric par notre m√©thodologie data-driven reconnue. Nous accompagnons nos clients sur l‚Äôensemble de la cha√Æne de valeur Data. Nous avons d√©compos√© notre offre autour de 3 practices d‚Äôexpertise : Data Marketing Conseil Data et Strat√©gie - Faire de la data et du digital un acc√©l√©rateur business Collecte & Analytics - Collecter, unifier, structurer et visualiser des donn√©es de performance fiables (Tracking) Exp√©rience client - Exploiter la data et les technologies du march√© pour d√©livrer des exp√©riences clients uniques (CRO) Performance m√©dia - Optimiser les budgets et les performances media gr√¢ce aux outils et m√©thodes de pointe du march√© Data & Tech Data Management - Identifier l‚Äôensemble des data points pouvant √™tre vecteurs de croissance et √©laborer une strat√©gie pour l‚Äôactivation de ces leviers Data Engineering & Architecture - Construire une architecture data r√©siliente et scalable, permettant son exploitation par le m√©tier Data Analysis - D√©ployer des outils facilitant la prise de d√©cision sur des points clefs du business et former les √©quipes sur la prise de d√©cision data driven Data Science - Mod√©liser et programmer pour assister la prise de d√©cision √† l‚Äôaide de statistiques descriptives et d‚Äôalgorithmes de pr√©diction et de classification Consumer & Market Insights Social Listening & Analytics - Ecouter la voix du client l√† o√π il s‚Äôexprime Notre ADN nous pousse √† √™tre constamment √† la pointe des sujets data. Pour cela, nos consultants accordent une part importante de leur temps √† de la veille, de la formation ou de la R&D. Nous recherchons un.e Manager Data Analysis, Engineering & Science ‚ú® Dans le cadre de la forte croissance d‚ÄôElevate et de notre practice Data & Tech, nous cherchons un ou une Manager afin de piloter une √©quipe d‚Äôune dizaine de consultants en mode r√©gie ou agence et d‚Äô accompagner nos clients sur des probl√©matiques techniques et business li√©es √† la data. Op√©rant pour des comptes internationaux et de secteurs tr√®s vari√©s (automobile, ecommerce, √©nergie, foodtech, fintech, banque, etc.) vous accompagnez nos clients dans leur transformation customer-centric. Alors si √™tre en charge d‚Äôun projet intrapreneurial dans une agence de conseil data en forte croissance vous inspire, ce poste est fait pour vous ! Parmi vos missions üõ† Management & recrutement : Vous avez sous gestion une √©quipe de consultants Data & Tech (juniors, confirm√©s, seniors) afin de mener √† bien des missions de data analyse, data sciences ou data engineering. Vous accompagnez dans leur carri√®re (appui d‚Äôexpertise, besoin de formation, taux de staffing, entretiens annuels et carri√®re‚Ä¶) votre √©quipe de consultants. Vous contribuez de mani√®re active au recrutement des nouvelles recrues en participant aux entretiens. D√©veloppement commercial de l‚Äôagence et de votre practice : Vous g√©rez directement un portefeuille de clients grands comptes multisectoriel pour lesquels vous conduisez des projets data & tech innovants : D√©finition, cadrage, mise en ≈ìuvre, application de m√©thodologies data-driven Transformation des organisations : d√©silotage, logique test&learn centr√©e client etc.* Vous participez √©galement activement au d√©veloppement de l‚Äôagence et en particulier sa Practice Data & Tech en prenant √† charge divers projets internes en fonction des opportunit√©s : Publication de comparatifs outils Participation √† des salons / conf√©rences Animation de retours d‚Äôexp√©riences et formation interne Contribution active au Knowledge Center Elevate* Vous accompagnez les associ√©s sur le volet commercial en participant aux appels d‚Äôoffres et aux efforts d‚Äôavant-vente, afin de transformer les opportunit√©s business et p√©renniser la relation client. Vous assurez le d√©veloppement commercial d‚Äôun portefeuille client au p√©rim√®tre d√©limit√© en identifiant et/ou favorisant l‚Äô√©mergence de nouveaux besoins chez vos clients (upsell & cross-sell). Qui pourrait vous accompagner ? ü§ù Aur√©lien, co-Fondateur : apr√®s un Master √† HETIC et diff√©rentes exp√©riences dans la data marketing, il se lance dans le freelance pendant 3‚Äâans. Aux c√¥t√©s de Maxime, partenaire de toujours depuis HETIC, ils se rendent vite compte que cette aventure entrepreneuriale d√©passe leurs attentes et souhaitent cr√©er un projet commun qui les ressemble. Ils d√©cident tous les deux, de cr√©er leur propre agence de conseil sp√©cialis√©e data. En octobre 2017, Elevate Agency voit le jour‚ÄØ! Aujourd‚Äôhui, il est responsable de la Team Talent, de l‚Äôactivit√© Marketing & Communication de l‚Äôagence & pilote le lancement en Espagne. Si vous cherchez une personne incollable sur l‚Äôunivers de la data et son actualit√©, Aur√©lien est votre homme ü¶∏‚Äç‚ôÇÔ∏è La data r√©v√®le que nous sommes moins susceptibles de postuler pour une offre d‚Äôemploi, si nous pensons ne pas avoir toutes les comp√©tences requises. üêë Notre mouton √† 5 pattes coche les cases suivantes, mais si vous n‚Äôen avez que 4, postulez quand m√™me ! Au sein d‚ÄôElevate nous saurons vous accompagner dans votre mont√©e en comp√©tences. Vous justifiez d‚Äôau moins 4 ans d‚Äôexp√©rience dans le domaine et d‚Äôune premi√®re exp√©rience en conseil et en gestion d‚Äô√©quipe. Niveau soft skills, on attendra de vous : Un esprit analytique, rigueur, logique et approche m√©thodique Un bon esprit d‚Äôinitiative, capacit√© √† travailler de mani√®re autonome et dynamique dans une activit√© en pleine croissance Le sens du service, aisance relationnelle Premi√®re exp√©rience manag√©riale (de deux personnes ou plus) est appr√©ci√©e Vous disposez √©galement des hard skills suivantes : De solides comp√©tences pratiques en data analyse (manipulation de donn√©es, statistiques, visualisation) et en machine learning au moins sur donn√©es tabulaires (classification, r√©gression, clustering) Vous parlez SQL et Python couramment Vous avez pilot√© et mis en place techniquement plusieurs projets data Vous avez une connaissance approfondie de l‚Äô√©tat du march√© / des m√©thodologies / des techniques sur ces trois domaines compl√©mentaires Vous √™tes familier.e avec l‚Äôoffre d‚Äôau moins un fournisseur cloud (GCP est un plus) et de la mani√®re dont celle-ci peut r√©pondre aux use-cases marketing Vous avez des comp√©tences reconnues en gestion de projet Une excellente communication √©crite et orale Une ma√Ætrise professionnelle de l‚Äôanglais üõ´Le processus de recrutement se fait en 3 √©tapes : Entretien t√©l√©phonique d‚Äôenviron 30 minutes avec notre √©quipe Talent Acquisition afin de vous laisser la parole pour mieux vous conna√Ætre. Entretien incluant un test de comp√©tences et de connaissances en data analyse, data sciences ou data engineering avec un.e manager & un.e consultant.e Elevate. Entretien approfondi avec l‚Äôun des co-fondateurs de l‚Äôagence √† l‚Äôoccasion duquel nous testons votre capacit√© de structure, d‚Äôanalyse et de synth√®se √† travers une ou deux √©tudes de cas. Nous attachons une importance toute particuli√®re √† votre rigueur, votre m√©thodologie d‚Äôanalyse et de structuration de probl√®mes ainsi que votre cr√©ativit√© pour les r√©soudre. Elevate s‚Äôengage √† donner une r√©ponse au candidat dans les plus brefs d√©lais. Elevate c‚Äôest avant tout ‚õ∫ Rejoindre une agence de conseil √† taille humaine. Une entreprise fond√©e autour de la formation et la mont√©e en comp√©tences de chaque membre de l‚Äô√©quipe. Un management humain et respectueux de toutes et tous. De la place pour les initiatives innovantes et cr√©atives. Une politique de t√©l√©travail flexible et bas√©e sur le choix ! Des parcours de carri√®res adapt√©s √† chacun.es Mais aussi üåû Une r√©mun√©ration fixe, attractive et bas√©e en fonction de votre niveau d‚Äôimpact et d‚Äôexpertise observ√© durant nos entretiens Des bureaux en plein Paris (mais aussi √† Bordeaux, Nantes, Lille et Lyon) Une assurance sant√© compl√©mentaire avec Alan ü©∫ Une carte Swile pour vos tickets restaurants (10‚Ç¨ par jour) üçΩ Le remboursement des frais de transport en commun √† 50% Des primes d‚Äôabondement, d‚Äôint√©ressement et une √©pargne salariale avec Epsor Un abonnement Urban Sport Club Nos consultant.es t√©moignent ü§ù Chez Elevate, nous avons √† c≈ìur d‚Äô√©couter, valoriser et respecter l‚Äôavis de nos consultant.es. Nous vous encourageons √† lire les avis de chacun et chacune sur notre page Glassdoor pour avoir plus de d√©tails sur les coulisses de notre aventure üôÇ Notre page Glassdoor üëà Si vous avez besoin d‚Äôun dispositif sp√©cial √† l‚Äôemploi (situation de handicap) ou d‚Äôune autorisation de travail sur le territoire fran√ßais, faites-nous en part le plus t√¥t possible pour que les d√©marches administratives ne ralentissent pas votre arriv√©e chez nous !","Elevate is seeking a Manager for Data Analysis, Engineering & Science to lead a team of consultants and support clients in their technical and business-related data problems. The position also includes managing and recruiting a team of consultants, developing the agency's commercial practice, transformation of organizations, and participating in avant-garde efforts. Candidates should have at least four years of experience in data analytics, a first-time management experience, and familiarity with GCP, Python and SQL.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,2,1,0.04154662416233763
443,56618,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-h-f_lille,Data engineer,Groupe SII,"{Scala,Dataflow,Java,JAVA,SQL,Python}",T√©l√©travail partiel possible,Lille,IT / Digital,CDI,2023-03-26,"Le Groupe SII est une soci√©t√© de conseil en technologies implant√©e dans 18 pays au travers de 100 implantations. Plus de 13 000 collaborateurs interviennent quotidiennement sur les probl√©matiques de transformation num√©rique des grands-comptes. Une entreprise o√π il fait bon travailler. Labellis√©e Great Place To Work pour la 5√®me ann√©e cons√©cutive, SII m√®ne de nombreuses actions li√©es √† la qualit√© de vie au travail. Au palmar√®s Great Place To Work 2021 √† la premi√®re place, le Groupe SII est au c≈ìur de l‚Äôinnovation et apporte son savoir-faire en accompagnant ses clients sur la transformation num√©rique. Chez SII Lille, nous leur apportons notre expertise technologique dans les m√©tiers du logiciel et l‚Äôing√©nierie d‚Äôinfrastructure pour les secteurs de la distribution, des t√©l√©coms, banques et mutuelles. Nos 170 collaborateurs sont anim√©s de cette m√™me passion pour la technologie et la veille permanente, et exercent leur m√©tier dans un cadre bienveillant, de proximit√© avec une dose de cr√©ativit√© et de fun ! En int√©grant le mouvement #fungenieur, vous pourrez mettre en pratique vos acquis et d√©velopper de nouvelles comp√©tences dans un climat de responsabilisation, de confiance et de transparence. SII Lille recherche un(e) : Data Engineer (H/F) Int√©gr√© √† un acteur majeur de la grande distribution, vous intervenez en tant que Data Engineer au sein de l‚Äô√©quipe IT Data en charge des plateformes Big Data. Vous d√©veloppez et g√©rez la maintenance de la plateforme Data et d‚Äôautres outils mais aussi des flux entre les diff√©rentes sources de donn√©es de l‚Äôentreprise. Vous contribuez √† :
‚Ä¢ Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform,
‚Ä¢ Concevoir les flux d‚Äôalimentation et les tables (structure de donn√©e),
‚Ä¢ Automatiser et industrialiser les flux,
‚Ä¢ Assurer le run applicatif, le cas √©ch√©ant. Profil : De formations sup√©rieure en informatique, type Bac+3/5, vous justifiez d‚Äôune exp√©rience significative en d√©veloppement sur un environnement BI et Big Data. Comp√©tences techniques : o Maitrise des langages suivants : SQL, Python (Java/Scala serait un plus)
o Connaissances de Google Cloud Dataflow (Python)
o Anglais n√©cessaire √† l‚Äô√©crit
o Notion de programmation fonctionnelle Au-del√† des comp√©tences techniques, vous fa√Ætes preuve de rigueur, de curiosit√© et aimez relever les challenges. Vous √™tes dot√©(e) d‚Äôun bon sens du service client, √™tes organis√© et pragmatique. Ces qualit√©s vous permettent de mener √† bien le projet. Vous vous reconnaissez dans ces comp√©tences et qualit√©s ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #Fung√©nieur de SII dans lequel la cr√©ativit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur ! Vous √™tes les cr√©ateurs de demain, osez mettre en avant vos comp√©tences, investissez-vous dans des projets innovants et venez relever de nouveaux d√©fis technologiques. Expertise, Innovation et fun est le mix que nous vous proposons ! Comp√©tences requises : JAVA, Python, Scala, SQL. Qualit√©s d√©sir√©es : Organisation, Rigueur, Satisfaction client. Avantages : Tr√®s bon CSE, Mutuelle et pr√©voyance, Tickets restaurant.","SII Lille is seeking a Data Engineer with experience in BI and Big Data to work with a major player in the retail industry. The role involves designing and developing future functionalities of the Big Data platform under Google Cloud Platform, designing data structure and feeding flows, automating and industrializing data flows, and ensuring the application run. The ideal candidate should have a degree in computer sciences and be proficient in SQL, Python, Java/Scala, and Google Cloud Dataflow. Organizational skills, client satisfaction, and curiosity are additional qualities needed for this position. SII offers a positive work environment, and great benefits including a good CSE, health coverage, and restaurant tickets.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
441,56825,https://www.welcometothejungle.com/fr/companies/kooperativa/jobs/data-engineer-m-z_praha,Data Engineer (m/≈æ),Kooperativa,"{Jupyter,NiFi,MapR,Git,Gitlab,Airflow,Informatica,Kafka,Hadoop,Hive,Spark,Docker,Github,SQL,Zeppelin}",T√©l√©travail partiel possible,"Pob≈ôe≈æn√≠ 665 , Praha, 18600","Assurance, Finance",CDI,2023-03-26,"Kooperativa funguje na ƒçesk√©m trhu u≈æ ƒçtvrt stolet√≠ a za tu dobu vyrostli do velk√© ƒçesk√© firmy s mezin√°rodn√≠m rozhledem i partnery. Maj√≠ p≈ôes dva miliony klient≈Ø a chtƒõj√≠ v√≠c ne≈æ jen vyhovƒõt jejich p≈ô√°n√≠m a po≈æadavk≈Øm, chtƒõj√≠ je p≈ôedƒç√≠t. Nechtƒõj√≠ b√Ωt neosobn√≠ spoleƒçnost√≠, v√≠, ≈æe aby byli √∫spƒõ≈°n√≠, mus√≠ dob≈ôe rozumƒõt lidem a jejich osud≈Øm. To plat√≠ i o p≈ô√≠stupu k zamƒõstnanc≈Øm, v nƒõm≈æ chtƒõj√≠ j√≠t naproti specifick√©mu potenci√°lu ka≈æd√©ho z nich a p≈ôistupovat f√©rovƒõ ke v≈°em bez v√Ωjimky. V t√Ωmu 6 Data Scientist≈Ø a nyn√≠ budujeme datalake pro ulo≈æen√≠ a analytiku velk√Ωch a nestrukturovan√Ωch dat. Hled√°me nad≈°ence pro modern√≠ technologie, kter√Ω n√°m pom≈Ø≈æe s rozvojem nov√© platformy. P≈ôedev≈°√≠m pak s automatizac√≠ datov√Ωch tok≈Ø, architekturou ulo≈æen√≠ dat, nasazen√≠m ML model≈Ø apod. Spoleƒçn√Ωm c√≠lem je vyu≈æ√≠t data pro rozvoj spoleƒçnosti od reportingu a≈æ po implementaci model≈Ø ML/AI a posouzen√≠ jejich praktick√©ho p≈ô√≠nosu. M√°me spoustu zaj√≠mav√Ωch analytick√Ωch √∫loh zejm√©na z oblast√≠ rizikovosti smluv a klient≈Ø, identifikace a generov√°n√≠ obchodn√≠ch p≈ô√≠le≈æitost√≠, segmentace klientsk√©ho portfolia a online chov√°n√≠ klient≈Ø. V r√°mci skupiny VIG zast≈ôe≈°ujeme Advanced Analytics Hub pro tvorbu statistick√Ωch a ML model≈Ø aBig Data Hub pro uchov√°n√≠ a velk√© a nestrukturovan√© data. Co v√°s ƒçek√°? Pr√°ce na zaj√≠mav√Ωch projektech s vysok√Ωm pozitivn√≠m dopadem na fungov√°n√≠ poji≈°≈•ovny a jej√≠ klienty Pr√°ce s velk√Ωmi a nestrukturovan√Ωmi daty obsa≈æen√Ωmi v datech (telematika, IOT, kalkulace, p≈ôepisy hovor≈Ø, fotografie nehod, dokumenty ‚Ä¶) Zaji≈°tƒõn√≠ a automatizace datov√Ωch tok≈Ø uvnit≈ô i mimo firmu √özk√° spolupr√°ce s data scientisty a datov√Ωm architektem, budeme souƒç√°st√≠ jednoho t√Ωmu Spolupr√°ce p≈ôi monitorov√°n√≠ a provozu datov√©ho prost≈ôed√≠ Co budete urƒçitƒõ pot≈ôebovat? Dobrou znalost Pythonu nebo PySparku vƒçetnƒõ notebook≈Ø Jupyter nebo Zeppelin Dobrou znalost pr√°ce s relaƒçn√≠mi datab√°zemi pomoc√≠ SQL Znalosti technologi√≠ pro DWH nebo datalake Z√°jem pozn√°vat a uƒçit se nov√© metody a technologie Co byte mohli zn√°t, ale nen√≠ to nutnost√≠? P≈ôede≈°l√© zku≈°enosti s budov√°n√≠m big data ≈ôe≈°en√≠ ve velk√© spoleƒçnosti Znalost nƒõkter√Ωch z n√°stroj≈Ø a technologi√≠ Spark, Airflow, MapR, Hadoop, Docker, OpenShift, Hive, NiFi Zku≈°enosti s integraƒçn√≠mi n√°stroji SSIS, ODI, Informatica, Pentaho Zku≈°enosti s technologiemi pro datov√© toky REST API, Kafka apod. Zku≈°enosti s n√°stroji pro spr√°vu a verzov√°n√≠ k√≥du Git, Gitlab/Github Znalost princip≈Ø datov√©ho modelov√°n√≠ ETL/ELT Zku≈°enosti s nasazen√≠m a automatizac√≠ DevOps, CI/CD a MLOps Znalost princip≈Ø a aplikac√≠ ML/AI model≈Ø Co v√°m za to nab√≠dnete? 32 dn≈Ø dovolen√© v roce (25 dn≈Ø dovolen√© + 5 voln√Ωch dn≈Ø + 1 charitativn√≠ den + 1 den p√©ƒçe) Flexibiln√≠ pracovn√≠ doba + mo≈ænost pr√°ce z domova Cestovn√≠ poji≈°tƒõn√≠ zdarma, nadstandardn√≠ p≈ô√≠spƒõvek na penzijn√≠ p≈ôipoji≈°tƒõn√≠ (a≈æ 1 000 Kƒç mƒõs√≠ƒçnƒõ) a ≈æivotn√≠ poji≈°tƒõn√≠ (a≈æ 3 150 Kƒç mƒõs√≠ƒçnƒõ), tƒõ≈°it se m≈Ø≈æete tak√© na velk√© slevy na na≈°e produkty a na produkty na≈°ich obchodn√≠ch partner≈Ø V r√°mci bonusov√©ho programu Cafeterie dostanete 12.000 Kƒç (v benefit bodech) a to, jak je uplat≈àovat, je jen na v√°s (sport, relax, kultura, dovolen√°, pobyty, apod.) Dotovan√° karta MultiSport za 500 Kƒç mƒõs√≠ƒçnƒõ Stravn√© 130 Kƒç/den (Kooperativa n√°m n√°jem 105 Kƒç) - v Praze m√°me vlastn√≠ j√≠delnu, bistro a kav√°rnu Intern√≠ i extern√≠ kurzy (IT a jazykov√© kurzy, vzdƒõl√°vac√≠ platforma Seduo), firemn√≠ kouƒç a psycholog, vyu≈æ√≠t m≈Ø≈æete i na≈°i firemn√≠ knihovnu Rozvojov√© a sportovn√≠ akce, zdravotn√≠ a preventivn√≠ programy, ale tak√© mo≈ænost nadstandardn√≠ zdravotn√≠ p√©ƒçe (fyzioterapie, j√≥ga, oƒçkov√°n√≠) Za doporuƒçen√≠ nov√©ho kolegy v√°s ocen√≠me a≈æ 45 000 benefit body do Cafeterie Zamƒõstnaneck√Ω mobiln√≠ tarif, pracovn√≠ telefon a notebook je samoz≈ôejmost√≠","Data Scientist with strong knowledge of Python, PySpark, SQL, and technology for DWH or datalake. The successful candidate will work on interesting projects with a positive impact on the insurance company and its customers, including working with large and unstructured data, automating data flows, and collaborating with data scientists and data architects. Bonus skills include experience with big data solutions, Spark, Airflow, MapR, Hadoop, Docker, OpenShift, and ML/AI models. The company offers flexible working hours, 32 days of vacation, travel insurance, and various bonus programs.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
440,50349,https://www.welcometothejungle.com/fr/companies/neoxia/jobs/canada-data-engineer-scientist-confirme-senior-2-ans-d-experience-minimum_montreal,Canada üá®üá¶ Data engineer/scientist confirm√©/s√©nior (2 ans d'exp√©rience minimum),Neoxia,"{Snowflake,Synapse,Azure,Microsoft,Dask,NoSQL,AWS,Teradata,http,Java,SQL,Hadoop,Scala,Prefect,Redshift,Airflow,via,R,Spark,BigQuery,GCP,Python}",T√©l√©travail partiel possible,"Montr√©al, H2L","Logiciels, IT / Digital",CDI,2023-02-07,"√Ä propos de Neoxia Cr√©√©e en 2000, Neoxia accompagne des entreprises, de la start up au tr√®s grand groupe, dans leur transformation num√©rique en r√©alisant des projets informatiques ambitieux et innovants sur le Cloud. Nous sommes aujourd‚Äôhui un partenaire certifi√© aupr√®s d‚ÄôAmazon Web Service (AWS), Google Cloud Platform (GCP) et Microsoft Azure. Passionn√©s de technologie, les ‚ÄúNeoxiens‚Äù ont des profils vari√©s, du data engineer au d√©veloppeur full-stack, en passant par le designer UX/UI, le d√©veloppeur mobile, le Scrum master, ou encore le DevOps pour accompagner les entreprises √† toutes les √©tapes de leur transformation num√©rique. Les avantages Neoxia sont : Du t√©l√©travail en mode hybride (1 jour par semaine au bureau minimum) Une assurance collective 4 semaines de vacances √ätre accompagn√© et progresser dans des technos qui te font vibrer, le tout dans une ambiance de solidarit√© et de bienveillance 20 % du temps consacr√© √† la R&D Du temps et du financement pour des certifications et des sandbox Cloud De la formation en interne avec des formations et une plateforme de partage de connaissances : la Nx-Academy ! Partager avec tes coll√®gues aussi bien une partie de PS4 que des bonnes pratiques de d√©v Des √©v√©nements d‚Äô√©quipes fr√©quents (barbecue, fins de semaines, etc.) De beaux locaux en centre-ville √âvoluer au sein d‚Äô√©quipes d‚Äôune grande diversit√© Du carburant pour coder (kombucha, th√© et caf√© bien s√ªr) Des possibilit√©s d‚Äô√©voluer rapidement au sein d‚Äôune entreprise en pleine croissance Collaborer avec des ONG partenaires de Neoxia sur des projets √† fort impact social et environnemental Tu peux en d√©couvrir plus sur la culture de Neoxia sur https://discover.neoxia.com / Rencontre l‚Äô√©quipe en vid√©o - Matthieu Chappaz, directeur de Neoxia Montr√©al / http://www.youtube.com/watch?v=JmD7gnHZ4q8 Gilles Mergoil, Pr√©sident du groupe Neoxia / https://www.youtube.com/watch?v=FMV_C44tppU Yann Coleu, architecte Cloud / https://www.youtube.com/watch?v=Vk-znZBsL1k&list=PLUndIPKSZI5TZViwSoNuAnNbdqr2XlY3W C√¥t√© Data, de la partie Engineering jusqu‚Äô√† la partie Ops en passant par le Machine Learning, notre √©quipe de sp√©cialistes en pleine croissance s‚Äôattaque √† tous les challenges autour des donn√©es qui nous entourent. Google Cloud, Amazon Web Service et Microsoft Azure sont nos partenaires, et nous construisons avec eux des solutions Data robustes, performantes et innovantes. En tant que Data engineer/scientist confirm√©/s√©nior, tu rejoindras une √©quipe Data en pleine croissance, et pourras participer √† la faire grandir. Tu apporteras √©galement ton expertise sur les projets tout au long des cycles de conception, de d√©veloppement et de d√©ploiement pour continuer √† apprendre tout en aidant les personnes autour de toi √† grandir. Tes actions pourront regrouper notamment : Pr√©coniser une architecture et des technologies adapt√©es au contexte du client D√©finir des standards technologiques internes √† partir de benchmark et d‚Äôune analyse des sp√©cificit√©s du client Garantir dans le temps la coh√©rence technique des plateformes Data Prototyper les solutions techniques pr√©conis√©es Assister les √©quipes internes du client ou celles d√©ploy√©es par Neoxia dans la mise en oeuvre des solutions techniques pr√©conis√©es Encadrer les √©quipes de consultants gr√¢ce √† la formation et au coaching, et suivre la mise en place des bonnes pratiques Assurer une veille technologique et diffuser les connaissances via l‚Äôorganisation d‚Äôateliers au sein de neoxia ou de meetup ouverts √† la communaut√© Participer aux r√©ponses aux appels d‚Äôoffres et assister l‚Äô√©quipe commerciale en tant qu‚Äôexpert technique de la Data Dans ton quotidien, tu contribueras au partage et √† la capitalisation des savoirs et des pratiques sur notre plateforme de partage NX-Academy Ma√Ætrise du fran√ßais Tu justifies d‚Äôau moins 2 ans d‚Äôexp√©rience sur des projets 100% Data Dipl√¥m√©(e) en informatique ou en sciences Dynamique et rigoureux(se), tu as un bon relationnel. Tu es √† la fois autonome et √† l‚Äô√©coute des autres. Humble, tu sais ce que tu sais faire et ce que tu ne sais pas faire pour tenir et respecter tes engagements Tu es passionn√©(e) de technologie et curieux(se) au sujet de l‚Äô√©volution des pratiques d‚Äôing√©nierie logicielle (Continuous Delivery, DevOps, ‚Ä¶) Comp√©tences Ma√Ætrise d‚Äôau moins un langage de programmation : Python, Scala, Java Ma√Ætrise des bases de donn√©es SQL et/ou NoSQL Ma√Ætrise des services Data d‚Äôun des Cloud Provider GCP, AWS ou Azure Ma√Ætrise des fondamentaux li√©s aux bases de donn√©es et aux Datawarehouse, avec de pr√©c√©dentes exp√©riences sur Redshift, Teradata, BigQuery, Snowflake ou Azure Synapse Ma√Ætrise des concepts et des solutions d‚Äôorchestration des donn√©es : Airflow, Prefect Ma√Ætrise des principaux concepts autour des traitements distribu√©s des donn√©es (Spark, Dask ou Hadoop) Connaissances autour des bonnes pratiques DevOps (Optionnel) Connaissances en machine learning Un √©change RH d‚Äôenviron 30 minutes pour te pr√©senter l‚Äôentreprise et le process de recrutement Un test technique en ligne pour d√©couvrir tes connaissances Data (optionnel pour certains profils) Un ‚Äúuse case‚Äù d‚Äô1h30 avec l‚Äôun de nos lead tech Une derni√®re √©tape avec Matthieu Chappaz, directeur de Neoxia Montr√©al, pour v√©rifier que Neoxia correspond √† ce que tu recherches, et vice-versa","Neoxia, a digital transformation company, is seeking a senior Data Engineer/Scientist to join their growing team. The successful candidate will have at least 2 years of experience in 100% data projects, a degree in computer science or sciences, and proficiency in programming languages such as Python, Scala, and Java, as well as SQL and/or NoSQL databases. Additionally, experience with cloud providers such as AWS, GCP, or Azure, as well as data orchestration tools and distributed data processing technologies like Spark and Dask, are desired. The role includes defining technological standards, assisting with project implementation, coaching and training colleagues, staying up-to-date with technological developments, and participating in the recruitment process. Neoxia offers benefits such as work-life balance, health insurance, vacations, R&D time and financing, internal training and knowledge-sharing platforms, and a collaborative team environment.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
398,34914,https://www.welcometothejungle.com/fr/companies/veepee/jobs/software-engineer-for-data-h-f_lyon,Software Engineer for Data,Veepee,"{Beam,k8s,Protobuf,gitlab,Kubernetes,Airflow,dbt,gRPC,kubernetes,Bigquery,Dataflow,Java}",T√©l√©travail partiel possible,Lyon,E-commerce,CDI,2022-08-08,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire europ√©enne avec la convergence des diff√©rentes soci√©t√©s qui le composent et leurs 6 000 collaborateurs vers une seule et m√™me marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd‚Äôhui pr√©sent dans 14 pays et devient un acteur majeur du commerce digital europ√©en, avec 72 millions de membres et un volume d‚Äôaffaires de 3,7 milliards d‚Äôeuros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour r√©veiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos strat√©gies, afin de proposer la meilleure exp√©rience possible √† nos clients. Vous avez soif d‚Äôapprendre ? Veepee vous permet de construire votre parcours parmi une pluralit√© de m√©tiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes‚Ä¶ prenez part √† une aventure humaine au c≈ìur d‚Äôenjeux digitaux. Impatients de les rencontrer ? Ils ont h√¢te aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a Software Engineer in Veepee‚Äôs data organization, you will.. .. be part of our data organization Veepee‚Äôs data organisation came into existence in 2018 and consists of a strong team of 40-50 data professionals, spread across different data domains (engineering, analytics, data science & ML and governance). You will be part of a multidisciplinary, multinational team that fosters collaboration, transparency, respect and of course‚Ä¶ a good amount of fun in the working environment. .. build and maintain APIs, tools and pipelines that form Veepee‚Äôs data platform For its data platform, Veepee firmly believes in a Push - Load - Transform strategy of ingesting data. Products are responsible for the data they produce and our data platform should enable them to push that information (in real-time) into our data platform in a governed way. Hence, we adopted data contracts to define which data comes in and have built our own set of tools and API‚Äôs around this to facilitate data ingestion, Veepee style. Furthermore, we keep improving our toolchain for data transformation (using dbt) and data exposure downstream. Responsibilities: Be part of a team running a set of applications with high SLA requirements; Develop, deploy and maintain a large Java stack serving a set of APIs mainly developed in gRPC & Protobuf Support, design, implement and deploy microservices running on Kubernetes with a Gitops approach; Identify data producer and consumer requirements and implement pragmatic and robust solutions based on solid architecture patterns (Reactive, Operator, Resilient..); Maintain data pipelines and data jobs mainly developed with Apache Beam and Apache Airflow; Keep improving your technical knowledge and expertise by attending conferences, contributing to open-source projects organizing and attending meetups Requirements: You have a strong experience (3-5 years) working on a large Java stack; You know how to implement and consume APIs, preferably in Protobuf & gRPC; You love making clean code and you are interested in having successful software engineering practices (Unit tests, pair programming, code reviews). You would like to help the team to grow in the quality of what they produce and their methodologies; You have experience with setting up CI/CD pipelines, preferably in gitlab; You have significant experience working with microservices and Kubernetes; You know or want to use helm charts as a templating language for k8s crd‚Äôs; You know or want to use the concept of a GitOps strategy for deploying kubernetes resources, preferably using ArgoCD; You are willing to learn data engineering concepts, tools and frameworks (Apache Beam, Apache Airflow, dbt); You would like to work with Google Cloud Platform (Bigquery, GKE, Dataflow); You know or want to learn Infrastructure as Code tools like terraform, atlantis; You are a strong team player. What we offer: The dynamic and creative environment within international teams; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences locally and internationally; Hybrid work organization and flexibility for full remote contracts; Advanced remote practices and tools. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you‚Äôll be sure to find your place, no matter the technology you want to work with. If you love to try things why don‚Äôt you jump on this new adventure? Need more info > https://careers.veepee.com/en/careers/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, part of the vente-privee group, is looking for a software engineer to join its data organisation. The successful candidate will be responsible for building and maintaining APIs, tools and pipelines on Veepee's data platform, developing microservices and deploying them on Kubernetes with a Gitops approach. The ideal candidate will have three to five years of experience working on a large Java stack and experience implementing and consuming APIs, preferably in Protobuf and gRPC. Furthermore, experience with microservices, Kubernetes, CI/CD pipelines and data engineering tools like Apache Beam, Apache Airflow, and dbt is sought.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
395,39813,https://www.welcometothejungle.com/fr/companies/easypicky/jobs/data-engineer_montpellier,Data Engineer,Easypicky,"{NoSQL,SQL,Python}",T√©l√©travail partiel possible,"621, Rue Georges M√©li√®s, Montpellier, 34000","Application mobile, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",CDI,2022-11-29,"Start-up montpelli√©raine cr√©√©e en 2017, EasyPicky r√©volutionne l‚Äôunivers de la grande distribution avec son application vid√©o bas√©e sur de la reconnaissance vid√©o offline. Sa solution permet aujourd‚Äôhui aux marques de contr√¥ler, organiser et optimiser √† chaque instant la pr√©sence et la visibilit√© de leurs produits en magasin. La technologie de reconnaissance d‚Äôimages d√©velopp√©e par EasyPicky peut √™tre d√©ploy√©e sur n‚Äôimporte quel syst√®me embarqu√© et utilis√©e partout sans connexion, et √ßa, c‚Äôest une v√©ritable r√©volution technologique ! Le poste : Dans un contexte de forte croissance de nos √©quipes - üöÄ x4 en 2021 üöÄ ‚Äì tu rejoindras l‚Äô√©quipe Tech & Product en tant que Data Engineer. Ton r√¥le en tant que responsable de la donn√©e sera de mettre en place et maintenir les services n√©cessaires pour fournir de mani√®re optimale une donn√©e structur√©e et propre aux diff√©rentes √©quipes de l‚Äôentreprise. Dans ce cadre, tes missions seront de‚ÄØ: ‚Ä¢ Faire un diagnostic des bases de donn√©es existantes‚ÄØ; ‚Ä¢ Concevoir et mettre en place une base de donn√©es unifi√©e, afin d‚Äôorganiser et structurer nos donn√©es‚ÄØ; ‚Ä¢ Ex√©cuter des requ√™tes de donn√©es (SQL/NoSQL) performantes‚ÄØ; ‚Ä¢ D√©tecter et r√©parer les anomalies dans la base de donn√©es‚ÄØ; ‚Ä¢ D√©finir les KPIs permettant de mesurer la qualit√© et la performance de la base de donn√©es‚ÄØ; ‚Ä¢ G√©rer plusieurs workflows int√©grant la donn√©e √† destination du reste des √©quipes Tech ; ‚Ä¢ Apporter son savoir-faire technique afin d‚Äôam√©liorer et de moderniser la gestion de nos bases de donn√©es. Ton profil‚ÄØ: ‚Ä¢ Titulaire d‚Äôune formation Bac+5 de type √©cole d‚Äôing√©nieur en informatique ou √©quivalent universitaire, tu disposes d‚Äôune exp√©rience de 6 ans minimum en Data Engineering. ‚Ä¢ Tu as eu l‚Äôoccasion de mettre en place des outils et plateformes de traitement de donn√©es. ‚Ä¢ Tu es √† l‚Äôaise avec les bases de donn√©es SQL/NoSQL, Python, gestion workflows, la construction et la maintenance de pipelines de donn√©es. ‚Ä¢ Tu poss√®des un niveau suffisant d‚Äôanglais technique. ‚Ä¢ Tu es curieux, bon communiquant et as une bonne compr√©hension du business pour traduire les besoins en termes de collecte et de transformation de donn√©es. Premier entretien RH de pr√©-s√©l√©ction Rencontre avec Manager IT et Team-Leads Entretien avec CEO","EasyPicky, a start-up that revolutionizes the retail industry with offline video recognition technology, is seeking a Data Engineer to join its Tech & Product team. The successful candidate will diagnose existing databases, design and implement a unified database, execute performant data queries, detect and fix anomalies, define KPIs, manage multiple workflows integrating data, and use technical expertise to improve database management. The ideal candidate must have a minimum of six years of experience in data engineering, comfort with SQL/NoSQL databases, Python, workflow management, and data pipeline construction and maintenance. Good communication skills, business acumen, and technical English proficiency are also essential.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,2,1,0.04154662416233763
317,56303,https://www.welcometothejungle.com/fr/companies/inferensia/jobs/consultant-data-engineer-data-scientist_lyon,Consultant Data Engineer - Data Scientist,Inferensia,"{Git,Talend,Kubernetes,PowerBI,Informatica,AWS,Docker,Kafka,R,Spark,GCP,Java,NoSQL,SQL,Python,Postgres}",T√©l√©travail partiel possible,"136 Cr Lafayette, Lyon, 69003","Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",CDI,2023-03-26,"Inferensia est un acteur du march√© Data et Innovation qui attache une grande importance au pragmatisme et √† la valeur de ses interventions. En tant que cabinet de conseil, nous : accompagnons nos clients sur leurs besoins leur permettons de se focaliser sur leur c≈ìur de m√©tier amenons/apportons nos savoir-faire et expertises donnons √† nos clients les moyens de devenir autonomes suite √† notre mission/intervention Nos domaines d‚Äôintervention : transformation et diagnostic des organisations pilotage & AMOA data (roadmap, mod√©lisation, int√©gration, reporting/dataviz‚Ä¶) expertise technique (architecture, cloud, API management‚Ä¶) Nous nous nourrissons de ces missions et exp√©riences afin d‚Äôen retirer les meilleures id√©es et d‚Äôindustrialiser des solutions au sein de notre DataLab. Ce dernier est en construction permanente et permet de valoriser et p√©renniser les projets internes de R&D. Un des premiers produits de ce DataLab est une plateforme SaaS multi-usages fond√©e sur la data qui centralise les diligences li√©es aux Risk & Compliance : la solution Kantik. Notre originalit√© est de r√©ussir √† garder une forte identit√© et une appartenance √† Inferensia tout en √©tant en mission pour nos clients. Nos valeurs sont le fondement de notre fonctionnement et constituent le moteur de cette belle aventure qu‚Äôest Inferensia : Comp√©tence, Proximit√©, Ecoute et Innovation. Dans un contexte de forte croissance, Inferensia renforce ses √©quipes en recrutant un(e) Consultant(e) Data Engineer / Data Scientist Confirm√©(e) ayant une forte app√©tence pour les sujets techniques. Vous avez d√©j√† 2 √† 5 ans d‚Äôexp√©rience professionnelle. V√©ritable couteau-suisse, vous avez une connaissance pratique des diff√©rents enjeux de la r√©alisation et de l‚Äôindustrialisation d‚Äôun projet Data/IA de m√™me que les m√©thodologies, outils et techniques d‚Äôimpl√©mentation des diff√©rentes briques techniques et applicatives composantes. Vos missions consisteront en : L‚Äô√©coute et l‚Äôanalyse du besoin client La conception des solutions par des propositions d‚Äôarchitectures applicative, fonctionnelle et technique La conduite et le suivi de l‚Äôimpl√©mentation des solutions L‚Äôoptimisation des performances des algorithmes de traitement de donn√©es, des pipelines Data ou encore des algorithmes d‚Äôintelligence artificielle Vous aimez encadrer techniquement les √©quipes et les accompagner dans leur mont√©e en comp√©tence. Vous √™tes √† l‚Äôaise pour r√©diger des documents techniques comme des normes de d√©veloppement ou des sp√©cifications. Vous souhaitez √©voluer vers un poste d‚Äôexpert ou de r√©f√©rent technique. Vous interviendrez sur des sujets tels que : des projets clients (Data Science, Data Engineering, Data Analytics‚Ä¶) des missions d‚Äôaide au choix d‚Äôoutils la d√©finition de roadmaps data l‚Äôavant-vente (r√©ponses √† appels d‚Äôoffres, d√©monstrations‚Ä¶) la formation des collaborateurs Vous serez √©galement amen√©(e) √† participer √† nos projets internes. Dot√© d‚Äôun excellent relationnel, avec l‚Äôambition d‚Äô√©voluer dans un contexte innovant et challengeant li√© aux sujets Data / Big Data / IoT / Data Science / Cloud‚Ä¶ Innovation ! Vous aimez travailler en √©quipe, and you are fluent in english ! Nous sommes bas√©s sur Lyon et ouverts au t√©l√©travail. Possibilit√© de d√©placements ponctuels. Comp√©tences minimum attendues : Bac +5 Minimum 2 ans d‚Äôexp√©rience professionnelle Maitrise des solutions de collecte, traitement, analyse et visualisation de la data Capacit√© d‚Äô√©coute et d‚Äôanalyse Capacit√© d‚Äôadaptation Stack technologique : Langage de programmation : Java, Python ‚Ä¶ Gestion et stockage des donn√©es : SQL, RDBMS (Postgres), NoSQL Big Data : Spark, Kafka, .. ETL : Talend, Informatica‚Ä¶ Analytics : ML/DL Visualisation : QlikSense, PowerBI Cloud : AWS / GCP/ Scaleway/ ‚Ä¶ Versioning & D√©ploiement : Git, Outils CI/CD, Docker, Kubernetes, MLOps Deux entretiens pour √©changer sur votre parcours et vos envies, et comprendre l‚ÄôADN d‚ÄôInferensia Inferensia s‚Äôengage √† accorder une attention particuli√®re √† la promotion de la diversit√©, de l‚Äôinclusion et de l‚Äô√©galit√© au sein de ses √©quipes, et ainsi, √† √©tudier √©quitablement chaque candidature.","Inferensia is seeking an experienced Data Engineer/Scientist with a strong technical background to join their team in Lyon. The ideal candidate will have 2-5 years of professional experience and be proficient in data collection, analysis, visualization, and architecture. The role involves analyzing client needs, designing technical solutions, overseeing implementation, and optimizing data processing algorithms. The company emphasizes practical expertise and innovation and values competence, proximity, listening, and innovation. Candidates should have excellent communication skills, be comfortable working in a team, and have a strong desire to work in a challenging and innovative environment. Fluency in English is also required.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
394,50467,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-confirme-f-h_bordeaux,Data Engineer Confirm√©,Thales,"{MySQL,durable,Qlikview,python,Talend,Nifi,Gitlab,bash,PostgreSQL,Docker,Kafka,Azure}",T√©l√©travail partiel possible,Bordeaux,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-02-07,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? L‚Äôactivit√© Syst√®mes de missions de d√©fense fournit des √©quipements, des solutions et des services li√©s aux syst√®mes de combat √©lectroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Sur le Campus Thales Bordeaux, nous concevons, d√©veloppons et livrons des syst√®mes, des √©quipements et des services pour assurer la r√©ussite des missions a√©roport√©es de nos clients, dans les domaines du transport, de la surveillance et du combat. Le D√©partement Ing√©nierie des Solutions Digitales et des Servcices (ISDS), recherche un Data Engineer Confirm√© (F/H) , en CDI √† Bordeaux. QUI ETES-VOUS ? Vous poss√©dez une r√©elle exp√©rience de TechLead dans le domaine du data management ? Vous ma√Ætrisez la chaine de traitement de la donn√©e de sa collecte √† sa restitution, en passant par son stockage, sa fiabilisation et ses traitements ? Nos technologies et concepts vous sont familiers ? Azure, Azure Stack Gitlab-ci, Docker Nifi, Talend , Data√Øku, Kafka Langage de scripting (bash, python, ‚Ä¶), PostgreSQL, MySQL Suite ELK Qlikview, Qliksense Vous savez d√©fendre vos convictions aupr√®s de clients internes ? Vous souhaitez combler votre curiosit√© technique dans un cadre de travail agile ? Vous aimez travailler en autonomie dans votre expertise au sein d‚Äôune √©quipe dynamique ? P√©dagogie, bonne communication et esprit d‚Äô√©quipe sont des atouts que l‚Äôon vous reconnait ? Si la r√©ponse √† toutes ces questions est oui, alors la suite va vous int√©resser ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Au sein de la Direction Soutien et Services Client (CSS), vous int√©grez le p√¥le DATA de l'Ing√©nierie des Solutions Digitales des Services (ISDS) afin d'accompagner la croissance d'une √©quipe √† taille humaine. Vous rejoignez une √©quipe pluridisciplinaire de 18 personnes , au c≈ìur des relations avec l'ensemble des intervenants techniques de notre √©cosyst√®me. En tant que Data Engineer Confirm√©, vos principales missions sont de concevoir, mettre en ≈ìuvre et maintenir des chaines de traitements de la donn√©e tout en apportant un support technique aux membres de l'√©quipe. En nous rejoignant, vos principales missions seront les suivantes : ‚Ä¢ Comprendre le besoin m√©tier et √™tre force de proposition pour les exigences formul√©es par les Product Owner, ‚Ä¢ D√©finir des solutions techniques, en accord avec l'architecte Solution, permettant de g√©rer le flux de donn√©es, ‚Ä¢ Accompagner l'√©quipe dans la r√©alisation et la maintenance des solutions, ‚Ä¢ Travailler la mise en qualit√© de la donn√©e et contribuer √† sa gouvernance, ‚Ä¢ Participer √† la mod√©lisation de bases d√©cisionnelles et au maintien et √† l‚Äô√©volution de bases de donn√©es relationnelles, ‚Ä¢ Apporter un support aux m√©tiers et assurer une veille technologique. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is seeking an experienced Data Engineer who is familiar with Azure, Gitlab-ci, Docker, and other technologies to join their team in Bordeaux. The ideal candidate should possess excellent technical skills and be able to work independently while collaborating with a dynamic team. They will be responsible for designing, implementing, and maintaining data processing chains while providing technical support to team members. They should have experience as a TechLead in data management and strong communication and team skills.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
355,37369,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-big-data-h-f_montpellier,Data Engineer Big Data,CGI,"{Python,MongoDB,Neo4j,Scala,Kafka,Cassandra,Hive,Spark,Git,Java,NoSQL,Hadoop,nifi}",T√©l√©travail partiel possible,N,"IT / Digital, Transformation, Big Data",CDI,2022-10-18,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 25 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√© par le domaine de la Data et avez d√©j√† une exp√©rience significative sur des probl√©matiques de data engineering : construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es, ‚Ä¶ Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi‚Ä¶) et/ou NoSQL (MongoDB, Neo4j, Cassandra‚Ä¶) et vous maitrisez un des trois langages suivants : Java, Scala, Python. Vous souhaitez diversifier vos comp√©tences Big Data pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 200 consultants) ? Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Big Data que ceux de votre domaine de comp√©tences initial. En tant que Data Engineer, vous serez int√©gr√© √† un p√¥le de consultants sp√©cialistes du Big Data intervenants sur des projets stimulants. Vos missions seront : ‚Ä¢ Analyser, conseiller, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs techniques et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques ‚Ä¢ R√©aliser les travaux d‚Äôimpl√©mentation des solutions (pr√©paration des donn√©es, industrialisation des mod√®les, communications entre les diff√©rentes technologies,‚Ä¶) ‚Ä¢ Produire les projets en mode agile avec des processus et outils de d√©veloppement de derni√®re g√©n√©ration (DevOps, Git, CI/CD‚Ä¶) ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique ‚Ä¢ Animer des formations internes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique Big Data aux √©quipes et aux clients au quotidien Accompagn√© et entour√© par une communaut√© Data passionn√©e, l‚Äô√©change, le partage et les formations vous offriront un v√©ritable espace pour vous √©panouir. La proximit√© et le suivi personnalis√© de votre manager, puis un bon nombre d‚Äô√©v√©nements tout au long de l'ann√©e, renforceront encore la convivialit√© et l‚Äôesprit d'√©quipe ! Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique ou dans le consulting de solutions Data. Passionn√© d‚Äôinformatique et de donn√©es, vous aimez le travail en √©quipe, apprendre et partager. Vous √™tes √©galement dot√© d'un esprit audacieux et ambitieux. Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. Vous justifiez de 2 √† 5 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil dans le Domaine du Big Data. Vous disposez d'une vision large des technologies et vous ma√Ætrisez au moins une technologie Big Data. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital services and consulting, is seeking a Data Engineer to work in its Big Data team, which provides services to different sectors, including Banking, Retail, Energy, and Transportation. The ideal candidate should have experience in data engineering, understanding of Big Data tools such as Hadoop, Spark, Hive, Kafka, and NoSQL databases, and capable of working with one of these languages, Java, Scala, or Python. The successful candidate will participate in analyzing, advising, developing, and implementing solutions while working in an agile environment. This role offers opportunities for professional growth and development, including leading technical teams or consulting Data Solutions.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
354,34807,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-engineer-h-f_paris-02_TDF_VbP0ybe,Data Engineer,TotalEnergies Digital Factory,"{Kafka,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,Paris 02,"Logiciels, Big Data, Energie",CDI,2022-08-08,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. TotalEnergies a d√©cid√© d'acc√©l√©rer la production interne de solutions digitales pour ses activit√©s en cr√©ant une Digital Factory. La Digital Factory de TotalEnergies allie l'agilit√© et l'esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Nous cr√©ons et d√©ployons des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. Nous consid√©rons les personnes comme la ressource la plus pr√©cieuse pour r√©ussir, c'est pourquoi nous tenons non seulement √† recruter les meilleurs talents, mais aussi √† cr√©er des liens uniques entre nos employ√©s. En accord avec les politiques HSE de la compagnie et celles de la Digital Factory, le/la Data Engineer int√©grera l'√©quipe ¬´ Delivery ¬ª, qui intervient dans la production des Minimum Viable Products (MVPs). En soutien de la Squad dans l'organisation des donn√©es, cette √©quipe √©volue dans un contexte agile (scrum/scrumban), en mode it√©ratif et co-constructif, en s'appuyant sur l'intelligence collective. Votre r√¥le est de garantir la qualit√© des pipelines data du produit, assurer le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es. Missions : Concevoir, construire et int√©grer des donn√©es, au sein de la squad et en collaboration avec les autres squads Assurer le stockage, la consommation, l'int√©gration et la gestion des donn√©es des cas d'utilisation. Faire l'analyse de l'accessibilit√© des donn√©es et recommander des solutions pour leur int√©gration. Coordonner la mise en place, l'industrialisation et la maintenance de l'architecture data : infrastructure, cloud, flux de donn√©es. Int√©grer les donn√©es dans le data lake. Collaborer avec les data scientists pour la r√©alisation des mod√®les de pr√©diction. Produire un code de qualit√©, mettre en place des tests automatis√©s pour le contr√¥ler. Interagir avec les architectes et les autres data engineers, pour s'assurer de l'efficacit√© des solutions et apporter des pr√©conisations techniques Ma√Ætriser les bonnes pratiques de monitoring des flux de donn√©es. Assurer la veille technologique sur les architectures data et les nouvelles technologies. Coacher et accompagner la communaut√© des Data Engineers de la Digital Factory. Vous √™tes dipl√¥m√©/e d'un Master ou d'une √©cole d'ing√©nieur sp√©cialis√©e en informatique ou math√©matiques. Vous avez au minimum 2 ans d'exp√©rience en data engineering. Vos comp√©tences techniques sont reconnues en Python, Spark et SQL. Vous avez une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles Vous mettez en place des pratiques de test syst√©matiques pour v√©rifier la qualit√© de votre code. Vous avez la capacit√© √† concevoir et √† mettre en uvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle. Vous avez une premi√®re exp√©rience sur un provider de Cloud, Azure de pr√©f√©rence et ma√Ætrisez la scalabilit√© en temps r√©el (Kafka). Vous comprenez le machine learning. Vous avez un niveau de fran√ßais et d'anglais courant.","TotalEnergies is seeking a Data Engineer to join their Digital Factory team, which is responsible for creating and deploying digital solutions for the company's energy production and supply activities. The successful candidate will ensure the quality of data pipelines, develop programs for collecting, preparing, transforming, and disseminating data, coordinate the implementation of data architecture, and collaborate with data scientists to build prediction models. The ideal candidate should have at least 2 years of experience in data engineering, strong technical skills in Python, Spark, and SQL, and familiarity with relational and non-relational databases and cloud providers (preferably Azure). They should also be able to design and implement large-scale data loading, manipulation, processing, analysis, and exploration solutions, understand real-time scalability, and have a good understanding of machine learning. Fluency in French and English is required.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 1 an,2,1,0.04154662416233763
226,56857,https://www.welcometothejungle.com/fr/companies/ekimetrics/jobs/data-engineering-architect-h-f-n-paris_paris,Data Engineering Architect /N) - Paris,Ekimetrics,"{precisely,durable,GCP,regard,color,pilot,AWS,scale,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,"36, Rue La Fayette, Paris, 75009","IT / Digital, Strat√©gie, Audit, Big Data",CDI,2023-03-26,"Ekimetrics est leader en data science et fournisseur de solutions AI. Depuis plus de 16 ans, nous utilisons de performance marketing, business et de la transition vers une performance plus durable. Notre obsession : r√©concilier gains business √† court terme et cr√©ation de valeur √† long terme. Nous sommes une entreprise ind√©pendante parmi les plus importantes dans le monde avec plus 400 experts data, sur trois continents : Europe, Am√©riques et Asie. Depuis 2006, nous avons men√© plus de 1000 projets data science dans plus de 50 pays, g√©n√©rant milliard de profit pour nos clients. Ekimetrics a pour ambition repenser la mani√®re dont elles op√®rent, en r√©conciliant indicateurs financiers et objectifs durables gr√¢ce √† la data. Nous d√©veloppons des solutions d‚ÄôIA et data science garantissant √† nos clients des optimisations √† fort impact, align√©es avec leur strat√©gie de marque et leurs enjeux de durabilit√© Quelques chiffres cl√©s : 16 ann√©es d‚Äôexp√©rience en Data Science +400 data scientists 4 bureaux √† Paris, Londres, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1M de profit g√©n√©r√© pour nos clients depuis 2006 +1000 projets Data Science Ekimetrics is the European leader in data science with +320 data scientists and +1,000 projects since 2006. Thanks to our global presence in Paris, London, NY, HK, we lead projects in +50 countries in all industries (automotive, financial services, retail, telecom, health, etc.). We help companies steer their data opportunity, build data capabilities , and deploy actionable solutions , to power up marketing and operational performance , as well as (re)energizing business models . Our primary focus is to deliver immediate business gains , while guaranteeing sustainable data capital for our clients. We are committed to the most advanced data science, and to building fair and conscious data & AI practices . Key figures: 16 years experience in Data Science +320 consultants, all are also data scientists 4 offices in Paris, London, New York & Hong Kong +350 clients (CAC40, Fortune500) +$1Bn profit generated for our clients since our creation +1,000 Data Science clients projects Data Architecture & Engineering team To help operationalize our data science projects among business lines, actively contribute to the transformation of our clients‚Äô infrastructure and organization, and democratize data driven approaches, we have created a department for data architecture and data engineering. This team is at the core of the ability to industrialize data science and build the environments to scale while supporting wider user access to analytics. By combining our expertise on data analytics with technical expertise, the team builds environments and processes to enable live production systems integrated into our clients‚Äô IT systems, with adequate levels of architecture, governance, security, scalability, maintainability, and resilience. Our Data Architecture & Engineering team consists in Architects, Data Engineers and DevOps Engineers. We are passionate about data processing, data quality and eager to solve data-centric issues. We love sharing our expertise, teach and enjoy our craft. Job responsibilities As a Data Architect, you will be involved in challenging projects with international blue-chip clients across diverse industries, building bespoke analytics solutions to answer the key questions and consulting on the findings, including high-profile presentations to senior clients. You will be working in teams, with other consultants (data scientists, data engineers or web developers) on 1 or 2 projects simultaneously. More precisely, your responsibilities will include: 1. Data Architecture & Innovation ¬∑ Lead assessments, strategies, and architecture recommendations ¬∑ Own the full cycle of the industrialization of data projects, from advisory to audit and review activities, with customers interactions ranging from technical teams to CIOs ¬∑ Be responsible for the data engineering code organization as well as data modelling approaches. The Data Architect will contribute to these topics with the other Lead Data Engineers (Governance, DevOps, etc.) ¬∑ Present actionable and easy-to-understand recommendations to drive high levels of adoption within client organizations ¬∑ Acting internally as an innovator and technical lead: we are continuously building engineered and enriched technical custom solutions for our clients 2. People Development ¬∑ Proactively contribute to the development of more junior team members, for them to have stronger impact across core all areas of the clients‚Äô businesses ¬∑ Share projects and practices within the team and more generally within Ekimetrics, be an ambassador one of our values: Transmission ¬∑ Participate and create/give technical trainings withing our internal training program Eki. Academy ¬∑ Contribute to the recruitment of new Data Engineers, Data Architects and therefore to the growth of the team 3. Business Management & Consulting ¬∑ Design and scope new projects, using the right analyses to answer client questions ¬∑ Participate in pre-sales of Ekimetrics projects, ¬∑ Deliver with excellence ‚Äì ensure high client satisfaction and make sure that issues are raised and resolved in a timely manner with no surprises ¬∑ Ensure client's business case is achievable and Ekimetrics has appropriate ability to influence promised outcomes ¬∑ Drive high client value and broaden relationships at the most senior levels with current and prospective clients and translate this into new business opportunities for Ekimetrics. ¬∑ Evangelising externally the innovative business solutions we offer to our clients by participating in thematic conferences or other specific tech exhibitions/events Candidate‚Äôs profile Qualifications The successful candidate will have a minimum of 8-10 years of professional background, with a proven expertise in both BI and Big Data architectures, either on-prem or in the Cloud. While working closely with the other members of the Data Engineering team, you will need to be autonomous enough to handle all meetings with customers on data architecture topics. The successful candidate will also prove a balance of business strategy understanding, client-facing consulting experience, and significant data and analytics expertise. The work will be rooted in the creation of innovative analytic engagements for clients. Technical skills ¬∑ A Ph.D. or Master's degree in a quantitative discipline such as computer science, statistics, applied mathematics from a leading academic institution is preferred ¬∑ 8+ years of experience in Data Analysis / Data Architectures / DWH / Data Lakes in a business setting, preferably in a client-facing consulting-oriented role ¬∑ Passion for data, extensive knowledge in statistics or applied mathematics, experience with techniques such as Machine Learning ¬∑ Expertise in key technologies related to Data Management: o SQL, Spark, Python, o Cloud platforms (Azure, GCP, AWS, etc.) ¬∑ Expertise in some aspects of Data Management and readiness to grow in the others: o Data analytics architectures o Data governance processes and platforms o Data ingestion & transformation in data-warehouses or data-lakes o Data visualization Soft skills ¬∑ Excellent communication skills ‚Äì especially translating complex technical findings into plain language insights and stories for stakeholders ¬∑ Demonstrated ability to develop new and lasting client relationships at senior levels across multiple industries ¬∑ Team oriented and collaborative working style, both with clients and within Ekimetrics ¬∑ Management experience and demonstrated ability to develop younger talent and build a high performing team. ¬∑ Project management and delivery expertise ¬∑ Passion for joining a small team and desire to help the business grow quickly What we offer For the first time Ekimetrics is certified Great Place to Work ! ¬∑ Competitive package in a data science company ¬∑ Challenging, diverse and complex missions with an early client exposure ¬∑ Creative and entrepreneurial start-up environment with vertical mobility ¬∑ A unique learning experience: You will be the pilot of your own career development ¬∑ A culture of Innovation and Knowledge ¬∑ International mobility opportunities that help boost your career. Ekimetrics is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or other legally protected categories, subject to applicable law.","Ekimetrics, a leader in data science and AI solutions, is seeking a Data Architect with 8-10 years of experience in BI and Big Data architectures. The successful candidate will be responsible for leading assessments, strategies, and architecture recommendations, developing data engineering code organization, presenting recommendations to drive high levels of adoption within client organizations, and contributing to the development of more junior team members. Additionally, the candidate should have expertise in data management technologies such as SQL, Spark, and Python, and possess excellent communication and team-working skills. The job offers a competitive package and international mobility opportunities.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 7 ans,2,1,0.04154662416233763
351,37262,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/data-engineer-h-f_wasquehal_EF_RgN1Kwp,Data Engineer,EPSILON France,"{Talend,EPSILON,Informatica,Spark,SQL,Python,marquez}",T√©l√©travail partiel possible,N,"Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2022-10-18,"EPSILON France est l‚Äôagence data Marketing du Groupe Publicis. Elle accompagne la transformation business des entreprises gr√¢ce √† la data, au marketing et √† la technologie. C‚Äôest le plus grand acteur datamarketing en France, avec 750 talents : Data Scientists, Digital Marketers, IT Experts, Business Analysts qui aident les entreprises √† stimuler leur croissance et am√©liorer leur efficacit√© op√©rationnelle gr√¢ce et autour de la data. Toute notre √©quipe Data vous attendent ! Le p√¥le Data Management est constitu√© de 60 passionn√©s et experts et de la data. Le p√¥le est en charge d‚Äôune dizaine de plateformes data internationales et couvrant l‚Äôensemble de use cases CRM et Data Marketing. Sa mission : mettre en place des solutions et plateformes permettant aux clients de valoriser, exploiter et produire leurs donn√©es CRM. Au sein d‚Äôune √©quipe d√©di√©e √† un client grand compte international vous pourrez travailler sur de la mise en place de processus de data flow ou l‚Äô√©criture de programmes de calcul d‚Äôindicateurs m√©tiers et business. Que fait un Data Engineer ? Analyser les demandes fonctionnelles des clients. Sp√©cifier techniquement les besoins du client en collaboration avec le chef de projet fonctionnel. R√©diger les sp√©cifications techniques associ√©es. D√©velopper les traitements, proc√©dures et flux. R√©aliser et formaliser les tests techniques, Optimiser les traitements, proc√©dures et flux Installer et d√©ployer les d√©veloppements en production Vous marquez des points si : Vous √™tes un expert du d√©veloppement sur SQL, et avez une exp√©rience d‚Äôau moins 2 ans en tant que Data Engineer ou d√©veloppeur ETL. Vous ma√Ætrisez un (ou plusieurs) ETL : Informatica, Datastage, Talend ou Stambia ‚Ä¶ Votre plus : Une premi√®re exp√©rience sur Spark et Python ! Ce qu‚Äôon attend de vous : Bon esprit d‚Äô√©quipe. App√©tence prononc√©e pour les nouvelles technologies (Big Data, Cloud...).","EPSILON France is seeking a Data Engineer who will analyze functional client requests and specifications. They must have at least 2 years of experience in SQL development and be proficient in one or more ETL tools such as Informatica, Datastage, Talend or Stambia. A passion for new technologies such as Big Data and Cloud is also expected.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
348,58084,https://www.welcometothejungle.com/fr/companies/groupe-credit-agricole/jobs/data-engineer-h-f_guyancourt,Data Engineer,Groupe Cr√©dit Agricole,"{Jenkins,Talend,unix,Informatica,via,Git,SQL}",T√©l√©travail partiel possible,"Boulevard des ch√™nes, Guyancourt, 78280","Banque, Assurance",CDI,2023-03-26,"Filiale du groupe Cr√©dit Agricole, Cr√©dit Agricole Payment Services, leader des services de paiement en France avec pr√®s de 30% de part de march√©, con√ßoit des solutions de paiement destin√©es aux entit√©s du groupe. Au c≈ìur de la relation client, les paiements font partie des usages quotidiens et √©voluent sur un march√© dynamique en perp√©tuelle transformation. Pilote de la strat√©gie paiement du Groupe, Cr√©dit Agricole Payment Services con√ßoit le processing des transactions r√©alis√©es par les clients des banques du groupe et d√©veloppe pour eux des offres de services innovantes, conjuguant facilit√© d‚Äôusage, s√©curit√© et r√©pondant aux meilleurs standards du march√©. En tant qu‚Äôing√©nieur data au sein du p√¥le Data Engineering, vous aurez pour principales missions : 1. La prise en charge de la cha√Æne CI / CD Conception / Param√©trage / Pilotage et suivi de l‚Äôimpl√©mentation Int√©gration de la cha√Æne dans les processus existants Accompagnement du changement aupr√®s des utilisateurs 2. Le d√©veloppement de traitements de flux de donn√©es Conception g√©n√©rique, d√©veloppement ETL (dans un premier temps sur les outils on premise puis √©volution vers les fonctionnalit√©s natives des cloud providers) Maintenance et √©volutions applicatives Int√©gration et suivi de bout en bout via la cha√Æne CI/CD 3. D‚Äôassurer la qualit√© et le fonctionnement de la plateforme Data Suivi de la production, gestion et analyse des incidents R√©daction de mode op√©ratoire, documentation de production Support N2 Ce poste est soumis √† un r√©gime d‚Äôastreinte de nuit et week-end ainsi qu‚Äô√† des interventions ponctuelles et planifi√©es de nuit, week-end et jours f√©ri√©s. Pourquoi nous rejoindre ? CAPS est une entreprise dynamique , port√©e par les innovations technologiques De nombreuses opportunit√©s professionnelles vous attendent chez CAPS et au sein du Groupe CA Vous b√©n√©ficiez √©galement d‚Äôun plan de formation et de d√©veloppement adapt√© √† vos besoins Au sein de nos diff√©rents Campus , de nombreux services vous facilitent le quotidien : conciergerie, espaces de travail collaboratifs, choix de restauration vari√©s, √©quipements digitaux, parkings‚Ä¶ Agir chaque jour dans l‚Äôint√©r√™t de nos collaborateurs et de la soci√©t√©, cela signifie aussi √™tre attentifs aux sujets de mixit√©, de handicap, d‚Äôengagement solidaire, autant d‚Äôaxes forts de notre politique RSE et facteurs de performance et d‚Äôinnovation. Quelques raisons suppl√©mentaires‚Ä¶ Un package de r√©mun√©ration attractif (primes sur objectifs, int√©ressement et participation) De nombreux avantages sociaux (CSE, offre bancaire groupe, remboursement des transports √† 90% etc.) 2 jours de t√©l√©travail par semaine en moyenne Un partenariat avec Vivrou.com pour aider nos (futurs) collaborateurs √† trouver leur lieu de vie id√©al. Formation : Bac +5 / M2 - Sp√©cialisation Ing√©nieur, Business Intelligence, Data Exp√©rience : 6 √† 10 ans d‚Äôexp√©rience dont 5 ans dans des fonctions similaires Comp√©tences : Programmation avan√ß√©e (algorithmique / conception de mod√®les de donn√©es) M√©thodologie projet (Agile + Bout en bout / CI CD) Connaissances fonctionnelles des paiements (mon√©tiques, fiduciaire, flux) serait un plus Capacit√© √† r√©aliser des conceptions d√©taill√©es de traitements et √† concevoir des traitements g√©n√©riques Monitoring et suivi d‚Äôenvironnements multiples (dev, int√©gration, homologation, production) Autonomie et sens de l‚Äôinitiative Outils informatiques : Excellente ma√Ætrise d‚Äôun outil ETL (Datastage, Informatica, Talend) Excellente ma√Ætrise des Syst√®mes de gestion de base de donn√©es (Vertica serait un plus) Tr√®s bonne ma√Ætrise du langage SQL, environnement de travail citrix & unix, Jenkins, Ansible & Git Langues : Anglais courant Notre processus de recrutement comprend deux entretiens (manag√©rial, RH associ√© √† un questionnaire de personnalit√©), avec la possibilit√© d‚Äôun √©change suppl√©mentaire.","The Credit Agricole Payment Services is seeking an experienced Data Engineer with advanced programming skills, project methodology, and knowledge of payment functions. The candidate is responsible for the design of processing transactions and the development of innovative payment solutions. The successful candidate should have experience with ETL development, monitoring, and overseeing multiple environments. The role requires autonomy, initiative, excellent technical skills using tools like Unix, Jenkins, Git, and Datastage, and good written and verbal communication in English. The position will work within an environment that requires night and weekend shifts, but it also offers attractive remuneration, benefits, training, and opportunities for professional growth.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
346,57023,https://www.welcometothejungle.com/fr/companies/ergoss-logiciels/jobs/flight-data-analyst-engineer_blagnac,Flight Data Analyst Engineer,Ergoss Logiciels,{},T√©l√©travail partiel possible,"3, Rue des Charrons, Blagnac, 31700","Logiciels, A√©ronautique / Spatiale",CDI,2023-03-26,"Cr√©√©e en 2009, l‚Äôentreprise a gard√© son esprit de start-up qui lui a permis de devenir le leader mondial des solutions innovantes dans le domaine de l‚Äôanalyse et du suivi des donn√©es de vol. Ergoss a une petite √©quipe au mode de fonctionnement unique pour maintenir cr√©ativit√© et flexibilit√©, et c‚Äôest ce qui a permis de percer et de devenir un challenger s√©rieux face aux grandes entreprises. En dix ans, l‚Äôentreprise a r√©ussi √† bousculer un march√© jusque-l√† tr√®s √©tabli en d√©poussi√©rant des id√©es et des concepts en place depuis plusieurs d√©cennies. Missions : Decode flight data recorders logical frames layout Develop encoded logics to detect deviations from standard and airlines procedures Respond to specific requests of airlines Flight Safety Officers Insure support of level 1 & 2 Produce training documentations & supports Conduct Training sessions for customers (at customers premises) and internal needs. Innovate on flight safety indicators & follow up methodologies Ressources / skills : Engineering degree in aeronautics Deep knowledge on aircraft operations and performances. Familiar with programming methodes and Ability to use different type of programming languages.","Ergoss, world leader in innovative solutions for flight data analysis, seeks an engineer with an aeronautics degree who can develop encoded logics, detect deviations from standard airline procedures, support Level 1 & 2, produce training materials, conduct training sessions for customers, and innovate on flight safety indicators. The ideal candidate has deep knowledge of aircraft operations, familiarity with programming methods, and the ability to use different programming languages.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
343,56454,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-data-science_paris,Software Engineer - Data Science,Datadog,"{Java,Go,Flink,color,Scala,anomaly,scale,Spark,Datadog,Python}",T√©l√©travail partiel possible,"21 Rue de Ch√¢teaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. The Data Science team designs and builds algorithmically driven features in the Datadog app. We work across a range of applications, primarily focusing on analysis on streaming data such as anomaly detection , error outliers and faulty deployment analysis . As a Software Engineer on the Data Science team, you will design, build and scale the backend systems that power our growing suite of Watchdog products . You will be working on large-scale distributed systems, horizontally-scalable datastores and a variety of data-processing frameworks to build our next-generation platform and capabilities for Data Science at Datadog. At Datadog, we place value in our office culture - the relationships that it builds, the creativity it brings to the table, and the collaboration of being together. We operate as a hybrid workplace to ensure our employees can create a work-life harmony that best fits them. What You‚Äôll Do: Build common services and components encapsulating data science capabilities for other products and teams to leverage Enable new capabilities for our core products by integrating and preprocessing data from tens of sources and preparing it for incorporation into data science models Ensure that our data science-driven features continue to scale well as Datadog adds more customers and ingests more data per customer Leverage modern tools and frameworks to improve the performance and cost-efficiency of data science services Join an amazing team of data scientists and software engineers building a product that our customers love to use Work all over the stack, moving fluidly between programming languages and technologies Who You Are: You have experience working in Python, Java, Scala or Go You have experience working with microservices and/or distributed systems You value simplicity and getting the right things done (Senior Level) You have built high-volume data pipelines (Senior Level) You have expertise in Python, Go or Scala and are familiar with Spark or Flink Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you‚Äôre passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: Competitive global benefits New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Opportunity to collaborate closely with colleagues across the Datadog offices in New York City and Paris Opportunity to attend and present at conferences and meetups Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-ER1 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog‚Äôs Applicant and Candidate Privacy Notice .","Datadog, a cloud application monitoring and security platform, is seeking a Software Engineer to join their Data Science team to design and scale the backend systems for their suite of Watchdog products. Candidates should have experience in Python, Java, Scala, or Go, as well as microservices and distributed systems. The company emphasizes a hybrid workplace and values people from diverse backgrounds. Benefits include global benefits, stock equity plans, and opportunities for professional development and networking.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
340,57071,https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-confirme-aws-h-f-lyon_lyon_EVOTE_6Lm3QY3,Data Engineer (H-F) - Lyon,evoteo,"{Glue,Hive,Azure,Docker,scala,Databricks,PowerBI,Python,ElasticSearch,Jenkins,AWS,Hadoop,SQL,Yarn,Flume,S3,Spark,Pig,GIT}",T√©l√©travail partiel possible,"23, Rue Cr√©pet, Lyon, 69007","Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-03-26,"evoteo est une entreprise de prestation sp√©cialis√©e en #DATA. L‚Äô√©volution des structures, √©tablies depuis plusieurs ann√©es, voire plusieurs d√©cennies, est en marche et evoteo accompagne ses partenaires pour y faire face. Les √©quipes d‚Äôevoteo sont compos√©es d‚Äôing√©nieurs, de chefs de projets et de transformations managers tous passionn√©s par ce changement technologique. La r√©ussite de l‚Äôentreprise repose sur un management de carri√®re simple et efficace de ses collaborateurs dont les axes principaux sont : L‚Äô√©volution La curiosit√© L‚Äôexigence La collaboration Dans le cadre de notre expansion ambitieuse mais contr√¥l√©e, et pour satisfaire aux besoins changeants de tous nos clients, nous recherchons une/un Data Engineer pour renforcer nos √©quipes. Mission Dans le cadre du projet de migration de notre client, de leur ancien syst√®me BI vers leur nouvel √©cosyst√®me Lakehouse (Discover) sur Databricks / AWS, nous sommes √† la recherche d‚Äôune personne qui peut g√©rer : La r√©cup√©ration (et surtout la refonte) de leur mod√®le de donn√©es pour qu‚Äôil soit la base de leurs futurs cas d‚Äôutilisation des donn√©es (refonte des proc√©dures SQL Server de Side vers des travaux Databricks en Python / SQL / Spark). La migration des tableaux de bord PowerBI ainsi que la refonte de leur mod√®le pour les simplifier, en les source sur le Lakehouse au lieu de Side. La refonte des rapports SSRS vers des tableaux de bord Databricks pour les rapports op√©rationnels. La r√©cup√©ration des exports (principalement des fichiers CSV) g√©r√©s par Side aujourd‚Äôhui. La dur√©e de ce projet devrait s‚Äô√©taler sur 2023-2024. Nous recherchons avant tout des personnalit√©s : curieuses, habiles, sociales, adaptables et passionn√©es. De formation BAC+5 (Master 2,DESS,DEA), formation ing√©nieure ou informatique, tu as une exp√©rience d‚Äôau moins 2 ans en engineering des environnements Big #DATA Les technos: D√©veloppement : Spark (scala), Python Int√©gration continue : GIT, Maven, Jenkins, Ansible, Docker Technologies Big #DATA (Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch) Cloud AWS : S3, Glue, ECS Cloud Azure Nous insistons sur les comp√©tences Spark. Ce poste en CDI est √† pourvoir d√®s que possible sur la r√©gion lyonnaise. Tu √™tes un futur collaborateur acteur, en qu√™te de perspectives d‚Äô√©volution, capable de rigueur et d‚Äôesprit d‚Äôanalyse ? Rejoins-nous ! Comme √©voqu√©, nous aimons les choses simples - envois-nous ta page Linkedin ou bien un CV, ensuite nous te proposerons: Un √©change t√©l√©phonique permettant de cibler au mieux tes souhaits Un entretien de d√©couverte mutuelle afin de savoir si nous avons envie de travailler ensemble Tu reviens vers nous si tu es int√©ress√© pour un dernier √©change avec le PDG afin de partager la vison, parler de te carri√®re et valider ta candidature.","evoteo is seeking a Data Engineer for their expansion. The candidate should have at least 2 years of experience in engineering Big Data environments and possess skills in Spark, Python, GIT, Maven, Jenkins, Ansible, Docker, Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch, Cloud AWS and Cloud Azure. The job entails working on the migration of clients' BI system to their new Lakehouse ecosystem, requiring data recovery and rebuilding, migration of dashboards, reports, and exports over a period of 2023-2024. The company is looking for curious, adaptable, and passionate candidates who can handle the changing needs of clients. Candidates interested in this full-time position can send their LinkedIn page or CV for the first stage of selection.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
336,60320,https://www.welcometothejungle.com/fr/companies/totalenergies/jobs/data-scientists-ml-engineers-h-f_paris-02_TDF_KjX50w0,Data Scientists- ML Engineers,TotalEnergies Digital Factory,"{Databricks,DataBricks,AWS,Azure,Python}",T√©l√©travail total possible,"Rue des jeuneurs, Paris 02, 75002","Logiciels, Big Data, Energie",CDI,2023-03-28,"TotalEnergies est une compagnie multi-√©nergies mondiale de production et de fourniture d'√©nergies : p√©trole et biocarburants, gaz naturel et gaz verts, renouvelables et √©lectricit√©. La Digital Factory de TotalEnergies est compos√©e de 300 personnes, 30 Squads, 39% de femmes et 25 nationalit√©s. Elle offre un environnement de travail international et interculturel en plein c≈ìur de Paris, engag√© dans la diversit√© et l'inclusion. Elle permet d' acc√©l√©rer la production interne de solutions digitales pour les activit√©s de la Compagnie dans les 130 pays o√π elle est pr√©sente. Elle allie l' agilit√© et l' esprit pionnier d'une entreprise technologique √† la robustesse et √† la rigueur d'une entit√© de production √† grande √©chelle. Elle cr√©e et d√©ploie des solutions digitales sur l'ensemble des sites de la compagnie TotalEnergies afin de fournir une √©nergie propre, fiable et abordable au plus grand nombre. En accord avec les politiques HSE de la Compagnie et de la TotalEnergies Digital Factory, le/la Data Scientist / Machine Learning Engineer a pour r√¥le de soutenir la Squad en cr√©ant des mod√®les utilisant des diagnostics analytiques avanc√©s. R√¥le : analyser des quantit√©s massives de donn√©es structur√©es ou non structur√©es afin d'aider √† la compr√©hension et √† la prise de d√©cisions. S√©lectionner des techniques d'analyse et des outils de mod√©lisation, construire des mod√®les, les d√©ployer et √©valuer les r√©sultats et les performances. Missions : Appliquer les statistiques, le machine learning et les approches analytiques pour r√©soudre les probl√®mes business Construire des algorithmes de machine learning industrialisables Conduire des projets de Machine Learning de la conception au d√©ploiement (id√©ation, conception des pipelines MLOps, gestion du cycle de vie des mod√®les en production...) Transformer les volumes de big data en informations utiles et exploitables G√©rer le cadrage et la livraison des cas d'utilisation Contribuer √† la formation et √† l'animation de la communaut√© globale de la Data Science chez TotalEnergies. Vous √™tes dipl√¥m√©(e) en Master ou √©cole d'ing√©nieur sp√©cialis√©e en statistiques, datamining ou math√©matiques Vous avez au moins 5 ans d'exp√©rience dans la mise en production d'algorithmes de Machine Learning Vous ma√Ætrisez Python, DataBricks, AMLS... Vous connaissez les meilleures pratiques du d√©veloppement et du codage Vous √™tes capable de tester des hypoth√®ses √† partir d'ensemble de donn√©es brutes et d'analyser les r√©sultats Une exp√©rience dans un contexte industriel serait appr√©ci√©e (logistique, gestion de stocks, maintenance industrielle, analyse de donn√©es de capteurs, analyse et mod√©lisation de proc√©d√©s). Votre niveau d'anglais est courant. Ce que nous t'offrons : Le d√©veloppement de tes comp√©tences avec le support de la Digital Academy et une enveloppe √©quivalente √† 10 jours de formations par an que tu peux choisir en toute autonomie. La possibilit√© de te certifier AWS et Azure, Databricks... Un programme de mentorat. Un √©quilibre vie professionnelle et vie personnelle avec le recours possible aux horaires flexibles et au t√©l√©travail.","The TotalEnergies Digital Factory in Paris is seeking a Data Scientist/Machine Learning Engineer to analyze vast amounts of structured and unstructured data to aid in decision-making. The role involves selecting analysis techniques and modeling tools, building and evaluating models, and deploying them to create useful information from big data. The successful candidate will have a master's degree in statistics, datamining or mathematics, at least five years of experience in ML algorithm deployment, and proficiency in Python, DataBricks, and AMLS, among others. An industry background would be advantageous, and fluency in English is essential. The company offers flexible working hours and telecommuting options, as well as training opportunities and mentorship programs.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,3,0,0.04154662416233763
335,60264,https://www.welcometothejungle.com/fr/companies/infinity-advertising/jobs/data-engineer_paris,Data engineer,Infinity Advertising,"{GCP,SQL,Python}",T√©l√©travail partiel possible,"5 Rue des Italiens, Paris, 75009","Digital Marketing / Data Marketing, Big Data, Digital",CDI,2023-03-28,"// LA SOCIETE Le groupe Casino et Intermarch√© ont cr√©√© ¬´ Infinity Advertising ¬ª, soci√©t√© commune charg√©e de commercialiser en France une offre Retail Media aupr√®s des marques et de leurs agences, en dehors de toute n√©gociation √† l‚Äôachat, et dans le respect des r√®gles relatives √† la protection des donn√©es personnelles et du droit de la concurrence. Le Retail Media est LE canal publicitaire actuellement en vogue. A la pointe de l‚Äôinnovation, les analystes tels que Forrester pr√©voient qu‚Äôaux Etats-Unis les investissements dans ce m√©dia vont, d√®s 2025, d√©passer ceux r√©alis√©s dans la publicit√© t√©l√©vis√©e. Infinity Advertising a ainsi pour mission de commercialiser tout un √©ventail de solutions publicitaires digitales sur les sites Intermarch√©, Casino, Monoprix et Franprix mais aussi sur des sites externes en ciblant finement les personnes expos√©es gr√¢ce aux bases de donn√©es constitu√©es par les habitudes d‚Äôachats des 17 millions de porteurs de cartes fid√©lit√©s de ces enseignes. Cr√©√© en 2021, Infinity Advertising conna√Æt une forte croissance et appr√©hende l‚Äôavenir sous les meilleurs auspices gr√¢ce √† sa capitalisation sur une offre tr√®s compl√®te. L‚Äôentreprise est aujourd‚Äôhui forte d‚Äôune cinquantaine de collaborateurs. // POSTE & MISSIONS La data est au c≈ìur de notre m√©tier car elle structure totalement notre offre produit. Le Data Engineer a vocation √† assurer la responsabilit√© de la structuration et de la mise √† disposition de cette donn√©e aux utilisateurs. Rattach√©(e) √† notre CTO, tu auras l‚Äôopportunit√© de collaborer avec l‚Äôensemble des √©quipes op√©rationnelles et techniques de l‚Äôentreprise. Tu travailleras en mode projet agile pour apporter des r√©ponses aux challenges techniques dans un contexte cloud et Big Data. Tes missions : ‚óè D√©velopper et maintenir un syst√®me de traitement de donn√©es √† grande √©chelle. ‚óã Aider √† concevoir, construire et maintenir notre architecture de donn√©es. ‚óã S‚Äôassurer que les pipelines construits prendront en charge les flux de donn√©es √† volume √©lev√©. ‚óã Les d√©velopper pour extraire, transformer et charger des donn√©es √† partir de sources vari√©es. ‚óè Optimiser les performances et la qualit√© des donn√©es. ‚óã D√©tecter les opportunit√©s d‚Äôacquisition, de stockage et d‚Äôinterrogation de donn√©es de mani√®re performante. ‚óã Optimiser la performance de nos bases de donn√©es et des pipelines de donn√©es existants. ‚óã Effectuer des tests de qualit√© pour garantir l‚Äôint√©grit√© et la pr√©cision des donn√©es. ‚óè Collaboration ‚óã Avec les data analysts pour identifier les besoins en mati√®re de donn√©es. ‚óã Avec le devops pour structurer et maintenir l‚Äôarchitecture de donn√©es. ‚óã Avec les utilisateurs pour effectuer des tests de qualit√© pour garantir l‚Äôint√©grit√© et la pr√©cision des donn√©es. // PROFIL ‚óè Exp√©rience similaire. ‚óè Tu ma√Ætrises SQL et Python. ‚óè Exp√©rience notable dans un contexte GCP : BQ, DataProc, CF, etc‚Ä¶ Une certification sera un plus. ‚óè Tu aimes le travail cross team et tu as envie de comprendre les enjeux business majeurs. ‚óè Dynamique et d√©brouillard(e), tu es polyvalent(e) et tu sais faire preuve d‚Äôinitiative. // LES AVANTAGES : ‚óè D√©velopper tes comp√©tences et tes connaissances dans le secteur des produits de grande consommation et du Retail Media ‚óè Rejoindre une √©quipe motiv√©e, dans un esprit start-up, dans une structure en cours de cr√©ation, et pour autant solide et reconnue sur le march√©, gr√¢ce √† l‚Äôappui de deux grands acteurs de la grande distribution ‚óè Travailler dans un cadre sympathique : locaux dans le centre de Paris, avec acc√®s rooftop, babyfoot, billard, salle de karaok√©, tickets restaurants‚Ä¶ // INFORMATIONS COMPL√âMENTAIRES ‚óè Type de contrat : CDI ‚óè Localisation : Paris 9e ‚Äì Op√©ra ‚óè Disponibilit√© : date de d√©marrage √† discuter avec le (la) candidat(e) retenu(e) ‚óè R√©mun√©ration : A d√©finir selon exp√©rience ‚óè Contact : recrutement@infinity-advertising.fr","Infinity Advertising, a joint venture by Casino and Intermarch√©, seeks a Data Engineer to develop and maintain a large-scale data processing system. The ideal candidate should have experience with SQL and Python, and notable experience in a GCP context. The position offers the opportunity to work in an agile project mode for cloud and big data challenges. The role involves collaborating with data analysts and devops to structure and maintain the architecture and optimize data performance. Infinity Advertising offers a competitive salary and benefits package and a pleasant work environment in the heart of Paris.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
331,34394,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-paris-or-remote-france_paris_DATAI_YzOxG4e,Software Engineer Data Visualization - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",T√©l√©travail partiel possible,Paris,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2022-08-08,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,200 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend). - Prototype and create new ways to import and request data at large scale. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with experience in software development and an interest in data visualization tools to create usable, intuitive, and beautiful interfaces for its platform. The ideal candidate should have knowledge of both front-end and back-end development, an understanding of customer needs, and a passion for high-quality code. Dataiku offers a flexible work-life balance, autonomy for its employees, and a caring culture that prioritizes diversity and inclusivity.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
329,49868,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-paris-or-remote-france_paris_DATAI_PjOXK2w,Software Engineer Data Visualization - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",T√©l√©travail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend). - Prototype and create new ways to import and request data at large scale. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a skilled software engineer to create usable, intuitive, and beautiful interfaces and scalable engines for their platform. The ideal candidate should have experience in software development and data visualization tools, be customer-oriented, have experience building real products, and be comfortable with both frontend and backend development. The company's culture is flexible, autonomous, and caring, with an emphasis on diversity and equal opportunity employment practices.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
328,56982,https://www.welcometothejungle.com/fr/companies/spendesk/jobs/analytics-engineer_paris,Analytics Engineer,Spendesk,"{Airflow,Looker,Fivetran,Hightouch,Snowflake,dbt,AWS,Kubernetes,SQL,Python,Tableau}",T√©l√©travail partiel possible,"51 Rue de Londres, Paris, 75008","FinTech / InsurTech, SaaS / Cloud Services",CDI,2023-03-26,"Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remotely. Spendesk believes that people do their best work when they‚Äôre given the freedom to thrive and grow. Being bold, bringing a positive attitude, and taking full ownership are fundamental to their culture. Ready to grow further? Check out their open roles! As Spendesk's customer base grows and our platform scales with new features, the growth of our data team becomes increasingly crucial. We are currently seeking an Analytics Engineer to strengthen the team further. The team is responsible for building the data platform that serves analytics and powers the Spendesk product and internal teams by leveraging data. Our team focuses on gathering data from all sources onto the data platform to build a source of truth and provide the right tooling to teams to access and leverage data in a self-service fashion. As an Analytics Engineer, you will design, develop, and maintain the company's analytics infrastructure, including data pipelines, data warehousing, and data visualization tools to support reporting and analytics needs of the organization. You will advocate and promote best practices at every level, anticipate growth, and be responsible for ensuring the accuracy and integrity of the data that is collected and analysed. As the data team plays a central role at Spendesk, you will work with many stakeholders to identify business opportunities and translate them into technical specifications. You will also collaborate with your teammates (data engineers and ML engineers) to drive projects and achieve objectives as the company and the team continue to grow. Key Responsibilities Collaborate with stakeholders to identify business requirements and translate them into technical specifications. Develop and maintain ETL processes for ingesting and transforming data from various sources. Design and develop data models to support business reporting and analytics needs. Lead data governance initiatives to ensure the accuracy and integrity of the data. Monitor and troubleshoot issues with our infrastructure, including data quality, ETL processes, and data pipelines. Promote and encourage the use of data by evangelizing and enabling self-service data capabilities. Stay up-to-date with the latest developments in data technology and provide recommendations for improving our analytics capabilities. Actively participate in the data team's routines and enhancement plans. Who we are looking for: You should have at least 1-2 years of experience in analytics engineering, business intelligence, or a similar role. Strong proficiency in SQL and knowledge of database design, optimization, and maintenance. Experience with data modeling, ETL processes, and data warehousing. Familiar with BI tools such as Looker, Tableau or Power BI. Familiar with job orchestrators or scheduling tools like Airflow. Strong problem-solving skills and the ability to work independently. Demonstrating the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. Our Stack Snowflake, dbt, Looker, Segment, Fivetran, Hightouch, Python, Airflow, AWS, Kubernetes As we are an international team, please submit your application and CV in English. About Spendesk Spendesk is the 7-in-1 spending solution built for finance teams to make faster, smarter spending decisions. Founded in 2016, Spendesk is now one of the fastest-growing fintechs in Europe, with over 4,000 customers and an international team of 500+ employees based in Paris, Berlin, London, Hamburg, and remote. We‚Äôve raised over ‚Ç¨260M from leading investors, and been named a French tech unicorn. And we‚Äôre not stopping there! About our people & culture We believe that people do their best work when they‚Äôre given the freedom to thrive and grow. That‚Äôs why liberation is at the core of everything we do. We empower Spendeskers to take ownership of their work, to navigate ambiguity, and seize every opportunity. Spendeskers come from all over the world (35+ countries and counting!) but we have plenty in common: we're bold, ever-curious, committed to kindness, and tackle every challenge with a positive mindset. About our benefits Our culture is built on trust, empowerment, and growth ‚Äî with benefits to match! - Lunch 60% funded by Spendesk (Swile Card) - 11 RTT in 2022 on a pro-rata basis, in addition to your 25 paid holiday days - Alan Premium health insurance - A Gymlib pass to let off steam after a productive day at work - Access to Moka.care for emotional and mental health wellbeing - Access to Vendredi allowing us to change the world - Latest Apple equipment (MacBook Air) - Great office snacks to fuel your day - A positive team to work with daily! Diversity & Inclusion At Spendesk, we're committed to fostering an environment where all differences are encouraged, supported and celebrated. We're building our culture for everyone, with everyone. Our goal is to attract and build a diverse, equal and inclusive team, where everyone feels welcome and we truly embrace and encourage people from all backgrounds to apply.","Spendesk, a fast-growing fintech company in Europe, is looking for an Analytics Engineer to join its data team. The successful candidate will design, develop and maintain the company's analytics infrastructure, including data pipelines and data warehousing, and ensure data accuracy and integrity. Key skills for the role include experience in analytics engineering or business intelligence, strong proficiency in SQL, and experience with data modeling, ETL processes, and BI tools such as Looker, Tableau or Power BI. Spendesk values freedom, ownership, and positive attitude in its employees and offers various benefits, including health insurance and gym memberships.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 1 an,2,1,0.04154662416233763
327,56464,https://www.welcometothejungle.com/fr/companies/canal-group/jobs/cdi-data-engineer-f-h_puteaux,CDI - Data Engineer -,CANAL+ Group,"{Kinesis,DynamoDb,EMR,Scala,Gitlab,Airflow,Lambda,AWS,Snowflake,Spark,Java,Python}",T√©l√©travail partiel possible,"6 Rue Godefroy, Puteaux, 92800","Application mobile, M√©dia, T√©l√©vision / Production audiovisuelle, Publicit√©, Digital",CDI,2023-03-26,"Bienvenue chez CANAL+ Group ! S√©ries, films, documentaires, √©missions, sports, ‚Ä¶Ce qui nous tient √† ‚ù§ c‚Äôest de cr√©er les meilleurs contenus et une exp√©rience immersive : √©motions et sensations garanties ! Et si vous passiez derri√®re l‚Äô√©cran ? Vous trouverez forc√©ment votre place parmi nos 7 500 passionn√©¬∑es dans le monde üåç. Pour √™tre au courant de nos derni√®res actualit√©s, n‚Äôh√©sitez pas √† nous suivre sur LinkedIn et Twitter ! üíª Les √©quipes TECH CANAL+ ? + de 500 expert¬∑es qui d√©nichent les derni√®res technos pour rendre l‚Äôexp√©rience de nos abonn√©¬∑es unique. Un seul mot d‚Äôordre : toujours plus d‚Äôagilit√© et d‚Äôinnovation ! Ok √ßa fait 2 mots‚Ä¶ üòâ üîé Rejoignez notre Direction Data , compos√©e de 50 expertes et experts, ayant une place importante et centrale au sein du groupe. Le but √©tant d‚Äôaccompagner l‚Äôensemble des m√©tiers business (marketing, √©tudes, r√©gie publicitaire‚Ä¶) dans leur quotidien. Vous int√©grerez l‚Äô√©quipe Delivery qui est en charge de toute la collecte, l'enrichissement et la mise √† disposition des diff√©rents types de donn√©es. üåü Notre stack technique : AWS (Lambda, Kinesis, EMR Serverless, DynamoDb et plein d‚Äôautres services AWS), Apache Airflow, Scala, Python, Snowflake, Gitlab et Gitlab CI. üåü Nos supers projets en cours ou √† venir : Data quality : notre √©quipe collecte 1,3 milliard de donn√©es par jour et 400 gigas par heure en moyenne. Dans ce contexte nous devons veiller √† ce que les donn√©es soient de qualit√©, mais aussi disponibles en temps et en heure. La collecte de ces donn√©es va nous permettre, entre autres, de recommander du contenu √† nos abonn√©¬∑es ainsi que la transmission de messages cibl√©s visant au renforcement de leur engagement. üåü Fun facts : Ces donn√©es vont nous permettre de convertir les prospects en abonn√©¬∑es et de les fid√©liser en personnalisant au maximum leurs exp√©riences, mais aussi d‚Äôanalyser l‚Äôimpact de certains √©v√©nements marquants (la signature d‚Äôun nouveau partenaire, la prolongation des droits de diffusion de la F1 ou encore la prolongation de Kylian MBAPPE au PSG) sur le comportement de nos abonn√©¬∑es ! üéØ Votre r√¥le et vos missions : Concevoir, impl√©menter et participer √† l'industrialisation des applications data Comprendre les probl√©matiques en jeu de chaque sujet Travailler en collaboration avec des profils DevOps, Tech Lead et PO Participer aux diff√©rentes guildes mises en place dans des processus d‚Äôam√©lioration continue autour de la Data Gouvernance, des normes et standards de d√©veloppements Description du profil : üèÜ Et si on parlait de vous ? Vous justifiez d‚Äôune exp√©rience de minimum 3 ans en tant que d√©veloppeur/d√©veloppeuse ou ing√©nieur¬∑e data. Vous ma√Ætrisez Scala (ou Java), Spark ou avez justifiez d‚Äôune exp√©rience de d√©veloppement dans un environnement distribu√© et vous avez une exp√©rience sur AWS ou au moins un Cloud provider. Une exp√©rience sur Airflow ou en ‚ÄúInfrastructure as Code‚Äù avec Teraform serait appr√©ci√©e. Vous faites preuve d‚Äôautonomie, appr√©ciez le travail en √©quipe et √™tes force de proposition. Vous avez d√©j√† travaill√© dans un environnement agile Vous √™tes sensible aux concepts de clean code, clean architecture et aux best practices pour la r√©alisation de projets DATA fiables et robustes. Vous avez un bon niveau d‚Äôanglais (lu, √©crit, parl√©) Vous souhaitez rejoindre un grand acteur de l‚Äôunivers des m√©dias ! üéÅ Les + Un abonnement collaborateur CANAL+ pour √™tre incollable sur nos univers ! Des avant-premi√®res de films et s√©ries dans notre salle de cin√©ma Des visites de nos plateaux et des participations √† nos √©missions Participer aux √©v√©nements de notre communaut√© CANAL+ TECH : meetups suivi d‚Äôafterworks, tech week, ‚Ä¶ Participation & Int√©ressement CSE attractif : ch√®ques vacances et no√´l, prime mariage / pacs / naissance, r√©duction billetterie sport / voyages / loisirs, prise en charge d‚Äôune partie de votre abonnement sportif, ‚Ä¶ Disposer d‚Äô1 jour d‚Äôengagement solidaire par an au profit d‚Äôune s√©lection d‚Äôassociations Devenir intrapreneur ou intrapreneuse avec l‚ÄôHack‚Äôcelerator, notre programme d‚Äôincubation interne Et parce que nous voulons vous aider √† vous √©panouir et vous perfectionner : des formations r√©guli√®res, des participations √† des conf√©rences en interne ou en externe ‚Ä¶ ! üè° Et le t√©l√©travail dans tout √ßa ? Vous pourrez en b√©n√©ficier jusqu‚Äô√† 3 jours par semaine ! Et le process ? Un 1er contact t√©l√©phonique avec un tech recruiter + 1 entretien avec le manager, le tech lead et un tech recruiter + 1 test technique + 1 entretien avec notre Directeur Data + 1 rencontre informelle avec l‚Äô√©quipe, environ 3 semaines en tout, en visio ou en physique comme vous le souhaitez ! üëâ Seulement chez CANAL+ √† Puteaux (92).","CANAL+ Group is seeking a Data Engineer with a minimum of 3 years of experience in development or data engineering. The role will involve designing, implementing, and industrializing data applications, working collaboratively with DevOps, Tech Lead, and PO profiles, and participating in various guilds related to data governance and development standards. Proficiency in Scala/Java, Spark, and AWS/Cloud provider is required, while experience with Airflow and Terraform is appreciated. The company offers attractive benefits, including an employee subscription to CANAL+, previews of films and series, and participation in the company's events and training programs. The position is based in Puteaux, France, with the possibility of remote work up to 3 days per week.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
325,56528,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-f-h-cio-cib_paris,Data Engineer Risks  CIO CIB,Natixis,"{scala,java,Jenkins,spark,Scala,via,Spark,Java,Hadoop}",T√©l√©travail partiel possible,"rue de montmartre, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de votre √¢ge, origine, orientation sexuelle, handicap... Au sein du p√¥le CIO CIB (Corporate & Investment Banking), dans le d√©partement Risks, vous rejoignez l'√©quipe DPM/Metrics Services, en tant que data engineer. Vous reportez directement au responsable de l'√©quipe Metrics Services, des √©volutions du composant de l'application ¬´ golden data ¬ª et des PV de Stress Tests. Ce composant est la clef de vo√ªte d'une chaine applicative FO to Risk pilot√©e par le programme SUNRISE. Au quotidien, vous avez pour missions de : Assurer l'√©volution de l'application d√©velopp√©e en spark/scala/java sur plateforme Hadoop dans un contexte projet ; Piloter des sujets multi-syst√®mes (r√©f√©rentiel market data, r√©f√©rentiel instrument, pricers front) ; G√©rer l'industrialisation et la mise en qualit√© des donn√©es ; Faire la coordination avec : les business analyst de l'√©quipe, les autres √©quipes de d√©veloppeurs du programme et les autres √©quipes IT (production applicative, infrastructure, support Hadoop) ; Assurer le support de niveau 2. La stack technique utilis√©e est la suivante : Java, Spark/Scala et Hadoop dans un environnement DevOps. Nous travaillons en m√©thode Agile (SAFe) et vous serez int√©gr√© √† notre communaut√© de data engineers. #MuchMoreThanJustAJob Ce poste est bas√© √† Paris avec la possibilit√© de t√©l√©travailler. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de leur √¢ge, origine, orientation sexuelle, handicap... A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure, vous avez au moins 10 ans d'exp√©rience en tant que data engineer dans le domaine fonctionnel de la finance de march√© (type DSI). Vous maitrisez : * les probl√©matiques d'optimisation de performance et vous proposez des solutions innovantes ; * la mise en place des protocoles de s√©curit√© dans des environnements de d√©veloppement ; * les langages Java et Hadoop ; * les bases du DevOps (int√©gration continue/automatisation, Jenkins, Sonar, XLDeploy, XLRelease ‚Ä¶) ; * la m√©thode Agile (SAFe). Vous √™tes : * passionn√© d'IT et data centric, vous souhaitez d√©velopper une v√©ritable expertise technique sur des projets innovants. Vous maitrisez l'anglais avec un niveau B2 minimum. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis Corporate & Investment Banking is seeking a data engineer to join their team in Paris. The successful candidate will have at least 10 years of experience as a data engineer in the functional domain of market finance and will be responsible for evolving the spark/scala/java application on Hadoop platform, ensuring data quality and coordination with business analysts and other IT teams. Skills required include Java, Hadoop, DevOps, and Agile methodology. The position offers opportunities for career development, training, and social engagement. Natixis is an equal opportunity employer committed to building an inclusive workplace.",Bac +5 / Master,> 2000 salari√©s,> 7 ans,2,1,0.04154662416233763
322,56488,https://www.welcometothejungle.com/fr/companies/la-javaness/jobs/data-engineer_paris_LJ_ArOw53o,Data Engineer,La Javaness,"{Synapse,Hive,Docker,Azure,Dataiku,Athena,Databricks,Talend,Gitlab,Looker,Fivetran,PowerBI,Git,Bash,Kubernetes,AWS,Teradata,Hadoop,SQL,Pandas,Prefect,Airflow,Redshift,HDFS,dbt,R,Spark,Pig,BigQuery,GCP,Python,Tableau}",T√©l√©travail partiel possible,"18, Rue d'Hauteville, Paris, 75010","Logiciels, Intelligence artificielle / Machine Learning",CDI,2023-03-26,"Tu te sens pr√™t √† plonger au c≈ìur de la r√©volution IA ?! En 6 ans, La Javaness s‚Äôest impos√©e comme leader fran√ßais de l‚ÄôIA pour les entreprises (BtoB). Sans tambour ni trompettes (mais avec beaucoup de R&D !), nous avons concentr√© nos forces √† d√©ployer l‚ÄôIntelligence Artificielle √† grande √©chelle au sein d‚Äôorganisations publiques et priv√©es en France et en Europe. Mais pas n‚Äôimporte comment ! Nous croyons en une IA √©thique, responsable, au service des salari√©s et des citoyens europ√©ens. Nous militons pour la souverainet√© des donn√©es et l‚Äôind√©pendance des entreprises europ√©ennes. Pragmatiques et rationnels, nous d√©ployons quotidiennement nos solutions ¬´ pr√™t-IA-porter ¬ª √† un niveau industriel. Nous faisons aussi de la haute couture en d√©veloppant des solutions IA sur-mesure pour r√©pondre aux d√©fis de certains de nos clients. Notre R&D bout sans rel√¢che pour inventer, tester et d√©ployer l‚ÄôIA de demain. En d‚Äôautres termes, dans la boutique de La Javaness, tu trouveras : Conseil data & IA, acc√©l√©ration par le design, d√©veloppement front & back de pointe, d√©fis business dans un joyeux mix exigeant d‚Äôintelligences. Avec ce super cocktail d‚Äôexpertises et de cr√©ativit√©, nous intervenons sur tous les secteurs d‚Äôactivit√© pour cracker les probl√®mes de nos clients ! Comment √ßa marche au quotidien ? 4 labs : Architecture & Ops, IT, Data, Business, travaillent ensemble sur tous les projets afin de concevoir et d√©ployer des solutions compl√®tes et innovantes r√©pondant aux besoins de nos clients. Fort d‚Äôun collectif unique, la Javaness investit sans cesse dans des talents pointus, atypiques et compl√©mentaires qui lui conf√®rent une force de frappe hors norme. Si √ßa te semble une aventure √† ta mesure, c‚Äôest par ici pour nous rejoindre ! En tant que data engineer au sein de La Javaness, tu seras amen√©.e √† effectuer les missions suivantes : Participation aux travaux d‚Äôarchitecture, r√©alisation des benchmarks et accompagnement des choix d‚Äôoutillage et d‚Äôinfrastructure D√©finition et mise en place des pipelines donn√©es, pour les besoins d‚Äôanalytiques et IA Assistance √† la d√©finition et √† la mise en place de dispositifs de gestion de la donn√©e (Data Management) ; Participation et contribution √† la vie d‚Äô√©quipe : R&D, Partage de connaissance, Recrutement, Code review, etc. Dot√©.e de 5 ans d‚Äôexp√©rience dans un r√¥le de data engineer, tu disposes des comp√©tences suivantes : Les bases : Python et son √©cosyst√®me, Pandas, Spark, SQL, Git, Bash, Docker. Tu as d√©j√† travaill√© dans un contexte de volum√©trie importante de donn√©es. Tu fais preuve de synth√®se et de rigueur. Tu poss√®des de bonnes capacit√©s de communication, orales et √©crites. Tu es curieux, avec une forte envie d‚Äôapprendre Tu poss√®des √©galement plusieurs des comp√©tences techniques suivantes : Outils d‚ÄôETL/ELT (Talend, dbt, Fivetran, etc.) √âcosyst√®me Hadoop (HDFS, Hive, Pig, Sqoop, etc.) Outils d‚Äôorchestration et d‚Äôordonnancement (Airflow, Prefect, Oozie, etc.) Outils de reporting (PowerBI, Tableau, Google Looker, Azure Synapse, etc.) Exp√©rience avec les plateformes cloud (AWS, Azure, GCP, IBMCloud, etc.) et leurs outils (Redshift, Athena, BigQuery, etc.) Plateformes pour le stockage et le traitement de la donn√©e (Teradata, Dataiku, Databricks, Snowflakes, etc.) Notions de DevOps (CI/CD, Gitlab CI, Docker, Kubernetes, etc.)","La Javaness, a French leader in AI for businesses, is looking for a data engineer to help with architecture work, define and implement data pipelines, and contribute to the team's R&D, code review, and recruitment. The ideal candidate should have a minimum of 5 years of experience with Python, Pandas, Spark, SQL, Git, Bash, and Docker, and have worked with large volumes of data. They should also possess knowledge of ETL/ELT tools, Hadoop, orchestration and scheduling tools, reporting tools, cloud platforms, data storage and processing platforms, and DevOps concepts.",N,N,N,2,1,0.04154662416233763
318,56435,https://www.welcometothejungle.com/fr/companies/citron/jobs/data-engineer-senior_suresnes,Data Engineer Confirm√©.e,Citron¬Æ,"{Airflow,Glue,AWS,scale,via,Python,Clickhouse}",T√©l√©travail partiel possible,"28, Quai Gallieni, Suresnes, 92150","Logiciels, Big Data, SocialTech / GreenTech",CDI,2023-03-26,"Citron¬Æ est une Proptech qui digitalise le management √©nerg√©tique et technique des entreprises , √† l‚Äôaide de 3 leviers : La plateforme Citron¬Æ Energie , qui centralise, suit et analyse les consommations √©nerg√©tiques des grands parcs immobiliers. D√©velopp√©e en interne, elle optimise le management √©nerg√©tique des b√¢timents , gr√¢ce √† des tableaux de bord ergonomiques et des pr√©conisations d‚Äôactions. La plateforme Citron¬Æ Technique , qui suit et analyse la performance de l‚Äôensemble des syst√®mes pr√©sents dans les b√¢timents (ascenseurs, chaufferies, CTA, etc.). D√©velopp√©e en interne, elle r√©unit tous les acteurs techniques (gestionnaires, prestataires, occupants, propri√©taires, etc.) pour une optimisation de la performance et de la transparence . Des Ing√©nieurs Conseil experts en efficacit√© √©nerg√©tique qui accompagnent les clients dans la d√©tection des gaspillages et d√©finissent des plans d‚Äôactions, en s‚Äôappuyant sur des innovations internes. Citron¬Æ compte plus de 70 collaborateurs et accompagne maintenant plus de 500 clients . Les donn√©es sont un catalyseur cl√© pour une entreprise comme Citron¬Æ qui r√©colte plus de 2 millions de donn√©es par jour ! En tant que Data Engineer ton r√¥le sera d‚Äôint√©grer la team Data Engineering compos√©e de 3 Data Engineers (qui passera √† 6 personnes d‚Äôici 2023) et d‚Äôun Data Engineering Manager dans un contexte agile et en collaboration avec l‚Äô√©quipe Tech et Produit. Le p√©rim√®tre des donn√©es √©nerg√©tiques comprend toutes les donn√©es (de la collecte √† la diffusion des donn√©es aux parties prenantes internes et externes) li√©es au √† la plateforme Technique. Citron¬Æ r√©cup√®re toutes les donn√©es li√©es aux consommations et √† la vie des b√¢timents, notamment les donn√©es de facturation issues des fournisseurs d‚Äô√©nergie (√©lectricit√©, gaz, eau‚Ä¶). Nous collectons aussi des donn√©es depuis les objets connect√©es pr√©sents dans les b√¢timents (sous-compteurs, sondes de temp√©ratures, automates, GTB, etc.) et donn√©es tierces (donn√©es m√©t√©orologique, linky, Gazpar ‚Ä¶) Tu es un.e Data Engineer et recherches une scale-up √† impact environnemental ? N‚Äôh√©site plus, postule ! On a h√¢te d‚Äôavoir ta candidature ! üëá TES MISSIONS.. üí™ Construire les architectures de donn√©es Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, process temps-r√©els, process batch) R√©colter, qualifier, surveiller, transformer et exposer les donn√©es produit et m√©tier Impl√©menter des jobs autour de la data: ingestion/mod√©lisation/transformation/contr√¥le qualit√© et d√©tection d‚Äôanomalies/exposition (APIs, Data Catalog‚Ä¶) Assurer la migration des donn√©es vers les nouveaux environnements Participer √† l‚Äô√©volution de la stack technique (Clickhouse / AWS Glue / Airflow ) et au choix des outils Participer √† la gouvernance de la donn√©e (process, normalisation, MDM) Maintenir et faire √©voluer la CI/CD Data Analyser les donn√©es Analyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Mettre en oeuvre des outils de Business Intelligence et visualisation via Cumul.io TU ES LE MATCH PARFAIT SI‚Ä¶ üéØ Tu es dipl√¥m√©.e d‚Äôune √©cole d‚Äôing√©nieurs Tu poss√®des au moins 2 ans d‚Äôexp√©rience en tant que Data Engineer Tu ma√Ætrises Python Tu as d√©j√† travaill√© sur un environnement AWS Tu as d√©j√† eu une exp√©rience sur Clickhouse Call RH (30mn) Test technique (2h) Double entretien sur site : - Whiteboard avec un Lead Dev et un d√©veloppeur (1h) - Pr√©sentation des plateformes avec notre CTO Adrien (30mn) Culture fit (en visio) avec 2 culture ambassadors (1h)","Citron, a Proptech company, is seeking a Data Engineer to join its Data Engineering team to work on data-related tasks for the Citron platform, including data collection, processing, and analysis. The successful candidate must have at least two years of experience in a similar role, be proficient in Python, have worked with AWS, and have experience with Clickhouse.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
356,37402,https://www.welcometothejungle.com/fr/companies/mantu/jobs/data-engineer_lyon,Data engineer,Mantu,"{Kubernetes,Docker,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,N,"Logiciels, IT / Digital, Organisation / Management",CDI,2022-10-18,"Mantu est un groupe international de conseil et de services aux entreprises et aux entrepreneurs. Il compte plus de 8500 femmes et hommes, de plus de 100 nationalit√©s diff√©rentes, et est pr√©sent sur 5 continents et dans plus de 60 pays. Mantu se tient aux c√¥t√©s des entreprises et des entrepreneurs pour accomplir leurs r√™ves, r√©aliser leurs ambitions et concr√©tiser leurs projets. Le groupe soutient leur croissance, permet leur d√©veloppement et conduit leur transformation. Leur conviction, c‚Äôest que l‚Äôentreprise est avant tout une aventure humaine qui fait avancer le monde. C‚Äôest la raison pour laquelle l‚Äôentrepreneuriat est son principal levier de transformation. Leur raison d‚Äô√™tre, c‚Äôest de cr√©er des opportunit√©s √† une large communaut√© de talents, de leur transmettre l‚Äôesprit d‚Äôaudace et leur culture de l‚Äôentrepreneuriat. Ils veulent contribuer √† changer la vie des gens en leur permettant d‚Äôavoir un impact, de faire la diff√©rence, et tous ensemble de faire avancer le monde. Quels que soient leur sp√©cialit√© ou leur secteur d‚Äôactivit√©, toutes les entreprises de Mantu partagent une seule et m√™me mission : r√©v√©ler et faire grandir une communaut√© de talents pour r√©aliser les ambitions des entreprises et des entrepreneurs. Pour accompagner nos partenaires Fran√ßais et internationaux, nous recherchons des Data Ing√©nieurs afin d‚Äô√©voluer sur des projets √† forte valeur ajout√©e technologique en IT & Digital. Passionn√© par les nouvelles technologies et les environnements innovants, vous souhaitez faire partie d‚Äôune organisation ayant un vrai impact dans la r√©volution num√©rique ? N‚Äôattendez plus, rejoignez la communaut√© Amaris Consulting. Au sein d‚Äôune BU, une √©quipe DATA est d√©di√©e pour cr√©er de la valeur et optimiser nos processus au travers d‚Äôoutils BI. Le Data Engineer int√©grera une √©quipe compos√©e d‚Äôun product manager, de 3 data ing√©nieurs et de 3 BI ing√©nieurs. Dans ce cadre vous allez participer aux activit√©s suivantes : Missions : Concevoir et maintenir des programmes Spark en Python/SQL Challenger des jobs existants et trouver des axes d‚Äôoptimisations Participer au support du parc applicatif Participer au design des solutions et √™tre force de proposition sur l‚Äôarchitecture cible de notre p√©rim√®tre. R√©diger des documentations Participer √† l‚Äôalimentation du datalake Profil: Titulaire d‚Äôun dipl√¥me d‚Äôing√©nieur ou universitaire √©quivalent (BAC+5), vous justifiez d‚Äôau moins 2 ans d‚Äôexp√©rience en tant qu‚Äôing√©nieurs cloud. Vous connaissez au moins l‚Äôune des technologies suivantes: Azure Cloud, Kubernetes, Terraform, Docker, Ansible, PowerShell, Python. Vous √™tes mobile √† Nantes. Aimant relever des challenges au quotidien, vous savez travailler en autonomie et √™tre force de proposition aupr√®s de vos interlocuteurs afin d‚Äôapporter une valeur ajout√©e √† vos projets. Gr√¢ce √† un management de proximit√© et une politique RH personnalis√©e, vous serez accompagn√© dans la construction de votre parcours au sein de l‚Äôentreprise. Vos qualit√©s relationnelles seront des atouts importants pour r√©ussir dans la fonction et √©voluer au sein de notre groupe. Vous souhaitez int√©grer une √©quipe dynamique et innovante ? Alors rejoignez-nous!","Mantu, a global consulting and service group, is seeking Data Engineers with experience in Python/SQL Spark programming, Azure, Kubernetes, Terraform, Docker, Ansible, or PowerShell to work in Nantes, France. The role involves optimizing data processes, designing solutions, and contributing to a collaborative team of product managers, data engineers, and BI engineers. With a focus on innovation, autonomy, and proposal skills, as well as a proactive and adaptable mindset, candidates who excel in this role will receive sufficient coaching in their career development from Mantu.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
357,39738,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-lyon-h-f_paris,Data Engineer - Lyon -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilit√©, SaaS / Cloud Services",CDI,2022-11-29,"Avec plus de 15 milliards de requ√™tes par an, Kisio Digital business unit de Kisio et filiale num√©rique du Groupe Keolis est un acteur majeur de la mobilit√©. Les trois grands domaines d‚Äôintervention de Kisio Digital portent sur les syst√®mes d‚Äôinformation-voyageur (recherche d‚Äôitin√©raire multimodal, porte-√†-porte et temps-r√©el) ; l‚Äôachat de titres de transport d√©mat√©rialis√©s et le mobile-ticketing. Sa vision de la mobilit√© : permettre √† chacun de se d√©placer plus facilement, plus agr√©ablement et avec le moins d‚Äôemprise possible sur la plan√®te. C‚Äôest ce qu‚Äôon appelle la ¬´ responsive locomotion ¬ª ! Kisio Digital travaille continuellement √† l‚Äôam√©lioration des algorithmes qui permettent de calculer les meilleures solutions d‚Äôitin√©raire en tenant compte du contexte et des pr√©f√©rences du voyageur. Pour r√©pondre aux enjeux d‚Äôune mobilit√© plus intelligente, plus ouverte et plus √©cologique, Kisio Digital r√©alise des applications mobiles, des sites web et des SDK bas√©s sur notre API www.navitia.io. Cette plateforme propose des services num√©riques de mobilit√© dans le monde entier. Elle rassemble une communaut√© de 20 000 d√©veloppeurs et participe √† leur strat√©gie d‚Äôinnovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, v√©lomanes, bussophiles, et autres passionn√©s de montgolfi√®re ou de transports pas toujours tr√®s communs. Curieux et ouverts d‚Äôesprit, ils sont passionn√©s par la mobilit√© au sens large, les nouvelles technologies et les communs num√©riques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communaut√© Open transport. Si vous souhaitez vous √©panouir dans un environnement multiculturel, sachez que Kisio Digital va d√©sormais lancer des services √† l‚Äô√©tranger. Rejoignez-les ! En tant que Data engineer Hove, vous √™tes int√©gr√© √† une √©quipe pluridisciplinaire m√™lant d√©veloppeurs, Product Owner, Architectes dont l‚Äôobjectif est de cr√©er des services √† fortes valeur ajout√© dans le domaine du transport. Vous avez la charge de d√©finir et mettre en ≈ìuvre le pipeline d‚Äôacquisition des donn√©es (datahub) global pour Hove, d‚Äôorganiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Cr√©er et faire √©voluer le moteur d‚Äôingestion des donn√©es (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilit√© des flux de donn√©es Travailler en collaboration avec les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©grations continues, scalabilit√© des mod√®les, craftsmanship, etc‚Ä¶) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners D√©ployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des donn√©es Superviser et monitorer le d√©ploiement et la robustesse des composants mis en production Participer activement √† la qualit√© de l‚Äôing√©nierie logicielle (Relecture de code, test, int√©gration continue, d√©ploiement, etc.) Participer aux √©v√®nements internes √† la communaut√© data interne et externes (AWS Summit, workshops, meetups‚Ä¶) Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.* Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 2 ans en tant que Data engineer Vous op√©rez dans le conseil et pouvez justifier de vos missions Vous maitrisez l‚Äôanglais professionnel Vous maitrisez au moins : Un framework de calcul distribu√© tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala‚Ä¶). Diff√©rents syst√®mes de base de donn√©es (SQL et NoSQL) et le langage SQL. Un framework de streaming de donn√©es tel que Kafka, Kinesis, ‚Ä¶ Une exp√©rience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks‚Ä¶ Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez √™tre capable de livrer du code de qualit√© dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l‚Äô√©quipe tech Un entretien avec notre CTO","Kisio Digital, a digital subsidiary of Group Keolis, seeks a data engineer to join its team in Hove, UK. The company aims to create software of high value in the transportation field. As data engineer, the role will involve creating the pipeline for acquiring data, organising storage, and enabling the use of data by data scientists and analysts, among other tasks. Applicants should have at least two years of experience, proficiency in programming languages such as Python, Java, and Scala, SQL and NoSQL databases, and experience in AWS cloud technologies.",N,N,N,2,1,0.04154662416233763
358,56804,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/ia-project-engineer-data-value-lab-f-m-d_paris,IA Project Engineer - Data Value Lab,Decathlon Digital,"{GCP,SQL,Python,AWS}",T√©l√©travail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES DU DATA VALUE LAB DE l'IA FACTORY DE DECATHLON Le Data Value Lab , au sein de l'unit√© Decathlon AI factory, est l'√©quipe charg√©e de d√©couvrir & d√©finir les cas d'utilisation d'IA qui apportent le plus de valeur ajout√©e. Mais aussi d'assurer l'exp√©rimentation de ces cas d'usages. Le terme X4, qui signifie eXplore, eXamine, eXperiment et eXtend, r√©sume parfaitement le modus operandi de l'√©quipe. Au sein du Data Value Lab, nous utilisons une approche agile ""test & learn"" pour analyser le potentiel de valeur, la faisabilit√© d'un cas d'usage et mesurer la performance de la solution avant d'en √©tendre les succ√®s (industrialisation). Nous sommes √©troitement li√©s aux parties prenantes m√©tiers de l'entreprise et aux √©quipes d'IA (personnalisation, tarification, pr√©vision, optimisation des offres) charg√©es de d√©ployer √† grande √©chelle les r√©sultats de nos exp√©rimentations . L'√©quipe joue un r√¥le central dans l'√©tablissement de nouvelles orientations en mati√®re d'IA au sein de Decathlon, en exp√©rimentant les derni√®res technologies d'apprentissage automatique pour r√©soudre des probl√®mes commerciaux √† fort impact et en diffusant la culture de l'IA dans toute l'organisation.Vous serez en charge de projets qui ont le potentiel de d√©finir l'avenir du sport. Rejoindre nos √©quipes c'est vraiment une chance de fa√ßonner l'industrie du sport gr√¢ce aux donn√©es et √† l'IA Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons en CDI un-e Data Value Engineer, bas√©-e √† Paris (pr√©voir des d√©placements r√©guliers de 2 jours tous les 15 jours sur Lille). VOS RESPONSABILITES En tant que Senior Data Value Engineer au sein du Data Value Lab, vous devrez: √ätre d√©di√© √† 100% aux projets digitaux strat√©giques li√©s √† la transformation de l'entreprise par l'IA, sur des sujets transverses (Sports & Process, Supply Chain, Marketing, Offre, Pricing, Sustainability principalement) Vous identifierez, cadrerez, prioriserez et construirez des solutions d'IA pour les m√©tiers : r√©alisation d'un business case, traduction d'un probl√®me m√©tier en solution d'IA, estimation du potentiel de valeur, exploration des donn√©es pour d√©terminer un niveau de faisabilit√© et enfin pilotage du build avec les √©quipes de Data Science. Vous remettrez en question les probl√®mes m√©tiers, la valeur potentielle et la faisabilit√© technique des besoins remont√©s . Vous serez amen√© √† projeter des cas d'usages pragmatiques √† partir de nos trajectoires digitales prioris√©es. Vous utiliserez vos connaissances des applications business de l'IA, ainsi que votre maitrise du cycle de vie d'un projet de Data Science , pour d√©finir les cas d'usages d'IA √† fort impact et garantir leurs mise en oeuvre. Vous serez en charge de l'organisation, de la pr√©paration et de l'ex√©cution des workshops m√©tiers lors de la phase de Design, avec des parties prenantes √† 360¬∞ afin d'identifier des besoins ou alors les cadrer. Vous appliquerez la m√©thodologie agile pour mener √† bien votre feuille de route et animer votre roadmap. V ous serez en charge du pilotage du projet lors des phases de Define et de Build , en collaborant avec des parties prenantes techniques et m√©tiers. Vous identifierez les donn√©es critiques (√† valeur) √† collecter et √† int√©grer dans le domaine des donn√©es d'entreprise, en partie gr√¢ce √† vos cadrages. Vous communiquerez efficacement l'analyse et les r√©sultats des exp√©rimentations, en passant par une mesure concr√®te de la valeur cr√©√©e. Et ce par le biais de visualisations, de documents et de pr√©sentations √† toutes les parties prenantes. CE DONT VOUS AUREZ BESOIN POUR R√âUSSIR Vous avez au moins 3 ans d'exp√©rience en tant que Consultant-e Data, Business Translator, PM Data ou Data Scientist; qui vous as permis-e d'√™tre un-e solide g√©n√©raliste Data sur l'ensemble du cycle de vie de la donn√©e. Hards Skills : Vous avez acquis une expertise des applications IA pour les business, de la traduction d'un probl√®me m√©tier en solution d'IA ; Vous comprenez et vous avez une connaissance compl√®te du cycle de vie d'un projet de Data Science, ainsi que des besoins et exigences en mati√®re de donn√©es; Vous avez acquis une exp√©rience en Business Analyse; Vous avez de solides comp√©tences de restitution d'analyses, pitch/argumentation ; Vous avez acquis une exp√©rience en management de projet Data, pilotant des √©quipes transverses √† la fois techniques et m√©tiers; Vous avez des comp√©tences en analyse des donn√©es : analyse et visualisation exploratoires des donn√©es; Vous avez un niveau de base en SQL et/ou en Python ; Vous √™tes exp√©riment√© en techniques de Design Thinking et leurs applications aux produits Data; Soft Skills : Vous avez d' excellentes comp√©tences interpersonnelles, analytiques, de communication et de pr√©sentation - capacit√© √† communiquer des r√©sultats complexes de mani√®re simple ; Vous avez des comp√©tences solides en mati√®re de r√©solution de probl√®mes, l'accent √©tant mis sur le d√©veloppement de produits ; Vous aimez d√©couvrir et r√©soudre des probl√®mes ; chercher de mani√®re proactive √† clarifier les exigences et les orientations ; vous √™tes une personne autonome qui prenez des responsabilit√©s lorsque cela est n√©cessaire ; Vous √™tes capable d'explorer diff√©rentes directions √† partir de donn√©es et √™tes capable de changer rapidement de direction en fonction de l'analyse ; Vous √™tes passionn√©.e par le sport et la mobilit√© Vous avez envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, notamment implant√©es √† Paris, Lille, Nantes, Lyon et Amsterdam. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .","Decathlon is looking for a Senior Data Value Engineer with at least 3 years of experience in data consulting or analysis. The role involves identifying and prioritizing AI solutions for various departments, managing agile projects, and communicating results to stakeholders. The ideal candidate will have expertise in AI applications for business, data analysis, communication, and problem-solving skills, as well as a passion for sports and mobility. Decathlon is committed to diversity, inclusion, and non-discrimination and offers benefits such as teleworking, skills development, and employee share ownership.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
378,58097,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/data-engineer_paris_DOCTR_JDmO7pQ,Data Engineer (Squad Produit),Doctrine,"{React,durable,NoSQL,NodeJS,Dask,Airflow,Kubernetes,PostgreSQL,S3,Elasticsearch,SQL,Github,Python}",T√©l√©travail partiel possible,"43, Avenue de Clichy, Paris, 75017","Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique",CDI,2023-03-26,"Doctrine rend l‚Äôinformation juridique plus accessible et intelligible pour les professionnels du droit : avocats, juristes, magistrats, experts‚Ä¶ Start-up de la Legal Tech fran√ßaise, Doctrine a convaincu plus de 6 500 clients de lui faire confiance depuis sa cr√©ation en 2016. Avec plus de 80 collaborateurs aujourd‚Äôhui, elle pr√©voit de recruter des dizaines de talents en 2021 et 2022 afin de poursuivre le d√©veloppement de ses solutions technologiques innovantes, de faciliter la vie de toujours plus de professionnels du droit, et d‚Äô≈ìuvrer encore davantage √† la transparence et la modernisation de la justice. Notre mission ‚öñÔ∏è Nous nous engageons pour un enjeu d√©mocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit. Doctrine est la premi√®re plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et d√©fendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et d√©j√† 9000 professionnels du droit nous font confiance. Nos valeurs ü§ù Challenge the status quo. Nous d√©fendons les id√©es audacieuses et la prise de risque intelligente. Liberty and responsibility. Nous promouvons l‚Äôautonomie, l‚Äôimpact de chacun¬∑e et l‚Äôownership. Knowledge is power. L'information est au c≈ìur de la mission de Doctrine, et nous voulons toujours apprendre plus. Release early, release often and listen to your customers. Nous croyons au pouvoir de l‚Äôit√©ration et √† l‚Äôimportance d‚Äô√©couter en permanence notre march√©, nos client¬∑e¬∑s et leurs probl√©matiques. Le contexte Nous sommes actuellement √† la recherche d‚Äôun profil Data Engineer pour rejoindre l‚Äôune de nos squads et participer √† la construction de la premi√®re plateforme d‚Äôintelligence juridique. Tu rejoindras une √©quipe d√©di√©e √† l‚Äôacquisition, l‚Äôenrichissement et la mise √† disposition de la donn√©e juridique dans notre plateforme. Notre stack technique : on travaille avec NodeJS, NestJS, React & NextJS Tu peux trouver des d√©tails sur l‚Äôensemble de la stack sur Github A savoir : il n‚Äôest pas n√©cessaire d‚Äôavoir une exp√©rience professionnelle dans le domaine du droit, cependant l‚Äôenvie de s‚Äôinvestir et de monter en comp√©tence dans la compr√©hension des documents juridique est importante :) Les missions üõ† Contribuer au maintient des pipelines de donn√©es du p√©rim√®tre de la squad. Concevoir, d√©velopper, monitorer et maintenir de nouveaux scripts d‚Äôacquisition et de traitement des donn√©es en Python pour ajouter de nouveaux contenus dans notre plateforme. Travailler en collaboration avec nos Machine Learning Engineers et experts NLP pour les aider √† int√©grer leur travail dans le pipeline de donn√©es. Contribuer √† l‚Äô√©volution de nos outils de pipeline de donn√©es (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...) Participer √† la vie du Chapter Data Le profil id√©al üëÄ De bonnes comp√©tences en programmation Python. Connaissance des pratiques d'acquisition et de mod√©lisation des donn√©es. Connaissance de SQL, NoSQL, Elasticsearch et du stockage objet. L‚Äôenvie de partager ton savoir au sein de l'√©quipe La ma√Ætrise de la langue fran√ßaise, car tu seras amen√©.e √† manipuler des donn√©es juridiques en fran√ßais Les √† c√¥t√©s du poste üëÅ Comme tous les Data Engineers de Doctrine, tu participeras √† un de nos chapters transverse, en l‚Äôesp√®ce le chapter Data. Au sein de ce chapter, tu contribueras √† des projets internes pour am√©liorer nos process et notre vision long-terme. Le chapter se r√©unit 2 fois par mois pour : ü§ù Partager des connaissances : am√©lioration continue, bonnes pratiques‚Ä¶ üéØ Proposer des √©volutions : nouveaux outils √† exp√©rimenter, nouveaux process √† mettre en ≈ìuvre üë©‚Äçüíª Recruter : tous les contributeurs individuels rencontrent des candidats √† l‚Äôoccasion de tests techniques ou d‚Äôentretiens. Ce qui t'attend si tu rejoins Doctrine ü§ó - Contribuer √† un projet ambitieux, avec un impact r√©el et positif sur la soci√©t√© : rendre le droit plus accessible et plus ouvert. - Un accompagnement sur mesure d√®s ton arriv√©e sur l'√©cosyst√®me juridique pour t'aider √† naviguer tr√®s vite dans cet environnement stimulant. - Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances √† l‚Äôensemble de tes coll√®gues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.) - Travailler au sein d‚Äôune √©quipe en √©bullition qui cherche sans cesse √† se renouveler : de la place pour innover et mener des projets en autonomie ou en √©quipe. Nos avantages pour faire la diff√©rence ‚òÄÔ∏è üè° Une politique de t√©l√©travail flexible, avec 2 jours de pr√©sence au bureau par semaine (mardi et jeudi) üå± De nombreuses options pour ta carri√®re, et des mobilit√©s internes ouvertes √† toutes et tous chez Doctrine üå¥ Des vacances flexibles et illimit√©es üìö Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750‚Ç¨ en usage libre et des formations en √©quipe et pour toute l'entreprise r√©guli√®rement üèÑ‚Äç‚ôÇÔ∏è Des √©v√®nements collectifs r√©guliers üë©‚Äç‚öïÔ∏è Une bonne assurance sant√© avec Alan üö≤ Un forfait mobilit√© durable √† hauteur de 66 euros par mois üèãÔ∏è‚Äç‚ôÄÔ∏è Un abonnement Gymlib pour les activit√©s sportives et bien-√™tre üç± Une carte Swile pour tes tickets restaurants üßò Un acc√®s gratuit √† la plateforme d'accompagnement √† la sant√© mentale Moka.care üí° Des centaines de r√©ductions et avantages n√©goci√©s gr√¢ce √† notre CSE üçè Un √©quipement de travail neuf chez Apple Notre processus de recrutement üöÄ - Un premier √©change de 30 min avec l‚Äôun.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te pr√©senter ce qu'on construit chez Doctrine - Une rencontre d‚Äô1h avec ton/ta futur.e manager , pour d√©tailler le poste et le scope de l‚Äô√©quipe, mais aussi r√©pondre √† toutes tes questions. - Un ou deux tests techniques pour √©valuer concr√®tement tes comp√©tences - Un d√©jeuner avec 3 personnes de diff√©rents d√©partements chez Doctrine, pour te donner un aper√ßu de tes futur.e.s coll√®gues - Un √©change sur les valeurs de l‚Äôentreprise pour te partager notre vision - Une rencontre avec Guillaume, notre CEO. (si n√©cessaire le processus pourra √™tre adapt√© pour r√©pondre √† tes contraintes personnelles et professionnelles) Mesdames, autorisez-vous √† candidater ! Certaines √©tudes scientifiques montrent qu'en particulier les femmes ont moins tendance √† postuler √† une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins. Si Doctrine vous int√©resse, sachez que nous aurons plaisir √† recevoir votre candidature !","Doctrine, a French Legal Tech start-up, is seeking a Data Engineer to help build its first legal intelligence platform. The ideal candidate should have good Python programming skills, knowledge of data acquisition and modeling practices, and familiarity with SQL, NoSQL, Elasticsearch, and object storage. The position offers flexible remote work, unlimited vacation, a focus on individual and collective training, and numerous employee benefits. Applicants who are not lawyers but wish to learn more about legal documents are encouraged to apply.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
393,34782,https://www.welcometothejungle.com/fr/companies/m13h/jobs/dataviz-engineer-france-europe-f-h_paris,DataViz Engineer - (France / Europe) -,M13h,"{OneTrust,DataStudio,Looker,PowerBI,Fivetran,dbt,Contentsquare,via,Adverity,SQL,Qlik,Tableau}",T√©l√©travail partiel possible,Paris,"Digital Marketing / Data Marketing, Strat√©gie, Big Data",CDI,2022-08-08,"A propos de M13h üëã M13h est une √©quipe de consultant¬∑e¬∑s passionn√©¬∑e¬∑s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Strat√©gique et expertises Data, Marketing & Technologies pour acc√©l√©rer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous ma√Ætrisons toute la cha√Æne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, ‚Ä¶ √† accro√Ætre leurs performances, au travers de missions vari√©es : Strat√©gie Data : d√©finir sa strat√©gie, ses cas d‚Äôusage data et le socle technologique pour la d√©ployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donn√©e pour cr√©er de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et am√©liorer les taux de conversion Privacy : s‚Äôadapter aux √©volutions technologiques et r√®glementaires tout en d√©veloppant ses performances marketing Modern Data Platforms : construire des plateformes de donn√©es sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des donn√©es pour prendre des d√©cisions √©clair√©es (dashboards, data analyse, data science, mod√©lisation avanc√©e, ‚Ä¶) M13h est membre du Groupe Labelium et met ses comp√©tences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure √† taille humaine o√π il fait bon travailler ! En plein mouvement de r√©gionalisation et d‚Äôinternationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l‚ÄôEurope (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N‚Äôh√©sitez pas √† en discuter en entretien. Description du poste üì¢ En tant que DataViz Engineer, tu interviens sur les probl√©matiques relatives √† la mise en place de dashboards et autres outils de pilotage d‚Äôactivit√© pour les clients de M13h. Pour cela, tu interviens √† diff√©rents stades des projets : Compr√©hension des besoins m√©tiers et d√©finition des indicateurs pour les repr√©senter de mani√®re efficace Cr√©ation des indicateurs de suivi Mise en place des dashboards Maintenance et √©volution des dashboards Veille sur les √©volutions du march√© D√©finition des bonnes pratiques de d√©veloppement de visualisation efficientes Quelques exemples de missions √† titre d‚Äôillustration : Cr√©ation de dashboard centralisant la donn√©e m√©dia issue des principales plateformes d‚Äôactivation Construction de rapport de suivi de performances marketing Mise en place d‚Äôun outil de pilotage de l‚Äôattribution m√©dia Cr√©ation de dashboard omnicanaux avec notamment les donn√©es issus de Google My Business et Facebook pages Mise en place de dashboards √† destination des franchis√©s Cr√©ation de templates de dashboards dans le cadre d‚Äôune industrialisation du pilotage media Rigoureux¬∑se, tu as √† c≈ìur de comprendre les besoins de tes interlocuteurs puis les traduire et les mat√©rialiser via des dashboards pertinents . En tant que Junior , tu seras encadr√©¬∑e par des profils plus seniors te permettant de progresser rapidement dans notre environnement et sur des outils modernes. Profil recherch√© üë®üë© Issu¬∑e d‚Äôune grande √©cole de commerce, d‚Äôing√©nieurs ou √©quivalent , tu souhaites t‚Äôorienter vers les m√©tiers de la business intelligence. Tu connais certains outils de march√© (Tableau, PowerBI, DataStudio, Qlik, Looker, ‚Ä¶) et tu as des bases dans la gestion et la structuration de donn√©es notamment en SQL, ainsi que sur la meilleure mani√®re de restituer des donn√©es de fa√ßon visuelle. Tu souhaites travailler sur des environnements cloud et d√©couvrir les outils ELTs. Au-del√† des comp√©tences techniques, tu fais preuve de rigueur, de cr√©ativit√© et d‚Äôautonomie. Tu as √©galement une forte capacit√© de formalisation et fait preuve de p√©dagogie. Pourquoi nous rejoindre ‚ùì M13h, c‚Äôest avant tout une √©quipe qui aime les challenges et porte des valeurs de bienveillance et de progr√®s collectif . Tu as d√©j√† lu √ßa ailleurs ? Contactes nos consultant¬∑e¬∑s sur LinkedIn pour v√©rifier directement :) D√©marrer chez M13h, c‚Äôest aussi une belle opportunit√© de d√©velopper tes comp√©tences conseil et ton expertise rapidement sur des missions vari√©es, au sein d‚Äôune structure √† taille humaine tout en profitant des avantages d‚Äôun groupe international. Tu es accompagn√© par un parrain ou une marraine d√®s ton arriv√©e en plus de ton manager, profites de formations, acc√®des √† de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, ‚Ä¶ Et puis M13h, c‚Äôest aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d‚Äôarriv√©e pour s‚Äô√©quiper pour le t√©l√©travail Une politique souple de t√©l√©travail Un abonnement gratuit √† des salles de sport 2 s√©minaires par an et de nombreux moments de coh√©sion d‚Äô√©quipe Des locaux au coeur de grandes villes fran√ßaises (Paris, Bordeaux, Lyon) et europ√©ennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge √† 100% et bien d‚Äôautres‚Ä¶ Comment postuler üôã Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontan√©e √† recrutement@m13h.com","M13h is seeking a DataViz Engineer to develop dashboards and other activity management tools for clients. The role requires understanding business requirements, creating key performance indicators, and implementing dashboards while remaining up-to-date with market trends. Candidates should have a degree from a top business, engineering, or equivalent school and knowledge of data management tools such as SQL, as well as demonstrate creativity and autonomy. M13h offers a supportive and collaborative work environment and provides training, resources, and perks like telecommuting, gym memberships, and team-building events.",Bac +5 / Master,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
388,35854,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-h-f-innovative-tech_lille_DIT_4DW7Y48,Data Engineer  - Innovative Tech,Devoteam Innovative Tech,"{DataStudio,Looker,Keras,TensorFlow,AWS,QlikView,GCP,Tableau}",T√©l√©travail partiel possible,N,"IT / Digital, Strat√©gie, SaaS / Cloud Services",CDI,2022-09-28,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs strat√©gies de modernisation de plateformes. Face √† l‚Äôav√®nement du Cloud et des nouvelles m√©thodes de travail qui en d√©coulent, les DSI doivent aujourd‚Äôhui r√©pondre √† plusieurs enjeux majeurs pour √™tre agiles, porteuses d‚Äôinnovation, per√ßues comme un v√©ritable ‚Äúbusiness partner‚Äù tout en ayant une gestion responsable de la consommation √©nerg√©tique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant √† adopter une posture cr√©ative et apprenante. L'√©quipe lilloise n‚Äôattendent que toi pour relever de nouveaux d√©fis. Ensemble nous accompagnerons nos clients dans la transformation de leur projet. Tes missions si tu l‚Äôacceptes : Accompagner les grands comptes dans leur projet de mise en place de projets Data avec GCP, AWS ou tout autre syst√®me Big data. Analyser les besoins clients : Animer des ateliers Pr√©coniser des architectures cibles R√©diger des dossiers d'architecture et sp√©cifications techniques D√©finir les m√©thodologies de d√©ploiement et plans de migration Construire les architectures de donn√©es : Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s Construire et d√©ployer les pipelines de donn√©es (ETL) Assurer la migration des donn√©es vers les nouveaux environnements Analyser les donn√©es : Analyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio‚Ä¶) S√©lectionner, entra√Æner, √©valuer et d√©ployer des mod√®les pr√©dictifs en s‚Äôappuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les √©quipes clients aux m√©thodes et concepts du cloud Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieurs ou d‚Äôun Master 2 en informatique , tu souhaites t'investir dans une √©quipe dynamique, passionn√©e et aux valeurs humaines. And You are fluent in english ! Tu es d√©sireux (se) de t'investir dans des projets challengeants et gagner rapidement en responsabilit√©s. Rejoigne la tribu ! Tu veux en savoir plus? Viens √©changer directement avec nos ambassadeurs . Le Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme dediscrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation.","Devoteam Innovative Tech is seeking an engineer or Master's holder in computer science to join their Lille-based team to aid major businesses with their big data projects using GCP, AWS or other big data systems. Responsibilities include analyzing clients' needs, developing data architectures, migration plans and deploying pipelines while providing constant cloud solutions support and training to clients. The ideal candidate should possess excellent analytical and communication skills, have knowledge of data analysis tools, and be proficient in English.",N,N,N,2,1,0.04154662416233763
386,39788,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer_paris_CONTE_DlplLYM,Data Engineer,Contentsquare,"{go,regard,ContentSquare,Go,color,Scala,Akka,AWS,Contentsquare,scale,Kafka,Elasticsearch,Spark,ClickHouse,Java}",T√©l√©travail partiel possible,"7, Rue de Madrid, Paris, 75008","SaaS / Cloud Services, E-commerce",CDI,2022-11-29,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team ‚Äì known as the CSquad ‚Äì representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of passionate and talented developers, designing and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at ContentSquare ! We collect several billions events per day, and query hundreds of terabytes in real time. Your daily work will consist of: ‚Ä¢Designing efficient architectures to store and analyze petabytes of data ‚Ä¢Leading large scale projects and mentoring other developers ‚Ä¢Implementing complex acquisition workflows ‚Ä¢Thinking of smart data formats to serve the functionalities of the product, while minimizing the cost ‚Ä¢Developing tools to help data-scientists, by using some open source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have an interest in functional programming and seek to develop your skills in Data engineer programming languages. Kafka, Akka, Spark, AWS‚Ä¶ You have had the chance to discover or work with these big data technologies. Ideally, you have some experience on a wide range of databases and you are interested in streaming. You would like to challenge yourself developing distributed infrastructure with a real time and data-intensive environment. You would like to share your skills and take part in technical choices. Why join ContentSquare‚Äôs Data Engineering team? ‚Ä¢You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data. ‚Ä¢You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences. ‚Ä¢You are looking for an environment where you‚Äôll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategical corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross team innovation days, we are committed to innovate towards tomorrow‚Äôs user experience. You‚Äôll also have: flexible working hours, remote ; yoga, and many other activities; after work beers provided every Friday, monthly parties‚Ä¶and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare: ‚ñ™Ô∏è We‚Äôre humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ‚ñ™Ô∏è We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ‚ñ™Ô∏è We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ‚ñ™Ô∏è Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ‚ñ™Ô∏è Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ‚ñ™Ô∏è Work flexibility: hybrid and remote work policies. ‚ñ™Ô∏è Generous paid time-off policy (every location is different). ‚ñ™Ô∏è Immediate eligibility for birthing and non-birthing parental leave. ‚ñ™Ô∏è Wellbeing allowance. ‚ñ™Ô∏è Home Office Allowance. ‚ñ™Ô∏è A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ‚ñ™Ô∏è Every full-time employee receives stock options, allowing them to share in the company‚Äôs success. ‚ñ™Ô∏è We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don‚Äôt meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, seeks a Data Engineer to design and develop a new data architecture, lead large-scale projects, implement complex acquisition workflows, and develop tools to help data scientists. Candidates should be proficient in Scala, Java, or Go and have experience with big data technologies like Kafka, Spark, and AWS. Benefits include flexible working hours, remote work, career development, mentorship, and competitive benefits. The company values uniqueness and is an equal opportunity employer.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
385,34440,https://www.welcometothejungle.com/fr/companies/veepee/jobs/software-engineer-for-data_barcelone,Software Engineer for Data,Veepee,"{Beam,k8s,Protobuf,gitlab,Kubernetes,Airflow,dbt,gRPC,kubernetes,Bigquery,Dataflow,Java}",T√©l√©travail partiel possible,Barcelone,E-commerce,CDI,2022-08-08,"Avec VEEPEE, le groupe vente-privee ouvre un nouveau chapitre de son histoire europ√©enne avec la convergence des diff√©rentes soci√©t√©s qui le composent et leurs 6 000 collaborateurs vers une seule et m√™me marque. Regroupant Privalia, Vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic et vente-privee, Veepee est aujourd‚Äôhui pr√©sent dans 14 pays et devient un acteur majeur du commerce digital europ√©en, avec 72 millions de membres et un volume d‚Äôaffaires de 3,7 milliards d‚Äôeuros en 2018. Leurs 6 000 collaborateurs ont choisi Veepee pour r√©veiller leur quotidien ! Tous ensemble, ils mettent les nouvelles technologies au service de nos strat√©gies, afin de proposer la meilleure exp√©rience possible √† nos clients. Vous avez soif d‚Äôapprendre ? Veepee vous permet de construire votre parcours parmi une pluralit√© de m√©tiers et de vous renouveler constamment. Tech, logistique, marketing, commercial, production des ventes‚Ä¶ prenez part √† une aventure humaine au c≈ìur d‚Äôenjeux digitaux. Impatients de les rencontrer ? Ils ont h√¢te aussi ! The vente-privee group has consolidated its various European brands, together made up of 6000 employees, under one unified conglomerate: Veepee. This coalescence marks a new chapter in its European history. With Privalia, vente-exclusive, Designer & Friends, Zlotewyprzedaze, Eboutic and vente-privee, Veepee achieved a 3.7 billion Euro turnover as of 2018. Present in 14 countries now, Veepee is taking a leading role in the European digital commerce landscape. Our 6000 employees have chosen a job at Veepee to spice up their daily lives! Our teams implement new technologies to fuel our strategies, offering our customers the best possible experience. Are you eager to learn? Veepee offers you a variety of trades to develop your career, enabling you to renew your skills constantly. Tech, logistics, sales, marketing, sales production: join us on an exciting, digital-centered journey. As a Software Engineer in Veepee‚Äôs data organization, you will.. .. be part of our data organization Veepee‚Äôs data organisation came into existence in 2018 and consists of a strong team of 40-50 data professionals, spread across different data domains (engineering, analytics, data science & ML and governance). You will be part of a multidisciplinary, multinational team that fosters collaboration, transparency, respect and of course‚Ä¶ a good amount of fun in the working environment. .. build and maintain APIs, tools and pipelines that form Veepee‚Äôs data platform For its data platform, Veepee firmly believes in a Push - Load - Transform strategy of ingesting data. Products are responsible for the data they produce and our data platform should enable them to push that information (in real-time) into our data platform in a governed way. Hence, we adopted data contracts to define which data comes in and have built our own set of tools and API‚Äôs around this to facilitate data ingestion, Veepee style. Furthermore, we keep improving our toolchain for data transformation (using dbt) and data exposure downstream. Responsibilities: Be part of a team running a set of applications with high SLA requirements; Develop, deploy and maintain a large Java stack serving a set of APIs mainly developed in gRPC & Protobuf Support, design, implement and deploy microservices running on Kubernetes with a Gitops approach; Identify data producer and consumer requirements and implement pragmatic and robust solutions based on solid architecture patterns (Reactive, Operator, Resilient..); Maintain data pipelines and data jobs mainly developed with Apache Beam and Apache Airflow; Keep improving your technical knowledge and expertise by attending conferences, contributing to open-source projects organizing and attending meetups Requirements: You have a strong experience (3-5 years) working on a large Java stack; You know how to implement and consume APIs, preferably in Protobuf & gRPC; You love making clean code and you are interested in having successful software engineering practices (Unit tests, pair programming, code reviews). You would like to help the team to grow in the quality of what they produce and their methodologies; You have experience with setting up CI/CD pipelines, preferably in gitlab; You have significant experience working with microservices and Kubernetes; You know or want to use helm charts as a templating language for k8s crd‚Äôs; You know or want to use the concept of a GitOps strategy for deploying kubernetes resources, preferably using ArgoCD; You are willing to learn data engineering concepts, tools and frameworks (Apache Beam, Apache Airflow, dbt); You would like to work with Google Cloud Platform (Bigquery, GKE, Dataflow); You know or want to learn Infrastructure as Code tools like terraform, atlantis; You are a strong team player. What we offer: The dynamic and creative environment within international teams; The variety of self-education courses on our e-learning platform; The participation in meetups and conferences locally and internationally; Hybrid work organization and flexibility for full remote contracts; Advanced remote practices and tools. Belonging to Veepee, <vpTech/> is one of the biggest tech communities in Europe with more than 800 IT collaborators. From Warsaw to Barcelona , through Lyon , Nantes , Tel Aviv , Brussels , Nice, Amsterdam, and Paris , all our projects are developed in a functional environment with a wide skills variety where you‚Äôll be sure to find your place, no matter the technology you want to work with. If you love to try things why don‚Äôt you jump on this new adventure? Need more info > https://careers.veepee.com/en/careers/ Vente-privee.com processes the collected data to handle the recruitment process, to evaluate your ability to carry out the job offered and your professional skills. You can learn more about our use of your data and your rights by reading our recruiting privacy policy .","Veepee, part of the vente-privee group, is seeking a software engineer to join its data organisation. The role involves building and maintaining the company's data platform, developing and deploying a large Java stack serving a set of application programming interfaces (APIs), designing microservices running on Kubernetes with a Gitops approach and maintaining data pipelines and data jobs largely developed with Apache Beam and Apache Airflow. Candidates are required to have three to five years' experience working on a large Java stack and should be familiar with gRPC, Protobuf and Helm charts.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
384,34338,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-cdi-f-h_niort_ASI_dDRXeKk,Data Engineer - CDI,ASI,"{DynamoDB,Matillion,Glue,Cassandra,Hive,Neo4J,Azure,Cloudera,MongoDB,Talend,Kafka,NoSQL,CouchDB,HBase,Java,Hadoop,Redis,EMR,Scala,Airflow,HDFS,S3,Spark,Python}",T√©l√©travail partiel possible,Niort,"IT / Digital, Transformation, Big Data",CDI,2022-08-08,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Dans un souci d‚Äôaccessibilit√© et de clart√©, les termes employ√©s au masculin se r√©f√®rent aussi bien au genre f√©minin que masculin. Dans le cadre du d√©veloppement de nos expertises Data et pour r√©pondre aux enjeux de nos clients, nous recherchons un Data Engineer pour int√©grer notre √©quipe Niortaise Au quotidien : Vous concevez et r√©alisez un sourcing de donn√©es Big Data, temps r√©el ou non Vous ma√Ætrisez les formats de donn√©es non structur√©s et savez les manipuler Vous mod√©lisez un sch√©ma de base de donn√©es relationnelle ou non-relationnelle Vous connectez une solution ETL / ELT √† une source de donn√©es (fichiers, API, base de donn√©es, flux temps r√©el) Vous concevez et r√©alisez un pipeline de transformation et de valorisation des donn√©es et ordonnancez son fonctionnement Vous veillez √† la s√©curisation des pipelines de donn√©es Vous concevez et r√©alisez des API utilisant les donn√©es valoris√©es Vous r√©alisez une veille technologique constante. Parlons de vous : Issu d‚Äôune formation sup√©rieure en informatique, math√©matiques ou sp√©cialis√© en Big Data. Vous poss√©dez une exp√©rience minimum de 2-3 ans en ing√©nierie des donn√©es et d'une exp√©rience op√©rationnelle r√©ussie dans la construction de pipelines de donn√©es structur√©es et non structur√©es. Vous avez une exp√©rience pratique dans l‚Äôun ou plusieurs des environnements technologiques suivants : L‚Äô√©cosyst√®me Data : Spark, Hive, HDFS, Kafka, HBase et id√©alement une distribution Hadoop (Cloudera, EMR, HDInsight) Les langages : Scala, Java, Python Les bases de donn√©es NoSQL : MongoDB, Cassandra, DynamoDB, CosmosDB, CouchDB, Redis, Neo4J Stockage cloud: S3, Azure Blob Storage‚Ä¶ Les ETL/Outils d'orchestration du march√© : Matillion, Airflow, Datafactory, Glue, Talend,... Le respect et l‚Äôengagement font partie int√©grante de vos valeurs. Vous avez l‚Äôesprit d‚Äô√©quipe et vos qualit√©s relationnelles vous permettent de vous int√©grer facilement au sein de l‚Äô√©quipe. √Ä comp√©tences √©gales ce poste est ouvert aux personnes en situation de handicap .","ASI, a French digital expertise consultancy, is seeking a Data Engineer to join their Niort team. The successful candidate should have a degree in computer science, mathematics, or big data and at least 2-3 years of experience in data engineering. They should be familiar with technologies such as Spark, Hive, HDFS, Kafka, etc., and have practical experience in building pipelines for structured and unstructured data. Additionally, they should have strong teamwork skills and a commitment to social responsibility. The position is open to candidates with disabilities.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
381,34126,https://www.welcometothejungle.com/fr/companies/lectra/jobs/ingenieur-qa-data-data-qa-engineer-h-f_cestas,Ing√©nieur(e) QA Data / Data QA Engineer,Lectra,"{Jenkins,GitLab,Scala,Kubernetes,Docker,Kafka,R,via,Git,Java,SQL}",T√©l√©travail partiel possible,Cestas,"Logiciels, SaaS / Cloud Services",CDI,2022-08-08,"Acteur majeur sur les march√©s de la mode, de l‚Äôautomobile et de l‚Äôameublement, Lectra contribue au d√©veloppement de l‚Äôindustrie 4.0 avec audace et passion. Le groupe propose des solutions d‚Äôintelligence industrielle √† la pointe de la technologie qui facilitent la transformation digitale des entreprises. Gr√¢ce √† ses logiciels, √©quipements, donn√©es et services, Lectra aide ses clients √† repousser les fronti√®res et √† lib√©rer pleinement leur potentiel. Ses 2 400 collaborateurs sont guid√©s par trois valeurs fondamentales, qui font la fiert√© du groupe : faire preuve d‚Äôouverture d‚Äôesprit, √™tre des partenaires de confiance et innover avec ardeur. Fond√©e en 1973, Lectra a r√©alis√© un chiffre d‚Äôaffaires de 388 millions d‚Äôeuros en 2021 et est cot√©e sur Euronext (LSS). Pour plus d‚Äôinformations, visitez lectra.com. Notre d√©partement R&D Software bas√© √† Bordeaux/Cestas est √† la recherche de son/sa futur(e) ing√©nieur(e) QA Data. Rattach√©(e) au Team Lead, vous serez int√©gr√©(e) dans une √©quipe agile sp√©cialis√©e dans le traitement de la donn√©e et compos√©e d‚Äôing√©nieurs Data, d‚Äôun Tech Lead et d‚Äôun chef de projet. Vous aurez en charge la validation des jeux de donn√©es et de leur traitement. Pour cela, vous participerez √† la d√©finition et mise en ≈ìuvre de la strat√©gie de test au travers de tests manuels et automatis√©s afin de garantir un tr√®s haut niveau de qualit√© sur l‚Äôensemble des d√©veloppements. Au sein de la Communaut√© QA, vous participerez aux activit√©s li√©es √† la strat√©gie de test, √† l‚Äôoutillage, √† la d√©finition des jeux de donn√©es et toutes les activit√©s li√©es √† l‚Äôam√©lioration continue. Vous contribuerez de fa√ßon active avec les √©quipes √† l‚Äôam√©lioration globale de la qualit√© logicielle. Int√©gr√©(e) √† une √©quipe dans un contexte Lean / Agile, vos missions principales seront les suivantes : ‚Ä¢ Avoir une bonne compr√©hension des besoins et des enjeux li√©s aux produits d√©velopp√©s, ‚Ä¢ D√©finir et mettre en ≈ìuvre de la strat√©gie de test en accord avec l‚Äôensemble des acteurs du projet, ‚Ä¢ R√©diger les plans de test et les cas de test, ‚Ä¢ Automatiser, suivre, analyser et maintenir les tests, ‚Ä¢ Saisir les anomalies, les suivre et valider leur correction, ‚Ä¢ Participer √† la mise en production des services Cloud dans le cadre des exigences de qualit√© d√©finies, ‚Ä¢ Participer √† la mise en place d‚Äôoutils de test ou de processus permettant d‚Äôoptimiser les t√¢ches de validation dans un contexte d‚Äôam√©lioration continue (scripting, gestion des jeux de donn√©es, etc.) et de livraison continue, ‚Ä¢ √ätre partie prenante au sein de la communaut√© QA, ‚Ä¢ Avoir un fort esprit d‚Äô√©quipe et un bon relationnel contribuant ainsi √† travailler dans un environnement productif, collaboratif et agr√©able. ENVIRONNEMENT TECHNIQUE Outils de test : Postman, Karate DSL, Selenium, Git / GitLab, Jenkins, VersionOne M√©thodes : Lean / Agile, Scrum / Kanban, BDD, Continuous Delivery Langages de d√©veloppement : Java, Scala, SQL De formation Bac+3 √† Bac+5, vous justifiez d‚Äôune exp√©rience de 2 ans sur le m√™me poste au sein d‚Äôune √©quipe de validation logicielle / qualit√© logicielle, de pr√©f√©rence en environnement Cloud. Comp√©tences requises : Expertise en m√©thodologie de test logiciel (une certification ISTQB serait un plus), Maitrise en outillage de test et d‚Äôautomatisation, Connaissance des environnements d‚Äôint√©gration continue (Jenkins) et de gestion de configuration (Git), Rigueur, analyse, esprit d‚Äô√©quipe, culture du changement et de la qualit√©. Comp√©tences souhait√©es : Notions de programmation Java et/ou Scala, Notions d‚Äôutilisation de Docker et Kubernetes, Notions du framework Kafka. Ce que Lectra vous propose ? ‚Ä¢ Rejoindre une entreprise innovante proposant des solutions et services premiums ‚Ä¢ Travailler dans un environnement international, multiculturel (32 nationalit√©s) et agile ‚Ä¢ Des locaux refaits √† neuf r√©cemment sur un site bois√© de 12 hectares ‚Ä¢ Un CSE attractif proposant des subventions pour les voyages, de la location de mat√©riel (randonn√©e, surf, ‚Ä¶), des activit√©s culturelles et sportives, une m√©diath√®que‚Ä¶ ‚Ä¢ La mise √† disposition du complexe sportif du Bouzet √† Cestas (badminton, court de tennis, piscine‚Ä¶) ‚Ä¢ Un restaurant d‚Äôentreprise ‚Ä¢ Un remboursement de 50% des transports en commun ‚Ä¢ Une mutuelle d‚Äôentreprise prise en charge √† 50% ‚Ä¢ Des primes de cooptation dans le cadre des recrutements ‚Ä¢ T√©l√©travail : 1jour/semaine Le poste est bas√© √† Cestas (23 chemin de Marticot) - pour nous rejoindre : ‚Ä¢ Accessible par l‚Äôautoroute sortie 25 de l‚ÄôA63 (parking voiture et deux-roues sur place) ‚Ä¢ Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de v√©lo/trottinette pour acc√©der au campus sur piste cyclable hors route. ‚Ä¢ Depuis Bordeaux - Pellegrin via le Transgironde 602 : arr√™t Marticot : 45 min ‚Äì depuis Pessac Unitec : 20 min","Lectra is looking for a QA Data Engineer to join their R&D Software department in Bordeaux/Cestas. The role involves validating datasets and their processing using manual and automated tests, working with the QA community to improve test strategies and tools, and contributing to the overall quality of software. Required skills include software testing methodology expertise, test automation proficiency, and experience with Git, Jenkins, Java, and SQL. The company offers an innovative, agile, and multicultural environment, along with attractive benefits and work-life balance opportunities. The position is based in Cestas.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
379,58102,https://www.welcometothejungle.com/fr/companies/altaide/jobs/data-engineer-media-de-premier-plan-h-f_paris,Data Engineer / Media de premier plan,ALTAIDE,"{Dataiku,Jenkins,Talend,GitLab,Shell,Airflow,DBT,Fivetran,Snowflake,via,Git,SQL,Python,linux}",T√©l√©travail partiel possible,"23 rue des Mathurins, Paris, 75008",Recrutement,CDI,2023-03-26,"Pionnier du recrutement digital, Alta√Øde est reconnu comme ¬´ LE ¬ª chasseur de t√™tes des startups et des entreprises en transformation digitale. Pr√©sents √† Paris, Bordeaux, Barcelone et Lisbonne, ils accompagnent leurs clients en Recrutement, Executive search, RPO et Conseil en France et √† l‚Äôinternational. Alta√Øde a r√©volutionn√© la chasse de t√™tes en inventant le social recrutement et en d√©veloppant une m√©thodologie √©prouv√©e qui s‚Äôappuie sur leur approche technologique du sourcing (LinkedIn Recruiter, Twitter, Marketing Automation, Programmatic, IA Search‚Ä¶). Ainsi depuis 2000, leur implication dans l‚Äô√©cosyst√®me, leur approche marketing, les moyens d√©ploy√©s en sourcing et la puissance de leur r√©seau relationnel, sont √† la base de leur succ√®s. D√®s la cr√©ation d‚ÄôAlta√Øde, ils ont adopt√© un style diff√©rent des cabinets de recrutement et autres chasseurs de t√™tes. Leur philosophie est bas√©e sur un m√©lange de fun, de professionnalisme, de proximit√© avec leurs clients et le secteur, et sur une approche conviviale de la relation candidat-recruteur. Seul cabinet fran√ßais du Top 25 Europe des Most Socially Engaged de Linkedin, et class√© dans les 50 meilleurs cabinets de recrutement des Echos, ils sont fortement reconnus pour leurs m√©thodes et leurs r√©sultats dans leur m√©tier. M√©dia presse et web de r√©f√©rence en France, nous sommes reconnus pour notre travail d‚Äôenqu√™te, de reportage et d‚Äôexpertise, notamment dans le domaine des id√©es, du savoir et de la science. Notre marque est historiquement pr√©sente en presse, largement √©tablie en num√©rique, et de fa√ßon physique (√©v√®nements). Notre qualit√© √©ditoriale alli√©e √† notre savoir-faire digital, font de nous un incontournable avec pr√®s de 15 millions de lecteurs web et une appli dans le Top 10 des applis d‚Äôinformations. Dans le cadre de l‚Äôacc√©l√©ration de la transformation num√©rique de notre mod√®le, nous recherchons un(e) Data Engineer qui deviendra le r√©f√©rent(e) Technologique du service Data. üéØUne missions riche : En tant que responsable de notre Data Plateforme, votre principale mission consiste √† op√©rer et superviser son impl√©mentation, sa gestion quotidienne (run, maintenance) ainsi que son am√©lioration continue. Pour cela, vous : Construisez, testez, maintenez et automatisez l‚Äôensemble des pipelines de donn√©es Connectez les sources de donn√©es √† la plateforme Data. Pour chaque source, vous recommandez et pr√©cisez les modalit√©s d‚Äôingestion recommand√©es et les donn√©es √† r√©cup√©rer Assurez la transformation des donn√©es (bronze vers or) en exploitant les langages et/ou outils ELT ad√©quats. Vous en structurez et en automatisez progressivement les diff√©rentes √©tapes. Assurez la migration des donn√©es ainsi que les traitements qui leur √©taient appliqu√©s vers la nouvelle plateforme Data, par priorit√©. Vous ajustez les nouveaux pipelines associ√©s en tenant compte des pipelines existants. Testez et d√©ployez des solutions d‚Äôobservabilit√© et de correction automatique pour am√©liorer la qualit√© des donn√©es. Savez d√©tecter les potentiels d‚Äô√©volution associ√©s √† chacune de ses composantes pour en maximiser la valeur ajout√©e (qualit√©, disponibilit√© des donn√©es, simplicit√© d‚Äôexploitation‚Ä¶), tout en minimisant ses co√ªts (de stockage, de requ√™tes, de maintenance‚Ä¶) Structurez et optimisez l‚Äôarchitecture de la plateforme Data (Warehouses et DataSets) en fonction des uses-cases et usages afin d‚Äôen permettre une exploitation simple, harmonieuse, contr√¥l√©e et √† co√ªts ma√Ætris√©s. Travaillez de mani√®re continue avec l‚Äô√©quipe Data : vous vous servez de ses besoins en mati√®re de Gouvernance / Data Analyse / Data Science / Compliance RGPD, comme use case pour guider vos actions, vos priorit√©s et alimenter votre feuille de route. Mettez ainsi √† disposition les donn√©es n√©cessaires aux diff√©rents utilisateurs, en adaptant les modalit√©s de mise √† disposition en fonction de leurs besoins. Connectez la Plateforme Data avec les solutions d‚Äôactivation de la donn√©e actuels ou √† venir : BI, marketing automation, CDP‚Ä¶ Assurez la gouvernance technique de la plateforme Data : vous structurez ou mettez √† jour en continu la partie technique de nos dictionnaires / mapping de donn√©es. Vous r√©digez les modes op√©ratoires, processus et RACI. Vous mettez en place l‚Äôensemble des r√®gles / scripts / filtres / s√©curit√©s / processus n√©cessaires Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun Master Informatique avec une sp√©cialisation dans la Data, vous disposez d‚Äôune exp√©rience d‚Äôau moins 4 ann√©es dans le milieu du Conseil en Data, ou sur un poste similaire au sein d‚Äôun environnement dynamique de transformation ou de croissance acc√©l√©r√©e. Vous √™tes reconnu pour votre parfaite ma√Ætrise de SQL et de Python . Vous avez une excellente connaissance des environnements Cloud de type Snowflake et des technologies Big Data. La certification SnowPro Core serait un vrai plus. Vous savez g√©rer la gouvernance d‚Äôune plateforme et en optimiser les co√ªts de fonctionnement (FinOps) . Vous ma√Ætrisez l‚Äôenvironnement DevOps via les outils de versioning (Git), les plateformes d‚Äôint√©gration continue (Jenkins, GitLab). Id√©alement, vous savez r√©aliser des programmes en Shell Script et connaissez les commandes standards sous linux. Vous avez une exp√©rience confirm√©e de d√©ploiement d‚ÄôETL (id√©alement Streamset de type Fivetran, Talend), de d√©ploiement de plateformes d‚Äôorchestration (Airflow, DBT) et de traitement automatis√©s des donn√©es (Saagie, Dataiku). Vous avez d√©j√† et aimez travailler en m√©thode Agile/Scrum , et vous √™tes √† l‚Äôaise dans un environnement dynamique. Votre leadership vous permet de mobiliser toutes les √©nergies des √©quipes, et faire adh√©rer les parties prenantes √† vos projets. Votre sens du service, de l‚Äô√©coute, votre esprit d‚Äô√©quipe et votre relationnel vous permettront de r√©ussir pleinement ces missions. Retrouvez notre offre : https://www.altaide.com/offre-emploi/digital-program-manager-ecole-digital/?utm_source=wttj&utm_medium=jobboard&utm_campaign=diffusion_w Pour ce poste, merci de contacter notre conseil en pr√©cisant la r√©f√©rence : LDE-12W Alta√Øde - Sonia Dujardin - 23, rue des Mathurins 75008 Paris E-Mail : sonia.dujardin@altaide.com","Alta√Øde, a French recruitment company specialized in startups and digital transformation, is looking for a Data Engineer to lead their Data department. The role involves building, testing, maintaining, and improving the company's data pipelines, connecting data sources and recommending ingestion methods, transforming data, migrating and optimizing data architecture, and ensuring governance and compliance. Candidates must have at least four years of experience in data consulting, expertise in SQL and Python, knowledge of Cloud environments and Big Data technologies, and experience in Agile/Scrum methodologies.",Bac +5 / Master,< 15 salari√©s,> 4 ans,2,1,0.04154662416233763
376,39685,https://www.welcometothejungle.com/fr/companies/tiime/jobs/data-engineer-f-h_paris_TIIME_4dyeeGa,Data Engineer,Tiime,"{Airflow,Kubernetes,Redshift,scale,Python}",T√©l√©travail partiel possible,"15-17 rue Auber, Paris, 75009","Application mobile, Organisation / Management",CDI,2022-11-29,"Tiime est une start-up fran√ßaise cr√©√©e en 2015. Chez Tiime, nous d√©veloppons LA super app pour entreprendre, au service des entrepreneurs fran√ßais et des experts comptables. C√¥t√© entrepreneur, la super app regroupe un maximum de fonctionnalit√©s pour g√©rer son entreprise au quotidien : facturation, achats, stockage des documents, compte pro. Le tout en 1 pour simplifier l‚Äôentrepreneuriat ! C√¥t√© expert-comptable, Tiime propose le meilleur de la technologie en mettant √† disposition des outils simples et puissants pour gagner en productivit√©, booster la croissance et repenser l‚Äôexp√©rience client. Pr√©curseur en mati√®re d‚Äôintelligence artificielle, Tiime est un acteur majeur de la digitalisation de la comptabilit√© et de la gestion financi√®re des entreprises. A travers ses produits, Tiime sert aujourd‚Äôhui le quotidien de plus de 100 000 entrepreneurs et 1 000 experts-comptables. Notre ambition ? Accompagner 1/3 des nouveaux cr√©ateurs d‚Äôentreprise en France et devenir le logiciel comptable leader du march√©. Pour atteindre cet objectif, nous renfor√ßons notre √©quipe Data et recrutons un Data Engineer (F/H). √áa te tente ? Rejoins notre aventure ! Tes missions : Au sein de l‚Äô√©quipe Data, en relation avec diff√©rentes √©quipes (les d√©veloppeurs back, l‚Äôinfra, le produit, le care, le marketing, la finance‚Ä¶) tu auras comme principales missions : D√©ployer, maintenir et am√©liorer en continu un projet de traitement de donn√©es en masse (transactions bancaires, documents justificatifs) dans un environnement de production int√©gr√© au cloud; vous aurez notamment l‚Äôopportunit√© d‚Äôagir sur : les bases de donn√©es; les pipelines qui les alimentent; le code permettant la bonne ex√©cution; l‚Äôinfrastructure (environnements de tests et de production); les outils de monitoring. Fiabiliser la donn√©e et en faciliter la distribution vers les autres √©quipes (back-end, produit, care, marketing, finance). Participer activement aux processus de relecture et contr√¥le du code. Participer √† l‚Äô√©laboration des sp√©cifications techniques. √ätre moteur de la veille technique. Contribuer √† la mont√©e en comp√©tence de l‚Äô√©quipe en valorisant le partage de comp√©tences et l‚Äô√©change Issu(e) id√©alement d‚Äôun Master en computer science ou d‚Äôune √©cole d‚Äôing√©nieur, tu justifies d‚Äôune premi√®re exp√©rience sur un poste similaire en tant que Data Engineer ou Data Architect (id√©alement acquise dans une scale-up). Tu es rigoureux(se), force de proposition, respectueux(se) de l‚Äôexistant et des √©quipes en place, humain et empathique. Tu ma√Ætrises les bases de donn√©es relationnelles (PostegreSQL, Redshift‚Ä¶) et les outils d‚Äôorchestration (Kubernetes, Airflow‚Ä¶). Une connaissance des outils de conteneurisation et de Python est un vrai plus. Ce que Tiime t‚Äôoffre : Un environnement de start-up made in France en pleine croissance. Un projet entrepreneurial ambitieux et challengeant. Tu rejoindras le leader de demain de notre secteur d‚Äôactivit√© Un projet qui impactera le quotidien de milliers d‚Äôentrepreneurs Une culture d‚Äôentreprise favorisant l‚Äôautonomie, la responsabilisation, la communication et la bienveillance‚Ä¶ Prends part √† une aventure humaine au c≈ìur d‚Äôenjeux entrepreneuriaux ! Impatient de nous rencontrer ? Alors n‚Äôh√©site pas √† postuler. Entretien RH Entretien technique avec un membre de l‚Äô√©quipe Entretien de validation avec notre CTO","Tiime, a French start-up that offers a super app for entrepreneurs and accounting experts, is seeking a Data Engineer to join their team. The ideal candidate should have a Master's in Computer Science or an Engineering degree, with experience as a Data Engineer or Data Architect. The role involves working with different teams to deploy, maintain and improve a project for processing large amounts of data in a cloud-integrated production environment, optimizing databases, pipelines, code execution, infrastructure, and monitoring tools. A strong knowledge of relational databases and orchestration tools is necessary, and knowledge of containerization and Python would be a plus. The company offers a challenging entrepreneurial project with autonomous and responsible work culture, a favorable work environment, and a leadership opportunity in the emerging industry.",N,N,N,2,1,0.04154662416233763
359,39648,https://www.welcometothejungle.com/fr/companies/equativ/jobs/data-engineer-business-process-automation_paris,Data Engineer - Business Process Automation,Equativ,"{Talend,color,Airflow,Snowflake,JAVA,SQL,Python,Tableau}",T√©l√©travail partiel possible,"66 rue de la Chauss√©e d'Antin , Paris, 75009",AdTech  / MarTech,CDI,2022-11-29,"Equativ is a French AdTech offering an advertising monetization platform for the most important websites in the world. Our objective‚ÄØ? Disrupt the digital advertising industry through high-performance solutions, innovative formats, and exceptional quality. Based in the heart of Paris (IX·µâ), the company continues its international development around the world (opening of the Singapore office in 2019). We have been recognized in the ‚ÄúChampions de la Croissance‚Äù rankings by Les Echos and the‚ÄùFast 500 EMEA‚Äù by Deloitte. Our pride? A team of over 500 employees who flourish through a corporate culture advocating ownership and who live through 3 essential values: Be brave, Be thoughtful, Be together. üë´ About the team Helping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Business Process Automation team (BPA) at Equativ, maximize the company‚Äôs efficiency by enabling easy and permanent access to quality data, and connecting pieces of software together to create business value. Our responsibility is to ensure fast, accurate delivery of the data within the company: The right data, at the right place at the right time. We truly believe in automation and technology to overcome manual repetitive tasks and make the best possible use of our time and brain. Your mission üëá We are looking for a Data Engineer to join our growing team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. What you'll do ‚úèÔ∏è - Develop database solutions to store and retrieve company information, and ensure their functionality - Design conceptual and logical data models and flowcharts - Acquire datasets that align with business needs - Build, test, and maintain optimal database pipeline architectures - Improve system performance by conducting tests, troubleshooting and integrating new elements - Assemble large, complex data sets that meet functional / non-functional business requirements. - Design or re-design infrastructure for greater scalability and optimal extraction, the transformation of data from different data sources - Optimize data delivery, and automate manual processes - Ensure a good data quality display - Collaborate with the data-analytics team to ensure a good and sustainable functionalities delivery - Develop algorithms to transform data into useful, actionable information - Collaborate with BPA team members to ensure team and company objectives About you üí™ - Bachelor's degree in computer science, Informatics, Information Systems, or another quantitative field - At least 3 years of experience as a data engineer or in a similar role - Experience using the following software/tools: - Experience with data pipeline and workflow management tools: Airflow - Knowledge of programming languages (SQL, JAVA, Python) - Experience with visualization tool: Tableau - A previous experience using Snowflake, Talend - Technical expertise in building and optimizing data pipelines, architectures and data sets. - Strong project management and organizational skills - Experience supporting and working with cross-functional teams in a dynamic environment. - Problem-solving attitude & ability to work toward multiple deadlines simultaneously üëã About us Equativ is the new single name for Smart Adserver, DynAdmic and LiquidM ‚Äî three proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication. Headquartered in Paris and New York, Equativ operates globally with a team of more than 450 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com . The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies. Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment. Come and lead the charge with us in building a transparent ecosystem based on quality! ---------------------- Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com","Equativ, the French AdTech company, is seeking a Data Engineer to join its growing Business Process Automation team. The role will focus on expanding and optimizing the company's data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. Candidates should hold a bachelor's degree in computer science, informatics, or another quantitative field, and have at least three years of experience as a data engineer or in a similar role. Technical skills required include knowledge of programming languages, experience with data pipeline and workflow management tools, and strong project management and organizational skills.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
375,57121,https://www.welcometothejungle.com/fr/companies/the-product-crew/jobs/data-engineer_paris,Data engineer,The Product Crew,{scale},T√©l√©travail partiel possible,"11 Rue Greneta, Paris, 75003",Recrutement,CDI,2023-03-26,"Chez The Product Crew, ils cherchent √† inventer le Futur du recrutement. Ils animent pour cela une communaut√© de membres s√©lectionn√©s pour leur talent en Product, Design, Data et Tech, avec pour vocation de leur apporter du soutien tout au long de leur vie professionnelle. Leur mission est d‚Äôaider les membres de cette communaut√© √† lib√©rer leur potentiel. Mais √©galement de permettre aux entreprises de construire et commercialiser les plus meilleurs produits technologiques. Pour cela, ils organisent du partage de connaissance (webinars, ateliers, meetups, masterclass, contenus exclusifs‚Ä¶) et des sessions intensives de recrutement en ligne. Fort d‚Äôune communaut√© de plus de 7500 talents et de plus de 400 entreprises technologiques partenaires; The Product Crew s‚Äôadresse sp√©cifiquement aux m√©tiers du Product, du Design, de la Data et de la Tech. Nous travaillons avec +400 startups et scale ups de la sc√®ne tech fran√ßaise et europ√©enne, √† la recherche de devs, ops, data engineers, scientists exp√©riment√©s de Confirm√©s √† C-Level : Heetch, Scaleway, Skello, Blablacar, Sendinblue, Mirakl, Partoo, Frichti, Swan, Jellysmack, MangoPay, Coinhouse‚Ä¶ mais aussi les startups d‚ÄôeFounders comme Collective Work, Numeral, ou Folk‚Ä¶ et bien d‚Äôautres. Nous d√©veloppons une communaut√© de hauts talents avec pour vocation d‚Äôapporter du soutien √† leur carri√®re tout au long de leur vie professionnelle. √âv√©nements, ressources, sessions de recrutement‚Ä¶ ü§ú D√©croche ton prochain r√¥le de Data Engineer avec l‚Äôaide de la communaut√© The Product Crew ü§õ üëâ Comme chaque 1er du mois, nous lan√ßons une nouvelle session de recrutement pour les Data Engineers exp√©riment√©s . Les inscriptions sont ouvertes pour quelques jours seulement : Tu as la possibilit√© de rendre ton profil visible aupr√®s de nos startups partenaires, Celles qui sont int√©ress√©es rentrent directement en contact avec toi, Nous t‚Äôaccompagnons tout au long du process. On sera ravis de t‚Äôaccompagner ton prochain objectif üöÄ L‚Äôinscription prend 5min. Pas besoin de CV, et c‚Äôest 100% gratuit üòä Voici le lien pour t‚Äôinscrire üëâ https://bit.ly/jobs-wttj En t‚Äôinscrivant 1 seule fois, tu pourras d√©crocher : üíé Des mises en relation directes avec les √©quipes de ces startups üíé Jusqu‚Äô√† 10 opportunit√©s concr√®tes en quelques jours üíé Que des √©quipes qui ont flash√© sur ton profil ‚ö°Ô∏è Tu peux postuler pour devenir membre de The Product Crew et participer √† cette session de recrutement (ou √† une prochaine). L‚Äôinscription prend 5min. Pas besoin de CV üòä En prenant ton caf√© ‚òïÔ∏è Inscription ici üëâ https://bit.ly/jobs-wttj","Looking for experienced Data Engineers, The Product Crew organizes online recruitment sessions to help members of their community achieve their career goals. They work with more than 400 French and European startups and technology companies, offering events, resources, and recruitment sessions to high-talented professionals in Product, Design, Data, and Tech. They provide direct connections to interested startups, support throughout the recruitment process, and opportunities to network and advance within their careers.",Non sp√©cifi√©,< 15 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
369,56688,https://www.welcometothejungle.com/fr/companies/alptis-assurances/jobs/data-engineer-h-f_lyon-3e,Data Engineer,Alptis Pr√©voyance & Sant√©,"{Talend,Snowflake,via,TALEND,Qlik}",T√©l√©travail partiel possible,"Lyon 3e, 69003",Assurance,CDI,2023-03-26,"L‚Äôambition d‚ÄôAlptis ? Permettre √† chacun d‚Äô√™tre acteur de sa sant√© ! Cr√©√© √† Lyon en 1976, Alptis est un groupement de protection sociale, ind√©pendant, associatif et entrepreneurial au mod√®le singulier dans le monde de l‚Äôassurance. Il s‚Äôinscrit dans le mouvement de l‚Äôentrepreneuriat soci√©tal porteur de valeurs et de convictions fortes : gouvernance participative et rentabilit√© raisonn√©e. Le Groupe Alptis intervient dans les domaines de l‚Äôassurance sant√©, de la pr√©voyance, de l‚Äôassurance de pr√™ts, de l‚Äô√©pargne retraite et du financement, pour les particuliers, les travailleurs non salari√©s et les entreprises. Nous sommes forts de : 600 collaborateurs engag√©s 475 000 adh√©rents 7 900 courtiers et conseillers en gestion de patrimoine ind√©pendants Rejoindre Alptis, c‚Äôest int√©grer un groupe qui conjugue bienveillance et performance, o√π l‚Äôon joue collectif, dans lequel on peut grandir et vivre des projets enrichissants. Nous recrutons pour notre si√®ge √† Lyon un Data Engineer (H/F) en CDI au sein de la Direction Digitale et Transformation. Notre objectif : renforcer l‚Äô√©quipe DATA du groupe Alptis pour mener √† bien l‚Äôensemble des projets permettant √† Alptis de devenir DATA Driven. Au sein de notre √©quipe, en tant que Data Engineer, vous avez la charge d‚Äôaccompagner les diff√©rents projets et certaines activit√©s de maintenance sur la nouvelle plateforme. Notre stack techno : Talend / Snowflake / Qlik / BO. Votre r√¥le est d‚Äôintervenir sur des missions diversifi√©es : Conception/r√©alisation des flux d‚Äôalimentations de notre Datawarehouse en provenance de nombreuses sources de donn√©es au moyen de l‚Äôoutil TALEND, Participation avec nos architectes DATA √† la mod√©lisation de notre Datawarehouse Collaboration avec nos Data analyst pour exposer les donn√©es aux meilleurs formats via les outils BO et Qlik ou aux Data Scientists. Vous agissez en tant qu‚Äôexpert Data et partagez vos connaissances avec d‚Äôautres data engineers, les parties prenantes de l‚Äôentreprise et avec les experts de la plateforme. Savoirs et savoirs faire : Vous √™tes de formation bac+5 en √©cole d‚Äôing√©nieur ou cursus informatique, Vous avez une exp√©rience de 3ans minimum en tant que Data Engineer, Vous avez une tr√®s bonne connaissance des ETL et de plateformes BIG DATA ainsi que des outils de data visualisation comme BO ou Qliksense, Id√©alement, vous maitrisez Talend, Mod√©liser des donn√©es, Vous proc√©dez √† l‚Äôimpl√©mentation d‚Äôarchitectures de flux de donn√©es, Savoirs Etre : Autonome, rigoureux et force de proposition. Vous poss√©dez d‚Äôexcellentes capacit√©s d‚Äôanalyse et de synth√®se. Rejoindre ALPTIS c‚Äôest b√©n√©ficier des avantages suivants : 10 jours de t√©l√©travail possible par mois, Mutuelle prise en charge √† 100% par l‚Äôemployeur, 14 RTT/an, Carte tickets-restaurant, Indemnit√©s kilom√©trique v√©lo, Contrat retraite compl√©mentaire. Un parking √† disposition des collaborateurs. Id√©alement situ√©s dans le quartier de la manufacture des tabacs, nos locaux sont √† quelques minutes √† pied du m√©tro D ‚ÄúSans Souci‚Äù et du tramway ‚ÄúManufacture Montluc‚Äù.","Alptis, an independent and entrepreneurial social protection group, is looking for a Data Engineer to reinforce its data team in Lyon. The ideal candidate should have a bachelor's degree in engineering, at least three years of experience in data engineering, and expertise in ETL and BIG DATA platforms. Collaboration skills, autonomy, rigor, and proposal force are also essential to the role. The company offers benefits such as telework, 100% employer-paid health insurance, 14 RTT per year, restaurant tickets, and retirement contract.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
367,56809,https://www.welcometothejungle.com/fr/companies/datadog/jobs/engineering-manager-1-data-science-core-models_paris,Engineering Manager 1 (Data Science) - Core Models,Datadog,"{Java,Go,color,Scala,Anomaly,scale,Datadog,Python}",T√©l√©travail partiel possible,"21 Rue de Ch√¢teaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. The Team The Core Models team owns time series algorithms that power features across the Datadog application. We are responsible for the implementation and performance of the algorithms, as well as the internal tooling to evaluate and iterate on them. Our models power features such as Watchdog Alerts and Log Anomaly Detection . As the Engineering Manager of the Core Models team, you will lead and grow a team of Data Scientists and Software Engineers that own the implementation and development of our core time series models. These models are at the heart of Data Science efforts and are driving an increasing number of use cases. At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them. What you'll do: Lead and develop an amazing team of data scientists and software engineers. Develop a strategy to build common services and components encapsulating data science capabilities for other products and teams to leverage. Ensure that our data science-driven features continue to scale well as Datadog adds more customers and ingests more data per customer. Collaborate with stakeholder teams to develop joint roadmaps that provide the underlying primitives required to execute the vision of the product. Ensure the development and continuous improvement of a scalable and reliable architecture that can keep up with the growth of the product in a sustainable manner. Who you are: You have 1+ years experience managing software engineers or data scientists. You have 5+ years of experience designing and building machine learning systems. You have experience in working and communicating effectively in a fast-paced, high-growth, distributed organization. You have partnered with product management in the past to set the vision and strategy for your projects. You value simplicity and getting the right things done. Nice to Haves: You have experience working with Data Science algorithms (Statistics, AI/ML). You have experience working with microservices and/or distributed systems. You have experience working with time series data. You have experience working in Python, Java, Scala or Go. You have experience working on big data / analytical systems. Datadog values people from all walks of life. We know not everyone will meet all the above qualifications on day one. That‚Äôs okay. If you‚Äôre passionate about technology and want to grow your experience, we encourage you to apply. Benefits & Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more #DatadogLife on Instagram , LinkedIn and Datadog Learning Center . #LI-AA5 About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog‚Äôs Applicant and Candidate Privacy Notice .","Datadog is seeking an Engineering Manager for its Core Models team responsible for implementing and developing the algorithms that power features across the Datadog application such as Watchdog Alerts and Log Anomaly Detection. The successful candidate should have experience managing software engineers or data scientists, and designing and building machine learning systems. They should also be able to work and communicate effectively in a fast-paced, high-growth, distributed organization, and partner with product management to set the vision and strategy for their projects. Experience in Data Science algorithms, microservices and/or distributed systems, time series data, and working in Python, Java, Scala or Go is a plus.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
366,37418,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-h-f_aix-en-provence,Data Engineer,Thales,"{Couchbase,MapR,Mongo,Nifi,HBase,Kafka,Spark,Marklogic,NoSQL,Hadoop,Python,Cloudera}",T√©l√©travail partiel possible,N,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2022-10-18,"Ceux qui font avancer le monde s‚Äôappuient sur Thales. Dans un monde en constante mutation, √† la fois impr√©visible et riche d‚Äôopportunit√©s, ils sont aux c√¥t√©s de ceux qui ont de grandes ambitions : rendre le monde meilleur et plus s√ªr. Riches de la diversit√© de leurs expertises, de leurs talents, de leurs cultures, leurs √©quipes d‚Äôarchitectes con√ßoivent un √©ventail unique de solutions technologiques d‚Äôexception, qui rendent demain possible d√®s aujourd‚Äôhui. Du fond des oc√©ans aux profondeurs du cosmos ou du cyberespace, ils aident leurs clients √† ma√Ætriser des environnements toujours plus complexes pour prendre des d√©cisions rapides, efficaces, √† chaque moment d√©cisif. Quel que soit l‚Äôenjeu. QUI SOMMES-NOUS ? Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces. QUI ETES VOUS ? Vous aimez le travail en √©quipe? Vous √™tes reconnu/e pour votre dynamisme et votre rigueur ? Si vous vous reconnaissez, vous avez alors toutes les qualit√©s pour rejoindre nos √©quipes ! CE QUE NOUS POUVONS FAIRE ENSEMBLE Rattach√©(e) √† la direction d‚Äôing√©nierie du logiciel d‚ÄôAix-En-Provence, votre mission sera de faire du d√©veloppement en environnement Big Data tout en gardant une vue globale du besoin. Vos missions principales sont les suivantes : Concevoir, d√©velopper et d√©ployer des pipelines de transformations de donn√©es en environnement Big Data Maintenir et param√©trer des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, ‚Ä¶) R√©aliser des prototypes sur des technologies et de la veille technologique sur le Big Data Comp√©tences techniques autour des produits Data / Big Data: Solution Hadoop Spark, Python Bases NoSQL (Mongo, HBase, Couchbase, Marklogic‚Ä¶) Capacit√© √† travailler en √©quipe, et dans une organisation Agile type Srcum ou SAFE Apportez votre cr√©ativit√©, nous saurons vous accueillir dans une √©quipe passionn√©e et dynamique pour b√¢tir le nouveau monde du digital ! Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is seeking a Big Data Engineer with experience designing, developing, and deploying data transformation pipelines in a Big Data environment. The candidate must have experience with Hadoop, Spark, Python, and NoSQL databases, as well as working in an Agile organization. The role involves maintaining and configuring Big Data clusters and conducting research on new Big Data technologies. The ideal candidate is a team player with strong attention to detail and a passion for innovation.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
364,49687,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-paris-or-remote-france_paris_DATAI_Lz5KM9M,Software Engineer Data Preparation - Paris or Remote France,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",T√©l√©travail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working '≈ìunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is looking for a full-stack software engineer with experience in software development and an interest in data processing. The ideal candidate will be customer-oriented and interested in solving actual customer problems. They should have experience building a real product, be curious about working ""under the hood,"" and have firsthand experience in data preparation. Dataiku values autonomy, work-life balance, camaraderie, and giving back to the community. The company is an equal opportunity employer.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
361,49717,https://www.welcometothejungle.com/fr/companies/carboat-media/jobs/data-engineer_paris,Data Engineer,Groupe La Centrale,"{Jupyter,Athena,Scala,Pandas,Redshift,Numpy,Glue,AWS,S3,Lambda,Scipy,Spark,Sagemaker,Python,Elastic,Tableau}",T√©l√©travail partiel possible,"37, Rue du Rocher, Paris, 75008","√âconomie collaborative, M√©dia",CDI,2023-02-07,"Le Groupe La Centrale est le groupe sp√©cialiste des marketplaces auto (La Centrale, Promoneuve et maVoitureCash) et du contenu √©ditorial (Caradisiac et Forum Auto). Avec plus de 50 millions de visites par mois, nous sommes la r√©f√©rence pour acheter, vendre et consulter un maximum d‚Äôinformations sur un v√©hicule. Nous sommes aujourd‚Äôhui plus de 200 collaborateurs qui participent √† l‚Äô√©volution de notre entreprise en g√©n√©rant un chiffre d‚Äôaffaires de 70 millions d‚Äôeuros. Notre mission est de rendre la d√©marche d‚Äôachat et de vente la plus simple et sereine possible, √† l‚Äôoccasion d‚Äôune d√©cision de vie engageante (le changement de voiture). Faciliter la recherche, exposer et d√©crypter toutes les informations utiles sur un v√©hicule, apporter davantage de transparence sont au c≈ìur de notre strat√©gie. Le Groupe dispose d‚Äôun √©cosyst√®me unique de marques compl√©mentaires, qui nous positionnent sur toutes les d√©marches digitales : ‚Ä¢ L‚Äôachat de v√©hicules d‚Äôoccasion avec La Centrale ‚Ä¢ L‚Äôachat de v√©hicules neufs avec Promoneuve ‚Ä¢ La vente de v√©hicules aupr√®s de Professionnels partenaires avec mavoiturecash ‚Ä¢ Toute l‚Äôactualit√© automobile enfin (essais, guides, comparatifs et avis) avec Caradisiac Sa vision strat√©gique ? Avoir toujours une longueur d‚Äôavance Chez le Groupe La Centrale la Data est au centre du business pour accompagner au mieux l‚Äôentreprise et les d√©cideurs ! Dans l‚Äôobjectif de faire de Groupe La Centrale une entreprise Data-Driven nous souhaitons renforcer notre √©quipe Data. Membre de la feature team Data compos√©e de 8 personnes dont 2 OPS; L‚Äô√©quipe DATA g√®re et construit la plateforme data BI, en supervisant notamment la construction d‚Äôun datalakehouse, au service de nos utilisateurs Tableau. Elle assure √©galement le d√©veloppement de l‚Äôalgorithme de cotation des v√©hicules d‚Äôoccasion (machine learning) En endossant le r√¥le de Data Engineer au sein de la feature team Data, tu auras pour r√¥le de participer aux d√©veloppement de la plateforme BI et de l‚Äôapplication ‚Äúla cote‚Äù Voici les missions qui te seront confi√©es : D√©velopper et assurer la mise production de nouvelles applications de pr√©dictions ou de nouveaux pipelines de donn√©es (ingestion, traitement, exposition) Contribuer aux choix de conception avec l‚Äô√©quipe, participer aux d√©veloppements et d√©ployer des infrastructures cloud AWS orient√© BigData Identifier les axes d‚Äôam√©lioration et de consolidation de notre plateforme Travailler en collaboration avec les data scientists ou les data analysts pour leur fournir un support Participer aux √©v√®nements (Workshop Group, Tableau Conf√©rence, AWS Summit‚Ä¶) Profil exp√©riment√©, tu as un fort int√©r√™t pour la data et tu as d√©j√† travaill√© sur des syst√®mes cons√©quents. Les bonnes pratiques et leur partage font partie de ton quotidien et tu es un r√©f√©rent pour ton √©quipe. Scala et Spark n‚Äôont pas de secrets pour toi. Une exp√©rience cloud serait un vrai plus. Un niveau d‚Äôanglais technique est requis et le poste implique de pouvoir collaborer ponctuellement avec les √©quipes de notre groupe Axel Springer. hardskills : Scala sur AWS Glue (Spark) AWS Redshift, Spectrum, AWS S3, Athena Python, Pandas, Jupyter Notebook, Scikit-learn, Numpy, Scipy AWS Sagemaker, AWS Lambda, AWS Codebuild, AWS ECR Tableau, Elastic Search Pourquoi GLC ? Int√©grer Groupe La Centrale c‚Äôest d√©velopper sa passion pour les technologies innovantes au sein d‚Äôune soci√©t√© web dynamique et de taille humaine avec des d√©veloppeurs ayant √† c≈ìur le partage de leur savoir-faire technique et agile. Nos petits plus : Mac ou PC, c‚Äôest toi qui choisis ! Participation √† des conf√©rences Petits d√©jeuner gratuits et Friday Pub S√©minaire annuel Participation attractive CE Quartier sympa (Saint-Lazare) D√©roulement des entretiens ‚Ä¢ Un call de 30 min avec Dalila, RH, et Chritophe, Deputy CTO ‚Ä¢ un Test ‚Ä¢ Une rencontre avec l‚Äô√©quipe et le futur Manager Christophe √† Paris","The Groupe La Centrale is seeking an experienced Data Engineer to join its Data team. The candidate must have experience with Scala on AWS Glue (Spark), AWS Redshift, AWS Sagemaker, and be knowledgeable in Python, Pandas, Jupyter Notebook, Scikit-learn, Numpy, Scipy, AWS Lambda, AWS Codebuild, AWS ECR, Tableau, and Elastic Search. The role will involve developing and deploying cloud infrastructure, working with data scientists and analysts, and participating in company events. The successful candidate will share the company's focus on simplifying and transparently communicating information to customers looking to buy or sell a car. The company offers a dynamic and collaborative work culture in a web-focused and growing business.",N,N,N,2,1,0.04154662416233763
360,49670,https://www.welcometothejungle.com/fr/companies/helexia/jobs/data-manager-f-h,Data Engineer,Helexia,{},T√©l√©travail partiel possible,La Madeleine,"Bureau d'√©tudes et d'ing√©nierie, Energie, Accompagnement d'entreprises",CDI,2023-02-07,"Fond√©e en 2010 avec la volont√© d‚Äôallier √©conomies & √©cologie, Helexia est expert de la transition √©nerg√©tique au service des organisations. Ils offrent √† leurs clients la possibilit√© de s‚Äôinscrire dans une d√©marche RSE tout en r√©alisant des √©conomies et ce, quel que soit leur niveau de maturit√© sur le sujet. Avec +250 collaborateurs pr√©sents dans 6 pays et avec la premi√®re famille industrielle et commerciale de France comme principal actionnaire, Helexia est un acteur majeur du march√© de la transition √©nerg√©tique. Aujourd‚Äôhui, seul acteur du march√© √† ne d√©pendre ni d‚Äôune technologie ni d‚Äôun producteur d‚Äô√©nergies classiques/fossiles, Helexia travaille donc en toute ind√©pendance. Helexia accompagne durablement et dans la totalit√© votre d√©marche de transition √©nerg√©tique. Au sein de l‚Äô√©quipe DAO (Digital Asset & Operation), le (la) Data Engineer F/H contribue √† la coh√©rence des syst√®mes d‚Äôacquisitions des donn√©es m√©tiers (Production & suivi d‚Äô√©nergies/ressources) afin d‚Äôassurer la double mission de disponibilit√© de flux de donn√©es pour les Business Units (+ de 6 localit√©s internationales √† ce jour) & l‚Äôagr√©gation de KPI consistants pour le compte du Groupe. Le (la) Data Engineer F/H se verra confier les responsabilit√©s suivantes, sans que cette liste ne soit exhaustive : ‚û° Administration et Maitrise d‚ÄôOuvrage de l‚ÄôEnergy Monitoring System groupe & solutions monitoring locales ; ‚û° Int√©gration au projet strat√©gique ‚ÄúGroup Data Architecture 2.0‚Äù ; ‚û° D√©veloppement d‚Äôautomatisations m√©tier (API / Power Automate / Script‚Ä¶) ; ‚û° Assistance au d√©ploiement d‚Äôoutils m√©tiers groupe. Le r√¥le du (de la) Data Engineer F/H est de : ‚û° D√©velopper des solutions d‚Äôacquisition de donn√©es r√©pondant aux imp√©ratifs divers des assets d‚ÄôHelexia (centrales photovolta√Øques, groupes froids, bornes de mobilit√©‚Ä¶) ; ‚û° Manager l‚Äôint√©gralit√© de l‚Äôoutil EMS groupe et de son infrastructure ; ‚û° Assurer le support de niveau 2 : G√©rer l‚Äôensemble des demandes de support interne sur les outils mis en place ; ‚û° Strat√©gie : Aligner les outils avec la strat√©gie groupe DTO. Helexia est certifi√©e ISO 9001. Dans ce cadre chaque collaborateur s‚Äôengage √† respecter les proc√©dures en place et √† contribuer √† l‚Äôam√©lioration continue du syst√®me. Pour mener √† bien ces missions, vous √™tes dipl√¥m√© Bac +4 ou +5 et justifiez d‚Äôune exp√©rience de 2 ans minimum. Vous √™tes capable de ma√Ætriser un EMS ainsi que des protocoles d‚Äôacquisition de donn√©es. Vous avez un bon niveau d‚Äôanglais qui vous permet de collaborer de fa√ßon efficace √† l‚Äô√©crit comme √† l‚Äôoral. Techniquement curieux et pragmatique, orient√© r√©solution de probl√®mes, vous exercez votre m√©tier avec enthousiasme. Polyvalent(e) et dot√©(e) d‚Äôun excellent relationnel, vous aimez travaillez en √©quipe et savez vous adapter √† des situations vari√©es ainsi qu‚Äô√† vos diff√©rents interlocuteurs. Enfin, vous √™tes convaincu.e que les √©nergies renouvelables ont un r√¥le majeur √† jouer dans l‚Äôavenir et souhaitez √™tre acteur de ce changement, vous avez envie de vous investir dans une structure en plein d√©veloppement, porteuse d‚Äôun projet ambitieux et passionnant. Helexia reconna√Æt et recrute tous les talents. Tous nos postes sont ouverts aux personnes en situation de handicap.","The Data Engineer at Helexia will ensure consistency in business data acquisition systems to provide consistent KPIs for the company. Responsibilities include administration of the Energy Monitoring System (EMS) group, integration into the Group Data Architecture 2.0 project, developing automation scripts, ensuring availability of data flows, and aligning tools with the DTO group's strategy. The ideal candidate is technically curious, pragmatic, has an excellent relationship building, and has a good level of English. They must have a Bachelor's or Master's degree and at least two years of relevant experience in handling EMS and data acquisition protocols.",Bac +4,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
353,34884,https://www.welcometothejungle.com/fr/companies/kisio-digital/jobs/data-engineer-h-f_paris,Data Engineer -,Kisio Digital > Hove,"{OpenStreetMap,python,Jenkins,Go,Git,GitHub,Kubernetes,AWS,Docker,github,Linux,Spark,kafka,RabbitMQ,kinesis,Github,Python}",T√©l√©travail partiel possible,Paris,"Application mobile, Mobilit√©, SaaS / Cloud Services",CDI,2022-08-08,"Avec plus de 15 milliards de requ√™tes par an, Kisio Digital business unit de Kisio et filiale num√©rique du Groupe Keolis est un acteur majeur de la mobilit√©. Les trois grands domaines d‚Äôintervention de Kisio Digital portent sur les syst√®mes d‚Äôinformation-voyageur (recherche d‚Äôitin√©raire multimodal, porte-√†-porte et temps-r√©el) ; l‚Äôachat de titres de transport d√©mat√©rialis√©s et le mobile-ticketing. Sa vision de la mobilit√© : permettre √† chacun de se d√©placer plus facilement, plus agr√©ablement et avec le moins d‚Äôemprise possible sur la plan√®te. C‚Äôest ce qu‚Äôon appelle la ¬´ responsive locomotion ¬ª ! Kisio Digital travaille continuellement √† l‚Äôam√©lioration des algorithmes qui permettent de calculer les meilleures solutions d‚Äôitin√©raire en tenant compte du contexte et des pr√©f√©rences du voyageur. Pour r√©pondre aux enjeux d‚Äôune mobilit√© plus intelligente, plus ouverte et plus √©cologique, Kisio Digital r√©alise des applications mobiles, des sites web et des SDK bas√©s sur notre API www.navitia.io. Cette plateforme propose des services num√©riques de mobilit√© dans le monde entier. Elle rassemble une communaut√© de 20 000 d√©veloppeurs et participe √† leur strat√©gie d‚Äôinnovation ouverte et collaborative. Vous trouverez parmi eux des ferrovipathes, v√©lomanes, bussophiles, et autres passionn√©s de montgolfi√®re ou de transports pas toujours tr√®s communs. Curieux et ouverts d‚Äôesprit, ils sont passionn√©s par la mobilit√© au sens large, les nouvelles technologies et les communs num√©riques auxquels ils contribuent : open data transport, open source, open innovation et partage de la connaissance avec la communaut√© Open transport. Si vous souhaitez vous √©panouir dans un environnement multiculturel, sachez que Kisio Digital va d√©sormais lancer des services √† l‚Äô√©tranger. Rejoignez-les ! En tant que Data engineer Navitia, vous √™tes int√©gr√© √† une √©quipe pluridisciplinaire m√™lant d√©veloppeurs, Product Owner et Architectes dont l‚Äôobjectif est de mettre en place un syst√®me de collecte, agr√©gation, mise en qualit√© de donn√©es pour les services d‚Äôinformation voyageur (itin√©raires, horaires √† l‚Äôarr√™t, perturbations, etc.). Les donn√©es manipul√©es sont tr√®s vari√©es (OpenStreetMap, GTFS de Paris, de New-York ou d‚ÄôAccra, v√©lo en libre services, etc.) et n√©cessitent des contr√¥les et des traitements tr√®s sp√©cifiques ; et de m√©langer ces donn√©es avec des centaines de flux temps r√©el par seconde pour finalement les int√©grer dans nos syst√®mes et ainsi r√©pondre aux 15 milliards de requ√™tes annuelles. Et surtout, ne jamais avoir pas peur ‚Ñ¢. Avec cette √©quipe, vous assurerez les missions suivantes : Participer √† la cr√©ation et √† l‚Äô√©volution du moteur d‚Äôingestion et de mise en qualit√© des donn√© Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners Concevoir techniquement la solution en collaboration avec les architectes, SRE, m√©tier‚Ä¶ Superviser et monitorer le d√©ploiement et la robustesse des composants mis en production Participer activement √† la qualit√© de l‚Äôing√©nierie logicielle (Relecture de code, test, int√©gration continue, d√©ploiement, etc.) Chiffrage des demandes d‚Äô√©volution Le Rust vous passionne, python ne vous fait pas peur, et le Go vous inspire Vous √™tes familier avec les probl√©matiques li√©es au contexte multi-threads Vous avez d√©j√† travaill√© avec un pubSub (kafka/kinesis) et un syst√®me de Queue tel que RabbitMQ Vous √™tes curieux des nouvelles technos et aimez partager ce que vous d√©couvrez, tout en sachant que tout r√©√©crire n‚Äôest pas toujours une bonne id√©e Vous √™tes motiv√© √† partager votre code source sur GitHub et √† participer √† l‚Äôaventure Open Source Navitia Vous avez une certaine culture de la mesure, de la m√©trologie du code et de son fonctionnement Anglais professionnel Vous √™tes pragmatique : la bonne techno pour r√©pondre au besoin, ni plus, ni moins. Vous √™tes responsable : Vous vous engagez sur un chiffrage, vous le respectez Vous justifiez d‚Äôune exp√©rience d‚Äôau moins. 2 ans sur un poste similaire Vous ma√Ætrisez : Linux Rust, Go, Python Apache Spark, PubSub & Queue‚Ä¶ Cloud Public (AWS‚Ä¶) Git, SonarQube, Jenkins Docker, Kubernetes Partagez avec nous votre Github, nous vous donnons le n√¥tre : https://github.com/CanalTP/navitia pour l‚Äôinformation voyageur, et https://github.com/CanalTP/transit_model / pour la manipulation du mod√®le de donn√©es !","Kisio Digital, a major player in mobility, is seeking a Data Engineer Navitia to develop a system for collecting, aggregating and ensuring the data quality of travel information services such as itineraries, stop schedules and disruptions, integrating that into its systems and responding to the 15 billion annual queries. Applicants should be familiar with Rust, Python and Go, have worked with pubSub (kafka/kinesis) and Queue systems such as RabbitMQ, be curious about new tech and have a culture of measurement, and must have at least two years of experience on a similar post.",N,N,N,2,1,0.04154662416233763
470,57106,https://www.welcometothejungle.com/fr/companies/mytraffic/jobs/engineering-manager-data-team_paris,Engineering Manager - Data Team,MYTRAFFIC,"{scale,via}",T√©l√©travail partiel possible,"37, Avenue Trudaine, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, SaaS / Cloud Services",CDI,2023-03-26,"Mytraffic, created in 2016, aims to boost the performance of commercial real estate players (Retail, Real Estate, Local Authorities, Consultancy) thanks to an innovative Saas solution raising the real world to the level of the digital world in terms of data analytics. We have already convinced more than 420 clients (Nhood, Nuveen, H&M, Dyson, Amorino, Carrefour, Klepierre, American Express, BNP) to work with us across Europe to help them expand their business, analyze and predict the performance of their investments, understand their customers‚Äô habits and benchmark themselves against their competitors. Mytraffic is a hyper growing scale up (+110%/year) supported by 30 Millions ‚Ç¨ Series B fundraising round with Axa Venture Partners, Alven and Kernel Investissements in November 2022 to finance its European expansion. Their ambition is to quickly become the European leader in data solutions for commercial real estate. Their values are: Believe in DATA Only MERIT prevails Be AMBITIOUS Work together with EMPATHY See things ANOTHER WAY Get it DONE You‚Äôll be focused on people and delivery execution. Reporting to the CTO. The Engineering Manager is in charge of the Data Team. Within this feature team: - is responsible for keeping people happy and motivated to work at Mytraffic (KR = employee retention rate, internal satisfaction surveys).
- is responsible for ensuring that pace of delivery stays high (KR = delivery results of the team) After building solid statistics on pedestrian and vehicle data geolocation, we continue to improve the performance of our algorithms. We plan to explore other data sources (social network data, banking transactions‚Ä¶) to integrate into our platform. The goal is to use these new datasets with existing ones to provide metrics to our customers to drive even better decisions. The Engineering Manager must have a technical background to understand the team‚Äôs blockers, to be able to evaluate individual contributions and to recruit effectively for the team (technical skills will be evaluated during the recruitment process). The Engineering Manager is not responsible for taking technical decisions within the team (but may have good insights), this is the scope of the tech lead. The Engineering Manager should take only 0-20% of its time in the code, to be familiar with the stack and understand the blockers, without slowing down the team as a whole. Tech Team Philosophy ‚Üí test, test, test. At Mytraffic, every line of code in production is a tested one, whether in the back or in the front end. ‚Üí constantly improve and help others. Whether on a daily basis via code reviews, or occasionally via workshops. Our goal is to progress together towards exemplary technical quality. ‚Üí questioning our processes and technical choices, proposing solutions and bringing up existing problems. Critical thinking is a guarantee of excellence. ‚Üí evolve according to your inclinations, we offer to help you grow by joining other teams during your career, or to specialise in the technology of your choice ‚Üí Participate in design thinking with the Product Manager, Designer and other stakeholders This job was meant for you if‚Ä¶ You have at least 7 years of experience in technologies similar to ours with operational constraints. Background in mentoring / leading a development team You have a good attitude towards change and uncertainty about the future, which is common in young, fast-growing start-ups. You are able to provide constructive and reasoned criticism of architectural and design decisions. You have the ability to give a relevant opinion on important business decisions such as hiring, implementing new processes, changing methods when necessary. Your written and verbal communication is good and concise so that you can easily convey your thoughts, opinions and feelings to other team members, teammates, clients or founders. You are open to feedback in order to continue to improve. What we offer Competitive salary: our demand for excellence pushes us to recruit the best profiles Possibility to dedicate 4 days a year to an association during your working time because Mytraffic‚Äôs values also lie in having a positive impact around us Frequent team building activities such as renting a house in the countryside to spend a week together because team spirit is at the heart of our values at Mytraffic Development opportunities for all our employees through workshops such as ‚ÄúFeedback culture‚Äù, ‚ÄúNon Violent Communication‚Äù, ‚ÄúWomen in leadership‚Äù (at Mytraffic, half of our managers are women) And as a bonus, we have great offices in the centre of Paris (75002) Interview process (2 weeks long) Call with our Talent Acquisition Manager First meeting with our CTO Meeting with Tech Leads Onsite Meeting with our CTO + the team Interview with our CEO","Mytraffic, a hyper-growing scale-up, is seeking an Engineering Manager to lead its data team responsible for data analytics for commercial real estate. The individual must have at least seven years of experience in similar technologies with a background in mentoring/leading a development team. The Engineering Manager is expected to help people and deliver results while keeping pace high at Mytraffic. The company values critical thinking, questioning processes and technical choices, and evolving the team members. The firm is currently preparing for European expansion, aiming to become the leader in data solutions for commercial real estate.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 7 ans,2,1,0.04154662416233763
225,56393,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_lyon,Data Engineer,ASI,"{Oracle,SAS,Talend,SAP,QlikView,Qlik}",T√©l√©travail partiel possible,Lyon,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ VOS MISSIONS Analyser et comprendre les besoins client Participer aux diff√©rentes phases : - Conception d‚Äôarchitecture d√©cisionnelle et technique - R√©daction des sp√©cifications fonctionnelles et techniques - Traitement de la donn√©e, concevoir et sp√©cifier les jobs d‚Äôalimentation - Construction de cubes de donn√©es - D√©veloppement des rapports - Tests et recette - Mise en production PARLONS DE VOUS Vous √™tes pr√™t √† monter en comp√©tences sur de nouvelles solutions, l‚Äôenvie d‚Äô√©largir votre spectre technologique. Vous √™tes curieux, rigoureux, analytique, dynamique et dot√© d'une grande capacit√© d'adaptation. Vous avez de l'app√©tence et/ou connaissance des nouveaux concepts de la data (Data Mining, Data Visualisation, Data Lake, ‚Ä¶) De formation sup√©rieure avec une exp√©rience r√©ussie sur un poste similaire avec les comp√©tences suivantes : - Travailler sur des projets de Data Intelligence, de fa√ßon autonome ou au sein d‚Äôune √©quipe - Ma√Ætrise d‚Äôune ou plusieurs solutions du march√© - Alimentation et stockage de donn√©es : SSIS, Talend, Oracle Data Integrator, SAP Data Services, ‚Ä¶ - Analyse : SSAS, SAS, ‚Ä¶ - Restitution : SSRS, SAP BO, QlikView, Qlik Sense, Power BI Ensemble, nous saurons d√©velopper vos comp√©tences et enrichir votre exp√©rience ! Alors rejoignez-notre Team ASI !","ASI, a digital expertise firm, is seeking a Data Intelligence Consultant with experience in data mining, data visualization, and data lakes. The candidate must be curious, rigorous, analytical, dynamic, and adaptable. The role involves analyzing client needs and participating in various project phases, including developing reports, constructing data cubes, and testing. The company values a responsible digital world for humans and encourages employees to develop new skills and expand their technological horizons.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
78,56726,https://www.welcometothejungle.com/fr/companies/psl-1/jobs/data-engineer_paris,Aqemia - Data Engineer,Deeptech @ PSL,"{regard,python,color,Kubernetes,AWS,K8s,instrumental,SQL}",T√©l√©travail partiel possible,"33, Rue Censier, Paris, 75005","Formation, Incubateur / Acc√©l√©rateur",CDI,2023-03-26,"This job offer is for Aqemia, a start-up issued from PSL University Ecosystem, with the following description: At Aqemia you will work in a multi-disciplinary team of passionate drug hunters, AI engineers and developers who are committed to our mission of finding many drugs, at high pace, to cure diseases. As part of our growing team, you will enjoy a fast-paced, challenging, science-driven and creative environment, working at the very forefront of AI & Deep physics-powered drug discovery. This is a tremendous opportunity to bring your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team. We are looking for highly skilled and collaborative individuals who are naturally curious, have a passion for learning and solving complex problems with a ‚Äúcan-do‚Äù mindset. If this sounds exciting to you, come and join us! The difference you‚Äôll make As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia‚Äôs engineering teams. You will also support engineering Teams to build their Data pipeline and assets. This way, you will be instrumental in all engineering teams‚Äô success. Our Workplace Environment Fast-paced, intellectually and scientifically demanding, results-driven. Our Founders boast: 10+ years experience in research at Ecole Normale Sup√©rieure in Paris, not to mention a stint in Oxford and Cambridge. 10+ years experience in strategy consulting at BCG. Aqemia has a rapidly growing team of +40 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale Sup√©rieure, Ecole Polytechnique, BCG) Our premises are conveniently located in center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work. Working language: English Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law. What you‚Äôll do Contribute in defining the relevant Data Architecture and stack for Aqemia. Contribute to build the relevant Data infrastructure for Aqemia in AWS. In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets. Support engineering team in designing their Data pipelines and assets. Bring the Data Engineering expertise in engineering projects from design to delivery. Your profile 2+ years experience as a Data or Software engineer in an engineering team of 4+ engineers. Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus). Good knowledge of Data Engineering building blocks (storage, orchestrator). Fluent in object-oriented language development (ideally python). Experience in delivering technical projects from start to finish. Preferred skills Proficient in SQL. Experience in backend engineering. Experience in infrastructure-as-code techniques (ideally Terraform). Knowledge in ML Ops and DevOps. Knowledge of Kubernetes, K8s administration. You know how to interact with technical stakeholders. Who you are You are eager to play an active role in contributing to Aqemia‚Äôs strategy to develop drugs for patients. You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds. You are keen to solve tough problems on issues that truly matter. You are inquisitive, and proactive with a can-do attitude. You are excited to join a small team and make your mark on drug discovery. You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track.","Aqemia, a start-up focused on drug discovery, is hiring a Data Engineer to join the team in Paris. The successful candidate will design and build a modern, scalable Data Platform and support engineering teams to build their data pipeline and assets. Applicants should have at least two years' experience as a Data or Software engineer, knowledge of cloud infrastructure and products, and experience delivering technical projects from start to finish. Proficiency in SQL and experience in backend engineering are preferred. Aqemia is an equal employment opportunity employer.",Bac +5 / Master,N,> 2 ans,2,1,0.04154662416233763
103,72838,https://www.welcometothejungle.com/fr/companies/elmy/jobs/junior-data-engineer_lyon_ELMY_0RjkJAK,Data Engineer,elmy,"{GCS,Github,Node,Python,Jenkins,Datadog,PostgreSQL,Beam,GCP,OpenTelemetry,Kubernetes,Docker,Prometheus,Airflow,Grafana,Julia,TypeScript}",T√©l√©travail partiel possible,"23, Boulevard Jules Favre, Lyon, 69006","Environnement / D√©veloppement durable, Energie",CDI,2023-04-22,"elmy est le 1er √©nerg√©ticien 100% fran√ßais et 100‚Äâ% vert üå±. elmy, c‚Äôest une √©quipe d‚Äôune centaine de personnes engag√©es pour une transition √©nerg√©tique, √©cologique et solidaire. Ils ma√Ætrisent l‚Äô√©nergie de A √† Z en interne et √ßa, √ßa fait toute la diff√©rence ! En √©tant pr√©sent sur l‚Äôensemble de la cha√Æne de valeur de l‚Äô√©lectricit√©, de la production √† la consommation, ils permettent √† chacun d‚Äôavoir l‚Äôimpact le plus concret sur la transition √©nerg√©tique. Une n√©cessit√© compte tenu des enjeux climatiques ! Leurs ambitions ? 1/ Participer √† la transformation du mod√®le √©nerg√©tique üí° 2/ Reconnecter les consommateurs √† l‚Äô√©nergie ‚ö°Ô∏è 3/ Tout faire pour encourager un maximum de monde √† passer au vert üå± 4/ Construire l‚Äôentreprise contributive de demain, car l‚Äôentreprise a un r√¥le soci√©tal √† tenir ü§ù Toi aussi, tu as l‚Äô√©nergie d‚Äôagir pour la transition √©nerg√©tique ? Rejoins-les ! Data Engineer En tant que Data Engineer, tu int√®gres notre √©quipe m√©tier ¬´‚ÄØTrading et analyse march√©‚ÄØ¬ª afin de contribuer √† construire une logique data au sein de l‚Äô√©quipe. En collaboration avec l‚Äô√©quipe Tech, tu d√©velopperas des outils de collecte et de traitement de la donn√©e en travaillant √©troitement avec des analystes et des traders avec pour ambition de mieux comprendre et mod√©liser les march√©s de l‚Äô√©lectricit√© de gros au c≈ìur de nos probl√©matiques actuelles. Nous portons beaucoup d‚Äôattention sur la qualit√© du code, donc les tests et relectures de code sont des √©tapes cl√©s du cycle de vie du produit. Nous privil√©gions le d√©veloppement continu ainsi que le contact permanent avec les autres m√©tiers de l‚Äô√©quipe. Tes challenges Tu int√®gres l‚Äô√©quipe Trading et analyse march√© et participes pleinement √† la construction de notre approche data : Tu es responsable du d√©veloppement de nos pipelines data ; Tu interviens, en lien avec l‚Äô√©quipe Tech, sur les sujets de d√©couvrabilit√©, de qualit√© et de visibilit√© de la donn√©e; Tu prends une part active √† la refonte de certains processus de nos pipelines data; Tu participes, avec l‚Äô√©quipe Tech, au d√©veloppement de la culture data de l‚Äôentreprise Tu participes √† la d√©finition de l‚Äôarchitecture de nos applications ; Tu as voix au chapitre sur la priorisation des chantiers de l‚Äô√©quipe ; Tu es garant.e des bonnes pratiques de d√©veloppement, notamment au niveau de la qualit√© et de la s√©curit√©. Notre stack technique Data : PostgreSQL , Stockage objet (GCS) , Apache Beam, Cloud Pub/Sub ‚Ä¶ Languages : Node/TypeScript, Python , Julia‚Ä¶ Orchestration : Kubernetes , Airflow ‚Ä¶ Devops : Docker, GCP ‚Ä¶ CI/CD : Github, Jenkins, SonarQube, ‚Ä¶ Monitoring : Datadog, Prometheus , Grafana, OpenTelemetry, ‚Ä¶ Ce qui t‚Äôattend si tu nous rejoins üí° Ce poste est ouvert dans nos locaux lyonnais avec du t√©l√©travail partiel possible. Nous proposons sur ce poste une r√©mun√©ration annuelle √† partir de 35.000 euros annuels en fonction de ton exp√©rience + un variable de 10% index√© sur objectifs. üöÄ semaine de 4 jours üå±un travail qui a du sens : avoir un impact positif sur l‚Äôenvironnement en ≈ìuvrant pour la transition √©nerg√©tique ü§ù de la flexibilit√© sur les horaires et le t√©l√©travail üßó‚Äç‚ôÄÔ∏è un pack sport de 200 euros par an üéµ un abonnement Deezer üë®‚Äçüë©‚Äçüë¶ une mutuelle Alan prise en charge √† 100% pour toi et ta famille üêù une organisation horizontale inspir√©e de l‚Äôholacratie favorisant l‚Äôautonomie et la cr√©ativit√© ‚ù§Ô∏è un quotidien avec une √©quipe conviviale, bienveillante et optimiste üíÜ‚Äç‚ôÄÔ∏è des locaux o√π il fait bon vivre : cours de yoga, paniers de fruits, coin piano et salle de sieste Tu es notre candidat.e id√©al.e si tu‚Ä¶ ü§© üëâ Impliqu√©.e et concern√©.e par les probl√©matiques environnementales, tu souhaites mettre ta passion pour le domaine technique au service de tes valeurs. üëâ Enthousiaste et social.e tu poss√®des un r√©el esprit d‚Äô√©quipe et une volont√© d‚Äôint√©grer un groupe convivial et multiculturel. Plus techniquement üëâ Tu justifies d‚Äôune premi√®re exp√©rience ou d‚Äôun stage sur un poste similaire. Rigoureux.se, tu portes un int√©r√™t majeur √† la qualit√© de ton travail / code / data. Passionn√©.e, tu es plus attir√©.e par la technologie que par un langage sp√©cifique. üëâ Autonome et cr√©atif.ve, tu montres une app√©tence pour le travail ¬´ from scratch ¬ª et es enthousiasm√©.e par l‚Äôid√©e de rejoindre des projets techniques d√®s leurs d√©buts. üëâ Curieux.se tu es capable d‚Äôintervenir sur plusieurs technologies. üëâ Orient√©.e data, tu as √† c≈ìur de comprendre les enjeux m√©tier derri√®re les donn√©es. Tu interagiras au quotidien avec les autres membres de l‚Äô√©quipe (analystes, traders). Ladies Les √©tudes montrent que les femmes ont moins tendance √† postuler √† une offre d‚Äôemploi lorsqu‚Äôelles n‚Äôont pas toutes les qualifications requises. Ladies, ne vous mettez pas de barri√®re et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d‚Äô√©changer avec vous ! üëâ Premier call de pr√©sentation üëâ Entretien avec Lilia, Talent Acquisition Manager. Le but est, d‚Äôun c√¥t√©, d‚Äôen savoir plus sur toi, et de l‚Äôautre, que nous puissions t‚Äôen dire plus sur ce que l‚Äôon fait ici. üëâEntretien avec Erwan, Analyste march√©, pour rentrer dans le vif du sujet et parler m√©tier üëâ Test technique suivi d‚Äôun debrief avec l‚Äô√©quipe üëâ Bienvenue :)",,Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,2,1,0.04154662416233763
102,72818,https://www.welcometothejungle.com/fr/companies/publicis-media/jobs/analytics-engineer-h-f-cdi_paris,Analytics Engineer  - CDI,Publicis Media,"{GCS,Python,Spark,NoSQL,AWS,SQL,bigquery,GCP}",T√©l√©travail partiel possible,"30-34 Rue du Chemin Vert, Paris, 75011","Design, Marketing / Communication, Publicit√©",CDI,2023-04-22,"Publicis Media c‚Äôest une √©quipe de pr√®s de 1000 talents r√©partis sur 5 sites en France : Paris, Lille, Lyon, Rennes et Montpellier. Passionn√©s ‚Äçüî• par les m√©tiers du conseil media et du trading, f√©rus d‚Äôinnovation ü§ü et engag√©s √† d√©livrer les meilleures performances business, Publicis Media accompagne ses clients dans l‚Äôunivers complexe des m√©dias d‚Äôaujourd‚Äôhui et d√©cline ses expertises sur tous les leviers et points de contact. Qu‚Äôils construisent la strat√©gie ou d√©ploient les campagnes de leurs clients, les talents testent, d√©veloppent et challengent les derni√®res technologies et participent √† faire bouger les lignes du secteur des agences m√©dia pour que nos m√©tiers √©voluent constamment. Publicis Media, c‚Äôest avant tout une aventure humaine, un collectif soud√© ‚úä, des projets avant-gardistes pour d√©velopper toujours plus la mont√©e en comp√©tences de ses talents et une ambiance de travail qui ne connait pas l‚Äôennui. C‚Äôest √† la fois des agences au service de ses clients : Zenith, Starcom, Blue 449, Performics, Spark Foundry, Publicis Sport, Publicis Media Connect et des centres d‚Äôexpertises au service de l‚Äôinnovation : Social media, Data, Content, Search, Performance marketing et digitale, Tech, Commerce. Int√©grer Publicis Media, c‚Äôest int√©grer le leader des media en France et un groupe mondial pr√©sent dans 115 pays. C‚Äôest aussi d√©cider d‚Äôapprendre tous les jours et de cr√©er des liens qui comptent. Vous √™tes rattach√©.e au Lead Data & Analytics de Publicis Media et serez en charge de la structuration et de la livraison des projets Analytics (ingestion de sources de donn√©es, traitement, transformation, mod√©lisation et restitution), entre autre associ√©s aux √©quipes Data Science & Data Engineering, mais √©galement structurants pour poursuivre les travaux de transformation de l‚Äôentreprise et de ses usages. L‚ÄôAnalytics Engineer occupe un r√¥le central dans notre strat√©gie Data, en sa capacit√© √† pouvoir contribuer √† convertir la donn√©e en connaissance, tout en s‚Äôappuyant sur la technologie, √† poursuivre la conception de la prochaine g√©n√©ration d‚Äôalgorithmes. Ce que vous ferez La construction de pipelines Data depuis la collecte jusqu‚Äô√† la restitution Le rapatriement et l‚Äôingestion de donn√©es de multiples sources (Cloud ‚Äì GCS, AWS‚Ä¶ ‚Äì SFTP, API‚Ä¶) L‚Äôutilisation des Best Practices pour la cr√©ation des data models L‚Äôautomatisation de l‚Äôanalyse au travers des m√©canismes de monitoring et d‚Äôalerting, en post-d√©ploiement La gestion du suivi et livraison des projets associ√©s ‚Äì depuis la conception, au d√©veloppement, testing, et op√©rations associ√©es Les d√©fis associ√©s Richesse des environnements : de multiples sources, de multiples environnements dans un √©cosyst√®me en perp√©tuel mouvement impliquent une grande capacit√© √† pouvoir les aborder pour rassembler les donn√©es attenantes Media, Marketing, CRM‚Ä¶ : des donn√©es de nature diff√©rentes (First, Third‚Ä¶), en grande quantit√©, √† forte granularit√©, r√©unies pour en d√©duire les meilleurs insights Scalabilit√© : la quantit√© de donn√©e de chaque Client peut √™tre cons√©quente, mais le travail de transformation et processing peut l‚Äô√™tre davantage Respect de la vie priv√©e, gestion des donn√©es personnelles : nous pouvons √™tre amen√©s √† traiter de la donn√©e Media mise √† disposition sur des ‚ÄúClean Rooms‚Äù (Google, Facebook, Amazon‚Ä¶) Gestion des co√ªts : m√©thode & rigueur sont essentielles pour optimiser les d√©penses de stockage et computing de la donn√©e (en interne ou pour le compte de nos clients) Viva La Diff√©rence ! Cette philosophie de Publicis Groupe t√©moigne depuis toujours de notre engagement pour la diversit√© et de la conviction que nos talents sont notre plus grande richesse et notre meilleur atout . Nous valorisons ainsi toutes les singularit√©s, sans distinction d‚Äô√¢ge, de sexe, de couleur de peau, d‚Äôorigine sociale, de religion, ou d‚Äôorientation sexuelle‚Ä¶ seules la comp√©tence et l‚Äô√©nergie comptent ! Nous encourageons toutes les candidatures qualifi√©es et seront ravis d‚Äôaccompagner tout au long du processus de recrutement, de mani√®re personnalis√©e un.e candidat.e en situation de handicap qui en ferait la demande. Publicis France est engag√©e pour l‚Äô√©galit√© des chances et l‚Äô√©quit√© d‚Äôopportunit√©s pour tous et toutes. Qualifications Formation d‚Äôing√©nieur.e en informatique (ou assimil√©.e), m√©thodes Agile ; vous disposez de 2 ans minimum d‚Äôexp√©rience dans l‚Äôadministration, configuration, monitoring, d√©bogage et mise en oeuvre d‚Äôune solution Cloud (GCP id√©alement), ainsi que dans les m√©canismes d‚Äôint√©gration (fichiers, messages, data‚Ä¶).
La certification Google Cloud Engineer est recommand√©e, ainsi que la pratique de l‚Äôanglais. Expertises & comp√©tences Langages de d√©veloppement : Python, SQL, Basch Comp√©tences : manipulation de donn√©es en SQL / NoSQL Expertise : Google Cloud Platform (Cloud Functions, Cloud Run, Cloud Pub/Sub, Cloud Workflow, Dataplex, CI/CD‚Ä¶), Amazon Web Services‚Ä¶ Connaissance des m√©canismes de constitution d‚ÄôETL, technologies d‚Äôorchestration (Workflow, cloud scheduler, ‚Ä¶). Des connaissances en Terraform et en bigquery est un plus Phases de testing ; documentation du code",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
101,34055,https://www.welcometothejungle.com/fr/companies/m13h/jobs/dataviz-engineer-france-europe-f-h_bordeaux,DataViz Engineer - Bordeaux -,M13h,"{OneTrust,DataStudio,Looker,PowerBI,Fivetran,dbt,Contentsquare,via,Adverity,SQL,Qlik,Tableau}",T√©l√©travail partiel possible,Bordeaux,"Digital Marketing / Data Marketing, Strat√©gie, Big Data",CDI,2022-08-08,"A propos de M13h üëã M13h est une √©quipe de consultant¬∑e¬∑s passionn√©¬∑e¬∑s au service de la performance business & marketing des entreprises. En forte croissance, le cabinet allie vision Strat√©gique et expertises Data, Marketing & Technologies pour acc√©l√©rer la transformation de leaders de leur secteur vers un pilotage data-driven. Nous ma√Ætrisons toute la cha√Æne de valeur de la data et aidons des marques comme LVMH, FDJ, Salto, Salomon, Boardriders, ‚Ä¶ √† accro√Ætre leurs performances, au travers de missions vari√©es : Strat√©gie Data : d√©finir sa strat√©gie, ses cas d‚Äôusage data et le socle technologique pour la d√©ployer Adtech & Martech : mettre en place les outils de collecte et exploiter la donn√©e pour cr√©er de la valeur (analyse, activation marketing, connaissance client) Customer experience : optimiser les parcours client et am√©liorer les taux de conversion Privacy : s‚Äôadapter aux √©volutions technologiques et r√®glementaires tout en d√©veloppant ses performances marketing Modern Data Platforms : construire des plateformes de donn√©es sur le cloud en utilisant la puissance des moderns data stacks Advanced Insights : tirer profit des donn√©es pour prendre des d√©cisions √©clair√©es (dashboards, data analyse, data science, mod√©lisation avanc√©e, ‚Ä¶) M13h est membre du Groupe Labelium et met ses comp√©tences data au profit de plus de 750 experts multidisciplinaires dans plus de 20 pays. Le tout en restant une structure √† taille humaine o√π il fait bon travailler ! En plein mouvement de r√©gionalisation et d‚Äôinternationalisation, la plupart de nos postes sont disponibles pour la France (Paris, Bordeaux, Lyon) et l‚ÄôEurope (Londres, Madrid, Vienne, Francfort, Milan, Lisbonne). N‚Äôh√©sitez pas √† en discuter en entretien. Description du poste üì¢ En tant que DataViz Engineer, tu interviens sur les probl√©matiques relatives √† la mise en place de dashboards et autres outils de pilotage d‚Äôactivit√© pour les clients de M13h. Pour cela, tu interviens √† diff√©rents stades des projets : Compr√©hension des besoins m√©tiers et d√©finition des indicateurs pour les repr√©senter de mani√®re efficace Cr√©ation des indicateurs de suivi Mise en place des dashboards Maintenance et √©volution des dashboards Veille sur les √©volutions du march√© D√©finition des bonnes pratiques de d√©veloppement de visualisation efficientes Quelques exemples de missions √† titre d‚Äôillustration : Cr√©ation de dashboard centralisant la donn√©e m√©dia issue des principales plateformes d‚Äôactivation Construction de rapport de suivi de performances marketing Mise en place d‚Äôun outil de pilotage de l‚Äôattribution m√©dia Cr√©ation de dashboard omnicanaux avec notamment les donn√©es issus de Google My Business et Facebook pages Mise en place de dashboards √† destination des franchis√©s Cr√©ation de templates de dashboards dans le cadre d‚Äôune industrialisation du pilotage media Rigoureux¬∑se, tu as √† c≈ìur de comprendre les besoins de tes interlocuteurs puis les traduire et les mat√©rialiser via des dashboards pertinents . En tant que Junior , tu seras encadr√©¬∑e par des profils plus seniors te permettant de progresser rapidement dans notre environnement et sur des outils modernes. Profil recherch√© üë®üë© Issu¬∑e d‚Äôune grande √©cole de commerce, d‚Äôing√©nieurs ou √©quivalent , tu souhaites t‚Äôorienter vers les m√©tiers de la business intelligence. Tu connais certains outils de march√© (Tableau, PowerBI, DataStudio, Qlik, Looker, ‚Ä¶) et tu as des bases dans la gestion et la structuration de donn√©es notamment en SQL, ainsi que sur la meilleure mani√®re de restituer des donn√©es de fa√ßon visuelle. Tu souhaites travailler sur des environnements cloud et d√©couvrir les outils ELTs. Au-del√† des comp√©tences techniques, tu fais preuve de rigueur, de cr√©ativit√© et d‚Äôautonomie. Tu as √©galement une forte capacit√© de formalisation et fait preuve de p√©dagogie. Pourquoi nous rejoindre ‚ùì M13h, c‚Äôest avant tout une √©quipe qui aime les challenges et porte des valeurs de bienveillance et de progr√®s collectif . Tu as d√©j√† lu √ßa ailleurs ? Contactes nos consultant¬∑e¬∑s sur LinkedIn pour v√©rifier directement :) D√©marrer chez M13h, c‚Äôest aussi une belle opportunit√© de d√©velopper tes comp√©tences conseil et ton expertise rapidement sur des missions vari√©es, au sein d‚Äôune structure √† taille humaine tout en profitant des avantages d‚Äôun groupe international. Tu es accompagn√© par un parrain ou une marraine d√®s ton arriv√©e en plus de ton manager, profites de formations, acc√®des √† de nombreuses ressources de nos partenaires data marketing ou modern data stack tels que : Google, Facebook, Didomi, OneTrust, AB Tasty, Kameleoon, Contentsquare, Funnel, Fivetran, Adverity, dbt, ‚Ä¶ Et puis M13h, c‚Äôest aussi des avantages et du fun :) 3 jours offerts aux volontaires pour des actions pro bono via la plateforme Vendredi Des primes d‚Äôarriv√©e pour s‚Äô√©quiper pour le t√©l√©travail Une politique souple de t√©l√©travail Un abonnement gratuit √† des salles de sport 2 s√©minaires par an et de nombreux moments de coh√©sion d‚Äô√©quipe Des locaux au coeur de grandes villes fran√ßaises (Paris, Bordeaux, Lyon) et europ√©ennes (Londres, Madrid, Vienne, Milan, Francfort, Lisbonne) Des tickets restaurants Une mutuelle et transports pris en charge √† 100% et bien d‚Äôautres‚Ä¶ Comment postuler üôã Postule directement sur notre page Welcome to the Jungle ou envoie nous une candidature spontan√©e √† recrutement@m13h.com","M13h, a consulting firm specializing in business and marketing performance, is seeking a DataViz Engineer with experience in dashboard implementation and maintenance. The ideal candidate should have a degree in engineering, commerce, or equivalent, and knowledge of market tools like Tableau, PowerBI, DataStudio, Qlik, and Looker. Besides technical expertise, the candidate must have attention to detail, creativity, autonomy, and excellent communication skills. M13h offers opportunities to work on diverse assignments and provide a learning platform through mentorship, training, flexible policies, and recreational events.",Bac +5 / Master,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
100,34072,https://www.welcometothejungle.com/fr/companies/bouygues-telecom/jobs/data-engineer-sre-h-f_meudon,Data Engineer / SRE -,Bouygues Telecom,"{MongoDB,ElasticSearch,Tensorflow,Anaconda,Kubernetes,HDFS,S3,Kafka,Hive,Spark,Superset,Docker,Java,Python,Tableau}",T√©l√©travail partiel possible,Meudon,"IT / Digital, Objets connect√©s, Electronique / T√©l√©communications",CDI,2022-08-08,"Depuis notre cr√©ation en 1996, toutes nos collaboratrices et tous nos collaborateurs ont la m√™me ambition: √™tre l‚Äôop√©rateur qui fait grandir les relations humaines. Nous innovons au service de technologies qui font grandir les amiti√©s, les liens de famille, les histoires d‚Äôamour, les engagements solidaires, les projets collectifs. Nous avons cr√©√© le premier forfait illimit√©, nous avons lanc√© l‚Äôinternet mobile. Chaque jour, nous redoublons d‚Äôefforts pour fournir un r√©seau encore plus puissant et √©tendu pour connecter tous les territoires. Nous sommes 9 500 artisans des liens humains, passionn√©s, au service de 25 millions de personnes partout en France. Nous sommes 9 500 engag√©s pour l‚Äôinclusion, tous diff√©rents : par notre parcours, notre m√©tier, nos id√©es. Alors si pour vous faire grandir les relations humaines est un m√©tier, on est fait pour √™tre ensemble. Bouygues Telecom recherche des futurs talents dans la tech en CDI ! Si le d√©veloppement Java, la CI/CD, la gestion de gros volumes de Data, les probl√©matiques de scalabilit√© et de distribution de charge ou encore Kubernetes vous parlent, rencontrons-nous ! Des postes de Data Engineer, Lead Technique et SRE sont √† pourvoir. L‚Äôun d‚Äôeux est peut-√™tre pour vous ! La Direction des Syst√®mes d‚Äôinformation R√©seau (IT RES) s‚Äôinscrit au c≈ìur du business de Bouygues Telecom. Elle fournit l‚Äôensemble des SI qui pilotent les processus cl√©s de la direction SI. Au sein de cette direction se trouve la structure Architecture D√©veloppement Op√©rations. Elle a pour vocation d‚Äôassurer la gestion des donn√©es du R√©seau de Bouygues Telecom entrant dans les processus d‚Äôam√©lioration de la qualit√© de l‚Äôexp√©rience utilisateur. Cette plateforme Big Data fournit √©galement un environnement de machine learning et d‚Äôanalytique aux ing√©nieurs r√©seaux de Bouygues Telecom. Vous serez immerg√© dans une √©quipe aux multiples savoir-faire (architecture technique, d√©veloppement, data science, product manager, SRE ‚Ä¶). C‚Äôest donc au sein de cette structure, et dans nos √©quipes compos√©es de collaborateurs internes et de prestataires, que peut s‚Äôinscrire votre avenir ! Vous travaillerez sur la cha√Æne compl√®te de nos projets, sur du Build comme du Run. Profil recherch√© : Notre environnement technique riche et vari√© : Big Data - Supervision et analyses de performances du r√©seau, m√©trologie applicative : Kubernetes, HDFS, S3, Hive, Kafka, Spark, PrestoDB, MongoDB, Tableau, Superset, ElasticSearch, Docker, ‚Ä¶ D√©tection d‚Äôanomalies li√©es √† la supervision du r√©seau, corr√©lation d‚Äôalarme, ‚Ä¶ : Tensorflow, DNN, VAE, Anaconda, Docker, ‚Ä¶ * Notre socle de d√©veloppement se fait principalement sous Java et Python. Localisation et R√©mun√©ration : Vous serez bas√© au Technop√¥le, situ√© √† deux pas de V√©lizy 2. Avantages & r√©mun√©ration : Selon exp√©rience, r√©mun√©ration fixe annuelle brute sur 13,1 mois + participation/int√©ressement + avantages groupe vari√©s + t√©l√©travail r√©gulier.","Bouygues Telecom, an operator of telecommunication services in France, is seeking talented individuals for various tech roles such as Data Engineer, Lead Technique, and SRE. The company is looking for individuals with skills in Java development, CI/CD, large data management, scalability and load distribution, and Kubernetes. The roles are based in the Architecture Development Operations structure of the company and require knowledge of technologies such as HDFS, S3, Hive, Kafka, Spark, PrestoDB, MongoDB, Tableau, Superset, ElasticSearch, and more. The position offers a competitive salary, benefits package, and regular telecommuting opportunities.",Bac +5 / Master,> 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
98,73701,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/manager-data-engineering-h-f_paris_EF_4Rr7q6,Manager Data Engineering,EPSILON France,"{Python,EPSILON,Microsoft,Cloudera,Azure,marquez,Kafka,Hadoop,Spark,Kubernetes,Docker,Gitlab,MongoDB}",T√©l√©travail partiel possible,"17 Rue Br√©guet, Paris, 75011","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-04-22,"EPSILON France est l‚Äôentit√© Datamarketing de Publicis Groupe avec 700 experts data, marketing et technologiques et plus de 40 m√©tiers repr√©sent√©s. Avec pour claim ¬´ Every Interaction Counts ¬ª, la mission d‚ÄôEPSILON est de conjuguer les pouvoirs de la data, du marketing et de la technologie pour rendre les interactions entre les marques et leurs clients toujours plus justes et pertinentes. EPSILON intervient sur l‚Äôensemble des √©tapes-cl√© d‚Äôun projet de transformation data-driven, de la d√©finition de la strat√©gie √† l‚Äôex√©cution op√©rationnelle. EPSILON compte plus de 300 clients actifs et pilote quotidiennement plus de 100 plateformes datamarketing. Le P√¥le Data & Analytics Platform est compos√© de 140 experts sp√©cialis√©s sur la transformation Data des entreprises : Cadrage fonctionnel et technique, D√©finition de use-cases, Conception d‚Äôarchitecture cloud ou hybride, Mise en ≈ìuvre et run de plateformes data, Impl√©mentation de solutions Dataviz et Analytics, Accompagnement du changement, Cadrage et d√©ploiement de Data Gouvernance, Mise en ≈ìuvre de Data Office. Au sein du P√¥le Data & Analytics Platform, le centre de comp√©tences des technologies Big Data et Cloud intervient sur l‚Äôensemble de la cha√Æne Data : Architecture, D√©veloppement de plateforme Data (ingestion, traitement, stockage, exposition des donn√©es), industrialisation et op√©rationnalisation des solutions d√©velopp√©es (essentiellement en mode cloud). Rattach√© √† ce centre de comp√©tences en tant que Manager Data Engineering, vous avez 4 grandes missions : Management : - Vous managez et animez votre √©quipe (8 √† 10 personnes) dans un esprit de formation, d‚Äôinnovation et de satisfaction client. Projet : Garant de la qualit√© du delivery de vos projets - Vous assumez le r√¥le de chef de projet ou de directeur de projets sur des missions et des clients vari√©s, de la conception √† l‚Äôimpl√©mentation, sans oublier l‚Äôoptimisation de la performance et la scalabilit√© de vos d√©veloppements. Innovate & Train : d√©veloppement du capital connaissance et de l‚Äôinnovation - Vous animez nos r√©seaux de comp√©tences et √™tes un support m√©thodologique et technique pour les consultants - Vous d√©veloppez des points de vue, des ""assets"", des bonnes pratiques et contribuez √† la croissance de l'√©quipe, - Vous √™tes source de conseils tout en participant √† la r√©alisation effective des projets. Sell : - Vous animez la relation client et contribuez activement aux activit√©s d‚Äôavant-vente. - Vous animez la relation avec certains partenaires √©diteurs d‚ÄôEPSILON (Google, Microsoft, ‚Ä¶) Vous marquez des points si Vous √©voluez depuis au moins 6 ans dans des environnements Data Agile et Cloud. La mise en ≈ìuvre de plateformes Data n‚Äôa pas de secret pour vous. Vous √™tes un fan de Scrum, SAFE ou DevOps‚Ä¶ et vous avez appliqu√© ces m√©thodes avec succ√®s √† vos projets ! Vous avez la maitrise d‚Äôune stack technique de r√©f√©rence Hadoop (Cloudera/HortonWorks), Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, ‚Ä¶ et une r√©elle exp√©rience des environnements cloud (en particulier Google Cloud Platform et Azure ). Vous avez d√©j√† encadr√©, manag√©, fait √©voluer des consultants √† travers une premi√®re exp√©rience significative de management ? Le partage de connaissance et la curiosit√© sont des pr√©-requis dans votre quotidien ? Dynamique et r√©actif, vous d√©montrez un r√©el leadership. La qualit√© de votre communication √©crite et orale ainsi que votre aisance relationnelle vous permettent d‚Äô√™tre reconnu comme un interlocuteur exigeant et fiable tant en interne qu‚Äôen externe.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
97,73696,https://www.welcometothejungle.com/fr/companies/evaneos/jobs/data-engineer_paris_EVANE_1p2gxJ0,Data Engineer,Evaneos,"{Looker,BigQuery,Python,durable,dbt,Dbt,via,airflow,Kubernetes,Git,Airflow,SQL,Amplitude,bigquery,GCP}",T√©l√©travail partiel possible,"27 rue de Mogador, Paris, 75009","Tourisme, SocialTech / GreenTech",CDI,2023-04-22,"Des voyages meilleurs pour les voyageuses et voyageurs, meilleurs pour la plan√®te üåç Depuis sa cr√©ation en 2009, Evaneos n‚Äôa cess√© d‚Äô≈ìuvrer pour que le voyage de demain devienne plus juste et plus durable. En connectant les voyageuses et les voyageurs avec la cr√®me des experts et expertes locales √† travers le monde, l‚Äôexp√©rience n‚Äôen est que meilleure pour nos voyageurs‚Äßeuses et meilleure pour les lieux visit√©s. Selon nous, tout est une question de qualit√© de service et d‚Äôimpact. Cela se traduit par une lutte permanente contre le tourisme de masse et toute forme d‚Äôexp√©riences d√©sincarn√©es effectu√©es au d√©triment des communaut√©s locales et de l‚Äôenvironnement. Gr√¢ce √† notre r√©seau de plus de 1 000 partenaires locaux, nous avons pu aider pr√®s de 500 000 voyageurs et voyageuses √† organiser des s√©jours exceptionnels dans plus de 160 pays √† travers le monde. L‚Äôaventure ne s‚Äôarr√™te pas l√†. Nous sommes sur le point de rendre chaque voyage vendu par Evaneos 100% neutre en carbone et nous allons ajouter √† notre r√©seau 200 nouvelles agences dirig√©es par des femmes. Nos valeurs sont tout aussi pr√©sentes au sein d‚ÄôEvaneos . Nous puisons notre force dans notre diversit√©, constitu√©e d‚Äôune multitude de langues, d‚Äôorigines et d‚Äôexp√©riences. Nous pensons que les meilleures √©quipes se construisent dans un environnement o√π chaque personne peut √™tre elle-m√™me, o√π l‚Äôon peut se faire confiance et s‚Äô√©panouir. Nous esp√©rons que vous nous rejoindrez pour contribuer √† cette mission ! üöÄ Team Data üìä L‚Äô√©quipe Data chez Evaneos existe depuis plus de 4 ans et est compos√©e d‚Äôune douzaine de personnes (Data Analysts, Product Analysts, Analytic Engineers, and Data Engineer). En tant que plateforme de mise en relation, Evaneos collecte chaque jour des donn√©es de diff√©rentes sources, et la vocation de l‚Äô√©quipe data consiste √† valoriser ces donn√©es pour accompagner la croissance de l‚Äôentreprise, notamment gr√¢ce √† : L‚Äôaide √† la d√©cision : Nous accompagnons l‚Äôensemble des m√©tiers √† prendre les meilleures d√©cisions possibles en utilisant au mieux la donn√©e. L‚Äôensemble des m√©thodologies m√©tiers reposent sur des d√©marches scientifiques et data-driven, √† travers l‚Äô√©mission d‚Äôhypoth√®ses et leur validation (ou invalidation) par la donn√©e. L‚Äôinnovation : Notre objectif 2024 est de lancer notre plateforme de Datascience et d‚Äôinnover, avec un fort accent sur l‚Äôindustrialisation √† travers les pratiques MLOps notamment. Tes missions üî≠ Au quotidien tu te sens √† l‚Äôaise avec l‚Äôune ou plusieurs de ces missions : Ing√©rer les nouvelles sources de donn√©es dans le datalake (airflow) Monitorer et maintenir les flux de donn√©es en production (airflow + dbt + bigquery) Maintenir l‚Äôinfrastructure cloud (Pulumi + GCP + Kubernetes) Am√©liorer l‚Äôenvironnement de travail des data analystes (VSCode + Notebooks) Construire la future plateforme datascience (Vertex AI ? √Ä d√©finir ensemble üîç) Devenir le r√©f√©rent de l‚Äôarchitecture c√¥t√© Data Et √©videmment , tu as envie de participer √©galement √† l‚Äôessor de la Team Data en t‚Äôimpliquant dans la vie d‚Äô√©quipe dans un but d‚Äôam√©lioration collective üôÇ üì¢ Note : n‚Äôh√©site pas √† postuler m√™me si tu ne coches pas toutes les cases, nous serons ravi¬∑e¬∑s de t‚Äôaccompagner dans ton apprentissage. Notre stack üìà Airflow Dbt BigQuery Looker Amplitude Git GCP (GKE, Vertex AI) Pulumi Nos outils de collaboration üìå Notion Slack Miro Figma Gather.town qui reproduit nos locaux sur internet Cadre de travail ‚úîÔ∏è Nous pla√ßons le bien-√™tre des ‚ÄúEvaneosien¬∑nes‚Äù au centre de nos valeurs : Budget voyage via le CSE pour d√©couvrir les services Evaneos T√©l√©travail √† temps plein ou t√©l√©travail ponctuel possible + Travelling TT pour travailler plusieurs fois par an dans d‚Äôautres pays/r√©gions Une flexibilit√© du temps de travail : en accord avec ton √©quipe, tu peux am√©nager tes horaires gr√¢ce aux ‚ÄúFlexi-Fridays‚Äù Bureaux proches de Saint-Lazare avec une superbe cour int√©rieure permettant d‚Äô√©changer avec tous les coll√®gues le soir et de faire des afterworks Cours de yoga, m√©ditation, sports en partie pris en charge par Evaneos gr√¢ce au partenariat avec Gymlib Diff√©rents groupes de loisirs : Groupe de musique, team jeu de soci√©t√©s, groupes de sports, etc. Des √©v√©nements internes pour se conna√Ætre, d√©couvrir et √©changer : d√©jeuners culturels, afterworks, daily, sprint planning, r√©tro, caf√©, etc. PC ou MacBook Pro fourni au choix Des BSPCE pour √™tre li√©.e au succ√®s de l‚Äôentreprise Tu as un bon sens du business, tu es pragmatique, organis√©¬∑e et rigoureux¬∑euse. Tu es pr√™t¬∑e √† challenger et √† √™tre challeng√©¬∑e par nos √©quipes data et produit. Tu es curieux¬∑euse, et tu as envie d‚Äôapprendre et de partager tes connaissances sur diff√©rents sujets (techniques comme business). Tu es p√©dagogue et bon¬∑ne communiquant¬∑e. Tu maitrises le Python et le SQL. R√©mun√©ration üí≥ Notre politique de r√©mun√©ration nous permet de d√©finir une fourchette de salaire selon l‚Äôexp√©rience professionnelle et le niveau d‚Äôimpact d‚Äôune personne. Cela correspond, chez nous, √† une fourchette entre 43 et 55k‚Ç¨. La communaut√© tech d‚ÄôEvaneos √©tant en compl√®te transparence de ses salaires, ta r√©mun√©ration sera d√©finie en comparant ton niveau √† celui de tes coll√®gues, afin de te proposer une r√©mun√©ration coh√©rente avec le reste de la communaut√©. 1 entretien avec Nicolas (Head of Data) et Ludovic (Data Engineer) 1 test technique ( √† r√©aliser chez toi ) 1 √©change ‚Äúteam fit‚Äù pour rencontrer d‚Äôautres membres de l‚Äô√©quipe Data : Camille, Victor, Agnes, Quentin, selon leurs disponibilit√©s.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
96,73677,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/data-engineer-cloud-confirme-e-pau-f-h_pau_CAPGE_7Z1pp7A,Data Engineer-Cloud Confirm√©.e PAU,Capgemini,"{TensorFlow,React,Python,Azure,PostgreSQL,Docker,AWS,Git,Java}",T√©l√©travail partiel possible,"Pau, 64000","IT / Digital, Organisation / Management, Strat√©gie, Transformation",CDI,2023-04-22,""" Get the future you want"" Telle est notre promesse chez Capgemini : Evoluer dans un environnement o√π le d√©veloppement des comp√©tences et les perspectives d'avenir sont √† port√©e de main ! Nous recherchons des femmes et des hommes passionn√©.e.s par l'IT pour int√©grer nos √©quipes techniques et accompagner nos clients dans leurs projets de transformation num√©rique. Nos √©quipes Data sur Pau c'est : Une √©quipe jeune et dynamique construite autour de 3 piliers : la data, l‚Äôexpertise et le fun ! Des data scientistes, des data ing√©nieur.e.s, des data analystes et des data architectes, Des projets Agiles et innovants dans le Cloud, Des personnes int√©gr√©es √† un r√©seau de plus de 1000 consultants Data en France et plus de 10000 de par le monde ! Notre Practice PER s‚Äôappuie sur l‚Äôexcellence technologique, la gestion des donn√©es, ainsi que l‚Äôexpertise propre aux activit√©s m√©tiers et aux secteurs. Notre quotidien est d‚Äôaider les entreprises aux enjeux de demain comme le green IT. Afin de r√©pondre aux besoins de nos clients du secteur P√©trolier/Gazier, nous recrutons un.e Data Engineer Cloud au sein de l'√©quipe de Ridha CHELGHAF . Int√©gr√©.e au sein de l‚Äô√©quipe Data ton r√¥le sera de : CONCEVOIR des mod√©lisations statistiques et des algorithmes pour exploiter les donn√©es DEVELOPPER les pipelines de collecte, stockage et transformation des donn√©es dans un contexte DevOps MODELISER les r√©sultats des analyses de donn√©es pour les rendre lisibles, accessibles et exploitables par les data analystes et data scientistes (PostgreSQL, Flask‚Ä¶) INDUSTRIALISER les solutions dans un contexte Cloud DevOps (AWS, Azure, Docker‚Ä¶) COLLABORER lors de la mise en place des strat√©gies ¬´ Data Driven ¬ª de l‚Äôentreprise ACCOMPAGNER de jeunes d√©veloppeur.euse.s dans leur mont√©e en comp√©tence au sein de notre entit√© PARTICIPER √† la vie de notre √©quipe Data (proposer / organiser / assister √† nos √©v√®nements et nos ateliers) Description du profil : Quels sont les pr√©requis ? Tu maitrises : Python, Panda, DevOps, Scikit Learn, TensorFlow, Git, Docker, Sonar, Flask, Angular, AWS ou Azure Tu maitrises √©galement Angular, React, Spring, Java ? N‚Äôh√©site pas, rejoins-nous ! Nous proposons : Tu int√©greras une √©quipe ambitieuse, fun et dynamique ! Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√© Des projets innovants autour de la Data et du Cloud Des clients vari√©s, leaders de leur secteur Un v√©ritable accompagnement dans l‚Äô√©volution de votre carri√®re Une √©quipe √† taille humaine, en renouvellement et en hyper croissance C√¥t√© r√©mun√©ration : ton salaire mais aussi de la participation, de l‚Äôint√©ressement, un PERCO, une mutuelle, une carte restaurants, des cong√©s suppl√©mentaires proportionnels √† ton anciennet√©, un CE tr√®s dynamique, un accord de t√©l√©travail et de parentalit√© et des horaires modulables.",,Bac +5 / Master,> 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
95,56759,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-sante-social-emploi-nantes_nantes_SS_84zVa21,Data Engineer - Big Data - Sant√© Social Emploi - Nantes,Sopra Steria,"{Iceberg,SAS,Python,MongoDB,Grafana,Trino,Airflow,PostgreSQL,Gitlab,Prometheus,Parquet,Ceph,R,Spark,Java,Jupyter}",T√©l√©travail partiel possible,"5-7 impasse Claude Reggiani 44800 Saint Herblain, Nantes","IT / Digital, Organisation / Management",CDI,2023-03-26,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Sant√© Social Emploi ¬ª regroupe l'ensemble des acteurs qui exercent une mission de service public dans ces domaines. Nos clients sont notamment les organismes de protection sociale de la sant√©, de la retraite et de la famille, et √©galement de grands acteurs du secteur de l'emploi. Notre pr√©sence globale dans l'√©cosyst√®me et la connaissance approfondie des m√©tiers de nos clients sont un atout majeur pour r√©pondre aux grands enjeux de transformation impliqu√©s par les r√©formes de l'Etat. Votre r√¥le et missions Votre futur environnement de travail : Si vous √™tes passionn√©(e) par les grands projets Data, rejoignez notre √©quipe d'ing√©nieurs du centre d'expertise Data de Nantes. Y sont pr√©sents des experts de la mise en ?uvre de Plateforme de Donn√©es, des Data Architectes ou autres experts solution autour des probl√©matiques de valorisation de la donn√©e. Vous √™tes accompagn√©(e) au d√©veloppement de vos connaissances et de vos comp√©tences √† travers nos programmes de formations Sopra Academy, vous b√©n√©ficiez du support des Directions Techniques et Fonctionnelles, ainsi que de la communaut√© Data. Rejoindre la communaut√© Data Sopra Steria, c'est rejoindre une communaut√© de Data Ing√©nieurs fiers de partager leur savoir et ouverts aux nouvelles exp√©riences et exp√©rimentations de la donn√©e! Votre r√¥le et missions : Dans le cadre de la mise en place de plateforme Data pour un de nos grands clients et selon votre exp√©rience, vous participez √† : - La compr√©hension des besoins m√©tiers et la traduction solution de data ing√©nierie et ou data analyste - La mise en oeuvre de solution d'ingestion des donn√©es quelles soit en batch et/ou en streaming au sein d'un Cloud priv√©. - Le traitement de la donn√©e jusqu'√† l'exposition au m√©tier. - La mise en place de la chaine CI/CD et de sa supervision. - Le d√©ploiement de la s√©curit√© sur la plateforme. Environnement technique : - Spark, Trino, Jupyter, SAS - Openshift, Keycloack, Bastion, Vault, Wallix - Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB - Prometheus, Grafana, ELK, Gitlab CI - Java, Python, R Ce que nous proposons : - Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions. - Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation. - Un accompagnement individualis√© avec un mentor. - Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª. - L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore?). Votre profil : Dipl√¥m√©(e) d'une √©cole d'Ing√©nieurs ou √©quivalent universitaire, vous avez d√©j√† particip√© √† un projet Data (Big Data, BI) et vous avez une exp√©rience de minimum 2 ans. Vous accordez une importance particuli√®re √† : - Au d√©veloppement de vos comp√©tences sur plusieurs technologies. - L'opportunit√© d'√©volution r√©elle de carri√®re au travers de l'exp√©rience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir aupr√®s de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le d√©veloppement de leur carri√®re. - A la bienveillance et √† la diversit√©. Chez Sopra Steria, nous sommes engag√©s pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les diff√©rences. Tous nos postes sont ouverts aux personnes en situation de handicap . En savoir plus ici","Sopra Steria seeks a Data Engineer to join its Nantes Data Expertise Center. The ideal candidate will have at least two years of experience in Big Data or BI projects, and will be responsible for understanding business needs, implementing data ingestion solutions, processing data, supervising CI/CD chains, and deploying security on data platforms. Technical skills required include Spark, Trino, Jupyter, SAS, Openshift, Keycloack, Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB, Prometheus, Grafana, ELK, Gitlab CI, Java, Python, and R. Sopra Steria offers teleworking options, mentoring, career advancement opportunities, individualized training, and a diverse and inclusive work environment.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
93,73651,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/data-engineer_paris_WEWYS_YxbkxZx,Data Engineer,Wewyse,"{Python,Jenkins,Scala,Azure,Hadoop,Spark,Docker,Kubernetes,NoSQL,AWS,Git,SQL,Java,GCP}",T√©l√©travail partiel possible,"48 Rue du Ch√¢teau d'Eau, Paris, 75010","Digital Marketing / Data Marketing, IT / Digital, Transformation",CDI,2023-04-22,"Wewyse est un cabinet de conseil sp√©cialis√© en Data et en Intelligence Artificielle . C‚Äôest aussi et surtout une communaut√© de passionn√©s partageant l‚Äôambition de grandir ensemble et d‚Äôouvrir le champ des possibles dans leurs domaines. Si vous pensez que la Data et l‚ÄôIntelligence Artificielle ont beaucoup √† offrir au monde de demain, et si vous souhaitez apporter votre contribution √† ce monde, avec humilit√© et enthousiasme, alors vous √™tes un Wyser en puissance. √ätre Data Engineer chez Wewyse c‚Äôest : int√©grer une communaut√© d‚Äôexperts Data passionn√©s, recevoir et partager de la connaissance et des savoirs-faire lors de nombreux √©v√®nements, intervenir chez des clients pour y porter l‚Äôexpertise Wewyse dans des contextes et des secteurs vari√©s, participer √† des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires acad√©miques et des start up, viser l‚Äôexcellence des d√©veloppement en s‚Äôappuyant sur le Software craftsmanship, concevoir des architectures logicielles modernes, penser DevOps pour l‚Äôautomatisation des d√©ploiements et la continuit√© des services. √™tre encourag√©, conseill√© et accompagn√© dans un parcours de formation adapt√© √† vos ambitions professionnelles, faire partie de la famille Wemanity avec ses √©v√®nements et ses multiples opportunit√©s de carri√®re. Ce que nous aimons chez Wewyse : les personnalit√©s ouvertes, curieuses, ambitieuses les langages Scala, Python et Java le cloud : AWS, GCP, Azure les √©cosyst√®mes : Hadoop et Spark la conteneurisation : Docker et Kubernetes les m√©thodes Agiles le SQL et le NoSQL l‚Äôapproche DevOps : Jenkins, Ansible et Terraform le versionning : Git l‚Äôanglais",,Bac +5 / Master,Entre 15 et 50 salari√©s,> 1 an,2,1,0.04154662416233763
92,73623,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-sante-social-emploi-nantes_nantes_SS_yrjr019,Data Engineer - Big Data - Sant√© Social Emploi - Nantes,Sopra Steria,"{Python,Iceberg,Ceph,SAS,Parquet,Jupyter,PostgreSQL,Java,Spark,MongoDB,Prometheus,Gitlab,Airflow,Grafana,R,Trino}",T√©l√©travail partiel possible,"5-7 impasse Serge Reggiani, Nantes","IT / Digital, Organisation / Management",CDI,2023-04-22,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Sant√© Social Emploi ¬ª regroupe l'ensemble des acteurs qui exercent une mission de service public dans ces domaines. Nos clients sont notamment les organismes de protection sociale de la sant√©, de la retraite et de la famille, et √©galement de grands acteurs du secteur de l'emploi. Notre pr√©sence globale dans l'√©cosyst√®me et la connaissance approfondie des m√©tiers de nos clients sont un atout majeur pour r√©pondre aux grands enjeux de transformation impliqu√©s par les r√©formes de l'Etat. Votre r√¥le et missions Votre futur environnement de travail : Si vous √™tes passionn√©(e) par les grands projets Data, rejoignez notre √©quipe d'ing√©nieurs du centre d'expertise Data de Nantes. Y sont pr√©sents des experts de la mise en ?uvre de Plateforme de Donn√©es, des Data Architectes ou autres experts solution autour des probl√©matiques de valorisation de la donn√©e. Vous √™tes accompagn√©(e) au d√©veloppement de vos connaissances et de vos comp√©tences √† travers nos programmes de formations Sopra Academy, vous b√©n√©ficiez du support des Directions Techniques et Fonctionnelles, ainsi que de la communaut√© Data. Rejoindre la communaut√© Data Sopra Steria, c'est rejoindre une communaut√© de Data Ing√©nieurs fiers de partager leur savoir et ouverts aux nouvelles exp√©riences et exp√©rimentations de la donn√©e! Votre r√¥le et missions : Dans le cadre de la mise en place de plateforme Data pour un de nos grands clients et selon votre exp√©rience, vous participez √† : - La compr√©hension des besoins m√©tiers et la traduction solution de data ing√©nierie et ou data analyste - La mise en oeuvre de solution d'ingestion des donn√©es quelles soit en batch et/ou en streaming au sein d'un Cloud priv√©. - Le traitement de la donn√©e jusqu'√† l'exposition au m√©tier. - La mise en place de la chaine CI/CD et de sa supervision. - Le d√©ploiement de la s√©curit√© sur la plateforme. Environnement technique : - Spark, Trino, Jupyter, SAS - Openshift, Keycloack, Bastion, Vault, Wallix - Exadata, Ceph, Iceberg, Parquet, Airflow, PostgreSQL, MongoDB - Prometheus, Grafana, ELK, Gitlab CI - Java, Python, R Ce que nous proposons : - Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions. - Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation. - Un accompagnement individualis√© avec un mentor. - Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª. - L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore?). Votre profil : Dipl√¥m√©(e) d'une √©cole d'Ing√©nieurs ou √©quivalent universitaire, vous avez d√©j√† particip√© √† un projet Data (Big Data, BI) et vous avez une exp√©rience de minimum 2 ans. Vous accordez une importance particuli√®re √† : - Au d√©veloppement de vos comp√©tences sur plusieurs technologies. - L'opportunit√© d'√©volution r√©elle de carri√®re au travers de l'exp√©rience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir aupr√®s de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le d√©veloppement de leur carri√®re. - A la bienveillance et √† la diversit√©. Chez Sopra Steria, nous sommes engag√©s pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les diff√©rences. Tous nos postes sont ouverts aux personnes en situation de handicap . En savoir plus ici",,Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
91,58093,https://www.welcometothejungle.com/fr/companies/cleyrop/jobs/support-engineer-data-platform_paris,Support Engineer Data Platform,Cleyrop,"{Databricks,Snowflake,via,Datahub,Hadoop,DataHub}",T√©l√©travail partiel possible,"16, Rue Washington, Paris, 75008","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data",CDI,2023-03-26,"Cleyrop a √©t√© cr√©√© fin 2020 avec pour objectif de cr√©er le premier DataHub europ√©en. Pourquoi ? Car aujourd‚Äôhui, c‚Äôest encore trop complexe. Car aujourd‚Äôhui, on se tourne vers des acteurs am√©ricains qui ne font qu‚Äôune partie du chemin. Car aujourd‚Äôhui, le pouvoir de la data doit √™tre √† la port√©e de chacun Now what ? Chez Cleyrop, nous sommes convaincus d‚Äôun monde o√π chacun pourrait prendre le contr√¥le de ses donn√©es afin d‚Äôen d√©multiplier l‚Äôusage. C‚Äôest pourquoi nous avons cr√©√© le premier DataHub europ√©en industriel, s√©curis√© et modulaire qui embarque les meilleures solutions europ√©ennes dans une plateforme consistante et pr√™te √† d√©ployer. Les enjeux sont importants, les ambitions aussi (CA 2021 3M‚Ç¨ et CA 2022 10M‚Ç¨) Nous avons d√©j√† lev√© fin 2021 4 Millions en Seed aupr√®s de business angels et de la BPI ce qui nous permet de se lancer dans ce d√©fi. Notre mission : Simplifier et d√©mocratiser l‚Äôacc√®s √† la donn√©e Les premiers projets d‚Äôexploitation des donn√©es dans des domaines tels que Sant√©, Recherche, Energie, ‚Ä¶ ont d√®s leurs premi√®res √©tapes obtenu des r√©sultats fantastiques. Que ce soient les partages collaboratifs, les corr√©lations inattendues, ou simplement la pertinence des analyses effectu√©es, la data commence seulement √† r√©v√©ler tout son potentiel. Et le meilleur est √† venir ! La data doit rentrer dans les usages courants de chacun pour que chaque entreprise ou organisation, puisse mettre l‚Äôintelligence de la donn√©e au coeur de ses d√©cisions et de ses op√©rations. Donn√©es brutes, sensibles, complexes‚Ä¶ notre mission est de rendre la Data accessible au plus grand nombre pour en d√©multiplier les usages. Notre ambition : Devenir le partenaire Data europ√©en de r√©f√©rence‚Äã Face √† la croissance exponentielle des donn√©es et ses usages, un point d‚Äôentr√©e unique et complet est une n√©cessit√© pour que les organisations puissent s‚Äôadapter √† leur environnement en constante √©volution. Pour cela, nous voulons offrir une solution simple, cl√© en main et souveraine avec un haut niveau de services. Cleyrop est fi√®re de constituer la 1√®re alternative europ√©enne et industrielle permettant aux organisations de devenir data driven dans un cadre de confiance. TLDR : Too long Didn‚Äôt read Participer pleinement √† la cr√©ation du premier Datahub europ√©en , avec une architecture et des technos les plus modernes possibles, tout √ßa au sein d‚Äôune √©quipe en pleine structuration , c‚Äôest ce qu‚Äôon te propose, tent√©.e ? Ce poste est en CDI // Localisation : Ile De France , Tu peux travailler depuis chez toi de mani√®re hybride et/ou depuis nos bureaux √† Paris 8√®me . Le salaire est compris entre 55k‚Ç¨ et 65k‚Ç¨ annuel brut en fonction du niveau qui te sera attribu√© √† l‚Äôissue du process de recrutement // Si tu as l‚Äôesprit doer , on est pr√™ts √† te recruter d√®s que tu veux en √™tre ! Pour ce poste une premi√®re exp√©rience similaire de 4 √† 6 ans est attendue. L‚Äôaventure que tu pourrais rejoindre : Nous avons cr√©√© Cleyrop fin 2020 avec pour objectif de cr√©er le premier DataHub europ√©en. ü§î Pourquoi ? Car aujourd‚Äôhui, c‚Äôest encore trop complexe. Car aujourd‚Äôhui, on se tourne vers des acteurs am√©ricains qui ne font qu‚Äôune partie du chemin. Car aujourd‚Äôhui, le pouvoir de la data doit √™tre √† la port√©e de chacun.e. üëÄ Now what ? Chez Cleyrop, nous sommes convaincus.es d‚Äôun monde o√π chacun pourrait prendre le contr√¥le de ses donn√©es afin d‚Äôen d√©multiplier l‚Äôusage. C‚Äôest pourquoi nous avons cr√©√© le premier DataHub europ√©en industriel, s√©curis√© et modulaire qui embarque les meilleures solutions europ√©ennes dans une plateforme consistante et pr√™te √† d√©ployer. Les enjeux sont importants, les ambitions aussi ! Notre contexte : Actuellement en plein d√©ploiement, nous ouvrons pour cette ann√©e une soixantaine de postes, il faut donc s‚Äôattendre √† rejoindre une √©quipe en pleine construction. Les ambitions sont fortes, collectivement nous portons √† bras le corps le projet Cleyrop pour qu‚Äôil r√©ussisse. Pourquoi ce recrutement ? Aujourd‚Äôhui le service support est √† construire , nous devons donc monter en comp√©tences sur le support L2 pour le rendre plus efficace. Nous devons √©galement √™tre capable de lire le code/log pour se retrouver dans notre produit. Nous devons √©galement √™tre garant de l‚Äôefficacit√© op√©rationnelle . Tu travailleras aux c√¥t√©s des √©quipes ops, produit et service , tu seras ainsi au coeur de la machine ! Tu travailleras √©galement aux c√¥t√©s de Leang qui intervient sur la partie support. Ce qui t‚Äôattend si tu nous rejoins Si tu nous rejoins, tes principaux objectifs seront les suivants : üéØ A court terme : √ätre √† l‚Äôaise avec notre produit √ätre l‚Äôaise avec la plateforme sous jacente R√©aliser les premiers tickets bien classifi√©s üöÄ A long terme : Le support L2 est en place Assurer le bon fonctionnement du support L2 Occuper le r√¥le de head of support si cette perspective d‚Äô√©volution te convient Plus techniquement, les objectifs attendus sont la qualit√© ops du service monitor√© depuis le ticketing system, la base de connaissance support est initi√©e, prise en main du produit de la data plateforme cleyrop d‚Äôun point de vue fonctionnelle et technique, service op√©rationnel. Notre process de recrutement : Ces comp√©tences et ces expertises seront v√©rifi√©es au cours de notre process de recrutement, d√©fini sp√©cialement pour ce job. 1/ D‚Äôabord un premier entretien avec Jennifer, notre Chief Recruitment Officer, pour √©changer autour de tes exp√©riences, r√©pondre √† tes questions concernant Cleyrop et le poste et d√©finir si le match s‚Äôop√®re entre tes attentes professionnelles et ce que nous pouvons te proposer. 2/ La deuxi√®me √©tape : un usecase pour comprendre ta m√©thode et tes comp√©tences. Il s‚Äôagit d‚Äôun cas concret qui te mettra aussit√¥t dans le bain de ce √† quoi tu pourrais √™tre confront√©.e chez Cleyrop. 3/ Le second entretien avec Jean, notre Directeur Technique afin d‚Äô√©changer autour de ton usecase, l‚Äôop√©rationnel sera de mise ! 4/ Le troisi√®me entretien avec Franck, notre VP Engineer, via cet √©change tu auras plus de visibilit√© concernant notre organisation il pourra √©galement te questionner sur la partie hard skill. 4/ La derni√®re √©tape sera un √©change avec Lauren, co-fondatrice et CPO pour t‚Äôexposer la vision long terme de Cleyrop. N‚Äôh√©site plus et envoie nous ta candidature, Jennifer t‚Äôattend d√©j√† pour le premier √©change !!! üòä C‚Äôest pour toi si : Si ce d√©fi t‚Äôattire, voici ce que l‚Äôon attend de toi. Les premi√®res comp√©tences sont requises et cruciales mais si tu ne les coches pas toutes parfaitement postules quand m√™me, nous sommes ouverts aux potentiels ! ü¶æ Les comp√©tences requises sont les suivantes : Connaissance ITIL incident VS problem management Connaissance data plateforme : 5 couches usual suspectes de la data plateforme Tu es Focus client et ton niveau de communication te permet d‚Äô√©changer avec tout type d‚Äôinterlocuteur, tu es √©galement orient√©.e problem solver Tu disposes d‚Äôune connaissance des m√©tiers tech pour naviguer facilement au sein de Cleyrop. C‚Äôest un vrai plus si tu es passionn√©.e de la DATA et si tu as d√©j√† travaill√© sur un/ou plusieurs de ces environnements : Databricks ; Datiku ; Snowflake ; Hadoop. Ce que nous pouvons t‚Äôapporter : Apporter sa pierre √† l‚Äô√©difice sur un projet √† impact ; Collaborer aux c√¥t√©s de passionn√©.es te permettant de monter en comp√©tences sur l‚Äôenvironnement de la data ; Partager dans un cadre collectif ; Ces comp√©tences et ces expertises seront v√©rifi√©es au cours de notre process de recrutement, d√©fini sp√©cialement pour ce job. 1/ D‚Äôabord un premier entretien avec Jennifer, notre Chief Recruitment Officer, pour √©changer autour de tes exp√©riences, r√©pondre √† tes questions concernant Cleyrop et le poste et d√©finir si le match s‚Äôop√®re entre tes attentes professionnelles et ce que nous pouvons te proposer. 2/ La deuxi√®me √©tape : un usecase pour comprendre ta m√©thode et tes comp√©tences. Il s‚Äôagit d‚Äôun cas concret qui te mettra aussit√¥t dans le bain de ce √† quoi tu pourrais √™tre confront√©.e chez Cleyrop. 3/ Le second entretien avec Jean , notre Directeur Technique afin d‚Äô√©changer autour de ton usecase, l‚Äôop√©rationnel sera de mise ! 4/ Le troisi√®me entretien avec Franck, notre VP Engineer, via cet √©change tu auras plus de visibilit√© concernant notre organisation il pourra √©galement te questionner sur la partie hard skill. 4/ La derni√®re √©tape sera un √©change avec Lauren , co-fondatrice et CPO pour t‚Äôexposer la vision long terme de Cleyrop. N‚Äôh√©site plus et envoie nous ta candidature, Jennifer t‚Äôattend d√©j√† pour le premier √©change !!! üòä","Cleyrop is seeking a Support Engineer to join their team and participate in creating the first industrial, modular, and secure European DataHub. This role requires experience in ITIL incident and problem management, along with knowledge of data platform technology. The successful candidate will have strong communication skills, be customer-focused, and have a passion for data. The job involves troubleshooting code and logs, ensuring operational efficiency, and being comfortable with the Cleyrop platform. The ideal candidate will work alongside the ops, product, and service teams and contribute towards creating a platform that simplifies and democratizes data access. Cleyrop offers a salary of 55k‚Ç¨ to 65k‚Ç¨ annually and provides an opportunity to work from home or Paris 8th office.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 4 ans,2,1,0.04154662416233763
90,73583,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-aerospatial-toulon-f-h_toulon,Data Engineer - A√©rospatial - Toulon -,Sopra Steria,"{Hadoop,Spark,Tableau,Nifi}",T√©l√©travail partiel possible,"Toulon, 13100","IT / Digital, Organisation / Management",CDI,2023-04-22,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Aeroline ¬ª regroupe nos activit√©s aupr√®s de grands acteurs de l'A√©ronautique et du Spatial avec une couverture internationale. Nos expertises principales : le manufacturing 4.0, la maintenance et les services qui englobent nos expertises autour de l'ing√©nierie et du ¬´ Product Lifecycle Management ¬ª. Sopra Steria est un acteur incontournable de la transformation et de la performance de la cha√Æne de valeur de nos clients. Votre futur environnement de travail Environnement technologique : Architecture Spark, Hadoop, Nifi, Qlick/Tableau, Environnement fonctionnel : Au sein d'une plateforme Big Data, l'√©quipe projet intervient, pour le compte d'un grand constructeur de la d√©fense de la r√©gion, sur le traitement et la mise √† disposition au client d'un grand volume de donn√©es dans le cadre d'une strat√©gie de transformation num√©rique. Votre r√¥le et vos missions : Vous rejoindrez une √©quipe dynamique et serez amen√©(e) √† contribuer de la construction au d√©ploiement de solutions permettant de traiter des enjeux comme : - Le remplacement d'outils clients par des solutions plus adapt√©es et plus efficaces, - Le d√©veloppement d'outils d'aide √† la d√©cision, - La digitalisation de chaines de traitement, - La mise en place d'indicateurs sur des √©quipements sp√©cifiques, - Etc. Vous aurez √©galement l'occasion de participer √† diff√©rents ateliers directement au contact du client afin de mieux cibler ses enjeux et ses attentes. Les apports du poste : - Sp√©cifier, d√©velopper des solutions techniques et les d√©ployer dans un contexte op√©rationnel - Participer √† des cycles courts favorisant le retour d'exp√©rience et la progression ; - Baigner dans un √©cosyst√®me Big Data √† forte valeur ; - Participer √† l'ensemble des activit√©s prises en charge par votre √©quipe (de l'ingestion jusqu'√† l'exposition data) ; - √ätre accompagn√©(e) au quotidien par un(e) responsable technique exp√©riment√©(e) et reconnu(e). Ce que nous proposons - Un package d'avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation. - Un accompagnement individualis√© avec un mentor. - Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ vendredi ¬ª. - L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore). - Vous √™tes √©galement form√©(e) au contexte de nos clients et √† leurs m√©tiers, ainsi qu'√† nos processus qualit√© et m√©thodes. Vous √™tes dipl√¥m√©(e) d'une √©cole d'Ing√©nieur ou d'un Master 2 Informatique. Vous √™tes curieux(se), logique et vous appr√©ciez le travail collaboratif. Vous √™tes passionn√©(e) par les enjeux induits par la transformation digitale en cours et √† venir et vous voulez en √™tre un acteur / une actrice. Vous avez un bon relationnel et adh√©rez √† l'id√©e que le d√©veloppement de la soci√©t√© s'appuie sur la veille technologique et l'esprit d'innovation des collaborateurs. Vous avez envie d'√©voluer au sein d'une √©quipe, dans un contexte d'innovation. Rejoignez-nous ! Employeur inclusif et engag√©, Sopra Steria oeuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils Tous nos postes sont ouverts aux personnes en situation de handicap",,Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
89,57088,https://www.welcometothejungle.com/fr/companies/railwai/jobs/software-and-data-engineer-f-h_montpellier,Software and Data Engineer,RAILwAI,"{Git,AWS,R,kubernetes,BigQuery,GCP,SQL,Python,docker}",T√©l√©travail partiel possible,"Rond-Point Benjamin Franklin, Montpellier, 34000","Logiciels, Intelligence artificielle / Machine Learning, Ferroviaire",CDI,2023-03-26,"RAILwAI est une jeune entreprise innovante cr√©√©e en octobre 2021. Elle combine les expertises de deux domaines tr√®s sp√©cifiques, √† haute technicit√© et √† forte valeur ajout√©e : La maintenance et l‚Äôexploitation d‚Äôinfrastructures de transport (lignes ferroviaires, m√©tros, tramways) La data science ou science des donn√©es RAILwAI propose des solutions logicielles, qui s‚Äôinterfacent avec tout type de capteurs ou sources de data, pour traiter et analyser les donn√©es brutes afin de constituer un panel d‚Äôoutils d‚Äôaide √† la d√©cision pour le client en fonction de ses besoins (e.g., tableaux de bord, data analytics ou maintenance pr√©dictive). Missions principales Participe √† la conception, au d√©veloppement et √† la maintenance des applications, modules ou services (back end, Cloud) qui permettent de traiter, visualiser, √©diter et valider des donn√©es, en prenant en compte les besoins des utilisateurs ainsi que les contraintes techniques (faisabilit√© au d√©veloppement) et celles li√©es √† l‚Äôoffre logicielle de la soci√©t√©. Activit√©s et T√¢ches Analyser / Concevoir : ‚àù Participer √† l‚Äôanalyse des besoins fonctionnels et techniques ‚àù Participer √† la d√©finition des sp√©cifications g√©n√©rales de la solution et de son environnement ‚àù Concevoir des solutions n√©cessitant l‚Äôutilisation de technologies Cloud, Data et Machine Learning pour r√©pondre √† des cas d‚Äôusages m√©tiers et √† la feuille de route Produit ‚àù Travailler en collaboration pour soutenir le d√©veloppement de nouvelles fonctionnalit√©s D√©velopper : ‚àù D√©velopper et tester des flux d‚Äôingestion de donn√©es de Data Lake et de traitement des donn√©es ‚àù D√©ployer, optimiser et industrialiser au quotidien des pipelines de donn√©es dans le Cloud ‚àù D√©velopper la solution (API, logiciel Web, application, syst√®me) en conformit√© avec les bonnes pratiques de d√©veloppement ‚àù Documenter le code source ‚àù Assurer la qualit√© du code, le respect des d√©lais, et les processus de mise en production Tester / D√©ployer : ‚àù Tester et valider les d√©veloppements : mettre en place des tests unitaires et d‚Äôint√©gration sur les fonctionnalit√©s d√©velopp√©es ‚àù Participer aux ateliers de recettes utilisateurs ‚àù Contribuer aux corrections n√©cessaires ‚àù Participer √† l‚Äôam√©lioration de la qualit√© du code ‚àù Participer √† la phase de mise en production des outils et solutions logicielles Maintenir : ‚àù Participer aux actions de maintenance des outils et solutions logicielles ‚àù Prendre en charge les demandes de corrections, petites √©volutions dans le cadre de cette maintenance ‚àù Participer au maintien en condition op√©rationnelle des solutions logicielles T√¢ches transverses : ‚àù Participer √† la documentation technique et globale du produit ‚àù Accompagner des √©quipes m√©tiers dans leurs travaux d‚Äôidentification et d‚Äôexpression des besoins sur la data ‚àù Contribuer √† la d√©finition, √† la r√©alisation et √† l‚Äôam√©lioration de la solution Produit de la soci√©t√© ‚àù Participer √† l‚Äô√©laboration des solutions logicielles, tant du point de vue d‚Äôarchitecture que du choix des diff√©rentes briques techniques (langages, frameworks, librairies, etc.) ‚àù Collaborer √©troitement avec les services de R&D et Innovation, de la Direction de la Strat√©gie et des Op√©rations, mais aussi au sein de l‚Äô√©quipe de la Direction Technique avec les diff√©rents profils √† venir ‚àù Collaborer aupr√®s des clients, fournisseurs, sous-traitants, notamment dans le cadre des diff√©rents projets, mais aussi en phase d‚Äôavant-vente avec l‚Äô√©quipe commerciale ‚àù Contribuer activement √† l‚Äô√©valuation des charges et de la planification ‚àù Pourra avoir la charge de la gestion et du suivi d‚Äô√©quipe au sein de la Direction Technique ‚àù Pourra encadrer des collaborateurs futurs (employ√©s, stagiaires, etc.) Environnement de travail Outils Google cloud platform (BigQuery, Cloud Run, etc.) Outils Atlassian (JIRA, BitBucket, SourceTree, Confluence) Python, Visual Studio Code Office 365, Teams, Outlook, etc. Comp√©tences requises Go√ªt pour l‚Äôinnovation et les nouvelles technologies Ouvert et curieux, aime travailler en mode agile Maitrise des langages SQL, R, Python Exp√©rience des environnements Cloud et Serverless : GCP/AWS Connaissances autour des processus d‚Äôindustrialisation et d‚Äôinfrastructure as code (Terraform), et des outils d‚Äôorchestration (docker, kubernetes, etc.) Pratique des outils de travail collaboratif (Git, Jira, etc.) Une exp√©rience en Machine Learning et Deep Learning et D√©veloppement Full Stack serait un atout. La ma√Ætrise de l‚Äôanglais technique serait un plus. Entretiens avec le Directeur Technique et le Directeur G√©n√©ral.","RAILwAI seeks a software developer to participate in the design, development, and maintenance of software applications that process, analyze, and visualize data for clients in the transportation industry. The ideal candidate has experience in Cloud environments, data processing, and machine learning, as well as familiarity with collaborative work tools and agile methodologies. Additional qualifications include expertise in SQL, R, and Python, and experience with infrastructure as code and orchestration tools such as Kubernetes. Fluency in technical English is desirable.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
88,57080,https://www.welcometothejungle.com/fr/companies/valtech/jobs/data-engineer-h-f-paris_paris,Data Engineer h/f - Paris,Valtech,"{DynamoDB,DBT,Snowflake,Synapse,Cassandra,Neo4J,Docker,Azure,MongoDB,Databricks,Kafka,Git,NoSQL,Qlik,Jenkins,Kubernetes,AWS,SQL,Airflow,Redshift,BigQuery,GCP,Python,Tableau}",T√©l√©travail partiel possible,"38 Rue des Jeuneurs, Paris, 75002","IT / Digital, Transformation",CDI,2023-03-26,"Valtech est une agence digitale d√©di√©e √† la transformation des entreprises. Valtech r√©unit plus de 5000 experts (dont 400 chez Valtech France) en technologies, design, d√©veloppement, cr√©ation, marketing et data, dans 61 bureaux r√©partis dans 22 pays (Allemagne, Argentine, Br√©sil, Bulgarie, Canada, Chine, Danemark, √âmirats arabes unis, √âtats-Unis, France, Inde, Mac√©doine, Mexique, Pays-Bas, Pologne, Portugal, Roumanie, Royaume-Uni, Singapour, Su√®de, Suisse, Ukraine). Ensemble, nous concevons et d√©ployons des strat√©gies digitales pour accompagner la transformation de grandes marques. Contexte Rejoignez le d√©partement d√©di√© √† la data ¬´ strat√©gie et donn√©es ¬ª de Valtech, qui aide les plus grandes marques et entreprises mondiales √† atteindre une croissance ambitieuse dans diff√©rents secteurs (luxe, retail, m√©dias, etc.). Nos clients nous choisissent en raison de la qualit√© de nos livrables et de notre engagement √† produire des r√©sultats commerciaux clairs et mesurables. Notre expertise s'exprime dans les domaines de l‚Äôing√©nierie et de la science des donn√©es, de l‚Äôanalyse de celles-ci, de l‚Äôoptimisation continue, de la technologie MarTech. Notre passion est de relever les d√©fis o√π nous r√©inventons le parcours client et construisons de nouvelles exp√©riences connect√©es et o√π nous orchestrons les donn√©es afin d'aider nos clients √† transformer leur mode de fonctionnement et optimiser les plateformes num√©riques pour le commerce et le marketing omnicanal. R√¥le / Mission Consultant Data Engineer En association avec des contributeurs et des gestionnaires individuels de haut niveau, vos principales fonctions et responsabilit√©s seront les suivantes : Am√©liorer la conception, mettre √† jour et modifier la programmation pour des parties et des sous-syst√®mes de pipelines de donn√©es, de r√©f√©rentiels et de mod√®les pour les donn√©es structur√©es/non structur√©es ; Travailler en tant qu‚Äôing√©nieur Big Data, contributeur individuel et joueur d‚Äô√©quipe ; Exploiter les donn√©es √† l‚Äôaide d‚Äôoutils et de langages de programmation modernes ; Analyser, concevoir et d√©terminer les activit√©s de codage, de programmation et d‚Äôint√©gration requises en fonction des objectifs sp√©cifiques et des lignes directrices √©tablies du projet ; Ex√©cuter et √©crire des parties de plans de test, de protocoles et de documentation pour la partie affect√©e de l‚Äôapplication ; Identifier et d√©bogguer les probl√®mes li√©s au code et sugg√©rer des modifications et/ou des am√©liorations ; Participer avec d‚Äôautres professionnels de la science des donn√©es pour d√©velopper des solutions fiables, rentables et de haute qualit√© pour les syst√®mes, mod√®les ou composants de donn√©es ; Collaborer et communiquer avec l‚Äô√©quipe de projet concernant l‚Äôavancement du projet et la r√©solution des probl√®mes. Profil Vous justifiez de 5 ans d'exp√©rience dans un r√¥le d‚Äôing√©nierie de donn√©es, d‚Äôanalyse commerciale, d‚Äôintelligence d‚Äôaffaires ou d‚Äôing√©nierie de donn√©es comparable, y compris les outils d‚Äôentreposage de donn√©es et d‚Äôintelligence d‚Äôaffaires. Hardskills Tableau, Qlik, Power BI, Data Studio ; Python, Tables delta, SGBDR traditionnel (SQL), NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan), Jenkins, Git, Apache, Kafka, AWS, Docker, Kubernetes, Apache Airflow, API Rest, Snowflake, DBT, BigQuery, AWS Redshift, Azure Synapse Analytics, Databricks ; Azure, AWS ou GCP sont des plus ; Softskills Direction de projets et d‚Äô√©quipes d‚Äôing√©nierie de data dans un cadre agile ; √ätre capable de transformer des donn√©es structur√©es, semi-structur√©es et non structur√©es, selon les meilleurs mod√®les de conception ETL / ELT ; Solide compr√©hension des principes de s√©curit√© de l‚Äôinformation pour assurer un traitement et une gestion conformes des donn√©es ; Une exp√©rience dans le secteur du luxe est un must ; Anglais ET Fran√ßais imp√©ratifs. Nos valeurs : Share - Dare - Care Share : Nous partageons les uns et les autres nos id√©es pour aller toujours plus loin - nous investissons dans la constitution d'√©quipes diversifi√©es et inclusives et dans une culture du travail et de l'excellence. Dare : Nous osons aller dans les territoires inconnus. √âchouer, recommencer, fait partie de notre m√©tier. Ce n'est ni un secret, ni un tabou, c'est une fa√ßon de penser, indissociable de l'exploration et de l'innovation. Care : Nous nous soucions de la qualit√© de ce que nous produisons. Nous souhaitons contribuer √† faire du monde un endroit meilleur gr√¢ce √† ce que nous cr√©ons. Diversit√© & Inclusion √Ä Valtech, nous concevons des exp√©riences fortes qui touchent chaque personne. Nous sommes donc proactifs en cr√©ant des lieux de travail qui conviennent √† chaque personne. Notre objectif est de cr√©er un lieu de travail √©quitable qui offre aux personnes de tous horizons le soutien dont elles ont besoin pour s'√©panouir, grandir et atteindre leurs objectifs (quels qu'ils soient). Si vous ne r√©pondez pas √† tous les crit√®res ou si vous avez des lacunes dans votre CV, nous serons heureux d‚Äôen savoir plus sur vous et qui sait ? Vous serez peut-√™tre le prochain Valtech ! L‚Äôagence Valtech est une agence digitale ax√©e sur la transformation des entreprises et nourrie par l'innovation. Avec +5500 experts en technologies, design, d√©veloppement, cr√©ation, marketing et data, dans 62 bureaux r√©partis dans 22 pays, nous sommes parfaitement positionn√©s pour soutenir la transformation globale de nos clients et leur permettre d'anticiper les d√©fis de demain, de stimuler leur croissance et d'obtenir un retour sur investissement rapide. Les clients font confiance √† Valtech pour √©liminer la complexit√© et fournir des solutions innovantes et sans friction comblant ainsi l'√©cart entre les attentes des clients et l‚Äôexp√©rience r√©elle. www.valtech.com Transform by Doing","Valtech seeks a Data Engineer Consultant to join their team dedicated to the ""strategy and data"" department. The role involves improving the design and modifying programming for data pipelines, repositories, and models while analyzing data using modern programming languages and tools, and collaborating with project teams to develop reliable, cost-effective, and high-quality solutions for data systems. The ideal candidate should have five years of experience in data engineering or a comparable role and possess technical skills in various data tools, languages, and platforms such as Python, Tableau, and AWS. Additionally, the candidate must have excellent project management and team leadership capabilities while understanding data security principles to ensure compliant data processing and management. Fluency in English and French is necessary for the role, and experience in the luxury sector is a must.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
87,73534,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_lyon_EXTIA_MgrzxmR,Data engineer,EXTIA,"{Python,Scala,Linux,SAS,HDFS,R,AWS,S3,Java,GCP}",T√©l√©travail partiel possible,"129 rue Servient, Lyon, 69003","Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-04-22,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Ensuite quoi Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶ Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes. Vous serez en charge de : Participer √† la d√©finition des besoins et √† la r√©daction des User Stories, Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e, Concevoir et construire des architectures de donn√©es, Int√©grer des sources de donn√©es, Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives, Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux. Profil : Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple, Vous maitrisez les bases de l‚Äôanalyse statistique, Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts. #LI-EB3 Curieux , vous adorez partager les derni√®res id√©es innovantes que vous avez d√©couvertes, Analytique , vous avez une √¢me d‚Äôenqu√™teur et les √©nigmes n‚Äôont aucun secret pour vous , Proactif , vous aimez les projets qui avancent vite et bien.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
82,56944,https://www.welcometothejungle.com/fr/companies/margo/jobs/data-engineer-h-f_paris_MARGO_r7xy5gZ,Data Engineer -,Margo,"{Scala,Hbase,via,Spark,Azure,Java,Hadoop,Python,Cloudera}",T√©l√©travail partiel possible,"1, Rue de Saint-P√©tersbourg, Paris, 75008","Logiciels, IT / Digital, FinTech / InsurTech",CDI,2023-03-26,"La mission de Margo ? Acc√©l√©rer la transformation digitale de ses clients en les accompagnant dans le d√©ploiement de projets IT complexes. Margo, c‚Äôest un cabinet de consulting √† taille humaine dont l‚Äôobjectif depuis 15 ans est d‚Äôassurer la satisfaction de ses consultants autant que celle de ses clients. Pour cela la recette est simple : ils s√©lectionnent avec attention leurs projets pour que chacun de leurs collaborateurs se sente stimul√© et progresse rapidement. Ils interviennent aujourd‚Äôhui principalement sur des sujets de coding et data, et sur des probl√©matiques m√©tiers dans la finance, la banque, l‚Äôassurance et l‚Äô√©nergie. Notre mission chez Margo ? Acc√©l√©rer la transformation digitale de nos clients en les accompagnant dans le d√©ploiement de projets IT complexes . Nous sommes un cabinet de conseil √† taille humaine dont l‚Äôobjectif depuis 15 ans est d‚Äôassurer la satisfaction de nos consultants autant que celle de nos clients. Pour cela la recette est simple : nous s√©lectionnons avec attention nos projets pour que chacun de nos collaborateurs se sente stimul√© et progresse rapidement . C‚Äôest pourquoi nous avons d√©velopp√© une expertise dans les secteurs d‚Äôactivit√© o√π l‚Äôon retrouve des contraintes techniques fortes : multithreading, temps r√©el, performance, volum√©trie de donn√©es,... Nos consultants interviennent ainsi chez des clients prestigieux en finance de march√©, assurance ou √©nergie, dans des grands groupes ou startups √† succ√®s. L‚Äôaventure Margo, c‚Äôest aussi int√©grer une communaut√© de 350 experts, tous passionn√©s par la tech, r√©partis entre Paris, Londres et Varsovie. A leurs c√¥t√©s, vous pourrez √©voluer rapidement et d√©velopper de nouvelles comp√©tences. Pr√™t √† nous rejoindre ? üéØ Exemple de projet propos√© par Margo : En int√©grant Margo, vous aurez le choix des missions sur lesquelles vous souhaitez travailler. Vous serez accompagn√© par notre √©quipe de Business Managers, dont le r√¥le est de rechercher le projet client qui correspondra le plus √† vos attentes. Ainsi, vous pourrez par exemple intervenir sur l‚Äôun de nos projets de refonte from scratch d‚Äôun datalake au sein d‚Äôun grand acteur de l‚ÄôAsset Management. L‚Äôobjectif est d'assurer la distribution de la donn√©e de la mani√®re optimis√©e pour cr√©er une couche de distribution et permettre aux Data Scientists d‚Äôimpl√©menter les use cases. Vous aurez ainsi l‚Äôopportunit√© d‚Äô√©voluer dans un environnement exigeant , en m√©thodologie agile et au sein d‚Äôune √©quipe d‚Äôexperts , compos√©e de 4 d√©veloppeurs Spark / Scala, 1 architecte data, 1 Ops et 1 tech lead. En tant que Data Engineer, vos missions seront : - D√©velopper en mode agile les usages m√©tier reposant sur le Datalake Hadoop - Identifier et mod√©liser des donn√©es n√©cessaires √† l'usage - S√©lectionner le stockage le plus adapt√© √† l'usage parmi les technologies de l'√©cosyst√®me Hadoop - D√©velopper en Spark et Scala des traitements de transformation et de production de donn√©es - D√©velopper des API RESTful (Scala / Play) permettant l'acc√®s aux donn√©es produites - Participer √† l‚Äôam√©lioration continue et au refactoring de code Stack techno : Hadoop/Cloudera Spark / Scala / Python / Java Cloud Azure Impala / Hbase ‚ú® La vie interne chez Margo Les projets que nous proposons chez Margo sont des missions longues (2 √† 3 ans) qui vous permettront d‚Äô√©voluer vers une expertise technique. Vous aurez √©galement l‚Äôopportunit√© de vous impliquer dans la vie interne de Margo et contribuer √† faire grandir notre communaut√©. Les possibilit√©s sont nombreuses, vous pourrez devenir : - Recruteur , pour tester techniquement les candidats pendant leur processus de recrutement, repr√©senter Margo lors de forums √©coles ou proposer des cooptations de personnes de votre r√©seau. - Formateur , pour partager votre expertise et vos connaissances au sein de la communaut√© Margo. - Manager, pour suivre en mission et √™tre garant de l‚Äô√©volution de carri√®re de consultants juniors. - R√©dacteur , pour mettre en lumi√®re votre expertise et celle de Margo en r√©digeant des articles techniques publi√©s sur notre blog et dans la presse sp√©cialis√©e. üîç Vous √™tes un(e) futur(e) Margo si : Must-Have - Vous √™tes issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun cursus universitaire √©quivalent niveau Bac + 5 / Master. - Vous aimez coder et vous √™tes passionn√©(e) d‚Äôinformatique. - Vous √™tes curieux(se) et vous vous int√©ressez aux derni√®res technologies du march√©. - Vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data Engineer. Nice to Have - Vous √™tes ambitieux et n‚Äôavez pas peur de travailler sur des projets challengeants dans des environnements √† fortes contraintes techniques, notamment de forte volum√©trie de donn√©es. - Vous aimez travailler en √©quipe et √™tes attach√© au respect des bonnes pratiques de code. - Vous parlez et comprenez l‚Äôanglais. ü§ùNotre processus de recrutement : 1. Postulez en ligne ! L‚Äô√©quipe RH √©tudie avec attention votre candidature et vous contacte si votre profil est en ad√©quation avec l‚Äôun de nos postes. 2. Premi√®re rencontre ! Vous √©changez avec un RH et un Business Manager sur votre parcours, vos aspirations professionnelles ainsi que sur Margo et les opportunit√©s que nous proposons. 3. Challengez-vous dans le cadre d‚Äôun entretien technique avec l‚Äôun de nos experts. C‚Äôest √©galement l‚Äôoccasion pour vous d‚Äôavoir son retour d‚Äôexp√©rience. 4. Dernier entretien de motivation : pour finir, vous rencontrez un membre du comit√© de direction de Margo pour confirmer notre fit culturel. Pendant tout le processus de recrutement, vous avez la possibilit√© de participer √† des √©v√©nements organis√©s par Margo et d‚Äô√©changer avec des collaborateurs afin d‚Äôen apprendre plus sur nous ! PS : Si vous √©tudiez ou travaillez loin de Paris, nous vous proposons de suivre ce processus en full visio via le syst√®me Hangout Meets de Google. üèä Plongez dans la culture d‚Äôentreprise de Margo : - Rencontrez nos √©quipes √† travers notre page WelcomeToTheJungle - D√©couvrez des retours d‚Äôexp√©riences de consultants Margo sur notre page YouTube - N‚Äôh√©sitez pas √† prendre connaissance des avis de nos collaborateurs sur GlassDoor Si vous ne vous reconnaissez pas dans cette offre, n‚Äôh√©sitez pas √† prendre connaissance de nos autres opportunit√©s üëâ nos offres d'emploi Engag√©e en faveur de l'√©galit√© des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap.","Margo is a human-sized consulting firm that aims to accelerate the digital transformation of its clients by accompanying them in complex IT projects. They are looking for a Data Engineer with a Bac + 5 degree, a passion for coding and a strong interest in the latest technologies, with previous experience in the field. The successful candidate will work on a project to revamp a datalake and will have the opportunity to develop new skills and progress quickly. Margo values the satisfaction of its consultants and clients and has developed expertise in the finance, banking, insurance, and energy sectors. The company offers long-term missions and opportunities for internal growth, such as becoming a recruiter, trainer, manager, or writer. The hiring process includes online application, interviews with the HR and business managers, a technical interview, and a meeting with a member of Margo's management team to confirm cultural fit.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
80,56818,https://www.welcometothejungle.com/fr/companies/stime/jobs/data-engineer-h-f_chatillon_STIME_0o7rxkK,Data Engineer,Stime,"{Microsoft,Databricks,Scala,Parquet,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,"117 Avenue de la R√©publique, Ch√¢tillon, 92320","Grande distribution, IT / Digital",CDI,2023-03-26,"La Stime r√©pond au mieux et au plus vite aux enjeux de business, de performance et de transformation du Groupement Les Mousquetaires et particuli√®rement de ses points de vente. Elle propose des services, con√ßoit et d√©livre des solutions informatiques simples, innovantes et adapt√©es aux besoins et aux usages. La Stime s‚Äôappuie sur des relations de partenariat et de confiance avec les p√¥les de performance et les services d‚Äôappui ainsi que sur les comp√©tences et l‚Äôengagement de ses collaborateurs. La Stime, DSI du Groupement Les Mousquetaires , est le moteur de la transformation informatique du Groupement Les Mousquetaires. Rejoindre la Stime c‚Äôest l‚Äôassurance de contribuer √† des projets √† fort enjeu et d‚Äô√™tre challeng√© dans ses missions. Contexte Au sein de la Direction Digital & Data, l‚Äô√©quipe Data Lab intervient sur les p√©rim√®tres Data et Analytics, dans le cadre du programme de transformation du SI du Groupement Les Mousquetaires. Vous aurez l‚Äôopportunit√© de rejoindre la Data Factory(STIME et Direction Data desenseignes Intermarch√© et Netto) dont la mission premi√®re est de d√©ployer des produits Analytics innovants √† destination des fonctions support et logistique, des magasins, et surtout des consommateurs. Apr√®s les premiers succ√®s et des attentes de plus en plus fortes, nous passons d√©sormais √† l‚Äô√©chelle avec une nouvelle organisation Agile en Domaine/Tribu/Squad et la n√©cessit√© d‚Äôindustrialiser nos pratiques pour acc√©l√©rer la livraison des produits, tout en capitalisant mieux sur le patrimoine de donn√©es constitu√©. Vous aurez l‚Äôoccasion d‚Äôint√©grer une de nos squad dont la principale mission est de d√©velopper des cas d‚Äôusage BI, Analytics et Data Science d√©ploy√©s sur notre plateforme Data h√©berg√©e sur le Cloud Azure. Partant(e) pour l‚Äôaventure ? Concr√®tement quelles seront vos missions : Participation √† des ateliers de d√©finition de besoin avec le PO ou le m√©tier Etude de besoin et proposition de solutions d‚Äôarchitecture sous la supervision d‚Äôun architecte solution Construction des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es dans notre Data Lake sur Azure D√©veloppement de notebooks de traitement avanc√© des donn√©es sur Databricks (langage Scala ou PySpark) Conception et mod√©lisation des donn√©es au niveau du Data Lake (format Parquet, Delta) Conception et mod√©lisation de donn√©es pour alimentation d‚Äôune base de donn√©es SQL sur le cloud Azure R√©alisation des tests unitaires, d‚Äôassemblage et d‚Äôint√©gration R√©daction de documentation technique (Dossier d'Analyse Technique, release delivery note, ‚Ä¶.) Pr√©paration de package pour livraison en CI/CD avec les √©quipes DevOps R√©alisation des activit√©s de maintenance corrective et √©volutive Participation aux c√©r√©monies agiles (Sprint Planning, Daily Scrum, Spring Review, Demo, Daily ‚Ä¶) Participation aux animations propos√©es r√©guli√®rement par la communaut√© de Data (groupe de travail, meetup avec des partenaires tels que Microsoft, Databricks ‚Ä¶) üí™ Les qualit√©s indispensables √† votre r√©ussite : Excellent relationnel et capacit√©s d‚Äôanalyse. R√©actif et force de proposition. Rigueur Curiosit√© et challenge Capacit√© √† travailler en √©quipe Autonomie üëä Nos forces : Un management qui favorise le travail collaboratif et s‚Äôappuie sur la co-construction Un environnement dynamique et stimulant Une excellente ambiance d‚Äô√©quipe. Vous aurez l‚Äôoccasion d‚Äôint√©grer une Data Factory compos√©e de pr√®s de 120 comp√©tences travaillant en mode agile. Vous serez int√©gr√© √† une communaut√© active compos√©e de plus 40 Data Engineer ou Data Scientist. Possibilit√© de participer √† des hackathon avec d‚Äôautres Data Engineer ou Tech lead Acc√®s √† de nombreux e-learning propos√©s par nos partenaires (Microsoft, Databricks, ‚Ä¶) Dipl√¥m√©(e) d‚Äôun Bac+2 avec une exp√©rience d'au moins 2 ans en data. Vous avez une app√©tence pour la Data, et poss√©dez au moins une exp√©rience dans la BI, Big Data et Analystics, avec une exp√©rience dans le d√©veloppement et l‚Äôimpl√©mentation de solutions Big Data, id√©alement sur le Cloud et des comp√©tences en d√©veloppement informatique (langages : Spark, Scala, SQL, Python). Bonne maitrise des concepts DevOps, CI/CD et outils associ√©s. Vous avez des capacit√©s d‚Äôanalyse, de pr√©sentation et de vulgarisation de votre travail et une bonne capacit√© d‚Äô√©coute et de recueil d‚Äôinformations en n‚Äôayant pas peur d‚Äôentrer dans les d√©tails d‚Äôun sujet technique ou m√©tier. Les plus : Une certification sur Spark, Azure ou Databricks sont un plus. Connaissance des outils Agile (JIRA) et ayant d√©j√† travaill√© en mode Agile Envie d‚Äôune exp√©rience enrichissante au sein d‚Äôune entreprise dynamique ? Rejoins-nous dans nos locaux √† Ch√¢tillon (92).","The Data Engineer position at Les Mousquetaires Group involves collaborating with the Data Lab team in developing BI, analytics, and data science use cases for the Group's support, logistics, stores, and customers. The successful candidate must have at least two years of experience in data, strong technical skills in Big Data development and implementation, and proficiency in Spark, Scala, SQL, and Python. They must also have an understanding of DevOps and CI/CD concepts, be able to work independently and in teams, and possess excellent analytical, presentation, and communication skills. Certification in Spark, Azure, or Databricks is desirable.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
104,72845,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-integration-de-flux_paris,Data Engineer - Int√©gration de Flux,Assistance Publique - H√¥pitaux de Paris - DSI,"{Linux,java,MySQL,Jupyter,Kafka,Jenkins,Scala,python,Nvidia,Talend,bash,via,Spark,SQL,Java,Python,Oracle,sql,Hadoop,Elastic,Docker,Kubernetes,NoSQL,Postgresql}",T√©l√©travail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDI,2023-04-22,"L‚Äô Assistance Publique - H√¥pitaux de Paris (AP - HP) est un √©tablissement public de sant√© et le centre hospitalier universitaire - CHU - de la r√©gion Ile-de-France, reconnu mondialement pour sa recherche. Le d√©partement Web Innovation Donn√©es (WIND) s‚Äôinscrit au sein de sa Direction des Syst√®mes d‚ÄôInformation. Sa mission ? üéØR√©aliser les projets num√©riques innovants au contact du monde hospitalier. Ses projets phares ? üöÄ Construire le plus gros entrep√¥t public de donn√©es de sant√© en Europe ! Le projet vise √† valoriser les donn√©es produites √† l‚ÄôAP-HP pour la recherche, l‚Äôinnovation et le pilotage des soins, tout en prot√©geant les donn√©es patient. L‚ÄôEntrep√¥t de Donn√©es de Sant√©, c‚Äôest d√©j√† +10 millions de patients dont les donn√©es sont structur√©es et r√©f√©renc√©es sur une plateforme Big Data d√©di√©e. üôã‚Äç‚ôÄÔ∏èüôã‚Äç‚ôÇFaciliter le quotidien des patients! Le domaine g√®re notamment toutes les applications mobiles et tous les t√©l√©services de l‚ÄôAP-HP. üî¨Monter une plateforme Bio-Informatique centrale pour assister les p√¥les de biologie de l‚Äô AP-HP dans leurs besoins informatiques (gestion du s√©quen√ßage, d√©ploiement de ressources de calcul). üåºD√©velopper et d√©ployer au niveau national les outils de collecte et d‚Äôanalyse √©pid√©miologique des donn√©es relatives aux maladies rares. La mission de votre √©quipe Afin de permettre le d√©veloppement de projets de recherche innovants, en particulier dans le domaine de l‚Äôintelligence artificielle, l‚ÄôAP‚ÄìHP a mis en place une plateforme Big Data, infrastructure informatique propre, int√©grant des capacit√©s de stockage et de calcul pour l‚Äôexploitation s√©curis√©e et performante des donn√©es de sant√© dont elle est d√©positaire. Cette plateforme h√©berge notamment l‚Äôentrep√¥t de donn√©es de sant√© (EDS) de l‚ÄôAP-HP. ‚Äã L‚ÄôEntrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP int√®gre des donn√©es administratives et m√©dicales de plus de 8 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (20 millions de dossiers m√©dicaux, plus de 10 millions de diagnostics, 181 millions de r√©sultats de laboratoires‚Ä¶). Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision. ‚Äã La Plateforme Big Data de l‚ÄôAP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d‚Äôespace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es, et de nombreuses autres machines applicatives. ‚Äã Votre √©quipe, le domaine ¬´ Plateforme Big Data ¬ª, a pour mission l‚Äôint√©gration des donn√©es de sant√© massives et complexes (donn√©es structur√©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation √† grande √©chelle, de mani√®re performante, ergonomique et s√©curis√©e dans le respect des principes et r√®gles de gouvernance des donn√©es d√©finis par l‚ÄôAP-HP. ‚Äã Vos missions Au sein de l‚Äô√©quipe en charge de la r√©alisation et du suivi des pipelines d‚Äôint√©gration de donn√©es, vous aurez pour missions de proposer et de d√©velopper de nouveaux flux de type ETL, de m√™me que des outils ou composants sp√©cifiques, adapt√©s √† la typologie des sources (donn√©es structur√©es ou non structur√©es). Ces d√©veloppements s‚Äôinscrivent dans un contexte exceptionnel de tr√®s grandes volum√©tries de donn√©es de sant√© avec des objectifs d‚Äôindustrialisation des flux d‚Äôint√©gration et de standardisation des donn√©es selon le mod√®le de donn√©es commun OMOP et d‚Äôinterop√©rabilit√© sur la base du standard d‚Äô√©change HL7-FHIR. En tant que data engineer - int√©gration de flux, sous la responsabilit√© du chef d‚Äô√©quipe int√©gration de flux, vous contribuez aux activit√©s transversales d‚Äôexploitation et collaborez avec les acteurs internes de l‚Äôinfrastructure et de DevOps pour b√¢tir le socle de nos projets de recherche sur donn√©es m√©dicales. Vos missions comportent typiquement des facettes suivantes : ‚Äã Contribuez √† la d√©finition des besoins techniques et √† l‚Äôaccompagnement des chercheurs/m√©decins lors de la r√©alisation de projets de recherche impliquant de nouvelles sources de donn√©es Analyserez les diff√©rents sources de donn√©es d‚Äôun point de vue technique (acquisition, stockage, transformation, exploitation, ‚Ä¶) D√©velopperez, industrialiserez et maintiendrez les flux d‚Äôint√©gration de donn√©es (extraction, s√©lection, collecte et int√©gration) soit avec l‚Äôutilisation de l‚ÄôETL Talend + connecteurs sp√©cifiques, soit via des d√©veloppements en Spark/Scala Contribuerez √† l‚Äôutilisation de ces nouvelles typologies de donn√©es (extraction, s√©lection, collecte et int√©gration) via des connecteurs sp√©cifiques d√©velopp√©s en java, python ou d‚Äôautres langages Industrialiserez le code de g√©n√©ration du flux de donn√©es et assurer sa performance globale Aiderez √† l‚Äôimpl√©mentation de standards et normes de mise √† disposition des donn√©es (OMOP/FHIR) D√©velopperez des m√©thodologies standardis√©es pour l‚Äôint√©gration de nouvelles donn√©es Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des donn√©es Travaillerez en collaboration avec des partenaires industriels dans le cadre des diff√©rents projets de recherche Id√©alement, vous.. Avez un dipl√¥me d‚Äôing√©nieur ou √©quivalent (bac+4/5, master2) en informatique ou sciences avec formation compl√©mentaire en informatique Avez une exp√©rience de d√©veloppement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, ‚Ä¶) et ETL (Talend ou autre) Avez une exp√©rience dans la manipulation de donn√©es avec le langage SQL Connaissez les standards en informatique de sant√© (HL7 v2, DICOM, HL7-FHIR, OMOP, ‚Ä¶) Avez le go√ªt de l‚Äôint√©gration de syst√®mes informatiques h√©t√©rog√®nes Avez des connaissances des bonnes pratiques de s√©curit√© informatique et de la r√©glementation informatique et libert√©s Adh√©rez aux valeurs du service public et vous avez un int√©r√™t prononc√© pour le domaine de la sant√© Avez un niveau d‚Äôanglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise du langage Python et de bash Bonnes connaissance des bases de donn√©es Oracle, Postgresql ou MySQL et langages associ√©s (sql) Bonne maitrise en m√©thode de conduite de projet (planification, reporting, analyse de risques, ‚Ä¶) Connaissance des outils ETL (Talend, ‚Ä¶), d‚Äôinformatique d√©cisionnelle et des m√©thodes de data warehouse (OLTP, RDBMS‚Ä¶) Connaissance du traitement des donn√©es massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en m√©thodes de d√©veloppement logiciel (dont cycle en V, m√©thodes agile), m√©thodes d‚Äôanalyse et de mod√©lisation (Merise, UML ‚Ä¶) Connaissance en administration d‚Äôenvironnements Linux Connaissance des m√©thodologies devops et des outils associ√©s (Docker, Kubernetes, Jenkins‚Ä¶) Et humainement ? Capacit√© √† appr√©hender des enjeux li√©s √† la recherche, √† l‚Äôanalyse de donn√©es et aux technologies de machine learning/deep learning, notamment dans le domaine de la sant√© (sant√© publique, imagerie m√©dicale, √©pid√©miologie, ‚Ä¶) Esprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collective Sens de l‚Äô√©coute, du r√©sultat et de la qualit√© Des qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√© Curieux, dynamique et cr√©atif, avec un r√©el envie de faire preuve d‚Äôinnovation 2-3 Entretiens T√©l/Visio + Pr√©sentiel",,Bac +4,Entre 250 et 2000 salari√©s,> 1 an,2,1,0.04154662416233763
108,72949,https://www.welcometothejungle.com/fr/companies/schneider-electric/jobs/cloud-data-engineer-f-h_rueil-malmaison,Cloud Data Engineer,Schneider Electric,"{Github,Python,Presto,Scala,Microsoft,Azure,durable,Databricks,Spark,Kubernetes,Docker,R,AWS,Flink,Java}",T√©l√©travail partiel possible,Rueil Malmaison,"Ing√©nieries Sp√©cialis√©es, Objets connect√©s, Energie",CDI,2023-04-22,"Schneider Electric est leader mondial de la gestion de l‚Äô√©nergie et des automatismes. Nous concevons, r√©alisons et mettons en ≈ìuvre des solutions innovantes pour une gestion de l‚Äô√©nergie s√ªre, efficace, fiable et durable. La raison d‚Äô√™tre de Schneider Electric est de permettre √† chacun de tirer le meilleur de son √©nergie et de ses ressources, afin de concilier progr√®s et d√©veloppement durable pour tous. Nous nommons cette ambition : Life is On. Notre mission est d‚Äô√™tre le partenaire digital du d√©veloppement durable et de l‚Äôefficacit√© de nos clients. Nous menons la transformation num√©rique en int√©grant les technologies de l‚Äô√©nergie et des automatismes les plus avanc√©es. Nous connectons jusqu‚Äôau cloud, produits, plateformes de contr√¥le, logiciels et services sur l‚Äôensemble du cycle de vie de vos activit√©s pour une gestion int√©gr√©e de l‚Äôhabitat r√©sidentiel, des b√¢timents tertiaires, des data centers, des infrastructures et des industries. Chez Schneider Electric , nous nous engageons √† r√©soudre des probl√®mes concrets pour cr√©er un avenir √©lectrique durable et num√©ris√©. L' Intelligence Artificielle a le potentiel de transformer les industries et d'aider √† d√©bloquer l'efficacit√© et la durabilit√©.Au sein de notre Global AI Hub , nous combinons notre expertise de longue date en mati√®re de fabrication et de domaine avec une innovation de pointe en mati√®re d'IA, d'apprentissage automatique et d'apprentissage profond pour favoriser une prise de d√©cision plus intelligente, l'agilit√© et la d√©carbonisation.Au sein de l'√©quipe AI Technology, nous recrutons un.e Cloud Data Engineer. Le groupe AI Technology (70 personnes) d√©veloppe 2 plateformes d'IA s'appuyant sur Azure et AWS pour r√©pondre aux besoins externes et internes. Vos responsabilit√©s : Ing√©nierie de pipelines de donn√©es efficaces, √©volutifs et adaptables pour traiter des donn√©es structur√©es, semi-structur√©es et non structur√©es. Maintenir et repenser les ensembles de donn√©es et les pipelines existants pour servir une grande vari√©t√© de cas d'utilisation. Mettre en ≈ìuvre l'observabilit√© des donn√©es et surveiller les pipelines de donn√©es en production afin d'en assurer le bon fonctionnement. Agir en tant que partenaire de l'√©quipe d'ing√©nierie de la plateforme et de l'√©quipe d'apprentissage automatique, comprendre leurs d√©fis et faire des recommandations avis√©es qui leur permettent d'avoir des solutions de donn√©es. Ecrire de l'infrastructure en tant que code pour d√©ployer notre infrastructure de donn√©es R√©diger des travaux ETL pour collecter et agr√©ger des donn√©es. Construire des mod√®les de donn√©es de haute qualit√©. Identification, mise en ≈ìuvre de composants et de biblioth√®ques partag√©s √† r√©utiliser d'un contexte √† l'autre. Sp√©cification, conception, mise en ≈ìuvre, test, validation et industrialisation de fonctions avanc√©es de gestion des donn√©es √† int√©grer dans les produits, syst√®mes et solutions. Collaboration avec des experts en donn√©es et en domaines afin d'identifier les m√©thodes, les outils et les technologies de transformation des donn√©es en vue d'√©laborer des plateformes et des offres de produits. Contribution √† l'identification et √† l'√©valuation de partenaires externes potentiels. Contribution √† la protection de la propri√©t√© intellectuelle, √† la capitalisation des connaissances et √† la communication interne et externe. Votre profil : Master ou doctorat ou dipl√¥me √©quivalent en traitement de donn√©es, informatique avec minimum 2 ans d'exp√©rience. Expert en ing√©nierie de pipeline de donn√©es utilisant des technologies telles que Presto, Spark ou Flink et ou les services g√©r√©s √©quivalents des fournisseurs de cloud public. Comp√©tences/exp√©rience en g√©nie logiciel : capacit√© √† coder, d√©boguer, tester (y compris les tests unitaires, les tests fonctionnels et les tests d'int√©gration) et d√©panner tout au long du processus de d√©veloppement de l'application et en mode agile. Id√©alement, connaissance du march√© de la gestion et de l'automatisation de l'√©nergie. Orientation vers la r√©solution de probl√®mes, l'obtention de r√©sultats et l'application de la technologie √† des cas concrets. Comp√©tences de communication efficaces, y compris une aptitude √† raconter des histoires bas√©es sur des donn√©es : convaincre avec des mots, avoir un impact avec des donn√©es et influencer avec des images. Autonomie ET capacit√© √† coop√©rer. Ouverture d'esprit ET rigueur scientifique. Anglais courant. Technologies : Langages : Python, Java, Scala Plateformes cloud : Microsoft Azure, AWS Outils : Kubernetes, Databricks, Docker, Spark, OpenDataSoft, Github, Terraform.Notre offre comprend une r√©mun√©ration attractive et va bien au-del√†. Nous offrons des avantages comp√©titifs, un environnement de travail qui encourage le d√©veloppement professionnel, un onboarding qualitatif et un accompagnement tout au long des diff√©rentes √©tapes de votre vie (formation, opportunit√©s de carri√®re, parentalit√©, flexibilit√©‚Ä¶), dans un lieu de travail formidable.Pourquoi nous? Schneider Electric est le chef de file de la transformation num√©rique de la gestion et de l'automatisation √©nerg√©tique. Nos technologies permettent au monde d'utiliser l'√©nergie de mani√®re s√ªre, efficace et durable. Nous nous effor√ßons de promouvoir une √©conomie mondiale √† la fois viable sur le plan √©cologique et hautement productive. 25,7 milliards d'euros de chiffre d'affaires global 137 000+ employ√©s dans plus de 100 pays 45 % du chiffre d'affaires de l'IdO 5 % du chiffre d'affaires consacr√© √† la R&D Vous devez soumettre une demande en ligne pour √™tre pris en consid√©ration pour ce poste. Ce poste sera post√© jusqu'√† ce qu'il soit rempli.",,Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
109,72959,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/analytics-engineer-h-f-cdi_paris,Analytics Engineer  - CDI,Publicis France,"{GCS,Python,Epsilon,Spark,NoSQL,AWS,SQL,bigquery,GCP}",T√©l√©travail partiel possible,"30-34 Rue du Chemin Vert, Paris, 75011","Marketing / Communication, Publicit√©, Digital, Relations publiques, AdTech  / MarTech, Ev√©nementiel, Design",CDI,2023-04-22,"Leader fran√ßais du marketing, de la communication et de la transformation digitale des entreprises, le groupe Publicis s‚Äôappuie sur un mod√®le unique qui allie cr√©ativit√©, technologie, m√©dias avec au c≈ìur la data. Pr√©sid√© par Agathe Bousquet, Publicis Groupe en France est une Talent company riche de plus de 5 000 collaborateurs, r√©partis dans 26 agences, qui accompagnent pr√®s de 600 clients. En France, le groupe est organis√© autour des activit√©s de cr√©ation avec les agences Publicis Conseil, Marcel, Leo Burnett Paris, Saatchi & Saatchi, Publicis Consultants, PublicisLive, Carr√© noir, Publicis Luxe, Prodigious, Razorfish. Le groupe est √©galement un acteur puissant des medias avec ses agences Publicis Media, Starcom, Zenith, Spark Foundry, Blue449, Performics. Enfin il intervient dans la transformation num√©rique avec Publicis Sapient, et dans la data avec Epsilon. Ainsi gr√¢ce √† une puissante alchimie, de la cr√©ativit√© et de la technologie, Publicis pilote la transformation des entreprises sur toute la chaine de valeur. La responsabilit√© soci√©tale de l‚Äôentreprise (RSE) irrigue tous ces m√©tiers et fait partie int√©grante de la strat√©gie globale de Publicis. Le groupe est par ailleurs le premier r√©seau en nombre d‚Äôagences √† avoir obtenu le label RSE Agences Actives d√©livr√© par l‚ÄôAACC avec 12 agences labellis√©es. Publicis, c‚Äôest aussi ¬´ Viva la diff√©rence ! ¬ª. Persuad√© que la diversit√© est un puissant moteur de cr√©ativit√© et de performance, Publicis s‚Äôengage sur de nombreux sujets pour promouvoir l‚Äô√©galit√© des chances et renforcer l‚Äô√©galit√© des origines. Le groupe est convaincu que la somme de ses diff√©rences fait sa richesse. Vous √™tes rattach√©.e au Lead Data & Analytics de Publicis Media et serez en charge de la structuration et de la livraison des projets Analytics (ingestion de sources de donn√©es, traitement, transformation, mod√©lisation et restitution), entre autre associ√©s aux √©quipes Data Science & Data Engineering, mais √©galement structurants pour poursuivre les travaux de transformation de l‚Äôentreprise et de ses usages. L‚ÄôAnalytics Engineer occupe un r√¥le central dans notre strat√©gie Data, en sa capacit√© √† pouvoir contribuer √† convertir la donn√©e en connaissance, tout en s‚Äôappuyant sur la technologie, √† poursuivre la conception de la prochaine g√©n√©ration d‚Äôalgorithmes. Ce que vous ferez La construction de pipelines Data depuis la collecte jusqu‚Äô√† la restitution Le rapatriement et l‚Äôingestion de donn√©es de multiples sources (Cloud ‚Äì GCS, AWS‚Ä¶ ‚Äì SFTP, API‚Ä¶) L‚Äôutilisation des Best Practices pour la cr√©ation des data models L‚Äôautomatisation de l‚Äôanalyse au travers des m√©canismes de monitoring et d‚Äôalerting, en post-d√©ploiement La gestion du suivi et livraison des projets associ√©s ‚Äì depuis la conception, au d√©veloppement, testing, et op√©rations associ√©es Les d√©fis associ√©s Richesse des environnements : de multiples sources, de multiples environnements dans un √©cosyst√®me en perp√©tuel mouvement impliquent une grande capacit√© √† pouvoir les aborder pour rassembler les donn√©es attenantes Media, Marketing, CRM‚Ä¶ : des donn√©es de nature diff√©rentes (First, Third‚Ä¶), en grande quantit√©, √† forte granularit√©, r√©unies pour en d√©duire les meilleurs insights Scalabilit√© : la quantit√© de donn√©e de chaque Client peut √™tre cons√©quente, mais le travail de transformation et processing peut l‚Äô√™tre davantage Respect de la vie priv√©e, gestion des donn√©es personnelles : nous pouvons √™tre amen√©s √† traiter de la donn√©e Media mise √† disposition sur des ‚ÄúClean Rooms‚Äù (Google, Facebook, Amazon‚Ä¶) Gestion des co√ªts : m√©thode & rigueur sont essentielles pour optimiser les d√©penses de stockage et computing de la donn√©e (en interne ou pour le compte de nos clients) Qualifications Formation d‚Äôing√©nieur.e en informatique (ou assimil√©.e), m√©thodes Agile ; vous disposez de 2 ans minimum d‚Äôexp√©rience dans l‚Äôadministration, configuration, monitoring, d√©bogage et mise en oeuvre d‚Äôune solution Cloud (GCP id√©alement), ainsi que dans les m√©canismes d‚Äôint√©gration (fichiers, messages, data‚Ä¶).
La certification Google Cloud Engineer est recommand√©e, ainsi que la pratique de l‚Äôanglais. Expertises & comp√©tences Langages de d√©veloppement : Python, SQL, Basch Comp√©tences : manipulation de donn√©es en SQL / NoSQL Expertise : Google Cloud Platform (Cloud Functions, Cloud Run, Cloud Pub/Sub, Cloud Workflow, Dataplex, CI/CD‚Ä¶), Amazon Web Services‚Ä¶ Connaissance des m√©canismes de constitution d‚ÄôETL, technologies d‚Äôorchestration (Workflow, cloud scheduler, ‚Ä¶). Des connaissances en Terraform et en bigquery est un plus Phases de testing ; documentation du code",,Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
128,73414,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/cloud-engineer_paris_WEWYS_dmjMkk,Cloud Engineer,Wewyse,"{Python,Jenkins,Azure,Shell,unix,Docker,Kubernetes,AWS,Java,GCP}",T√©l√©travail partiel possible,"48 Rue du Ch√¢teau d'Eau, Paris, 75010","Digital Marketing / Data Marketing, IT / Digital, Transformation",CDI,2023-04-22,"Wewyse est le cabinet de conseil de Wemanity, sp√©cialis√© en Data et en Intelligence Artificielle. C‚Äôest aussi et surtout une communaut√© de passionn√©s partageant l‚Äôambition de grandir ensemble et d‚Äôouvrir le champ des possibles dans leurs domaines. Nous apportons conseil et expertise technique pour d√©finir avec nos clients les strat√©gies et solutions adapt√©es √† leurs enjeux, puis nous les accompagnons dans les phases de conception et de d√©ploiement. √ätre Cloud Engineer chez Wewyse, c‚Äôest : planifier, designer et d√©velopper des applications sur le cloud, maintenir et r√©aliser le support des architectures cloud, migrer des applications on-premise vers le cloud, intervenir chez des clients pour y porter l‚Äôexpertise Wewyse dans des contextes et des secteurs vari√©s, recevoir et partager de la connaissance et des savoirs-faire lors de nombreux √©v√®nements, participer √† des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires acad√©miques et des start up, √™tre encourag√©, conseill√© et accompagn√© dans un parcours de formation adapt√© √† vos ambitions professionnelles faire partie de la famille Wemanity avec ses √©v√®nements et ses multiples opportunit√©s de carri√®re. Chez Wewyse, nous aimons : Les providers cloud : AWS, GCP, Azure Les langages Java, Python, Shell unix Les API La conteneurisation : Docker et Kubernetes Les outils DevOps : Jenkins, Ansible , Terraform La s√©curit√© : VaultLes m√©thodes Agiles Les personnalit√©s ouvertes, curieuses, ambitieuses L‚Äôanglais",,Bac +5 / Master,Entre 15 et 50 salari√©s,> 1 an,2,1,0.04154662416233763
148,56344,https://www.welcometothejungle.com/fr/companies/lectra/jobs/ingenieur-data-data-engineer-h-f_cestas,Ing√©nieur Data / Data Engineer,Lectra,"{Microsoft,Jenkins,Git,Scala,Kubernetes,Snowflake,Docker,Kafka,Linux,via,Spark,RabbitMQ,Azure,Java,SQL,Python}",T√©l√©travail partiel possible,"23, Chemin de Marticot, Cestas, 33610","Logiciels, SaaS / Cloud Services",CDI,2023-03-26,"Acteur majeur sur les march√©s de la mode, de l‚Äôautomobile et de l‚Äôameublement, Lectra contribue au d√©veloppement de l‚Äôindustrie 4.0 avec audace et passion. Le groupe propose des solutions d‚Äôintelligence industrielle √† la pointe de la technologie qui facilitent la transformation digitale des entreprises. Gr√¢ce √† ses logiciels, √©quipements, donn√©es et services, Lectra aide ses clients √† repousser les fronti√®res et √† lib√©rer pleinement leur potentiel. Ses 2 400 collaborateurs sont guid√©s par trois valeurs fondamentales, qui font la fiert√© du groupe : faire preuve d‚Äôouverture d‚Äôesprit, √™tre des partenaires de confiance et innover avec ardeur. Fond√©e en 1973, Lectra a r√©alis√© un chiffre d‚Äôaffaires de 521 millions d‚Äôeuros en 2022 et est cot√©e sur Euronext (LSS). Pour plus d‚Äôinformations, visitez lectra.com. Tu recherches une nouvelle exp√©rience de Data Engineer (H/F) alors on a un job pour toi ! Tes missions : ‚Ä¢ Tu participeras aux √©tudes et phases exploratoires des projets Data, ‚Ä¢ Tu r√©aliseras en √©quipe la conception et l‚Äôimpl√©mentation des solutions en gardant un haut niveau de qualit√©, ‚Ä¢ Tu livreras r√©guli√®rement de la valeur en production et tu sauras mettre les outils n√©cessaires √† la supervision de ton d√©veloppement, ‚Ä¢ Tu participeras √† l‚Äôam√©lioration continue de l‚Äô√©quipe (pratiques de d√©veloppement, organisation d‚Äô√©quipe, etc) ‚Ä¢ Tu rechercheras la techno la plus adapt√©e pour garantir la s√©curit√©, la scalabilit√© des solutions et l‚Äôexp√©rience utilisateur la plus optimale Environnement technique ‚Ä¢ Linux pr√©f√©r√© ou Windows ‚Ä¢ Snowflake, Apache Spark, Azure Datalake, Apache Kafka, RabbitMQ ‚Ä¢ SQL, Scala, Kotlin, Python, Java ‚Ä¢ Cloud : Microsoft Azure, Docker, Kubernetes ‚Ä¢ Outillage : Git, Jenkins ‚Ä¢ M√©thodologie : Agile (Kanban), pair/mob programming, code review. Tes formations / comp√©tences : Tu as une formation Bac+5 souhait√©e en d√©veloppement logiciel ou √©quivalent, Tu as une exp√©rience significative d√©j√† en tant qu‚ÄôIng√©nieur Data ou dans le d√©veloppement logiciel orient√©e vers la donn√©e, Tu recherches le sens et la valeur des fonctionnalit√©s qui te sont demand√©es, Tu aimes d√©velopper en suivant les bonnes pratiques dans un environnement en int√©gration continue, Tu as l‚Äôhabitude de travailler en √©quipe et de partager ton point de vue, Tu connais au moins un de ces composants des Data Platforms modernes (Snowflake, Azure Datalake, Apache Spark, Apache Kafka, ‚Ä¶) et tu ma√Ætrises un langage de d√©veloppement (id√©alement Scala ou Kotlin, Python, Java) en sus du SQL, Tu sais structurer la donn√©e (relationnel, dimensionnel ou document) pour la rendre le plus facilement exploitable. Tu es sensible aux probl√©matiques de qualit√© (de la donn√©e et des livrables), tests et Architecture As Code. Tu es ouvert(e) √† l‚Äôagilit√© et au travail en √©quipe. Ce que l‚Äôon te propose chez Lectra ? ‚Ä¢ De faire √©merger une architecture en √©quipe dans la bonne humeur et le partage, ‚Ä¢ De travailler sur des projets Data avec une stack de traitement et des langages et frameworks modernes, ‚Ä¢ De d√©ployer en continu ton code avec une culture int√©gr√©e des tests, ‚Ä¢ Travailler sur des probl√©matiques d‚Äôune plateforme donn√©e, et de traitements par lot ou temps r√©el des donn√©es, ‚Ä¢ De travailler dans un environnement Agile, ‚Ä¢ De fortement collaborer avec les autres membres de l‚Äô√©quipe √† travers le pair-programming, le mob-programming et les revues de code fr√©quentes, ‚Ä¢ De b√©n√©ficier de la souplesse du travail dans le Cloud Azure, ‚Ä¢ D‚Äôaller √† des conventions et conf√©rences √† travers le monde (Devoxx, Dataquitaine, AgileFrance, MixIT, BDX I/O, Kafka SUMMIT et bien d‚Äôautres), ‚Ä¢ De b√©n√©ficier de nos nombreuses formations internes et externes, ‚Ä¢ De conserver un √©quilibre vie pro/vie perso (70 jours de t√©l√©travail par an, CSE, restaurant d‚Äôentreprise, ‚Ä¶), ‚Ä¢ Des activit√©s sportives et ludiques entre midi et 2 (club de jeux, badminton, running, cross training, ‚Ä¶). Le poste est bas√© √† Cestas (23 chemin de Marticot) - pour nous rejoindre : avec possibilit√© de t√©l√©travail : 1 jour et demi par semaine. ‚Ä¢ Accessible par l‚Äôautoroute sortie 25 de l‚ÄôA63 (parking voiture et deux-roues sur place) ‚Ä¢ Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de v√©lo/trottinette pour acc√©der au campus sur piste cyclable hors route. ‚Ä¢ Depuis Pessac - Arr√™t Unitec via le Transgironde 602 : arr√™t Marticot : 20min.","Lectra, a major player in fashion, automotive, and furniture markets, is looking for a Data Engineer with experience in software development and data orientation. The successful candidate will work on data projects, participate in the design and implementation of solutions while ensuring high quality and supervising the development. Skills required include experience in at least one component of modern data platforms and proficiency in one or more programming languages. The role is based in Cestas, with the possibility of teleworking. Lectra offers benefits that include 70 working days of telecommuting per year, sports and leisure activities, and international conventions and conferences.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
140,50015,https://www.welcometothejungle.com/fr/companies/itera-cz/jobs/middle-data-integration-application-support-engineer_brno,Middle Data Integration Application Support Engineer,Itera Czechia,"{Microsoft,Oracle,SAS,Denodo,PostgreSQL,Informatica,Linux,Azure,SQL,Python,Bash}",T√©l√©travail partiel possible,"Vlnƒõna, Brno, 602 00",Logiciels,CDI,2023-02-07,"Itera is a Norwegian IT consulting company, which spreaded thoughout the whole Europe during its nearly 30 years existence and recently opened a brand new office in the most modern co-working space in Brno, Czechia. People in Itera work on various projects in the banking and insurance sector explicitely for Scandinavian clients, mostly Norwegian companies. It‚Äôs the Norwegian origin which makes Itera so special and imprints into its atmosphere, culture and values. The most important aspects are: Equality and trust: Itera gives every consultant a space for self-realisation and stands as an equal partner to its clients, where proactivity, open and honest feedback and clear communication are the basic essence. Work-life balance: Instead of overtimes and pressure from upcoming deadlines, consultants in Itera have an opportunity to adjust work according to their time possibilities. The biggest priority is to deliver high-quality solutions. ‚ÄúItera fit‚Äù: Itera carefully chooses new colleagues not only according to their technical skills and experience, but complex communication skills are similarly important. They also love to spend time together not only at work, but also on a teambuilding, sports activities or playing games. Itera is looking for a Middle Application (Data Integration) Support Engineer with a wide experience within IT operations, system engineering, client-server Data Analytics and Reporting applications support, for one of Itera customers which provides services in financial sector. Strong technical background, problem analysis skills, and good communication skills are essential. Tasks and responsibilities: Client-server application support: maintenance, troubleshooting, consultancy etc. Data ETL (Extract, Transform, Load) tasks development, deployment, and support Routines automation, reports development Code performance improvements Work with a global team spread across tech hubs in multiple geographies and time zones Perform root-cause incident analysis to gather findings and identify follow-up actions that lead to more reliable products 1+ year experience with systems/applications support, preferably Data Integration, Analytics & Reporting systems Microsoft stack: Windows 10/11, Servers Experience with database administration (e.g., MS SQL Server, PostgreSQL, Oracle) T-SQL basic knowledge Network and AD basics Familiarity with logging, monitoring and metric collection systems Experience in configuration, deployment and maintenance of cloud-based infrastructure (Azure) Scripting languages: PowerShell (Python, Bash, SAS be a plus) Hands-on experience with Azure DevOps Understanding of L1-L3 support chain Excellent troubleshooting skills Experience with ServiceNow or similar tracking system Passion for continuously striving to improve the customer experience Strong desire to current on technical trends in order to suggest innovative tools and approaches to interesting problems Will be a plus if you have: SAS Analytics support experience and basic programming skills Denodo Platform support experience Any Data integration system support experience (Informatica, HP Connect-IT etc.) DevOps skills and experience Linux administration Data Engineer skills ‚Äì Cloud (Azure)/On-prem Step 1: prescreen with our recruiter (phone/MS Teams/etc.) Step 2: 1st round ITW (online/f2f) * part 1 with Recruiter & People manager will give you more info about how we operate * part 2 with our technical colleague will provide you a chance to discuss tech details and your competence Step 3: 2nd round ITW with our Director of Itera Czechia (online/f2f) Step 4: offer :)","Itera is seeking a Middle Application (Data Integration) Support Engineer with experience in IT operations, system engineering, data analytics, and reporting applications support in the financial sector. Strong technical and communication skills, as well as problem analysis skills, are necessary for the role. The ideal candidate will have experience with Microsoft stack, database administration, network and AD basics, and cloud-based infrastructure. The company values work-life balance, teamwork, and communication skills.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
139,56572,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-modelisation-standardisation_paris,Data Engineer - Big Data,Assistance Publique - H√¥pitaux de Paris - DSI,"{Oracle,python,bash,Nvidia,Docker,Postgresql,MySQL,scala,Talend,Kafka,Linux,NoSQL,Elastic,java,Jenkins,Kubernetes,Java,SQL,Hadoop,Jupyter,Scala,via,Spark,sql,Python}",T√©l√©travail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDD / Temporaire,2023-03-26,"L‚Äô Assistance Publique - H√¥pitaux de Paris (AP - HP) est un √©tablissement public de sant√© et le centre hospitalier universitaire - CHU - de la r√©gion Ile-de-France, reconnu mondialement pour sa recherche. Le p√¥le Innovation& Donn√©es (ID) s‚Äôinscrit au sein de sa Direction des Services Num√©riques. Sa mission ? üéØR√©aliser les projets num√©riques innovants au contact du monde hospitalier. Ses projets phares ? üöÄ Construire le plus gros entrep√¥t public de donn√©es de sant√© en Europe ! Le projet vise √† valoriser les donn√©es produites √† l‚ÄôAP-HP pour la recherche, l‚Äôinnovation et le pilotage des soins, tout en prot√©geant les donn√©es patient. L‚ÄôEntrep√¥t de Donn√©es de Sant√©, c‚Äôest d√©j√† +12 millions de patients dont les donn√©es sont int√©gr√©es, structur√©es et r√©f√©renc√©es sur une plateforme Big Data d√©di√©e. üôã‚Äç‚ôÄÔ∏èüôã‚Äç‚ôÇFaciliter le quotidien des patients! Le domaine g√®re notamment toutes les applications mobiles et tous les t√©l√©services de l‚ÄôAP-HP. üî¨Monter une plateforme Bio-Informatique centrale pour assister les p√¥les de biologie de l‚Äô AP-HP dans leurs besoins informatiques (gestion du s√©quen√ßage, d√©ploiement de ressources de calcul). üåºD√©velopper et d√©ployer au niveau national les outils de collecte et d‚Äôanalyse √©pid√©miologique des donn√©es relatives aux maladies rares. La mission de votre √©quipe Afin de permettre le d√©veloppement de projets de recherche innovants, en particulier dans le domaine de l‚Äôintelligence artificielle, l‚ÄôAP‚ÄìHP a mis en place une plateforme Big Data, infrastructure informatique propre, int√©grant des capacit√©s de stockage et de calcul pour l‚Äôexploitation s√©curis√©e et performante des donn√©es de sant√© dont elle est d√©positaire. Cette plateforme h√©berge notamment l‚Äôentrep√¥t de donn√©es de sant√© (EDS) de l‚ÄôAP-HP. ‚Äã L‚ÄôEntrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP int√®gre des donn√©es administratives et m√©dicales de plus de 8 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (20 millions de dossiers m√©dicaux, plus de 10 millions de diagnostics, 181 millions de r√©sultats de laboratoires‚Ä¶). Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision. ‚Äã La Plateforme Big Data de l‚ÄôAP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d‚Äôespace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es, et de nombreuses autres machines applicatives. ‚Äã Votre √©quipe, le domaine ¬´ Plateforme Big Data ¬ª, a pour mission l‚Äôint√©gration des donn√©es de sant√© massives et complexes (donn√©es structur√©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation √† grande √©chelle, de mani√®re performante, ergonomique et s√©curis√©e dans le respect des principes et r√®gles de gouvernance des donn√©es d√©finis par l‚ÄôAP-HP. ‚Äã Vos missions Au sein de l‚Äô√©quipe en charge de la Plateforme Big Data de l‚ÄôAPHP, vous aurez pour missions de proposer et de d√©velopper des outils ou composants r√©pondant aux attentes des m√©decins et chercheurs pour l‚Äôexploitation des donn√©es collect√©es dans le cadre de leurs projets de recherche. Ces d√©veloppements s‚Äôinscrivent dans un contexte de standardisation des donn√©es selon le mod√®le de donn√©es commun OMOP et d‚Äôinterop√©rabilit√© sur la base du standard d‚Äô√©change HL7-FHIR. En tant que data engineer - donn√©es massives, sous la responsabilit√© du chef d‚Äô√©quipe d√©veloppement donn√©es massives, il s‚Äôagira de contribuer √† la cr√©ation d‚Äôoutils d‚Äôint√©gration, de visualisation, d‚Äôexploration et d‚Äôenrichissement de donn√©es m√©dicales pour la recherche, souvent en lien direct avec des personnels m√©dicaux. Outre l‚Äôint√©gration technique des donn√©es cliniques, les d√©veloppements rel√®vent globalement de la pseudonymisation des donn√©es pour assurer la confidentialit√© des dossiers m√©dicaux, de la standardisation des mod√®les de donn√©es, de la mise en place de moteurs de recherche performant incluant des notions s√©mantiques et de l‚Äôanalyse qualitative et statistique des donn√©es collect√©es. Selon la typologie des donn√©es (donn√©es structur√©s, imagerie, voix, signaux physiologiques, etc.) des outils plus sp√©cifiques sont √©galement mise en ≈ìuvre. Vos missions comportent typiquement des facettes suivantes : ‚Äã Contribuez √† la d√©finition des besoins techniques et √† l‚Äôaccompagnement des datascientists, chercheurs, et m√©decins lors de la r√©alisation de projets de recherche impliquant de nouvelles sources de donn√©es Analyserez les diff√©rents sources de donn√©es d‚Äôun point de vue technique (acquisition, stockage, transformation, exploitation, ‚Ä¶) D√©velopperez, industrialiserez et maintiendrez des traitements de donn√©es (extraction, s√©lection, collecte et int√©gration) dans un contexte big data (d√©veloppements en Spark/Scala) Contribuerez √† l‚Äôutilisation de ces nouvelles typologies de donn√©es (extraction, s√©lection, collecte et int√©gration) via des connecteurs sp√©cifiques d√©velopp√©s en java/scala, python ou d‚Äôautres langages Aiderez √† l‚Äôimpl√©mentation de standards et normes de mise √† disposition des donn√©es (OMOP/FHIR) Industrialiserez le code de g√©n√©ration du flux de donn√©es et assurer sa performance globale Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark) D√©velopperez des m√©thodologies standardis√©es pour l‚Äôint√©gration de nouvelles donn√©es Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des donn√©es Travaillerez en collaboration avec des partenaires industriels dans le cadre des diff√©rents projets de recherche Id√©alement, vous.. Avez un dipl√¥me d‚Äôing√©nieur ou √©quivalent (bac+4/5, master2) en informatique ou sciences avec formation compl√©mentaire en informatique Avez une exp√©rience de d√©veloppement sous Linux, des langagage Java/Scala et si possible Python Avez une exp√©rience dans la manipulation de donn√©es avec le langage SQL Connaissez les standards en informatique de sant√© (HL7 v2, DICOM, HL7-FHIR, OMOP, ‚Ä¶) Avez le go√ªt de l‚Äôint√©gration de syst√®mes informatiques h√©t√©rog√®nes Avez des connaissances des bonnes pratiques de s√©curit√© informatique et de la r√©glementation informatique et libert√©s Adh√©rez aux valeurs du service public et vous avez un int√©r√™t prononc√© pour le domaine de la sant√© Avez un niveau d‚Äôanglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise des langages Java/Scala (Spark), Python et de bash Bonnes connaissance des bases de donn√©es Oracle, Postgresql ou MySQL et langages associ√©s (sql) Bonne maitrise en m√©thode de conduite de projet (planification, reporting, analyse de risques, ‚Ä¶) Connaissance des outils ETL (Talend, ‚Ä¶) et des m√©thodes de data warehouse (OLTP, RDBMS‚Ä¶) Connaissance du traitement des donn√©es massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en m√©thodes de d√©veloppement logiciel (dont cycle en V, m√©thodes agile), m√©thodes d‚Äôanalyse et de mod√©lisation (Merise, UML ‚Ä¶) Connaissance en administration d‚Äôenvironnements Linux Connaissance des m√©thodologies devops et des outils associ√©s (Docker, Kubernetes, Jenkins‚Ä¶) Et humainement ? Curieux, dynamique et cr√©atif, avec un r√©el envie de faire preuve d‚Äôinnovation Esprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collective Sens de l‚Äô√©coute, du r√©sultat et de la qualit√© Capacit√© √† appr√©hender des enjeux li√©s √† la recherche, √† l‚Äôanalyse de donn√©es et aux technologies de machine learning/deep learning dans le domaine de la sant√© (sant√© publique, imagerie m√©dicale, √©pid√©miologie, ‚Ä¶) Des qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√© 2-3 Entretiens T√©l/Visio + Pr√©sentiel","The AP-HP is seeking a data engineer with experience in developing big data tools to join their Plateforme Big Data team. The successful candidate will contribute to the integration, visualization, exploration, and enrichment of medical data for research, as well as developing methodologies for the integration of new data. Candidates must have experience with Java/Scala, SQL, and HL7-FHIR, as well as an understanding of data security and privacy regulations. Strong teamwork skills, curiosity, and creativity are also desirable qualities.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
138,50060,https://www.welcometothejungle.com/fr/companies/april/jobs/data-analytics-engineer_lyon,DATA Analytics Engineer,APRIL,"{Dataiku,Mongo,Snowflake,R,SQL,Python}",T√©l√©travail partiel possible,"114 Bd Marius Vivier Merle, Lyon, 69003","Logiciels, Assurance, Big Data",CDI,2023-02-07,"Les 2 300 collaborateurs d‚ÄôAPRIL dessinent au quotidien le futur de l‚Äôassurance en proposant √† leurs clients et partenaires ‚Äì particuliers, professionnels et entreprises ‚Äì une exp√©rience remarquable alliant le meilleur des relations humaines et de la technologie. APRIL est le cr√©ateur et le leader du courtage grossiste en assurance en France avec un r√©seau de plus de 15 000 courtiers partenaires. Nous sommes aujourd‚Äôhui un acteur reconnu en France, en Europe, en Asie et en Am√©rique du Nord pour nos savoir-faire en sant√© et pr√©voyance des particuliers, professionnels et TPE, en assurance des emprunteurs, en sant√© internationale et en dommages de niches. Rejoindre APRIL et prendre soin du futur c‚Äôest : ‚Ä¢ choisir un m√©tier dont vous pourrez √™tre fier : ¬´accompagner et prot√©ger √† chaque moment qui compte, simplement¬ª telle est la mission et la raison d‚Äô√™tre partag√©e par l‚Äôensemble de nos collaborateurs, ‚Ä¢ d√©velopper votre expertise dans un environnement en pleine transformation, au carrefour de l‚Äôinnovation et de l‚Äôexp√©rience client : notre ambition √† horizon 2023, √™tre un acteur digital, omnicanal et agile, champion de l‚Äôexp√©rience client, ‚Ä¢ vous engager au sein d‚Äôune entreprise engag√©e : nous rejoindre, c‚Äôest faire partie d‚Äôun groupe responsable qui agit en entreprise citoyenne en √©tant mobilis√© autour de 4 axes (sant√©, aidants, √©ducation et environnement) avec un impact soci√©tal positif et r√©el. APRIL a obtenu la m√©daille d‚Äôargent EcoVadis pour la 2√®me ann√©e cons√©cutive V√©ritable industrie de la donn√©e, rejoignez le monde de
l‚Äôassurance et mettez votre expertise au service de la valorisation de notre
patrimoine informationnel ! Votre objectif :
√©clairer et objectiver les prises de d√©cisions des diff√©rentes parties
prenantes de l'entreprise. Et si √™tre ¬´ DATA Analytics Engineer ¬ª chez APRIL vous permettait ‚Ä¶ de choisir un m√©tier dont vous pourrez √™tre fier : ¬´accompagner et prot√©ger √† chaque moment qui compte, simplement¬ª telle est la mission et la raison d‚Äô√™tre partag√©e par l‚Äôensemble de nos collaborateurs, de d√©velopper votre expertise dans un environnement en pleine transformation, au carrefour de l‚Äôinnovation et de l‚Äôexp√©rience client : notre ambition √† horizon 2023, √™tre un acteur digital, omnicanal et agile, champion de l'exp√©rience client, de vous engager au sein d'une entreprise engag√©e : nous rejoindre, c‚Äôest faire partie d‚Äôun Groupe responsable qui agit en entreprise citoyenne en √©tant mobilis√© autour de 4 axes (sant√©, aidants, √©ducation et environnement) avec un impact soci√©tal positif et r√©el. Nous nous engageons √† promouvoir des emplois respectant la diversit√© et la diff√©rence, ouverts √† chacun. VOS FUTURES MISSIONS : Gestion des donn√©es et support √† la d√©cision Participer aux ateliers d'expression des besoins internes m√©tiers comprendre leurs probl√©matiques et les traduire de mani√®re analytique, Extraire les donn√©es n√©cessaires √† l'analyse, Analyser les donn√©es (mod√®les et tests statistiques) Restituer les r√©sultats des analyses sous forme de tableaux de bord Echanger sur les r√©sultats et les solutions avec les √©quipes m√©tiers, Participer au contr√¥le de la qualit√© des donn√©es tout au long de leurs traitements Veille et d√©veloppement de l'activit√© Contribuer √† la promotion de la culture data au sein de l'entreprise, Assurer une veille technologique sur les outils d'analyse de la donn√©e. Cette opportunit√© est √† pourvoir dans le cadre d'une cr√©ation de poste Directement rattach√©.e √† Samuel , Chief Data Officer , vous rejoindrez l'√©quipe DIAG (Data Innovation & Analytics group) bas√©e √† Lyon. D√®s votre arriv√©e, vous b√©n√©ficierez d'un parcours d'int√©gration pour favoriser votre prise de poste. Vous disposez au minimum d'un Bac +3en statistique et traitement de l'information ou Datamining ou √©conom√©trie ou informatique d√©cisionnelle . NOTRE COLL√àGUE ID√âAL : ¬∑Est curieux et passionn√© : Il fait grandir son √©quipe en partageant son savoir et sa veille ¬∑Est autonome et proactif : Il challenge l‚Äôexistant et est force de proposition pour am√©liorer les produits logiciels et les pratiques. ¬∑Travaille en √©quipe agile : Il est orient√© cr√©ation de valeur et est soucieux de la pertinence et de la qualit√© des produits d√©livr√©s. Vous pourrez √©galement mettre √† profit : vos comp√©tences techniques : langages de programmation (Python, R, SQL), cr√©ation d'applications data (Dataiku, Streanlit), Base de donn√©es (Snowflake, SQL Server, Mongo), Maitrise de l'anglais. vos comp√©tences transverses : Orientation client, Capacit√© d'analyse et esprit critique, travail collaboratif Cette opportunit√© est faite pour vous ? N'attendez plus pour postuler en nous adressant votre CV accompagn√© de quelques lignes sur votre projet professionnel et ce qui pourrait vous √©panouir aujourd'hui. Ce sera la premi√®re √©tape de notre processus de recrutement. Si vous n‚Äô√™tes pas s√ªr(e) que cette offre soit LA bonne, d‚Äôautres postes sont √† pourvoir , alors n‚Äôh√©sitez pas √† consulter notre site carri√®re et/ou notre page Linkedin !","APRIL, a leading wholesale insurance brokerage firm in France, is seeking a Data Analytics Engineer to join its Data Innovation and Analytics group in Lyon. The ideal candidate should have a minimum of a bachelor's degree in statistics, data mining, econometrics, or decision-making informatics. The job responsibilities include extracting and analyzing data, ensuring data quality control, participating in technology watch activities, contributing to increasing data culture, and promoting the company's corporate social responsibility initiatives. The candidate should be curious, passionate, autonomous, proactive, and capable of working in an agile team-oriented environment. Technical skills required include knowledge of programming languages (Python, R, SQL), data application design (Dataiku, Streamlit), database management (Snowflake, SQL Server, Mongo), and proficiency in English.",Bac +2,> 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
135,39848,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-confirme-h-f_lyon,Data Engineer  Confirm√©,ASI,"{UNIX,GitHub,Cassandra,Elasticsearch,Docker,Azure,Microsoft,GitLab,SAP,MySql,Kafka,Linux,NoSQL,SAS,Jenkins,Kubernetes,AWS,HBase,Teradata,Java,Hadoop,SQL,Javascript,Scala,Redshift,Spark,GCP,Python}",T√©l√©travail partiel possible,Lyon,"IT / Digital, Transformation, Big Data",CDI,2022-11-29,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Et si vous d√©veloppiez votre exp√©rience Data avec ASI ? Vous avez un parcours professionnel sur l‚Äôensemble de la chaine de traitement de la data ou bien vous venez du monde du d√©veloppement d‚Äôapplication/web avec une app√©tence particuli√®re √† l‚Äôexploitation de la donn√©e ‚Ä¶ N‚Äôattendez plus Rejoignez une √©quipe en plein d√©veloppement et participez √† l'enrichissement de notre expertise de la DATA En tant que Data Engineer , vous intervenez pour nos principaux clients en expertise ou sur des projets √† fort enjeux : - Vous apporterez une expertise en Big Data , - Vous serez amen√© √† travailler avec des syst√®mes de bases de donn√©es, - Vous concevez des plateformes permettant de traiter des volumes importants de donn√©es, des API et des outils pour les process ETL , - Vous faites de la mod√©lisation de donn√©es, - Vous veillez √† la s√©curisation des pipelines de donn√©es, - Vous r√©alisez une veille technologique constante. Leader technique, vous pourrez √™tre amen√© √† encadrer techniquement et √† coacher une √©quipe de d√©veloppement. Le poste est √† pourvoir d√®s que possible ! A comp√©tences √©gales, ce poste est ouvert aux personnes en situation de handicap. Qui √™tes-vous ? Cr√©ateur de syst√®mes, vous √™tes celui qui d√©veloppe, teste, met en place des architectures data. Vous cr√©ez des bases de donn√©es, g√©rez des gros volumes et organisez les flux de donn√©es entre les sources et les bases de stockage. Passionn√©(e) par la technologie et ses diff√©rents cas d'usage, vous disposez de plusieurs exp√©riences significatives. Comp√©tences cl√©s du Data Engineer : - Ma√Ætrise des langages structur√©s : Scala, Java, Javascript, Python, - Ma√Ætrise de divers syst√®mes d‚Äôexploitation : UNIX, Linux, Windows, - Connaissances en solutions de bases de donn√©es : SQL, MySql, Teradata, Microsoft SQL Server, SAS Base, SAP Hana, - Connaissances des syst√®mes NoSQL : Elasticsearch, HBase, Cassandra, Redshift - Forte expertise le stockage de donn√©es et les outils ETL, - Ma√Ætrise des technologies du Big Data permettant le traitement et la manipulation de donn√©es (Hadoop, Spark, Kafka‚Ä¶), - Outils DevOps, int√©gration et d√©ploiement continu : Jenkins, Ansible, GitHub, GitLab, cr√©ation de CI/CD, Docker, Kubernetes‚Ä¶ - √ätre √† l‚Äôaise dans des environnements cloud : Azure, AWS, GCP, - La maitrise de l‚Äôanglais est un plus. Le profil aura une exp√©rience sup√©rieure √† 2 ans sur ce type d'environnement. Qualit√©s du Data Engineer attendues : - Sens de la qualit√©, - R√©activit√©, - Esprit analytique et de synth√®se, - Esprit d‚Äô√©quipe et excellent relationnel. Curieux(se) et dispos√©(e) √† √©largir votre champ de comp√©tences √† de nouvelles technologies, vous faites preuve de rigueur et √™tes force de proposition sur l'am√©lioration des pratiques et les sujets √† √©tudier. Vous souhaitez rejoindre une √©quipe dynamique ? Rejoignez-nous","ASI, a digital expertise firm, is seeking a Data Engineer with expertise in Big Data, databases, ETL, data modeling, and data security. The successful candidate should have experience with programming languages such as Scala, Java, Javascript, and Python, as well as operating systems such as UNIX, Linux, and Windows. Experience in cloud environments, DevOps, continuous integration and deployment, and Big Data technologies such as Hadoop, Spark, Kafka, Elasticsearch, HBase, Cassandra, and Redshift are required. The position requires at least two years of experience, analytical and synthetic thinking, and teamwork skills.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
134,39691,https://www.welcometothejungle.com/fr/companies/efounders/jobs/backend-data-engineer-delteer_paris,Backend Data Engineer @Delteer,eFounders,"{React,go,DynamoDB,ElasticSearch,Django,Typescript,Gitlab,PostgreSQL,AWS,Lambda,Elasticsearch,Sentry,Docker,Datadog,NoSQL,Python}",T√©l√©travail partiel possible,"9, Rue Ambroise Thomas, Paris, 75009","Incubateur / Acc√©l√©rateur, Accompagnement d'entreprises",CDI,2022-11-29,"About eFounders Together with entrepreneurs, we turn unique ideas into successful companies. We build businesses that create the tools of tomorrow and inspire new ways of working , in short, we build the future of work! Startup studio eFounders was the first to pioneer the model in 2011 and has since launched over 32 companies (7 of them have made exits) with $700M in funding and now reaching a valuation of over $3 billion - including unicorns Aircall & Spendesk. Our companies : Front ‚Ä¢ Mailjet ‚Ä¢ Aircall ‚Ä¢ Spendesk ‚Ä¢ Forest ‚Ä¢ Upflow ‚Ä¢ Collective ‚Ä¢ Numeral ‚Ä¢ and +28 other startups and many more to come üöÄ üëã Who we are We‚Äôre reinventing the old-shool loyalty programs of brands ! Today‚Äôs consumers have changed. They support brands which are aligned with their identity & their values. They want to be contributors, to feel part of a community. But brands are unequipped to federate their community in such a way. That‚Äôs why we‚Äôve built Delteer. Delteer is the new way for brands to engage their customers and turn them into active stakeholders. With our mobile app, brands can offer engaging activities to their customers, and reward them for their participation. It‚Äôs a win-win for brands and consumers : consumers get a more engaging & rewarding experience from their favorite brands, and brands turn their consumers into loyal advocates ! Things are moving fast ! We just closed a Pre-Seed round and joined eFounders Web3 startup studio, 3Founders. We‚Äôre looking for motivated and talented people to join the adventure! The Team Delteer was co-founded by two brothers: Pierre , CEO - ex Project Leader @ Boston Consulting Group (6 years) Louis , CTO - ex Lead Data Scientist @ Mazars (4 years) üíº What you‚Äôll do We are looking for a Backend Data Engineer. This is a unique opportunity to join the latest eFounders project as one of the first Engineer and have a huge impact on the product and technical stack. You will work closely with Louis , our CTO, and Delteer‚Äôs Engineering team to build a world class data pipeline. Responsibilities: Contribute to design, implementation and documentation of the Delteer‚Äôs core data pipeline Work closely with the founders and product team to shape data pipeline new components to feed future application features Leverage open-source and in-house technologies to improve the stack Design indexing schemas to foster query efficiency Keep Delteer‚Äôs technical stack up-to-date with industry standards and technology developments. 3+ years in Data Engineering : experience working with Python (Django is a plus), NoSQL databases (Elasticsearch / Opensearch - DynamoDB) Ownership mentality : you are a doer and have a bias for action, no task is below you. You like to own projects from start to finish Long-term vision : you know how to set best practices to ensure code quality, reusability and maintenance in the long run Entrepreneurial mindset : you thrive in fast-paced environments where you have broad responsibilities. You are ambitious and want to take a part in the development of a world-class product and company Problem solver : you know how to deconstruct complex problems to use appropriate technologies to meet requirements Team player : you perform well in a group and enjoy sharing knowledge with your peers üõ†Ô∏è Technical stack Backend: Python, Django, PostgreSQL, ElasticSearch, OpenSearch, DynamoDB, Thirds party APIs (Discord, etc.) Frontend: React, React Native, Typescript, Chart.js / Detroit.js Infra: AWS Serverless (Lambda, Eventbridge, Fargate - CDK Python), Docker Monitoring: Datadog, Sentry Version control: Gitlab ‚≠ê What we offer! Competitive compensation and equity package Great working environment surrounded by very cool and talented people in the center of Paris (75009) - we are looking for people committed to building a great team, but we are remote flexible ! Challenging work experience building and owning an ambitious product Quality-driven environment A strong product and technical culture *eFounders is committed to creating a diverse environment. All qualified applicants will receive consideration for employment irrespective of gender, origins, identity, background and sexual orientations. We are aware there‚Äôs a long way to go with regards to diversity in our industry, which is why we encourage all applicants- and especially those listed above- to apply to our open positions.*","Delteer, a loyalty scheme start-up that enables¬†brands to engage with customers and turn them into ""active stakeholders"" is looking for a back-end data engineer to join its¬†engineering team in Paris. Founded by the CEO, Pierre, a former project leader at the Boston Consulting Group, and CTO Louis, an ex-lead data scientist at Mazars, Delteer¬†offers¬†mobile clients¬†to allow brands to offer engaging activities, rewards and opportunities to their customers. The¬†startup was created in 2021 and¬†is part of¬†eFounders Web3 start-up studio, 3Founders.
",N,N,N,2,1,0.04154662416233763
129,73476,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-h-f_bordeaux_NEXTO_lwk0NeX,Data engineer,NEXTON,"{Talend,Python,SQL}",T√©l√©travail partiel possible,"Marine Clauzade, Bordeaux","Design, IT / Digital, Digital",CDI,2023-04-22,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, Nexton conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, professionnalisme et performance. Et pour vous ? Notre politique de d√©veloppement des comp√©tences dynamique saura vous s√©duire avec un programme de suivi de carri√®re sur-mesure. NEXTON recrute un DATA Engineer H/F , en CDI , √† Bordeaux ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, NEXTON conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance. Et pour toi ? Notre politique de d√©veloppement des comp√©tences dynamique saura te s√©duire avec un programme de suivi de carri√®re sur-mesure. Le contexte : En tant que Data Engineer, tu es garant de l'acc√®s aux sources de donn√©es, et aux donn√©es, et travailles sur l'ensemble des activit√©s li√©es √† la banque. Les missions : Tu es responsable de : Construire des pipelines scalables de donn√©es structur√©es et non structur√©es D√©finir la strat√©gie des stacks techniques et garantir la CI/CD Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ; Contribuer activement √† notre communaut√© de data engineers. Tu es issu d'une formation sup√©rieure d'ing√©nieur en informatique ou √©quivalent, tu as plus de 3 ans d'exp√©riences en tant que data engineer.Tu as un bon niveau sur SQL et id√©alement sur les ETL (Talend ou √©quivalent) ainsi qu'en programmation sur Python. Tu es rigoureux, avec un esprit analytique et de synth√®se. Enfin, tu aimes travailler en √©quipe. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'ann√©e : - Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'ann√©e - Des moments privil√©gi√©s avec ton manager Pr√™ts √† nous rejoindre ? Rencontrons-nous !",,Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
127,73324,https://www.welcometothejungle.com/fr/companies/opensee/jobs/dataops-engineer-big-data-analytics-fintech-paris_paris,DataOps Engineer - Big Data & Analytics Fintech PARIS,Opensee,"{go,kubernetes,aws,golang,pandas,python,numpy,scale,Unix,AWS,lambda,bash,azure,SQL,docker,Python,Bash,Docker,Kubernetes,linux}",T√©l√©travail partiel possible,"28, Rue de Madrid, Paris, 75008","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"About Opensee Opensee provides instant big data analytics solutions to financial institutions. Our mission is to empower business users to autonomously exploit data at a scale and granularity never seen before in order to optimize risk management, trade execution, regulatory reporting and more. Founded in 2015 by senior banking executives and big data technology experts, Opensee‚Äôs commercial traction exploded in 2020 with deployment in several Tier 1 financial institutions on critical use cases. To sustain that growth, we doubled our headcount that same year and are now expanding in London, NYC and Singapore. What‚Äôs in it for you? Develop expertise in one of the most advanced solution for risk aggregations Work in a dynamic environment where innovation and creativity are highly value Benefit from a wealth of development opportunities as we constantly seek new talents to join us, and support our growth What are you going to do? You will work in the team responsible for all aspects of the client success project. This involves closely working with client‚Äôs internal teams to drive growth and address concerns efficiently: Install our solution in client infrastructure, at the multiple steps of the sales process (POC / Test / Production). Clients could use servers, VM, clouds (aws, azure, gcloud), and you must be able, with the help of the teams and our experience, to adapt to that. Help the client integrate our solution in their ecosystem Ingesting their data (possibly managing an ETL) Integrating our clients (windows, web) with their environment, e.g. for authentication Helping them with our API Help the client use our platform particularly using our python User Defined Function system, similar to AWS lambda. We also have a CLI written in go, to deploy and manage our platform on bare-metal servers and kubernetes (something like aws-cli). Your role will be to improve, expand and stabilize this CLI, that is used by us, and our clients. You will also take part of the Ops part of our infrastructure, that is used for CI/CD/CT and demo. We are also implementing a SaaS and you will work on that too. Keywords: linux, bash , python pandas, ops, devops, database, docker, kubernetes About you Interest: You like to have your hands dirty from systemd to CI/CD pipelines passing by firewalls and ssh tunnels on multiple environments? Come talk to us. Qualities: Great communication and negotiation skills; Autonomy AND Team working ; Creativity, Problem-solving mindset, Proactive Prior experience: Ops / DevOps experience (on-premise or in cloud) a plus. Curriculum: Minimum 2 years Technical skills: Unix systems / Bash / networks Terraform / golang / Docker / Kubernetes Big data / Distributed databases / SQL / Python (numpy, pandas) Scripting / Analyzing / Optimizing in the context of Tera or Peta scale data Testing, Deployment logics, Hardware specifications, Integration Language skills: Fluent in English both written and verbal, French is a plus Working conditions Multiple full-time positions Duration : permanent contract Salary : Competitive, profile based Location : Paris (near Saint-Lazare) How to apply Send us your resume and a brief description of why you are interested in joining us, and we will come back to you very shortly!",,Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
112,34675,https://www.welcometothejungle.com/fr/companies/adevinta-fr/jobs/data-analytics-engineer_barcelona,Data Analytics Engineer,Adevinta,"{Cassandra,Hive,Docker,Azure,Zeppelin,go,Kinesis,Athena,Beam,Databricks,Kafka,Luigi,Presto,Git,NoSQL,Flink,Kubernetes,Akka,Argo,SQL,Jupyter,Scala,Airflow,Redshift,via,Spark,BigQuery,Python,Tableau}",T√©l√©travail partiel possible,Barcelona,"Intelligence artificielle / Machine Learning, Big Data, E-commerce",CDI,2022-08-08,"Adevinta is a global classifieds specialist, with +40 online marketplaces in 14 countries. Through their trusted brands, including leboncoin in France, mobile.de in Germany and 2dehands in The Netherlands, they create perfect matches. They connect house-hunters to new homes, jobseekers to new careers and buyers and sellers to give previously-owned products a new life, all helping to create brighter futures for millions of people. By making these connections, they‚Äôre creating positive change for the world and helping to build a more sustainable future. You will work in the Corporate data Team by providing data products which allow teams, managers and the entire B2B Organisation to access the data easily to solve their analytical needs, and providing high-level analyses and recommendations to help them make data-driven decisions. You will definitely make an analytical impact in Adevinta Spain. Main responsabilities: Lead a Data Analytics Project end-to-end: From detecting opportunities and understanding needs, data capture and transformation, visualisation, analysis and analytical training. Set, prioritise and coordinate implementation of data requirements and data-quality standards. Requirements analysis in systems engineering Understand business needs and produce insightful analyses for internal teams and leaders/managers to make the right decisions. Design, create and evolve data products via programming data pipelines and using models of structured/unstructured raw data. Ensure best experience of data product users through measurement of SLO and satisfaction levels and implementation of learning. Provide real time solutions using modern tools and programming languages. Maintain, develop and orchestrate the pipelines that build curated datasets Ensure that quality standards and data governance are being achieved Develop comprehensive data capture, transformation, and visualizations for self service analytics. Guarantee definitions of dimensions and indicators across the company. Assist colleagues in gaining access to the right data, train them and eliminate the barriers that exist in order to facilitate the analytical autonomy of the teams. Provide accurate data, insights, analysis and forecasts for decision makers and stakeholders Work with the technical team to translate business requirements into detailed technical design Communicate results in a clear and concise manner, with an understanding of data visualization and the importance of drawing accurate conclusions from multiple data sources Coach colleagues and users on how to access the right data helping eliminate barriers for self service and autonomy of the teams. Additional Information At Adevinta Spain, we believe in the power of a fair and equitable benefits policy. And we do everything we can to make it so. Therefore, we pay special attention to all aspects that are key in your day-to-day life: Ever since COVID-19 hit, we've all been working remotely following the health recommendations, but the offices are open and you can go in whenever you'd like with all the necessary health measures in place. Now, we are shaping our new post-COVID-19 working model. It will be based on a hybrid formula that will have a significant remote work component. Every year we engage into benchmarking against the external market in order to create competitive compensation packages. Moreover, we do have plans that allow you to ""flex your gross salary"" in order to purchase benefits such as meal vouchers, commuters card, training and child care. All Adevintans have in common the passion for innovation and technology. You can choose whether to have a Macbook or Dell XPS laptop and you can opt for an Iphone or a Samsung. We subsidize your parking up to a maximum of 90‚Ç¨/ month. Your well-being is our priority. We cover fully for your medical insurance and we allow family members to be added to the policy for a discounted price. We have a doctor in our facilities and we do offer extra wellness initiatives such as Yoga at the office in Madrid and physiotherapy in Barcelona. Do you like going to the gym? We sponsor 70% of the monthly fee of your chosen centre/ studio and we have agreements with both Andjoy and McFit for discounted membership prices. We enjoy 23 days of paid-time-off a year. In Barcelona offices we offer free breakfast and beveragesü•ê You can choose the daily menu freshly prepared in our canteen. Last but not least, you have 5 extra days to attend conferences and we offer one entrance ticket per year Must: 3 years experience in a similar position. Nice to have a 3 years experience in a similar position Knowledge of Tableau. Storytelling skills Extensive experience with SQL Extensive experience with Python and Pyspark. Clouds Azure and Amazon Experience working with data processing frameworks like Spark, Flink, Kafka Streams or Beam. Familiarity developing data pipelines with scheduling tools like: Airflow, Luigi, Cloud Componer, Argo. Proficiency in building well-tested code. Querying tools: Hive, Athena, Presto, BigQuery‚Ä¶ Good development practices (SOLID, testing) and data care (rigor for data quality). Self-starter and detail-oriented . You can complete projects with minimal supervision Excellent communication skills and ability to interact with multidisciplinary teams Intermediate knowledge of Git Experience with Agile methodologies Fluent in English Nice to have knowledge: Experience with Docker and container orchestration tools like Kubernetes, ECS, Docker Swarm. Experience with streaming processing tools like Kafka / Kinesis, Structured Streaming, Akka Streams, Flink, Spark Streaming‚Ä¶ Notebooks: Jupyter, Zeppelin, Databricks, , Scala NoSQL databases: Redshift, Cassandra Fluent in English","Adevinta is hiring a Senior Data Analytics Project Leader in Spain to lead end-to-end data analytics projects, set and coordinate data requirements and quality standards, produce insightful analyses for internal teams and leaders, and design, create and evolve data products via programming data pipelines. The ideal candidate will have experience with Tableau, SQL, Python, Pyspark, and cloud services like Azure and Amazon, as well as good development and data quality practices. Fluency in English is required. Adevinta offers a competitive compensation package, remote work options, medical insurance, wellness initiatives, gym subsidies, and more.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
124,57139,https://www.welcometothejungle.com/fr/companies/neolynk/jobs/data-engineer-3-ans-d-experiences-h-f_paris,Data Engineer 3 ans d'exp√©riences,NeoLynk,"{Python,SQL,Spark,AWS}",T√©l√©travail partiel possible,"91 rue du faubourg saint honore, Paris, 75008",IT / Digital,CDI,2023-03-26,"Une mani√®re innovante de r√©pondre aux challenges digitaux de nos clients, une mani√®re diff√©rente de valoriser nos consultants. Depuis plus de 6 ans, NeoLynk √©volue dans le domaine de l‚ÄôOpen Source, passionn√©ment ! Au travers de notre Tribu JVM et de nos projets innovants, nous conduisons nos consultants vers une maturit√© technologique toujours plus forte ! Passionn√©(e) par le Big Data ? Int√®gre notre Tribu et participe √† son √©volution, le tout en contribuant √† des projets clients challengeants au sein d‚Äô√©quipes exp√©riment√©es ! Quelques clients : Rakuten, Soci√©t√© G√©n√©rale, Saint Gobain, Kering ‚Ä¶ Vous √©voluez au quotidien au sein de la tribe transverse Data Tools and Services, constitu√©e de 7 p√¥les : Data Science, Data Engineering, BI/DATAVIZ, Data Analysis, Product Analysis, Data Quality, Data discovery. Vous aurez le soutien de l‚Äôentreprise qui a une ambition de r√©volutionner l‚Äôusage et le business model gr√¢ce aux nouvelles technologies. Vous travaillerez conjointement avec l‚Äô√©quipe Data Science et l‚Äô√©quipe data engineering. Vos missions: Vous travaillerez sous la responsabilit√© conjointe des deux managers Data Engineer & Data Science. Vous participerez √† la mise en place d‚Äôun important chantier data au sein du client ‚Äúla Data Plateform (DP)‚Äù qui permettra la centralisation, la creation et la mise √† disposition de segments d‚Äôutilisateurs. Cette DP permettra d‚Äôalimenter diff√©rents use cases produit du client (Pub, CRM,Premium, Service Client, ‚Ä¶). Vous serez en charge d‚Äôapporter votre expertise et votre support sur 3 principaux composants de cette DP : ÔÉò La librairie de cr√©ation de segment existante : qui permet l‚Äôint√©gration et la gestion des tables de r√©f√©rencement et d‚Äôarchivage de segments. Des modifications seront apport√©es √† cette librairie pour s‚Äôadapter √† la DP ÔÉò La table de r√©f√©rencement des segments : Changement de la table permettant de r√©pertorier les segments disponibles dans la DP. ÔÉò Les notebooks permettant de cr√©er les segments existants : o Refactoring de ces notebooks en tenant compte des nouveaux changements de la librairie et des nouvelles bases de donn√©es (Xiti) ‚Ä¢ Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 3 ans dans le domaine de la data ‚Ä¢ Une exp√©rience dans des environnements cloud avec des connaissances en Spark et AWS est tr√®s souhait√©e. ‚Ä¢ Une bonne maitrise du langage Python et du SQL. ‚Ä¢ Capacit√© de synth√®se, de vulgarisation de communication. ‚Ä¢ √ätre force de proposition. ‚Ä¢ Sens du partage et esprit d‚Äô√©quipe. ‚Ä¢ Prise d‚Äôinitiative. Entretien t√©l√©phonique Test technique Entretien physique","NeoLynk, an Open Source technology company, seeks a Big Data expert to join their transverse Data Tools and Services tribe. The successful candidate will work closely with the Data Science and Data Engineering teams to support the Data Platform (DP) project for a client by bringing expertise on three key components. A minimum of three years of data experience and knowledge of cloud environments, Spark, AWS, Python, and SQL is required, with good communication skills, team spirit, and initiative.",Bac +5 / Master,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
122,57086,https://www.welcometothejungle.com/fr/companies/ekkiden/jobs/data-engineer,Data Engineer,Ekkiden Technologies,"{GCP,R,Python,Git}",T√©l√©travail partiel possible,Lille,"IT / Digital, Transformation",CDI,2023-03-26,"The consulting world needs a new, more human, more modern, and more agile actor. This is the ambition that gave birth to Ekkiden in 2019. Today, this international consulting group is challenging traditions and bringing a large dose of innovation to its sector. Through its ecosystem of passionate, enthusiastic, and committed consultants, Ekkiden leads organizational, operational, and technological transformation projects in three areas, IT/Digital, Industry/R&D and Pharma/Biotech, mainly with large accounts and SMEs. Vous serez en charge de l‚Äôalimentation du datalake par des donn√©es Vous r√©aliserez les calculs d‚Äôagr√©gats Vous participerez √† la conception g√©n√©rale et √† l‚Äôanalyse technique Vous d√©velopperez des programmes et les tests unitaires associ√©s Vous participerez √† la recette fonctionnelle et √† la pr√©paration de la mise en production Vous serez en charge du support aux utilisateurs Vous r√©aliserez des compte rendu des avanc√©es et des points d‚Äôalerte Vous participerez √† la migration du cluster bigdata on premise vers GCP Vous √™tes issu d‚Äôune formation Bac+ 5 en informatique Vous justifiez de bonnes connaissances sur GCP Vous avez id√©alement une exp√©rience concr√®te sur Python et son framework Pyspark Des connaissance sur Git et Jira sont un v√©ritable plus Vous √™tes curieux, ouvert d‚Äôesprit et poss√©dez un un bon esprit d‚Äôinvestigation et d‚Äôanalyse Premier √©change : t√©l√©phonique avec un membre de l‚Äô√©quipe recrutement Deuxi√®me √©change : visio avec un Business Manager Troisi√®me √©change (optionnel) : visio avec le Directeur commercial du p√©rim√®tre","Ekkiden, an international consulting group, seeks a data engineer to feed data into the datalake, perform aggregate calculations, participate in technical analysis and design, develop programs and associated unit tests, participate in functional testing, support users, and participate in the migration of the big data cluster to GCP. The ideal candidate should have a degree in computer science, good knowledge of GCP, practical experience in Python and its framework Pyspark, knowledge of Git and Jira, curiosity, an open mind, and analytical skills. The hiring process includes a phone interview, a video conference with a business manager, and an optional video conference with the commercial director of the perimeter.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
120,73546,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/front-software-engineer-f-m-d-data-observability_croix,Front Software Engineer  - Data Observability,Decathlon Digital,"{NodeJS,Github,AWS,GraphQL,via,Kafka,Javascript,Docker,Kubernetes,React,Git,GitHub,GCP,TypeScript}",T√©l√©travail partiel possible,"4 Rue du Professeur Langevin, Croix, 59170","Grande distribution, Sport, E-commerce",CDI,2023-04-22,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub) et Lille (HQ) rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES DATA DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour accompagner cette transformation digitale internationale de Decathlon, les √©quipes Data √©voluent et mettent au c≈ìur de leurs enjeux : La qualit√© et l‚Äôaccessibilit√© de la donn√©e La scalabilit√© des processus associ√©s au cycle de vie de la donn√©e (ingest, store, transform, expose) L‚Äô√©lasticit√© des infrastructures et des services Int√©gr√© au c≈ìur de la data platform votre r√¥le sera de servir ces deux enjeux majeurs Garantir l'acc√®s et l'usage de la donn√©e pour tous nos utilisateurs data en d√©livrant outils et guidelines La scalabilit√© REJOINS L'√âQUIPE DATA OBSERVABILITY En fournissant la capacit√© √† identifier, diagnostiquer, tracer et r√©soudre les √©v√®nements de transformation de la donn√©e dans le SI de Decathlon, nous donnons le pouvoir aux √©quipes data de fiabiliser leurs produits et d'en mesurer la qualit√©. En tant que Software Engineer Frontend tu auras pour mission de cr√©er les meilleures exp√©riences possibles et unifi√©es via des interfaces pour nos √©quipes internes. Dans le cadre de l‚Äôouverture d‚Äôun poste en CDI, nous recrutons un-e Software Engineer, bas√©-e, au choix √† Paris o√π √† Lille. P√©rim√®tre d‚Äôaction Tu prendras part de bout en bout au d√©veloppement d'un portail complet et de nouvelles fonctionnalit√©s (React/ Svelte) en lien avec le Product Manager. Tu √©volueras √©galement au contact des autres co√©quipi√®res et co√©quipiers : l‚Äôam√©lioration continue et l‚Äôautonomie sont particuli√®rement valoris√©es chez Decathlon ! Ton exigence technique (qualit√© du code, pratiques, patterns, outils‚Ä¶) et tes qualit√©s relationnelles permettent de diffuser les bonnes pratiques dans l‚Äô√©quipe, en collaboration avec le Tech Lead. TES RESPONSABILITES Construire une plateforme front pour rendre l'observabilit√© accessible √† tous intervenir sur toute la cha√Æne de livraison des fonctionnalit√©s : conception, impl√©mentation, tests, documentation technique, exemples, API, SDK‚Ä¶ √™tre moteur dans le processus d'int√©gration et de livraison continue se montrer force de proposition dans les choix techniques mais aussi aussi dans nos moyens de collaboration Le p√©rim√®tre technique : HTML / CSS : accessibilit√©, standards W3C, web performance‚Ä¶ Svelte / Vue JS / ReactJS / GraphQL / Material UI Javascript / TypeScript, NodeJS Git (Github Actions) Tests unitaires et fonctionnels Outils collaboratifs : Confluence, Slack, Jira‚Ä¶ Infrastructure : AWS, Kafka, Docker, Kubernetes‚Ä¶ CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience (minimum 3-5 ans) du d√©veloppement web frontend (Svelte / Vue JS / React), des architectures micro services / micro frontend, et de d√©ploiement continu et tu as d√©j√† effectu√© de l'UX design Tu as un bon niveau d‚Äôanglais qui te permet de communiquer avec nos clients et partenaires (60 pays Decathlon) ; Tu as un √©tat d'esprit agile tourn√© vers l'am√©lioration continue, l'intelligence collective, l‚Äôentraide et la solidarit√© Tu aimes travailler dans un environnement collaboratif (Pair Prog, Code Review, et √©cosyst√®me GitHub) Tu as une passion de la technique que tu aimes partager Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style relationnel et la vie en √©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon √† Lille o√π √† Paris (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme d'1 ou 2 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Digital, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©s notamment √† Paris, Lille et Amsterdam. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .",,Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
119,73511,https://www.welcometothejungle.com/fr/companies/voyage-prive/jobs/data-engineer-f-h_aix-en-provence_VP_5y1d2xD,Data Engineer,Voyage Priv√©,"{GitLab,BigQuery,Elasticsearch,Python,Scala,SQL,scale,Hadoop,Spark,Tableau,Docker,NoSQL,GitHub,Airflow,YARN,Dataiku,moderne}",T√©l√©travail partiel possible,"330 Rue Pascal Duverger, Aix-En-Provence, 13090","Luxe, Loisirs, E-commerce",CDI,2023-04-22,"Aventure entrepreneuriale lanc√©e en France en 2004, Voyage Priv√© est le leader europ√©en de la vente √©ph√©m√®re de voyage en ligne. Ils font voyager 56 millions de membre en d√©nichant partout dans le monde des produits haut de gamme n√©goci√©s au meilleur prix. Pr√©sents sur 9 march√©s (France, Allemagne, Espagne, Italie, Angleterre, Belgique, Suisse, Pays-Bas, Autriche) et ne comptent pas s‚Äôarr√™ter l√† ! Le groupe a connu une croissance dynamique √† deux chiffres depuis sa cr√©ation avant d‚Äô√™tre ralenti en 2020 par la crise covid. Nous poursuivons aujourd‚Äôhui notre phase de scale amorc√©e en 2020. Ils se pr√©parent pour un nouveau cycle de croissance tr√®s soutenue et recrutent les talents qui participeront √† la reprise explosive du voyage ! Voyage Priv√©, c‚Äôest aussi un groupe qui a l‚Äôambition de faire √©clore une nouvelle fa√ßon d‚Äôentreprendre, conciliant r√©ussite √©conomique et initiatives sociales, le tout port√© par le dynamisme et l‚Äôengagement de ses collaborateurs. Leur Campus rassemble salari√©s, sportifs de haut niveau et √©ducateurs. Chacun apprenant des autres pour d√©velopper le meilleur de lui-m√™me et impacter positivement. Pourquoi nous rejoindre ? L'univers du voyage est un terrain de jeu magique en termes de data : donn√©es clients, marketing, fournisseurs, navigation, CRM, service client... Notre activit√© g√©n√®re un important volume de donn√©es (+80 To) dont l'analyse a un impact direct sur l'exp√©rience utilisateur, la conversion, les relations fournisseurs. En tant que Data Engineer, vous accompagnez le d√©ploiement de notre architecture vers le cloud et les projets (data warehouse, CI/CD, h√©bergement des mod√®les de machine learning) Vous participerez √† la consolidation d'une plateforme robuste, performante, aux co√ªts optimis√©s, facile d‚Äôexploitation et offrant la capacit√© √† l‚Äôensemble de l‚Äô√©quipe data de travailler dans les meilleures conditions (reporting, ad-hoc analysis, A/B tests, industrialisation de mod√®les de data science) Vos missions D√©veloppement de l‚Äôarchitecture data Challenger l‚Äôarchitecture actuelle et l‚Äôoptimiser pour en faciliter l‚Äôexploitation Int√©grer de nouvelles donn√©es par les √©quipes de d√©veloppement (back-end et front-end, APIs externes) Am√©liorer le mod√®le de donn√©es en collaboration √©troite avec les ing√©nieurs BI Proposer et mettre en place des am√©liorations dans le processus de d√©veloppement (CI/CD, monitoring, optimisation des co√ªts, best practices, etc.) Cr√©er l‚Äôarchitecture adapt√©e √† l‚Äôindustrialisation d‚Äôalgorithme de machine learning Maintenance de la plateforme Maintenir un pipeline de traitement capable de traiter un volume important de donn√©es tout en garantissant leur s√©curit√© Monitorer et am√©liorer les m√©triques du data pipeline (disponibilit√©, taux d‚Äôerreur, latency, etc.) Prendre en compte le contexte r√©glementaire de r√©colte et d‚Äôacc√®s aux donn√©es (RGPD) Notre environnement technique : Tableau, Dataiku DSS, BigQuery, Elasticsearch, ETL interne, Apache Spark on YARN, Google Cloud Storage, Google Cloud Dataproc, Google Cloud Pub/Sub D√©veloppement en Python et Scala avec Docker, GitHub/GitLab Vous allez prendre plaisir √† nous rejoindre ‚Ä¶ S‚Äôimpliquer pleinement dans l‚Äôaventure entrepreneuriale Voyage Priv√© et devenir acteur de la r√©ussite du Groupe. Vivre dans le Sud de la France dans un environnement naturel, √©conomique et culturel exceptionnel et dans un campus moderne, num√©rique et √©co-responsable. D√©couvrir un √©cosyst√®me unique et porteur de sens, cr√©ateur de ponts entre des univers souvent √©loign√©s : l‚Äô√©conomique, le sportif, l‚Äôacad√©mique, le social et participer √† l‚Äôun des projets Vision (Ecole des XV - Provence Rugby - VP Green- Les Tremplins ‚Äì Chez Pierre). Faire du sport sur le campus, assister aux matchs de rugby du Provence-Rugby ou danser sur les sons du Dalida Institute ! D√©couvrir le monde en b√©n√©ficiant de remises compl√©mentaires sur vos √©vasions Voyage Priv√© pour vous, votre famille et vos amis. Vivre au rythme des diff√©rents temps forts Business & fun de Voyage-Priv√© (Company Breaks, Carnaval, Convention annuelle ‚Ä¶) et participer √† des meet-up et des talks √™tre en permanence ouvert au monde qui nous entoure ‚Ä¶ Nous sommes faits pour nous rencontrer et grandir ensemble si ‚Ä¶. Vous √™tes de formation bac+5 √©cole d'ing√©nieur ou universitaire, vous avez une exp√©rience d‚Äôau moins 4 ans en tant que data ing√©nieur Vous ma√Ætrisez SQL, les concepts et le d√©ploiement des bases de donn√©es relationnelles et NoSQL ainsi que le langage Python Vous √™tes habitu√© √† travailler dans un environnement dynamique et capable de prioriser vos projets Vous avez d√©j√† con√ßu, d√©ploy√© et maintenu une architecture complexe en production : sp√©cifications, conception, monitoring, alerting, gestion des incidents, recherche des root causes Vous avez d√©velopp√© une expertise dans au moins une des technologies big data (Hadoop, process ETL, Spark, Airflow, etc.) Une exp√©rience sur Google Cloud Platform serait un plus",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
118,73400,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-scientist-data-engineer,Data scientist / Data engineer,MP DATA,"{Postgres,GCS,Python,Azure,Django,SQL,Kafka,Spark,MongoDB,AWS,Git,S3,Snowflake,Java,GCP}",T√©l√©travail partiel possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-04-22,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leur donn√©es. Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement. Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais. MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences. Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort. Le dataLab entit√© de la Direction Technique a pour mission de d√©velopper des solutions d‚ÄôIntelligence Artificielle (IA) dans le groupe, sur toute la chaine de valeur. Le dataLab poss√®de une expertise en data science et dans les technologies d‚ÄôIA (Jumeaux, num√©riques, Machine Learning, Computer Vision ou encore de Speech to Text‚Ä¶.). Ses travaux sont d√©ploy√©s √† la demande des directions m√©tiers dans le but d‚Äôapporter une valeur ajout√©e √† l‚Äôentreprise. Ing√©nieur d‚Äôune grande √©cole (Centrale, Mines, Supaero, Supelec, ‚Ä¶), vous avez des connaissances en mod√©lisation et machine learning (deep learning, random forest, svm‚Ä¶) acquises lors de votre scolarit√© ou de vos exp√©riences pass√©es (stage ou c√©sure) vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite √† votre cursus ing√©nieur ou vos exp√©riences professionnelles, vous disposez de connaissances m√©tiers dans les domaines de l‚Äôa√©ronautique, √©nergie, transport, etc‚Ä¶ Vous √™tes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacit√© √† √™tre force de proposition. Vous √™tes int√©ress√©s pour vous d√©passer en data science & data engineering et vous avez des premi√®res exp√©riences dans ce domaine, comme par exemple : C/C++ / Java / Rust Spark Kafka Cloud : AWS / GCP / Azure Technologies de stockage : Snowflake / S3 / GCS / Azure Blob Django / Flask Git SQL : Postgres / MongoDB CI/CD.",,Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
224,57008,https://www.welcometothejungle.com/fr/companies/deepreach/jobs/data-engineer_paris,Data Engineer,DeepReach,"{count,JavaScript,SQL,Python}",T√©l√©travail partiel possible,"40, Rue du Colis√©e, Paris, 75008","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-03-26,"Who are we ? 1DeepReach is the leading AI SaaS-based multi-channel platform disrupting digital local advertising. Our company was born in France in 2018 to bring brands closer to their local consumers. At a time when all brands are refining their local strategies, DeepReach technology increases agencies‚Äô capacity to better address local ads. 1We shape another approach of digital advertising: more local, more multi-channel, more business-driven, thus more efficient, with the power of data. Boosted by +11M‚Ç¨ fundraising, we are proud to count +55 Adtech talents working across France, +250 clients of all sizes from international groups (WPP, Publicis‚Ä¶) to local agencies and +20 000 local campaigns operated through our platform. Our success story in France was built on a continuous search of innovation, excellence, and customer-centric approach, fueled by a teamwork and entrepreneurial mindset. Aiming the ambition of becoming a worldwide digital local platform leader at its very beginning, DeepReach is actively undertaking its global expansion in Europe in 2022, rolling out its presence and business in several countries such as UK, Germany, Spain, Italy, Belgium, and Switzerland. What you will be doing As a Data Engineer you will be working alongside the Data team liaising with various stakeholders internally and externally, handling large quantities of data from multiple sources, working on multiple tasks & projects simultaneously and dealing with any queries. The focus on your work will be to find hidden patterns and correlations in raw data, build prototypes and find data-driven ways to improve our offer. üöÄAnalyze and organize raw data üöÄEvaluate business needs and objectives üöÄInterpret trends and patterns üöÄConduct complex data analysis and report on results üöÄPrepare data for prescriptive and predictive modelling üöÄBuild algorithms and prototypes üöÄCombine raw information from different sources üöÄExplore ways to enhance data quality and reliability üöÄDevelop analytical tools and programs Your profile üöÄPrevious experience as a data engineer or in a similar role (2-5 years) üöÄTechnical expertise with data models, data mining, and segmentation techniques üöÄKnowledge of programming languages (e.g. Python, JavaScript) üöÄHands-on experience with SQL database design üöÄGreat numerical and analytical skills üöÄDegree in Computer Science, IT, or similar field üöÄPrevious experience in AdTech or Digital Marketing is a big plus üöÄPrevious experience with GIS and/or time series data is a big plus Interview process HR screening Interview with our Data Product Manager Interview with our VP Product Interview with our CTO An informal conversation with our data developers to get to know the team and the tech stack","1DeepReach, an AI SaaS-based multi-channel platform disrupting digital local advertising, is seeking a Data Engineer with previous experience and technical expertise in data models, data mining, and segmentation techniques. The successful candidate will analyze and organize raw data, evaluate business needs and objectives, interpret trends and patterns, conduct complex data analysis, build algorithms and prototypes, and develop analytical tools and programs. Previous experience in AdTech or Digital Marketing is a plus. The company is expanding globally and is looking for someone to join its team of 55 Adtech talents working across France. The interview process includes HR screening, interviews with Data Product Manager, VP Product, CTO, and an informal conversation with the data developers.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
115,73196,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-h-f_bezons_ATOS_0Kw7a1D,Data engineer confirm√©,Atos,"{SnowFlake,Kafka,Dataflow,Hive,Redshift,Kibana,CouchBase,HDFS,Beam,BigQuery,Spark,Redis,Logstash,ElasticSearch,MongoDB,Java,Python,Cassandra,Teradata,Hadoop,Docker,Kubernetes,NoSQL}",T√©l√©travail partiel possible,"80 quai Voltaire, Bezons, 95870",IT / Digital,CDI,2023-04-22,"Atos est un leader international de la transformation digitale avec plus de 110 000 collaborateurs dans 73 pays et un chiffre d‚Äôaffaires annuel de plus de 11 milliards d‚Äôeuros. Num√©ro un europ√©en du Cloud, de la cybers√©curit√© et des supercalculateurs, le groupe fournit des solutions int√©gr√©es de Cloud Hybride Orchestr√©, Big Data, Applications M√©tiers et Environnement de Travail Connect√©. Partenaire informatique mondial des Jeux Olympiques et Paralympiques, le Groupe exerce ses activit√©s sous les marques Atos, Atos Syntel, et Unify. Atos est une SE (Soci√©t√© Europ√©enne) cot√©e sur Euronext Paris et fait partie de l‚Äôindice CAC 40. La raison d‚Äô√™tre d‚ÄôAtos est de contribuer √† fa√ßonner l‚Äôespace informationnel. Avec ses comp√©tences et ses services, le groupe supporte le d√©veloppement de la connaissance, de l‚Äô√©ducation et de la recherche dans une approche pluriculturelle et contribue au d√©veloppement de l‚Äôexcellence scientifique et technologique. Partout dans le monde, Atos permet √† ses clients et √† ses collaborateurs, et plus g√©n√©ralement au plus grand nombre, de vivre, travailler et progresser durablement et en toute confiance dans l‚Äôespace informationnel. Atos est responsable de la d√©finition, de la conception et de la construction de plateformes et de solutions s√©curis√©es Big Data. Vous interviendrez au sein d‚Äôune √©quipe dynamique d‚Äôexpertise Big Data en forte croissance r√©alisant des activit√©s allant du conseil en architecture et gouvernance de la donn√©e aux aspects Data Ingestion, Data Analytiques et DataScience / IA , en passant par la mise en place, l‚Äôint√©gration, le d√©veloppement et l‚Äôoptimisation de solutions Big Data pour les projets strat√©giques de nos clients. Notre valeur ajout√©e repose sur une forte expertise technique et business de la data renforc√©e par de nombreux partenariats avec les √©diteurs actifs dans les domaines des architectures applicatives distribu√©es et du Big Data & Analytics. Dans le cadre de notre croissance et pour r√©pondre aux nouveaux besoins de nos clients, nous recherchons √† √©toffer nos √©quipes Big Data en recrutant un(e) Data Engineer Exp√©riment√©(e). Description du profil : Expertise en d√©veloppement Python ou Java Spring Boot, Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam, ‚Ä¶, Connaissance des √©cosyst√®mes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana) , MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS, ‚Ä¶ Connaissance des architectures conteneurs : Docker, Kubernetes, ‚Ä¶., La connaissance des services manag√©s BigData de Google Cloud Platform (Dataflow, BigQuery, Pub/Sub, ML Engine,‚Ä¶) est appr√©ci√©e, La connaissance des approches Agile & DevOps est appr√©ci√©e. Nous proposons : Ce domaine technologique √©tant tr√®s dynamique, plus que des connaissances et des comp√©tences techniques, vous devrez d√©montrer une r√©elle envie d‚Äôapprendre, de progresser et de se tenir √† jour sur toutes les technologies et architectures.",,Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
79,56821,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes_EDF_k5RgOpe,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",T√©l√©travail partiel possible,"Tour EDF La D√©fense, Colombes, 92400","Environnement / D√©veloppement durable, Energie",CDI,2023-03-26,"Chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez EDF m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez EDF m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf La DSIN est en charge de d√©velopper le SI et les outils num√©riques de la Direction Commerce pour faire face aux d√©fis que doit affronter EDF dans le cadre de la concurrence accrue du march√© de l'√©nergie et des services. Elle contribue √† la performance des m√©tiers, √† leur √©volution et √† la transformation de la Direction √† travers ses activit√©s SI et Data Science. Au sein de la DSIN, le Centre de Solutions et de Comp√©tences DataScience & IA (CSC DS & IA), a pour mission de r√©aliser les travaux d'analyse et de valorisation des donn√©es de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux m√©tiers du March√© d'Affaires et du March√© des Clients Particuliers pour r√©pondre √† des enjeux vari√©s comme les d√©parts √† la concurrence, la conqu√™te de nouveaux clients, la satisfaction client, la d√©tection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de donn√©es cons√©quentes (~26 millions de clients, B2C+B2B). Afin de r√©pondre √† ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une √©quipe de Data Engineer, et en appui d'une √©quipe de plus de 20 Data Scientists, votre mission consistera √† : - Mettre en place des pipelines de traitements de donn√©es - avec des volumes importants de donn√©es (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de donn√©es distribu√©es (Spark ‚Ä¶) - Extraire massivement des donn√©es (Hadoop - Hive, Oracle - SQL, ‚Ä¶) - vous-m√™me ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de donn√©es (compr√©hension des probl√©matiques Yarn, JVM, tablespace temp‚Ä¶) - Accompagner les Data Scientists dans le maintien et l'√©volution des outils de requ√™tage d√©velopp√©s en interne (dnquery pour requeter Oracle et Hive), extension √† une nouvelle technologie de stockage des donn√©es (PostGre, SQL Server‚Ä¶) - Accompagner les d√©ploiements de mod√®les de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des cha√Ænes r√©currentes de type traitement de la donn√©e ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer √† la construction des strat√©gies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer √† l'√©volution de l'environnement technique des Data Scientists Votre Profil ? - Vous √™tes titulaire d'un Bac +5 (Master, dipl√¥me d'ing√©nieur) dans le domaine informatique, des math√©matiques / statistiques, de la Data Science ou du Big Data - Vous b√©n√©ficiez d'une exp√©rience d'au moins 3 ans en tant que Data Engineer - Vous avez d√©j√† travaill√© dans un contexte de Datascience et automatis√© des traitements de type Datascience - Vous ma√Ætrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez d√©j√† manipul√© des donn√©es stock√©es sous S3 - Vous √™tes √† l'aise avec les outils collaboratifs de d√©veloppement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous b√©n√©ficiez d'une ou plusieurs exp√©riences de travail en mode Agile - Vous √™tes curieux et les projets innovants vous passionnent - Vous √™tes force de proposition et proactif - Vous aimez transmettre et travailler en √©quipe M√©thodologie de travail : Vous collaborerez √©troitement avec les R√©f√©rents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'√©quipe en charge des lacs de donn√©es au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark‚Ä¶). Le poste est situ√© √† Colombes, proche de La D√©fense Ouest, avec une possibilit√© de t√©l√©travail partiel. R√©mun√©ration : Fourchette estimative : entre 50k et 57k‚Ç¨, la r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is seeking a Data Engineer to join its Centre de Solutions et de Comp√©tences DataScience & IA (CSC DS & IA) in Colombes, France. The successful candidate will work closely with the team of Data Engineers, as well as assist and support more than 20 Data Scientists in developing and maintaining internal tools. The candidate should have a Master's or Engineer's degree in computer science, mathematics/statistics, data science or big data, at least three years of experience as a Data Engineer, and expertise in Python, SQL, R, Docker, Airflow, Hadoop, and Git. The position is open to all applicants, and telecommuting is available.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
72,73470,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-engineer_paris_NUMBE_e8AR0gm,Data Engineer,Numberly,"{RabbitMQ,Linux,MySQL,HBase,Kafka,Hive,Cube,Tabular,Scala,HDFS,Airflow,AWS,hadoop,Druid,Spark,SQL,ElasticSearch,MongoDB,Java,Python,ScyllaDB,Hadoop,Docker,Kubernetes,Celery,NoSQL,Git,GCP}",T√©l√©travail partiel possible,"28 rue de Ch√¢teaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Numberly is looking for a Data Engineer to join its dedicated team Data. As a Data Engineer you will: Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MS SQL Server, MongoDB, ScyllaDB). Participate in a huge migration from CRM to CDP (SQL Server to hadoop, relational DB to NoSQL) Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage. Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly. Work alongside Data Analytics, Data Scientists, DevOps, and many other talented techs. Suggest your own technological solutions and try them out (our latest POCs include Apache Druid and Tabular) . Join a great multicultural team filled with wonderful people At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (‚ÄúLive my life‚Äù in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Positions available in Paris, Lyon, Bordeaux, Marseille, Nantes, Lille You : Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused‚Ä¶ Like work well done and pay attention to detail Dream of being able to develop and manage website databases with strong traffic Want to work with various, prestigious clients on different problems Are on the lookout for new languages/technologies and test the latest open source trends before others You love the following stack ? Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...) SQL Databases (MySQL, SQLServer) Apache Spark ETL (Apache Airflow or equivalent) NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...) Apache Kafka Python, Java, Scala Git Linux Even better if you know : Cube OLAP and SSRS Cloud Solutions (AWS, GCP, ‚Ä¶) API REST, WebServices Docker Kubernetes Apache Druid Data Science and Machine Learning Message Queuing (RabbitMQ, Celery, ‚Ä¶)",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
155,56495,https://www.welcometothejungle.com/fr/companies/margo/jobs/margo-analytics-data-engineer-h-f_paris,Margo Analytics - Data Engineer -,Margo,"{Databricks,Scala,via,Spark,Azure,Hadoop,Python}",T√©l√©travail partiel possible,"1, Rue de Saint-P√©tersbourg, Paris, 75008","Logiciels, IT / Digital, FinTech / InsurTech",CDI,2023-03-26,"La mission de Margo ? Acc√©l√©rer la transformation digitale de ses clients en les accompagnant dans le d√©ploiement de projets IT complexes. Margo, c‚Äôest un cabinet de consulting √† taille humaine dont l‚Äôobjectif depuis 15 ans est d‚Äôassurer la satisfaction de ses consultants autant que celle de ses clients. Pour cela la recette est simple : ils s√©lectionnent avec attention leurs projets pour que chacun de leurs collaborateurs se sente stimul√© et progresse rapidement. Ils interviennent aujourd‚Äôhui principalement sur des sujets de coding et data, et sur des probl√©matiques m√©tiers dans la finance, la banque, l‚Äôassurance et l‚Äô√©nergie. Margo Analytics - Data Engineer ‚Äì H/F CDI. Paris. Notre mission chez Margo Analytics? Accompagner la transformation Data et Cloud de nos clients en combinant ROI et Innovation technologique. Nous sommes un cabinet de conseil √† taille humaine dont l‚Äôobjectif est d‚Äôassurer la satisfaction de nos consultants autant que celle de nos clients. Pour cela la recette est simple : nous s√©lectionnons avec attention nos projets pour que chacun de nos collaborateurs se sente stimul√© et progresse rapidement . C‚Äôest pourquoi nous avons d√©velopp√© une expertise sur les derni√®res technologies Data et Cloud dans les secteurs d‚Äôactivit√© o√π l‚Äôon retrouve des contraintes techniques fortes (Banque, Assurance, Industrie, √ânergie et Retail). L‚Äôaventure Margo Analytics, c‚Äôest aussi int√©grer une communaut√© de 350 experts du groupe Margo, tous passionn√©s par la tech, r√©partis entre Paris, Londres et Varsovie. A leurs c√¥t√©s, vous pourrez √©voluer rapidement et d√©velopper de nouvelles comp√©tences. Pr√™t √† nous rejoindre ? üéØ Exemple de projet propos√© par Margo Analytics : En int√©grant Margo Analytics, vous aurez le choix des missions sur lesquelles vous souhaitez travailler. Vous serez accompagn√© par les 2 fondateurs de l‚Äôentreprise, dont le r√¥le est de rechercher le projet client qui correspondra le plus √† vos attentes et de vous accompagner dans votre carri√®re. Ainsi, vous pourrez par exemple intervenir sur l‚Äôun de nos projets de refonte from scratch d‚Äôun datalake au sein d‚Äôun grand acteur de l‚ÄôIndustrie et de sa migration vers le Cloud Azure.L‚Äôobjectif est d'assurer la distribution de la donn√©e de mani√®re optimis√©e pour cr√©er une couche de distribution et permettre aux entit√©s m√©tiers d‚Äôimpl√©menter les use cases.Vous aurez ainsi l‚Äôopportunit√© d‚Äô√©voluer dans un environnement tr√®s exigeant, en m√©thodologie agile et au sein d‚Äôune √©quipe d‚Äôexperts. En tant que Data Engineer, vos missions seront : D√©velopper en mode agile les usages m√©tier reposant sur le Datalake HadoopParticiper au projet de MoveToCloud vers Azure Identifier et mod√©liser des donn√©es n√©cessaires √† l'usage S√©lectionner le stockage le plus adapt√© √† l'usage parmi les technologies de l'√©cosyst√®me Databricks D√©velopper en Python et en Scala des traitements de transformation et de production de donn√©es Participer √† l‚Äôam√©lioration continue et au refactoring de code Stack techno : Hadoop/Spark / KafkaScala / Python Databricks Cloud Azure ‚ú® La vie interne chez Margo Analytics Les projets que nous proposons chez Margo Analytics sont des missions longues (2 √† 3 ans) qui vous permettront d‚Äô√©voluer vers une expertise technique. Vous aurez √©galement l‚Äôopportunit√© de vous impliquer dans le d√©veloppement et la strat√©gie de Margo Analytics et contribuer √† faire grandir notre communaut√©. Les possibilit√©s sont nombreuses et tr√®s rapidement nous vous proposons d‚Äôavoir un 2√®me r√¥le au sein de la structure : Recruteur , pour √©changer techniquement avec les candidats pendant leur processus de recrutement, repr√©senter Margo Analytics lors de forums √©coles ou proposer des cooptations de personnes de votre r√© seau. Formateur , pour partager votre expertise et vos connaissances au sein de la communaut√© Margo Analytics. Manager , pour suivre en mission et √™tre garant de l‚Äô√©volution de carri√®re de consultants juniors. R√©dacteur , pour mettre en lumi√®re votre expertise et celle de Margo Analytics en r√©digeant des articles techniques publi√©s sur notre blog et dans la presse sp√©cialis√© e. Speaker , pour prendre la parole et proposer des d√©bats lors de conf√©rences internes ou externes üîç Vous √™tes un(e) futur(e) Margo Analytics si : Must-Have Vous √™tes issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun cursus universitaire √©quivalent niveau Bac + 5 / Master.Vous aimez coder et vous √™tes passionn√©(e) d‚Äôinformatique et de Data.Vous √™tes curieux(se) et vous vous int√©ressez aux derni√®res technologies du march√©.Vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data Engineer. Nice to Have Vous √™tes ambitieux(se) et n‚Äôavez pas peur de travailler sur des projets challengeants dans des environnements √† fortes contraintes techniques (forte volum√©trie de donn√©es, temps r√©el, optimisation de la performance). Vous aimez travailler en √©quipe et √™tes attach√©(e) au respect des bonnes pratiques de code.Vous parlez et comprenez l‚Äôanglais. üôå Les avantages : ü§ùNotre processus de recrutement : Postulez en ligne ! L‚Äô√©quipe RH √©tudie avec attention votre candidature et vous contacte si votre profil est en ad√©quation avec l‚Äôun de nos postes. Premi√®re rencontre ! Vous √©changez avec un RH et un des associ√©s de Margo Analytics sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunit√©s que nous proposons. Challengez-vous dans le cadre d‚Äôun entretien technique avec l‚Äôun de nos experts. C‚Äôest √©galement l‚Äôoccasion pour vous d‚Äôavoir son retour d‚Äôexp√©rience. Dernier entretien de motivation : pour finir, vous rencontrez un membre du comit√© de direction de Margo Analytics pour confirmer notre motivation commune. Pendant tout le processus de recrutement, vous avez la possibilit√© de participer √† des √©v√©nements organis√©s par Margo Analytics et d‚Äô√©changer avec des collaborateurs afin d‚Äôen apprendre plus sur nous ! PS : Si vous √©tudiez ou travaillez loin de Paris, nous vous proposons de suivre ce processus en full visio via le syst√®me Hangout Meets de Google. üèä Plongez dans la culture d‚Äôentreprise du groupe Margo : Rencontrez nos √©quipes √† travers notre page WelcomeToTheJungle D√©couvrez des retours d‚Äôexp√©riences de consultants Margo sur notre page YouTube N‚Äôh√©sitez pas √† prendre connaissance des avis de nos collaborateurs sur GlassDoor Si vous ne vous reconnaissez pas dans cette offre, n‚Äôh√©sitez pas √† prendre connaissance de nos autres opportunit√©s üëâ nos offres d'emploi Engag√©e en faveur de l'√©galit√© des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap.","Margo Analytics is seeking a Data Engineer to join their team in Paris, France. The company aims to combine ROI and technological innovation to help clients transform their data and cloud technologies. The ideal candidate should have a Bachelor's or Master's degree in engineering or a related field, experience working as a Data Engineer, and be passionate about technology and data. They should also be willing to work on challenging projects and adhere to code best practices. The company offers long-term missions, opportunities for growth and development, and the chance to contribute to the company's development and strategy. The recruitment process includes interviews with HR, company associates, and technical experts.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
71,56418,https://www.welcometothejungle.com/fr/companies/withings/jobs/data-engineer-h-f_issy-les-moulineaux_WITHI_bJ6kDAw,Data Engineer,Withings,"{ElasticSearch,dbt,Dagster,via,Linux,Unix,ClickHouse,SQL,Python}",T√©l√©travail partiel possible,"2 rue Maurice Hartmann, Issy-Les-Moulineaux, 92130",Objets connect√©s,CDI,2023-03-26,"Chez Withings, ils souhaitent redonner aux individus le contr√¥le de leur sant√©. Ils ont l‚Äôobsession de cr√©er des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; leurs balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de leur gamme sont aujourd‚Äôhui utilis√©s par des millions d‚Äôutilisateurs. Leur objectif : permettre la pr√©vention, le d√©pistage et l‚Äôaccompagnement d‚Äôun certain nombre de maladies chroniques via des produits et des services innovants, afin de r√©volutionner la mani√®re dont on prend soin de notre sant√©. Chez Withings, nous souhaitons redonner aux individus le contr√¥le de leur sant√©. Nous avons l‚Äôobsession de cr√©er des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; nos balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd‚Äôhui utilis√©s par des millions d‚Äôutilisateurs. Notre objectif : permettre la pr√©vention, le d√©pistage et l‚Äôaccompagnement d‚Äôun certain nombre de maladies chroniques via des produits et des services innovants, afin de r√©volutionner la mani√®re dont on prend soin de notre sant√© . Au sein de Withings, l‚Äô√©quipe Data Analytics facilite le traitement et l‚Äôusage de gros volumes de donn√©es afin de permettre √† toutes les √©quipes de Withings de prendre des d√©cisions bas√©es sur la r√©alit√©. Dans ce cadre, tu auras les responsabilit√©s suivantes: Maintenance et administration de base de donn√©es (ClickHouse / PostgresSQL / ElasticSearch) Mod√©lisation de donn√©es en SQL (SQL - dbt) D√©veloppement de connexions API (Python / Rust) D√©veloppement de pipelines de donn√©es complexes (Python - Dagster) Maintenance et administration de machines virtuelles (Unix) Soutien technique au reste de l‚Äô√©quipe Former les √©quipes m√©tiers aux bases de SQL Requirements Fortes comp√©tences informatiques : SQL, Python, Linux, d√©veloppement de connexions API‚Ä¶ App√©tence forte pour les challenges techniques : stack on-premise, outils open-source, contraintes physiques des serveurs, s√©curit√© forte li√©e √† l‚Äôutilisation de donn√©es de sant√©‚Ä¶ Rigueur, autonomie, prise d'initiatives, curiosit√©... Ma√Ætrise parfaite de la communication en fran√ßais et en anglais, aussi bien √† l‚Äô√©crit qu‚Äô√† l‚Äôoral Benefits Rejoindre l‚Äôaventure Withings, c‚Äôest : Int√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show Contribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution Int√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen Participer √† l‚Äôam√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues B√©n√©ficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, r√©ductions pour des activit√©s culturelles et sportives, restaurant d‚Äôentreprise, et bien plus encore Participer √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical Collaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites ! Toutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l‚Äôorigine ethnique, des croyances, de la religion, du genre, de l‚Äôorientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l‚Äô√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.","Withings is seeking a Data Analyst to maintain and administer databases, model data in SQL, develop API connections and complex data pipelines, and provide technical support in an agile and constantly evolving environment. The ideal candidate should have strong technical skills in SQL, Python, Linux, and API development, as well as a strong interest in technical challenges related to on-premise stacks, open-source tools, server physical constraints, and data security. Withings offers various benefits, including contributing to innovative and ambitious health projects, teleworking, stock options, a choice of smartphone and computer, and more.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
28,67470,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont_NATIX_V4xO2LW,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"Charenton le Pont, Charenton-Le-Pont, 94220","Banque, Transformation, Assurance",CDI,2023-04-07,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de votre √¢ge, origine, orientation sexuelle, handicap... Au sein du d√©partement CIO CIB, vous rejoignez l'√©quipe de Sensitivities, au sein de l'IT Risks, compos√©e de 10 personnes. En nous rejoignant, vous prenez part √† plusieurs programmes de transformation de notre syst√®me d'information afin de r√©pondre aux besoins du d√©partement des risques, des r√©gulateurs, tout en accompagnant les front offices dans leurs nouvelles activit√©s. L'√©quipe est en charge de la maintenance et des √©volutions de deux applications cl√©s pour la gestion des risques de march√©s : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities r√©pondant √† la r√©glementation FRTB). Nos principaux interlocuteurs sont le d√©partement des risques de march√©s (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk), les √©quipes support/production √† Porto et les √©quipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques √† mettre en ≈ìuvre et estimer le co√ªt avec l'√©quipe ; D√©velopper de nouvelles fonctionnalit√©s de la phase de conception aux tests, dans une d√©marche durable (haute qualit√© du code, respect des principes d'architecture et de s√©curit√© informatique, documentation, automatisation des tests, utilisation maitris√©e de l'infrastructure) ; Travailler sur des probl√©matiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et am√©liorer la Software Factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 et les d√©veloppements n√©cessaires pour maintenir une production ponctuelle, de qualit√© et ma√Ætris√©e. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Paris et √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en informatique avec une sp√©cialisation en big data, vous avez au moins 3 ans d'exp√©rience en tant que data engineer. Vous ma√Ætrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La pr√©conisation de solutions techniques. Vous √™tes : - Reconnu pour votre leadership ; - Capable de proposer des am√©liorations continues ; - Rigoureux, autonome et p√©dagogue. Vous ma√Ætrisez l'anglais avec un niveau minimum B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.",,Bac +4,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
27,67387,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-dpm-h-f_charenton-le-pont_NATIX_OQAO6RD,Data Engineer Risks DPM,Natixis,"{Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"30 AVENUE PIERRE MENDES-FRANCE, Charenton-Le-Pont, 75013","Banque, Transformation, Assurance",CDI,2023-04-07,"Au sein de la direction CIO CIB Risks, dans le d√©partement Data Processing and Metrics, vous rejoignez l'√©quipe Metric Services P&L Explain qui est compos√©e de 5 personnes. Dans cette √©quipe nous travaillons √† calculer l'explication du P&L (profit and loss) par les sensibilit√©s. Notre application est √©galement partie prenante des calculs de Stress Tests et IPV (ind√©pendance price validation). Nous intervenons donc sur plusieurs cha√Ænes de valeurs, aupr√®s de notre client : le d√©partement des risques de march√©. Au quotidien vous avez pour missions de : Contribuer aux sp√©cifications techniques et fonctionnelles ; Intervenir de la phase de conc√©ption aux tests : d√©veloppement de nouvelles fonctionnalit√©s, revue de code, documentation, ... ; Travailler sur des probl√©matiques d'optimisation de performance et proposer des solutions innovantes ; Maintenir et am√©liorer la software factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 pour avoir une production ponctuelle, de qualit√© et ma√Ætris√©e. Nos principaux interlocuteurs sont : le d√©partement des risques de march√© (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk) et les √©quipes support et production √† Porto. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Vous travaillez dans un environnement international, au sein d'une communaut√© d'experts qui place l'excellence, l'impact et l'action collective au c≈ìur de tout ce qu'elle entreprend. Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en finance et/ou en informatique avec une sp√©cialisation en big data, vous avez une exp√©rience d'au moins 2 ans en tant que Data Engineer (Hadoop, Spark, Scala). Vous ma√Ætrisez : * La finance de march√©, et plus pr√©cis√©ment le march√© des risques et PNL (m√©thode d'explication du PNL) ; * Les sp√©cifications des besoins de l'√©quipe et vous √™tes capable de proposer des maquettes aux utilisateurs en autonomie. Vous √™tes : * P√©dagogue et vous savez expliquer les sujets sur lesquels vous travaillez ; * Autonome et rigoureux ; * Capable de proposer des am√©liorations continues. Vous ma√Ætrisez l'anglais avec un niveau B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.",,Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
26,56945,https://www.welcometothejungle.com/fr/companies/cgi/jobs/ingenieur-data-big-data-tips-h-f_paris,Ing√©nieur DATA - BIG DATA / TIPS,CGI,"{GCP,Talend,Informatica,AWS,Spark,Azure}",T√©l√©travail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. - Conseil, Audit et Maitrise d‚Äô≈ìuvre, * Etudes d‚Äôopportunit√©, cadrage de projet d‚Äôint√©gration de donn√©es et aide au Choix de solution, * Accompagnement √† la mise en place de DataLake/Big Data * Conception et d√©veloppement de flux d‚Äôint√©gration des donn√©es (ETL,ELT, streaming ,API ‚Ä¶ ) * Conception et mise en ≈ìuvre de plates-formes On Premise ou Cloud de stockage des donn√©es dans un Data Lake (Big Data) - Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.) * Migration des donn√©es - Move to Cloud Profil de consultant Data Ing√©nieur: * Animation d‚Äôateliers M√©tier/ IT de d√©finition des processus d‚Äôint√©gration des donn√©es, * Animation d‚Äôatelier de d√©finition de plateforme d‚Äôint√©gration et de stockage des donn√©es * Proposition de type d‚Äôarchitecture de gouvernance (Centrale, d√©centralis√©e, etc.) - Capacit√© √† int√©grer une √©quipe d‚Äôint√©gration des donn√©es - Capacit√© √† proposer des solutions & architectures de donn√©es * Capacit√© √† configurer des outils d‚Äôint√©gration et de Reporting des donn√©es * Formation et pratique d‚Äôoutils de Data Int√©gration (Informatica , Talend, API, Spark, Atlas, Ranger etc.. )","CGI, a global leader in digital consulting and services, is seeking a Data Engineer consultant to work on a variety of projects in industries such as banking, retail, energy, and transport. The ideal candidate should have experience in data integration, cloud platforms, data architecture, and tools such as Informatica and Talend. The role involves leading workshops, proposing solutions, and configuring data integration and reporting tools.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
25,67290,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-h-f-nwm_paris_NATIX_xmqzm5r,Data Engineer  - NWM,Natixis,"{Microsoft,via,SQL}",T√©l√©travail partiel possible,"paris, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-04-07,"Avec plus de 450 collaborateurs, Natixis Wealth Management est implant√©e en France et intervient √©galement au Luxembourg. Natixis Wealth Management fait partie du Groupe BPCE, 2√®me acteur bancaire en France qui lui offre solidit√© et s√©curit√©. Elle entretient des liens √©troits avec les r√©seaux qui le composent (Banque Populaire, Caisse d'Epargne et BPCE IOM) pour servir ses clients. Naturellement, elle s'appuie sur les talents et les expertises de Natixis pour proposer des solutions financi√®res se situant hors de son p√©rim√®tre d'activit√©. ¬´ En tant qu'entreprise socialement responsable, Natixis Wealth Management s'engage √† favoriser l'insertion professionnelle et le maintien dans l'emploi des personnes en situation de handicap. Nous sommes tous mobilis√©s pour que chaque collaborateur puisse exprimer tout son potentiel. ¬ª L'√©quipe activit√©s et projets transverses, que vous rejoignez en tant que Data Engineer, est compos√©e d'une quinzaine de personnes au sein de la DSI. Dans cette √©quipe, nous travaillons notamment √† la refonte de la plateforme data et participons √† l'ensemble des enjeux data de la banque. Au quotidien, vous avez pour missions : D'assurer, dans un premier temps, un r√¥le de tech lead sur le programme de r√©novation de la plateforme data ; De mettre en oeuvre les bonnes pratiques concernant le socle data du SI de Natixis Wealth Management (NWM) ; De participer √† la fiabilisation du SI et d'apporter un support de niveau 2 sur certains incidents ou demandes d'assistance ; D'assurer une veille technologique ; D'analyser les demande d'√©volution ou de maintenance corrective. Les stacks techniques utilis√©es sont les suivantes : SQL, SQL Server, SSIS, Microsoft. Nos √©quipes travaillent en mode Agile. Vous int√©grez une communaut√© d'experts qui place l'excellence, l'impact et l'action collective au c≈ìur de tout ce qu'elle entreprend. #MuchMoreThanJustAJob Le poste est bas√© √† Paris et chez nous, vous b√©n√©ficierez de 10 jours de t√©l√©travail par mois, de 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, de d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√©.e par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier) Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait.e pour travailler avec nous : De formation sup√©rieure en √©cole d'ing√©nieur ou √©quivalent, vous disposez d'au moins cinq ans d'exp√©rience sur des fonctions similaires. Vous ma√Ætrisez : * Les m√©thodes agiles ; * Le langage SQL, les bases de donn√©es SQL Server, le SSIS et la stack technique Microsoft ; * Les techniques de mod√©lisation des donn√©es et les probl√©matiques de stockage des donn√©es ; * L'ETL et le big data ; * Les outils DevOps. Vous √™tes : * Capable de vous adapter rapidement au contexte de Natixis Wealth Management (NWM) ; * Adaptable ; * Reconnu pour votre leadership. Vous ma√Ætrisez l'anglais avec un niveau B1. Dites-nous que vous √™tes int√©ress√©.e en r√©pondant √† cette annonce.",,Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
24,56896,https://www.welcometothejungle.com/fr/companies/advanced-schema/jobs/data-engineer_paris,Data Engineer,ADVANCED SCHEMA,"{NoSQL,Java,BASH,SQL,Python}",T√©l√©travail partiel possible,"19, Rue Galil√©e, Paris, 75116","IT / Digital, SaaS / Cloud Services, Big Data",CDI,2023-03-26,"ADVANCED SCHEMA, sp√©cialiste des probl√©matiques data, accompagne ses clients depuis plus de 20 ans dans la r√©ussite de leurs projets strat√©giques. Nous concevons des solutions data centr√©es sur les usages et la performance. Notre positionnement : une expertise de pointe, des projets √† fort enjeux m√©tiers et technologiques, toujours men√©s √† bien dans le respect de notre ADN. Nos valeurs et notre mode de fonctionnement font d‚ÄôADVANCED SCHEMA une entreprise unique, guid√©e par ses fortes convictions technologiques. Chaque collaborateur apporte son expertise et son savoir-faire pour participer √† l‚Äôengagement collectif de son √©quipe. Prenez part √† l‚Äôexp√©rience ADVANCED SCHEMA port√©e par la diversit√© des projets dans lesquels vous pourrez exprimer pleinement votre potentiel. En tant que Data Engineer, vous aurez les missions suivantes : -Concevoir des mod√©lisations physiques -Construire des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation. -D√©velopper des flux des donn√©es -Contribuer au pilotage de projets, de proof of concepts -Participer √† des missions d‚Äôexpertise N‚Äôh√©sitez pas √† postuler m√™me si vous ne r√©pondez pas √† toutes les exigences. Nous accordons autant d‚Äôimportance √† la capacit√© d‚Äôapprendre qu‚Äô√† la ma√Ætrise d‚Äôune technologie. Ce poste est √† pourvoir en stage et CDI Comp√©tences professionnelles & niveau d‚Äô√©tudes requis : -Vous √™tes titulaire d‚Äôun dipl√¥me Bac +3 minimum dans le domaine de la data -Vous poss√©dez minimum 1 an d‚Äôexp√©rience dans le m√©tier -√ätre enthousiaste √† l‚Äôid√©e d‚Äôapprendre de nouvelles technologies -Exp√©rience de la m√©thodologie Agile / Scrum -Capacit√© √† planifier et √† prioriser les t√¢ches et les activit√©s confi√©es en autonomie -Ma√Ætrise de l‚Äôanglais oral et technique obligatoire -Exp√©rience av√©r√©e dans l‚Äô√©criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL Etape 1 : Rapide √©change t√©l√©phonique, dont le but est d‚Äô√©changer sur ce que vous recherchez, et d‚Äôapprendre √† se conna√Ætre. Etape 2 : Entretien en visioconf√©rence afin d‚Äô√©changer sur votre parcours et votre motivation Etape 3 : Entretien physique au sein des locaux d‚ÄôADVANCED SCHEMA pour finaliser le processus de recrutement.","Advanced Schema is seeking a Data Engineer with expertise in Advanced Schema and data-related issues to join their team. The ideal candidate will possess a minimum of a bachelor's degree in data-related fields with at least one year of experience in the field. The candidate should also have a strong ability to learn new technologies and experience with Agile/Scrum methodologies. They should also possess excellent problem-solving skills and be proficient in at least two of the following languages: BASH, SQL, Java, Python, or NoSQL.",Bac +3,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
22,61959,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_rennes_ASI_61x8rWj,Data Ing√©nieur  - Manipulation et valorisation des big-datas,ASI,"{Oracle,Snowflake,Cassandra,Azure,Cloudera,MySQL,MongoDB,Databricks,Kafka,NoSQL,ElasticSearch,RabbitMQ,Java,SQL,Hadoop,Scala,Flume,PostGreSQL,Spark,Python}",T√©l√©travail partiel possible,Rennes,"IT / Digital, Transformation, Big Data",CDI,2023-03-30,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Vous aurez pour mission de : Concevoir et r√©aliser un sourcing de donn√©es Big Data Temps r√©els ou non Ma√Ætriser les formats de donn√©es non structur√©s et savoir les manipuler Concevoir et r√©aliser une cha√Æne de traitement dans un environnement Big Data Concevoir et r√©aliser des applications et API utilisant les donn√©es valoris√©es G√©rer et administrer les bases de donn√©es filesystem et NoSQL Ecosyst√®me en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra. Langages de d√©veloppement‚ÄØ: Python, Java, Scala. Comp√©tences principales : Hadoop (Cloudera)et/ou une solution de base de donn√©es NoSQL Le requ√™tage SQL, HiveQL Le d√©veloppement Spark avec SQL, Python et/ou Scala Le d√©veloppement Java (API en particulier) Les bases de donn√©es relationnelles (PostGreSQL, Oracle, SQLServer, MySQL‚Ä¶) Comp√©tences sp√©cialis√©es : Base de donn√©es NoSQL‚Äã (ElasticSearch, MongoDB, Cassandra‚Ä¶‚Äã) Solutions Cloud‚Äã (Azure Data (Datalake Store, Databricks), Snowflake‚Ä¶‚Äã) Message broker‚Äã (Kafka, Flume, RabbitMQ‚Ä¶)","ASI is a French digital expertise firm that supports public and private organizations in their digital transformation by developing digital services for their employees, partners, and clients. They are looking for a Big Data Consultant who can design and implement data sourcing, processing and application development using Hadoop, Spark, Kafka, Elasticsearch, MongoDB and Cassandra among other tools. Candidates should have expertise in SQL querying, HiveQL, Spark development using SQL, Python, and Scala, as well as experience working with NoSQL databases like ElasticSearch, MongoDB, and Cassandra, as well as Cloud solutions like Azure Data and message brokers like Kafka, Flume, and RabbitMQ.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
21,66884,https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f_paris_EL_q5RNw31,Data Engineer,Eleven Labs,"{Jupyter,SnowFlake,GO,Node,Spark,BigQuery,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"102, Rue du Faubourg Saint-Honor√©, Paris, 75008","Logiciels, IT / Digital, Audit",CDI,2023-04-07,"Eleven Labs est une soci√©t√© de conseil, sp√©cialis√©e en cr√©ation et r√©alisation de projets Web agiles de qualit√©. Les astronautes interviennent sur des missions qu‚Äôils choisissent, et elles sont ax√©es sur du d√©veloppement, de l‚Äôarchitecture, de la conduite de projet Agile, de l‚Äôaudit et du conseil. Au quotidien, tout est fait pour encourager la progression et l‚Äô√©panouissement technique, √† travers des plateformes d√©di√©es √† l‚Äôapprentissage ( le blog , le codelabs , des acc√®s √† Udemy et egghead.io ‚Ä¶), ou gr√¢ce √† des √©v√©nements internes (workshops, meetups, formations‚Ä¶) r√©guliers. Seras-tu notre furtur.e Data Engineer ! Un peu de contexte ‚òùÔ∏è De plus en plus de nos consultants s‚Äôint√©ressent de pr√®s au sujet de la Data, ce qui nous a pouss√© √† explorer ces probl√©matiques chez nos clients et de constater un besoin fort d‚Äôaccompagnement de leur part. Nous recherchons donc la personne qui ouvrira la voie √† cette expertise chez Eleven Labs et qui accompagnera la cr√©ation de l‚Äôescouade Data ! Nos attentes üß† Nous recherchons quelqu‚Äôun d‚Äôexp√©riment√©/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de r√©pondre au mieux aux probl√©matiques qui lui seront soumises, pour qui les requ√™tes SQL, NoSQL sur BDD n‚Äôont aucun secret, et qui ma√Ætrise d√©j√† une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake). üçí Cerise sur le g√¢teau : on cherche aussi un profil ma√Ætrisant les langages type Python, Java, GO et Node.JS pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribu√©. Des connaissances dans l‚Äôutilisation d‚Äôoutils ML et d‚Äôenvironnement Cloud en g√©n√©ral sont un vrai plus. üé≠ C√¥t√© personnalit√©, et outre cet aspect exp√©riment√© et ‚Äúouvreur de voie‚Äù, on cherche quelqu‚Äôun de moteur, avec un r√©el enthousiasme √† transmettre ses connaissances, former et √©changer. Les missions üïµÔ∏è Les missions propos√©es te feront intervenir dans des secteurs divers, avec des cas d‚Äôusage vari√©s souvent en lien avec le marketing et impliqueront principalement : d‚Äô√™tre force de proposition quant au choix des outils et pratiques ; faire de la data visualisation (B.I.) d‚Äôassurer l‚Äôextraction de donn√©es et leur transformation de g√©rer la mise en place from scratch de pipelines et data lakes. Nos engagements üí™ Tu participeras activement au d√©veloppement de l‚Äôescouade Data chez Eleven Labs pour laquelle nous avons de v√©ritables ambitions de production de contenu externe (talks, articles, implication dans le recrutement‚Ä¶), et interne (workshops, animation de la communaut√© Data, mentorat de profils juniors‚Ä¶). üî• Nos clients sont des sites grand publics principalement des secteurs m√©dias/presse et e-commerce, avec pour points communs un fort accent mis sur la qualit√©, et un fonctionnement en m√©thodologie Agile. üíñ Tu travailleras avec une √©quipe de passionn√©(e)s qui aime partager, remettre en question ses fa√ßons de faire, et trouver de nouvelles id√©es pour gagner en efficacit√©. ü§ù Tu √©volueras dans une culture d‚Äôentreprise qui valorise le collectif : nous restons m√™me √† 100 salari√©s une entreprise o√π les gens se connaissent et √©changent quotidiennement (pour parler de leur job mais aussi du dernier meme ou d‚Äôun compte Twitter improbable). Si tu es int√©ress√©(e), comment √ßa se passe ? üó®Ô∏è Tout commence par un entretien d‚Äôintroduction Tu t‚Äôentretiendras avec une recruteuse tech qui te suivra tout le long de ton parcours chez nous. Vous parlerez de tes attentes et de ce que tu aimes dans ton job, et elle te pr√©sentera Eleven Labs. üëã Ensuite il y a un entretien de cas pratique Pour avoir une id√©e de ce qui t‚Äôattend, on te propose de rencontrer R√©my (Data Architect) ainsi que Charles-√âric (Directeur Technique). üè† On conclut par une visite des locaux On t‚Äôinvite dans les locaux ! Tu pourras y rencontrer d‚Äôautres membres de la fus√©e pour √©changer sur leurs parcours et le tien autour d‚Äôun caf√©.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
19,49633,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris-or-remote-france_paris_DATAI_M5g1m4J,Software Engineer Data Presentation - Paris or Remote France,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,dataiku,Spark,D3,SQL,Python,Tableau}",T√©l√©travail partiel possible,"203 rue de Bercy, Paris, 75012","Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machines or deep learning models with just a few clicks. What we do: We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do: With your top-tier teammates from the engineering team and the help of the UX team, you will: Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad-hoc web applications in a scalable way (both frontend and backend). Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with frontend and backend development skills to create usable, intuitive, and beautiful interfaces and scalable engines for its Dataiku DSS platform. The ideal candidate has experience in software development and is interested in data visualization tools, is customer-oriented, and has firsthand experience building a real product. The role involves building components to allow users to create and display charts, dashboards, and ad-hoc web applications in a scalable way, prototyping and creating new ways to interact with data, and working with product managers and UX designers to refine solutions. The company values autonomy, work-life balance, and a diverse and inclusive culture.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
18,39694,https://www.welcometothejungle.com/fr/companies/wakam/jobs/data-engineer-python_paris,Data Engineer Python,Wakam,"{GIT,databricks,python,Django,Snowflake,magic,R,snowflake,Azure,SQL,Python}",T√©l√©travail partiel possible,"120-122 rue R√©aumur, Paris, 75002","Assurance, FinTech / InsurTech, Blockchain",CDI,2022-11-29,"Wakam (qu‚Äôon prononce Ouakam pas Vakam) est un assureur B2B qui con√ßoit, en marque blanche, des produits d‚Äôassurance sur-mesure pour ses partenaires distributeurs (des courtiers en assurance mais cela peut aussi √™tre des acteurs du e-retail, des n√©o-banques, des compagnies a√©riennes). Nos produits d‚Äôassurances ont la particularit√© d‚Äô√™tre embarqu√©s dans les produits ou services propos√©s au client final (par exemple, tu prends une trottinette en libre-service üõ¥, tu es assur√© automatiquement). Wakam est pr√©sent dans 32 pays europ√©ens (point bonus si tu arrives √† les citer en entretien) √ßa commence √† faire beaucoup et on risque de ne pas s‚Äôarr√™ter l√† car notre part du chiffre d‚Äôaffaires en dehors de France est en forte progression (58% √† la fin de l‚Äôann√©e 2020). C‚Äôest pour cette raison que l‚Äôon recrute de futurs Wakamees qui parlent bien anglais (mieux que Brian in the kitchen hein‚ÄØ!). Chez Wakam nous croyons √† la formule ¬´‚ÄØfor profit & for good‚ÄØ¬ª. Depuis mars 2021, nous sommes une Soci√©t√© √† mission, √ßa veut dire que notre raison d‚Äô√™tre ¬´‚ÄØRendre l‚Äôassurance transparente et impactante‚ÄØ¬ª est inscrite dans nos statuts. Nous avons d√©fini 9 engagements concrets pour donner corps √† cette mission comme par exemple, r√©diger les contrats d‚Äôassurance en langage clair (fini les formules alambiqu√©es et les petites lignes illisibles). Nous cr√©ons aussi pour des associations, des produits d‚Äôassurance sur lesquels nous ne faisons aucune marge. Notre culture ? Free to impact. Une culture o√π tout est possible, o√π toutes les id√©es sont consid√©r√©es, o√π chacun a un impact sur la transformation de l‚Äôassurance ! Qu√™te de libert√© ? Soif d‚Äôautonomie ? Si tu es intr√©pide et aimes le challenge (ouai ouai je sais ce mot que toutes les startups ont √† la bouche) Wakam devrait √™tre fait pour toi. Nos 11 marqueurs culturels en disent long sur qui nous sommes, √† d√©couvrir sur notre site web ! Au sein de l‚Äô√©quipe Project Data du Data Office, le Data Engineer/Developpeur Python participera aux d√©veloppements de produits data sur notre asset End To End Data Factory. Ces produits sont autour de la qualit√© de donn√©es, des flux d‚Äôint√©gration de donn√©es et de moteur de calculs de KPIs, construits √† l‚Äôaide du langage Python. Les produits sont mis en ≈ìuvre dans une approche product management et des pratiques DevOps. Nous travaillons d‚Äôun √©cosyst√®me technique Azure et Snowflake. Description du poste au sein de l‚Äô√©quipe projet du Data Office : D√©velopper en python des features/US pour construire nos produits data : Industrialisation de contr√¥les de donn√©es techniques et fonctionnelles, sur plusieurs types de formats : fichiers dans Azure Datalake : csv, json, xml, xlsx, tables parquets databricks, tables BDD snowflake, logger les r√©sultats dans snowflake. Interfacer ces produits en construisant des APIs, cr√©er des IHMs pour la mise √† jour des param√©trages et les process de validations. Cr√©er des flux de collecte de donn√©es en requ√™tant des APIs. R√©aliser un moteur de calculs de KPIs de r√©assurances. Travailler en m√©thodologie Agile, en collaboration avec les Products Owner et les Business Analyst, d√©tailler les US en t√¢ches, estimer la complexit√© et les efforts d‚Äôimpl√©mentations Garantir la qualit√© et les performances de ces d√©veloppements en mettant en place des strat√©gies de test automatique et de d√©ploiement continu Accompagner le Product Owner et les Business Analysts lors des recettes des nouvelles features/Users Stories R√©diger des sp√©cifications techniques et documenter les d√©veloppements r√©alis√©s √ätre force de proposition et proposer des solutions pour am√©liorer de fa√ßon continue les produits data (E2E DataFactory) Participer au maquettage ou √† la mise en place de Proof of concept dans le cadre de l‚Äôactivit√© de R&D Veille technologique ‚úØ Le profil recherch√© Vous avez au minimum 5 ans d‚Äôexp√©rience sur un poste similaire, Vous √™tes un Master sur Python (Exemple de librairies : standard (os, time, date), panda, json, regex, yaml, magic, requests‚Ä¶) et les frameworks Python tels que Flask, Django,... pour cr√©er des APIs et IHMs n'ont plus de secret pour vous DevOps (Azure DevOps, VS Code, GIT, CI/CD ‚Ä¶) SQL Etre force de proposition, cr√©atif et innovant, Porter un grand soin √† la qualit√© et √† la performance de ses d√©veloppements Process de recrutement Echange avec Danny, Talent Acquisition Expert Echange technique avec C√©dric, BI Project Manager Echange avec l'√©quipe Echange avec Rapha√´l, Chief Data Officer Echange RH avec Amandine - Chief People Officer et/ou Laura - Head of Talent => Welcome @Wakam üôå Positive energy, agility, and team spirit are essential to support Wakam in its hyper-growth! You have the Wakam mindset? Join us! More about us Our culture? Free to impact . A culture where everything is possible, where all ideas are taken into consideration, where everyone has an impact on the transformation of insurance! Hungry for freedom? Thirsty for autonomy? If you are bold and like challenges (yeah yeah! That one word that all startups have at the tip of their tongues), then the Wakam adventure might be made for you! Discover -on our website- who we really are with the 11 cultural markers that so well describe us! Mindset compatibility with our ‚ÄòFree to Impact‚Äô culture: Think big Biased for action Curious and eager to learn Can say no and find solutions Aims for the moon (but please don‚Äôt stick on the moon) And above all: have fun working together ü§úü§õ ! Wakam is not based on a hierarchy but on a methodology where everyone finds his role and knows his objectives. With a flat hierarchical system and a highly collaborative operating model, Wakam is an extremely agile and transparent company. Every last Friday of the month, it's Free.day at Wakam, a day without meetings to take a step aside and dedicate ourselves to skills sponsorship or other activities (because we are curious, I remind you). Full-remote is a reality at Wakam (there is even one Wakamee who works from his sailing boat ‚õµ) Last but not least : we are nice and we have fun! (you'll find out by yourself üòâ) What happened in 2021 @Wakam?","Wakam is hiring an experienced Data Engineer/Python Developer to join their Project Data team and develop data products related to data quality, data integration, and KPIs using Python. The candidate should be proficient in Python libraries and frameworks, have a DevOps mindset, and possess strong problem-solving and collaboration skills. Wakam is a B2B insurer that creates customized insurance products for its partner distributors, and its mission is to make insurance transparent and impactful. They operate in 32 European countries and believe in a culture of freedom to impact, where everyone's ideas are valued, and every employee has a hand in transforming insurance. The company is a Soci√©t√© √† mission, which means that its raison d'√™tre (reason for being) is ingrained in its statutes.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
17,37362,https://www.welcometothejungle.com/fr/companies/addixware/jobs/data-engineer-h-f_sophia-antipolis,Data Engineer,AddixGroup,"{Azure,explosion,Python,DataBricks}",T√©l√©travail partiel possible,N,Logiciels,CDI,2022-10-18,"AddixData (ADD) fait partie du premier groupe fran√ßais d‚Äôing√©nierie informatique sp√©cialis√© dans la transformation digitale. ADD constitue l‚Äôun des 2 hub technologiques et B2B d‚ÄôAddixGroup. Il fournit des solutions et des services aux entreprises qui veulent apporter de l‚Äôintelligence √† leurs donn√©es informatiques. L‚Äôoffre Data est n√©e de l‚Äôexplosion du volume des donn√©es informatiques et du fait que nous consid√©rons qu‚Äôune donn√©e informatique d√©nu√©e d‚Äôintelligence n‚Äôa aucune valeur. Il est devenu essentiel d‚Äôen faire le tri et d‚Äôapporter de l‚Äôintelligence humaine √† toutes ces donn√©es afin de construire un monde qui soit plus vertueux. Compos√© d‚ÄôIng√©nieurs et Docteurs en Data Science, ADD r√©pond √† l‚Äôensemble des probl√©matiques li√©es √† la Data : Analyse des donn√©es, nettoyage et traitement, machine learning, business Intelligence, d√©ploiement de bases de donn√©es et int√©gration de solutions data. Nous sommes pr√©sents sur Paris, Aix-en-Provence et Sophia-Antipolis. AddixData a remport√© un projet innovant pour son partenaire sp√©cialiste de la valorisation immobili√®re. Notre client recup√®re, traite et valorise beaucoup de donn√©es provenantes de diff√©rentes sources, afin de proposer √† leurs clients des informations cl√©s des biens immobiliers, les points d‚Äôint√©r√™ts et les risques permettant √† l‚Äôacheteur de se positionner en s√©curit√© sur l‚Äôachat d‚Äôun bien. Dans ce contexte, vous intervenez en temps que Data Engineer pour piloter ce projet. Profil: Vous ma√Ætrisez DataBricks Vous connaissez Azure Python n‚Äôa pas de secret pour vous? Vous souhaitez rejoindre une √©quipe dynamique et agile ? Ce projet est fait pour vous !","AddixData is seeking a Data Engineer with expertise in DataBricks, Azure, and Python to lead an innovative project focused on real estate data processing and analysis. The ideal candidate will have experience in data cleaning, machine learning, business intelligence, and database deployment. A strong commitment to building a more virtuous world through intelligent data analysis is a must.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 4 ans,2,1,0.04154662416233763
13,72980,https://www.welcometothejungle.com/fr/companies/opteven/jobs/data-engineer-f-h_villeurbanne,Data Engineer,Opteven,"{Tableau,PostgreSQL,Jenkins,SQL}",T√©l√©travail partiel possible,"Rue Olympe de Gouges, Villeurbanne, 69100","Mobilit√©, Assurance",CDI,2023-04-22,"Soci√©t√© ind√©pendante comprenant 950 collaborateurs et repr√©sentant 278 millions d‚Äôeuros de chiffre d‚Äôaffaires, OPTEVEN (www.opteven.com) est un des acteurs majeurs en France et en Europe de l‚ÄôAssistance et de la Garantie Panne M√©canique. Notre croissance depuis plus de 10 ans sur ces deux m√©tiers d√©montre que la qualit√© de nos prestations est pl√©biscit√©e par nos clients, professionnels de l‚Äôautomobile et de l‚Äôassurance. Rejoindre OPTEVEN, c‚Äôest rejoindre une entreprise innovante, engag√©e dans la RSE et convaincue que le succ√®s d‚Äôune entreprise se fait gr√¢ce aux talents qui la composent. Pour accompagner sa croissance et son √©volution technologique, Opteven renforce sa DSI et recherche des Data Engineer F/H, rattach√©(e) au responsable du P√¥le Data/BI. Vous prenez en charge les sp√©cifications et conceptions techniques, puis la mise en oeuvre de traitements de donn√©es (√©changes, int√©gration, extraction) dans ou depuis nos syst√®mes et vous serez le r√©f√©rent sur les sujets de flux d‚Äô√©changes avec nos clients (entrants et sortants). Vous serez √©galement amen√© √† travailler ponctuellement sur l‚Äôalimentation de nos entrep√¥ts de donn√©es statistiques. Missions principales du poste : Vous concevez et d√©veloppez les flux d‚Äô√©changes inter-applicatifs au sein du SI OPTEVEN et avec les SI de ses clients/partenaires Vous analysez les impacts sur le SI, notamment sur les traitements existants, vous pr√©conisez des modalit√©s techniques d‚Äôint√©gration performantes, √† l‚Äô√©tat de l‚Äôart, et dans le respect des r√®gles de s√©curit√© d‚ÄôOPTEVEN Vous analysez les besoins en lien avec les p√¥les m√©tiers demandeurs Vous apportez une expertise technique aupr√®s des interlocuteurs internes de la DSI, vous identifiez les traitements portant des risques potentiels de performances. Vous √™tes force de proposition dans la re-engineering des cha√Ænes de traitement Vous r√©alisez des tests unitaires et recette des d√©veloppements effectu√©s Vous √™tes garant du bon fonctionnement des flux d‚Äô√©changes et assurez la supervision, le support et le maintien en condition op√©rationnelle. Vous r√©digez et enrichissez les documentations n√©cessaires √† la base de connaissance : r√©f√©rentiels, proc√©dures d‚Äôexploitation, sp√©cifications techniques, gestion d‚Äôincident. Vous √™tes en contact avec les √©quipes techniques de nos clients pour la gestion, la mise en place de flux entrants et sortants Vous √™tes en relation avec les services m√©tier internes pour r√©pondre √† leurs besoins en termes de donn√©es Vous travaillez en collaboration avec les √©quipes fonctionnelles et techniques dans le cadre de projets (lancements clients, mise en place de nouveaux r√©f√©rentiels‚Ä¶) Master en informatique avec une sp√©cialisation en gestion de donn√©es. Une premi√®re exp√©rience sur un poste √©quivalent est fortement appr√©ci√©e. Comp√©tences recherch√©es : Connaissances avanc√©es en SQL Exp√©rience de 2 √† 3 ans minimum dans le domaine du traitement et de l‚Äôint√©gration de donn√©es, avec utilisation d‚Äôun ETL Vous avez des exp√©riences d‚Äôutilisation de solutions d‚Äôordonnancement, d‚Äôoutils de ticketing Anglais professionnel √† minima Qualit√©s requises : Passionn√©(e) par la technique Adaptabilit√© Sens de la communication Rigueur Autonomie Organisation Environnement technique : ETL : Pentaho (version 5.2 et 9) Jenkins Base de donn√©es : PostgreSQL Tableau Poste en CDI OPTEVEN assure une prise en charge √† hauteur de 60% de l‚Äôabonnement des transports en commun (ou une prime de transport) Participation aux contrats mutuelle et pr√©voyance Participation et int√©ressement Carte restaurant T√©l√©travail : possibilit√© de faire jusqu‚Äô√† 2 jours/semaine une fois la p√©riode d‚Äôessai valid√©e Poste localis√© √† Lyon Villeurbanne (69) Rejoignez-nous !",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
12,72953,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer_bucharest,Data Engineer,EXTIA,"{go,GCS,Python,Scala,Hadoop,Spark,SQL,Git,GCP}",T√©l√©travail partiel possible,Bucharest,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-04-22,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. ‚ö°Then what: Mastery in Spark-SQL API (ability to use the Spark-SQL API to design optimized Spark-SQL queries for big data environments); Mastery writing Spark UDF functions using optimized algorithms designed in Scala; Mastery writing Scala/Spark-SQL applications and debuggin code written in Scala/Spark SQL; Advanced or Mastery in SQL, preffered Big Query dialect (ability to write SQL optimised queries); Experience in writing stored procedures; Advanced knowledge of the Hadoop cluster architecture and Hadoop ecosystem; Basic Python programming skills to debug CI/CD pipeline processes; Experience with Git, InteliJ or an IDE equivalent; Expertise in JSON files manipulation; Basic knowledge of the GCP infrastructure(like GCP dataproc, Big Query SQL dialect, GCS, gsutils API). üöÄ You recognize yourself in the ""Who"" and you represent the ""What""? Apply and let's talk! ‚ö°First who: Flexible, you can adapt to different people and tools, ways of working and new ideas; Passionate and thirsty to learn, you like to keep up with the IT trends; Team player, you are convinced that ‚Äúalone, we go faster, but together, we go further‚Äù;",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
11,56793,https://www.welcometothejungle.com/fr/companies/teleparis-galaxie/jobs/data-engineer_neuilly-sur-seine,Data engineer,T√©l√©paris Galaxie,"{pandas,JavaScript,SQL,Python}",T√©l√©travail partiel possible,"9, Rue du Commandant Pilot, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Edition, Presse √©crite, T√©l√©vision / Production audiovisuelle",CDI,2023-03-26,"Teleparis Galaxie est une fabrique de contenus ¬´ signature ¬ª innovants et originaux. D√©veloppement web, production et diffusion, T√©l√©paris Galaxie est un content producer √† 360¬∞ travaillant avec les groupes audiovisuels, de grandes marques, et des m√©dias digitaux ind√©pendants. Fond√© par St√©phane Simon en 1999, T√©l√©paris a commenc√© par produire des √©missions cultes pour la t√©l√©vision. Depuis sa cr√©ation, T√©l√©paris Galaxie n‚Äôa eu de cesse de se r√©inventer, d‚Äôexplorer de nouveaux territoires et d‚Äôinnover en tenant compte des nouveaux m√©dias et des nouveaux usages. Ainsi, T√©l√©paris s‚Äôest diversifi√© depuis 10 ans dans le digital (d√©veloppement de sites web et de m√©dias ind√©pendants en lignes, accompagnement digital et social etc.). Aujourd‚Äôhui, T√©l√©paris c‚Äôest aussi une factory de pr√®s de 1000 m2 proposant √† ses clients toutes les solutions de production : studios de tournage, de podcasts, montage et mixage, √©quipes de production et de r√©alisation, r√©dactions et p√¥les journalistes, teams d√©veloppement web, Social Media Management et Data analysis, fonctions supports, bureaux et co-working‚Ä¶ Toute la production de contenus est regroup√©e dans un lieu unique, T√©l√©paris studio, √† l‚Äôattention de grands comptes et de co-workers. Description : Rattach√© au p√¥le innovations mais aussi en √©troite collaboration la r√©daction et la direction, vous serez responsable du d√©veloppement et de la maintenance de l‚Äôen- semble des projets data du m√©dia. Vos principales missions : ‚Ä¢ Concevoir et d√©velopper des pipelines de donn√©es pour collecter, stocker, traiter et analyser les donn√©es √† partir de dif√©rentes sources (API, bases de donn√©es, fchiers, etc.). ‚Ä¢ Maintenir et optimiser les infrastructures de stockage et de traitement de donn√©es, y compris les bases de donn√©es SQL et les outils cloud (Google Cloud Platform, Big Query, Cloud Run, Vertex AI, etc.). ‚Ä¢ Collaborer avec les √©quipes √©ditoriales et commerciales pour comprendre leurs besoins en mati√®re de donn√©es et concevoir des solutions de reporting, de visualisation et d‚Äôanalyse adapt√©es. ‚Ä¢ Participer √† la conception de nouveaux outils pour l‚Äôentreprise en utilisant des donn√©es pour informer les d√©cisions. ‚Ä¢ √âtudes statistiques ponctuelles sur des donn√©es propri√©taires ou scrap√©es par vos soins. ‚Ä¢ Vous avez un dipl√¥me d‚Äôing√©nieur en informatique, en math√©matiques, en statistiques ou dans un domaine connexe. ‚Ä¢ Vous avez une premi√®re exp√©rience acquise au sein d‚Äôun environnement exi- geant o√π vous avez men√© √† bien des projets techniques. ‚Ä¢ Vous avez d‚Äôexcellentes comp√©tences en programmation en Python, y com- pris l‚Äôutilisation de pandas et d‚Äôautres biblioth√®ques pour l‚Äôanalyse de don- n√©es. ‚Ä¢ Vous avez de l‚Äôexp√©rience dans l‚Äôutilisation d‚ÄôAPI pour collecter des donn√©es et dans le web scraping. ‚Ä¢ Vous avez des comp√©tences en technologies cloud, des connaissances de SQL et des bases de donn√©es relationnelles, et des notions de JavaScript et de ReactJS. ‚Ä¢ Vous savez travailler de mani√®re autonome et g√©rer plusieurs projets simulta- n√©ment. ‚Ä¢ Vous avez un int√©r√™t pour les r√©seaux sociaux, les m√©dia et l‚Äôaudiovisuel. Type de contrat : CDI Salaire : selon profil Localisation : Paris","Teleparis Galaxie, a content producer, is seeking a data engineer to develop and maintain data projects across the media. The candidate should have experience with Python programming, API usage for data collection and web scraping, cloud technologies, SQL, and relational databases, as well as be able to manage multiple projects simultaneously. A degree in engineering, mathematics, statistics, or related fields is required, as well as experience working in a demanding environment. The position is a full-time contract in Paris.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
8,72905,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_a7WPg97,Data Engineer,FACILECOMM (SHIPPINGBO),"{Pandas,PostgreSQL,R,Airflow,AWS,Redis,SQL,MongoDB,Redshift}",T√©l√©travail partiel possible,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-04-22,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait men√©(e) jusqu‚Äô√† cette annonce ! Peut-√™tre est-ce toi, le/la futur(e) Data Engineer que nous attendons‚Ä¶ En tout cas, nous l‚Äôesp√©rons. Dans un premier temps, permets nous de nous pr√©senter. Qui est Shippingbo ? La premi√®re chose que tu dois te demander c‚Äôest ‚Äúqui est Shippingbo‚Äù et c‚Äôest une tr√®s bonne question ! Shippingbo est une technologie logistique e-commerce fond√©e en 2016, par la soci√©t√© facilecomm. Nous mettons √† disposition des vendeurs en ligne une technologie qui leur permet d‚Äôoptimiser toute leur cha√Æne logistique : depuis la r√©cup√©ration des commandes, jusqu‚Äô√† leur exp√©dition, en passant par la pr√©paration. Pour la faire tr√®s simple, on est la technologie de l‚Äôombre qui permet √† ton site favori de te livrer dans les meilleurs d√©lais, tout en te notifiant de l‚Äôavanc√©e de ta commande. Pas mal, non ? Notre ambition : permettre √† nos clients de proposer aux consommateurs un parcours d‚Äôachat au top, digne des g√©ants du e-commerce ! Aujourd‚Äôhui, nous comptons pas moins de 1000 clients aux activit√©s e-commerce assez vari√©es : e-commer√ßants, retailers, fournisseurs, grossistes‚Ä¶. mais dont le point commun reste la vente en ligne ! Avec pr√®s de 72% de croissance en 2021 et plus d‚Äô1 milliard d‚Äôeuros de GMV, nous sommes bien d√©cid√©s √† poursuivre sur cette lanc√©e pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage europ√©en d‚Äôici 3 ans ! Shippingbo cherche aujourd‚Äôhui √† d√©velopper les outils d‚Äôanalyse qu‚Äôelle met √† disposition de ses clients ainsi qu‚Äô√† d√©velopper de nouvelles fonctionnalit√©s se fondant sur l‚Äôanalyse des donn√©es. En tant que data engineer, votre r√¥le sera de construire et maintenir les entrep√¥ts et pipelines de donn√©es. Vos missions principales consisteront √† : Participer √† la d√©finition des sch√©mas de donn√©es et aux choix d‚Äôarchitecture ; D√©finir et optimiser les requ√™tes fa√Ætes par l‚ÄôAPI et celles au c≈ìur des pipelines ; Pr√©parer des datasets exploitables √† des fins d‚Äôanalyse ; Identifier de facon plus g√©n√©rale les moyens optimaux de r√©pondre √† l‚Äôensemble des requ√™tes de donn√©es ; Optimiser √©galement le fonctionnement des pipelines et maintenir les syst√®mes surveillant leur bon fonctionnement et la qualit√© des donn√©es ; Participer √† l‚Äôadministration, la configuration et le param√©trage des bases de donn√©es. - Vous avez au moins 2 ans d‚Äôexp√©rience comme data engineer (ou des r√¥les similaires) et dans la construction et la maintenance de pipelines de donn√©es ; - Vous avez une connaissance approfondie de SQL , de l‚Äôoptimisation de requ√™tes et des entrep√¥ts de donn√©es ; - Vous avez une exp√©rience avec au moins une base de donn√©e orient√©e colonnes ; - Id√©alement vous avez √©galement une exp√©rience avec une base de donn√©e orient√©e documents et une base de donn√©e cl√©-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en m√©tro, arr√™t Ramonville) Rattach√© au d√©partement R&D de l'entreprise Mise √† disposition d‚Äôoutils informatiques Tickets restaurant >>> Venez d√©couvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversit√© occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'√©galit√© professionnelle et l'emploi des travailleurs en situation de handicap. A comp√©tences √©quivalentes, ce poste est ouvert √† tous.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
7,56972,https://www.welcometothejungle.com/fr/companies/yassir/jobs/data-science_paris,Data Science Engineer (f/m/x),Yassir,"{color,Shell,SQL,Python}",T√©l√©travail partiel possible,"128, Rue La Bo√©tie, Paris, 75008","Application mobile, Intelligence artificielle / Machine Learning, Mobilit√©",CDI,2023-03-26,"Yassir is the leading super App for on demand, ride-hailing, last-mile delivery, payment services and more, set to change the way daily services are provided. It currently operates in 45 cities across multiple countries. It has raised $150 million in Series B funding, five times what it raised in its previous priced round last November with world class investors such as BOND and Y Combinator, which is the precursor of the likes of Airbnb, Stripe, Dropbox, Doordash, among others. We offer on-demand services such as ride-hailing and last-mile delivery. Building on this infrastructure, we are now introducing financial services to help our users pay, save and borrow digitally. Helping usher the continent into a digital economy era. We‚Äôre not just about serving people - we‚Äôre about creating a marketplace to bring people what they need while infusing social values. About Yassir Yassir is the leading super App for on demand, ride-hailing, last-mile delivery, payment services and more, set to change the way daily services are provided. It currently operates in 45 cities across multiple countries. It has raised $150 million in Series B funding, five times what it raised in its previous priced round last November with world class investors such as BOND and Y Combinator, which is the precursor of the likes of Airbnb, Stripe, Dropbox, Doordash, among others. We‚Äôre not just about serving people - we‚Äôre about creating a marketplace to bring people what they need while infusing social values. Global context and problematic of the subject Recent progress in the field of deep learning has led to major advances in Natural Language Processing (NLP). Among its most complex tasks, sentiment analysis has also made great progress thanks to the possibility of training efficient neural models for understanding languages using dialogue data collected from different outlets (emails, SMS, comments, question answering, booking an event, etc.). However, these models are still very limited when it comes to providing accurate results when analysing the Arabic language [1]. Arabic is a category IV language in parameters of complexity and difficulty to learn [2] and has a high ability for new word formations with rich semantic meanings [3]. Progress is being made regarding this when it comes to standard arabic, some dialects that are more or less formal (Gulf Peninsular, Levantine, and Egyptian) [4]. However, none are made when it comes to Maghreb dialect (Morocco, Algeria, Tunisia)[4]. Scientific objective - results and obstacles to be overcome The objective of the thesis is to propose solutions to mutualise natural language understanding and sentiment analysis, that is to study the progressive fusion of various tasks mixing language diarization and language transliteration for Arabic representation or manipulation. The context of application will first be that of dialect written only in Arabic, then that of full form dialect with both latin and arabic characters and word from different languages. The focus will be on the development of original and efficient learning strategies for the construction of these multi-task neural models, rather than testing existing models blindly. Among these strategies, the use of prompting techniques as well as attention models is highly anticipated [5-7]. The work will be based on local corpora developed using comments extracted from the different apps of YASSIR. In this respect, one of the main obstacles is labeling this data in meaningful way within the learning process, both in terms of the given sentiment and transliteration. About your experience Deep learning, machine learning Natural language processing Python, Shell SQL Optionally, knowledge extraction and management or graph databases Google Cloud Platform Good communication in English, both oral and written Education required (Master's degree, engineering degree, PhD, scientific and technical field, etc.) Degree: Master's degree or engineering degree Field: Computer science or apple math with a focus on machine learning Interested candidate need to send their transcripts from the last year of study (Master 2) and at least 3 reference contacts (e-mail and phone number) preferably of teacher/supervisor who are experts in the fields of machine learning, artificial intelligence or natural language processing. References M. Al-Ayyoub, A. A. Khamaiseh, Y. Jararweh, and M. N. Al-Kabi, ‚ÄúA comprehensive survey of arabic sentiment analysis,‚Äù Information Processing & Management, vol. 56, no. 2. Elsevier BV, pp. 320‚Äì342, Mar. 2019. doi: 10.1016/j.ipm.2018.07.006. Foreign Service Institute (FSI). 2021. Foreign Language Training. URL https://www.state.gov/foreign-language-training/ . K. Shaalan, S. Siddiqui, M. Alkhatib, and A. Abdel Monem, ‚ÄúChallenges in Arabic Natural Language Processing,‚Äù Computational Linguistics, Speech and Image Processing for Arabic Language. WORLD SCIENTIFIC, pp. 59‚Äì83, Sep. 19, 2018. doi: 10.1142/9789813229396_0003. K. Meftouh, K. Smaili, and Nadjette Bouchemal, ‚ÄúA study of non-resourced language: the case of an Algerian dialect,‚Äù The third International Workshop on Spoken Languages Tech-nologies for Under-resourced Languages , vol12. 1-7. 2012, doi: 10.13140/RG.2.1.4881.1041. Liu, H., Paola Garcia Perera, L., Zhang, X., Dauwels, J., H Khong, A. W., Khudanpur, S., & Styles, S. J. (2021). End-to-End Language Diarization for Bilingual Code-Switching Speech . https://doi.org/10.21437/Interspeech.2021-82 Chowdhury, S. A., Hussein, A., Abdelali, A., & Ali, A. (2021). Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR . https://doi.org/10.21437/Interspeech.2021-1809 Jia, Y., Zen, H., Shen, J., Zhang, Y., & Wu, Y. (2021). PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS . https://doi.org/10.21437/Interspeech.2021-1757 Process Candidates will be evaluated in 4 steps (no expectations are made) Phone interview/screening Technical interview with our applied researcher Programming assignment, candidates need to read a paper and implement it. Reviewing the programming assignment. *As a company, we are passionate about diversity and inclusion, 40% of our team are women leaders in the tech sector. Research shows that women do not apply for jobs if they do not meet all of the requirements. We would like to hear from you if you feel you would be a good fit for us! Do you want to become part of our first-class team? Then you absolutely have to send us your application. üöÄ PS: And if you want to stand out in your application, just let us know in your cover letter why we should have in our team. üí° Diversity & Inclusion & Engagement: We celebrate diversity and are committed to creating an inclusive environment for all employees, as we believe diverse teams are more successful in the long term. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, and we encourage all people equally to apply for jobs with us.","Yassir, a super app for on-demand services, is seeking a candidate with experience in deep learning, machine learning, natural language processing, Python, Shell, and SQL for a thesis project focused on sentiment analysis and natural language understanding in Arabic. The objective is to build multi-task neural models for Arabic representation and manipulation using local corpora collected from Yassir's apps. The company highlights its commitment to diversity and inclusion and encourages all qualified candidates to apply.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
5,57012,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_z7WGAV0,Data Engineer,EXTIA,"{Microsoft,Jenkins,Git,Scala,Airflow,Kubernetes,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,Paris,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-03-26,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Maitrise de l‚Äô√©cosyst√®me Microsoft Azure Data Factory, Azure Data Lake est un plus Maitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala‚Ä¶ Maitrise des bonnes pratiques de d√©veloppement et m√©thodes agiles Base de donn√©es : SQL, Postgr√© SQL (Paas) et mod√©lisation de la donn√©e Connaissance des syst√®mes de gestionnaire de conteneur (Kubernetes,‚Ä¶) Connaissance des outils de d√©ploiements : Jenkins, Git, maven, Ansible Qualit√©s relationnelles et capacit√© √† g√©rer nombreuses interactions Dynamisme, autonomie et envie de d√©couvrir des mani√®res diff√©rentes/innovantes de faire #LI-MV2 Rigoureux , vous ne laissez rien au hasard, Efficace , vous ne remettez pas √† demain ce qui peut √™tre fait d√®s aujourd‚Äôhui, Autonome , vous savez mener vos missions √† bien sans aide","Extia, an IT, digital, and engineering consulting firm, is looking for a candidate proficient in Microsoft Azure Data Factory, Azure Data Lake, and IT technologies such as Power BI, Spark, Airflow, Python, and Scala. The ideal candidate should also have adequate knowledge about Kubernetes, Jenkins, Git, maven, and Ansible. The skills required for this role include good communication skills, the ability to manage multiple interactions, rigor, efficiency, and autonomy.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
2,57011,https://www.welcometothejungle.com/fr/companies/devoteam-revolve/jobs/data-engineer-experimente-h-f,Data Engineer exp√©riment√©,Devoteam Revolve,"{UNIX,DynamoDB,Glue,Lambda,Snowflake,Azure,Docker,MLlib,EC2,Kinesis,Athena,Databricks,GitLab,PowerBI,QlikView,Kafka,Linux,Git,PyTorch,linux,ElasticSearch,Jenkins,Keras,Kubernetes,AWS,Java,D3,SQL,Hadoop,Tensorflow,EMR,Scala,Redshift,Airflow,S3,Spark,GCP,Python,Tableau}",T√©l√©travail partiel possible,Paris,"IT / Digital, SaaS / Cloud Services",CDI,2023-03-26,"Nous sommes une communaut√© d‚Äôexplorateurs et d‚Äôexploratrices en constant apprentissage ! Le savoir et le partage sont au c≈ìur de notre raison d‚Äô√™tre. Une carri√®re chez Devoteam Revolve, c‚Äôest tracer une trajectoire qui vous permet de donner le meilleur de vous-m√™me et de r√©v√©ler vos singularit√©s. Nous pensons notre organisation au quotidien pour permettre √† nos collaboratrices et collaborateurs de produire du savoir sur les nouvelles pratiques et les nouveaux usages apport√©s par la technologie. Le d√©bat et la curiosit√© intellectuelle qui nous caract√©risent nous permettent de toujours repenser nos actions et d‚Äôam√©liorer notre savoir-faire et savoir-√™tre. Nous sommes convaincus que la technologie n‚Äôest pas neutre et qu‚Äôil est vital d‚Äôapporter du sens et de l‚Äô√©thique dans notre fa√ßon de travailler en prenant en compte les enjeux soci√©taux et environnementaux auxquels nous devons faire face. En constant mouvement, nous gravitons dans des √©cosyst√®mes hyper technologiques toujours en √©volution. Notre projet concr√©tise les r√©flexions sur le sens que nous souhaitons donner √† la technologie et notre volont√© de lutter contre les raccourcis intellectuels et de proposer des alternatives. Et pour cela, nous avons besoin de vous ! Si vous √™tes int√©ress√©¬∑e d‚Äôint√©grer une √©quipe qui challenge ses pratiques et r√©v√®le les singularit√©s de chaque membre de notre collectif, alors cette annonce est faite pour vous ! Envie de rejoindre une √©quipe de ‚Äúbuilders‚Äù qui travaillent sur de vrais projets de Data en production et √† l‚Äô√©chelle ? Vous √™tes au bon endroit ! Vous avez au moins 2 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶) dans un context agile Vous disposez de solides connaissances sur les architectures de donn√©es et les environnements cloud (GCP, Azure, AWS‚Ä¶) Vous disposez d‚Äôune exp√©rience en visualisation de donn√©es (PowerBI, Tableau, QlikView, D3.js‚Ä¶) Vous ma√Ætrisez au moins un langage de programmation sp√©cifique (Spark, Scala, Python, Java, SQL) Vous ma√Ætrisez des syst√®mes d‚Äôexploitation (UNIX, Linux, Solaris ) avec une expertise dans le stockage de donn√©es et les outils ETL. Vous avez une bonne culture DevOps, une bonne communication op√©rationnelle et une forte capacit√© d‚Äôadaptation. Vous √™tes conscient¬∑e de la valeur que peut apporter l‚Äôautomatisation. Vous √™tes convaincue par la culture Data, Cloud, tech et souhaitez affirmer vos convictions. Vous cultivez votre savoir faire, et cherchez constamment de meilleures mani√®res de faire et votre volont√© de la partager avec les autres n‚Äôa pas de limite. L‚Äôorganisation, la rigueur, l‚Äôautonomie font partie de vos qualit√©s tout comme l‚Äô√©coute et le partage. Vous ma√Ætrisez √©galement l‚Äôanglais √† l‚Äôoral comme √† l‚Äô√©crit. Voici une liste non exhaustive de vos missions au quotidien, nous vous faisons confiance pour les prendre en main et les enrichir √† votre fa√ßon : Participer √† des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions h√©berg√©es sur une architecture AWS (Snowflake, Databricks, etc.) D√©velopper et automatiser des pipelines d‚Äôingestion de donn√©es avec des layers de traitement dans les technologies ad√©quates ( Python,, Spark, Kafka) Industrialiser des algorithmes de Data Science Concevoir des sch√©mas de donn√©es extensibles et g√©n√©riques pour r√©pondre √† des besoins de reporting ou autre (SQL) D√©velopper des applications custom sur la base de composants g√©n√©riques existants pour r√©pondre √† des besoins client (sc√©narisation, suivi d‚Äôentra√Ænement de mod√®les pr√©dictifs et d‚ÄôIA, reporting, etc. Encadrer et superviser les consultant(es) juniors i.e., peer code review, application des best practices. Accompagner notre √©quipe commerciale sur la r√©daction de propositions et des r√©unions d‚Äôavant-vente. Participer au d√©veloppement de notre communaut√© interne (REX, workshops, articles, hackerspace. Participer au recrutement de nos futurs talents. Comp√©tences techniques requises : La liste des technologies sur lesquelles vous seriez amen√© √† travailler est la suivante : Python, PySpark ou Scala Spark. Scikit-learn, MLlib, Tensorflow, Keras, PyTorch ,LightGBM, XGBoost, Scikit-Learn et Spark (pour ne citer qu‚Äôeux) Les architectures Data et les environnements Hadoop, ElasticSearch, Kafka notamment. La stack AWS Big Data (Step Function, Lambda, ECR, S3, EC2, Code Build, Glue, outils d‚Äôautomatisation et Devops, EMR, Redshift, Athena) Mise en place des environnements DevOps et Infra As Code Une bonne partie des outils Git, GitLab CI, Jenkins, Ansible, Terraform, Docker, Kubernetes, ML Flow, Airflow ou leurs √©quivalents dans les environnements Cloud. Bon √† savoir : Revolve training est notre centre de formation permettant √† toutes et tous de pouvoir suivre des formations et monter en comp√©tence. Les Revolvers peuvent, au-del√† de leurs missions, contribuer √† Gravity, notre centre de recherche contributive qui explore les sujets li√©s √† la sobri√©t√© num√©rique, l‚Äô√©thique de la technologie, la souverainet√© num√©rique, le machine learning au service de l‚Äô√©cologie, ou tout autre projet susceptible de faire progresser la communaut√© et ses pratiques. Flexibilit√© : Le t√©l√©travail fait partie du quotidien des collaboratrices et collaborateurs. Une mutuelle attractive La possibilit√© de choisir son mat√©riel (mac, windows, linux, smartphone‚Ä¶). Une participation annuelle aux frais de transports Une carte ticket restaurant Offre exclusive Meyclub Ce qui fait la diff√©rence chez Devoteam Revolve, c‚Äôest notre fa√ßon de : Partager ouvertement, largement et d√©lib√©r√©ment les informations. Encourager les prises de d√©cision autonomes de la part des collaborateurs et collaboratrices. Ne collaborer sur le long terme qu‚Äôavec des collaborateurs et collaboratrices hautement comp√©tent¬∑es et ayant un impact positif sur le collectif. Toujours rechercher une ‚Äúmeilleure fa√ßon‚Äù de faire les choses. √ätre ouvert¬∑e d‚Äôesprit aux id√©es changeantes et aux approches nouvelles. Le processus de recrutement se d√©roule en trois √©tapes : Entretien RH pour apprendre √† vous connaitre et comprendre votre projet professionnel ainsi que pour vous pr√©senter l‚Äôentreprise et notre vision. Entretien Technique pour faire le bilan sur vos comp√©tences et votre coh√©rence sur le poste. Entretien avec la direction pour se projeter ensemble sur votre trajectoire professionnelle au sein de Devoteam Revolve. Devoteam Revolve s‚Äôengage √† promouvoir la diversit√© et est fier de favoriser l‚Äô√©galit√© des chances au sein de l‚Äôentreprise. Chaque candidature est consid√©r√©e sans tenir compte de l‚Äôorigine, de la couleur de peau, de la religion, du genre, de l‚Äôidentit√© de genre, de l‚Äôorientation sexuelle, du handicap, des caract√©ristiques g√©n√©tiques ou de l‚Äô√¢ge. Parce que nous voulons que le savoir soit utile au plus grand nombre, nous croyons √† l‚Äôinclusion de toutes et tous.","Devoteam Revolve seeks a data engineer with a minimum of two years of experience in data engineering, solid knowledge of data architectures and cloud environments such as GCP, Azure, and AWS, and experience in data visualization with PowerBI, Tableau, QlikView, or D3.js. The company values DevOps culture, automation, and ethical considerations and expects the candidate to have expertise in programming languages such as Spark, Scala, Python, Java, or SQL, as well as storage and ETL tools. The ideal candidate must also have strong communication skills, autonomy, problem-solving aptitude, and a willingness to develop new skills and share knowledge. The company offers online training programs and grants access to research projects centered around digital sobriety, ethical technology, digital sovereignty, and machine learning for ecology. Devoteam Revolve is committed to promoting diversity, equity, and inclusion in its recruitment practices.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
31,67534,https://www.welcometothejungle.com/fr/companies/amazon-operations/jobs/data-center-engineering-operations-intern-m-f-d_paris,Data Center Engineering Operations Intern,Amazon Operations,{AWS},T√©l√©travail partiel possible,Paris,"Ing√©nieries Sp√©cialis√©es, Supply Chain, E-commerce",CDI,2023-04-07,"Vous connaissez s√ªrement Amazon, mais connaissez-vous Amazon Op√©rations ? C‚Äôest la branche op√©rationnelle d‚ÄôAmazon, le c≈ìur de son activit√© logistique. Amazon Op√©rations, c‚Äôest des proc√©d√©s parmi les plus avanc√©s au monde, des technologies toujours plus novatrices et une excellence op√©rationnelle qui permet de livrer efficacement les clients. Chez Amazon Op√©rations, les √©quipes sont engag√©es et guid√©es par des valeurs communes. C‚Äôest ce que vous retrouverez sur l‚Äôensemble de leurs sites en France. Job summary Amazon Web Services (AWS) is growing rapidly, and we are looking for Data Center Engineering Operations Technician Interns to join our expanding Infrastructure Operations team in a 3 months' Fulltime internship program in our Data Center in Paris. This internship covers mandatory as well as voluntary university internships, please inform us which of the two you are aiming to pursue. As an AWS Intern, you will collaborate with experienced Amazon Technicians to ensure that the Data Center's mechanical, electrical and plumbing operates at 100% availability while maintaining first-class customer service to the teams and groups within the data centers. You will be tasked with driving innovation while reducing operational costs in the facilities. The Engineering Operations team is Amazon‚Äôs front-line responders for hands-on electrical and mechanical equipment troubleshooting and operations. you will work with equipment that supports mission-critical servers and must maintain better than 99.999% uptime. This equipment includes, but is not limited to, stand-by diesel generators, switchgear, UPS‚Äôs, PDU‚Äôs, AHU‚Äôs, chillers, cooling towers, chemical treatment systems, pumps, motors, VFD‚Äôs, and building automation systems. Upon successful completion of the internship program, you will receive an offer as a permanent EOT. Are you ready to embrace the challenge? Come build the future with us. Key job responsibilities Maintain mechanical and electrical equipment Assist root cause analysis of equipment failures Assist in troubleshooting of facility and rack-level events within internal SLA Take daily operational readings of all mechanical and electrical equipment Utilize internal CMMS to manage building workflows Previous facilities or data center operations experience Amazon est un employeur engag√© pour l'√©galit√© des chances. Nous sommes convaincus qu'une main d'oeuvre diversif√©e est essentielle √† notre r√©ussite. Nous prenons nos d√©cisions de recrutement en fonction de votre exp√©rience et de vos comp√©tences. Nous appr√©cions votre envie de d√©couvrir, d'inventer, de simplifier et de construire. La protection de votre vie priv√©e et la s√©curit√© de vos donn√©es constituent depuis longtemps une priorit√© absolue pour Amazon. Veuillez consulter notre Politique de Confidentialit√© pour en savoir plus sur la fa√ßon dont nous collectons, utilisons et traitons les donn√©es personnelles de nos candidats.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
32,67595,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risks-f-h-cio-cib_paris_NATIX_rw4gg9,Data Engineer Risks  CIO CIB,Natixis,"{scala,java,Jenkins,spark,Scala,via,Spark,Java,Hadoop}",T√©l√©travail partiel possible,"CHARENTON-LE-PONT, Paris, 94220","Banque, Transformation, Assurance",CDI,2023-04-07,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de votre √¢ge, origine, orientation sexuelle, handicap... Au sein du p√¥le CIO CIB (Corporate & Investment Banking), dans le d√©partement Risks, vous rejoignez l'√©quipe DPM/Metrics Services, en tant que data engineer. Vous reportez directement au responsable de l'√©quipe Metrics Services, des √©volutions du composant de l'application ¬´ golden data ¬ª et des PV de Stress Tests. Ce composant est la clef de vo√ªte d'une chaine applicative FO to Risk pilot√©e par le programme SUNRISE. Au quotidien, vous avez pour missions de : Assurer l'√©volution de l'application d√©velopp√©e en spark/scala/java sur plateforme Hadoop dans un contexte projet ; Piloter des sujets multi-syst√®mes (r√©f√©rentiel market data, r√©f√©rentiel instrument, pricers front) ; G√©rer l'industrialisation et la mise en qualit√© des donn√©es ; Faire la coordination avec : les business analyst de l'√©quipe, les autres √©quipes de d√©veloppeurs du programme et les autres √©quipes IT (production applicative, infrastructure, support Hadoop) ; Assurer le support de niveau 2. La stack technique utilis√©e est la suivante : Java, Spark/Scala et Hadoop dans un environnement DevOps. Nous travaillons en m√©thode Agile (SAFe) et vous serez int√©gr√© √† notre communaut√© de data engineers. #MuchMoreThanJustAJob Ce poste est bas√© √† Paris avec la possibilit√© de t√©l√©travailler. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de leur √¢ge, origine, orientation sexuelle, handicap... A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure, vous avez au moins 10 ans d'exp√©rience en tant que data engineer dans le domaine fonctionnel de la finance de march√© (type DSI). Vous maitrisez : * les probl√©matiques d'optimisation de performance et vous proposez des solutions innovantes ; * la mise en place des protocoles de s√©curit√© dans des environnements de d√©veloppement ; * les langages Java et Hadoop ; * les bases du DevOps (int√©gration continue/automatisation, Jenkins, Sonar, XLDeploy, XLRelease ‚Ä¶) ; * la m√©thode Agile (SAFe). Vous √™tes : * passionn√© d'IT et data centric, vous souhaitez d√©velopper une v√©ritable expertise technique sur des projets innovants. Vous maitrisez l'anglais avec un niveau B2 minimum. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.",,Bac +5 / Master,> 2000 salari√©s,> 7 ans,2,1,0.04154662416233763
34,56721,https://www.welcometothejungle.com/fr/companies/directfamily/jobs/datovy-analytik-data-engineer_brnopraha-7_DF_4LoWXL0,Datov√Ω analytik/Data Engineer,Direct Family,"{Python,Kubernetes,AWS,postgreSQL,Argo,GIT}",T√©l√©travail partiel possible,Brnopraha 7,"Application mobile, Mobilit√©, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Direct family je prostor, jeho≈æ souƒç√°st√≠ jsou firmy Direct poji≈°≈•ovna, Direct Fidoo, Direct auto a Direct nadace, kter√© vznikly, aby mƒõnily svƒõt kolem sebe k lep≈°√≠mu. Je to m√≠sto, kde mohou svobodnƒõ tvo≈ôit, pracovat a posouvat vƒõci, kter√© maj√≠ pozitivn√≠ dopad na prostor, ve kter√©m ≈æijeme. Zaj√≠m√° tƒõ, jak prob√≠h√° anal√Ωza hlasov√Ωch slu≈æeb, obrazov√Ωch dat nebo anal√Ωza chovan√≠ u≈æivatel≈Ø pomoc√≠ umƒõl√© inteligence? Budovan√≠ datov√Ωch pipelines v cloudu? Sleduje≈° novinky v oblasti zpracov√°n√≠ dat? Bav√≠ tƒõ tvo≈ôit nov√© vƒõci a p≈ôem√Ω≈°let out-of-the-box? Chce≈° zanechat stopu a zmƒõnit fungov√°n√≠ v nejrychleji rostouc√≠ poji≈°≈•ovnƒõ na ƒçesk√©m trhu. Pak hled√°me pr√°vƒõ tebe! Co tƒõ u n√°s ƒçek√°? Aktivn√≠ spolupr√°ce s t√Ωmem Advanced Analytics a budov√°n√≠ datov√Ωch pipelines. V√Ωvoj a spr√°va orchestrace datov√Ωch tok≈Ø. Pr√°ce se zaj√≠mav√Ωmi daty a spolupr√°ce nad projekty nejen z oblasti poji≈°≈•ovnictv√≠. Integrace extern√≠ch dat, pr√°ce s REST API. Jak si tƒõ p≈ôedstavujeme?‚Äã M√°≈° za sebou alespo≈à rok v√Ωvoje v jazyce Python a rozum√≠≈° z√°klad≈Øm programov√°n√≠. Verzov√°n√≠m k√≥du pomoc√≠ GIT n√°stroj≈Ø pro tebe nen√≠ ≈æ√°dn√Ω probl√©m. M√°≈° nad≈°en√≠ pro data a um√≠≈° samostatnƒõ a systematicky plnit √∫koly. R√°d se uƒç√≠≈° nov√© technologie a chce≈° tvo≈ôit prostƒõ to nejlep≈°√≠. CI/CD nejsou pro tebe zkratky hudebn√≠ skupiny. Zku≈°enosti s Kubernetes, Argo, TeamCity v√Ωhodou. Rozum√≠≈° datov√Ωm typ≈Øm, um√≠≈° si transformovat data, pr√°ce s relaƒçn√≠mi datab√°zemi je tv≈Øj denn√≠ chl√©b. Znalost MSSQL, postgreSQL v√Ωhodou. Znalost AWS v√Ωhodou. M√°≈° r√°d v√Ωzvy a r√°d se rozv√≠j√≠≈°.","Direct family is seeking a Data Engineer with at least one year of experience in Python development and basic programming skills to work with the Advanced Analytics team in building data pipelines in the cloud, integrating external data, and working with REST APIs. The ideal candidate should have a passion for data and be able to work independently and systematically on tasks, as well as continuously learn new technologies. Experience with Kubernetes, Argo, and TeamCity is a plus, as is familiarity with MSSQL, postgreSQL, and AWS.",Sans dipl√¥me,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
56,73347,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-engineer-cloud-f-h_toulouse_CG_eV3RDoQ,Data Engineer Cloud -,CS GROUP,"{IAM,Python,Cassandra,AWS,dynamoDB,Scala,Grafana,EC2,HBase,Java,Hadoop,Spark,Docker,Kubernetes,Airflow,SQL,S3,MongoDB}",T√©l√©travail partiel possible,"6 Rue Emmanuel Arin, Toulouse, 31300","Ing√©nieries Sp√©cialis√©es, A√©ronautique / Spatiale, Energie",CDI,2023-04-22,"La mission de CS GROUP : √™tre √† la pointe des technologies pour garantir la s√©curit√© de tous dans un monde en pleine mutation. L‚Äôexpertise reconnue de CS GROUP lui permet d‚Äôintervenir l√† o√π les enjeux de s√©curit√© sont les plus sensibles : d√©fense, spatial, a√©ronautique, √©nergie‚Ä¶ Et, aussi, l√† o√π les r√©ponses sont √† inventer ou √† r√©inventer: lutte anti-drone, cybers√©curit√©, traitement de donn√©es satellitaire‚Ä¶ Le positionnement de CS GROUP en fait un acteur unique sur son march√© : son expertise technique se combine avec une forte affinit√© avec les m√©tiers de ses clients. √Ä la cl√©, un capital confiance qui lui ouvre les portes d‚Äôun fort d√©veloppement partout dans le monde pour des interventions tout au long de la cha√Æne de valeur. Conseil, conception, d√©veloppement, int√©gration, maintenance et support aux op√©rations‚Ä¶ Nous recrutons un.e Ing√©nieur Data Engineer Cloud pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data & Process Intelligence . Elle accompagne nos clients dans leurs probl√©matiques associ√©es √† la transformation digitale. Nos offres se d√©clinent autour de la data intelligence & de la maintenance pr√©dictive, de la digitalisation des processus industriels et du SI M√©tiers. Votre mission : Dans le cadre de projets, vous rejoindrez notre √©quipe et participerez aux missions suivantes : Concevoir et d√©velopper des outils de traitements et processing de donn√©es - D√©ploiement, industrialisation et tests de solutions d√©velopp√©es, - Monitoring et analyse de flux de donn√©es. - R√©diger les rapports d‚Äôanalyse de donn√©es, et assurer la pr√©sentation au client - Savoir utiliser les outils d'analyse et de visualisation de donn√©es - Environnement cloud L‚Äôenvironnement technique : Bases de Donn√©es : AWS RDS, No SQL, MongoDB, Apache Cassandra, HBase et Amazon dynamoDB Framework : Hadoop, Hortonworks, Spark, Airflow Outils de containerisation : Docker / Kubernetes Cloud computing: AWS (IAM, S3, EC2, etc.) ou √©quivalent chez un autre fournisseur de services cloud Langages: Java, Python, Scala Visualisation : Dash, Grafana, Python Qui √™tes-vous ? De formation Bac+5, vous avez une premi√®re exp√©rience en Data Engineering , id√©alement dans le secteur a√©ronautique. La connaissance des techniques et outils de traitement de la donn√©e en Python , Spark/Hadoop dans un environnement cloud vous sera demand√© dans l‚Äôexercice de votre fonction. L'utilisation d'outil de data mining et analyse de donn√©es serait un plus. Un niveau d‚Äôanglais courant est requis. Vous √™tes autonome et vous savez faire preuve de capacit√© d‚Äôanalyse ? Vous √™tes bon communiquant et cr√©atif ? Alors vous √™tes la p√©pite que nous recherchons ! A comp√©tences √©gales, ce poste est ouvert aux personnes en situation de handicap.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
70,56369,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-engineering-manager-data-solutions-f-m-d_paris,Data Engineering Manager - Data Solutions,Decathlon Digital,"{GCP,AWS}",T√©l√©travail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOINS LES EQUIPES DATA DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Au sein de cette entit√© Data, nous recherchons un¬∑e Data Engineering Manager en CDI. Tu piloteras les comp√©tences de l'√©quipe et seras responsable de la bonne d√©livrabilit√© des solutions techniques li√©es √† vos Data domains (ex : supply chain, sport et process, retail, sustainability ...) Le poste est bas√©, au choix √† Paris, Lille, Lyon ou Nantes (pr√©voir des d√©placements r√©guliers sur Lille) TES RESPONSABILITES Comprendre les besoins remont√©s pas les diff√©rents utilisateurs des solution de ton data domaine En collaboration avec les autres √©quipes de D√©cathlon, concevoir et proposer les solutions data r√©pondant √† ces besoins Mettre en place ces solutions Assurer la d√©livrabilit√©, la maintenance, l‚Äô√©volution et le maintien en condition op√©rationnel des solutions data sous ta responsabilit√© TA MISSION : Tu es responsable de l‚Äôarchitecture et l'op√©rabilit√© des solutions data de ton domaine d‚Äôactivit√©. Tu es responsable des engagements de d√©livrabilit√© de ton √©quipe En tant que responsable de l'ing√©nierie data de ton domaine, tu construis, coaches et soutiens ton √©quipe pour qu'elle grandisse et soit performante. Tu alignes ton √©quipe et les autres √©quipes data autour des choix techniques et des bonnes pratiques applicables aux fonctionnalit√©s sur lesquelles elle travaille. Tu t‚Äôassures que ton √©quipe comprenne et suive les directives de l'entreprise (outils, langues, s√©curit√©, etc.) Tu recrutes les meilleurs Talents en fonction des besoins de notre √©cosyst√®me. Tu g√®res l‚Äò√©volution professionnelle et le bien √™tre au travail de tes collaborateurs. Tu m√®nes des revues de talents et les entretiens r√©guliers pour assurer la performance de l'√©quipe et les aider √† atteindre l'excellence. Tu co-construis avec les autres leaders notre data Factory Tu es responsable du maintien en condition op√©rationnelle des solutions mises en place. Tu challenges les strat√©gies techniques transversales et partages la vision dans ton domaine d'expertise. Tu connais les techniques de conduite de projets et d‚Äôanimation de produit en mode agile, et tu pilotes ton √©quipe au travers de cette m√©thode. CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu es hands on et reconnu-e en tant que data ing√©nieur-e ; Tu as 2 ans d'exp√©rience minimum dans l‚Äôencadrement direct d‚Äôing√©nieur-e-s ( Data engineer/Ops/DevOps/ DataOps). Tu as une solide exp√©rience dans l‚Äôenvironnement agile et tu es capable d‚Äôaccompagner des collaborateurs dans ce contexte. Tu as un exp√©rience √©prouv√©e dans le run d‚Äôun ou plusieurs produits data. Tu aimes d√©velopper et faire grandir tes collaborateurs¬∑trices. Tu as un int√©r√™t pour le pilotage √©conomique. Tu comprends le cycle de vie de la donn√©e et tu es √† l‚Äôaise avec les concepts de data lineage, data gouvernance et data privacy. Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et l‚Äôanimation de tes √©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien","Decathlon is seeking a Data Engineering Manager to lead and manage the team responsible for delivering technical solutions related to various data domains. The ideal candidate should have a minimum of two years of experience mentoring direct engineering teams, a solid background in agile environments, and proven experience in running one or more data products. Other requirements include a passion for developing and mentoring team members, a strong interest in economic management, and familiarity with data governance, lineage, and privacy. This position is available in Paris, Lille, Lyon, or Nantes, with regular travel to Lille. Decathlon offers two days of remote work per week, international exposure, and opportunities for professional growth and certification.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
69,56411,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-engineer_paris_NUMBE_7zVVerd,Data Engineer,Numberly,"{Hive,Docker,Celery,MySQL,MongoDB,Cube,Kafka,Linux,Git,Tabular,ScyllaDB,NoSQL,hadoop,ElasticSearch,Kubernetes,AWS,HBase,RabbitMQ,Java,Hadoop,SQL,Scala,Airflow,HDFS,Druid,Spark,GCP,Python}",T√©l√©travail partiel possible,"28 rue de Ch√¢teaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-03-26,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Numberly is looking for a Data Engineer to join its dedicated team Data. As a Data Engineer you will: Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MS SQL Server, MongoDB, ScyllaDB). Participate in a huge migration from CRM to CDP (SQL Server to hadoop, relational DB to NoSQL) Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage. Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly. Work alongside Data Analytics, Data Scientists, DevOps, and many other talented techs. Suggest your own technological solutions and try them out (our latest POCs include Apache Druid and Tabular) . Join a great multicultural team filled with wonderful people At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (‚ÄúLive my life‚Äù in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Positions available in Paris, Lyon, Bordeaux, Marseille, Nantes, Lille You : Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused‚Ä¶ Like work well done and pay attention to detail Dream of being able to develop and manage website databases with strong traffic Want to work with various, prestigious clients on different problems Are on the lookout for new languages/technologies and test the latest open source trends before others You love the following stack ? Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...) SQL Databases (MySQL, SQLServer) Apache Spark ETL (Apache Airflow or equivalent) NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...) Apache Kafka Python, Java, Scala Git Linux Even better if you know : Cube OLAP and SSRS Cloud Solutions (AWS, GCP, ‚Ä¶) API REST, WebServices Docker Kubernetes Apache Druid Data Science and Machine Learning Message Queuing (RabbitMQ, Celery, ‚Ä¶)","Numberly, a marketing technologist company with a people-based approach, is seeking a Data Engineer to join its dedicated team. The role requires creating and maintaining pipeline jobs, participating in a migration from CRM to CDP, optimizing data operations and storage, and suggesting technological solutions. The company offers an international environment, delivers diversity by design, and enables remote work up to 50% of the time. The ideal candidate should have expertise in Hadoop ecosystem, SQL databases, Apache Spark, ETL, and NoSQL databases, along with knowledge of cloud solutions and data science.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
67,73407,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret_MICRO_DjqwlKX,Data Engineer / GCP,Micropole,"{Python,Scala,Microsoft,durable,Spark,R,AWS,Java,GCP}",T√©l√©travail partiel possible,"91 Rue Carnot, Levallois-Perret, 92300",IT / Digital,CDI,2023-04-22,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√© : Poste : Data Engineer / GCP Localit√© : Levallois-Perret Type de contrat : CDI Niveau d‚Äôexp√©rience : au moins 2 ans Vous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ? Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services. Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus ! Au sein de notre agence bas√©e √† levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus et dans leur strat√©gie pour optimiser leur performance. Dans vos‚ÄØmissions quotidiennes, vous serez amen√©(e) √†‚ÄØ: D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence GCP. Vos comp√©tences techniques‚ÄØ: Vous avez un minimum de 2 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos atouts: Vous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest : Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels. Processus de recrutement : Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ; Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visio Etape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts. En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) LA VIE CHEZ MICROPOLE, C‚Äôest : Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ; Participation √† des projets internes sur la base du volontariat. #LI-DM1 Comp√©tences GCP",,Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
65,73390,https://www.welcometothejungle.com/fr/companies/veolia/jobs/data-engineer-h-f_aubervilliers,Data Engineer,Veolia,"{Python,durable,Dataflow,Java,GCP}",T√©l√©travail partiel possible,"30 Rue Madeleine Vionnet, Aubervilliers, 93300","Environnement / D√©veloppement durable, B√¢timent / Travaux publics, Energie",CDI,2023-04-22,"Vous voulez donner du sens √† votre activit√© professionnelle ? Vous ressentez le besoin d‚Äô√™tre utile ? Vous voulez agir en faveur de la plan√®te et pour un avenir meilleur et durable ? Vous vous sentez l‚Äô√¢me d‚Äôun ‚ÄúRessourceur‚Äù ? ‚Ä¶. Chez Veolia, 84% des collaborateurs et 92% des managers se sentent engag√©s dans leur travail. Les √©quipes trouvent un sens et une utilit√© √† leur activit√©, dans les m√©tiers de l‚Äôeau, l‚Äô√©nergie ou les d√©chets. Chez Veolia, nous recrutons plusieurs centaines de jeunes dipl√¥m√©s chaque ann√©e : issus d‚Äô√©coles d‚Äôing√©nieurs, d‚Äô√©coles de commerce et d‚Äôuniversit√©s, ils nous rejoignent pour un stage, un contrat d‚Äôalternance ou un premier job. Nous leur proposons aussi des V.I.E. gr√¢ce √† notre programme Pangeo, qui leur est d√©di√©. Au travers de notre r√©seau des Campus, nous accueillons aussi des apprentis, et nous les formons du CAP au master‚Ä¶ Chez Veolia, nos 178 894 collaborateurs ont une mission : Ressourcer le monde. C‚Äôest pourquoi nous les appelons ‚ÄúRessourceurs‚Äù. Tous, nous ≈ìuvrons ensemble pour atteindre l‚Äôambition de Veolia : √™tre l‚Äôentreprise de r√©f√©rence de la transformation √©cologique. Pr√©sent sur les cinq continents, dans 51 pays, avec plus de 178 894 salari√©s , Veolia con√ßoit et d√©ploie des solutions qui participent au d√©veloppement durable des villes et des industries, dans les domaines de la gestion de l‚Äôeau, des d√©chets et de l‚Äô√©nergie. Sp√©cialiste des m√©tiers de l‚Äôenvironnement, Veolia s‚Äôattache tous les jours, sur tous les continents, √† d√©velopper l‚Äôacc√®s aux ressources , les pr√©server et les renouveler. Le Groupe veille au strict respect des lois et des trait√©s internationaux garantissant les droits humains et sociaux de chacun, √† la fois au sein de l‚Äôentreprise, et aupr√®s de ses parties prenantes. Ces valeurs et r√®gles de conduite int√®grent les diversit√©s culturelles du Groupe. En 2020, le groupe Veolia a servi 95 millions d‚Äôhabitants en eau potable et 62 millions en assainissement, produit pr√®s de 43 millions de m√©gawattheures et valoris√© 47 millions de tonnes de d√©chets. L‚Äôobjectif du poste de Data Engineer est de contribuer aux activit√©s de build et de run de l‚Äô√©quipe Data Factory D√©finir les architectures ‚ñ™ D√©finir les services GCP ad√©quats pour la mise en place de flux streaming et batch ‚ñ™ Participer √† la d√©finition de l‚Äôimpl√©mentation / architecture lors de la mise en place de nouveaux pipelines ‚ñ™ D√©finir et suivre les droits d‚Äôacc√®s en fonction des caract√©ristiques des utilisateurs ou des services ‚ñ™ Suivre et actualiser la configuration et l‚Äôarchitecture des syst√®mes d‚Äôinformation et des donn√©es en fonction des √©volutions Monitorer / exploiter les solutions ‚ñ™ S‚Äôappuyer sur les outils de monitoring et les enrichir ‚ñ™ Analyser les performances du syst√®me d‚Äôinformation et pr√©coniser des mesures d‚Äôam√©lioration de la qualit√©, la s√©curit√©, la productivit√© ‚ñ™ Identifier et diagnostiquer les dysfonctionnements, incidents, non-conformit√©s et mettre en ≈ìuvre les mesures correctives ‚ñ™ Int√©grer les donn√©es dans l‚Äôenvironnement GCP de la Data Factory Am√©liorer ‚ñ™ Participer √† la compr√©hension des probl√©matiques m√©tiers et op√©rationnelles pour impl√©menter les pipelines de fa√ßon optimale (tous m√©tiers : fonctions supports et op√©rationnels) ‚ñ™ Faire √©voluer les flux de donn√©es en fonctions des contraintes op√©rationnelles (co√ªt, volum√©trie) ‚ñ™ Comprendre la mod√©lisation des r√©sultats dans Big Query afin de fournir des conseils pertinents et/ou d√©tecter la cause d‚Äôanomalies dans les r√©sultats. Communiquer - travailler en √©quipe ‚ñ™ Maintenir la documentation et particuli√®rement les documents d'architecture technique ‚ñ™ √ätre capable d'apporter des modifications sur des √©l√©ments d√©velopp√©s par d‚Äôautres. ‚ñ™ Participer aux rituels agiles de l‚Äô√©quipe Data Factory (SCRUM). Informations suppl√©mentaires En tant qu'entreprise inclusive, Veolia s‚Äôengage pour la diversit√© et accorde la m√™me consid√©ration √† toutes les candidatures, sans discrimination. Bac + 4/5 - √âcole d‚Äôing√©nieur ou √©quivalent et 5 √† 10 ans d‚Äôexp√©rience √©quivalente Ma√Ætrise du build (mode projet) et de l'exploitation (run) en environnement ‚ÄúBig Data‚Äù / ETL Ma√Ætrise de Python et des services Data Google Cloud Platform (Big Query, Composer, Dataflow, ...) Java est un plus. Au-del√† de solides comp√©tences techniques, ce poste requiert une culture informatique large (d√©veloppement, ETL, data, API, r√©seau...), une capacit√© d‚Äô√©coute et un bon relationnel pour accompagner les clients, et une capacit√© √† prendre du recul pour adopter les meilleures solutions. La ma√Ætrise de l'anglais est exig√©e pour ce poste.",,Bac +4,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
59,73331,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/cloud-data-engineer-h-f_wasquehal_EF_ky6dJwo,Cloud Data Engineer,EPSILON France,"{Python,EPSILON,Azure,Microsoft,HDFS,Hadoop,Hive,GCP}",T√©l√©travail partiel possible,"29 Avenue de la Marne, Wasquehal, 59290","Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",CDI,2023-04-22,"EPSILON France est l‚Äôentit√© Datamarketing de Publicis Groupe avec 700 experts data, marketing et technologiques et plus de 40 m√©tiers repr√©sent√©s. Avec pour claim ¬´ Every Interaction Counts ¬ª, la mission d‚ÄôEPSILON est de conjuguer les pouvoirs de la data, du marketing et de la technologie pour rendre les interactions entre les marques et leurs clients toujours plus justes et pertinentes. EPSILON intervient sur l‚Äôensemble des √©tapes-cl√© d‚Äôun projet de transformation data-driven, de la d√©finition de la strat√©gie √† l‚Äôex√©cution op√©rationnelle. EPSILON compte plus de 300 clients actifs et pilote quotidiennement plus de 100 plateformes datamarketing. L‚Äôambition du P√¥le Data Management est d'offrir la meilleure exp√©rience √† nos clients gr√¢ce √† des solutions data-driven et cloud. Nous les accompagnons sur des projets innovants et la cr√©ation de mod√®les s'appuyant sur les nouvelles technologies. En tant que Cloud Data Engineer Azure et/ou Google voici vos missions : Contribuer √† la r√©alisation de projets Data Client, Data Lake, Data services dans un contexte de plus en plus DevOps et Agile, Assurer la veille technologique sur les composants d‚Äôune plateforme Data, Datalake, Cloud, R√©diger des documents projets (design, r√©alisation, d√©ploiement, ‚Ä¶), G√©rer l‚Äô√©volution des solutions propos√©es, et possiblement en assurer la TMA, Participer aux initiatives projets et √† l‚Äô√©volution de nos assets data internes. C'est un travail passionnant et enrichissant pour nos collaborateurs qui sont amen√©s √† collaborer avec le marketing, le digital et la cr√©ation. H/F, vous avez 2 ans d'exp√©rience minimum sur des projets data en environnement cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des m√©thodes agiles, voire du DataOps. Vous souhaitez √©voluer sur les technologies Big Data Hadoop/HDFS, Hive, Python et le requ√™tage de donn√©es (Impala, Hive, ...). Votre exp√©rience dans le traitement de la data, sa valorisation et sa production est un atout consid√©rable. Une connaissance d‚Äôun ETL est un plus. CHOISISSEZ‚Ä¶ - Notre expertise reconnue dans le domaine du d√©cisionnel et du Big Data depuis 30 ans, un cadre m√©thodologique et une organisation des comp√©tences anim√©es constamment dans un souci de veille et de progression, - Nos projets innovants et nos missions de conseil en cours de r√©alisation ou r√©alis√©s autour des solutions BI, Big Data et DMP, nos projets transverses Data et Marketing √† la fois. - Notre diversit√© de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale‚Ä¶) ainsi que des clients internationaux. - Notre organisation en communaut√©s technologiques est un atout pour votre int√©gration et le travail en √©quipe. - Notre partenariat privil√©gi√© et avanc√© avec Google, Microsoft et Salesforce est une force qui vous permettra de monter en comp√©tence rapidement sur les solutions cloud. - Notre management de proximit√© et notre souci de d√©veloppement des comp√©tences",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
58,73351,https://www.welcometothejungle.com/fr/companies/opensee/jobs/analytics-and-ai-engineer_paris_OPENS_WrV53YA,Analytics and AI Engineer,Opensee,"{Python,SQL}",T√©l√©travail partiel possible,"28, Rue de Madrid, Paris, 75008","IT / Digital, FinTech / InsurTech, Big Data",CDI,2023-04-22,"A propos d‚ÄôOpensee Opensee est un fournisseur de solutions d‚Äôanalyse de donn√©es instantan√©es, illimit√©es et en libre-service, ouvrant la valeur du big data en permettant aux institutions financi√®res de transformer les d√©fis du big data en opportunit√©s comp√©titives et vitales pour les utilisateurs professionnels. Fond√©e en 2015 par une √©quipe de banquiers seniors et d‚Äôexperts en technologie big data, Opensee se d√©ploie d√©sormais dans plusieurs grandes institutions financi√®res de premier plan sur des cas d‚Äôutilisation critiques. Pour soutenir cette croissance, nous avons doubl√© nos effectifs et nous nous d√©veloppons d√©sormais depuis 2020 √† Londres, New York et Singapour. Pourquoi nous rejoindre ? Rejoignez une Fintech fran√ßaise pour d√©couvrir et contribuer √† notre solution Big Data innovante destin√©e au secteur financier. √âvoluez dans un environnement dynamique et international dans lequel cr√©ativit√© et innovation sont fortement encourag√©es : toutes vos bonnes id√©es seront √©tudi√©es. B√©n√©ficier d‚Äôune multitude d‚Äôopportunit√©s de d√©veloppement, au travers de notre croissance en France et √† l‚Äôinternational Description du poste En tant qu‚Äôing√©nieur au sein de l‚Äô√©quipe Solutions, vous devrez aider √† la cr√©ation et √† la maintenance de la couche Solutions, et √©galement assister dans les services Solutions aux clients. Ces solutions peuvent utiliser des algorithmes calculatoires simples ou plus complexes, type Machine Learning ou Deep Learning. En d√©tails : Recueillir les besoins des clients pour d√©finir au mieux les outils n√©cessaires √† notre couche Solutions. D√©velopper ces outils de Solutions en Python, que ce soit des solutions sp√©cifiques pour certains clients ou des solutions plus g√©n√©riques qui seront propos√©es √† tout client. Contribuer √† tous les aspects des am√©liorations des solutions, que cela soit l‚Äôam√©lioration de la performance, plateforme de tests et documentation. Contribuer au support et √† l‚Äôanalyse des incidents sur les solutions. A propos de vous Comp√©tences professionnelles : Dipl√¥me d‚Äôing√©nieur ou master en math√©matiques/informatique Vous avez une premi√®re exp√©rience (stage inclus) dans le secteur financier Bonnes comp√©tences en communication fran√ßais/anglais obligatoires Comp√©tences en Data Science, IA Comp√©tences en technologies Big Data, SQL et Python. Qualit√©s personnelles : Vous savez analyser rapidement un probl√®me technique. Autonome, vous √™tes √† l‚Äôaise pour interagir avec diff√©rents interlocuteurs pour r√©soudre un probl√®me et progresser sur votre d√©veloppement de produits Vous √™tes capable de comprendre √† la fois les besoins des utilisateurs, les outils th√©oriques et les contraintes techniques li√©s aux outils D√©tails pratiques : Date de d√©but : imm√©diate Lieu : Paris (quartier Saint-Lazare) Qu‚Äôen dites-vous ? Si vous vous retrouvez dans cette annonce et que vous r√©pondez aux crit√®res de s√©lection alors n‚Äôh√©sitez pas, postulez! Nous serons ravis d‚Äô√©changer avec vous.",,Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
57,73349,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineer-confirme-scala_paris,Data Engineer Confirm√© - Scala,Groupe SeLoger,"{Redshift,Jenkins,Scala,Datadog,CircleCI,Athena,AWS,Argo,Grafana,Airflow,Spark,Glue,SQL,S3,Java,Python,Kubernetes,Git,EMR}",T√©l√©travail partiel possible,"65 Rue Ordener, Paris, 75018","Application mobile, IT / Digital, M√©dia",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Fran√ßais dans la r√©alisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d‚Äôoffrir √† chacun de nos utilisateurs, une exp√©rience immobili√®re simple et efficace afin qu‚Äôils concr√©tisent leurs projets d‚Äôachat, de vente ou de location en toute s√©r√©nit√©. Nous mettons √† disposition des Fran√ßais le plus large choix d‚Äôannonces afin de leur faciliter la recherche d‚Äôun bien selon leurs crit√®res propres, et r√©pondre √† toutes les questions soulev√©es par la r√©alisation d‚Äôun projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque pr√©f√©r√©e des Fran√ßais pour se rep√©rer et se lancer dans leur projet immobilier. Ce poste est √† pourvoir en CDI uniquement. Rejoignez l‚Äô√©quipe Marketplace Design AVIV La marketplace AVIV est le lieu de rencontre privil√©gi√© de tous les acteurs de l‚Äôannonce immobili√®re: potentiels acqu√©reurs ou locataires, propri√©taires ou agents, ‚Ä¶ Afin de garder notre position, nous devons fournir la meilleure qualit√© de service possible en termes de s√©curit√©, de confiance, d‚Äôefficacit√© et de pertinence des √©changes entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualit√© et s√©rieux des prospects et des agents ainsi que la qualit√© des informations affich√©es. Le r√¥le de l‚Äô√©quipe Marketplace design est de concevoir et ex√©cuter toutes les actions n√©cessaires pour assurer la satisfaction de nos utilisateurs : qualit√© et correction des donn√©es, scoring, matching, gamification, et am√©lioration continue. Ces actions requi√®rent un usage important des donn√©es, l‚Äô√©quipe Data Operations est responsable de la gouvernance, la mod√©lisation et la qualit√© des donn√©es ainsi que de fournir les data-sets cl√©s et maintenir une data platform robuste et efficace pour tout le groupe AVIV. Vos responsabilit√©s : En tant que Data Engineer au sein de l‚Äô√©quipe Data Operations, vous travaillez en √©troite collaboration avec un Product Manager et votre Engineering Manager. Vos d√©veloppements respectent les bonnes pratiques en place et sont align√©s avec l‚Äôarchitecture d‚Äôentreprise AVIV. Vous apportez votre expertise technique √† votre √©quipe, vous cr√©ez, adaptez et am√©liorez la qualit√© des data-sets largement utilis√©s chez AVIV. L‚Äô√©quipe Data Operations L‚Äô√©quipe est constitu√©e d‚Äôenviron 40 personnes, avec notamment: coach Agile Data Engineers Data Quality Engineers Data Analysts & Modelers Devops Engineers Enterprise & Solution Architects Product Managers Les projets D√©centraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv Fournir les insights sur les usages des diff√©rents sites et apps mobiles europ√©ens Notre Stack Technique data AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS) Spark Git, CircleCI, Datadog Scala, Java Vous avez id√©alement des connaissances compl√©mentaires telles que : Python Apache Airflow, Kubernetes Jenkins, Argo CD, Grafana, VictoriaMetrics Nous recherchons une personne capable de: Cr√©er et maintenir des datasets complexes et √† gros volumes selon des sp√©cifications fonctionnelles pr√©cises. Participer √† la cr√©ation d‚Äôune infrastructure solide et optimale pour l‚Äôextraction, la transformation et le chargement (ETL) de donn√©es √† partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud. Identifier, concevoir et impl√©menter les processus internes d‚Äôam√©lioration: automatisation, optimisation du delivery, scalabilit√©, etc‚Ä¶ Travailler avec des experts data et donn√©es analytiques au d√©veloppement de nouvelles fonctionnalit√©s Maitriser la m√©thodologie Agile: communication directe, adaptation, fail fast, am√©lioration continue et Software Craftsman Ma√Ætriser le produit et le business, impactant l‚Äôam√©lioration du service aux clients, du produit et de l‚Äôarchitecture Rigueur, curiosit√©, autonomie et √©tat d‚Äôesprit positif Partager des connaissances et ouvert aux nouveaut√©s Ma√Ætriser les sujets RGPD, s√©curit√© et respect de la vie priv√©e Exp√©rience recherch√©e Exp√©rience r√©ussie de data engineering, dans diff√©rents environnements, notamment Spark. Ma√Ætrise des design patterns actuels et des architectures d√©veloppements courants. Ma√Ætrise de l‚Äôanglais professionnel.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
52,73319,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineer-confirme-python_paris,Data Engineer Confirm√© - Python,Groupe SeLoger,"{PostgresQL,Github,Python,Jenkins,Grafana,Spark,Docker,R,Kubernetes,Airflow,AWS,SQL,GCP}",T√©l√©travail partiel possible,"65 Rue Ordener, Paris, 75018","Application mobile, IT / Digital, M√©dia",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Fran√ßais dans la r√©alisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d‚Äôoffrir √† chacun de nos utilisateurs, une exp√©rience immobili√®re simple et efficace afin qu‚Äôils concr√©tisent leurs projets d‚Äôachat, de vente ou de location en toute s√©r√©nit√©. Nous mettons √† disposition des Fran√ßais le plus large choix d‚Äôannonces afin de leur faciliter la recherche d‚Äôun bien selon leurs crit√®res propres, et r√©pondre √† toutes les questions soulev√©es par la r√©alisation d‚Äôun projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque pr√©f√©r√©e des Fran√ßais pour se rep√©rer et se lancer dans leur projet immobilier. Le poste : Nous recherchons un Data Engineer Confirm√© pour rejoindre l‚Äô√©quipe charg√©e des relations entre vendeur et agent au sein de l‚Äôentit√© Data, Science, Geo & Property Team du groupe. L'√©quipe Data Science est charg√©e de produire et d'exposer les insights les plus pertinents sur le march√© du logement (cartes de prix, outils d'estimation, ...) et les analyses data-driven √† un large public : particuliers, agents immobiliers, institutions priv√©es et publiques. Compos√© d'une quarantaine de personnes, nous adoptons une approche scientifique pour mod√©liser le march√© de l'immobilier r√©sidentiel et d√©velopper des produits √† fortes valeurs ajout√©es. Au sein de ce p√¥le, notre √©quipe Data Engineering est compos√©e de 14 profils ayant des comp√©tences en extraction et traitement de l'information, architecture syst√®me, traitement du signal et gestion de bases de donn√©es. Nous travaillons en √©troite collaboration avec des doctorants et des docteurs en math√©matiques, √©conomie, finance et statistiques, ing√©nieurs en Machine Learning et GIS. Vos missions seront : Internationalisation d'une plateforme de donn√©es Moderniser et harmoniser notre architecture et la faire √©voluer Fournir √† l'√©quipe Data Science un environnement R&D stable Construire un pipeline de traitement de donn√©es robuste et efficace D√©velopper des processus de contr√¥le de la qualit√© et identifier les am√©liorations Concevoir des API et des syst√®mes de livraison de donn√©es Outils : GCP, AWS Python, Spark, Docker, Airflow, PostgresQL, Kubernetes Github, Jenkins, ArgoCD, Grafana, VictoriaMetrics A propos de vous : MS/PhD en informatique, statistiques, math√©matiques ou similaire Exp√©rience de d√©veloppement Python Ma√Ætrise le langage SQL et id√©alement une exp√©rience de Postgis Rigoureux, curieux, autonome, force de proposition Grand int√©r√™t pour la visualisation et la cartographie des donn√©es",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
35,67656,https://www.welcometothejungle.com/fr/companies/edenred/jobs/lead-azure-data-engineer-architect-w-m_malakoff,Lead Azure Data engineer/Architect (w/m),Edenred France,"{Amplitude,MongoDB,Databricks,PowerBI,Synapse,scale,via,Spark,Azure,NoSQL,SQL}",T√©l√©travail partiel possible,"178 Boulevard Gabriel P√©ri, Malakoff, 92240","Application mobile, Restauration, FoodTech",CDI,2023-04-07,"Edenred France est la plateforme de services et de paiements qui accompagne au quotidien les acteurs du monde du travail. Elle connecte 6 millions de salari√©s utilisateurs et 380 000 commer√ßants partenaires via 150 000 entreprises clientes en France. En 2019, gr√¢ce √† ses actifs technologiques globaux, le Groupe Edenred a g√©r√© dans le monde 2,5‚ÄØmilliards de transactions de paiement √† usages sp√©cifiques, repr√©sentant un volume d‚Äôaffaires de 31 milliards d‚Äôeuros r√©alis√© principalement via applications mobiles, plateformes en ligne et cartes. Edenred France propose des solutions de paiement √† usages sp√©cifiques d√©di√©es √† l‚Äôalimentation (Ticket Restaurant¬Æ), √† la mobilit√© (Ticket Fleet Pro, Ticket Mobilit√©), √† la motivation et √† la qualit√© de vie (Kad√©os, ProwebCE, CleanWay, Ticket CESU, Ticket Service), et aux paiements professionnels (cartes virtuelles). Ces solutions am√©liorent le bien-√™tre et le pouvoir d‚Äôachat des salari√©s, renforcent l‚Äôattractivit√© et l‚Äôefficacit√© des entreprises, et vitalisent l‚Äôemploi et l‚Äô√©conomie locale. Les 1 200 collaborateurs d‚ÄôEdenred France s‚Äôengagent au quotidien pour faire du monde du travail un monde connect√©, simple, s√ªr et efficace. OUR CONTEXT For a very ambitious agile-at-scale program (Feature Teams organization), we are seeking talented and ambitious professionals to join our team based primarily in Paris and Bucharest as we accelerate our transformative digital and product journey. We are fully embracing Cloud Native capabilities and best practices and operating as a multi-tribe Product team to better serve our customers (Clients, Merchants and Users) and our Edenred employees. We are leveraging Agility at scale principles and are leading the charge in establishing ‚ÄúFinTech Product‚Äù ways of working for Edenred. We are also embracing data mesh principles. This means that we are empowering our domain teams to own their data products and encouraging a culture of collaboration and innovation across our entire organization. We want to foster a data-driven culture that enables us to unlock the full potential of our data assets and drive business value for our customers. With data mesh, we are transforming the way we work with data and revolutionizing the employee benefits industry. Our main focus areas to drive value from our Data products : Product excellence: ensure the product team is equipped with Analytics to monitor UX, usage, adoption & performance of the product, both for Front-end and Process aspects Business Performance: ensure the Business Units using our platform can access the data from the different domains for their own BI and propose ‚Äúready to use‚Äù dashboard to help driving convergence across the Business line for Business performance reporting Value for our Customers & monetization: leverage a 360 view of our Customers and relevant external data sources - through partnerships when relevant - to bring personalized value to our Customers and differentiate from our competition Some critical success factors : Data privacy: protect the data of our customers and fully integrate GDPR regulation principles across our architecture - including consent management and right to be forgotten Data quality: drive a ‚Äúquality by design‚Äù engineering mindset and establish best in class Data observability Data democratization : ensure data is available and easily accessible to who need them, with clear definition, usage guidelines and lineage collaboratively maintained in a catalog Data UX: adopt a persona approach for our Data consumption use cases and promote a superior UX in our visualizations Our Technology stack for Data : Azure Data Platform including Event hub and Synapse Databricks Data Cataloguing - TBD PowerBI and PowerApps for visualization MongoDB/NoSQL for User and Customer domains Vertabelo for data modelling and ‚ÄúData as code‚Äù Amplitude for Front-end analytics Didomi for Consent management YOU WILL VIBE WITH US At Edenred, we believe that data is the key to unlocking business value and driving positive change for our customers. As a Data Engineering Leader, you will play a critical role in this mission, leading a team of data engineers to design, build, and maintain our data platform and pipelines using cutting-edge technologies such as Azure Cloud data technology and Databricks. In this role, you will have a strong focus on technical excellence and innovation, leveraging your deep expertise in data engineering and cloud data architecture to design and implement scalable data solutions that meet the needs of our business and customers. You will be a driving force for implementing data mesh principles, empowering domain teams to own their data products and creating a culture of collaboration and innovation across the organization. You will collaborate with domain owners, data product managers, and other stakeholders to define the data product architecture and ensure that it aligns with data mesh principles. Your main responsibilities: Lead a team of data engineers responsible for designing, building, and maintaining our data platform and pipelines. Design and implement scalable data solutions that leverage Azure Cloud data technology and Databricks to their full potential, including data ingestion, processing, storage, and consumption. Collaborate closely with cross-functional teams, including business stakeholders, product managers, and domain owners, to define and execute the data strategy and ensure that our data solutions meet business objectives and customer needs. Implement data mesh principles and empower domain teams to own their data products, creating a culture of collaboration and innovation across the organization. Define the data product architecture and ensure that it aligns with data mesh principles, collaborating with domain owners, data product managers, and other stakeholders to develop and execute the architecture roadmap. Implement best practices for data observability, data quality, data governance, and data security across all data solutions and pipelines. Develop and maintain documentation and technical specifications for all data solutions and pipelines, ensuring that they are up to date and accessible to all relevant stakeholders. Stay up to date with the latest trends and technologies in the data engineering field, and apply this knowledge to continuously improve our data solutions and pipelines. WE WILL VIBE WITH YOU You could be our next teammate if you have : Bachelor‚Äôs degree in Computer Science, Engineering, or a related field. 10+ years of experience in data engineering or architecture roles, with a strong focus on Azure Cloud data technology and Databricks. Good understanding of data mesh principles and domain designed data products. Experience leading and managing high-performing data engineering teams, with a focus on developing team members and creating a culture of collaboration and innovation. Strong technical skills in data ingestion, processing, storage, and consumption, using technologies such as Azure Data Factory, Azure Databricks, SQL Server, NoSQL databases, and Spark. Strong knowledge of data quality, data governance, and data security best practices, and experience implementing these practices in a production environment. Strong communication and collaboration skills, with the ability to work closely with cross-functional teams and stakeholders to define and execute the data strategy.",,Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
50,73289,https://www.welcometothejungle.com/fr/companies/dynatrace/jobs/systems-engineer-m-f-x-observability-devops-and-cloud-engineering_linz,"Systems Engineer (m/f/x)  - Observability, DevOps, and Cloud Engineering",Dynatrace,"{Jenkins,bash,scale,Dynatrace,Kubernetes,Docker,dynatrace,Java}",T√©l√©travail partiel possible,Linz,"Logiciels, IT / Digital, SaaS / Cloud Services",CDI,2023-04-22,"Dynatrace exists to make the world‚Äôs software work perfectly. Our unified software intelligence platform combines broad and deep observability and continuous runtime application security with the most advanced AIOps to provide answers and intelligent automation from data at an enormous scale. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences. That is why the world‚Äôs largest organizations trust Dynatrace¬Æ to accelerate digital transformation. Job Description Build and maintain demo applications to showcase Dynatrace features with various technologies and languages Deploy and manage applications using tools like Kubernetes and Docker Develop and maintain team-internal Kubernetes environments Automate deployments and infrastructure using Terraform and Jenkins Collaborate and assist your colleagues in international development teams Continuously research and evaluate new technologies and tools to optimize the team‚Äôs workflows Qualifications A strong interest in technology and a willingness to continuously learn new things Technical studies‚ÄØrelated to Computer Science or similar experience Fluent in Java, and open to other programming languages and frameworks Working knowledge of containerization technologies (Docker, Kubernetes) Interest in infrastructure-as-code tools like Terraform Admin experience (bash scripting, system maintenance) is a plus Hands-on team player with high quality standards Curious and innovative mindset with a bias towards action Additional Information What's in it for you? A one-product software company creating real value for the largest enterprises and millions of end customers globally, striving for a world where software works perfectly . Working with the latest technologies and at the forefront of innovation in tech on scale; but also, in other areas like marketing, design, or research. Working models that offer you the flexibility you need, ranging from full remote options to hybrid ones combining home and in-office work. A team that thinks outside the box, welcomes unconventional ideas, and pushes boundaries . An environment that fosters innovation, enables creative collaboration, and allows you to grow . A globally unique and tailor-made career development program recognizing your potential, promoting your strengths, and supporting you in achieving your career goals. A truly international mindset that is being shaped by the diverse personalities, expertise, and backgrounds of our global team. A relocation team that is eager to help you start your journey to a new country , always there to support and by your side. Attractive compensation packages and stock purchase options with numerous benefits and advantages . Compensation and rewards We offer attractive compensation packages and stock purchase options with numerous benefits and advantages. Due to legal reasons, we are obliged to disclose the minimum salary for this position, which is ‚Ç¨ 39,200 gross per year based on full-time employment. We offer a higher salary in line with qualifications and experience. Discover more perks & benefits Growth opportunities - find out how Dynatrace supports your career development and personal growth journey: https://careers.dynatrace.com/grow-with-us/career-development/ Flexible working - our flexible and trusting work environment fits your current life situation: https://careers.dynatrace.com/ways-of-work/ Relocation Support - discover how we can support you if you wish to join us at one of our global locations: https://careers.dynatrace.com/relocation/ Company Description Dynatrace exists to make software work perfectly.‚ÄØOur platform combines broad and deep observability and continuous runtime application security with advanced AIOps to provide answers and intelligent automation from data. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
48,34671,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_paris-la-defense,Data Engineer,Soci√©t√© G√©n√©rale,"{Kafka,Spark,Java}",T√©l√©travail partiel possible,Paris La D√©fense,"Banque, Finance",CDI,2022-08-08,"Au sein de Soci√©t√© G√©n√©rale : Pour vous, l'utilisation des donn√©es repr√©sente l'avenir ? Vous avez envie de rejoindre une √©quipe agile, dynamique, engag√©e et qui travaille en forte proximit√© avec le business ? Rejoiniez une √©quipe de passionn√©, dans un environnement international pour contribuez aux d√©veloppements des outils d'analyse de l'activit√© du p√©rim√®tre Fixed Income. Concr√®tement, vous serez amen√©(e) √† : * Travailler en √©troite collaboration avec les Products Owner m√©tiers du p√©rim√®tre fixed income * Proposer des solutions bas√©es sur la stack Big Data pour l'analyse et la restitution de l'activit√©, historique comme temps r√©el * Inover et imaginer les solutions du future * Vous √™tes dipl√¥m√©(e) d'un Bac +5 en informatique / √©cole d'ing√©nieur * Passionn√©(e) de data, vous proposez des am√©liorations et partagez avec votre √©quipe * Incollable sur la stack big data: Spark,Kafka en langage Java,Pytoh vous avez √©galement la fibre DevOps et FinOps * You're fluent in English!","Join an agile team at Soci√©t√© G√©n√©rale as a Big Data Engineer to work closely with Fixed Income business owners, propose data-driven solutions for analysis and visualization, develop innovative solutions, have a strong knowledge of big data stack, and possess a degree in computer science or engineering. Fluency in English is required.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
45,56672,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-equipements-biomedicaux-connectes_paris,Data Engineer - Equipements Biom√©dicaux connect√©s,Assistance Publique - H√¥pitaux de Paris - DSI,"{Oracle,python,bash,Nvidia,Docker,Postgresql,MySQL,Talend,Kafka,Linux,NoSQL,Elastic,java,Jenkins,Kubernetes,Java,SQL,Hadoop,Jupyter,via,Spark,sql,Python}",T√©l√©travail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDD / Temporaire,2023-03-26,"L‚Äô Assistance Publique - H√¥pitaux de Paris (AP - HP) est un √©tablissement public de sant√© et le centre hospitalier universitaire - CHU - de la r√©gion Ile-de-France, reconnu mondialement pour sa recherche. Le d√©partement Web Innovation Donn√©es (WIND) s‚Äôinscrit au sein de sa Direction des Syst√®mes d‚ÄôInformation. Sa mission ? üéØR√©aliser les projets num√©riques innovants au contact du monde hospitalier. Ses projets phares ? üöÄ Construire le plus large entrep√¥t public de donn√©es de sant√© en Europe ! Le projet vise √† valoriser les donn√©es produites √† l‚ÄôAP-HP pour la recherche, l‚Äôinnovation et le pilotage des soins, tout en prot√©geant les donn√©es patient. L‚ÄôEntrep√¥t de Donn√©es de Sant√©, c‚Äôest d√©j√† +12 millions de patients dont les donn√©es sont structur√©es et r√©f√©renc√©es sur une plateforme Big Data d√©di√©e. üôã‚Äç‚ôÄÔ∏èüôã‚Äç‚ôÇFaciliter le quotidien des patients! Le domaine g√®re notamment toutes les applications mobiles et tous les t√©l√©services de l‚ÄôAP-HP. üî¨Monter une plateforme Bio-Informatique centrale pour assister les p√¥les de biologie de l‚Äô AP-HP dans leurs besoins informatiques (gestion du s√©quen√ßage, d√©ploiement de ressources de calcul). üåºD√©velopper et d√©ployer au niveau national les outils de collecte et d‚Äôanalyse √©pid√©miologique des donn√©es relatives aux maladies rares. La mission de votre √©quipe Afin de permettre le d√©veloppement de projets de recherche innovants, en particulier dans le domaine de l‚Äôintelligence artificielle, l‚ÄôAP‚ÄìHP a mis en place une plateforme Big Data, infrastructure informatique propre, int√©grant des capacit√©s de stockage et de calcul pour l‚Äôexploitation s√©curis√©e et performante des donn√©es de sant√© dont elle est d√©positaire. Cette plateforme h√©berge notamment l‚Äôentrep√¥t de donn√©es de sant√© (EDS) de l‚ÄôAP-HP. ‚Äã L‚ÄôEntrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP int√®gre des donn√©es administratives et m√©dicales de plus de 8 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (20 millions de dossiers m√©dicaux, plus de 10 millions de diagnostics, 181 millions de r√©sultats de laboratoires‚Ä¶). Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision. ‚Äã La Plateforme Big Data de l‚ÄôAP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d‚Äôespace disque), de machines GPU (48 Nvidia P40 / V100), de 20 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es, et de nombreuses autres machines applicatives. ‚Äã Votre √©quipe, le domaine ¬´ Plateforme Big Data ¬ª, a pour mission l‚Äôint√©gration des donn√©es de sant√© massives et complexes (donn√©es structur√©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation √† grande √©chelle, de mani√®re performante, ergonomique et s√©curis√©e dans le respect des principes et r√®gles de gouvernance des donn√©es d√©finis par l‚ÄôAP-HP. Les donn√©es issues des √©quipements biom√©dicaux connect√©s proviennent globalement de l‚Äôensemble des services de l‚ÄôAPHP et en particulier dans les services de soins intensifs. Selon le contexte, la fr√©quence d‚Äôacquisition et la dur√©e d‚Äôenregistrement des signaux varient dans des proportoins importantes (de quelques secondes √† plusieurs jours et de 0.02Hz √† 3kHz). Vos missions Au sein de l‚Äô√©quipe en charge de la Plateforme Big Data de l‚ÄôAPHP, vous prenez en charge le d√©veloppement des outils ou composants r√©pondant aux attentes des m√©decins et chercheurs pour le stockage et l‚Äôexploitation des donn√©es de type signaux physiologiques (ECG, EEG, EMG, courbes respiratoires, ‚Ä¶) collect√©es dans le cadre de leurs projets de recherche. La plateforme big data cherche a se doter d‚Äôune solution technique sp√©cifique pour le stockage, le traitement et l‚Äôexploitation de ces donn√©es sous forme de s√©ries temporelles. Vous serez amen√© √† analyser, √† proposer et √† mettre en oeuvre une architecture et des solutions adapt√©es aux diff√©rents besoins des projets de recherche et vous participerez √©galement √† la mise en place d‚Äôun certain nombre d‚Äôoutils de base (visualisation, annotation, etc.) pour faciliter l‚Äôexploitation et l‚Äôenrichissement des donn√©es physiologiques par les utilisateurs de la plateforme. En tant que data engineer sp√©cialis√© en traitement du signal et id√©alement en syst√®mes biom√©dicaux, vous : R√©aliserez la d√©finition des besoins et l‚Äôaccompagnement des m√©decins pour la r√©alisation d‚Äôun projet de recherche Analyserez les diff√©rents √©quipements biom√©dicaux, signaux et protocoles de communication D√©velopperez, industrialiserez et maintiendrez les flux d‚Äôint√©gration des signaux physiologiques pour permettre leur collecte au sein de la plateforme big data Contribuerez √† l‚Äôutilisation de ces nouvelles typologies de donn√©es (extraction, s√©lection, collecte et int√©gration) via des connecteurs sp√©cifiques d√©velopp√©s en java, python ou d‚Äôautres langages Industrialiserez le code de g√©n√©ration du flux de donn√©es et assurer sa performance globale Aiderez √† l‚Äôimpl√©mentation de standards et normes de mise √† disposition des donn√©es Mettrez en place des outils permettant l‚Äôenrichissement des donn√©es (analyse, annotation, etc) Travaillerez en collaboration avec des partenaires industriels dans le cadre des diff√©rents projets de recherche Id√©alement, vous.. Avez un dipl√¥me d‚Äôing√©nieur ou √©quivalent (bac+4/5, master2) en informatique ou sciences avec formation compl√©mentaire en informatique Avez une exp√©rience de d√©veloppement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, ‚Ä¶) et ETL (Talend ou autre) Avez une exp√©rience dans la manipulation de donn√©es avec le langage SQL Connaissez les standards en informatique de sant√© (HL7 v2, DICOM, HL7-FHIR, OMOP, ‚Ä¶) Avez le go√ªt de l‚Äôint√©gration de syst√®mes informatiques h√©t√©rog√®nes Avez des connaissances des bonnes pratiques de s√©curit√© informatique et de la r√©glementation informatique et libert√©s Adh√©rez aux valeurs du service public et vous avez un int√©r√™t prononc√© pour le domaine de la sant√© Avez un niveau d‚Äôanglais courant Vous avez un savoir faire dans un de ces domaines : Bonne maitrise du langage Python et de bash Bonnes connaissance des bases de donn√©es Oracle, Postgresql ou MySQL et langages associ√©s (sql) Bonne maitrise en m√©thode de conduite de projet (planification, reporting, analyse de risques, ‚Ä¶) Connaissance des outils ETL (Talend, ‚Ä¶), d‚Äôinformatique d√©cisionnelle et des m√©thodes de data warehouse (OLTP, RDBMS‚Ä¶) Connaissance du traitement des donn√©es massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Connaissance en m√©thodes de d√©veloppement logiciel (dont cycle en V, m√©thodes agile), m√©thodes d‚Äôanalyse et de mod√©lisation (Merise, UML ‚Ä¶) Connaissance en administration d‚Äôenvironnements Linux Connaissance des m√©thodologies devops et des outils associ√©s (Docker, Kubernetes, Jenkins‚Ä¶) Et humainement ? Capacit√© √† appr√©hender des enjeux li√©s √† la recherche, √† l‚Äôanalyse de donn√©es et aux technologies de machine learning/deep learning, notamment dans le domaine de la sant√© (sant√© publique, imagerie m√©dicale, √©pid√©miologie, ‚Ä¶) Esprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collective Sens de l‚Äô√©coute, du r√©sultat et de la qualit√© Des qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√© Curieux, dynamique et cr√©atif, avec un r√©el envie de faire preuve d‚Äôinnovation Au cours de 2 √† 3 entretiens vous √©changerez avec diff√©rents chefs de projets et le directeur de la plateforme","AP-HP is looking for a data engineer with expertise in signal processing and ideally in biomedical systems. The successful candidate will be responsible for developing tools and components for the storage and exploitation of physiological signals such as ECG, EEG, EMG, and respiratory curves collected as part of research projects. They will work with doctors to define project requirements, analyze biomedical equipment and communication protocols, develop and maintain integration flows, and implement standards and data provisioning tools. The ideal candidate holds a degree in computer science or a related field, has experience with Java and/or Python, and is familiar with EAI and ETL tools. They should also have knowledge of SQL, health informatics standards, and data security regulations, as well as expertise in project management, software development, and DevOps methodologies.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
42,73153,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_34O3aKb,Data engineer,EXTIA,"{Python,Scala,Linux,SAS,HDFS,Hadoop,Spark,R,AWS,S3,Java,GCP}",T√©l√©travail partiel possible,Paris,"Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie",CDI,2023-04-22,"Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, du digital et de l‚Äôing√©nierie , nous privil√©gions depuis notre cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. R√©compens√©e depuis 2012 par le label Great Place to Work¬Æ, cette conviction s‚Äôincarne au quotidien dans notre marque de fabrique : ¬´ D‚Äôabord qui, ensuite quoi ¬ª ! Nous partons du ¬´ Qui ¬ª, de la personne, de ses aspirations et ses talents, pour ensuite co-construire le ¬´ Quoi ¬ª, un projet porteur de sens et de valeur ajout√©e pour elle et pour Extia. üéØ Cette vision de l‚Äôentreprise est aujourd‚Äôhui partag√©e par plus de 2500 Extien¬∑ne¬∑s en France et √† l‚Äôinternational qui accompagnent nos 250 clients dans la r√©alisation de leurs projets. Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶ Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes. Vous serez en charge de : ‚óè Participer √† la d√©finition des besoins et √† la r√©daction des User Stories, ‚óè Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e, ‚óè Concevoir et construire des architectures de donn√©es, ‚óè Int√©grer des sources de donn√©es, ‚óè Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives, ‚óè Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux #LI-GG1 ‚óè Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple, ‚óè Vous maitrisez les bases de l‚Äôanalyse statistique, ‚óè Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus, ‚óè Vous maitrisez Spark et Hadoop ‚óè Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, ‚óè Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
39,73085,https://www.welcometothejungle.com/fr/companies/cdiscount/jobs/dataops-engineer-h-f_bordeaux-33,DATAOPS ENGINEER,Cdiscount,{},T√©l√©travail partiel possible,"Bordeaux (33), 33000","Logistique, SaaS / Cloud Services, E-commerce",CDI,2023-04-22,"Cdiscount est une aventure du num√©rique fran√ßais. Pass√©e en 20 ans d‚Äôune start-up bordelaise au leader fran√ßais du e-commerce, l‚Äôentreprise n‚Äôa eu de cesse de r√©pondre aux attentes de ses clients. L‚Äôobjectif ? Rendre possible l‚Äôacc√®s aux biens (high-tech, √©lectrom√©nager, vins, d√©corations ou encore les jouets) et aux services (√©nergie, offres de voyages ou forfaits t√©l√©phoniques) au plus grand nombre en construisant une √©conomique num√©rique, europ√©enne, inclusive et responsable. Avec audace et engagement, les collaborateurs de Cdiscount ≈ìuvrent tous les jours pour proposer gr√¢ce √† la technologie et l‚Äôinnovation, une exp√©rience client riche, humaine et fluide. Depuis 2011, l‚Äôentreprise offre une vitrine aux PME/TPE en France et √† l‚Äô√©tranger et accompagne leur digitalisation gr√¢ce √† sa marketplace. Ce qui lui permet de proposer plus de 60 millions de produits √† ses 9 millions de clients. Conservant l‚Äôagilit√© de son mod√®le et forte de son positionnement de leader fran√ßais, Cdiscount construit chaque jour le e-commerce d‚Äôaujourd‚Äôhui et de demain. Cdiscount en chiffres : ‚Ä¢ 4 Mds ‚Ç¨ de Volume d‚Äôaffaires en 2019 ‚Ä¢ 20 millions de visiteurs uniques par mois ‚Ä¢ 60 millions de r√©f√©rences ‚Ä¢ 2 000 collaborateurs ‚Ä¢ 560 000 m¬≤ d‚Äôentrep√¥t logistique ‚Ä¢ 70% de trafic sur mobile ‚Ä¢ Plus de 60 m√©tiers repr√©sent√©s REJOIGNEZ UN COLLECTIF ANIME PAR LE GOUT DU DEFI Chez Peaksys , filiale Tech de Cdiscount, nous sommes plus de 650 passionn√©(e)s de Tech, mobilis√©(e)s chaque jour pour acc√©l√©rer les d√©veloppements BtoB et BtoC de Cdiscount et ses filiales. Rejoignez Peaksys, venez faire du hors norme votre norme. Notre mission : Fabriquer et op√©rer des solutions digitales √† l‚Äô√©chelle pour tout l‚Äô√©cosyst√®me Cdiscount (Cdiscount.com, Octopia, C-Logistics, Cdiscount Advertising), en assurant √† nos utilisateurs une qualit√© d‚Äôexp√©rience sans compromis. Notre terrain de jeu : nos syst√®mes traitent 1 Md de requ√™tes par an sur le moteur de recherche/ Jusqu‚Äô√† 1001 commandes clients par minute/ 3000 mises √† jour d‚Äôoffres vendeurs par seconde/ 1 changement en production toutes les 7 minutes. Ce qui nous caract√©rise : nous visons l‚Äôexcellence et une vitesse d‚Äôex√©cution toujours plus rapide pour chacun de nos produits. Notre conviction : nous croyons en l‚Äô√©quipe et en la puissance du collectif comme moteur de notre performance. Vous avez soif de d√©fis ? Venez prendre part √† une aventure humaine et technologique exceptionnelle sur un terrain de jeu Tech hors norme. Description du profil : Peaksys est un employeur investi en faveur de la diversit√© : du recrutement √† l‚Äô√©volution professionnelle, nous garantissons l‚Äô√©galit√© des chances √† tous nos collaborateurs. Vous √™tes persuad√© que l‚Äôavenir appartient √† celles et ceux qui osent faire bouger les lignes ? Nous aussi. Alors, Inventez-tout, R√©v√©lez-vous ! Venez d√©velopper vos comp√©tences et votre employabilit√© dans un environnement de travail unique : üè° : Un accord t√©l√©travail pouvant aller jusqu‚Äô√† 3 jours par semaine, üåâ : Des locaux modernes et situ√©s au bord de la Garonne en plein c≈ìur des Bassins √† Flots, hub de la tech Bordelaise, üé§ : Des animations, conf√©rences, et temps d‚Äô√©changes d√©di√©s avec la Direction, üéì : Une offre de formation innovante et √† la pointe des nouvelles technologies, üèÜ : De nombreux labels obtenus (Great Place To Work, Happy Trainees, AFNOR ‚ÄúDiversit√©‚Äù et ‚ÄúEgalit√© F/H‚Äù), üõí : Un abonnement Cdiscount √† volont√© (CDAV) offert et des r√©ductions toute l‚Äôann√©e, üé¢ : Des offres avantageuses gr√¢ce au CSE (cin√©ma, parcs de loisirs, concerts), üåç : L‚Äôopportunit√© d‚Äô√™tre acteur d‚Äôinitiatives RSE et li√©es √† la Diversit√© : (HandiTeam, GreenTeam), üë∂üèΩ : Des places en cr√®ches et un dispositif de garde d‚Äôenfant en urgence, üí∞ : Des plans d‚Äô√©pargnes (PEE, PERCOL, abondement employeur sur versements volontaires), Et les indispensables : üçî cartes restaurants, üåÖ ch√®ques vacances, ü©πmutuelle adapt√©e √† tous, üöé remboursement √† hauteur de 50% des titres de transport. Les prochaines √©tapes : Un entretien t√©l√©phonique RH avec H√©l√®ne , votre contact RH durant votre processus de recrutement, Un entretien avec votre future manager, Fabien et H√©l√®ne, Un entretien technique avec votre N+2, Julien, Notre proposition d‚Äôembauche ! Informations compl√©mentaires Type de mobilit√©: Mobilit√© d√©finitive Localisation: Bordeaux (33) R√©f√©rence: 10688",,Bac +5 / Master,> 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
38,56703,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/manager-data-engineering-h-f_paris_PF_zNkwZlM,Manager Data Engineering,Publicis France,"{Microsoft,Azure,MongoDB,Gitlab,Kubernetes,EPSILON,Cloudera,Kafka,Spark,Epsilon,Docker,Hadoop,Python,marquez}",T√©l√©travail partiel possible,"17 Rue Br√©guet, Paris, 75011","Marketing / Communication, Publicit√©, Digital, Relations publiques, AdTech  / MarTech, Ev√©nementiel, Design",CDI,2023-03-26,"Leader fran√ßais du marketing, de la communication et de la transformation digitale des entreprises, le groupe Publicis s‚Äôappuie sur un mod√®le unique qui allie cr√©ativit√©, technologie, m√©dias avec au c≈ìur la data. Pr√©sid√© par Agathe Bousquet, Publicis Groupe en France est une Talent company riche de plus de 5 000 collaborateurs, r√©partis dans 26 agences, qui accompagnent pr√®s de 600 clients. En France, le groupe est organis√© autour des activit√©s de cr√©ation avec les agences Publicis Conseil, Marcel, Leo Burnett Paris, Saatchi & Saatchi, Publicis Consultants, PublicisLive, Carr√© noir, Publicis Luxe, Prodigious, Razorfish. Le groupe est √©galement un acteur puissant des medias avec ses agences Publicis Media, Starcom, Zenith, Spark Foundry, Blue449, Performics. Enfin il intervient dans la transformation num√©rique avec Publicis Sapient, et dans la data avec Epsilon. Ainsi gr√¢ce √† une puissante alchimie, de la cr√©ativit√© et de la technologie, Publicis pilote la transformation des entreprises sur toute la chaine de valeur. La responsabilit√© soci√©tale de l‚Äôentreprise (RSE) irrigue tous ces m√©tiers et fait partie int√©grante de la strat√©gie globale de Publicis. Le groupe est par ailleurs le premier r√©seau en nombre d‚Äôagences √† avoir obtenu le label RSE Agences Actives d√©livr√© par l‚ÄôAACC avec 12 agences labellis√©es. Publicis, c‚Äôest aussi ¬´ Viva la diff√©rence ! ¬ª. Persuad√© que la diversit√© est un puissant moteur de cr√©ativit√© et de performance, Publicis s‚Äôengage sur de nombreux sujets pour promouvoir l‚Äô√©galit√© des chances et renforcer l‚Äô√©galit√© des origines. Le groupe est convaincu que la somme de ses diff√©rences fait sa richesse. Le P√¥le Data & Analytics Platform est compos√© de 140 experts sp√©cialis√©s sur la transformation Data des entreprises : Cadrage fonctionnel et technique, D√©finition de use-cases, Conception d‚Äôarchitecture cloud ou hybride, Mise en ≈ìuvre et run de plateformes data, Impl√©mentation de solutions Dataviz et Analytics, Accompagnement du changement, Cadrage et d√©ploiement de Data Gouvernance, Mise en ≈ìuvre de Data Office. Au sein du P√¥le Data & Analytics Platform, le centre de comp√©tences des technologies Big Data et Cloud intervient sur l‚Äôensemble de la cha√Æne Data : Architecture, D√©veloppement de plateforme Data (ingestion, traitement, stockage, exposition des donn√©es), industrialisation et op√©rationnalisation des solutions d√©velopp√©es (essentiellement en mode cloud). Rattach√© √† ce centre de comp√©tences en tant que Manager Data Engineering, vous avez 4 grandes missions : Management : - Vous managez et animez votre √©quipe (8 √† 10 personnes) dans un esprit de formation, d‚Äôinnovation et de satisfaction client. Projet : Garant de la qualit√© du delivery de vos projets - Vous assumez le r√¥le de chef de projet ou de directeur de projets sur des missions et des clients vari√©s, de la conception √† l‚Äôimpl√©mentation, sans oublier l‚Äôoptimisation de la performance et la scalabilit√© de vos d√©veloppements. Innovate & Train : d√©veloppement du capital connaissance et de l‚Äôinnovation - Vous animez nos r√©seaux de comp√©tences et √™tes un support m√©thodologique et technique pour les consultants - Vous d√©veloppez des points de vue, des ""assets"", des bonnes pratiques et contribuez √† la croissance de l'√©quipe, - Vous √™tes source de conseils tout en participant √† la r√©alisation effective des projets. Sell : - Vous animez la relation client et contribuez activement aux activit√©s d‚Äôavant-vente. - Vous animez la relation avec certains partenaires √©diteurs d‚ÄôEPSILON (Google, Microsoft, ‚Ä¶) Vous marquez des points si Vous √©voluez depuis au moins 6 ans dans des environnements Data Agile et Cloud. La mise en ≈ìuvre de plateformes Data n‚Äôa pas de secret pour vous. Vous √™tes un fan de Scrum, SAFE ou DevOps‚Ä¶ et vous avez appliqu√© ces m√©thodes avec succ√®s √† vos projets ! Vous avez la maitrise d‚Äôune stack technique de r√©f√©rence Hadoop (Cloudera/HortonWorks), Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, ‚Ä¶ et une r√©elle exp√©rience des environnements cloud (en particulier Google Cloud Platform et Azure ). Vous avez d√©j√† encadr√©, manag√©, fait √©voluer des consultants √† travers une premi√®re exp√©rience significative de management ? Le partage de connaissance et la curiosit√© sont des pr√©-requis dans votre quotidien ? Dynamique et r√©actif, vous d√©montrez un r√©el leadership. La qualit√© de votre communication √©crite et orale ainsi que votre aisance relationnelle vous permettent d‚Äô√™tre reconnu comme un interlocuteur exigeant et fiable tant en interne qu‚Äôen externe.","Publicis Groupe is seeking a Manager for its Data Engineering team to drive the transformation of companies across the entire value chain. The candidate must have at least six years of experience in agile data and cloud environments and must be skilled in Scrum, SAFE, or DevOps methodologies. They should have expertise in developing data platforms using Hadoop, Spark, Kafka, Python, MongoDB, Kubernetes, Gitlab, Docker, and cloud environments particularly Google Cloud Platform and Azure. The Manager Data Engineering will be responsible for managing and leading a team of 8-10 employees, project quality, innovation, and client satisfaction. They will also lead client relations and support the team's development and growth by contributing points of view, assets, and best practices.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
36,34114,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_puteaux_SG_RaReRwz,Data Engineer,Soci√©t√© G√©n√©rale,"{Nifi,Scala,Kibana,lambda,Kafka,KAFKA,Hive,Spark,NIFI,Hadoop,Python,Elastic}",NaN,Puteaux,"Banque, Finance",CDI,2022-08-08,"Chez Soci√©t√© G√©n√©rale, nous sommes convaincus que vous √™tes le moteur du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques ann√©es ou toute votre carri√®re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Cr√©er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez √™tre dans l'action, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer ! Dans le cadre d'une √©quipe agile, en tant que Data Engineer, vous garantissez l'acc√®s aux donn√©es li√©es √† l'activit√© de la banque. Vous impl√©mentez et industrialisez des traitements pour collecter, nettoyer et synth√©tiser des donn√©es afin de les rendre accessibles tout en veillant √† leur qualit√©. Concr√®tement, vous serez amen√©(e) √† : Concevoir des solutions pour collecter, transformer et exploiter des gros volumes de donn√©es Participer √† l'industrialisation des traitements et √† leur am√©lioration continue pour qu'ils soient fiables, robustes, performants et r√©silients afin de r√©pondre aux exigences des partenaires m√©tiers Assurer la maintenance et l'√©volution des diff√©rents pipelines de traitement Assurer une veille technologique afin d'√™tre √† la pointe des connaissances en mati√®re de data Vous √™tes curieux(se) avec un bon esprit d'analyse et de synth√®se Passionn√©(e) de data, vous proposez des am√©liorations et partagez avec votre √©quipe You're fluent in English! Vous √™tes dipl√¥m√©(e) d'un Bac +5 en informatique / √©cole d'ing√©nieur et avez une premi√®re exp√©rience dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc. Vous disposez des comp√©tences techniques suivantes : Connaissances des outils Big data : Spark, Hive, Hadoop, NIFI, KAFKA, Elastic, Kibana. Langage de d√©veloppement : Scala, Python, Devops, outils CI/CD, microservice, API. Connaissances des architectures Big Data : R√©silience, architecture Kappa et lambda, couplage, event driven.","As a Data Engineer at Soci√©t√© G√©n√©rale, you will be responsible for implementing and industrializing processes to collect, clean, and summarize data to ensure its accessibility and quality. You will design solutions for collecting and exploiting large volumes of data, participate in the industrialization and continuous improvement of processes, ensure maintenance and evolution of processing pipelines, and stay up-to-date with the latest data technologies. This role requires a strong analytical and synthetic mindset, a passion for data, and proficiency in English. Technical skills in big data tools, development languages, and architectures are also necessary, with a Bachelor's or Master's degree in IT or engineering and previous experience in a tech environment.",Bac +5 / Master,> 2000 salari√©s,< 6 mois,0,3,0.04154662416233763
154,56970,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/data-engineer-ingenieur-e-big-data_paris,Data Engineer / Ing√©nieur¬∑e Big Data - CDI - Caen ou Paris,SoyHuCe,"{python,PostgreSQL,Cassandra,noSQL,Azure,JAVA,MySQL,MongoDB,Dataiku,Shell,github,Kafka,NoSQL,PyTorch,ElasticSearch,Kubernetes,Golang,AWS,CouchDB,Hadoop,SQL,Redis,regard,Minio,Tensorflow,Scala,Kibana,HDFS,MXNet,R,Spark,GCP,Python}",T√©l√©travail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Transformation",CDI,2023-03-26,"Tech Lab sp√©cialis√© en algorithmes et en IA, SOYHUCE accompagne ses clients en proposant une offre ad√©quate et compl√®te avec ses √©quipes Parisienne et Caennaise. La d√©marche de SOYHUCE se d√©cline en 3 expertises : Une usine digitale ; Un laboratoire R&D en algorithmie & IA ; La data factory SOYHUCE se positionne sur le march√© du digital et de la Data comme un ¬´ valorisateur de donn√©es ¬ª. Elle se repose sur des logiciels et des algorithmes personnalisables, centr√©s sur les m√©tiers, et sur sa capacit√© √† faire ressortir les besoins au-del√† de ceux exprim√©s au travers d‚Äôune approche analytique fine. Cr√©√©e en 2013, SOYHUCE souhaite apporter un nouveau regard dans les innovations. Tout en pla√ßant l‚Äôhumain au c≈ìur des entreprises, nos solutions sont adapt√©es aux enjeux √©conomiques, sociales et soci√©tales d‚Äôaujourd‚Äôhui. Leurs produits : OctoData : La plateforme d‚Äôorchestration de technologies Big Data, pr√™te √† l‚Äôemploi et d√©di√©e au traitement et √† la valorisation de vos donn√©es massives. iStoryPath : La webapp de g√©n√©ration de parcours touristiques et √©v√©nementiels personnalis√©s. AlgoRH : L‚Äôoutil de gestion de planning intelligent √† destination des Centres de Relation Clients. Vous souhaitez mettre en oeuvre vos talents au sein d‚Äôune jeune entreprise innovante, o√π bonne ambiance et d√©fis techniques rythment votre quotidien ? Dans le cadre du d√©veloppement de ses activit√©s de R&D et de ses missions de conseil, SoyHuCe est √† la recherche d‚Äôun¬∑e Data Engineer pour consolider son √©quipe infrastructure et d√©veloppement Big Data. √Ä propos Studio R&D en algorithmie et data science, SoyHuCe accompagne les entreprises, et les collectivit√©s dans leurs r√©flexions et projets num√©riques et m√©tiers. Les solutions que con√ßoit et d√©veloppe SoyHuCe sont centr√©es sur les utilisateurs, mettant l‚Äôhumain au c≈ìur des organisations. Descriptif du poste Vous travaillerez conjointement avec les Data Scientists et le Data Architect d√©j√† en poste et vous serez impliqu√©(e) dans la prise de d√©cisions li√©e √† notre solution Big Data et √† son √©volution. Vous participerez √©galement √† la construction d‚Äôun p√¥le Data au sein de l‚Äôentreprise. Vos missions au quotidien : Contribuer au d√©veloppement de notre offre Big Data; Comprendre, analyser et proposer des solutions techniques r√©pondant aux besoins des Plateformes digitales et des projets des BUs ; D√©finir l‚Äôarchitecture logiciel de votre solution en collaboration avec vos pairs ; Travailler la donn√©e sous toutes ses formes (stockage, √©laboration du mod√®le, structuration, nettoyage) ; R√©diger la documentation sous confluence / github ; Mettre en ≈ìuvre les standards de l‚Äôusine logiciel (int√©gration continue, livraison continue, test driven‚Ä¶) ; Partager votre savoir-faire entre les diff√©rents membres de l‚Äô√©quipe ; Concevoir et d√©velopper des connecteurs entre les sources de donn√©es (internes et/ou externes) et la plateforme ; Concevoir et d√©velopper des pipelines de traitements de donn√©es (batch et/ou temps r√©el) dans un environnement Big Data ; Assurer une veille technologique. Comp√©tences techniques attendues : Exp√©rience en d√©veloppement : Fournisseur cloud , R, python. JAVA, C++ ; Connaissance en bases de donn√©es : SQL et noSQL ; Exp√©rience dans le traitement de donn√©es √† grande √©chelle en utilisant les syst√®mes traditionnels et distribu√©s tels que Hadoop ou Spark ; Sensibilit√© √† la culture devops et au software craftmanship ; Data Analysis ; Data Engineering ; Data Visualisation ; Gestion de projets Data ; D√©ploiement d‚Äôarchitecture cloud. Notre stack (en constante √©volution) : Stockage de donn√©es: PostgreSQL, Cassandra, Kafka, ElasticSearch, MongoDB, Minio, Redis; Cloud: AWS, GCP, Azure, OVH; Orchestrateurs: Kubernetes; Technologies Big Data : Spark; Cassandra, HDFS, Kafka Bases de donn√©es : PostgreSQL, MySQL, CouchDB Machine learning: Tensorflow, PyTorch, MXNet, Scikit-Learn; Langages: Scala, Python, Golang, Shell ; Outils : Kibana, Dataiku, Power BI. Dipl√¥m√©¬∑e d‚Äô√©tudes sup√©rieures dans le syst√®me d‚Äôinformation, computer sciences, big data (√©cole d‚Äôing√©nieurs, √©cole sp√©cialis√©e, √©cole de commerce ou √©quivalent universitaire), vous justifiez d‚Äôune premi√®re exp√©rience en BI et/ou Data engineering, ainsi qu‚Äôune exp√©rience confirm√©e en conseil ou en gestion de projet. Vous avez une exp√©rience concr√®te sur la mise en place de pipelines complets de valorisation de donn√©es massives, de la collecte √† la mise √† disposition d‚Äôapplications en passant par le traitement. Vous √™tes orient√© code quality, pair programming ou encore Test driven development. Pro-actif, vous savez travailler en autonomie. C√¥t√© technique, vous poss√©dez de solides bases en traitement de donn√©es avec Spark, Spark Streaming et Kafka dans un environnement Cloud ainsi qu‚Äôen base de donn√©es NoSQL. Vous √™tes rigoureux¬∑euse, ouvert¬∑e, tr√®s curieux¬∑euse et adorez explorer et √©prouver des nouvelles technologies. Un pr√©-qualification avec notre Talent Acquisition Senior Un entretien avec un R√©f√©rent Technique M√©tier Un challenge technique Un entretien avec notre CEO","SoyHuCe, a tech lab specializing in algorithms and AI, is seeking a data engineer to develop their Big Data offering, working collaboratively with their existing team of Data Scientists and Data Architects, contributing to the construction of an in-house Data department. Candidates must have experience in BI and/or data engineering, with a solid understanding of data processing, Spark, Spark Streaming, Kafka, NoSQL databases, and cloud deployment. Technical proficiency with R, Python, Java, C++, SQL, MongoDB, and Redis is essential.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
116,35595,https://www.welcometothejungle.com/fr/companies/tinyclues/jobs/data-engineer_paris_TINYC_z7QQOmy,Data Engineer,Tinyclues,"{Kubeflow,Airflow,TensorFlow,S3,GCS,BigQuery,SQL,DataFlow,Python}",T√©l√©travail partiel possible,N,"SaaS / Cloud Services, Big Data",CDI,2022-09-28,"Tinyclues est une entreprise de tech focalis√©e sur le marketing CRM. Nous pensons que la construction d‚Äôune strat√©gie CRM solide n‚Äôa pas √† √™tre co√ªteuse et difficile. C‚Äôest pourquoi nous avons con√ßu une technologie extr√™mement simple pour que nos clients BtoC atteignent toujours les bonnes personnes avec chacune de leurs campagnes. Permettre √† chacun de nos clients de satisfaire chaque personne de sa base CRM, en leur proposant les bons produits, est l‚Äôobjectif que l‚Äôon souhaite atteindre avec chacun de nos clients. Nous travaillons avec plus de 250 entreprises B to C, principalement dans les secteurs du Retail et du Travel. Plus de 100 000 campagnes marketing ont d√©j√† √©t√© cr√©es gr√¢ce Tinyclues, sur la base le plus de 100 milliards de dollars de transactions ! Last but not least, nos clients nous aiment - NPS en 2021 de 80 (et nous leur rendons bien). Tinyclues AI-first marketing platform is built with the latest technologies including ML frameworks like TensorFlow, Vertex, Kubeflow but also BigQuery, DataFlow. Our software stack is based on the Python ecosystem, natively designed for the cloud and deployed on Google Cloud Platform. We focus on using those technologies for what they do best. The solution processes and analyzes hundreds of terabytes of data every day from our 100+ enterprise clients across 13 countries. It runs dozens of powerful and carefully designed Deep Learning algorithms to find the ‚Äútiny clues‚Äù in our clients‚Äô first-party databases. We believe empowering people is the most efficient way to build the best product together. The teams are organized in small & autonomous feature teams working on different business needs with agile methodologies. Our innovative technology has led Tinyclues to be identified by leading IT analyst firm Gartner as a Vendor to Watch for digital marketing analytics and a Cool Vendor in multichannel marketing. By joining Tinyclues, you will have an impact on one of top fast-growing start-ups with a unique AI-first vision, breakthrough predictive technology and proven global success. Learn more about building successful predictive systems by reading our two articles on Medium.com: How we tamed our multi-tenancy model in less than a week and Beyond Cold-Start. What you will do You will join the Data team whom: Build, manage & improve several hundred data pipelines Design, Organize & Optimize our BQ data warehouse Power our Deep Learning technologies, gather critical data from our clients using various means (Data Cloud/ GCS/ S3/ SFTP/API), build easily consumable insights & deliver audiences to our marketing cloud partners. Our challenges: Multi-Tenant: every client has its own data schema, ability to build flexible and configurable KPIs. Scalability: client data can be big but the computation and scoring we process for our client are even bigger. Cost efficiency: linked to the amount of data to process for each client, we maintain the cost low to make a profit. Requirements: You are an engineer: given an issue, you search for the best and easiest way to tackle it and provide a reliable simple solution. You always try to reuse the existing stacks when possible. You propose an enhancement of the architecture only if it simplifies or prepares the future.( KISS : KeepItSimpleStupid) You understand the power and limitations of different data technologies and know how to turn them into accelerators to deliver client value. You handle and share the global vision of the solution and you propose options to make the best choice with the stakeholders of the product and engineering and are able to define the right plan to tackle things in a sequence of incremental value. You have been working in an Agile environment and are able to manage sprints, velocity, etc‚Ä¶ You are fluent in English. French is a plus. Technical skills: You have strong SQL skills You know orchestration technologies (Airflow, Kubeflow ). You are Python fluent. Knowledge of Google Cloud Platform would be appreciated. Experience of BigQuery is a plus.","Tinyclues is seeking a Data Engineer to join their team and help build, manage, and improve several hundred data pipelines while designing, organizing, and optimizing their BQ data warehouse. The ideal candidate should have strong SQL skills, be fluent in Python, understand the power and limitations of different data technologies, and have experience in an Agile environment. The company utilizes ML frameworks such as TensorFlow, Vertex, and Kubeflow, as well as the Google Cloud Platform, making knowledge in these areas a plus.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
156,56516,https://www.welcometothejungle.com/fr/companies/promovacances/jobs/data-engineer-h-f_paris,DATA ENGINEER,Promovacances,"{cube,Azure,Microsoft,Snowflake,BigQuery,AZURE,SQL,SnowFlake}",T√©l√©travail partiel possible,"17, Rue de l'√âchiquier, Paris, 75010",Tourisme,CDI,2023-03-26,"N¬∞1 de la vente de s√©jours en ligne avec plus de 7 millions de visiteurs uniques par mois sur ses diff√©rents sites, le groupe Karavel connait une croissance dynamique et continue avec un CA de 400 millions d euros. En tant que Data Engineer, vous interviendrez sur la totalit√© de la chaine d√©cisionnelle au sein du p√¥le DATA, et serez charg√©, entre autres de : La maintenance corrective et √©volutive de l'existant impl√©ment√© sur la suite MS BI en collaboration avec le reste de l'√©quipe DATA . La participation au projet de refonte de notre BI actuelle (MS BI, Access, BigQuery) vers AZURE / SnowFlake / Power BI. Analyse de l'existant et des nouveaux besoins m√©tiers ; R√©alisation des sp√©cifications fonctionnelles et techniques ; Mod√©lisation ; Cr√©ation de package sous SSIS ; Impl√©mentation des chargements de donn√©es vers SnowFlake ; D√©veloppement sous cube Tabulaire (service AS Azure) ; R√©alisation de rapports sous Power BI / Excel Recette et mise en production ; Vous disposez d'au moins 5 ann√©es d'exp√©rience sur la suite Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS) avec une solide comp√©tence en SQL De comp√©tences sur Snowflake (architecture, d√©veloppement, administration) d'au moins 2 ans d'exp√©rience sur Power BI Une premi√®re exp√©rience r√©ussie dans le machine learning serait un plus Vous avez d√©montr√© un forte capacit√© d'adaptation et d'autonomie √† travailler au sein d'environnements complexes et h√©t√©rog√®nes en termes de syst√®mes d'information et de domaines fonctionnels couverts. Vous √™tes dot√© d'une forte culture de l'engagement et du r√©sultat, vous √™tes autonome, r√©actif et aimez relever les challenges. Vous avez d√©j√† une exp√©rience dans le secteur du digital et vous avez √©t√© confront√©s aux probl√®mes de qualit√© de donn√©es et de volum√©tries.","Karavel Group, a leading online travel agency, is seeking a Data Engineer with at least 5 years of experience in Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS), Snowflake, and Power BI. The role involves maintaining and developing their existing BI system, as well as participating in a project to move to Azure/Snowflake/Power BI. The ideal candidate should have a strong ability to adapt to complex and heterogeneous environments and have a culture of engagement and result-orientation. Experience in the digital sector and dealing with data quality and volume issues is also preferred.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
200,56823,https://www.welcometothejungle.com/fr/companies/witco/jobs/data-engineer_paris,Data Analytics Engineer,Witco (Ex-MonBuilding),"{MongoDB,Athena,PowerBI,Lambda,S3,AWS,Nodejs,SQL,Python}",T√©l√©travail partiel possible,"7, Rue de Magdebourg, Paris, 75116","Application mobile, SaaS / Cloud Services, Immobilier commercial",CDI,2023-03-26,"Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life‚Ä¶ Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi‚Ä¶ After raising a ‚Ç¨12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who is Witco? Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life‚Ä¶ Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi‚Ä¶ After raising a ‚Ç¨12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who is Witco? Founded in 2016, Witco is a Worktech solution and a EU leader in workspace management, hybrid work management, and employee experience. From booking a desk or a meeting room, to smart office tools, lifestyle services, and access to the office community life‚Ä¶ Witco helps employees stay connected to each other and to their company, and improves productivity and well-being at work. Today, the app equips more than 800 buildings and is used by more than 5,000 companies worldwide such as BNP Paribas Real Estate, Axa, Dior, Vinci, Sanofi, Amundi‚Ä¶ After raising a ‚Ç¨12 million Series A with top VCs Daphni and Eurazeo in 2021, we opened offices in Spain, the UK and Germany in 2022 and plan to open more countries. Witco counts over 75 employees. Who we are looking for 70% Data engineer 50% analytics Able to develop and maintain our data platform: support and enhance data architecture & instrumentation, define database schema, create datamarts and pipelining Your mission in the team Work with the team to analyze needs of data and work the the solutions to collect the data Prepare (collect, clean, transform, enrich, ‚Ä¶), publish and test datasets Build and maintain general data architecture, data lake and derived data marts Work on the data pipelines, scheduling, orchestration Put in place automated tests for the data pipelines Implement monitoring and alert solutions for the data pipelines Create the necessary API endpoints to provide access to statistic data to 3rd party consumers Who are you? You have solid experience in a similar role with a proven track record of building, maintaining and optimizing data pipelines You have strong analytical skills and you are data-driven thinking You are result-oriented and focus on the value created by your development You have the ability to take ownership and be a technical lead to potentially lead the data engineering team in the future Fluent in English Experience Handling of large datasets with SQL Monitoring and improving the scalability & reliability of data pipelines Business-oriented data models & schemas Database programming Cloud computing (AWS S3, Athena, Terraform, etc) Main Technologies used AWS technologies: Athena S3 Lambda functions Python SQL Other technologies used: Terraform - Used to configure the infrastructure Nodejs - used for exports of MongoDB and communication with client app MongoDB - Main app data is stored on MongoDB Power BI - Create PowerBI dashboards with internal performance indicators. Benefits üè† 2 days remote per week ‚òÄÔ∏è Beautiful and spacious offices in the centre of Paris with a rooftop view on the Eiffel tower! üë• A diverse, international, and friendly team of talented people üìö Access to training programs üè• Alan health mutual (covered 50% by witco) üçΩ Restaurant tickets with Swile üéâ Bi-annual off-sites and regular Afterworks At Witco, we are committed to an inclusive recruitment process and to fostering diversity within our teams.","Witco, a Worktech solution, is seeking a data engineer with a proven track record in building, maintaining, and optimizing data pipelines. The successful candidate must have strong analytical skills and be result-oriented, with the ability to take ownership and potentially lead the data engineering team in the future. Witco offers remote work opportunities, beautiful offices in the centre of Paris, access to training programs, health benefits, restaurant tickets with Swile, and regular social events. The company values diversity and promotes an inclusive recruitment process.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
208,34881,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/software-engineer-data-collection_paris_CONTE_r48OXPZ,Software Engineer - Data Collection,Contentsquare,"{React,regard,Jenkins,ContentSquare,Javascript,color,Contentsquare,TypeScript}",T√©l√©travail partiel possible,Paris,SaaS / Cloud Services,CDI,2022-08-08,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We‚Äôve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, we raised $600M in Series F f unding, doubling our valuation to $ 5.6B . But we‚Äôre not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! This position is open to several locations: Paris, Lyon, Rennes, Barcelona ContentSquare's Data Collection team is looking for a talented Software Engineer! The main role of the Data Collection team is the collection of raw data application and web in an innovative way without impacting the performance of our customers (the largest digital companies in France, US, and UK). For this, we develop an universal web and application tag and we are willing to integrate the most modern frameworks such as React, Angular, Vue.js, Polymer, etc.This team faces the permanent technical challenge of constantly improving our technology to make it more innovative and more efficient. Our web collector is executed over 100 millions times daily on a large numbers of browsers and devices, so compatibility and stability is mission critical for the team. Technology wise, our web collector is developed in TypeScript with as few dependencies as possible. Our unit tests are launched on every browser we support and our codebase has 60+% test coverage at all times. We pride ourselves with automation of building, shippings, testing, validation and automate basically anything we can get our hands on. With our focus on automating the mundane, engineers have only to focus on the task at hand. Our codebase and processes baked in our CI can guarantee that when Jenkins shows green it really is green. This all means our product owners can ship by themselves on a Friday afternoon and can have the confidence to do so. We are building our own progressive rollout flow, so that we can do progressively and safely rollout our code to clients. If all of the above sounds like something you believe in and would like to be a part of, please see if you also like the following requirements. What you will do: - Participate in all phases of development lifecycle, from inception to deployment monitoring - Diagnose intricately complex issues, evaluate, recommend and execute the best resolution - Write regression free code, with unit tests and documentation - Implement code design, execute project deliverables and estimate scope of work - Work in an Agile SCRUM environment and having a TDD mindset What you will need: - Enthusiastic follower of good practices of development - You have some experience with TypeScript / Javascript - Fluent in English Why joining our Data Collection team - You are interested in contributing to open source projects as well as investing yourself on the tech scene by participating in meetups and presenting topics in conferences - You are looking for an environment where you'll have the possibility to have responsibilities and learn from more experienced developers - You share our ""quality focused"" vision: code reviews, coverage of unit and functional tests, ... Why you should join Contentsquare - We‚Äôre humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we‚Äôd like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company‚Äôs success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is a digital experience analytics company seeking a Software Engineer for their Data Collection team. The team develops an innovative way to collect raw data application and web, without impacting customers' performance. They are looking for someone with experience in TypeScript/Javascript, enthusiastic about development practices, and fluent in English. The company offers various benefits like stock options, parental leave, and a wellbeing allowance. They're an equal opportunity employer and welcome everyone to apply.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
167,56447,https://www.welcometothejungle.com/fr/companies/datadog/jobs/software-engineer-database-reliability_paris,Software Engineer - Global Data Platform,Datadog,"{Redis,color,Golang,Kafka,scale,Cassandra,Elasticsearch,Datadog,Python,Postgres}",T√©l√©travail total possible,"21 Rue de Ch√¢teaudun, Paris, 75009",SaaS / Cloud Services,CDI,2023-03-26,"Datadog (NASDAQ: DDOG) is the monitoring and security platform for cloud applications. Our SaaS platform is used by organizations of all sizes across a wide range of industries to enable digital transformation & cloud migration and drive collaboration. These capabilities help businesses secure their systems, avoid downtime, & ensure customers are getting the best user experience. Paris is our regional EMEA headquarters and secondary Engineering & Product hub, after our global headquarters in NYC. Database Reliability Engineers (DRE) build production-ready solutions that our product engineers can use to build developer tools and automation that quickly scale up for use by thousands of customers. This team ensures that our databases are scalable and cost-efficient, giving our engineers the platform they need to operate in a high-volume, low-latency environment that is continuing to double in size. The DRE team works collaboratively with engineers across the company, using their deep systems understanding to respond to infrastructure failures and reduce operational toil for all. What You‚Äôll Do: Keep our datastores reliable, available and fast. Respond to, investigate and fix issues, whether it‚Äôs deep in the database code or in the client application. Build tooling to minimize customer-facing downtime, and scale up resources on short notice Protect and ensure the consistency of customer data. Work with developers to design data models, and choose the correct datastores, to support orders of magnitude more customer data and traffic. Who You Are: 3+ years of experience in software engineering You value correctness and efficiency; you leave no stone unturned when diagnosing production issues You handle infrastructure with code because automation lets you focus on the more difficult and rewarding problems You have production experience with distributed datastores, e.g. Cassandra, Postgres, Kafka, Elasticsearch, Redis, You have created tooling for, or submitted contributions to, an open-source datastore You are fluent in Python or Golang Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you‚Äôre passionate about technology and want to grow your skills, we encourage you to apply. Benefits and Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP) Continuous professional development, product training, and career pathing Intradepartmental mentor and buddy program for in-house networking An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups) Access to Inclusion Talks, our Internal panel discussions Free, global mental health benefits for employees and dependents age 6+ Competitive global benefits Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog. #LI-AD1 #LI-Remote This is a remote position About Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers‚Äô entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram , LinkedIn and Datadog Learning Center. Equal Opportunity at Datadog: Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Your Privacy: Any information you submit to Datadog as part of your application will be processed in accordance with Datadog‚Äôs Applicant and Candidate Privacy Notice .","The Database Reliability Engineers (DRE) at Datadog are responsible for building and maintaining scalable, cost-efficient databases that enable the company's product engineers to develop tools and automation used by thousands of customers. Candidates must have at least three years of experience in software engineering and knowledge of distributed datastores such as Cassandra, Postgres, Kafka, Elasticsearch, and Redis. Fluency in Python or Golang is also required. Datadog values inclusivity and offers a range of benefits, including professional development opportunities, global mental health benefits, and an inclusive company culture. This is a remote position.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,3,0,0.04154662416233763
169,56372,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-h-f-cdi_puteaux_DATAS_ZMLPerq,Data Engineer  | CDI,Datascientest,"{Microsoft,GCP,Scala,Kubernetes,Airflow,AWS,Docker,R,Spark,Azure,Python,Bash}",T√©l√©travail ponctuel autoris√©,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"ü§ùüèªDataScientest ? DataScientest, est le leader de la formation aux m√©tiers de la Data, en Europe La pluralit√© des formations propos√©es et la disponibilit√© de ses √©quipes talentueuses permet √† tous les apprenants (B2B, B2C), quels que soient leurs besoins (reconversion professionnelle, d√©veloppement de comp√©tences, professionnalisation), et leur niveau, de se perfectionner, de progresser, d‚Äô√™tre coach√©s et de booster leur carri√®re dans le monde de la Tech. De plus, DataScientest propose des formations adapt√©es aux objectifs de ses entreprises partenaires, notamment √† travers son √©troite collaboration avec p√¥le emploi, mais √©galement des particuliers qui b√©n√©ficient d‚Äôun accompagnement personnalis√© (√©quipes career & customer care). Enfin, DataScientest ≈ìuvre pour l‚Äôemployabilit√© et le d√©veloppement des comp√©tences de ses apprenants, notamment √† travers les dispositifs de POEI et l‚Äôouverture de son centre de formation en apprentissage (CFA). üìàEn quelques chiffres : Plus de 7000 apprenants inscrits et satisfaits, 70 groupes partenaires, dont 30 du CAC40, 2 partenaires acad√©miques prestigieux : Mines Paris Executive Education et l‚ÄôUniversit√© Panth√©on La Sorbonne, Des partenaires √©diteurs majeurs : AWS, Microsoft Azure üèÜSes ambitions : D‚Äôici 3 ans, DataScientest a pour objectif de devenir un champion mondial en continuant √† proposer des produits de formation qui r√©pondent aux besoins du march√© et en poursuivant son expansion g√©ographique, Afin d‚Äôappuyer son statut de leader, DataScientest continue de se d√©velopper √† l‚Äôinternational et de cr√©er ses propres √©coles en Cybers√©curit√© et DevOps adapt√©es aux besoins du march√© (CyberUniversity, DevUniversity) ! Comment ? Avec un format p√©dgogique hybride unique, un studio R&D et surtout les √©quipes de DataScientest qui donnent le meilleur d‚Äôeux m√™me au quotidien pour d√©livrer des formations de qualit√© ! En tant que Data Engineer, vous ma√Ætrisez les technologies d‚Äôacquisition, de traitement, et d‚Äôextraction de donn√©es et avez des connaisisances scientifiques qui vous permettent de dialoguer avec des √©quipes Data. Missions et activit√©s principales : Cr√©ation et d√©veloppement de contenus Cr√©ation environnement de formation et contribution au d√©veloppement de notre plateforme de formation Accompagnement et mentorat sur des sujet d‚Äôengineering Participation et organisation d‚Äô√©v√®nements data Participation √† la strat√©gie R&D du d√©partement Tech Comp√©tences requises : Excellente maitrise de Python Bonne maitrise de la programmation orient√© objet La maitrise de Scala (Spark) est un + Attrait pour l‚Äôactualit√© relative au machine learning, l‚Äôengineering et √† l‚Äôopen-source. Bon niveau en Anglais. La connaissance d‚Äôun provider cloud est tr√®s appr√©ci√©e (AWS, Azure, GCP) ETL Bonne connaissance des diff√©rents Syst√®mes de Gestion de Bases de Donn√©es Bonnes connaissances en script Bash Attrait pour l‚Äôactualit√© relative au machine learning Outils de mise en production: Docker, Kubernetes, FastAPI, Airflow Savoir faire S‚Äôadapter rapidement aux nouvelles technos de Data Engineering Aimer transmettre ses connaissances et accompagner des profils sur des th√©matiques de Data Engineering Travailler en √©quipe Savoir g√©rer son temps et hi√©rarchiser les priorit√©s, Capable de supporter des charges de travail parfois √©lev√©es R√©soudre des probl√©matiques complexes Savoir √™tre √ätre autonome, rigoureux(se), organis√©(e) Avoir un bon esprit d‚Äôanalyse, et une capacit√© √† explorer de nouvelles strat√©gies Preneur(se) d‚Äôinitiatives Avoir un gout prononc√© pour l‚Äôapprentissage de nouvelles technologies Disposer d‚Äôun bon niveau r√©dactionnel en fran√ßais/anglais. Niveau d‚Äô√©tude et exp√©rience : Bac +5 en maths/informatique minimum, et au moins 1 stage en entreprise sur des probl√©matiques de Data Engineering Vous avez une app√©tence pour la formation et votre √©tat d‚Äôesprit start-up vous permettra d‚Äô√©voluer rapidement et de tirer l‚Äôentreprise vers le haut ? Rejoignez-nous ! 1 - Appel de cadrage 2 - Entretien(s) avec l‚Äô√©quipe technique 3 - Evaluation technique 4 - Entretien avec un co-fondateur","DataScientest is a leader in data training in Europe, offering a variety of courses to both individuals and businesses. The organization aims to become a global champion in the next three years by continuing to offer relevant training and expanding geographically. The Data Engineer will be responsible for creating content, contributing to the development of the training environment, mentoring, and participating in data engineering events. Required skills include Python proficiency, object-oriented programming, ETL, database management systems, and a knowledge of cloud providers like AWS and Azure. Candidates should also be adaptable, able to work collaboratively, and able to manage competing priorities. A minimum of a bachelor's degree in math or computer science and experience working with data engineering problems is also required.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 6 mois,1,2,0.04154662416233763
206,65925,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/database-reliability-engineer-f-m-d_paris,Database Reliability Engineer,Decathlon Digital,"{Redis,MongoDB,Dynatrace,Github,NoSQL,ElasticSearch,Mysql,Aiven,AWS,via,Kafka,GCP,Datadog,SQL,CouchBase,Python}",T√©l√©travail partiel possible,"17 Rue de la Banque, Paris, 75002","Grande distribution, Sport, E-commerce",CDI,2023-04-05,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES CLOUD PLATFORM ENGINEERING Ses objectifs principaux sont de rationaliser le catalogue de produits techniques r√©f√©renc√©s au sein du groupe ET de fournir des services ‚Äúcl√© en main‚Äù pour les √©quipes IT, qui pourront ainsi se concentrer sur le d√©veloppement de services √† valeur ajout√©e. Le fait d‚Äôavoir moins d‚Äôoutils va permettre de mettre plus de monde sur chacun et d‚Äôapprofondir l‚Äôusage de ceux-ci. Il sera aussi plus simple de basculer d‚Äô√©quipe en √©quipe gr√¢ce √† des comp√©tences communes. Aujourd‚Äôhui, la CPE est une Business Unit de pr√®s de 150 personnes qui continuent √† se renforcer et travailler main dans la main avec les √©quipes de chaque domain. REJOINS L'√âQUIPE DATA BASE RELIABILITY ENGINEERING L‚Äô√©quipe Database Reliability Engineering que tu int√©greras s‚Äôoccupe de fournir des solutions de base de donn√©es les plus innovantes, les plus performantes et les plus packag√©es possibles afin d‚Äôacc√©l√©rer la mise √† disposition des applications pour nos clients finaux. Une partie du travail de l‚Äô√©quipe est d‚Äô industrialiser et d'automatiser les solutions r√©f√©renc√©es afin de toujours donner plus de moyens et d‚Äôautonomie aux d√©veloppeurs pour am√©liorer les performances de leurs applications. Un des objectifs est √©galement de tester les derni√®res solutions du march√© pour les int√©grer √† notre catalogue si un b√©n√©fice pour les √©quipes est identifi√©. L‚Äô√©quipe a √©galement une mission de conseil en architecture, d‚Äôaudit aupr√®s des applications et domaines afin de toujours coller au mieux aux besoins des √©quipes de d√©veloppement. Tu pourras i ntervenir sur des probl√©matiques de performances complexes sur des applications de l'ensemble de nos BUs √† l'international (60 pays). Tous nos h√©bergements sont d√©j√† sur le Cloud. Nous nous appuyons donc beaucoup sur des solutions manag√©es des Cloud Providers ou de tiers via les Marketplaces ou services agnostiques (#CloudNative). L'√©quipe doit s'assurer que chacune de ces offres soit en conformit√© avec notre Cloud Security Policy et adopter l'approche Security By Design. Le p√©rim√®tre technique : Databases : PgSQL, Mysql, MongoDB, Redis, CouchBase, OpenSearch Managed Databases : Aiven (avec Kafka, PgSQL, OpenSearch) Managed Databases : Amazon RDS, Cloud SQL Cloud Service Providers : GCP, AWS Infra-as-Code : Terraform / Python Observabilit√© / monitoring : Dynatrace, Datadog Gestion de code : Github CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience d' au moins 2 ans en bases de donn√©es et sur des solutions Cloud Tu es √† l‚Äôaise dans l‚Äô √©tude de performances des bases de donn√©es relationnelles et/ou NoSQL Tu as d√©j√† install√© et administr√© des bases de donn√©es et tu capitalises maintenant sur des connaissances plus larges √† propos des infrastructures Tu aimes d√©couvrir, tester les nouvelles solutions du march√© afin de faire des propositions pertinentes sur les produits et optimiser les services dont tu as la charge Tu es coutumier des bonnes pratiques DevOps et tu as √† c≈ìur de les mettre en oeuvre et des les partager avec le reste des √©quipes Tu es reconnu pour ton sens du service, tes capacit√©s d‚Äô√©coute et ta p√©dagogie Tu pratiques r√©guli√®rement l‚Äôanglais dans un contexte professionnel Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et la vie d'√©quipe ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) Tu poss√®des les hard skills suivantes : Databases : PgSQL, Mysql, MongoDB, Redis, CouchBase, OpenSearch - Niveau interm√©diaire sur une de ces technologies Managed Databases : Aiven (avec Kafka, PgSQL, ElasticSearch) - Niveau d√©butant Managed Databases : Amazon RDS, Cloud SQL - Niveau d√©butant Cloud Service Providers : GCP, AWS - Niveau d√©butant Infra-as-Code : Terraform / Python - Niveau interm√©diaire Observabilit√©/Monitoring : Dynatrace, Datadog - Niveau d√©butant Gestion de code : Github - Niveau interm√©diaire CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon √† Lille ou Paris (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon, the leading sportswear company, is seeking a Database Reliability Engineer to join their Cloud Platform Engineering team. The role involves providing innovative and high-quality database solutions, improving the performance of applications, and delivering automation and industrialization of the reference solutions. The ideal candidate should have a minimum of 2 years of experience in databases and cloud solutions, excellent knowledge of databases and cloud infrastructure, and proficiency in DevOps practices. Decathlon offers a flexible work environment, opportunities for professional growth, and a mission to make the benefits of sports accessible to everyone.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
204,65924,https://www.welcometothejungle.com/fr/companies/relyens/jobs/developpeur-etl-talend-h-f_lyon,DEVELOPPEUR ETL - TALEND,Relyens,"{SQL,Qlik,Talend}",T√©l√©travail partiel possible,"20 Rue Edouard Rochet, Lyon, 69008","Assurance, FinTech / InsurTech, Sant√©",CDI,2023-04-05,"Relyens est le Groupe mutualiste europ√©en de r√©f√©rence en Assurance et Management des risques sp√©cialiste des acteurs du soin (h√¥pitaux, cliniques, Ehpad, professionnels de sant√©‚Ä¶) et des territoires (r√©gions, mairies, √©lus locaux, centres de gestion‚Ä¶). Pour s√©curiser leur activit√© et garantir la qualit√© des services d√©livr√©s aux patients et citoyens, nous les accompagnons dans la ma√Ætrise des risques li√©s √† la d√©livrance du soin, √† la gestion du capital humain ou √† la cybers√©curit√©. Nous d√©ployons une approche globale et unique combinant des solutions de pilotage, de pr√©vention des risques et d'assurance. Cr√©√© √† Lyon il y a pr√®s de 100 ans par et pour des hospitaliers, Relyens est Entreprise √† Mission depuis 2021 . ¬´ Agir et innover, aux c√¥t√©s de celles et ceux qui ≈ìuvrent √† l'int√©r√™t g√©n√©ral, pour construire un monde de confiance .¬ª, telle est la raison d'√™tre qui anime nos 1100 collaborateurs en France, en Espagne, en Italie et en Allemagne. √Ä votre tour, rejoignez-nous et impliquons-nous ensemble pour ceux qui s'engagent. Pour en savoir plus, rendez-vous sur Relyens.eu Restons connect√©s : LinkedIn , Twitter , Youtube Au sein de notre DSI et en interaction forte avec les Services Finance & RH, vous intervenez sur la mise en ≈ìuvre des √©volutions majeures du Syst√®me d'Information financier et RH (en mode projet), sur les activit√©s de maintenance √©volutive et corrective et le support de niveau 3 (support technique) aupr√®s des utilisateurs. Vos missions : Au sein d'une √©quipe de 5 personnes, vos missions principales sont les suivantes : - Analyser les sp√©cifications fonctionnelles et assurer la conception technique et le d√©veloppement des flux de donn√©es ETL sous Talend sur le domaine SIFI/SIRH - Contribuer √† l'assistance aux phases de recette technique et fonctionnelle - Pr√©parer et accompagner les mises en production dans le respect des processus internes - Contribuer activement √† l'optimisation constante des flux de donn√©es sur le domaine SIFI/SIRH - Contribuer √† la r√©daction de la documentation (SFD, STD, CR d'atelier, cahier de tests, supports de formation‚Ä¶) - Assurer une bonne coordination avec les experts internes Talend afin de garantir la conformit√© avec les normes et standards de d√©veloppements IT Groupe - Assurer une assistance technique √† l'√©quipe en charge de l'exploitation du SI - Intervenir dans le cadre du support Assurer le bon fonctionnement du SIFI et du SIRH en assurant la supervision quotidienne des flux et batchs, et mener les actions correctives en respect des contraintes op√©rationnelles des √©quipes Finances et RH - Contribuer au d√©veloppement et au maintien en conditions op√©rationnelles des applications de pilotage financier et RH. Votre profil : De formation sup√©rieure type √©cole d'ing√©nieur ou √©quivalent en informatique, vous justifiez d'une exp√©rience d'au moins 3 ans dans la mise en en ≈ìuvre de flux ETL et ma√Ætrisez les bonnes pratiques de d√©veloppement et d'exploitation d'une plateforme. Vous poss√©dez les comp√©tences suivantes : ETL (Talend), langage SQL et manipulation de requ√™tes complexes, la s√©curisation des √©changes de donn√©es. Id√©alement vous avez des notions de comptabilit√© g√©n√©rale et technique (sch√©mas comptables, CRE / CRI‚Ä¶, d√©veloppement BI (Qlik)). Autonome, rigoureux, force de proposition et dot√© d'un tr√®s bon sens du service et du collectif, vous avez plaisir √† travailler en √©quipe dans des organisations matricielles et multisites, vous aimez intervenir en mode projet et sur des activit√©s de maintenance √©volutive et corrective. Vous faites preuve d'Agilit√© et √™tes √† l'aise avec les process et outils correspondants (orientation client, user stories, gestion du backlog, Kanban, JIRA, Confluence‚Ä¶). Un niveau d'anglais √† l'√©crit et √† l'oral de niveau B2 minimum est requis. Mission bas√©e √† Lyon, des d√©placements peuvent avoir lieu de fa√ßon tr√®s ponctuelle sur nos diff√©rents sites (France et International). Relyens est un Groupe handi-accueillant et handi-bienveillant. Tous nos postes sont ouverts aux personnes en situation de handicap.","Relyens, a European mutual insurance and risk management group specializing in healthcare and territory actors, is seeking a Financial and HR Information System Developer with at least 3 years of experience in ETL flow implementation, SQL, and data exchange security. The successful candidate will join a team of 5 people in Lyon and have a good understanding of accounting, BI development, and agile processes. The position requires occasional travel to Relyens' various sites in France and internationally. Relyens is a disability-friendly group, and all its positions are open to people with disabilities.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
202,57135,https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f_paris_EL_7z5xOwg,Data Engineer,Eleven Labs,"{Jupyter,SnowFlake,GO,Node,Spark,BigQuery,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"102, Rue du Faubourg Saint-Honor√©, Paris, 75008","Logiciels, IT / Digital, Audit",CDI,2023-03-26,"Eleven Labs est une soci√©t√© de conseil, sp√©cialis√©e en cr√©ation et r√©alisation de projets Web agiles de qualit√©. Les astronautes interviennent sur des missions qu‚Äôils choisissent, et elles sont ax√©es sur du d√©veloppement, de l‚Äôarchitecture, de la conduite de projet Agile, de l‚Äôaudit et du conseil. Au quotidien, tout est fait pour encourager la progression et l‚Äô√©panouissement technique, √† travers des plateformes d√©di√©es √† l‚Äôapprentissage ( le blog , le codelabs , des acc√®s √† Udemy et egghead.io ‚Ä¶), ou gr√¢ce √† des √©v√©nements internes (workshops, meetups, formations‚Ä¶) r√©guliers. Seras-tu notre furtur.e Data Engineer ! Un peu de contexte ‚òùÔ∏è De plus en plus de nos consultants s‚Äôint√©ressent de pr√®s au sujet de la Data, ce qui nous a pouss√© √† explorer ces probl√©matiques chez nos clients et de constater un besoin fort d‚Äôaccompagnement de leur part. Nous recherchons donc la personne qui ouvrira la voie √† cette expertise chez Eleven Labs et qui accompagnera la cr√©ation de l‚Äôescouade Data ! Nos attentes üß† Nous recherchons quelqu‚Äôun d‚Äôexp√©riment√©/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de r√©pondre au mieux aux probl√©matiques qui lui seront soumises, pour qui les requ√™tes SQL, NoSQL sur BDD n‚Äôont aucun secret, et qui ma√Ætrise d√©j√† une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake). üçí Cerise sur le g√¢teau : on cherche aussi un profil ma√Ætrisant les langages type Python, Java, GO et Node.JS pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribu√©. Des connaissances dans l‚Äôutilisation d‚Äôoutils ML et d‚Äôenvironnement Cloud en g√©n√©ral sont un vrai plus. üé≠ C√¥t√© personnalit√©, et outre cet aspect exp√©riment√© et ‚Äúouvreur de voie‚Äù, on cherche quelqu‚Äôun de moteur, avec un r√©el enthousiasme √† transmettre ses connaissances, former et √©changer. Les missions üïµÔ∏è Les missions propos√©es te feront intervenir dans des secteurs divers, avec des cas d‚Äôusage vari√©s souvent en lien avec le marketing et impliqueront principalement : d‚Äô√™tre force de proposition quant au choix des outils et pratiques ; faire de la data visualisation (B.I.) d‚Äôassurer l‚Äôextraction de donn√©es et leur transformation de g√©rer la mise en place from scratch de pipelines et data lakes. Nos engagements üí™ Tu participeras activement au d√©veloppement de l‚Äôescouade Data chez Eleven Labs pour laquelle nous avons de v√©ritables ambitions de production de contenu externe (talks, articles, implication dans le recrutement‚Ä¶), et interne (workshops, animation de la communaut√© Data, mentorat de profils juniors‚Ä¶). üî• Nos clients sont des sites grand publics principalement des secteurs m√©dias/presse et e-commerce, avec pour points communs un fort accent mis sur la qualit√©, et un fonctionnement en m√©thodologie Agile. üíñ Tu travailleras avec une √©quipe de passionn√©(e)s qui aime partager, remettre en question ses fa√ßons de faire, et trouver de nouvelles id√©es pour gagner en efficacit√©. ü§ù Tu √©volueras dans une culture d‚Äôentreprise qui valorise le collectif : nous restons m√™me √† 100 salari√©s une entreprise o√π les gens se connaissent et √©changent quotidiennement (pour parler de leur job mais aussi du dernier meme ou d‚Äôun compte Twitter improbable). Si tu es int√©ress√©(e), comment √ßa se passe ? üó®Ô∏è Tout commence par un entretien d‚Äôintroduction Tu t‚Äôentretiendras avec une recruteuse tech qui te suivra tout le long de ton parcours chez nous. Vous parlerez de tes attentes et de ce que tu aimes dans ton job, et elle te pr√©sentera Eleven Labs. üëã Ensuite il y a un entretien de cas pratique Pour avoir une id√©e de ce qui t‚Äôattend, on te propose de rencontrer R√©my (Data Architect) ainsi que Charles-√âric (Directeur Technique). üè† On conclut par une visite des locaux On t‚Äôinvite dans les locaux ! Tu pourras y rencontrer d‚Äôautres membres de la fus√©e pour √©changer sur leurs parcours et le tien autour d‚Äôun caf√©.","Eleven Labs is seeking an experienced Data Engineer with expertise in ETL/ELT pipeline and data lake/hub, SQL and NoSQL databases, and one or more Data Warehouse solutions. Proficiency in languages like Python, Java, GO, and Node.JS is preferable with knowledge in tools like Spark, Jupyter, and Cloud Run for distributed computing. The successful candidate should have a genuine enthusiasm for mentoring, sharing knowledge, and exchanging expertise with the team. The missions will involve data visualization, data extraction, transformation, and management for various sectors, with emphasis on marketing.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
172,57020,https://www.welcometothejungle.com/fr/companies/greenflex/jobs/data-engineer_paris,Data Engineer,GreenFlex,"{durable,InfluxDB,Databricks,Gitlab,AWS,DataDog,MLflow,Spark,SQL,Qlik,Python}",T√©l√©travail partiel possible,"7-11 boulevard Haussmann, Paris, 75009","Environnement / D√©veloppement durable, Energie",CDI,2023-03-26,"Nous aidons les organisations √† changer de trajectoire en se transformant sur le plan environnemental, √©nerg√©tique et soci√©tal. Notre raison d‚Äô√™tre ? Construire une √©conomie qui cr√©e et pr√©serve plus qu‚Äôelle ne d√©truit. Notre mod√®le est bas√© sur la multi expertise : Conseil-environnemental et soci√©tal Mise en ≈ìuvre de projets de performance √©nerg√©tique et bas-carbone Financement de la transition Plateforme digitale de pilotage des plans d‚Äôactions Face aux urgences environnementales et soci√©tales, ce mod√®le nous permet aujourd‚Äôhui d‚Äôacc√©l√©rer la transition de nos 800 clients et plus encore demain. GreenFlex recherche un Data Engineer pour participer √† l‚Äôaccompagnement des clients internes et grands comptes dans la r√©duction de leur empreinte √©nerg√©tique et environnementale √† travers des projets analytics. MISSIONS ET RESPONSABILIT√âS : Au sein d‚Äôune √©quipe digitale organis√©e en squads ¬´ agile ¬ª avec une forte culture devops, membre du Chapter Data Analytics, vous travaillerez sur l‚Äôindustrialisation des mod√®les de Machine Learning sur la plateforme Greenflex IQ, plateforme d√©di√©e √† l‚Äôacc√©l√©ration de la transition environnementale de ses clients (√©nergie, d√©veloppement durable, RSE, financement, ‚Ä¶). Vous aurez la possibilit√© de travailler sur un environnement √† haut niveau technique (AWS, Databricks, MLflow, Qlik, DataDog, Gitlab, librairies Python notamment de Data Science). Vous serez principalement amen√©(e) √† travailler sur des sujets orient√©s analyse de donn√©es et mod√©lisation qui consisteront √† : ‚Ä¢ Participer √† la poursuite de la mise en place et √† la maintenance des outils MLOps de la plateforme (model registry, model serving, model monitoring, automatisation, metadata handling, features store, etc.) ‚Ä¢ Contribuer √† la conception et aux d√©veloppements des nouveaux produits analytics de la plateforme, en appliquant les ¬´ best practices ¬ª du g√©nie logiciel ‚Ä¢ Assurer la maintenance des produits analytics ‚Ä¢ Alimenter et maintenir les documentations techniques Vous participerez √† l‚Äô√©laboration d‚Äôalgorithmes de traitement, d‚Äôanalyses de donn√©es et mod√®les d‚Äôapprentissage automatique avanc√©s : r√©seaux de neurones, clustering, r√©gression logistique, PCA‚Ä¶ Vous serez immerg√© dans les probl√©matiques m√©tiers des √©quipes de management de l‚Äô√©nergie sur des secteurs d‚Äôactivit√© tel que le retail, l‚Äôindustrie ou encore sur des probl√©matiques d‚ÄôENR ‚àí Grandes √©coles d‚Äôing√©nieur ou universit√© avec une majeur ou sp√©cialisation en math√©matiques appliqu√©es, statistiques ou big data analytics. ‚àí Exp√©rience professionnelle exig√©e : 4 ans en tant qu‚Äôing√©nieur de donn√©es, et ayant participer √† l‚Äôarchitecture et la r√©alisation de flux d‚Äôacquisition, d‚Äôingestion, de pr√©paration et de traitements de donn√©es (distribu√©s ou non) COMPETENCES TECHNIQUES : ‚àí Maitrise d‚Äôun langage de programmation, tel que Python, Pyspark est obligatoire ‚àí Maitrise d√©veloppement en Spark sur l‚Äôenvironnement Databricks / module Delta est obligatoire ‚àí Connaissances DevOps et GitOps ‚àí Connaissances en base de donn√©es tels que : SQL, InfluxDB, Spark, RDBMS ‚àí Maitrise d‚ÄôAPI tel que Graph QL serait appr√©ciable ‚àí Bonne maitrise d‚ÄôExcel et de PowerPoint ‚àí Bonne connaissance des enjeux environnementaux et IT ‚àí Une connaissance des m√©thodes d‚Äôexplicabilit√© des mod√®les de Machine Learning (XAI) serait un plus APTITUDES : ‚Ä¢ Esprit Engineering et G√©nie logiciel ‚Ä¢ Bon niveau d‚Äôanglais ‚Ä¢ M√©thodologies Agile ‚Ä¢ Une connaissance du secteur du d√©veloppement durable et/ou de l‚Äô√©nergie serait un plus SAVOIR ETRE : ‚àí Communication orale et √©crite claire ‚àí Sens du service ‚àí Qualit√© d‚Äô√©coute et de p√©dagogie ‚àí Esprit de collaboration ‚àí Autonomie ‚àí Rigueur","GreenFlex is seeking a data engineer with a degree in applied mathematics, statistics, or big data analytics and a minimum of 4 years' experience in data engineering. The candidate must have skills in programming languages like Python and Pyspark, DevOps, GitOps, database management, and a good understanding of environmental and IT issues. The role involves working on Machine Learning models, designing, and implementing new analytics products and maintaining existing analytics products. The candidate should have an engineering and software engineering mindset with good communication, collaboration, and listening skills.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 4 ans,2,1,0.04154662416233763
173,58074,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_montpellier,Expert technique ETL Semarchy xDI / Stambia,CGI,{},T√©l√©travail total possible,"Montpellier, 34000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Semarchy xDI / Stambia ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Semarchy ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√©.e d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert.e technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI is seeking a passionate and ambitious Data ETL Expert with at least 3 years of experience in technical integration of data within digital services or consulting firms. The candidate would join the Digital Innovation Center and work collaboratively in teams to support clients' digital transformation through the efficient delivery of data solutions. The role includes analyzing and improving solution efficacy, collaborating with experts on technical queries, facilitating training, participating in pre-sales as a technical expert, and supporting clients and teams on a daily basis. The ideal candidate has experience with Semarchy xDI / Stambia ETL and a desire to diversify their skill set. CGI is an inclusive employer committed to supporting diverse candidates and their career development.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,3,0,0.04154662416233763
174,56315,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-risk-dpm-sensitivities-f-h_charenton-le-pont_NATIX_yRRpMQO,Data Engineer Risk DPM Sensitivities,Natixis,"{durable,Scala,Kafka,via,Hive,Spark,Hadoop}",T√©l√©travail partiel possible,"avenue de la libert√© , Charenton-Le-Pont, 94018","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. En tant qu'employeur responsable et engag√© √† construire un environnement de travail inclusif, nous offrons les m√™mes opportunit√©s aux talents de tous horizons, ind√©pendamment de votre √¢ge, origine, orientation sexuelle, handicap... Au sein du d√©partement CIO CIB, vous rejoignez l'√©quipe de Sensitivities, au sein de l'IT Risks, compos√©e de 10 personnes. En nous rejoignant, vous prenez part √† plusieurs programmes de transformation de notre syst√®me d'information afin de r√©pondre aux besoins du d√©partement des risques, des r√©gulateurs, tout en accompagnant les front offices dans leurs nouvelles activit√©s. L'√©quipe est en charge de la maintenance et des √©volutions de deux applications cl√©s pour la gestion des risques de march√©s : Susanoo (repository des sensitivities ) et Amaterasu (calcul des sensitivities r√©pondant √† la r√©glementation FRTB). Nos principaux interlocuteurs sont le d√©partement des risques de march√©s (√©quipe de transformation et √©quipes de production du P&L), les √©quipes IT Natixis Paris (IT Front, et IT Risk), les √©quipes support/production √† Porto et les √©quipes infrastructure/big data. Au quotidien vous avez pour missions de : Concevoir les solutions techniques √† mettre en ≈ìuvre et estimer le co√ªt avec l'√©quipe ; D√©velopper de nouvelles fonctionnalit√©s de la phase de conception aux tests, dans une d√©marche durable (haute qualit√© du code, respect des principes d'architecture et de s√©curit√© informatique, documentation, automatisation des tests, utilisation maitris√©e de l'infrastructure) ; Travailler sur des probl√©matiques d'optimisation de performances et proposer des solutions innovantes ; Maintenir et am√©liorer la Software Factory et les environnements de d√©veloppement ; Assurer, avec l'√©quipe, le support de niveau 3 et les d√©veloppements n√©cessaires pour maintenir une production ponctuelle, de qualit√© et ma√Ætris√©e. La stack technique utilis√©e est la suivante : Hadoop, Spark, Scala, Hive, Sybase IQ et ASE Kafka. Nous travaillons en m√©thode agile avec des sprints de deux semaines. #MuchMoreThanJustAJob Le poste est bas√© √† Paris et √† Charenton-le-Pont et chez nous c'est 10 jours de t√©l√©travail par mois, 15 √† 17 jours de RTT par an, des services sur site comme la restauration, la salle de sport ou la conciergerie d'entreprise. Nos r√©mun√©rations sont compos√©es d'un fixe, d'un bonus annuel, d'un dispositif d'√©pargne entreprise incluant l'int√©ressement, la participation et l'abondement. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : De formation sup√©rieure en informatique avec une sp√©cialisation en big data, vous avez au moins 3 ans d'exp√©rience en tant que data engineer. Vous ma√Ætrisez : - Les langages Spark, Scala et Hadoop ; - La revue de code ; - La pr√©conisation de solutions techniques. Vous √™tes : - Reconnu pour votre leadership ; - Capable de proposer des am√©liorations continues ; - Rigoureux, autonome et p√©dagogue. Vous ma√Ætrisez l'anglais avec un niveau minimum B2. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis Corporate & Investment Banking is looking for a Data Engineer with at least 3 years of experience in big data who is proficient in Spark, Scala, and Hadoop. The role involves developing sustainable solutions, optimizing performance, and maintaining and improving the Software Factory and development environments. The successful candidate will be autonomous, rigorous, and able to propose continuous improvements while working in an agile framework. Natixis offers flexible working arrangements, career development and training opportunities, and the chance to make a positive impact on society.",Bac +4,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
175,56367,https://www.welcometothejungle.com/fr/companies/gojob/jobs/staff-ml-engineer-datascientist-aix-en-provence_aix-en-provence,Staff ML Engineer (DataScientist) - Aix en Provence,Gojob,"{Kubeflow,GCP,Azure,MongoDB,regard,Go,Gitlab,PostgreSQL,AWS,dbt,scale,R,BigQuery,Docker,SQL,Python,Elastic}",T√©l√©travail partiel possible,"220 Rue de la tramontane, Aix-En-Provence, 13090",Recrutement,CDI,2023-03-26,"Qui sommes-nous ? Implant√©e en France et aux USA, Gojob est une plateforme de service pour l‚Äôemploi qui s‚Äôappuie sur ses propres technologies et donn√©es pour rendre le march√© du travail plus fluide et accessible, et accompagner chaque individu avec dignit√©. Chez Gojob, ‚ÄúWe staff instantly, at scale and with care‚Äù. Membre trois ann√©es cons√©cutives de la promotion French Tech FT120, deux fois salu√©e par le prestigieux classement du Financial Times, √©lue n¬∞1 des Champions de la Croissance 2021 des Echos, Gojob continue son ascension sur le march√© de l‚Äôemploi pour un impact social concret. Notre ambition ‚ÄúProposer un accompagnement personnalis√© √† nos int√©rimaires quelque soit leur formation et leur exp√©rience et permettre √† nos clients de trouver instantan√©ment les meilleurs profils r√©pondant √† leurs exigences. ‚Äú Pour faire la diff√©rence et offrir un mod√®le 100% tech int√©gr√© sur un march√© de l‚Äôint√©rim traditionnel, nous avons cr√©√© et investi 12M‚Ç¨ en R&D dans notre laboratoire d√©di√© √† l‚ÄôIntelligence Artificielle afin de d√©velopper notre technologie propri√©taire. Fruit de 6 ans de recherche, nous avons aujourd‚Äôhui un √©cosyst√®me tech et data qui r√©volutionne les process de recrutement et r√©invente l‚Äôaccompagnement de l‚Äôindividu. Sourcing, matching, gestion, onboarding, suivi, formation‚Ä¶ chez Gojob, la technologie est partout. Avec une IA et des flux d‚Äôautomatisation bas√©s sur des donn√©es exclusives, notre stack tech nous permet de sourcer, s√©lectionner et valider des candidats : 32x plus rapidement qu‚Äôune agence traditionnelle Plus qualitativement : 95% des profils recommand√©s automatiquement par l‚ÄôIA sont embauch√©s et pr√©sents le premier jour. Tout en favorisant l‚Äôimpact social : notre algorithme matche les candidats les plus pertinents au regard de + 100 dimensions observ√©es, en prenant en compte les soft-skills et sans aucune discrimination. Cet algorithme est monitor√© par notre comit√© d‚Äô√©thique qui veille √† son int√©grit√©. Il fait l‚Äôobjet d‚Äôun brevet et nous avons publi√© plusieurs articles scientifiques sur le sujet. Reconnu pour son savoir-faire et souvent pr√©sent√© dans les m√©dias, le lab a su attirer des talents et des ing√©nieurs issus des meilleures formations en intelligence artificielle. Pr√©sentation du poste : La data est au coeur de la strat√©gie de Gojob. Notre √©quipe travaille quotidiennement sur du delivery avec un impact imm√©diat sur l‚Äôoffre de service Gojob. La Data science est partie prenante de l‚Äôactivit√© et en interaction r√©guli√®re avec les √©quipes produits, business et le Comex. Nous renfor√ßons l‚Äô√©quipe Data de notre labo d‚Äôintelligence artificielle avec un poste de Staff ML engineer (Data-Scientist) en CDI sur Aix-en-Provence. Vous aurez l‚Äôopportunit√© unique de travailler avec un groupe de passionn√©s pour une innovation continue qui r√©volutionne le march√© de l‚Äôemploi avec un impact social concret et r√©el. D√©tail des missions : Identifier, mod√©liser et d√©velopper des projets data science de bout en bout Vous travaillez en collaboration avec le Produit dans l‚Äôidentification de sujets sur lesquels la data science peut avoir de l‚Äôimpact au service du business et de la strat√©gie. Vous allez sur le terrain √† la rencontre des diff√©rentes parties prenantes de Gojob (m√©tiers en interne, clients, Gojobbers). Vous mod√©lisez les probl√®mes m√©tiers puis construisez avec pragmatisme, d√©ployez et maintenez les produits data science de bout en bout : scoring, matching, recommandation, sequence modelling, NLP. Vous am√©liorez continuellement les produits data science existants, entre autres, AGLAE : notre algorithme de matching au service des recruteurs de Gojob. Vous mesurez l‚Äôimpact de vos travaux et vous assurez de la p√©rennit√© de la performance des mod√®les mis en production. Faire progresser l‚Äô√©quipe Data Vous √™tes un √©l√©ment moteur dans la vie de l‚Äô√©quipe Data : daily, upskilling, partage de connaissance, Coproj avec le C-level.. Vous √™tes un mentor et r√©alisez le coaching technique des data scientists. Vous les aider √† monter en comp√©tence techniquement et √† gagner en ownership sur les projets data que vous avez initi√©s. Porter la voix de la data science chez Gojob Vous √™tes un vrai r√©f√©rent en data science aupr√®s de Gojob : vous r√©alisez une veille techno et scientifique constante, vous identifiez les prochains sujets ‚Äúgame changer‚Äù en lien avec le Head of Data, vous √™tes force de proposition pour faire √©voluer la stack Data de Gojob en lien avec le Data Engineer Vous avez la capacit√© √† expliquer et vulgariser des concepts complexes au business et aux utilisateurs. Valoriser les actifs tech de Gojob aupr√®s des investisseurs et de la communaut√© scientifique vous encadrez la r√©daction des brevets et d‚Äôarticles scientifiques vous g√©rez les relations avec les laboratoires et les universit√©s pour faire avancer notre recherche Quelle est notre stack technique ? Python, SQL Google Cloud Platform Docker, Gitlab CI/CD PostgreSQL, BigQuery, MongoDB, Elastic Search Poetry, VertexAI, Kubeflow Feature store, precompute, fast API dbt √ätes-vous notre futur(e) Staff ML engineer ? Vous avez au moins 5 ans d‚Äôexp√©rience en tant que ML Engineer-Data Scientist. Vous avez un cursus BAC+5 ou ing√©nieur dans un de ces domaines: informatique, stats, math√©matiques et/ou data science. L‚Äôobtention d‚Äôun PhD est un plus. Vous avez une r√©elle app√©tence pour les enjeux business et strat√©giques. Vous avez la capacit√© et le relationnel n√©cessaires pour √©changer avec les diff√©rentes parties prenantes de Gojob et faire √©voluer notre produit. Vous avez une exp√©rience consistante en mod√©lisation, et √™tes ainsi tr√®s √† l‚Äôaise pour faire le lien entre les besoins business et les solutions techniques possibles. Vous √™tes de nature entreprenante, vous savez porter des initiatives et √™tre un r√©el moteur de la strat√©gie data. Vous avez une excellente ma√Ætrise de Python et SQL et une exp√©rience professionnelle sur des projets NLP. Vous √™tes familier avec le d√©ploiement de solutions Data Science dans des infrastructures Cloud (type GCP, AWS, Azure ou autre). Vous savez travailler avec Gitlab, et une ma√Ætrise de la CI/CD est un plus. Ce que nous vous offrons : Une r√©mun√©ration attractive selon votre profil Une politique de t√©l√©travail flexible (2 jours/semaine et plus de flexibilit√© ponctuellement) La carte Swile (√©quivalent ticket resto) d‚Äôune valeur de 8‚Ç¨/jour pris en charge √† 55% par Gojob 6 semaines de Cong√©s Pay√©s Une excellente mutuelle/pr√©voyance 50% du titre de transport en commun rembours√© Des cours hebdomadaires de yoga Un forfait sport √† 150‚Ç¨/an Les avantages de Gojob: Si vous travaillez sur Aix-en-Provence : 300 jours de soleil par an dans un cadre de travail inspirant avec jardin avec vue sur les vignes et la lavande :) √† 30 minutes de la mer et juste √† c√¥t√© de la c√©l√®bre Sainte Victoire propice √† de superbes randonn√©es les week-ends ! Et pour tous‚Ä¶ Le ‚ÄúGo Community program‚Äù, c‚Äôest √† dire une team d√©di√©e, charg√©e d‚Äôanimer la vie de l‚Äôentreprise tous les mois en proposant des activit√©s culturelles, solidaires, sportives, sans oublier festives ! Quel est le processus de recrutement ? Un entretien avec Oliver (Head of data) Un √©change technique avec l‚Äô√©quipe Data Un entretien avec Guillaume (Head of product) Un entretien avec Nicolas (CTO)","Gojob, a job services platform with a focus on using technology and data to make the job market more accessible, is seeking a Staff ML Engineer (Data Scientist) to join its team in Aix-en-Provence, France. The successful candidate will work on identifying, modeling, and developing data science projects in collaboration with the product team, and is expected to have at least five years of experience as an ML engineer or data scientist. The role also involves mentoring and coaching data scientists, and promoting the voice of data science at Gojob. An excellent understanding of Python and SQL, and experience with NLP, are required for the role.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 5 ans,2,1,0.04154662416233763
164,65899,https://www.welcometothejungle.com/fr/companies/ekkiden/jobs/data-engineer-f-h_paris,Data engineer,Ekkiden Technologies,"{Cassandra,R}",T√©l√©travail partiel possible,"Paris, 75001","IT / Digital, Transformation",CDI,2023-04-05,"The consulting world needs a new, more human, more modern, and more agile actor. This is the ambition that gave birth to Ekkiden in 2019. Today, this international consulting group is challenging traditions and bringing a large dose of innovation to its sector. Through its ecosystem of passionate, enthusiastic, and committed consultants, Ekkiden leads organizational, operational, and technological transformation projects in three areas, IT/Digital, Industry/R&D and Pharma/Biotech, mainly with large accounts and SMEs. Le r√¥le: Data Engineer Responsabilit√©s: Vous alimenterez le datalake par des donn√©es Vous r√©aliserez les calculs d‚Äôagr√©gats Vous participerez √† la conception g√©n√©rale et √† l'analyse technique Vous d√©velopperez des programmes et les tests unitaires associ√©s Vous participerez √† la recette fonctionnelle et √† la pr√©paration de la mise en production Vous serez en charge du support aux utilisateurs Vous r√©aliserez des compte rendu des avanc√©es et des points d‚Äôalerte Ce que nous recherchons : Vous √™tes issu d'une formation Bac+ 5 en informatique Vous justifiez de bonnes connaissances sur Cassandra Vous √™tes curieux, ouvert d'esprit et poss√©dez un bon esprit d'investigation et d'analyse Ce que nous proposons: ü§ù Nous rejoindre au bon moment pour faire ta place au sein d‚Äôune organisation en tr√®s forte croissance üöÄ Des missions vari√©es dans un environnement challengeant qui te permettront d‚Äôavoir un r√©el impact sur la bo√Æte üí™ La possibilit√© de travailler de fa√ßon autonome et d‚Äô√™tre force de proposition pour grandir ensemble ‚ú® Un parcours de carri√®re adapt√© √† ta personnalit√©, aussi bien au niveau du r√¥le que de la localit√© ü§ì Une formation exigeante en continu pour lib√©rer tout ton potentiel üëç Des conditions de travail flexibles (horaires, t√©l√©travail, ‚Ä¶) üí∏ Une culture de la performance avec de belles primes de r√©sultats ‚ù§Ô∏è Une mutuelle tr√®s compl√®te (Alan) et des titres-restaurant (carte Swile)","Ekkiden, an international consulting group, is seeking a Data Engineer with knowledge of Cassandra to contribute to its data lake, perform aggregation calculations, develop programs and participate in functional testing, among other responsibilities. The role offers the opportunity to work with a fast-growing organization, have a real impact, work autonomously, and receive continuous training and flexible work conditions.",Bac +5 / Master,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
176,56436,https://www.welcometothejungle.com/fr/companies/hove/jobs/data-engineer-paris-h-f_paris,Data Engineer - Paris -,Hove,"{Kinesis,Flink,Databricks,Github,Scala,AWS,Storm,Kafka,Linux,Spark,datahub,Git,Java,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"20 rue Hector Malot , Paris, 75012","Application mobile, Mobilit√©, SaaS / Cloud Services",CDI,2023-03-26,"Hove est un acteur incontournable de la data-mobilit√©, en plus d‚Äô√™tre une filiale de Keolis. Depuis sa cr√©ation il y a 24 ans, Hove est un acteur cl√© dans ce domaine et l‚Äôun des premiers experts. Il occupe une place consid√©rable dans l‚Äô√©cosyst√®me de la mobilit√© et fait partie d‚Äôune communaut√© de 20 000 d√©veloppeurs, qui participent √† leur strat√©gie d‚Äôinnovation ouverte et collaborative. Acteur de la Greentech, Hove porte une vision √©volutive des mobilit√©s douces, pour un impact plus positif et plus responsable de notre environnement gr√¢ce √† ses 2 produits et m√©tiers : Avec Navitia , Hove travaille continuellement √† l‚Äôam√©lioration des algorithmes qui permettent de calculer les meilleures solutions d‚Äôitin√©raire, tout en tenant compte du contexte et des pr√©f√©rences du voyageur. L‚Äôobjectif ? permettre √† chacun de se d√©placer plus facilement, plus agr√©ablement et avec le moins d‚Äôimpact possible sur la plan√®te. Avec Patterns , Hove analyse les motifs que dessinent les mobilit√©s sur un territoire cibl√©. L‚Äôobjectif ? Suivre la fr√©quentation, √† travers des matrices origine ‚Äì destination, les parts modales‚Ä¶ √Ä partir du recueil et de l‚Äôanalyse des traces GPS et WiFi, entre autres. En tant que Data engineer Hove, vous √™tes int√©gr√© √† une √©quipe pluridisciplinaire m√™lant d√©veloppeurs, Product Owner, Architectes dont l‚Äôobjectif est de cr√©er des services √† fortes valeur ajout√© dans le domaine du transport. Vous avez la charge de d√©finir et mettre en ≈ìuvre le pipeline d‚Äôacquisition des donn√©es (datahub) global pour Hove, d‚Äôorganiser sont stockage (datalake) et de permettre son utilisation tant par des briques logicielles que par des data scientists et data analystes. Vous assurerez les missions suivantes : Cr√©er et faire √©voluer le moteur d‚Äôingestion des donn√©es (ingestion, traitement et exposition) en batch et streaming Assurer la mise en production et la maintenabilit√© des flux de donn√©es Travailler en collaboration avec les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©grations continues, scalabilit√© des mod√®les, craftsmanship, etc‚Ä¶) Analyser et comprendre les besoins clients avec les Product managers et/ou les Business Owners D√©ployer des infrastructures cloud full infra as code (Terraform) pour faire le traitement des donn√©es Superviser et monitorer le d√©ploiement et la robustesse des composants mis en production Participer activement √† la qualit√© de l‚Äôing√©nierie logicielle (Relecture de code, test, int√©gration continue, d√©ploiement, etc.) Participer aux √©v√®nements internes √† la communaut√© data interne et externes (AWS Summit, workshops, meetups‚Ä¶) Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.* Vous justifiez d‚Äôune exp√©rience d‚Äôau moins 2 ans en tant que Data engineer Vous op√©rez dans le conseil et pouvez justifier de vos missions Vous maitrisez l‚Äôanglais professionnel Vous maitrisez au moins : Un framework de calcul distribu√© tel que Spark, Storm, Flink. Un ou plusieurs langages de programmation (Python, Java, C/C++, Scala‚Ä¶). Diff√©rents syst√®mes de base de donn√©es (SQL et NoSQL) et le langage SQL. Un framework de streaming de donn√©es tel que Kafka, Kinesis, ‚Ä¶ Une exp√©rience sur les technologies Cloud AWS Technologies : Python, Java, Scala Apache Spark, Suite Databricks‚Ä¶ Cloud AWS Terraform, CloudFormation Git / Github, SonarQube, Linux Enfin le delivery et les projets en production faisant parti de notre ADN, vous devrez √™tre capable de livrer du code de qualit√© dans un environnement dans les temps et dans le budget imparti. Un call RH Un entretien avec l‚Äô√©quipe tech Un entretien avec notre CTO","Hove, a subsidiary of Keolis, is seeking a Data Engineer with at least two years of experience in the field. The ideal candidate will have proficiency in distributed computing frameworks such as Spark, Storm, and Flink, programming languages including Python, Java, C/C++, and Scala, and streaming data frameworks like Kafka and Kinesis. They will also have experience with AWS technologies, including Terraform and CloudFormation, and knowledge of SQL and NoSQL databases. The role involves working in a multidisciplinary team to develop high-value services in the transport sector, including designing and implementing a global data acquisition pipeline, managing data storage, and providing support to data scientists and analysts.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,2,1,0.04154662416233763
198,56696,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-engineering-manager-f-h_evry_CARRE_aPXyR8o,Data Engineering Manager,Carrefour,"{durable,Looker,dbt,Node,scale,BigQuery,Python}",T√©l√©travail partiel possible,√âvry,"Grande distribution, E-commerce, Grande consommation",CDI,2023-03-26,"Si Carrefour est partenaire de Paris 2024, c'est parce que nous retrouvons beaucoup de nous dans les valeurs du sport ! Nous aimons les challenges et visons une performance durable : Face aux d√©fis de notre √©poque, Carrefour a pour ambition de rendre le meilleur accessible √† tous et de s'affirmer en chef de file d'une distribution responsable. Cela signifie de nombreux projets et occasions d'innover au quotidien pour nos √©quipes. Nous nous √©panouissons en √©quipe : M√©tiers du commerce, m√©tiers d'expertise, entrepreneurs unissent leurs comp√©tences et leurs efforts pour construire ensemble une cha√Æne de valeur au service des consommateurs. Au plus pr√®s de nos clients ou en coulisses, chacun a un r√¥le √† jouer mais peut compter sur les autres pour r√©ussir. Nous veillons √† ce que chacun puisse aller loin : L'envie et le m√©rite sont les seuls pr√©-requis pour nous rejoindre, acc√©der √† une formation, changer de m√©tier, √™tre promu ou cr√©er son entreprise. Nous partageons la victoire : nos collaborateurs sont engag√©s et nous nous engageons en retour. En offrant des r√©mun√©rations et des avantages parmi les meilleurs de notre secteur, en permettant √† chacun d'√™tre associ√© aux r√©sultats, en veillant √† la sant√© de tous. Carrefour capitalise sur la richesse de ses donn√©es pour d√©velopper de nouvelles solutions √† destination de ses partenaires, incluant le partage d'insights √† forte valeur ajout√©e, le ciblage et l'activation marketing au travers de campagnes de derni√®re g√©n√©ration, la publicit√© digitale cibl√©e, etc. L'ensemble de ces solutions sont d√©velopp√©es et d√©ploy√©es dans le cadre d'un programme de valorisation de la donn√©e appel√© ""Carrefour Links"". Porteur de cette ambition, la Direction Links Operations, recrute un(e) : Data Engineering Manager F/H BON √Ä SAVOIR : ASAP / CDI / CADRE / MASSY Missions Rattach√©(e) au CTO Carrefour Links, vous √™tes responsable des √©quipes d'ing√©nierie des produits Carrefour Links. Dans ce cadre, vous incarnez la strat√©gie technique et la d√©clinez au sein de vos √©quipes. Vous vous assurez du recrutement et de l'accompagnement des nouveaux profils, du suivi et du coaching des √©quipes en place, de la mise en place et de l'optimisation des bonnes pratiques ainsi que de la coordination avec les autres parties prenantes du p√©rim√®tre. Responsabilit√©s : ‚óè Participe activement au processus de recrutement des nouveaux profils ‚óè Suit les prestations de service sur le p√©rim√®tre ‚óè Met en place un parcours de ramp-up afin de garantir aux nouveaux arrivants une int√©gration optimale au sein des √©quipes ‚óè Assure le d√©veloppement des √©quipes gr√¢ce √† une communication ouverte, un coaching continu et la mise en place de bonnes pratiques ‚óè Identifie les probl√®mes existants et travaille avec les √©quipes pour les r√©soudre ‚óè Collabore √©troitement avec le CTO et est force de proposition sur l'√©volution de la stack technique et le choix des outils ‚óè Se synchronise avec l'ensemble des parties prenantes du programme Links (produits, business, plateforme, RUN, p√¥le agile‚Ä¶) ‚óè S'assure aupr√®s des √©quipes du delivery des produits avec le bon niveau de qualit√© Exemples de profils dans les √©quipes : Tech Lead, Data &amp; Analytics Engineers, QA Engineers, D√©veloppeurs Cloud Exemples de technologies utilis√©es sur le p√©rim√®tre Carrefour Links : BigQuery, dbt, Looker, Data Studio, Cloud Functions, Cloud Workflows, Node.js, Vue.js, Python. Informations compl√©mentaires En rejoignant Carrefour Links au sein du Groupe Carrefour, vous b√©n√©ficiez d'avantages sociaux √©labor√©s pour vous fournir un cadre de travail des plus attractifs et flexibles : ‚óè Le t√©l√©travail √† votre rythme : jusqu'√† 3 jours de t√©l√©travail par semaine et 2 jours de pr√©sence sur le site de Massy en flex office ‚óè Une activit√© en plein scale-up avec des √©quipes qui s'agrandissent ; ‚óè Des avantages sociaux et financiers attractifs : Primes, int√©ressement, Participation, Avantages collaborateurs sur achats Carrefour, R√©gime de retraite, Mutuelle avantageuse, Comit√© d'Entreprise g√©n√©reux pour vos Loisirs, Voyages et √âquipements, etc. ‚óè L'acc√®s √† des services exclusifs √† Massy : salle de sport, cr√®che, plusieurs options de restauration au sein du si√®ge avec participation CE, infirmerie, t√©l√©consultation m√©dicale, conciergerie, coiffeur, etc. ‚óè Carrefour s'engage pour la sant√© et le bien-√™tre de ses collaborateurs en leur proposant une solution gratuite pour faire du sport : Gymlib ‚óè Un acc√®s √† un large choix de restauration (dont Paul et Starbucks au sein du campus) ‚óè Des opportunit√©s de formation continue (l'Universit√© Carrefour, la Digital Academy) ; ‚óè La mobilit√© internationale : des plans de mobilit√© pour nos collaborateurs qui souhaitent rejoindre l'une de nos neuf filiales ; Chez Carrefour, nous avons √† c≈ìur de ne passer √† c√¥t√© d'aucun talent et sommes fiers de compter des √©quipes repr√©sentatives de la soci√©t√© dans son ensemble. Nous encourageons ainsi tous types de profils √† postuler √† cette offre et garantissons un processus de recrutement d√©nu√© de toutes formes de discriminations. Profil : ‚óè Vous √™tes dipl√¥m√©(e) d'une √©cole d'ing√©nieur ou √©quivalent Bac+5 minimum. ‚óè Vous avez une exp√©rience d'au moins 5 ans dans le d√©veloppement logiciel (id√©alement sur des produits Data) dont 2 sur un poste √©quivalent. ‚óè Vous avez un anglais professionnel √† l'oral comme √† l'√©crit. Comp√©tences : ‚óè Vous √™tes passionn√©(e) par la Data et faisant preuve √† la fois d'expertise technique et d'app√©tence fonctionnelle. ‚óè Vous aimez construire et animer des √©quipes d'ing√©nierie logicielle. ‚óè Vous avez une exp√©rience av√©r√©e dans la mise en place de pipeline d'analytics de bout-en-bout dans un contexte industriel et sur des volum√©tries importantes. ‚óè Vous avez de bonnes comp√©tences dans l'architecture des syst√®mes, bases de donn√©es, m√©thodologies d'analyse. ‚óè Vous appr√©ciez le travail en √©quipe dans un contexte Agile (Scrum, SAFe) ‚óè Vous faites preuve de leadership et √™tes capable de f√©d√©rer les diff√©rentes parties prenantes autour de vos initiatives. ‚óè Vous √™tes curieux/se et menez r√©guli√®rement de la veille technologique autour des th√©matiques Cloud, Data, IA et Devops.","Carrefour is seeking a Data Engineering Manager to be responsible for the engineering teams of Carrefour Links products. The ideal candidate should have experience in software development, a passion for data, and hands-on expertise in analytics pipelines. The role involves coaching, hiring, and improving teams, proposing ideas on technical stacks, and coordinating with various stakeholders such as business, platform, and run. The candidate should also have good skills in system architecture, data analysis methodologies, and agile practices. Carrefour offers a flexible work environment with attractive social and financial benefits.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
196,56515,https://www.welcometothejungle.com/fr/companies/echosens/jobs/ingenieur-data-h-f_paris,Ing√©nieur Data,Echosens,"{Java,SQL,Python,Talend}",T√©l√©travail partiel possible,"6, Rue Ferrus, Paris, 75014","Logiciels, SaaS / Cloud Services, Objets connect√©s, Intelligence artificielle / Machine Learning, Sant√©, Pharmaceutique / Biotechnologique",CDI,2023-03-26,"Echosens, entreprise fran√ßaise innovante de haute technologie cr√©√©e en 2001, est le leader mondial des dispositifs m√©dicaux non invasifs dans le domaine de l‚Äôh√©patologie. Forte d‚Äôun rythme ambitieux de d√©veloppement de ses produits, Echosens est √©galement pr√©sente dans les activit√©s d‚ÄôE-sant√© (syst√®me de diagnostic avanc√©). Echosens poursuit sa strat√©gie d‚Äôexpansion internationale au travers de ses filiales en Chine, aux Etats-Unis et en Europe (Allemagne, Espagne, Angleterre et Italie) et commercialise ses produits et ses services dans plus de 100 pays. Rejoindre Echosens , c‚Äôest faire le choix d‚Äôun parcours professionnel dynamique, enrichissant et valorisant. Dans le cadre de son fort d√©veloppement, Echosens recrute en CDI un : Ing√©nieur Data (H/F) Poste bas√© Paris 14i√®me Int√©gr√©(e) au sein de la Direction des Syst√®mes d‚ÄôInformation (7 personnes) et rattach√©(e) au Responsable P√¥le Projets, vous concevez, mettez en ≈ìuvre, faites √©voluer et op√©rer les flux d‚Äô√©change de donn√©es entre les applications de l‚Äôentreprise tout en s‚Äôassurant de la coh√©rence des donn√©es de l‚Äôentreprise (gestion, stockage, s√©curit√©). Votre r√¥le central vous am√®ne √† la conception des interfaces, la mod√©lisation des donn√©es, leur mise en ≈ìuvre et la d√©finition des attentes d‚Äôint√©grit√©, de s√©curit√© et de disponibilit√© des donn√©es au sein de l‚Äôentreprise. Vous serez √©galement en charge de g√©rer le portefeuille d‚Äôinterfaces (Webservices, ETL) et leur cycle de vie, ainsi que contribuer au design de ces interfaces en lien avec les applications m√©tier de l‚Äôentreprise. Enfin, vous g√©rerez la surveillance des flux de donn√©es et serez garant de la r√©solution d‚Äôincidents qui pourraient en d√©couler. Vous √™tes garant de l‚Äôint√©grit√©, de la s√©curit√© et de la disponibilit√© des donn√©es d‚ÄôEchosens et proposerez des am√©liorations de mod√®les de donn√©es, de flux et de technologies associ√©es. Environnement technique du poste : ¬∑ SQL , Java , Python. ¬∑ ETL (Talend) ¬∑ API Webservices Rest/Soap. Titulaire d‚Äôun dipl√¥me Bac+3 en informatique (ou exp√©rience √©quivalente), vous disposez d‚Äôune exp√©rience r√©ussie de 3 ans minimum dans l‚Äôint√©gration de flux de donn√©es d‚ÄôERP/CRM. Vous poss√©dez de r√©elles qualit√©s relationnelles. Rigoureu(x/se), organis√©(e) et m√©thodique, vous savez analyser et synth√©tiser les situations. Votre curiosit√© technique vous permet d‚Äôappr√©hender de nouvelles technologies et d‚Äô√™tre force de proposition. Enfin, votre esprit d‚Äô√©quipe sera un atout majeur pour mener √† bien ce challenge ambitieux. 1 entretien RH par Teams 1 entretien en pr√©sentiel Manager/DSI 1 entretien avec un autre manager op√©rationnel","Echosens, a French innovative high-technology company that focuses on non-invasive medical devices in hepatology and e-health, is seeking a Data Engineer to design, implement, and operate data exchange flows between the company's applications while ensuring the integrity, security, and availability of data. The ideal candidate will have a minimum of three years of experience in integrating ERP/CRM data flows and possess excellent analytical, organizational, and technical skills with knowledge of SQL, Java, Python, ETL (Talend), and API Webservices Rest/Soap. The position is based in Paris, and the company offers a dynamic and rewarding professional career path.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
157,56648,https://www.welcometothejungle.com/fr/companies/raedy/jobs/data-engineer_neuilly-sur-seine,Data Engineer,R√¶dy,"{durable,Scala,Atscale,Presto,Hive,Spark,scale,moderne,Hadoop,Python,Tableau}",T√©l√©travail partiel possible,"89, Boulevard Pereire, Paris, 75017","Digital Marketing / Data Marketing, IT / Digital, Audit",CDI,2023-03-26,"R√¶dy est une jeune entreprise innovante qui a pour ambition de red√©finir les codes du service num√©rique en cr√©ant ¬´ l‚ÄôArtisanat au Service du Num√©rique ¬ª. A l‚Äôinstar des artisans, R√¶dy tend vers l‚ÄôExcellence du service afin d‚Äôaccompagner ses clients sur l‚Äôensemble du cycle de vie de leur Acc√©l√©ration Digitale : Acquisition et valorisation du savoir-faire Ajout constant de valeur Animation d‚Äôune communaut√© d‚Äôexperts D√©veloppement de partenariats productifs √ätre Data Engineer chez R√¶dy, √ßa consiste √† quoi ? D√©velopper des solutions techniques de stockages Concevoir l‚Äôarchitecture technique n√©cessaire pour la valorisation des donn√©es Prioriser les besoins m√©tiers Mod√©liser, d√©velopper et effectuer la maintenance du Datawarehouse Assurer la clart√© et la s√©curit√© des donn√©es D√©celer les dysfonctionnements √©ventuels Consolider les donn√©es √† des fins analytiques ou de Datascience Explorer et effecteur la fouille des donn√©es R√©aliser des tests unitaires et d‚Äôint√©gration Suivre le RUN Participer √† des POC Mettre √† jour les technologies et langages utilis√©s Assurer le suivi de production et la maintenance Comp√©tences requises Tu fais de la veille informatique et technologique pour compl√©ter ton expertise L‚Äôesprit d‚Äô√©quipe est essentiel pour toi Tu ma√Ætrises les langages Scala, Spark et Python Tu as des connaissances dans la gestion volume de donn√©e et d‚Äôapplications Big Data sur Hadoop Tu as des connaissances sur les nouvelles techniques analytiques Big Data : Apache Kylin, Atscale, Hive, Presto DB Tu utilises les techniques de visualisation de donn√©es : Tableau Software Tu ma√Ætrise la m√©thode agile Petit + : tu as des connaissances en mod√©lisation datalake C‚Äôest pour toi si : Ce r√¥le est pour toi si tu aimes cr√©er, concevoir et travailler en √©quipe ! Fort de ta curiosit√© data et tech, tu es capable d‚Äôintervenir en totale autonomie et d‚Äô√™tre force de proposition sur des solutions respectant les contraintes internes. Tu es passionn√©.e, organis√©.e et curieux.se avec un bon √©tat d‚Äôesprit Tu as une formation d‚Äôing√©nieur en informatique ou √©quivalent (Bac +5) Tu as minimum 3 √† 5 ans d‚Äôexp√©rience significative Tu ma√Ætrises l‚Äôenvironnement data √† la perfection 1/ Tout commencera avec un premier entretien avec nos Talents Acquisition Recruiters. Tu pourras parler de toi, tes exp√©riences, tes attentes et nos √©quipes t‚Äô√©claiciront sur la mission. 2/ Un √©change technique sera alors effectu√© pour analyser tes comp√©tences. 3/ Si le feeling passe et que la mission te convient, un deuxi√®me entretien sera organis√© avec notre client. L‚Äôoccasion d‚Äô√©changer sur tes motivations et expertises m√©tier. Vous allez pouvoir partager vos passions pour la data avant que l‚Äôaventure ne commence ü§ûüèº Pourquoi rejoindre R√¶dy ? ## Notre devise, ¬´ l‚ÄôArtisanat au Service du Num√©rique ¬ª prend tout son sens quand il s‚Äôagit de recruter. Notre approche permet de r√©pondre √† vos attentes, vos ambitions d‚Äô√©volution et de les faire correspondre aux exigences de nos clients. CDI ou freelance, pas de diff√©rence pour nous, votre bien √™tre et votre √©panouissement seront notre priorit√©. En nous rejoignant, vous travaillerez aux c√¥t√©s des acteurs du SBF120, des ETI, des scale-up et des licornes. Les + : Salaire en fonction de ton exp√©rience T√©l√©travail autoris√© Swile : titres-restaurant 12,50‚Ç¨ / jour (participation √† 60‚Ç¨) et forfait mobilit√© durable (50‚Ç¨/ mois) Alan : la meilleure mutuelle et pr√©voyance prise en charge √† 100% Beaucoup de travail et beaucoup de fun Afterworks et √©v√®nements r√©guliers Si tu as lu jusqu‚Äôici, n‚Äôh√©site plus ! Rejoins une entreprise moderne, disruptive et en plein d√©veloppement. On attend ton CV ü§ó","R√¶dy is looking for a data engineer to develop technical storage solutions and design the necessary architecture for data optimization. The ideal candidate should have expertise in Scala, Spark, and Python, as well as knowledge of Hadoop and Big Data analytical techniques such as Apache Kylin and Presto DB. The role requires strong teamwork skills and the ability to work autonomously. The company offers a flexible work environment and opportunities for career development.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 4 ans,2,1,0.04154662416233763
178,34327,https://www.welcometothejungle.com/fr/companies/disneyland-paris/jobs/data-engineer-f-h-cdi_chessy,Data Engineer  - CDI,Disneyland¬Æ Paris,"{GCP,Redshift,Kubernetes,Glue,AWS,S3,Snowflake,Docker,SageMaker,Spark,Git,Sagemaker,SQL,Python,EC2,Tableau}",T√©l√©travail partiel possible,Chessy,"Cin√©ma, Tourisme, Loisirs",CDI,2022-08-08,"Pour faire vivre la magie, Disneyland¬Æ Paris peut compter sur l‚Äôengagement et l‚Äôexpertise de multiples talents nomm√©s Cast Members, qui font vivre le parc Disneyland¬Æ, le parc Walt Disney Studios¬Æ, le centre de divertissements Disney Village¬Æ ainsi que nos h√¥tels √† th√®me. Disneyland¬Æ Paris est une soci√©t√© o√π les r√™ves deviennent vraiment r√©alit√©. Nos Cast Members travaillent dans des centaines de professions li√©es aux op√©rations et au soutien, sur sc√®ne ou en coulisses. Leur mission : offrir √† chaque client une exp√©rience Disney inoubliable. La passion et l‚Äôenthousiasme de nos √©quipes ont fait de notre soci√©t√© la destination touristique num√©ro un en Europe ! Faire r√™ver implique de grandes responsabilit√©s. Pour notre destination, la performance sur le long terme doit s‚Äôappuyer sur un mod√®le de tourisme responsable. Nous avons pris des engagements socio-environnementaux tr√®s importants, que nous nous attachons √† concr√©tiser avec l‚Äôimplication constante de nos collaborateurs et parties prenantes. Disneyland Paris est une filiale de la Walt Disney Company, leader international du secteur du divertissement et des m√©dias. Voici votre chance de vivre une aventure professionnelle unique ! Votre environnement ? Disneyland Paris vit actuellement une transformation data en se dotant d‚Äôune √©quipe centralis√©e (Data Office) et d‚Äôune data platform sur AWS pour exploiter ses donn√©es riches et vari√©es : digital, billetterie, h√©bergement, op√©rations, maintenance, finance, boutiques, restaurants, supply chain, costumes, flux, ressources humaines‚Ä¶ Le Disneyland Paris Data Office est au c≈ìur de ce projet de transformation et pilote : La maintenance et l‚Äô√©volution de notre data platform, la centralisation de la donn√©e au sein d‚Äôun datalake, la production de la valeur √† partir de nos donn√©es ; La promotion de l‚Äôutilisation de la data et l‚Äôacc√©l√©ration du self-BI pour r√©duire les temps d‚Äôanalyse et de prise de d√©cision ; L‚Äôanimation des communaut√©s d‚Äôutilisateurs ; La d√©finition et le d√©veloppement des produits data-driven bas√©s sur l‚Äôintelligence artificielle. Nous mettons ainsi la data au c≈ìur des d√©cisions strat√©giques et facilitons l‚Äôacc√®s √† la data pour tous. Nous encourageons nos √©quipes √† r√©aliser le potentiel qu‚Äôapporte la data, √† se rendre compte de sa puissance et les aidons √† innover. Dans ce contexte, nous recrutons un(e) Data Engineer qui interviendra dans le d√©ploiement de cas d‚Äôusage data au service des m√©tiers, par les m√©thodes de collecte de la donn√©e jusqu‚Äô√† son exposition et en contribuant √† la mise en place de pipeline de machine learning. Vous rejoindrez l‚Äô√©quipe Data compos√©e d‚Äôune trentaine de personnes et reporterez au Senior Manager Decisions. Vous contribuerez aux avanc√©es de nos squad, en collaboration avec les autres membres de l‚Äô√©quipe data (Product Owner, Data Engineer, BI Developer, Data Steward, Tester), dans un environnement stimulant, o√π l‚Äôesprit d‚Äô√©quipe et la volont√© continue d‚Äôam√©lioration & d‚Äôapprentissage sont cl√© ! Chacun des membres de l‚Äô√©quipe a l‚Äôopportunit√© d‚Äô√™tre acteur de ce que nous mettons en place. Vous aurez ainsi la possibilit√© d‚Äôapporter vos connaissances, remettre en question l‚Äôexistant, innover, mettre en place de nouvelles choses constamment et rapidement ! Vos missions ? Vous participerez activement √† la construction de notre data platform et aux choix des outils , aiderez √† la prise de d√©cision et √† d√©velopper la croissance de Disneyland Paris. Vos missions consistent, en particulier, √† : Etudier et mettre en place les meilleures solutions techniques pour g√©rer de grands volumes de donn√©es, de la collecte de donn√©es d‚Äôentrainement jusqu‚Äôau d√©ploiement en production ; Maitriser la qualit√© du code mis en production pour assurer le run (Git, √©valuation de performance de mod√®le) ; Travailler en collaboration avec le Data Engineer, le Data Scientist et le Product Owner pour int√©grer des mod√®les machine learning en tant que livrables dans un produit ; D√©velopper et maintenir notre stack data √† l‚Äô√©tat de l‚Äôart ; Contribuer par de nouveaux data pipelines : Collecter sur notre datalake (S3), d√©velopper et maintenir les flux d‚Äôentr√©e et de sortie de la DP, sur des donn√©es internes et externes, en batch et realtime, jusqu‚Äô√† l‚Äôactivation des donn√©es (Snowflake / Redshift / Tableau, APIs‚Ä¶) Transformer la donn√©e collect√©e, enrichir et maintenir notre data warehouse (Snowflake) Assurer l‚Äôint√©grit√© du cycle de vie de la donn√©e Dessiner, mettre en place et maintenir tout le pipeline de production pour d√©ployer des mod√®les de machine learning avec les Data Scientists Proposer, mettre en place et accompagner les best practices au sein de l‚Äôorganisation data (agile, code review, ‚Ä¶) ; Pratiquer de la veille technologique sur le cloud et le data engineering. Vous aurez l‚Äôopportunit√© de travailler sur des technologies vari√©es. Notre environnement technique actuel, en cours de construction donc non exhaustif, se base sur AWS Glue / S3 / EC2 / Sagemaker, Snowflake, Python, Spark, SQL, Git . Nous rejoindre, c‚Äôest la garantie de participer √† la naissance du projet data platform et d‚Äôavoir de l‚Äôimpact dans sa structuration et ses choix technologiques ! Vous aurez l‚Äôopportunit√© de travailler sur des sujets tr√®s diversifi√©s , avec le support des √©quipes Data Science & Engineering de The Walt Disney Company aux √âtats-Unis. La diff√©rence Disneyland Paris ? Un environnement exceptionnel, international et multiculturel, concentr√© sur un site unique ; Un environnement o√π les valeurs d‚Äôinclusion et de diversit√© sont cl√©, dans lequel tous les collaborateurs sont encourag√©s √† √™tre authentiques ; Une session d‚Äôint√©gration compl√®te et un large √©ventail d‚Äôoptions de formation pour le d√©veloppement des comp√©tences ; De nombreuses possibilit√©s de carri√®re (promotion interne ou mobilit√© horizontale). Pr√™t(e) √† participer √† une formidable aventure humaine ? A rejoindre nos collaborateurs (Cast Members) partageant la m√™me ambition professionnelle : celle de faire vivre la magie Disneyland Paris pour les millions de visiteurs qui viennent dans nos parcs tous les ans ? Il ne vous reste plus qu‚Äô√† postuler car nous sommes pr√™ts √† vous donner les moyens de faire rayonner vos talents ! Disneyland Paris est soucieux d‚Äôoffrir √† ses Cast Members les conditions de travail les plus favorables √† leur √©panouissement professionnel. Dans ce cadre et pour garantir une flexibilit√© optimale, les emplois qui ne n√©cessitent pas une intervention ou l‚Äôacc√®s √† des installations ou applications sur site et/ou des interactions physiques peuvent s‚Äôexercer en t√©l√©travail, avec un minimum de pr√©sence requis de cinq jours par mois sur site. Nos bureaux sont situ√©s √† 5 minutes √† pieds de la gare de Val d‚ÄôEurope. Vous √™tes le/la candidat(e) id√©al(e) pour ce poste si : Vous √™tes issu(e) d‚Äôune formation sup√©rieure type √©cole d‚Äôing√©nieur ou master sp√©cialis√© en data engineering/big data/cloud engineering/data science et avez acquis une exp√©rience de 5 ans minimum dans des projets data , au sein d‚Äôun environnement international et agile ; Vous connaissez au moins un environnement cloud (AWS ou GCP) et avez d√©j√† d√©ploy√© du code sur ce dernier ; Vous avez d√©j√† particip√© √† un projet de datawarehouse ; Vous ma√Ætrisez un langage de programmation ( Python et SQL en priorit√©) ou de configuration YAML, connaissez les concepts DevOps (Docker, Kubernetes) et les services manag√©s (AWS) ; Vous avez une exp√©rience dans l‚Äôindustrialisation de mod√®les de machine learning (AWS SageMaker) ; Vous savez vous exprimer en anglais couramment (niveau C1) pour une utilisation quotidienne √† l‚Äô√©crit comme √† l‚Äôoral, ainsi qu‚Äôen fran√ßais (niveau B2). Vous r√©ussirez dans ce r√¥le si : Vous faites preuve de curiosit√© et √™tes capable de proposer, tester de nouvelles choses, remettre en question l‚Äôexistant et faire des recommandations ; Votre leadership vous permet d‚Äô√™tre √† l‚Äôaise pour porter un sujet, le d√©fendre, le vendre aupr√®s de vos interlocuteurs techniques comme fonctionnels ; vous savez vulgariser les sujets techniques pour convaincre ; Vous appr√©ciez collaborer avec des interlocuteurs pluridisciplinaires, travailler en √©quipe et partager votre savoir ; Vous √™tes particuli√®rement sensible √† la qualit√© des d√©ploiements et mettez tout en ≈ìuvre pour d√©livrer un produit de qualit√©. C‚Äôest le bon moment pour avoir un fort impact sur nos activit√©s et contribuer √† la mont√©e en puissance de la culture data au sein d‚Äôun environnement incroyablement sp√©cial ! Premier √©change avec notre recruteur pour faire connaissance et voir si nous pouvons aller plus loin ensemble Entretien avec notre recruteur et √©valuer l‚Äôad√©quation entre votre personnalit√©, vos attentes et ce que nous pouvons vous offrir Entretien avec notre data engineer pour vous donner une vision √©largie du poste et √©valuer vos capacit√©s techniques Entretien avec nos product owners pour vous donner une vision fonctionnelle et √©valuer vos capacit√©s fonctionnelles Entretien final avec vos futurs manager et N+2 pour vous envisager au sein de notre environnement. Bien s√ªr, l‚Äôensemble de ces √©changes peut se faire √† distance, dans un d√©lai que nous nous effor√ßons de raccourcir un maximum. Les candidatures sont √©tudi√©es au fur et √† mesure de leur arriv√©e ; ne passez pas √† c√¥t√©, postulez d√®s maintenant !","Disneyland Paris is looking for a Data Engineer to join their Data Office team, participating in the development of their data platform by deploying data use cases for the business. The successful candidate will work alongside Data Scientists and Product Owners to integrate machine learning models and ensure optimal data engineering practices. The role requires a minimum of 5 years of experience in data engineering, with a deep knowledge of at least one cloud environment such as AWS or GCP, and proficiency in Python and SQL. Strong communication skills in English and French are also necessary. Disneyland Paris offers a unique and international environment, with training options and career development opportunities.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
182,36576,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-tableau-dataviz-bi-factory-f-m-d_nantes,BI Engineer Tableau / DataViz - BI Factory,Decathlon Technology,"{AWS,dataset,github,GCP,SQL,Tableau}",T√©l√©travail partiel possible,N,"Grande distribution, Sport, E-commerce",CDI,2022-10-12,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris, Lille, Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour r√©pondre aux mieux a son ambition de pilotage par la data, Decathlon a organis√© une DATA UNIT √† laquelle la BI Factory est rattach√©e. TA RESPONSABILITE : Ta mission principale consiste √† : R√©pondre √† des demandes d‚Äôanalyses r√©currentes de KPIs en mettant √† disposition des m√©tiers, de mani√®re automatique et r√©guli√®re, des outils de data visualisation performants. Intervenir d√®s la finalisation du cadrage projet par le Project Manager jusqu‚Äô√† la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : Project Manager, les autres BI Engineers, les m√©tiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e BI Engineer, bas√©-e, au choix √† Paris, Lille, Lyon ou Nantes. Le p√©rim√®tre technique : ma√Ætrise du SQL ma√Ætrise d‚Äôune BDD ma√Ætrise d‚Äôun ETL ma√Ætrise d‚Äôun outil de datavisualisation (id√©alement Tableau software) R√©daction de documentation dans github et/ou wiki M√©thodologie AGILE CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience d‚Äôau moins 3 ans en d√©veloppement BI et parle un Anglais courant (relation avec des √©quipes √† l'international). Tu as d√©j√† produit de la data visualisation performant avec Tableau Software ; Pour r√©ussir, tu dois savoir: Comprendre le besoin m√©tier / interagir avec les interlocuteurs fonctionnels Comprendre un mod√®le de donn√©es et t'en servir. Mod√©liser un dataset afin de d√©velopper des visualisations en assurant les performances techniques D√©velopper le flux d‚Äôextraction des data n√©cessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages m√©tiers exprim√©s lors du cadrage Ma√Ætriser les technologies utilis√©es et les bonnes pratiques de d√©veloppement Partager ton avancement et les difficult√©s rencontr√©es lors des instances AGILE d√©di√©es. R√©diger la documentation technique permettant d‚Äôassurer un run efficace Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et la vie en √©quipes ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a BI Engineer with three years of experience in BI development, data visualization, and expertise in SQL, ETL, and data visualization tools such as Tableau. The selected candidate will be responsible for developing data extraction flow, modeling datasets, and providing technical expertise on visualizing KPIs. Additionally, the candidate will coordinate with the data team, project managers, and other BI Engineers, and contribute to agile instances to ensure efficient deliveries. Decathlon Technology offers opportunities for mentoring, diverse projects, and certifications, with the possibility of teleworking two days a week and working from any Decathlon office in Lille, Paris, Nantes, or Lyon.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
192,50457,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",T√©l√©travail partiel possible,"Tour EDF La D√©fense, Colombes, 92400","Environnement / D√©veloppement durable, Energie",CDI,2023-02-07,"Chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez EDF m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Au sein de la DSIN, le Centre de Solutions et de Comp√©tences DataScience & IA (CSC DS & IA), a pour mission de r√©aliser les travaux d'analyse et de valorisation des donn√©es de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux m√©tiers du March√© d'Affaires et du March√© des Clients Particuliers pour r√©pondre √† des enjeux vari√©s comme les d√©parts √† la concurrence, la conqu√™te de nouveaux clients, la satisfaction client, la d√©tection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de donn√©es cons√©quentes (~26 millions de clients, B2C+B2B). Afin de r√©pondre √† ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une √©quipe de Data Engineer, et en appui d'une √©quipe de plus de 20 Data Scientists, votre mission consistera √† : - Mettre en place des pipelines de traitements de donn√©es - avec des volumes importants de donn√©es (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de donn√©es distribu√©es (Spark ‚Ä¶) - Extraire massivement des donn√©es (Hadoop - Hive, Oracle - SQL, ‚Ä¶) - vous-m√™me ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de donn√©es (compr√©hension des probl√©matiques Yarn, JVM, tablespace temp‚Ä¶) - Accompagner les Data Scientists dans le maintien et l'√©volution des outils de requ√™tage d√©velopp√©s en interne (dnquery pour requeter Oracle et Hive), extension √† une nouvelle technologie de stockage des donn√©es (PostGre, SQL Server‚Ä¶) - Accompagner les d√©ploiements de mod√®les de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des cha√Ænes r√©currentes de type traitement de la donn√©e ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer √† la construction des strat√©gies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer √† l'√©volution de l'environnement technique des Data Scientists Votre Profil ? - Vous √™tes titulaire d'un Bac +5 (Master, dipl√¥me d'ing√©nieur) dans le domaine informatique, des math√©matiques / statistiques, de la Data Science ou du Big Data - Vous b√©n√©ficiez d'une exp√©rience d'au moins 3 ans en tant que Data Engineer - Vous avez d√©j√† travaill√© dans un contexte de Datascience et automatis√© des traitements de type Datascience - Vous ma√Ætrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez d√©j√† manipul√© des donn√©es stock√©es sous S3 - Vous √™tes √† l'aise avec les outils collaboratifs de d√©veloppement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous b√©n√©ficiez d'une ou plusieurs exp√©riences de travail en mode Agile - Vous √™tes curieux et les projets innovants vous passionnent - Vous √™tes force de proposition et proactif - Vous aimez transmettre et travailler en √©quipe M√©thodologie de travail : Vous collaborerez √©troitement avec les R√©f√©rents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'√©quipe en charge des lacs de donn√©es au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark‚Ä¶). Le poste est situ√© √† Colombes, proche de La D√©fense Ouest, avec une possibilit√© de t√©l√©travail partiel. R√©mun√©ration : Fourchette estimative : entre 50k et 57k‚Ç¨, la r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is seeking a Data Engineer to join its Center of Solutions and Competences Data Science & AI (CSC DS & IA) team. The role involves setting up data processing pipelines, helping data scientists in debugging and data extraction, deploying machine learning models, and contributing to the evolution of the technical environment for data scientists. Candidates must have at least three years of experience as a data engineer and hold a Master's degree, engineering diploma or equivalent in computer science, mathematics/statistics, data science or big data. Proficiency in Python, SQL, Docker, and Airflow, and experience with Hadoop and S3 storage systems are must-haves. The position is located in Colombes, France, near La D√©fense Ouest, with the possibility of partial teleworking. The salary ranges from ‚Ç¨50k to ‚Ç¨57k and is commensurate with experience and market trends.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
184,36687,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/engineering-manager_paris,Engineering Manager Data,Contentsquare,"{go,regard,ContentSquare,color,Aerospike,Akka,Contentsquare,Kafka,scale,Spark,ClickHouse}",T√©l√©travail partiel possible,N,SaaS / Cloud Services,CDI,2022-10-12,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since our founding in France in 2012, we have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. We‚Äôve been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, we raised $600M in Series F funding, doubling our valuation to $5.6B. But we‚Äôre not stopping there. To reach our ambitious goals for the future, we will be nearly doubling the size of our global workforce in the next 2 years. Want to learn, innovate and contribute your unique perspective to an industry leader? Join the team dedicated to bringing more human analytics to the world! As an Engineering Manager, you will join and lead a team of passionate and talented Data Engineers. Do not hesitate to check on our YouTube video to see what it's like to be a Data Engineer at ContentSquare! We collect several billions of events per day and query hundreds of terabytes in real-time. The role of the Data Team is to: ‚Ä¢ Design robust and efficient architectures to store and analyze petabytes of data ‚Ä¢ Select, along with the product team, valuable functionalities for Contentsquare users ‚Ä¢ Develop, test, and deploy corresponding features to best serve the functionalities ‚Ä¢ Constantly maintain and improve the underlying infrastructure and services leveraging state of the art technologies such as Kafka, Spark, Akka, ClickHouse, Aerospike‚Ä¶ ‚Ä¢ Integrate the best technologies and innovate to optimize accuracy, speed, and cost ‚Ä¢ Contribute to advance and share tech knowledge by contributing to open source projects, publishing articles, and participating in events As an Engineering Manager, you will be one of the leaders of the Data Team, with a responsibility to: ‚Ä¢ Collaborate with Product to determine the tech roadmap and priorities for your team ‚Ä¢ Ensure your team makes the right technical choices ‚Ä¢ Lead the timely and efficient delivery of multiple large scale projects by your team ‚Ä¢ Identify & address risks, determine the team staffing needs ‚Ä¢ Manage your team (rituals, career path, recruitment) and mentor Senior team members ‚Ä¢ Interact with other stakeholders (other Data Engineering Teams, Data Science, QA, Front End, & Platform Teams, Product, Program Management, HR‚Ä¶) to collectively succeed Why join ContentSquare‚Äôs Data Engineering team? ‚Ä¢You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data ‚Ä¢You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences ‚Ä¢You are looking for an environment where you‚Äôll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategic corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross-team innovation days, we are committed to innovating towards tomorrow‚Äôs user experience. You‚Äôll also have flexible working hours, remote days; soccer, handball, yoga, and many other activities; after-work beers provided every Friday, monthly parties‚Ä¶and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare - We‚Äôre humans first. We hire talented people and provide them with the trust, resources and flexibility to get the job done - We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits - We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge opportunity to make an immediate and lasting impact - Our clients, partners and investors love our industry-leading product To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are some we‚Äôd like to highlight: - Virtual onboarding, Hackathon, and our annual kickoff trip on a global basis! You have the opportunity to interact with our global colleagues - Generous paid time-off policy (every location is different) - Immediate eligibility for birthing and non-birthing parental leave - Wellbeing allowance - Home Office Allowance - A Culture Crew in every country to organize regular outings such as game nights, movie nights, and happy hours - Every full-time employee receives stock options, allowing them to share in the company‚Äôs success - We offer many benefits in various countries -- ask your recruiter for more information Uniqueness is embedded in our DNA as one of our core values. We welcome everyone to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare, a digital experience analytics company, is looking for an Engineering Manager to lead and collaborate with their passionate and talented Data Engineers team. The ideal candidate is responsible for leading the team in delivering multiple large-scale projects, identifying risks, determining team staffing needs and making the right technical choices. Contentsquare aims to double its global workforce in the next two years and values innovation, diversity, and flexibility. They offer a generous paid time-off policy, home office allowance, and wellbeing allowance, among other benefits. They are looking for individuals who are committed to innovating the user experience and want to join their awesome adventure.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
185,65908,https://www.welcometothejungle.com/fr/companies/3dsoutscale/jobs/data-engineer-f-h_saint-cloud,Data Engineer,3DS OUTSCALE,"{scala,matplotlib,pandas,tableau,R,Spark,kafka,bokeh,Python,numpy}",T√©l√©travail partiel possible,"1 rue royale , Saint-Cloud, 92210 ","SaaS / Cloud Services, Big Data",CDI,2023-04-05,"L‚Äôhistoire de 3DS OUTSCALE a d√©but√© en 2010 avec un objectif : assurer la souverainet√© des donn√©es et garantir leur s√©curit√© au quotidien. Filiale et partenaire strat√©gique de Dassault Syst√®mes, 3DS OUTSCALE s‚Äôest impos√© comme le Cloud d‚Äôhyper-confiance aupr√®s des OIV, du secteur public et des √©diteurs de logiciel en proposant des services Cloud d‚ÄôInfrastructure hautement qualifi√©s : ISO 27001, HDS, SecNumCloud, RSE Lucie 26000‚Ä¶ Pour assurer la qualit√© de nos services et en ma√Ætriser le c≈ìur technologique, nous avons d√©velopp√© notre propre orchestrateur de IaaS : TINA OS, qui √©volue continuellement par l‚Äôinnovation de notre d√©partement R&D. Vous rejoindrez une entreprise humaine, compos√©e d‚ÄôOutscaliennes et d‚ÄôOutscaliens passionn√©.es par la technologie, motiv√©.es d‚Äôapprendre en continu dans une ambiance agr√©able. Nous sommes fier.√®res de voir grandir nos √©quipes dans un contexte de perp√©tuelle croissance. Nous recherchons des talents aux valeurs fortes, passionn√©.es par les challenges que repr√©sentent le Cloud ! Nos valeurs : L‚ÄôExcellence L‚ÄôExpertise L‚ÄôHumain √âtant une entreprise en perp√©tuelle croissance, et toujours √† la recherche de nouveaux talents, nous recrutons un¬∑e Data Engineer afin de renforcer notre SU Billing . Vos missions Rattach√©¬∑e au sein de la Service Unit Billing, le collaborateur¬∑trice contribuera aux projets relatifs aux traitements des donn√©es de facturation des ressources du Cloud. Les applications de facturation g√©n√®rent les diff√©rents rapports de consommation (√† la demande et r√©guliers), les tableaux de bord et les factures destin√©s aux clients externes et internes (autres SU). Vos missions seront les suivantes : La pr√©paration, l‚Äôimpl√©mentation et le contr√¥le des donn√©es n√©cessaires dans les diff√©rents projets La d√©finition et la conception des indicateurs de performance La pr√©paration de rapports et des autres livrables L‚Äôautomatisation et p√©rennisation des tableau de bords La diffusion de la culture de la data aupr√®s des √©quipes m√©tiers La veille technologique Stack technique Donn√©es machines de test et de production : consommation, √©v√©nements, etc. Time series analysis, donn√©s cat√©goriques, Machine learning (clustering, classification, etc.) Python (numpy, pandas, scikits, matplotlib, bokeh) et/or scala Spark (rdd, stream, ml), kafka Titulaire d‚Äôun BAC+5 d‚Äôune grande √©cole ou d‚Äôun master avec une sp√©cialisation en traitement de donn√©es, vous √™tes rigoureux, organis√©(e) et m√©thodique. Vous poss√©dez un fort int√©r√™t pour le monde de l‚ÄôIT Vous appr√©ciez le travail en √©quipe Vous √™tes force de proposition, pers√©v√©rant¬∑e et proactif¬∑ve Vous parlez anglais couramment La Diversit√© de 3DS OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privil√©gie l‚Äô√©galit√© des chances, la diversit√© des individus au sein de nos √©quipes.","3DS OUTSCALE, a cloud infrastructure provider, is seeking a Data Engineer to join its Service Unit Billing team. The candidate will be responsible for contributing to billing data processing and generating consumption reports, dashboards, and invoices. The ideal candidate should possess a Bachelor's or Master's degree with a specialization in data processing and have expertise in time series analysis, categorical data, machine learning, Python, Scala, Spark, Kafka, and English proficiency. The company values excellence, expertise, and a human touch while encouraging diversity and equal opportunities.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,2,1,0.04154662416233763
210,65913,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/data-engineer-f-h_la-defense_INGNI_g5AxQwL,Data Engineer -,Ing√©niance,"{GCP,Redis,Scala,Kubernetes,AWS,Storm,Cassandra,Hadoop,Azure,Java,NoSQL,SQL,Python,Cloudera,docker}",T√©l√©travail partiel possible,La Defense,IT / Digital,CDI,2023-04-05,"Ing√©niance, est une soci√©t√© de conseil sp√©cialis√©e dans des projets li√©s aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajout√©e en associant innovation technologique, transformation digitale, expertise m√©tier (Banque, Finance et Assurance) & m√©thodes agiles. Technology-oriented, elle offre une r√©elle expertise √† ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l‚ÄôAgilit√©. Son projet d‚Äôentreprise s‚Äôappuie aussi sur des valeurs humaines, soci√©tales et environnementales (Label EcoVadis Gold). La proximit√©, la performance, la convivialit√© et le progr√®s sont des atouts sur lesquels elle b√¢tit son√©volution collective au quotidien. Quelles seront vos missions ? Vos missions s'inscrivent dans un contexte de travail Agile, au sein du centre d'expertise Data en charge du d√©veloppement et de la gestion des syst√®mes de collecte, normalisation croisement et restitution des donn√©es. Dans ce cadre, vous contribuerez √† : D√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, stockage) D√©velopper des moyens de restitution de la donn√©e (APIs, g√©n√©ration fichier, autres...) Industrialiser et automatiser les tests des APIs (Swagger, Postman, ...) D√©velopper des moyens de parall√®lisation des processus (Apache Storm, Multithreading, ...) D√©finir les bonnes pratiques de d√©veloppements sur le cloud (AWS, Azure, GCP, ...) R√©diger la documentation n√©cessaire au partage et √† la maintenance du code Faire partie d'une √©quipe agile et suivre la m√©thodologie Scrum Qui √™tes-vous ? Entre 5 et 10 ans d'exp√©rience en d√©veloppement dont au moins 3 sur un programme DATA Vous ma√Ætriser un langage de programmation (Java, C#, Scala, Python) Vous √™tes √† l'aise avec les architectures distribu√©es ou sur le cloud et leur mise en place. Vous avez de solides connaissances en SQL ainsi que sur des bases de donn√©es NoSQL (Mango, Redis, Cassandra) Vous avez d√©j√† travaill√© avec des outils de conteneurisation comme docker et d'orchestration tel que Kubernetes Enfin vous avez d√©j√† impl√©ment√© des solutions dans le cloud (AWS, Azure, GCP...) Les comp√©tences que vous renforcerez : Vous interviendrez sur la conception et le d√©ploiement d'environnements ¬´ clusturis√©s ¬ª de type Datalake (Hadoop/Cloud & distributions Hortonworks, Cloudera) Vous pourrez vous confronter et contribuer √† une communaut√© d'experts Vous accompagnerez les √©quipes de Datascientist, d'experts du Machine Learning et des approches statistiques, sur des projets de mise en oeuvre de ces approche s et du traitement des donn√©es associ√©es. Vous √©voluerez dans un environnement fonctionnel riche","Ing√©niance, a technology-oriented consulting company specializing in finance, seeks a Senior Data Engineer with at least five years of development experience, three of which are in a data program. The candidate should be skilled in programming languages such as Java, C#, Scala, or Python, as well as having experience in distributed or cloud architectures, SQL, and NoSQL databases. The candidate should also have experience with tools such as Docker and Kubernetes, and implementing solutions in AWS, Azure, or GCP. The candidate will work in an Agile environment and follow Scrum methodology, contributing to the development and management of data collection, normalization, cross-referencing, and restitution systems.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
166,64475,https://www.welcometothejungle.com/fr/companies/mckinsey-digital/jobs/data-engineer,Data Engineer,McKinsey Digital,"{intrinsic,iterative,Scala,modular,scale,R,Python}",T√©l√©travail partiel possible,Paris,"Intelligence artificielle / Machine Learning, IT / Digital, Strat√©gie, SaaS / Cloud Services, Big Data",CDI,2023-04-03,"McKinsey Digital accompagne les organisations dans l‚Äôexploitation de la puissance de la technologie et de la donn√©e pour concevoir de nouvelles exp√©riences, optimiser leurs op√©rations et cr√©er de nouveaux business. Pour cela, le p√¥le met √† leur disposition le meilleur de ses comp√©tences (combinaison de talents tech et de talents m√©tiers), ses approches innovantes (telles que Leap by McKinsey, activit√© de cr√©ation de nouveaux business num√©riques), un large √©cosyst√®me de partenaires, ainsi que de nombreuses solutions propri√©taires utilis√©es au quotidien. Le Digital est en tr√®s forte croissance et concerne d√©j√† la moiti√© des projets r√©alis√©s par McKinsey & Company. McKinsey Digital s‚Äôappuie sur l‚Äôexpertise et la richesse exceptionnelle des 6 000 talents qui constituent le p√¥le √† l‚Äô√©chelle mondiale, parmi lesquels des data scientists, designers, ing√©nieurs, architectes IT, d√©veloppeurs, responsables technologiques, coaches agiles, designers reconnus et experts en cybers√©curit√©. McKinsey Digital France compte une centaine de personnes. McKinsey Digital met au service de ses clients le meilleur de ses expertises digitales √† travers le monde, dans plus de 60 pays, de mani√®re transparente et flexible. WHO YOU‚ÄôLL WORK WITH Based in Paris and working across the region, as a consultant data engineer you will work closely with our clients, data scientists and all types of McKinsey consultants to curate problem specific datasets that feed directly into our machine learning and modelling approach. This hybrid client-facing/technical role will allow you to use state of the art technologies to solve highly impactful business problems, whilst also leveraging your strong communication skills to convey complex intractable ideas to non-technical audiences. Who you are This position is for a data engineer (all seniority levels) with strong intrinsic technical ability and an aptitude to solving complex problems using technology. A core value at QuantumBlack is fusion and at the heart of our multi-disciplinary teams is the belief that the sum of individual parts will always be less than the impact of the entire team. You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly. Trust between colleagues is paramount here ‚Äì you are an individual who can always be trusted to work in the best interests of all colleagues and to achieve the best outcome for QuantumBlack and our clients. You are naturally enthusiastic and enjoy sharing your passion with others. WHAT YOU‚ÄôLL DO As a Data Engineer with the Paris office‚Ä¶ You will work in multi-disciplinary environments harnessing data to provide real-world impact for organizations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance. See our video: A Day in the Life of a Data Engineer Role responsibilities Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches Acquire, ingest, and process data from multiple sources and systems into Big Data platforms Understanding, assessing and mapping the data landscape. Maintaining our Information Security standards on the engagement. Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models. Defining the technology stack to be provisioned by our infrastructure team. Building modular pipeline to construct features and modelling tables. Use new and creative techniques to deliver impact for our clients as well as internal R&D projects. What you‚Äôll learn _No project is ever the same ‚Äì we work across multiple sectors, providing unique learning and development opportunities across the region._ How successful projects on real world problems across a variety of industries are completed through referencing past deliveries of end to end pipelines. Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations. Be focused on the wrangling, clean-up and transformation of data by working alongside the Data Science team which focuses on modelling the data. Using new technologies and problem-solving skills in a multicultural and creative environment. You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport. Master‚Äôs degree in quantitative field like computer science, engineering, statistics, mathematics or related field required; advanced degree advantageous Experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data Ability to write clean, maintainable, and robust code in Python, Scala, or similar languages Familiarity with the latest OSS, cloud, container, query languages and database technologies Ability to work collaboratively in a team environment Commercial client-facing or senior stakeholder management experience a plus Fluency in both English and French Willingness to travel up to 60% Interviewing is a two-way process‚Äîit gives us the opportunity to learn about you as a potential colleague, and allows you to learn about McKinsey and what you could do here. Overall, we look for personal impact, entrepreneurial drive, inclusive leadership and problem solving, as well as your technical skills. As a Data Engineer, the process will assess your technical skills during Pair programming and technical interviews as well as your business sense.","McKinsey Digital, which helps organizations optimize operations, create new business opportunities, and design new customer experiences, is seeking a consultant data engineer in Paris. The successful candidate will work with clients and data scientists to create problem-specific datasets for use in machine learning and modeling projects. The role is client-facing and requires strong communication skills, alongside demonstrable technical competence in building data pipelines in production. Fluency in French and English, as well as availability for up to 60% travel, is also required.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
190,39763,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-data-scientist-h-f-cdi-paris_puteaux,Data Engineer/ Data scientist  - CDI - Paris,AXA,"{Microsoft,GCP,AZURE,Databricks,Git,Scala,AWS,R,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,"VILLE DE PUTEAUX, Puteaux, 92400","Banque, Assurance, FinTech / InsurTech",CDI,2022-11-29,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l‚Äôassurance et de la gestion d‚Äôactifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous prot√©ger en donnant √† chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! 1. AXA GROUP The AXA Group, world leader in Financial Protection, supports and advises its individual and corporate customers at every life stage, providing them with the products and services that meet their insurance, personal protection, savings and wealth management needs. Our areas of expertise are reflected in a range of products and services adapted to the needs of each client in three major business lines: property-casualty insurance, life & savings, and asset management. In 2022, present in 64 countries, the 153,000 employees and distributors of AXA were committed to serving 105 million clients. AXA Corporate Center‚Äôs main missions are to: Steer the entities in order to ensure the coherence of the strategies, the consistency of the commercial approaches as well as the optimization of the risks and results; Defining and coordinating Group policies, different transversal projects and standards, identifying and sharing best practices; Supporting the entities in order to help them to grow, to develop their offer, their management and steering standards as well as their risk management. The head office of AXA Group (GIE AXA), based in La D√©fense, gathers the Group's corporate activities. It coordinates the various entities according to the Group's strategy and is responsible for managing international projects. The headquarters is composed with over 1000 employees and is distinguished by its strong international culture (45 nationalities). 2. PRESENTATION OF THE DIRECTION Group Performance Management (GPM) is responsible for performance monitoring within the Group. Its objective is to coordinate a regular dialogue with the entities in order to deliver to the Group Management Committee of AXA information on the financial, operational and strategic performance of the entities and to be the Gatekeeper for Group requests vis a vis the entities. Information Management team is part of Group Performance Management Department within Group Finance. Led by the Corporate Center Chief Data Officer, Information Management team setup and deploy the Data strategy though (i) Data Governance and Data Quality Programs, (ii) efficient Data Architecture design, (iii) Data Operation services and (iv) Data Culture fostering. 3. PRIMARY MISSION: Within the Information Management team, you will be responsible for (i) organizing, optimizing, and operating the collection of transversal data, either external or internal (ii) optimizing their distribution, (iii) ensuring their quality and (iv) controlling the entire data lifecycle, from collection to operational use. You will work hand in hand with Business Data Analysts and Data Transformation teams prioritizing and implementing use cases to create value for the overall organization. 4. KEY ACCOUNTABILITIES: We are looking for a Data Engineer to take part in the scaling of our data platform and support the team‚Äôs and company‚Äôs growth. Within the Data Operation services team, you will work with the following objectives: Design, implement, and maintain our Data Lake that collects, stores, and processes external and internal data, focusing on scalability and reliability Designing, developing, and maintaining pipeline to integrate data Controlling and managing their entire lifecycle, from collection to operational use considering Group Security and GDPR policies Ensuring the scalability, security, and availability of platform data Carrying out a technological watch to be at the forefront of cloud & Data solutions Distribute data to final users ensuring expected data quality Modelling and analyzing data Industrialising and automating data cleansing aligned with final users‚Äô specifications Managing, maintaining, and documenting the several data bases Create and automatise dashboards for final users Design and build machine-learning algorithms and tooling to explore and visualize data. Proposing technical solutions answering business needs and simplifying process through automation Designing, developing, testing, and industrializing ‚ÄúBig Data‚Äù processing in different business and application contexts in collaboration with data architects and devOps Developing automation, integration, and continuous deployment tools Ensuring the proper application of the Group's security and confidentiality rules within data processing Work hand in hand with Data Transformation team to create value for AXA accompanying Corporate Center‚Äôs departments and entities in their project, or new needs: Contributing to implement, new use cases of Business Intelligence, or Data Visualization Contributing to business specifications, build and tests phases, as well as data migration. Supporting clients in training sessions to end users. Participate in maintaining consistency and good practices with other data engineers Contribute to the Group's technical expertise communities Embody and relay product and data-driven methodologies </li></ul></li></ul> 5. TECHNICAL AND PROFESSIONAL SKILLS: Fluency in English is mandatory Programming Languages: Spark, Scala, Python, R, SQL Cloud Platforms: Microsoft Azure, or AWS, or GCP Tools: Azure Data Factory (ADF), Databricks, Azure DevOps, Git, JIRA, etc. Microsoft AZURE Data engineer certification (DP 203) is a plus 6. SOFT SKILLS AND COMPETENCIES: Team player who can break the silos with tact and diplomacy Leadership, influence, and conflict resolution Able to adapt to changing requirements, to deal with competing priorities and pressure Proactive, able to change things and to lead projects while being customer centric Comfortable working in a complex and multidisciplinary international environment 7. BACKGROUND & EXPERIENCE: Graduate degree in information systems, informatics, statistics, computer science or another quantitative field 3-5 years‚Äô experience working as a developer/Engineer with ideally operational experience in Data platforms among which Master Data Management, BI & Analytics (data warehousing, big data, data science), integration services, Data storage solutions Experience within insurance, bank, or investment management sectors is a plus Project Management experience is a plus </li></ul>","AXA, a world leader in financial protection and management, is seeking a Data Engineer to join their Information Management team. The successful candidate will be responsible for organizing, optimizing, and operating the collection of transversal data, designing and implementing data pipelines, ensuring data quality, and managing data lifecycles, as well as contributing to the development and implementation of new use cases for business intelligence and data visualization. Proficiency in programming languages such as Spark, Scala, Python, R, and SQL, as well as cloud platforms such as Microsoft Azure, AWS, or GCP, is required. The ideal candidate should also possess strong soft skills such as the ability to work in a complex and multidisciplinary international environment, adaptability, and customer-centricity. A graduate degree in a quantitative field and 3-5 years of experience in Data platforms, BI & Analytics, and integration services are preferred. A Microsoft AZURE Data Engineer certification (DP 203) is also a plus.",Non sp√©cifi√©,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
160,59920,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad_barcelone,Data Engineering Manager - Customer squad,Back Market,"{color,dynamodb,Scala,Lambda,AWS,via,Spark,GCP,Datadog,Python}",T√©l√©travail partiel possible,"Barcelone, 08007","Environnement / D√©veloppement durable, √âconomie collaborative, E-commerce",CDI,2023-03-28,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world‚Äôs leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of 963,226‚ÄØtons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: ‚Äúbe a coach not a dictator‚Äù is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc‚Ä¶ - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We‚Äôre here to SABOTAGE: It‚Äôs our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team.","BackMarket seeks an Engineering Manager with expertise in building reliable, high-performing, and secure data infrastructures and tools to manage its Customer data team. The candidate must align the tech vision with the objectives of the company, build and execute a growth plan, identify and improve the processes, practices, and products of the company. The ideal candidate must have great communication skills in English, be knowledgeable in Lambda, dynamaodb, Big Query, and possess leadership qualities. Additionally, the role comes with great benefits such as flexible hours, equity, health insurance, parental benefits, and other personal and career development schemes.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
218,65922,https://www.welcometothejungle.com/fr/companies/ingeniance/jobs/big-data-engineer-f-h_la-defense_INGNI_VGLdzo9,BIG DATA ENGINEER-,Ing√©niance,"{Jenkins,Git,HDFS,Linux,Hive,Spark,Docker,Java,Hadoop,Python}",T√©l√©travail partiel possible,La D√©fense,IT / Digital,CDI,2023-04-05,"Ing√©niance, est une soci√©t√© de conseil sp√©cialis√©e dans des projets li√©s aux nouvelles technologies et leader dans le secteur de la finance. Elle apporte sa valeur ajout√©e en associant innovation technologique, transformation digitale, expertise m√©tier (Banque, Finance et Assurance) & m√©thodes agiles. Technology-oriented, elle offre une r√©elle expertise √† ses clients, notamment autour du Craft Development, du Big Data, du Cloud/Devops et de l‚ÄôAgilit√©. Son projet d‚Äôentreprise s‚Äôappuie aussi sur des valeurs humaines, soci√©tales et environnementales (Label EcoVadis Gold). La proximit√©, la performance, la convivialit√© et le progr√®s sont des atouts sur lesquels elle b√¢tit son√©volution collective au quotidien. Missions : Rattach√© √† nos experts, au sein de notre lab ¬´ Big Data ¬ª , vous : aurez en chargela r√©alisation d'un prototype Big Data(technologies Hadoop HDFS, Hive, Spark, etc) participerez aux activit√©s de veille technologique sur le domaine du Big Data (recherches, exp√©rimentations, etc) participerez √† la r√©daction d'articles et √† l'animation de nos r√©seaux sociaux sur le domaine du Big Data √©voluerez dans des √©quipes fonctionnant en m√©thode Agile utiliserez les outilsDevOpsd√©ploy√©s sur nos cha√Ænes d'int√©gration continue (Jenkins, Docker, Git, etc) Ce poste sera l'occasion d'int√©grer notre programme de formation interne avec pour objectif d'acqu√©rir les comp√©tences fonctionnelles de base sur nos secteurs d'activit√© (finance de march√©, banque et assurances) mais aussi de solides connaissances techniques. Profil recherch√© : Vous √™tes dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent. Une sp√©cialisation dans le g√©nie logiciel sera vivement appr√©ci√©e. R√©actif, avec le sens du service, vous justifiez de bonnes capacit√©s d'√©coute, d'un bon relationnel et une bonne gestion du stress. Curieux, autonome, et proactif, vous avez les qualit√©s n√©cessaires √† ce projet. Vous √™tes int√©ress√© par le conseil , les syst√®mes d'informations et le secteur de la Banque/ Finance/ Assurance Comp√©tences requises : Des comp√©tences en d√©veloppement : Java ou Python. Des comp√©tences des OS Linux et Windows ; Des comp√©tences sur le framework Hadoop ; Une connaissance th√©orique et id√©alement pratique de la gestion d'un projet informatique; A minima une connaissance th√©orique des m√©thodes Agile (Scrum par exemple).","Ing√©niance is seeking an engineer for the Big Data lab to work on building a prototype, conduct technology watch activities, and contribute to social media posts. The ideal candidate holds an engineering degree with software engineering specialization, has good listening and stress management skills, is curious, independent, proactive, has knowledge of Java/Python, Linux/Windows, Hadoop, and Scrum. The role offers an opportunity to develop consulting and technical expertise via the company‚Äôs internal training program.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
163,57137,https://www.welcometothejungle.com/fr/companies/oris/jobs/data-engineer-permanent-contract_saint-quentin-fallavier,Data Engineer - Permanent Contract,ORIS,"{GitLab,modular,PowerBI,AWS,S3,Lambda,scale,via,Docker,Sagemaker,SQL,Python,Tableau}",T√©l√©travail partiel possible,"Rue du Montm√ªrier, Saint-Quentin-Fallavier, 38070","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, B√¢timent / Travaux publics",CDI,2023-03-26,"Join us! Innovation, adventure, agile environment, start-up context‚Ä¶ A dynamic team spirit and a company on a human scale aiming for excellence, that‚Äôs what defines us. ORIS is the first digital platform for sustainable infrastructure materials. Supported by high-level artificial intelligence, ORIS evaluates road designs from a global perspective to improve the sustainability of road construction. This solution can reduce the cost of road construction projects by a third and carbon dioxide emissions by half, while tripling the durability and service life of roads. Through intelligent design, ORIS helps managers, road authorities and investors to increase sustainability and reduce inefficiencies in road construction. ORIS also helps material suppliers to present and manage their product catalogue and identify road project opportunities. website: www.oris-connect.com Main tasks: Develop and maintain data integration pipelines from internal and external data sources to a datalake Develop data flows from the datalake, allowing their explotation (Datamart, reinjection in ORIS, manual verification reporting, ‚Ä¶) Ensure automatic verification and continuous improvement of data quality Ensure data security, accessibility and integrity within the framework of ISO 27001 certification You may also be required to work on related data analysis or machine learning topics : Implementing machine learning models from geo-spatial data with AWS Sagemaker or text recognition Develop AI solutions to assess climate change resilience of infrastructure Create interactive dashboards for internal and external users with AWS Quicksight Knowledge of the Python language for the creation of ETL and machine learning solutions Knowledge of the AWS cloud environment and services such as S3, Lambda functions and Step functions, Sagemaker, ‚Ä¶ Good knowledge of GitLab versioning Knowledge of SQL databases Ability to extract data via APIs Knowledge of Docker containers Knowledge of a BI tool ideally AWS Quicksight, or such as Tableau, Qliksense, PowerBI A good command of English is essential Mastery of algorithms and the development of structured, modular and reusable code Ability to develop solutions iteratively in an agile environment (Kanban, Scrum) Good knowledge of data modelling and business intelligence concepts Ability to document well the codes or methodologies used. Desire to work in a start-up structure, focused on innovation and sustainable development Enjoy teamwork and knowledge sharing Have a great technical curiosity and a capacity to learn and adapt quickly Good communication skills and an entrepreneurial spirit Requirements : Master degree with an IS background and ideally a Data specialisation Have previous experience in data management and development of data integration solutions in Python, ideally in the AWS environment 2 interviews with HR Manager and CDO, and then with the COO.","ORIS is seeking a data integration specialist with experience developing and maintaining data integration pipelines and data flows from internal and external sources to a datalake. The ideal candidate should have a Master's degree in IS with a data specialisation, experience in data management and development of data integration solutions in Python, and knowledge of AWS environment and services. Additionally, experience in implementing machine learning models, using AWS Quicksight, GitLab versioning, and SQL databases is also preferred. A good command of English, good communication skills, and a desire to work in a start-up structure focused on innovation and sustainable development are essential.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,2,1,0.04154662416233763
217,65944,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-engineer-f-h_colombes_EDF_2gLPzM5,Data Engineer,EDF,"{Oracle,Git,Airflow,Yarn,HDFS,S3,Hadoop,Hive,Spark,R,Docker,SQL,Python}",T√©l√©travail partiel possible,"Rue d'Estiennes D'Orves, Colombes, 92050","Environnement / D√©veloppement durable, Energie",CDI,2023-04-05,"Chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez EDF m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez EDF m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf La DSIN est en charge de d√©velopper le SI et les outils num√©riques de la Direction Commerce pour faire face aux d√©fis que doit affronter EDF dans le cadre de la concurrence accrue du march√© de l'√©nergie et des services. Elle contribue √† la performance des m√©tiers, √† leur √©volution et √† la transformation de la Direction √† travers ses activit√©s SI et Data Science. Au sein de la DSIN, le Centre de Solutions et de Comp√©tences DataScience & IA (CSC DS & IA), a pour mission de r√©aliser les travaux d'analyse et de valorisation des donn√©es de Commerce. Les collaborateurs du CSC DS & IA apportent ainsi leur expertise fonctionnelle et technique aux m√©tiers du March√© d'Affaires et du March√© des Clients Particuliers pour r√©pondre √† des enjeux vari√©s comme les d√©parts √† la concurrence, la conqu√™te de nouveaux clients, la satisfaction client, la d√©tection des fraudes ou encore la mise en place de services innovants. Pour cela, ils s'appuient sur un environnement technique riche et des bases de donn√©es cons√©quentes (~26 millions de clients, B2C+B2B). Afin de r√©pondre √† ces besoins, le CSC DS & IA recrute un/une Data Engineer. Au sein d'une √©quipe de Data Engineer, et en appui d'une √©quipe de plus de 20 Data Scientists, votre mission consistera √† : - Mettre en place des pipelines de traitements de donn√©es - avec des volumes importants de donn√©es (plusieurs dizaines de millions de lignes) - Mettre en place des traitements de donn√©es distribu√©es (Spark ‚Ä¶) - Extraire massivement des donn√©es (Hadoop - Hive, Oracle - SQL, ‚Ä¶) - vous-m√™me ou en appui d'un Data Scientist - Aider au debuggage des Data Scientists dans l'extraction de donn√©es (compr√©hension des probl√©matiques Yarn, JVM, tablespace temp‚Ä¶) - Accompagner les Data Scientists dans le maintien et l'√©volution des outils de requ√™tage d√©velopp√©s en interne (dnquery pour requeter Oracle et Hive), extension √† une nouvelle technologie de stockage des donn√©es (PostGre, SQL Server‚Ä¶) - Accompagner les d√©ploiements de mod√®les de Machine Learning - Installer ou construire des outils permettant la fiabilisation et le suivi des cha√Ænes r√©currentes de type traitement de la donn√©e ; Accompagner les Data Scientists dans l'utilisation de ces outils - Contribuer √† la construction des strat√©gies de monitoring et d'industrialisation des livrables des Data Scientists - Contribuer √† l'√©volution de l'environnement technique des Data Scientists Votre Profil ? - Vous √™tes titulaire d'un Bac +5 (Master, dipl√¥me d'ing√©nieur) dans le domaine informatique, des math√©matiques / statistiques, de la Data Science ou du Big Data - Vous b√©n√©ficiez d'une exp√©rience d'au moins 3 ans en tant que Data Engineer - Vous avez d√©j√† travaill√© dans un contexte de Datascience et automatis√© des traitements de type Datascience - Vous ma√Ætrisez les langages Python, SQL, R (en bonus) et les outils Docker, Airflow - Connaissance de l'environnement Hadoop : HDFS, Hive, Spark - Vous avez d√©j√† manipul√© des donn√©es stock√©es sous S3 - Vous √™tes √† l'aise avec les outils collaboratifs de d√©veloppement (Git, Confluence, ...) - Une connaissance de GitlabCI est un plus - Vous b√©n√©ficiez d'une ou plusieurs exp√©riences de travail en mode Agile - Vous √™tes curieux et les projets innovants vous passionnent - Vous √™tes force de proposition et proactif - Vous aimez transmettre et travailler en √©quipe M√©thodologie de travail : Vous collaborerez √©troitement avec les R√©f√©rents Techniques, Run et DevSecOps du CSC DS & IA, ainsi qu'avec l'√©quipe en charge des lacs de donn√©es au sein de la DSIN. A ce titre, vous participerez fortement au collectif afin de diffuser les bonnes pratiques (Python, Spark‚Ä¶). Le poste est situ√© √† Colombes, proche de La D√©fense Ouest, avec une possibilit√© de t√©l√©travail partiel. R√©mun√©ration : Fourchette estimative : entre 50k et 57k‚Ç¨, la r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","EDF is hiring a Data Engineer to work in its Center of Solutions and Competences DataScience & AI. The position requires knowledge of Python, SQL, R, Docker, Airflow, and Hadoop, among other tools, as well as experience in automating Data Science-type treatments. The salary range is between ‚Ç¨50k and ‚Ç¨57k. The data engineer will be based in Colombes, France, and teleworking is possible. The role will involve working closely with technical, run, and DevSecOps contacts within EDF. The position is open to all, including people with disabilities.",Bac +5 / Master,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
220,66096,https://www.welcometothejungle.com/fr/companies/aviv-group/jobs/data-quality-engineer-m-w-d_hamburg,Data Quality Engineer,AVIV Group,"{scala,java,python,javascript,AZURE,AWS,GCP,sql}",T√©l√©travail total possible,Hamburg,"Immobilier commercial, Immobilier particulier",CDI,2023-04-06,"Aviv Group is one of the world‚Äôs largest, privately owned real estate tech companies and a subsidiary of Axel Springer. Its mission is to unlock everyone‚Äôs perfect place! Some of Europe‚Äôs best known digital real estate marketplaces and brands form part of the Group, they are: üá´üá∑Meilleurs Agents üá´üá∑Group SeLoger üáßüá™Immoweb üá¨üáßReal estate world üá™üá∏Housell üáÆüá±Yad2 Aviv Group also invest in innovative business models which shape the future of how people buy, sell, rent or lend properties and hold minority participations in companies such as: üá¨üáß PurpleBricks üá©üá™ Homeday üá∫üá∏ Zumper üá∫üá∏ Parcel The ambition is to be the leading employer in proptech across Europe. Join us on our exciting journey and become an AVIVer ü§© WHAT WE DO IN Marketplace Design‚Äì Product and Tech at AVIV The Marketplace Design Domain at AVIV group is part of the Product & Tech organization and its objective is to deliver the internal services that powers Actor teams to brings safety, trustworthiness and remove opacity from the experience. Building on local expertise from Immowelt (Germany & Austria), Immoweb (Belgium), Groupe SeLoger and Meilleurs Agents (France), we deliver fraud / cheat / information reliability assessment services to raise marketplace safety and reliability in the interactions between Seekers and Owner / Agent. WE ARE LOOKING FOR AN INDIVIDUAL WHO CAN: Will be part of an agile, multidisciplinary, international team and work closely with them to Identify data quality issues, and implement solutions to verify, validate, and monitor data quality. Contributes to analysis of data issues and help identifying business processes and technical improvements that contribute to higher quality data. Work with the product team to establish data quality standards within the sprints, develop a test plan and deliver high quality builds on time. Work with product owners and data engineers to improve the overall experience by suggesting improvements and changes. Design and maintain QA reports for the internal data systems. Align and collaborate with the rest of the data quality team to improve the overall quality, assess risks, promote consistency, identify common needs. Develop test strategies for automation both for backend and data. Write and execute both functional and non-functional data tests. You convince with your analytical way of thinking. WHAT WE OFFER YOU: We are one of the leading PropTech platforms in Europe. If you‚Äôve ever rented or purchased a property then you may have used one of our classified portals. This is a great time to join us to help elevate our AVIV brand. You'll experience a good work-life balance with 30 days holiday per year, flexible working hours, mobile working options and openness to sabbaticals You have the autonomy to work in a style which suits you to be the most productive. You are part of a great team with an exceptionally positive spirit that turns employee events into very special experiences. INDIVIDUAL WHO HAS: Solid experience (at least 3 Years) as Data Quality Engineer. Practical experience working with agile methodologies. Degree in Computer Science or other relevant qualifications. ISTQB Certification is a plus. Practical experience creating and maintaining ETL and API tests. Experience in automating data tests with frameworks like Deequ or other. Experience in automating APIs tests with javascript or java libraries like fetch, superAgent, restAssured... You are comfortable reading and writing code in at least one programming language, ideally java, scala, python. Basic understanding of sql. Experience with CI/CD Tools. Basics in cloud experience like AWS, GCP, AZURE is plus. A proactive team player that analyses the risk and impact of issues and is working with the team to prioritise and resolve them. Any experience with performance, GDPR, accessibility, interoperability and security testing is a plus. Excellent communication skills, with fluency in English. Willingness to travel from time to time is available.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,3,0,0.04154662416233763
216,65928,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-banque-bordeaux_bordeaux_SS_VXqZ4xe,Data Engineer - Big Data - Banque - Bordeaux,Sopra Steria,"{Hdfs,Jenkins,spark,Scala,Shell,hive,GitLab}",T√©l√©travail partiel possible,"18 avenue de Pythagore, Bordeaux, 33700","IT / Digital, Organisation / Management",CDI,2023-04-05,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Banque ¬ª s'est d√©velopp√©e autour des m√©tiers de la banque de d√©tail, de la banque priv√©e et des services financiers sp√©cialis√©s. Nous participons √† la r√©volution digitale gr√¢ce √† notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos comp√©tences dans les domaines fonctionnels des Cr√©dits, des Risques/Conformit√© et des Moyens de Paiement. Votre futur environnement de travail : Int√©gr√©(e) au sein d'une √©quipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participez √† un projet Big Data, en mode Agile, et intervenez en tant que r√©f√©rent(e) technique au sein de votre √©quipe. Votre r√¥le et vos missions : A cette occasion vous √™tes amen√©(e) √† : - Apporter votre expertise et votre exp√©rience √† vos coll√®gues lors des phases de conception et d√©veloppement - Accompagner vos coll√®gues dans leur mont√©e en comp√©tence technique au sein du projet - D√©finir et impl√©menter des solutions au sein d'un p√©rim√®tre applicatif existant - Proposer des id√©es d'am√©lioration continue √† votre client et √† votre √©quipe (revue de proc√©dures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualim√©trie) - Concevoir et d√©velopper des sujets complexes. Environnement du projet : - M√©thodologie projet : Mode Agile (Scrum). Environnement technique : - Hdfs, hive, spark, oozie - Scala, HQL, Shell - GitLab, Nexus, Maven, Jenkins, Sonar Environnement fonctionnel : - Alimentation d'un DataLake jusqu'au build d'un moteur de calcul ; - Intervention sur la mise en place de r√®gle relatives aux normes B√¢loise. Votre profil : De formation Bac+5, vous avez au moins 5 ans d'exp√©rience dans la data dont 3 ans en Big Data, notamment sur les technologies mentionn√©es ci-dessus. Vous aimez travailler en √©quipe, relever les d√©fis techniques, conseiller et apporter votre valeur ajout√©e √† une √©quipe. Vous savez √™tre challengeant et leader envers le client et l'√©quipe de Dev en ce qui concerne l'am√©lioration continue (process de livraison, automatisation du testing/validation, maintenance des bonnes pratiques et performance des runs). Vous aimez vous tenir inform√©(e) des nouveaut√©s technologiques et √™tes √† la recherche d'√©volution de carri√®re r√©elle bas√©es sur l'exp√©rience projet et l'acquisition de nouvelles comp√©tences. Employeur inclusif et engag√©, Sopra Steria oeuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils. Tous nos postes sont ouverts aux personnes en situation de handicap. https://www.soprasteria.fr/carrieres/decouvrez-sopra-steria/nos-engagements-rse","Sopra Steria, a European leader in digital transformation, is looking for a Big Data expert to join their team and work on a project with a major banking client. The ideal candidate should have at least five years of experience in data, with three years in Big Data, as well as a strong technical background in Hdfs, hive, spark, oozie, Scala, HQL, and Shell. The successful candidate will work in an Agile environment and be responsible for providing technical expertise and support to their team, as well as implementing solutions and proposing improvements. Diversity and inclusion are encouraged, and all candidates, including those with disabilities, are welcome to apply.",Bac +5 / Master,> 2000 salari√©s,> 5 ans,2,1,0.04154662416233763
213,65898,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-nantes-f-h_nantes_SS_AAy3xXD,Data Engineer - Big Data - Nantes -,Sopra Steria,"{Hive,datahub,Azure,Cloudera,DataBricks,Talend,SAP,Informatica,Kafka,Qlik,Elastic,SAS,Java,Hadoop,DataIku,Scala,R,Spark,Python}",T√©l√©travail partiel possible,"impasse claude nougaro, Nantes, 44000","IT / Digital, Organisation / Management",CDI,2023-04-05,"Sopra Steria, l'un des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d'√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activit√© et des technologies innovantes √† une approche r√©solument collaborative. Sopra Steria place l'humain au centre de son action et s'engage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif. Fort de 47 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d'affaires de 4,7 milliards d'euros en 2021. The world is how we shape it. Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division ¬´ Banque ¬ª s'est d√©velopp√©e autour des m√©tiers de la banque de d√©tail, de la banque priv√©e et des services financiers sp√©cialis√©s. Nous participons √† la r√©volution digitale gr√¢ce √† notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos comp√©tences dans les domaines fonctionnels des Cr√©dits, des Risques/Conformit√© et des Moyens de Paiement. Votre futur environnement de travail : Si vous √™tes passionn√©(e) par la valorisation de la donn√©e, rejoignez notre Data Factory localis√©e √† Nantes et les quelques 100 Data Ing√©nieurs qui la composent. Vous y rencontrerez des experts de la mise en oeuvre de Plateforme de Donn√©es, des Data Architectes ou autres experts solution autour des probl√©matiques de valorisation de la donn√©e. Vous √™tes accompagn√©(e) au d√©veloppement de vos connaissances aux travers de diff√©rents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donn√©e, la mod√©lisation et mise √† disposition. Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communaut√© de Data Ing√©nieurs fiers de partager leur savoir et ouverts aux nouvelles exp√©riences et exp√©rimentations de la donn√©e. Votre r√¥le et vos missions : Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre exp√©rience et votre app√©tence pour l'un de nos chapitres Data ci-dessous, vous participez √† : - La compr√©hension des besoins m√©tiers et la traduction solution de data ing√©nierie et ou data analysis. - La mise en oeuvre de solution d'ingestion des donn√©es quelles soit en batch et/ou en streaming dans un contexte Cloud. - La structuration du DataLake, la mise en place des processus de gouvernance et de s√©curisation des donn√©es. - Le traitement de la donn√©e jusqu'√† l'exposition au m√©tier. - La mise en place de la chaine CI/CD et de sa supervision. - La veille technologie avec nos partenaires √©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'id√©ation pour nos clients. Environnement technique : - Spark, Hadoop, Hive, Kafka, Elastic - Cloudera, Azure HD Insight - Informatica, Talend, Stambia, DataStage, - SAS, DataIku, DataBricks - Qlik, SAP BI (BO), Power BI - Java, Scala, Python, R Votre profil : Dipl√¥m√©(e) d'une √©cole d'Ing√©nieurs ou √©quivalent universitaire, vous avez d√©j√† particip√© √† un projet Data (Big Data, BI) et vous avez une exp√©rience de minimum 2 ans. Vous accordez une importance particuli√®re √† : - Au d√©veloppement de vos comp√©tences sur plusieurs technologies. - L'opportunit√© d'√©volution r√©elle de carri√®re au travers de l'exp√©rience projet. - L'apport de valeur pour vos clients. - La transmission de votre savoir aupr√®s de vos collaborateurs plus juniors et l'accompagnement de ceux-ci dans le d√©veloppement de leur carri√®re. - A la bienveillance et √† la diversit√©. Les avantages √† nous rejoindre : - Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions. - Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation. - Un accompagnement individualis√© avec un mentor. - Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble. - Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª. - L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore). Chez Sopra Steria, nous sommes engag√©s pour lutter contre toute forme de discrimination. Nous favorisons un environnement de travail inclusif et respectueux de toutes les diff√©rences. Tous nos postes sont ouverts aux personnes en situation de handicap.","Sopra Steria is seeking a Data Engineer to join their Data Factory team in Nantes, France. Candidates should have a degree in engineering or a related field, as well as a minimum of two years of experience working in Big Data or BI projects. The role involves participating in the implementation of data platform solutions for clients, such as ingestion, structuring, processing, and visualization of data, and collaborating with Data Architects and other experts to provide solutions for data-related challenges. Candidates must be passionate about data and interested in developing their knowledge and skills in areas such as automation of processes, big data, AI, and cloud computing. Sopra Steria is committed to inclusivity and encourages applications from individuals with disabilities. The company offers its employees various benefits and opportunities for career growth, such as telecommuting, mentoring programs, training, and social engagement initiatives.",Bac +5 / Master,> 2000 salari√©s,> 1 an,2,1,0.04154662416233763
221,66225,https://www.welcometothejungle.com/fr/companies/adevinta-fr/jobs/data-engineer-team-data-platform-f-m_paris,Data Engineer team Data Platform,Adevinta,"{DynamoDB,Glue,Elasticsearch,Docker,Hudi,durable,Athena,Kafka,Kubernetes,AWS,Java,Github,Jupyter,SQL,Airflow,Redshift,S3,R,Spark,Unix,Python,MLFlow}",T√©l√©travail partiel possible,"22 Rue des Je√ªneurs, Paris, 75002","Intelligence artificielle / Machine Learning, Big Data, E-commerce",CDI,2023-04-06,"Adevinta est un leader mondial des petites annonces en ligne, avec plus de 40 marketplaces dans 13 pays, regroupant 8 100 collaborateurs. C‚Äôest au travers de ces marketplaces, qui incluent leboncoin en France, mobile.de en Allemagne et 2dehands au Pays-Bas, que se font des connexions et des rencontres. Ainsi, Adevinta met en relation des acheteurs avec des vendeurs pour l‚Äôachat d‚Äôune nouvelle maison ou d‚Äôune voiture, des personnes √† la recherche d‚Äôun emploi avec les annonces correspondantes et plus g√©n√©ralement des personnes qui vendent avec des personnes qui ach√®tent pour donner une seconde vie √† des produits. √âtablir ces connexions contribue √† cr√©er un changement positif et √† construire un avenir plus durable pour des millions de personnes. Vous √™tes rattach√©.e √† l‚Äô√©quipe Data Engineering , compos√©e de data engineers et de SRE. Cette √©quipe vous accompagne sur la stack technique data, vous permet d‚Äô√©changer sur des sujets transverses et de participer aux rituels data engineering (guilde, r√©tro‚Ä¶). Cette √©quipe appartient √† la tribe ‚ÄúData Tools & Services‚Äú, qui regroupe les services data centraux La stack : D√©veloppement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm Dans un environnement √† la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi Ce que vous ferez : D√©velopper des applicatifs complexes assurant une circulation optimale des donn√©es, et assurer leur fiabilit√© : API d‚Äôexposition de donn√©es, applications de streaming, industrialisation de mod√®les de machine learning Optimiser notre architecture et notre environnement AWS : stockage, s√©curit√©, automatisation, scalabilit√© Assurer la s√©curit√© des donn√©es de nos utilisateurs sur la data platform, dans le respect de la r√©glementation en vigueur (GDPR, e-privacy) Participer activement √† la veille technologique et √† l'effort de R&D Garantir le bon fonctionnement, la disponibilit√©, l‚Äô√©volution et la performance des outils Assurer l‚Äôinterface avec les √©quipes techniques du produit Informations suppl√©mentaires Poste bas√© √† Paris 10 Les √©tapes : Premier √©change avec Simon (RH) Entretien manag√©rial avec Thomas (Engineering Manager) Entretien technique avec deux membres de l'√©quipe (Data Eng) Entretien Fit/RH avec Julien (directeur data) et Simon (RH) Vous avez au moins 5 ans en tant que Data Engineer Vous connaissez les environnements Unix, et poss√©dez un niveau avanc√© en Java / Python . Vous √™tes familier avec l'environnement cloud AWS , et avez de solides notions d‚Äôarchitecture distribu√©e et de gestion de data platform √† forte volum√©trie. Vous √™tes √† l‚Äôaise en anglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral.",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
219,66090,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-middleware-h-f-services_paris,Data Engineer Middleware  - Services,CGI,"{Azure,Numpy,Pandas,Python}",T√©l√©travail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-04-06,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Fonctions et responsabilit√©s - Savoir identifier et pr√©senter les avantages/inconv√©nients de solutions techniques afin de r√©pondre aux besoins m√©tiers - Participer aux phases de r√©alisation, d'√©volution et de maintenance √† l'application ainsi qu'aux phases de test des fonctionnalit√©s d√©velopp√©es - Echanger avec les m√©tiers et comprendre l'expression de besoin fonctionnel - Concevoir et d√©velopper des nouvelles fonctionnalit√©s from scratch ou des √©volutions - R√©daction de la documentation technique et fonctionnel - Mise en place de tests unitaires - Diagnostiquer les incidents et d√©velopper les correctifs tout en s'inscrivant dans un processus d'am√©lioration continue - Effectuer de la veille technologique et proposer des √©volutions Qualit√©s requises pour r√©ussir dans ce r√¥le De formation bac +4/5 dans le domaine de l'IT ou de l'ing√©nierie, tu poss√®des une exp√©rience significative de minimum 2 ans en analyse et d√©veloppement Python. - Comp√©tences techniques : Python, Azure Devops, Jira, ESB, middleware, Pandas, Numpy, Petl librairies : aiflow - Comp√©tences m√©tier : Capacit√© orale et r√©dactionnelle, M√©thodologie Agile Anglais requis Mobilit√© en Ile-de-France A comp√©tences √©gales, ce poste est ouvert aux personnes en situation de handicap, √† l'√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Allier savoir et faire Alors que la technologie s‚Äôinscrit au c≈ìur de la transformation num√©rique de nos clients, nous savons que les individus sont au c≈ìur du succ√®s en affaires. Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos coll√®gues et clients pour proposer des id√©es exploitables qui produisent des r√©sultats concrets et durables. Nous appelons nos employ√©s ""membres"" parce qu‚Äôils sont actionnaires et propri√©taires de CGI. Ils ont du plaisir √† travailler et √† grandir ensemble pour b√¢tir une entreprise dont nous sommes fiers. C‚Äôest notre r√™ve depuis 1976. Il nous a men√©s l√† o√π nous sommes aujourd‚Äôhui ‚Äì l‚Äôune des plus importantes entreprises ind√©pendantes de conseil en technologie de l‚Äôinformation (TI) et en management au monde. Chez CGI, nous reconnaissons la richesse que la diversit√© nous apporte. Nous aspirons √† cr√©er une culture √† laquelle nous appartenons tous et collaborons avec nos clients pour cr√©er des communaut√©s plus inclusives. En tant qu‚Äôemployeur qui pr√¥ne l‚Äô√©galit√© des chances pour tous, nous voulons donner √† tous nos membres les moyens de r√©ussir et de s‚Äô√©panouir. Si vous avez besoin d‚Äôun accompagnement sp√©cifique durant le processus de recrutement et d‚Äôint√©gration, veuillez nous en informer. Nous serons heureux de vous aider. Pr√™t √† faire partie d‚Äôune entreprise qui est gage d‚Äôexcellence? Rejoignez CGI ‚Äì o√π vos id√©es et vos actions changent la donne.",,Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,2,1,0.04154662416233763
223,56833,https://www.welcometothejungle.com/fr/companies/trend-it/jobs/data-engineer-azure-data-factory-msbi-stack_paris,DATA ENGINEER  (Azure Data Factory/MSBI Stack),TREND-IT,"{Microsoft,Azure,SQL}",T√©l√©travail partiel possible,"277, Rue Saint-Honor√©, Paris, 75008",Logiciels,CDI,2023-03-26,"TREND-IT est un cabinet de conseil IT, d‚Äôexpertise technique et de transformation digitale. Nous sommes une ESN pure player Microsoft. Nous accompagnons nos clients tout au long de leurs processus de transformation digitale : Analyse, Conception, R√©alisation, D√©ploiement et Audit, sp√©cialis√©s sur les prestations intellectuelles dans les technologies Microsoft. TREND-IT √©volue dans une activit√© B to B. Elle propose les services suivants : le conseil (en syst√®me d‚Äôinformation, en conduite de changement‚Ä¶), l‚Äôint√©gration de syst√®me (architecture de syst√®mes d‚Äôinformation, int√©gration de progiciels, ERP‚Ä¶). TA TEAM TREND-IT met l accent sur l esprit d‚Äô√©quipe et collaboratif. En plus de faire partie d‚Äôune √©quipe, tu feras partie de la famille TREND-IT ! Pour renforcer ses √©quipes TREND-IT recrute dans l‚Äôimm√©diat un Data Engineer pour travailler sur un projet de grande envergure avec des intervenants hautement qualifi√©s. Nous sommes √† la recherche d‚Äôun profil confirm√© sur la suite Microsoft BI pour un poste en CDI. Nous recherchons une personne justifiant d‚Äôau moins 5 ans d‚Äôexp√©riences, dans un environnement Microsoft. Les comp√©tences/app√©tences suivantes sont requises pour le poste: MSBI( SSIS, SSAS, SSRS) Power BI SQL Server : Suivi performance(Charge serveur/Optimisation/Log‚Ä¶) Azure Data Factory Autonome et rigoureux(se) Bon(ne) communicant(e) Maitrise de l‚Äôanglais","TREND-IT is hiring a Data Engineer with at least 5 years of experience in Microsoft environment, for a CDI position, to work on a large-scale project. The ideal candidate should have expertise in MSBI (SSIS, SSAS, SSRS), Power BI, SQL Server, Azure Data Factory, be autonomous, rigorous, a good communicator, and have a command of English. TREND-IT is an IT consulting firm specialized in Microsoft technologies, offering consulting and system integration services.",Bac +5 / Master,< 15 salari√©s,> 5 ans,2,1,0.04154662416233763
222,56782,https://www.welcometothejungle.com/fr/companies/octopus-energy/jobs/ingenieur-data_saint-denis,Data Engineer exp√©riment√©¬∑e,Octopus Energy France,"{durable,AWS,dbt,SparkSQL,Python}",T√©l√©travail partiel possible,"6, Boulevard Haussmann, Paris, 75009","Environnement / D√©veloppement durable, Energie",CDI,2023-03-26,"Octopus Energy France (anciennement Pl√ºm √©nergie), est un fournisseur d‚Äô√©lectricit√© verte. Sa mission est d‚Äôacc√©l√©rer la transition √©cologique aupr√®s des particuliers, des entreprises et des collectivit√©s. C‚Äôest une entreprise reconnue d‚Äôutilit√© sociale par le gouvernement (ESUS). Cr√©√©e en 2016 et apr√®s plusieurs tours de financement, la start-up a rejoint d√©but 2023 le groupe innovant et engag√© Octopus Energy, afin de lutter contre le r√©chauffement climatique √† grande √©chelle. Octopus Energy est un fournisseur et producteur d‚Äô√©nergie verte Britannique, d√©j√† plusieurs fois ‚Äúlicorne‚Äù, qui fournit plusieurs millions de client¬∑e¬∑s √† travers le monde. Leur technologie, Kraken, r√©volutionne le march√© de l‚Äô√©nergie et permet de garantir aux client¬∑e¬∑s de r√©aliser des √©conomies, tout en b√©n√©ficiant de la meilleure exp√©rience du march√©. La filiale fran√ßaise a d√©j√† rencontr√© de beaux succ√®s, en gagnant par exemple trois fois cons√©cutives l‚Äôappel d‚Äôoffre de la ville de Paris. Parcs, √©coles, mus√©es, √©clairage public‚Ä¶ Pr√®s de 8 000 b√¢timents et √©quipements publics parisiens sont aujourd‚Äôhui chez Octopus. Et la Canebi√®re √† Marseille, c‚Äôest √©galement Octopus qui l‚Äô√©claire ! Toujours en continuant d‚Äôenrichir le nouveau syst√®me √©nerg√©tique durable que le groupe a su construire, le prochain challenge d‚ÄôOctopus Groupe est d‚Äôatteindre 100 millions de client¬∑e¬∑s dans le monde d‚Äôici 10 ans. Nous recherchons un¬∑e ing√©nieur¬∑e data exp√©riment√©¬∑e pour rejoindre notre √©quipe data en France. Chez Octopus, nous avons d√©velopp√© une plateforme de donn√©es qui fournit des services √† toutes les parties de notre entreprise au Royaume-Uni et dans le monde entier. Cette plateforme permet √† des centaines d‚Äôutilisateurs/trices d‚Äôeffectuer des analyses de donn√©es en libre-service et d‚Äôautomatiser tous nos flux de donn√©es. Dans ce r√¥le, tu seras responsable de la construction et de la maintenance de nouvelles pipelines de donn√©es et d‚Äôapplications de donn√©es pour permettre √† l‚Äô√©quipe de production de d√©velopper, g√©rer et optimiser efficacement ses actifs renouvelables. Ce que tu feras Construire et maintenir des pipelines de data qui fournissent des informations cl√©s √† l‚Äôentreprise. Int√©grer de nouvelles sources de donn√©es dans la plateforme de donn√©es par le biais d‚ÄôAPI ou de transferts de donn√©es en masse. Travailler en √©troite collaboration avec les √©quipes data. Cr√©er et maintenir des cadres de test et de documentation pour nos sources de donn√©es. Travailler avec l‚Äôentreprise pour d√©finir la port√©e et la r√©alisation de nouveaux projets et des exigences en mati√®re d‚Äôing√©nierie des donn√©es. Maintenir et d√©velopper notre infrastructure de donn√©es et nos outils existants. Soutenir l‚Äôinternationalisation de notre infrastructure de donn√©es dans le cadre de notre croissance mondiale. Avant tout, nous voulons que nos ing√©nieur¬∑e¬∑s data soient d‚Äôexcellent¬∑es ing√©nieur¬∑e¬∑s en logiciels, passionn√©s par l‚Äô√©criture de code de haute qualit√©. Il serait utile d‚Äôavoir de l‚Äôexp√©rience/expertise dans les domaines suivants (par ordre de priorit√© approximatif) : Python / SparkSQL Exp√©rience dans la mod√©lisation des donn√©es pour l‚Äôanalyse - id√©alement, exp√©rience dans l‚Äôutilisation de dbt comme outil de mod√©lisation. Exp√©rience dans l‚Äôassurance de la qualit√© des donn√©es Exp√©rience dans le d√©ploiement de services de donn√©es dans un environnement cloud (id√©alement AWS). Les projets seront vari√©s et nous recherchons une personne capable de travailler de mani√®re autonome et proactive pour d√©finir les probl√©matiques, les r√©soudre et fournir des solutions pragmatiques. Pourquoi tu vas adorer ce poste Tu te demandes quel est le salaire pour ce poste ? Demande-le nous ! Lors de notre premier contact, c‚Äôest un point que nous abordons toujours, car nous souhaitons r√©ellement faire correspondre ton exp√©rience avec le bon salaire. La raison pour laquelle nous n‚Äôen parlons pas ici est que nous avons un certain degr√© de flexibilit√© et que nous ne voudrions jamais que le salaire soit une raison pour laquelle quelqu‚Äôun.e ne postule pas chez Octopus - ce qui est plus important pour nous est de trouver le bon octofit ! Octopus Energy a une culture unique : nous avons gagn√© le prix de la meilleure entreprise pour laquelle travailler en 2022, sur Glassdoor UK nous avons √©t√© √©lus parmi les 50 meilleurs endroits o√π travailler en 2022 et notre PDG, Greg, a enregistr√© un podcast sur notre culture et la fa√ßon dont nous donnons du pouvoir √† nos employ√©s - c‚Äôest la m√™me chose ici en France. Nous sommes une organisation o√π les gens apprennent, d√©cident et construisent plus rapidement. O√π ils travaillent de mani√®re autonome, avec des gens extraordinaires, sur des projets qui innovent. Int√©ressement au capital, flex-office, excellente mutuelle, forfait mobilit√© douce, remboursement du pass navigo au del√† du minimum l√©gal, et m√™me des jours de cong√©s sp√©ciaux pour mener des projets associatifs qui te tiennent √† coeur‚Ä¶ nous voulons que ton dur labeur soit r√©compens√© par des avantages auxquels vous tenez vraiment ! Nous recherchons une personne qui aime r√©soudre des probl√®mes difficiles. Quelqu‚Äôun qui peut challenger ceux qui l‚Äôentourent et √™tre challeng√©, tout en offrant une exp√©rience agr√©able √† nos clients internes et externes. Si tout cela te passionne, postule d√®s maintenant.","Octopus Energy France is seeking an experienced data engineer to join their team in building and maintaining new data pipelines and applications for effective renewable asset management. The candidate should have expertise in Python, SparkSQL, data quality assurance, and AWS cloud deployment. Octopus Energy is a socially responsible energy provider and producer, aiming to accelerate the ecological transition for individuals, businesses, and communities. The company offers flexible working hours and a unique culture where individuals learn and innovate autonomously.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,2,1,0.04154662416233763
397,35714,https://www.welcometothejungle.com/fr/companies/retailmenot/jobs/data-engineer-h-f_paris,Data Engineer,RetailMeNot,"{Qlikview,Looker,Airflow,Braze,S3,Snowflake,SQL,Python,Tableau}",T√©l√©travail partiel possible,N,"Application mobile, E-commerce, Marketing / Communication",CDI,2022-09-28,"RetailMeNot France fait partie de Ziff Media Group, un groupe au rayonnement mondial, leader dans les secteurs Shopping, M√©dia et Technologie. Ziff Media est connu en France sous les marques grand public Poulpeo, le service shopping qui accompagne les consommateurs tout au long de leur parcours d‚Äôachat avec des solutions de cashback, de codes promos, de bons plans et des guides d‚Äôachat, et Ma Reduc, la r√©f√©rence des consommateurs fran√ßais pour profiter des meilleures offres promotionnelles. Reprise de la g√©n√©ration de tous les flux de donn√©es Business Analytics Maintenance et optimisation des jobs SQL existants, Possibilit√© de cr√©er / corriger le d√©veloppement d‚Äôune API, Capacit√© √† optimiser / corriger un dashboard mis en place, Suivi des donn√©es envoy√©es quotidiennement √† notre outil Marketing ‚ÄúBraze‚Äù, Cr√©ation de nouveaux flux de donn√©es from scratch: capacit√© √† mod√©liser et cr√©er des donn√©es agr√©g√©es √† ing√©rer quotidiennement Cr√©er de la valeur business √† partir d‚Äôun ensemble de donn√©es Travailler en collaboration avec notre √©quipe Marketing afin de segmenter notre base utilisateurs et leur adresser des messages pertinents (scoring algorithmiques, syst√®me de fid√©lit√©, etc.), Appr√©hender et am√©liorer nos algorithmes de recommandations d‚Äôoffres et marchands automatis√©s, Travailler avec les ing√©nieurs front pour pousser du contenu segment√© en temps r√©el sur nos produits afin d‚Äôam√©liorer l‚Äôengagement, Suivre les performances des diff√©rents AB tests lanc√©s par nos √©quipes produits, Travailler de paire avec nos analystes de donn√©es et r√©aliser des dashboards √† destination des √©quipes m√©tiers. Manager et accompagner un alternant Transmission de vos comp√©tences √† un alternant lui permettant d‚Äôacqu√©rir une autonomie sur le long terme, Cr√©ation d‚Äôune roadmap data en ad√©quation avec la strat√©gie de l‚Äôentreprise, Suivi des comp√©tences et d√©l√©gation des t√¢ches. Management de Snowflake, notre ‚ÄúCloud Data Platform‚Äù Cr√©ation des utilisateurs et gestion des r√¥les pour la s√©curit√©, Comprendre les routines d‚Äôimports et d‚Äôingestion de donn√©es stock√©es de nos d√©p√¥ts Amazon S3 vers Snowflake, Manager et suivre mensuellement les d√©penses Snowflake pour respecter le budget annuel. Formation de type √©cole d‚Äôing√©nieurs, Une premi√®re exp√©rience r√©ussie en tant que Data Engineer, Expertise SQL requise (des tests seront effectu√©s), Ma√Ætrise avanc√©e d‚Äôun langage de programmation comme Python, Ma√Ætrise de la suite Office, Connaissance requise d‚Äôun outil de data visualisation type Tableau / Looker / Qlikview, La manipulation d‚Äôun outil d‚ÄôETL type SSIS / Airflow est un plus, La connaissance business du milieu e-commerce / digital est un plus, Tr√®s bonne communication n√©cessaire, La ma√Ætrise de l‚Äôanglais est obligatoire. Ce que nous offrons De l‚Äôautonomie, des responsabilit√©s, de la confiance Des avantages classiques (carte Swile tickets restaurants, remboursement de l‚Äôabonnement transport, mutuelle‚Ä¶) Et aussi, le remboursement de votre abonnement √† la salle, pour vous maintenir en forme et a√©rer l‚Äôesprit ! Des horaires flexibles & du t√©l√©travail Des √©v√®nements r√©guliers (m√™me si c‚Äô√©tait plus facile avant) Des coll√®gues un peu fous, mais hyper disponibles et toujours bienveillants Un visio avec notre RH pour pr√©senter votre parcours & vos attentes (20-30 mins) Un entretien avec notre Business Analytics Manager incluant un cas pratique et test technique (1h30) Un dernier √©change avec notre DG (1h)","RetailMeNot France seeks a Data Engineer to manage, maintain, and optimize existing SQL jobs, create new data flows, and improve algorithms for customer segmentation, recommendations, and promotions. The candidate should have a degree in engineering, expertise in SQL, advanced programming skills in Python, and proficiency in data visualization tools such as Tableau. The ability to communicate effectively, prioritize tasks, and manage an apprentice is also required. Fluency in English is mandatory. The company offers flexible schedules, remote work, gym reimbursement, and regular team-building events.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
84,57003,https://www.welcometothejungle.com/fr/companies/jow/jobs/data-engineer_paris,Data Engineer,JOW,"{Looker,Redshift,Airflow,magic,scale,NoSQL,SQL,Python}",T√©l√©travail partiel possible,"17, Rue de Lancry, Paris, 75010","E-commerce, Grande consommation, FoodTech",CDI,2023-03-26,"Jow is a new way to eat better, smarter and healthier every day. Jow‚Äôs app automatically creates a customized menu, just for you, with simple and delicious recipes, and automatically fills your cart with all the ingredients you need, magic! Your grocery is then delivered to your door by your favorite merchant, and you can enjoy our video tutorials to cook our simple and delicious recipes every day. We are strengthening our Data team and we‚Äôre looking for an experimented Data Engineer profile to develop, maintain and operate Jow‚Äôs data stack. As Jow‚Äôs Data Engineer, you‚Äôll be responsible for Jow‚Äôs Data Warehouse and ETL tools, helping Jow teams make the most of their data. Reporting to Jow‚Äôs Head of Data within Jow Platform Team (a cross-disciplinary team in charge of all tech & products challenges at Jow), you‚Äôll make an immediate impact on Jow‚Äôs business and strategy and play a central role, working with both technical and business teams. What you‚Äôll do: Develop, maintain and build evolutions to Jow‚Äôs data stack and tools: warehouse databases, ETL process, scripts & tools‚Ä¶ Maintain and enhance the existing data infrastructure Optimize the performance and scalability of the data pipelines that ingest, transform, and load data from a variety of sources into our data warehouse Collaborate with the technical, product and business teams to identify and prioritize data needs Implement data quality controls and monitoring processes Stay up-to-date with the latest data engineering technologies and best practices Our current stack: Data Warehouse: Redshift ETL: Airflow BI platform: Looker Master‚Äôs degree in Computer Science, Data Engineering, Software Development or a related field 3-5 years building/developing data architectures and/or working on data issues, ideally in a fast growing data-driven start-up company Experience with the core toolkit of Data Engineering: Python SQL & NoSQL databases Data modeling Large-scale data sets manipulation Data warehousing ETL development Able to work in French and in English Strong problem-solving and communication skills Basic full-stack dev & DevOps knowledge is a plus Call: to know about each other and check if the stars are aligned 2 to 3 more formal/classic interviews with the team, including some tech tests to assess your hard skills Breakfast or coffee with some members of the team: we want you to be happy to see our teammates every morning, so one of the very first things we check is the cultural fit. We have a ‚Äúno brilliant jerk‚Äù rule. Being nice, cool and humble is as mandatory as being good at what you do ;-)","Jow is seeking an experienced Data Engineer to develop, maintain, and operate Jow‚Äôs data stack. The role involves optimizing the performance and scalability of data pipelines, collaborating with technical, product, and business teams to identify and prioritize data needs, implementing data quality controls and monitoring processes, and staying updated with the latest data engineering technologies and best practices. The ideal candidate should have a Master's degree in Computer Science, Data Engineering, Software Development, or related fields, 3-5 years of experience building/developing data architectures and/or working on data issues, and expertise in Python, SQL & NoSQL databases, data modeling, large-scale data sets manipulation, data warehousing, and ETL development.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
468,56729,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-cdi-scala-spark_paris,Data Engineer - CDI - Scala & Spark,Assistance Publique - H√¥pitaux de Paris - DSI,"{UNIX,bash,Hive,Nvidia,Docker,portable,Kafka,NoSQL,Postgres,Elastic,Kubernetes,Java,SQL,Hadoop,Jupyter,Scala,via,Spark,Python}",T√©l√©travail partiel possible,"33 Boulevard de Picpus, Paris, 75012","Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDI,2023-03-26,"L‚Äô Assistance Publique - H√¥pitaux de Paris (AP-HP) est un √©tablissement public de sant√© et le centre hospitalier universitaire - CHU - de la r√©gion Ile-de-France, reconnu mondialement pour sa recherche. Le d√©partement Innovation & Donn√©es (I&D) s‚Äôinscrit au sein de sa Direction des Syst√®mes d‚ÄôInformation . üéØ Sa mission ? R√©aliser les projets num√©riques innovants au contact du monde hospitalier. üöÄ Ses projets phares ? Construire le plus large entrep√¥t public de donn√©es de sant√© en Europe ! Le projet vise √† valoriser les donn√©es produites √† l‚ÄôAP-HP pour la recherche, l‚Äôinnovation et le pilotage des soins, tout en prot√©geant les donn√©es patient. L‚Äô Entrep√¥t de Donn√©es de Sant√© , c‚Äôest d√©j√† +13 millions de patients dont les donn√©es sont structur√©es et r√©f√©renc√©es sur une plateforme Big Data d√©di√©e. Notre objectif est de cr√©er une base de donn√©es standardis√©e et centralis√©e √† partir d‚Äôune multitude de sources de donn√©es ( donn√©es textuelles, images, radiographies, examens, analyses biologiques, signaux physiologiques, etc.. ). Faciliter le quotidien des patients! Le domaine g√®re notamment toutes les applications mobiles et tous les t√©l√©services de l‚ÄôAP-HP, dont par exemple le ‚ÄúPortail Patient‚Äù. Monter une plateforme Bio-Informatique centrale pour assister les p√¥les de biologie de l‚ÄôAP-HP dans leurs besoins informatiques (gestion du s√©quen√ßage, d√©ploiement de ressources de calcul). D√©velopper et d√©ployer au niveau national les outils de collecte et d‚Äôanalyse √©pid√©miologique des donn√©es relatives aux maladies rares. üìä Quelles statistiques : L‚Äô Entrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP accueille aujourd‚Äôhui plus de 170 projets de recherche m√©dicale sur donn√©es : https://eds.aphp.fr/recherches-en-cours L‚ÄôEDS int√®gre des donn√©es administratives et m√©dicales de plus de 13 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (40 millions de dossiers m√©dicaux, plus de 45 millions de diagnostics, 2.5 milliards de r√©sultats de laboratoires‚Ä¶) . Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision. L‚ÄôEDS de l‚ÄôAP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 2Po d‚Äôespace disque) , de machines GPU (80 Nvidia P40, V100 et A100) , plus de 20 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es , et de nombreuses autres machines applicatives. En tant que Data Engineer , vous serez int√©gr√© au sein de l‚Äô√©quipe Big Data de l‚Äô Entrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP . Cette √©quipe est compos√©e d‚Äôune dizaine de Data Engineer travaillant √† la conception et au d√©veloppement de la base de donn√©es standardis√©e et centralis√©e de l‚ÄôEDS. Cette base contient des donn√©es aggr√©g√©es provenant de divers applicatifs de l‚ÄôAP-HP avec des typologies tr√®s diff√©rentes (donn√©es structur√©es, non-structur√©es, imagerie, voix, signaux physiologiques, etc.) qui n√©cessitera la mise en oeuvre d‚Äôoutils sp√©cifiques √† leur int√©gration et leurs traitements. Contribuer √† la d√©finition des besoins techniques et √† l‚Äôaccompagnement des Datas Scientists, chercheurs, et m√©decins lors de la r√©alisation de projets de recherche impliquant de nouvelles sources de donn√©es Analyser les diff√©rents sources de donn√©es d‚Äôun point de vue technique (acquisition, stockage, transformation, exploitation, ‚Ä¶) D√©velopper, industrialiserez et maintiendrez des traitements de donn√©es (extraction, s√©lection, collecte, int√©gration et aggr√©gation) dans un contexte Big Data (d√©veloppements en Spark/Scala/Python) Int√©gration d‚Äôalgorithmes sp√©cifiques (ML, NLP, etc.) co-d√©velopp√©s avec l‚Äô√©quipe Data Science de l‚ÄôEDS Contribuer √† l‚Äôutilisation de ces nouvelles typologies de donn√©es (extraction, s√©lection, collecte et int√©gration) via des connecteurs sp√©cifiques d√©velopp√©s en Java/Scala & Python Aider √† l‚Äôimpl√©mentation de standards et normes de mise √† disposition des donn√©es (OMOP/FHIR) Industrialiser le code de g√©n√©ration du flux de donn√©es et assurer sa performance globale Optimiser la performance des outils dans un contexte Big Data (Hadoop / Spark) D√©velopper des m√©thodologies standardis√©es pour l‚Äôint√©gration de nouvelles donn√©es Metter en place des outils les processus de tests unitaires, de recette et de qualification des donn√©es D√©velopper des solutions permettant la mise √† disposition des donn√©es dans les espaces des projets de recherche D√©velopper des solutions pour monitorer les diff√©rents processus en production ainsi que la qualit√© des donn√©es Travailler en collaboration avec des partenaires industriels dans le cadre des diff√©rents projets de recherche Vous serez force de proposition pour am√©liorer la qualit√© des d√©veloppements, notamment en r√©alisant une veille continue sur les outils et technologies, en proposant des algorithmes pouvant resoudre des probl√©matiques fonctionnelles et techniques. Avantages Technique : un cluster Hadoop de +30 serveurs une infrastructure Kubernetis√©e cons√©quente (+100 serveurs) op√©r√©e par une √©quipe voisine un ordinateur portable i7/32Go Quotidien : Cantine T√©l√©travail (max 3 jours par semaine) 25 Cong√©s pay√©s et environ 22 RTT Salaire de cadre dans la fonction publique (40 000,00‚Ç¨ √† 60 000,00‚Ç¨ par an) impos√© √† 15% contre 25% dans le priv√© N‚Äôh√©sitez pas √† vous envoyer votre CV pour un premier entretien pour en d√©couvrir + sur le poste, et peut-√™tre par la suite venir nous rencontrer dans le 12e arrondissement ! Bac+5/Master 3 ans d‚Äôexp√©riences en tant que Data Engineer Technologies et comp√©tences requises : Environnement UNIX (ou Windows selon pr√©f√©rence) Scala / Java & Python Traitement des donn√©es massives et des technologies Big Data (Hadoop, Kafka, Spark, Elastic Search, NoSQL, etc.) Bases de donn√©es SQL (Postgres, Apache Hive, LevelDB, etc.) DevOps (CI/CD, Docker, scripting, bash, etc.) Qualit√© de code (Tests, veille, code reviews, etc.) Excellent relationnel et expression personnelle Au moins un des points suivants : Industrialisation d‚Äôapplication ou de flux de traitement de donn√©es massives de mani√®re distribu√©e Administration de cluster Hadoop Pipelines CI/CD | Kubernetes / Helm charts Connaissance des standards d‚Äôinterop√©rabilit√© du domaine de la sant√© (FHIR, OMOP, CDA, HL7, CIM, Snomed, LOINC, etc.) D√©roul√© des entretiens (susceptible de varier en fonction du profil du candidat) : 1 premier entretien en visio avec des membres de l‚Äô√©quipe 1 second entretien sur place (75012 - Campus Picpus) avec possibilit√© d‚Äô√©changes avec les membres de l‚Äô√©quipe (recommand√©) 1 dernier entretien avec le directeur de la Plateforme Big Data (N+2)","The Assistance Publique - H√¥pitaux de Paris (AP-HP), the largest hospital center in the Paris region, is seeking a Data Engineer to join its Big Data team within its Department of Innovation & Data. The role involves contributing to the development of a public health data warehouse, integrating and processing diverse data types including structured and unstructured, imaging, voice, and physiological signals. The successful candidate will have at least three years of experience in data engineering and be proficient in Scala/Java and Python, Hadoop/Spark/Kafka as well as working in DevOps and CI/CD environments. Knowledge of health interoperability standards such as FHIR and OMOP is also desirable.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
234,58100,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/bi-analyst-analytics-engineer-h-f_paris,BI Analyst / Analytics Engineer,NEXTON,"{dbt,SQL,Tableau}",T√©l√©travail partiel possible,"5, Rue Saint-Fiacre, Paris, 75002","Design, IT / Digital, Digital",CDI,2023-03-26,"Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, Nexton conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, professionnalisme et performance. Et pour vous ? Notre politique de d√©veloppement des comp√©tences dynamique saura vous s√©duire avec un programme de suivi de carri√®re sur-mesure. NEXTON recrute un BI Analyst / Analytics Engineer H/F , en CDI , √† Paris ! Qui sommes-nous ? NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶). Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel. Fort du succ√®s, Nexton conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance. Et pour vous ? Notre politique de d√©veloppement des comp√©tences dynamique saura vous s√©duire avec un programme de suivi de carri√®re sur-mesure. Le contexte : En tant qu'Analyste BI / Ing√©nieur Analytics, vous faites partie d'une √©quipe multi-comp√©tence Data et vous agissez en tant qu'expert BI et data warehousing. Vos missions : Recueillir et comprendre les exigences des produits commerciaux et de donn√©es (de mani√®re autonome ou en √©quipe avec des analystes de donn√©es ; suivis par les PO/PM) Concevoir et d√©velopper des actifs BI & Datawarehouse robustes, √©volutifs et industrialis√©s (flux d'int√©gration de donn√©es / ETL / pipelines ; tables de dimension et de faits ; datamarts ; m√©triques ; KPI,‚Ä¶) visant √† faciliter et rendre coh√©rente la consommation de donn√©es en soutenant les √©quipes m√©tiers dans le suivi de leurs performances et de l'atteinte des objectifs et √©galement dans le partage de donn√©es avec d'autres syst√®mes D√©velopper des approches de support (documentation, communication, outillage, formation, etc.) vers les √©quipes techniques & m√©tiers pour assurer une acc√©l√©ration progressive de l'organisation vers une utilisation plus facile et plus syst√©matique des actifs BI dans leurs activit√©s quotidiennes De formation sup√©rieure, vous justifiez 4 √† 8 ans d'exp√©rience dans le domaine de la data. Vous travaillez de mani√®re autonome, proactive, responsable et orient√©e vers les solutions : vous n'attendez pas qu'on vous dise quoi faire. Vous fournissez des ressources approfondies et fiables dans un environnement en √©volution rapide, avec une excellente organisation et une excellente gestion du temps. Vous ma√Ætrisez les mod√®les de transformation de donn√©es (ETL/ELT) ainsi que le SQL (dbt) et Tableau. Vous avez une connaissance pointue des pratiques d'int√©gration et de mod√©lisation de donn√©es : conception ETL, techniques de mod√©lisation des donn√©es dimensionnelles et techniques de reporting / visualisation de donn√©es Vous savez travailler en m√©thode agile et g√©rer plusieurs sujets en parall√®le, avec diff√©rents acteurs impliqu√©s. Des excellentes comp√©tences en communication orale et √©crite en anglais sont obligatoires. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'ann√©e : - Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts - De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'ann√©e - Des moments privil√©gi√©s avec votre manager Pr√™ts √† nous rejoindre ? Rencontrons-nous !","NEXTON, a digital transformation company, is seeking a BI Analyst/Analytics Engineer with 4-8 years' experience and expertise in data warehousing, ETL/ELT, SQL, Tableau, and data integration and modeling. The successful candidate will have excellent communication skills, work autonomously and proactively, and be able to manage multiple projects simultaneously.NEXTON offers a dynamic skills development program and a supportive work environment.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
232,56848,https://www.welcometothejungle.com/fr/companies/thelio/jobs/data-engineer-experimente_lyon,Data Engineer,Th√©lio,"{Oracle,Databricks,Talend,Qlik,Scala,Snowflake,Kafka,Hadoop,Spark,Azure,NoSQL,SQL,Tableau}",T√©l√©travail partiel possible,"21, Quai Antoine Riboud, Lyon, 69002","IT / Digital, Strat√©gie, Big Data",CDI,2023-03-26,"Th√©lio est n√© pour relever un d√©fi : d√©mystifier le monde de la Data pour la rendre accessible √† toutes les entreprises Sa raison d‚Äô√™tre ? : des entreprises et organisations plus performantes, innovantes et humaines, gr√¢ce √† l‚Äôintelligence de la donn√©e N√© √† Bordeaux et continuant sa croissance √† Lyon et Aix-en-Provence , Th√©lio intervient sur toute la cha√Æne de valeur de la donn√©e‚ÄØ: Strat√©gie & Gouvernance Data Data Visualisation Modern Data Platform Int√©gration Data Master Data Management Qualit√© & Conformit√© de la Donn√©e Selon vos exp√©riences, votre mission, si vous l‚Äôacceptez, sera de : D√©finir les architectures data de nos clients : challenger l‚Äôexistant et proposer de nouvelles solutions, Effectuer des analyses fonctionnelles et de r√©diger les sp√©cifications, retranscrire les besoins m√©tiers en solutions techniques, Concevoir et d√©velopper des pipelines de donn√©es, Garantir la s√©curit√© et l‚Äôint√©grit√© des donn√©es, Encadrer vos coll√®gues dans le respect de la charge et du planning projet et transmettre votre expertise, √ätre garant des solutions techniques mises en ≈ìuvre, D‚Äôune mani√®re g√©n√©rale, √™tre force de proposition sur les projets de la conception √† la mise en production. En fonction de votre exp√©rience, vous serez √©galement amen√©(e) √† intervenir sur les sujets tels que : participation aux avant-ventes, mise en place de POC, accompagnement √† la gestion de projet, missions de conseil et d‚Äôaudit, d‚Äôexpertise technique et d‚Äôoptimisation sur tous nos clients Auvergne-Rh√¥nes-Alpes. Pour relever ce d√©fi, il vous faut : Avoir au moins 3 ans d‚Äôexp√©rience : o Sur des probl√©matiques de mod√©lisation, d‚Äôorganisation de donn√©es, mise en place de pipelines de donn√©es, optimisations techniques o Sur des probl√©matiques d‚Äôing√©nierie de donn√©es : temps-r√©el, gestion de sch√©mas, r√©silience, redondance, scalabilit√©, ordonnancement‚Ä¶ √ätre aguerri(e) √† la maitrise du SQL, Poss√©der une r√©elle app√©tence pour la donn√©e, et √™tre toujours en veille sur le domaine, Ma√Ætriser une ou plusieurs technologies suivantes : o Azure Data Factory, Azure Databricks o Stockage : SQL Server, Oracle, Azure Datalake, Google Big Query, Snowflake o Big Data : Kafka, Spark, Scala, Hadoop, Google Big Query, HortonWorks, NoSQL o Grand avantage : Poss√©der une ou des certifications sur les outils maitris√©s Sensibilit√© au cloud (gestion des co√ªts, scalabilit√©s, flexibilit√©‚Ä¶) En bonus, exp√©riences en d√©cisionnel : mod√©lisation BI et/ou ETL (Talend, SSIS) et/ou outil de dataviz (Power BI, Tableau, Qlik, Cognos) √ätre force de proposition et aimer transmettre votre savoir On vous aide dans la recherche de votre nouveau logement sur Lyon, afin de faciliter votre d√©marrage chez nous !","Th√©lio is seeking for a Data Engineer to define data architectures for clients, develop data pipelines, ensure data security, and lead project teams. The ideal candidate should have at least 3 years of experience in data modeling, pipeline development, and knowledge of SQL, Azure Data Factory, Azure Databricks, and other relevant technologies. Certification in relevant tools and experience in data visualization and BI are a plus.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
199,56766,https://www.welcometothejungle.com/fr/companies/thelio/jobs/data-engineer-experimente-bordeaux_begles,Data Engineer,Th√©lio,"{Oracle,Databricks,Talend,Qlik,Scala,Snowflake,Kafka,Hadoop,Spark,Azure,NoSQL,SQL,Microstrategy,Tableau}",T√©l√©travail partiel possible,"Boulevard Jean-Jacques Bosc, Bordeaux, 33800","IT / Digital, Strat√©gie, Big Data",CDI,2023-03-26,"Th√©lio est n√© pour relever un d√©fi : d√©mystifier le monde de la Data pour la rendre accessible √† toutes les entreprises Sa raison d‚Äô√™tre ? : des entreprises et organisations plus performantes, innovantes et humaines, gr√¢ce √† l‚Äôintelligence de la donn√©e N√© √† Bordeaux et continuant sa croissance √† Lyon et Aix-en-Provence , Th√©lio intervient sur toute la cha√Æne de valeur de la donn√©e‚ÄØ: Strat√©gie & Gouvernance Data Data Visualisation Modern Data Platform Int√©gration Data Master Data Management Qualit√© & Conformit√© de la Donn√©e Selon vos exp√©riences, votre mission, si vous l‚Äôacceptez, sera de : D√©finir les architectures data de nos clients : challenger l‚Äôexistant et proposer de nouvelles solutions, Effectuer des analyses fonctionnelles et de r√©diger les sp√©cifications, retranscrire les besoins m√©tiers en solutions techniques, Concevoir et d√©velopper des pipelines de donn√©es, Garantir la s√©curit√© et l‚Äôint√©grit√© des donn√©es, Encadrer vos coll√®gues dans le respect de la charge et du planning projet et transmettre votre expertise, √ätre garant des solutions techniques mises en ≈ìuvre, D‚Äôune mani√®re g√©n√©rale, √™tre force de proposition sur les projets de la conception √† la mise en production. En fonction de votre exp√©rience, vous serez √©galement amen√©(e) √† intervenir sur les sujets tels que : participation aux avant-ventes, mise en place de POC, accompagnement √† la gestion de projet, missions de conseil et d‚Äôaudit, d‚Äôexpertise technique et d‚Äôoptimisation sur tous nos clients Sud-Ouest. Pour relever ce d√©fi, il vous faut : Avoir au moins 3 ans d‚Äôexp√©rience : sur des probl√©matiques de mod√©lisation, mise en place de pipelines de donn√©es, optimisation techniques, sur des probl√©matiques d‚Äôing√©nierie de donn√©es : temps-r√©el, gestion de sch√©mas, r√©silience, redondance, scalabilit√©, ordonnancement‚Ä¶, √ätre aguerri(e) √† la maitrise du SQL, Poss√©der une r√©elle app√©tence pour la donn√©e, et √™tre toujours en veille sur le domaine, Ma√Ætriser une ou plusieurs technologies suivantes : Azure Data Factory, Azure Databricks Stockage : SQL Server, Oracle, Azure Datalake, Google Big Query, Snowflake Big Data : Kafka, Spark, Scala, Hadoop, Google Big Query, HortonWorks, NoSQL Grand avantage : Poss√©der une ou des certifications sur les outils maitris√©s Sensibilit√© au cloud (gestion des co√ªts, scalabilit√©s, flexibilit√©‚Ä¶) En bonus, exp√©riences en d√©cisionnel : mod√©lisation BI et/ou ETL (Talend, SSIS) et/ou outil de dataviz (Power BI, Tableau, Qlik, Microstrategy) √ätre force de proposition et aimer transmettre votre savoir On vous aide dans la recherche de votre nouveau logement sur Bordeaux, afin de faciliter votre d√©marrage chez nous !","Th√©lio is seeking a Data Architect with at least 3 years of experience in data modeling, pipeline development, and technical optimization. The ideal candidate should have strong SQL skills and be knowledgeable in Azure Data Factory, Azure Databricks, and various storage and big data technologies. They must also possess excellent problem-solving skills and be able to propose and transmit their ideas effectively. A certification in any of the relevant tools is a plus, along with experience in BI modeling or ETL tools. Applicants should be proactive and enjoy sharing their expertise. As a bonus, Th√©lio helps with housing in Bordeaux for a smooth transition into the company.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
463,56506,https://www.welcometothejungle.com/fr/companies/quanticfy/jobs/data-software-engineer_tunis_TQF_Jj3m1dV,Data Software Engineer,THE QUANTIC FACTORY,"{MySQL,PHP,Linux,GIT}",T√©l√©travail partiel possible,Tunis,Big Data,CDI,2023-03-26,"Quanticfy est une solution SaaS d‚Äôanalyse de donn√©es disponible pour les boutiques utilisant la plate-forme eCommerce Shopify. Elle propose de centraliser leurs data puis de les traiter √† des fins d‚Äôattribution marketing et d‚Äôanalyses clients. A propos de Shopify : il s‚Äôagit du CMS le plus populaire du moment, il r√©unit environ 2 millions de boutiques eCommerce du monde entier, le volume d‚Äôaffaires que repr√©sente l‚Äôensemble de ces boutiques se situe entre celui d‚ÄôAmazon et celui d‚ÄôEBay. L‚Äôambition de Quanticfy est de d√©mocratiser l‚Äôusage de la data aupr√®s de tous les eCommer√ßants de cet √©cosyst√®me, en leur apportant des solutions technologiques √† haute valeur ajout√©e, le tout dans un contexte o√π l‚Äôusage de la donn√©e se doit d‚Äô√™tre exemplaire en mati√®re de respect de la vie priv√©e. Le Data Software Engineer prend en charge, sp√©cifie, d√©veloppe, documente et d√©ploie des services applicatifs utilis√©s 24h/24 dans le monde entier. Rattach√©.e √† la DIRECTION TECHNIQUE, vous aurez √† charge des missions telles que : D√©velopper de nouveaux algorithmes pour toute la cha√Æne de traitement, notamment le traitement des donn√©es par Data Science ; Concevoir l‚Äô√©volution des syst√®mes pour mieux r√©pondre aux besoins de nos clients (devops) ; R√©diger des sp√©cifications. Soutenu.e par notre Directeur technique vous d√©velopperez vos comp√©tences techniques au sein d‚Äôune entreprise tourn√©e vers l‚Äôexcellence technologique. Vous vous verrez confier rapidement des responsabilit√©s importantes et vous aurez l‚Äôoccasion d‚Äôutiliser des technologies de pointe. The Quantic Factory d√©veloppe des logiciels SaaS de synchronisation de donn√©es √† destination des e-commer√ßants. VOTRE PROFIL Autonomie, responsabilit√©, cr√©ativit√©, forte dose d‚Äôapprentissage‚Ä¶ sont pour vous des aspirations ! Nous recherchons un d√©veloppeur doubl√© d‚Äôun chef de projet comp√©tent, motiv√©, consciencieux, impliqu√©, capable d‚Äôimaginer rapidement des solutions simples √† des probl√®mes parfois complexes. L‚Äôusage de m√©thodologies de travail d√©riv√©es des m√©thodes Agile (ex : Scrum) est d√©j√† appr√©hend√©. Vous √™tes un bon communiquant ce qui vous permet d‚Äô√©voluer dans des projets dont le contexte est collaboratif. Les qualit√©s que nous recherchons avant tout : le pragmatisme et la rigueur, l‚Äôimplication, la cr√©ativit√©, capacit√© de communication, et la soif d‚Äôapprendre. VOTRE FORMATION, VOTRE EXPERIENCE Issu(e) d‚Äôune formation technique (Ing√©nieur ou √©quivalent), vous : avez une exp√©rience dans le d√©veloppement de logiciels utilisant de la donn√©e de mani√®re intensive avez d√©j√† men√© des projets techniques de A √† Z (depuis les sp√©cifications jusqu‚Äô√† la livraison) COMPETENCES RECHERCHEES Indispensables : Programmation objet/syst√®me, Ma√Ætrise d‚Äôau moins un langage backend Versionning sous GIT, Base de donn√©es : MySQL Linux. Appr√©ci√©es : Devops, Anglais Environnement Google Cloud Platform, Architecture orient√©e service (SOA). PHP 7 Un √† deux entretiens sont pr√©vus (avec le CEO et le CTO) ainsi qu‚Äôun test technique.","Quanticfy seeks a data software engineer who will develop new algorithms for data processing, design system evolution, and write specifications for a SaaS data analysis solution. The ideal candidate should be autonomous, reliable, creative, and a good communicator with experience in developing software and leading technical projects. Proficiency in programming and system object, MySQL, Git, and Linux is a must, while experience in DevOps, SOA, and fluency in English is favourable. Quanticfy offers a collaborative environment that values pragmatism, diligence, creativity, communication, and continuous learning.",Bac +5 / Master,< 15 salari√©s,> 3 ans,2,0,0.027697749441558416
462,56304,https://www.welcometothejungle.com/fr/companies/d-edge/jobs/database-reliability-engineer-m-f-nb_paris,Database Reliability Engineer NB,D-EDGE Hospitality Solutions,"{Microsoft,GCP,Couchbase,MongoDB,Redis,color,MariaDB,Mysql,AWS,R,Elasticsearch,noSQL,Linux,Azure,NoSQL,SQL}",T√©l√©travail partiel possible,Paris,"Digital Marketing / Data Marketing, SaaS / Cloud Services, Tourisme",CDI,2023-03-26,"Have you ever booked a hotel online? Then you‚Äôve probably used D-EDGE without knowing it. Every day, we help more than 17,000 hotels worldwide to develop their online visibility and sales through a range of SaaS and digital marketing solutions. Amongst the 500+ D-EDGERS, the Tech and Product team is made up of a hundred or so enthusiasts who are reinventing hotel booking for both the traveller and the hotelier. As a subsidiary of the Accor group, D-EDGE simplifies the life of independent hotels and hotel chains alike. ABOUT THE TEAM: You will be joining the ‚ÄúEngineering Infrastructure Team‚Äù alongside Guillaume DEFENDINI , Skander REDJEL , Philippe BECHU , Gabriel GARCIA , Jeremy BOUCHET . You will be reporting to Julien SCHERER , Engineering Team Leader. The team focuses on the deployment of new infrastructure architectures and softwares to answer the business needs in accordance with the standards defined by the architecture team. Designing, Testing and Referencing solutions for the infrastructure of Tomorrow is the main goal accross all team members. Team conceives infrastructure for production team, for itself and for the business in a devops mindset and by discussing with the R&D department, mainly with the development tech leads and the software architects. ABOUT THE ROLE : As a DBRE, you will design, optimize, supervise and participate in the maintenance in operational conditions of the databases within our global Cloud infrastructure in order to meet the business requirements in terms of performance, availability, security and sustainability for our external customers and our internal uses. You will be the technical referent of the Database domain of the data architecture enabling a transformation to the Cloud by qualifying the health of the databases, their capacities, their performance, the debugging of the queries, the training of the internal development teams. MISSIONS: Maintain databases in optimal conditions (performance, availability). Automation of deployments / updates (Infrastructure as a Code) Risk and security management (DRP, How do we recover data? Does our backup granularity meet RPO requirements) Performance optimization of SQL/noSQL processing performed by our platforms in close collaboration with our development and architecture teams Supporting developers in the design of data structures and SQL/NoSQL development Develop the DEVOPS culture through the Dev / Ops teams Participation in the production releases of the components we develop and operate Supervision and analysis of Database activity, monitoring of jobs, incident management Security management in accordance with the internal PSSI and the standards in force, user management Management and supervision of data archiving and data structure cleaning Technical watch WHAT WE ARE LOOKING FOR: Bac+5 in IT 3 years experience minimum as DBRE (or similar) Very good knowledge of NoSQL/SQL databases (MongoDB, AWS Aurora, Couchbase, SQL Server, Mysql, MariaDB, ‚Ä¶) Good knowledge of Cloud environments (AWS, Microsoft Azure, GCP or OVH) Good knowledge of distributed data storage (Elasticsearch, Redis..) Good knowledge of automation tools (Ansible, Terraform..) Competence on Linux technologies (Ubuntu / CentOS environment) and Microsoft Server Knowledge of the Agile / DevOps environment (Scrum - Kanban).Very good level of English (read / spoken / written). Good interpersonal skills, sense of service, analytical and synthesis skills, autonomy, versatility, dynamism and you have the ability to generate confidence in our business Communication skills, team spirit, intellectual curiosity, strength of proposal, reactivity, rigor, sense of responsibility and commitment WHAT WE OFFER: Attractive salary according to your profile D-Edge is Remote Friendly 50% of transport costs from home to work Meal Allowance (Swile : 9,48‚Ç¨/day, paid at 60%) Accor Employee Card : Discount on hotel bookings Incentives plans, bonuses and wage savings CSE: Sports and cultural activities, gift cards and various discounts Vendredi : Access a network of certified nonprofits to get involved in You will participate to our great internal invents: D-Convention: This is THE event that D-EDGERS are looking forward to D-Coffee roulette: Informal meetings between colleagues from all over the world. D-Summer Party: Annual meeting to spend a fun and friendly moment with all D-EDGERS 1) Telephone interview with Talent Acquisition 2) First interview with Infrastructure Team Lead 3) On-line Technical Test 4) Technical interview with team members 5) Interview with the Head of Infrastructure ‚Ä¶ and welcome to D-EDGE ! :) Please be aware that we will be asking for work references. D-EDGE is an equal opportunity employer. We do not discriminate based on : race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status.","D-EDGE is seeking a DBRE with a minimum of three years of experience and good knowledge of SQL and NoSQL databases, automation tools like Ansible and Terraform, cloud environments like AWS, Microsoft Azure, GCP, and OVH, and Linux technologies. The candidate should also have knowledge of the Agile/DevOps environment, strong analytical and synthesis skills, and be able to generate confidence for the company. The company offers an attractive salary, remote working, meal allowance, and discounted hotel bookings, among other incentives. The interview process comprises a telephone interview, technical tests, and multiple interviews with team members and the Head of Infrastructure.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
10,56410,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-cloud-poei_puteaux_DATAS_5xMkPLa,Data Engineer  | POEI,Datascientest,"{Microsoft,GCP,AWS,Azure,Java,Python}",T√©l√©travail ponctuel autoris√©,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"Vous √™tes demandeur d‚Äôemploi et vivement int√©ress√©(e) par les m√©tiers de la Data ? Rejoignez DataScientest en int√©grant une formation 100% financ√©e par P√¥le Emploi afin d‚Äôacqu√©rir les comp√©tences cl√©s qui vous permettront de booster votre carri√®re en tant que Data Engineer Cloud, un m√©tier en tension et en plein essor. Cette formation est certifi√©e par l‚ÄôEcole des Mines ParisTech, et inclut le passage de certifications √©diteurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilit√©. Apr√®s avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire. Les candidats retenus b√©n√©ficieront d‚Äôune formation intensive, enti√®rement prise en charge par le dispositif POEI (Pr√©paration Op√©rationnelle √† l‚ÄôEmploi Individuel) avec P√¥le-Emploi. En tant que Cloud Data Engineer, vous aurez pour missions de proposer les meilleures solutions aux entreprises afin d‚Äôoptimiser leur activit√©, √† travers les missions suivantes : D√©veloppement de solutions permettant de traiter des volumes importants de donn√©es, Conception, collection et fabrication des donn√©es brutes, Cr√©ation d‚Äôoutils et algorithmes pour le traitement des donn√©es, Pr√©paration des donn√©es pour le Data Analyst, S√©curisation des Pipelines donn√©es pour les Data Analysts et Data Scientists, Organisation de l‚Äôarchitecture du cloud Ce que nous vous offrons : Une certification de l‚ÄôEcole des Mines ParisTech Un CDI aupr√®s de notre partenaire JEMS Group, expert europ√©en dans le traitement et l‚Äôexploitation des donn√©es Un salaire attractif √† la cl√© : 35 000‚Ç¨ √† 48 000‚Ç¨ selon le profil Votre profil : Issu(e) d‚Äôune fili√®re scientifique ou informatique vous disposez d‚Äôun bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieur, Vous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la Data, Vous ma√Ætrisez un langage objet type Java, Python, C++, etc. Vous √™tes inscrit(e) √† P√¥le Emploi","DataScientest is seeking job seekers with scientific or computer science backgrounds to join their 100% funded training program to become a Cloud Data Engineer. The program is certified by the √âcole des Mines ParisTech and includes certifications from AWS, Microsoft Azure, or GCP to increase employability. Graduates of the program will be offered a permanent contract to join JEMS Group as a Cloud Data Engineer with a salary ranging from ‚Ç¨35,000 to ‚Ç¨48,000. Ideal candidates have experience in computer development or data architecture and knowledge of object-oriented programming languages such as Java or Python. Applicants must be registered with P√¥le Emploi.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,1,1,0.027697749441558416
81,73486,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-quality-engineer_paris,Data Quality Engineer,Groupe SeLoger,"{AZURE,python,java,scala,sql,javascript,AWS,GCP}",T√©l√©travail partiel possible,"7 Boulevard Haussmann, Paris, 75009","Application mobile, IT / Digital, M√©dia",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Fran√ßais dans la r√©alisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d‚Äôoffrir √† chacun de nos utilisateurs, une exp√©rience immobili√®re simple et efficace afin qu‚Äôils concr√©tisent leurs projets d‚Äôachat, de vente ou de location en toute s√©r√©nit√©. Nous mettons √† disposition des Fran√ßais le plus large choix d‚Äôannonces afin de leur faciliter la recherche d‚Äôun bien selon leurs crit√®res propres, et r√©pondre √† toutes les questions soulev√©es par la r√©alisation d‚Äôun projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque pr√©f√©r√©e des Fran√ßais pour se rep√©rer et se lancer dans leur projet immobilier. Ce que nous faisons dans le domaine Marketplace Design- Product and Tech √† l'AVIV Le domaine Marketplace Design du groupe AVIV fait partie de l'organisation Product & Tech et son objectif est de fournir les services internes qui permettent aux √©quipes d'Acteurs d'apporter la s√©curit√©, la fiabilit√© et de supprimer l'opacit√© de l'exp√©rience. En s'appuyant sur l'expertise locale d'Immowelt (Allemagne et Autriche), Immoweb (Belgique), Groupe SeLoger et Meilleurs Agents (France), nous fournissons des services d'√©valuation de la fraude, de la tricherie et de la fiabilit√© de l'information afin d'am√©liorer la s√©curit√© et la fiabilit√© de la place de march√© dans les interactions entre les chercheurs et les propri√©taires/agents. Nous recherchons une personne qui: Fera partie d'une √©quipe agile, multidisciplinaire et internationale et travaillera en √©troite collaboration avec elle pour Identifier les probl√®mes de qualit√© des donn√©es, et mettre en ≈ìuvre des solutions pour v√©rifier, valider et surveiller la qualit√© des donn√©es. Contribuer √† l'analyse des probl√®mes de donn√©es et aider √† identifier les processus op√©rationnels et les am√©liorations techniques qui contribuent √† une meilleure qualit√© des donn√©es Travailler avec l'√©quipe produit pour √©tablir des normes de qualit√© des donn√©es au sein des sprints, d√©velopper un plan de test et livrer des builds de haute qualit√© dans les d√©lais. Travailler avec les propri√©taires de produits et les ing√©nieurs de donn√©es pour am√©liorer l'exp√©rience globale en sugg√©rant des am√©liorations et des changements Concevoir et maintenir des rapports d'assurance qualit√© pour les syst√®mes de donn√©es internes Aligner et collaborer avec le reste de l'√©quipe de qualit√© des donn√©es pour am√©liorer la qualit√© globale, √©valuer les risques, promouvoir la coh√©rence, identifier les besoins communs. D√©velopper des strat√©gies de test pour l'automatisation √† la fois pour le backend et les donn√©es R√©diger et ex√©cuter des tests de donn√©es fonctionnels et non fonctionnels. Vous convainquez par votre esprit d'analyse Une personne qui a: Une solide exp√©rience (au moins 3 ans) en tant qu'ing√©nieur en qualit√© des donn√©es Une exp√©rience pratique de travail avec les m√©thodologies agiles Dipl√¥me en informatique ou autres qualifications pertinentes La certification ISTQB est un plus Exp√©rience pratique de la cr√©ation et de la maintenance de tests ETL et API Exp√©rience dans l'automatisation de tests de donn√©es avec des frameworks comme Deequ ou autres Exp√©rience dans l'automatisation de tests d'API avec javascript ou des biblioth√®ques java comme fetch, superAgent, restAssured... Vous √™tes √† l'aise pour lire et √©crire du code dans au moins un langage de programmation, id√©alement java, scala, python Compr√©hension de base de sql Exp√©rience avec les outils CI/CD Les bases de l'exp√©rience du cloud comme AWS, GCP, AZURE sont un plus Un joueur d'√©quipe proactif qui analyse le risque et l'impact des probl√®mes et travaille avec l'√©quipe pour les prioriser et les r√©soudre Toute exp√©rience en mati√®re de tests de performance, GDPR, accessibilit√©, interop√©rabilit√© et s√©curit√© est un plus Excellentes comp√©tences en communication, avec une ma√Ætrise de l'anglais. La volont√© de voyager de temps en temps est disponible",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
194,56473,https://www.welcometothejungle.com/fr/companies/pass-culture/jobs/data-engineer_paris_PC_N4R853W,Data Engineer,pass Culture,"{Algolia,React,ElasticSearch,Tensorflow,Metabase,CloudSQL,Looker,Airflow,Kubernetes,Docker,github,GCS,K8s,Bigquery,GCP,Python}",T√©l√©travail partiel possible,"89, Rue La Bo√©tie, Paris, 75008","Application mobile, Mus√©es / Institutions culturelles, Th√©√¢tre, Cin√©ma, Musique, Art / March√© de l'art",CDI,2023-03-26,"Le pass Culture est l‚Äôune des r√©formes prioritaires du gouvernement en mati√®re culturelle. Il s‚Äôappuie sur une application gratuite et g√©olocalis√©e destin√©e √† favoriser l‚Äôacc√®s des jeunes aux arts et √† la culture, encourager et diversifier leurs pratiques culturelles et artistiques. Le dispositif permet aux jeunes de b√©n√©ficier d‚Äôun cr√©dit en fonction de leur √¢ge (20 ‚Ç¨ √† 15 ans, 30 ‚Ç¨ √† 16 et 17 ans, 300 ‚Ç¨ √† 18 ans), qu‚Äôils peuvent d√©penser dans une vari√©t√© d‚Äôoffres physiques ou num√©riques pour approfondir ou s‚Äôinitier √† une pratique artistique. En parall√®le, un volet collectif, inscrit dans la politique d‚Äô√âducation Artistique et Culturelle (EAC) est directement attribu√© aux √©tablissements scolaires. Chaque classe, de la 4√®me √† la Terminale, se voit allouer un cr√©dit de 20, 25 ou 30 euros par √©l√®ve, destin√© √† financer des activit√©s effectu√©es en groupes et encadr√©es par les professeurs. Le p√¥le data est compos√© √† la fois de data analysts, data scientists et data engineers qui travaillent en collaboration avec les diff√©rentes √©quipes du pass Culture (tech, produit, d√©veloppement, programmation). Son r√¥le est de collecter et de transformer la donn√©e afin de cr√©er de nouveaux services et de proposer des solutions aux diff√©rentes probl√©matiques rencontr√©es. Le p√¥le est notamment en charge de la mise en place d‚Äôalgorithmes ML (recommandation d‚Äôoffres au utilisateurs, segmentation, alerting, ‚Ä¶), de la mise en place d‚ÄôAB tests sur le produit (utilisation de la recherche, la performance de la page d‚Äôaccueil de l‚Äôapplication mobile, retention des utilisateurs et des acteurs culturels‚Ä¶), d‚Äôanalyses sur les pratiques culturelles , de la mise √† disposition de tableaux de bords pour les √©quipes interne ainsi que de la valorisation de la donn√©e √† l‚Äôexterne (institutions, partenaires et conf√©rences). Cette √©quipe, au c≈ìur du pass Culture, accompagne ainsi l‚Äôensemble de l‚Äôorganisation au coeur d‚Äôune politique publique qui cherche √† intensifier et diversifier les pratiques culturelles des jeunes de 15 √† 20 ans. Tu peux trouver plus d‚Äôinformation sur l‚Äôorganisation produit sur cette fiche Notion . Au sein de l‚Äô√©quipe Data, tes missions seront : üí´ Conception, d√©veloppement et responsabilit√© du datalake üß† D√©veloppement, supervision et am√©lioration des services data ML internes (API, Recommandation) üë∑ Automatisation des pipelines et cr√©ation de nouveaux mod√®les de donn√©es üó∫Ô∏è Participation √† la strat√©gie data et aux rituels de notre p√¥le : stand-ups, d√©mo, team building, etc üí´ Accompagnagment et coaching des data analysts & scientists sur leur probl√®matiques engineering ü´∂ Et surtout‚Ä¶ tu souhaites relever le d√©fi de porter la culture vers tous ! Notre stack : Data Visualisation : Metabase, Looker Infrastructure : GCP (Airflow, K8s, CloudSQL, VertexAI) Data Warehouse : Bigquery / GCS ML : Python / Tensorflow Cloud Management : Terraform Autres √©quipes : Python & React Native Autres services : Contentful, Algolia, ElasticSearch, GA Une bonne partie est open source, tu peux trouver les repos ici : https://github.com/pass-culture üë¥ Tu as 4 ans d‚Äôexp√©rience en tant que Data Engineer / ML Engineer üß± Tu as de solides comp√©tences en ing√©nierie et en data science üîÆ Capacit√© √† comprendre et √† expliquer des architectures complexes üåá Exp√©rience dans la construction et la maintenance de syst√®mes en production üíª Ma√Ætrise de Python, Docker, Airflow. Kubernetes est un plus ü§ù Esprit d‚Äô√©quipe et int√©r√™t pour la mission du pass Culture entretien d√©couverte avec le Lead Data entretien technique avec l‚Äô√©quipe entretien de motivation avec un Product Manager","The Pass Culture program is seeking a Data Engineer/ML Engineer to work with their data analysts, data scientists, and data engineers to collect, transform and analyze data to improve their services and address different challenges. The ideal candidate should have at least 4 years of experience, strong engineering and data science skills, and expertise in Python, Docker, and Airflow. They should also have an interest in the Pass Culture program's mission of intensifying and diversifying cultural experiences for 15-20-year-olds.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
68,57120,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_5N1XgoR,Data Engineer - Madonne Core,Natixis,"{SingleStore,Scala,via,Spark,SQL,Hadoop}",T√©l√©travail partiel possible,"rue de montmartre, Paris, 75002","Banque, Transformation, Assurance",CDI,2023-03-26,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking , financements, banque commerciale et sur les march√©s de capitaux. Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050. Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne. Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job. Vous rejoignez l'√©quipe Core en charge de la maintenance √©volutive des applications Madonne (R√©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifi√©e au coeur de l'IT Risque). Au quotidien vous avez pour missions de : Participer √† l'adaptation de nos applications en ad√©quation avec les besoins m√©tiers (nouveaux produits, nouvelles r√®glementations, nouveaux SI Front) ; Participer activement √† la modernisation de nos outils, modernisation de notre cha√Æne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ; Monter en comp√©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous d√©velopperez une compr√©hension globale des cha√Ænes de traitements ; Participer √† tous les travaux de modernisation de notre SI, et √™tre donc engag√© dans la migration de nombreux process vers le DataLake Risk. #MuchMoreThanJustAJob Ce poste est bas√© √† Paris avec la possibilit√© de t√©l√©travailler. En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours. Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif. Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise. A propos du processus de recrutement Vous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier). Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous : Vous souhaitez b√©n√©ficier d'une premi√®re exp√©rience significative en d√©veloppement Spark et Scala. Vous maitrisez : * Les m√©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une app√©tence pour la manipulation de la data. Vous √™tes : * Reconnu par votre esprit d'√©quipe ; * Capable de communiquer avec des publics diff√©rents, notamment avec le m√©tier ; * Autonome et nt√©ress√© par l'environnement finance de march√©. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.","Natixis Corporate & Investment Banking, a top international financial actor, is seeking a developer proficient in Spark and Scala, with knowledge of Agile methodologies, C#, SQL, and an interest in market finance. The successful candidate will join the Core team responsible for maintaining and improving the Madonne and BOP applications, and will participate in modernizing the tools and processes. Fluency in English at the B1 level is required. Natixis is committed to environmental transition and offers an inclusive, hybrid work environment with opportunities for internal mobility, career development, and social engagement.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
73,56678,https://www.welcometothejungle.com/fr/companies/illuin-tech/jobs/data-engineer_neuilly-sur-seine,Data Engineer,ILLUIN Technology,"{UNIX,Scala,Kubernetes,AWS,Docker,R,Git,Java,NoSQL,SQL,Python,Bash,MLFlow}",T√©l√©travail partiel possible,"183, Avenue Charles de Gaulle, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"ILLUIN Technology, c‚Äôest LA r√©f√©rence pour le d√©veloppement de solutions technologiques de pointe en France. En √† peine 6 ans, ILLUIN Technology est pass√©e de 11 √† 80+ Illuiners et a atteint un chiffre d‚Äôaffaires de 7,2 M‚Ç¨ en 2022 en r√©alisant des projets sur mesure aussi diversifi√©s - IA, web, mobile, AR/VR, IoT, etc. - que bluffants sur le plan technique et UX. Le secret ? Leurs quelques 50+ clients grands comptes, startups, asso, etc. vous le disent : ‚ÄúILLUIN, ce sont des personnes agr√©ables, dot√©es d‚Äôun tr√®s haut niveau technique, polyvalentes et toujours engag√©es.‚Äù Et ce n‚Äôest pas tout ! Depuis 2 ans, la soci√©t√© propulse aussi ses propres produits utilisant l‚Äô√©tat de l‚Äôart du NLU dans le domaine de l‚ÄôIA conversationnelle et du traitement intelligent de document (parsing, search‚Ä¶). - Pourquoi nous rejoindre ? üèÖ Nous sommes certifi√©s HappyAtWork 2022 et avec le 2√®me meilleur score des startups fran√ßaises üåç Nous donnons 1500‚Ç¨ √† une association pour chaque cooptation et autant au cooptant üöÄ Nous avons un framework d‚Äô√©volution clair et transparent qui permet de se projeter üí∏ Nous proposons un package de r√©mun√©ration des plus attractifs du march√© et une √©volution rapide üåø Nous donnons du sens au travail : coaching d‚Äô√©tudiants, Tech4Good, unit√© Data x Sant√©, startup studio‚Ä¶ üòç Nous valorisons plus que tout la bienveillance, la stimulation intellectuelle et l‚Äô√©quilibre pro-perso üíª Nous travaillons sur du mat√©riel haut de gamme (Macbook Pro / DELL XPS, √©cran QHD) ‚Üí Votre mission En tant que Data Engineer, votre r√¥le sera d‚Äôindustrialiser des solutions d‚ÄôIA scalables √† grande √©chelle, de d√©velopper des pipelines de transformation de donn√©es √† gros volume ainsi que de mettre en place des solutions de stockage centralis√© (data warehouses, data lakes). Ces solutions s‚Äôinscrivent dans le cadre de projets sur-mesure pour nos clients ou pour r√©pondre aux besoins en data engineering de nos produits ILLUIN Technology. ‚Üí Vos responsabilit√©s Participer √† la conception et l‚Äôoptimisation de solutions technologiques traitant un gros volume de donn√©es √† grande √©chelle et r√©pondant aux besoins des utilisateurs/clients R√©aliser des projets en √©quipe, encadr√©.e par des profils exp√©riment√©s qui vous feront monter en comp√©tences Perfectionner ses comp√©tences et chercher constamment √† am√©liorer les outils et les m√©thodes employ√©es (veille technologique, R&D, √©changes de bonnes pratiques, hackathons) Participer √† des code reviews avec les membres de votre √©quipe, challenger les impl√©mentations, partager votre expertise et faire grandir les illuiners juniors autour de vous Prendre part aux c√©r√©monies et sprint reviews en lien direct avec le client / nos √©quipes produits Participer au d√©veloppement de projets internes transverses : recherche, OPS, s√©curit√©, formations, ‚Ä¶ Participer √† l‚Äô√©volution de notre offre de Data Engineering en √©paulant ponctuellement l‚Äô√©quipe commerciale gr√¢ce √† votre expertise technique Nous cherchons le match parfait üíì ‚Ä¶mais nous croyons √† la richesse des rencontres ! Alors si vous n‚Äô√™tes pas certain.e de matcher notre recherche nous vous encourageons √† nous contacter quand m√™me ‚úâÔ∏è ‚úÖ Must have Exp√©rience avec un langage de programmation (Java / Kotlin / Scala / Python) Bonne compr√©hension des solutions de processing de donn√©es (queueing, streaming, batch processing, caching) Bonne compr√©hension des solutions de stockage donn√©es (bases de donn√©es SQL / NoSQL, data warehouse, data lake) Exp√©rience avec Git et des outils d‚Äôint√©gration continue Exp√©rience avec Docker üåà Nice to have Bonne compr√©hension du fonctionnement du Web Tests unitaires et d‚Äôint√©gration Exp√©rience en OPS (Kubernetes, Terraform, Ansible, ‚Ä¶) Exp√©rience avec un framework back-end (Spring, Symfony, ‚Ä¶) Utilisation de framework de MLOps / ML Engineering (Zen ML, ClearML, MLFlow, ‚Ä¶) Connaissances de base UNIX & Bash Exp√©rience sur des outils cloud (Google Cloud, AWS, OpenStack, ‚Ä¶) Connaissances en IA / data science (machine learning, deep learning, NLP) ü§© Les gens disent de vous que‚Ä¶ Vous √™tes engag√©.e et pr√™t.e √† donner le meilleur de vous-m√™mes Vous √™tes curieux.se, flexible, empathique, autonome Vous avez le sens du partage et le sens du travail en √©quipe Vous partagez nos valeurs : confiance, empowerment, excellence, innovation Apr√®s un 1er contact par t√©l√©phone, voici le processus : Test technique √† distance (1h) Entretien Tech Live Entretien Human Fit Entretien Head of Software Engineering Entretien CEO","ILLUIN Technology is seeking a Data Engineer with programming experience in Java/Kotlin/Scala/Python and a good understanding of data processing, storage solutions, and Git. The role involves industrializing scalable AI solutions, developing pipelines for data processing, and centralizing storage solutions. The company values collaboration, personal development, and diversity. The recruitment process includes a technical test, two technical interviews, a Human Fit interview, and a final interview with the Head of Software Engineering and CEO. The company offers competitive compensations, promotes work-life balance, and supports various charitable causes. Nice-to-have skills include experience in OPS, web testing, cloud platforms, and AI/data science.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
75,56695,https://www.welcometothejungle.com/fr/companies/scalapay/jobs/data-engineer_barcelona,Data Engineer,Scalapay,"{Athena,Kubernetes,Glue,AWS,magic,S3,scale,Linux,Git,SQL,Python}",T√©l√©travail partiel possible,"Barcelona, 08007","FinTech / InsurTech, Mode, Art de vivre",CDI,2023-03-26,"Scalapay transforme la fa√ßon dont les consommateurs r√©alisent leurs achats online et en magasin, en permettant aux commer√ßants d‚Äôoffrir √† leurs clients des exp√©riences magiques. Avec plus de 4 000 d√©taillants dans les secteurs de la mode, de la beaut√©, de la maison et du voyage qui nous font confiance (Moschino, Calzedonia, G√©rard Darel, Nike, Shein, pour n‚Äôen citer que quelques-uns), nous avons plus d‚Äôun million de clients qui utilisent Scalapay aujourd‚Äôhui en Europe. Apr√®s une s√©rie B de 497M$ en f√©vrier 2022 men√©e par Tencent et Willoughby Capital, nous avons obtenu le statut de licorne ! Gr√¢ce √† cela, nos √©quipes grandissent rapidement et nous recherchons des talents extraordinaires pour venir rejoindre l‚Äôaventure et nous aider √† fa√ßonner l‚Äôavenir du paiement et des produits checkout dans l‚Äô√©cosyst√®me eCommerce. Travailler avec nous signifie un quotidien o√π tout va tr√®s vite, o√π chacun a l‚Äôopportunit√© de mener des projets passionnants et stimulants, et de faire partie d‚Äôune √©quipe anim√©e par 4 valeurs tr√®s fortes : #createmagic #staycurious #beimpactful #playasateam. Nous sommes fiers d‚Äô√™tre l‚Äôune des 10 meilleures startups pour lesquelles travailler selon LinkedIn, et la startup de l‚Äôann√©e 2021 en Italie. This is where your magic happens. If you love it, Scalapay it üñ§ Thanks to our innovative BuyNow PayLater payment solution, Scalapay is transforming the way more than 3.5 million customers buy online and in-store, empowering 5,000+ merchants to give their customers magical shopping experiences. Being only 3 years old didn‚Äôt stop us from becoming a unicorn ü¶Ñ We have raised over $700mln and we did this thanks to a team built around our 4 core values: #createmagic #staycurious #beimpactful #playasateam. This is where your magic happens. If you love it, Scalapay it ‚ô• THE MISSION Data-driven decisions are the centre of our efforts to automate processes and support decisions across the business. As Data Engineer , your role will focus on developing distributed software for large-scale heterogeneous data processing, the development of ETL and reverse ETL pipeline. You will be responsible for: - Data modelling - Data lineage - Data quality / Data observability - SLA, performance and scalability You‚Äôll be required to discuss requirements for data access and integrations with colleagues across the business, design solutions to the company‚Äôs problems and implement these using modern software processes in the cloud. The role gives a large amount of autonomy and the chance to work with a top-notch team of experienced data experts. Who we are looking for: - Strong Python and SQL experience - Experience building and deploying ETL pipelines - Experience with API integration - Ability to scope projects and decompose work into tasks - Familiarity with Linux-like development stacks, including Git, Kubernetes, etc - Familiarity with AWS infrastructure (such as S3, Athena, Glue, etc) - Knowledge of Data Modeling / Data Observability is a plus - Ability to engage with colleagues on business processes - A Bachelor's degree in computer science or a related field Why you should join Scalapay: - Attractive packages based on skills and experience - International environment with significant challenges to be met every day - Lots of opportunities to work with a team of industry tech leaders who are focused on delivering products that offer exceptional user experiences - Personalised support to accelerate your professional growth and take ownership of the products you deliver: we want to help you grow! - Latest technologies and being encouraged to bring your flair to the role Recruitment Process: 1) A quick chat with one of our Talent Acquisition team members 2) The first interview with the Hiring Manager to deep dive into your experiences and better understand your motivation 3) A case study to test your hard skills 4) A Meet The Team session where you‚Äôll get to meet different people at Scalapay and see if you‚Äôll fit into our culture _________________________________________________________________________ Want to learn more? Don't hesitate to explore our Careers website and Careers website, and our LinkedIn, WTTJ, Meritocracy and Glassdoor pages. Pro tip: send your CV in English üòâ Super Pro tip: we know that application processes can be scary and frustrating but‚Ä¶ we look for talent, not people that tick all our boxes. We believe in the power of diversity: Scalapay is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation.","Scalapay, an innovative BuyNow PayLater payment solution transforming online and in-store shopping experiences, is seeking a Data Engineer to build and develop software for large-scale heterogeneous data processing, ETL and reverse ETL pipeline. The role requires strong Python and SQL skills, experience with API integration and Linux-like development stacks, among others. The ideal candidate will have a Bachelor's degree in computer science or a related field, and be able to engage with colleagues on business processes. Scalapay provides an international working environment, attractive packages, and personalized support for professional growth.",Bac +3,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
76,73482,https://www.welcometothejungle.com/fr/companies/neoxia/jobs/data-engineer-confirme-h-f,Data Engineer confirm√©,Neoxia,"{Kafka,Kinesis,Snowflake,Redshift,Scala,Dask,Beam,Airflow,AWS,Pandas,Prefect,BigQuery,Azure,via,Spark,Java,Synapse,Python,Teradata,Hadoop,GCP}",T√©l√©travail partiel possible,Paris,"Logiciels, IT / Digital",CDI,2023-04-22,"A chacun son domaine d‚Äôexcellence, sa source d‚Äôexpression ! Qu‚Äôils soient Cloud-Native d√©veloppeur, ou Product Designer, les Neoxiens de la Tribe Digital participent √† la r√©alisation de projets ambitieux en s‚Äôappuyant sur les meilleurs √©cosyst√®mes Cloud (AWS, GCP, Azure) pour leurs Clients grands comptes ou Start-Up (comme Veolia, Free2Move, BlaBlaCar, JC Decaux, Eurosport, Pernod-Ricard, le Minist√®re de l‚Äô√âducation Nationale, Safran, Intermarch√©, Routard.com, PlayPlay‚Ä¶). Du cot√© de la Tribe Data, personne ne fait semblant. De la partie Engineering jusqu‚Äô√† la partie Ops en passant par le Machine Learning, leur √©quipe de sp√©cialistes en pleine croissance adresse tous les challenges autour des Datas qui les entourent. Cloud, Infra as Code et DevOps raisonnent comme un Eldorado ? Bienvenue chez SKALE-5, soci√©t√© du Groupe NEOXIA pure player du secteur ! Google Cloud, Amazon Web Service et Azure n‚Äôont pas de secret pour eux. √ätre Neoxien ou Skaleur c‚Äôest √™tre exigeant, c‚Äôest vouloir une ma√Ætrise concr√®te des technologies car leurs m√©tiers impliquent une r√©alisation s√©rieuse et soign√©e. Par ailleurs, ils sont convaincus que la r√©alisation de soi passe aussi par la satisfaction que l‚Äôon tire de son travail. C‚Äôest ici, dans un contexte bienveillant que vous trouverez la solidarit√© et l‚Äôentraide pour vous exprimer pleinement. Au sein de notre Tribe Data Participer √† l‚Äô√©laboration d‚Äôarchitectures cibles pour la collecte, le stockage, le traitement et l‚Äôanalyse de donn√©es sur les plateformes cloud de nos partenaires AWS, Google, Azure Concevoir, d√©velopper et d√©ployer des flux de donn√©es complexes sur des environnements cloud Assurer le suivi de la qualit√© des donn√©es collect√©es et trait√©es √† travers la mise en place de tests automatis√©s Suivre la bonne application des r√®gles de gouvernance des donn√©es √† travers la mise en place d‚Äôoutils d√©di√©s Participer √† la mise en place de plateformes data sur le cloud et au d√©ploiement des outils n√©cessaires pour le traitement et l‚Äôanalyse des donn√©es. Concevoir et d√©ployer les outils n√©cessaires pour la mise √† disposition des donn√©es pour les data scientists et pour les utilisateurs finaux des donn√©es Accompagner les data engineers / ops des squads projet par la formation, le coaching et la mise en place des bonnes pratiques Assurer une veille technologique et diffuser les connaissances via l‚Äôorganisation d‚Äôateliers au sein de neoxia ou de meetup ouverts √† la communaut√© (ex Azure UG ) Tu interviendras √©galement dans l‚Äôanimation interne autour des diff√©rents sujets Data Engineering et Data Ops. Ainsi, tu devras : Assurer une veille technologique et diffuser tes connaissances via l‚Äôorganisation d‚Äôateliers au sein de neoxia ou de meetup ouverts √† la communaut√© Intervenir au sein des guildes internes ‚ÄúData Engineering‚Äù et ‚ÄúData Ops / ML Ops‚Äù pour consolider les convictions de Neoxia et cr√©er les supports n√©cessaires pour pouvoir partager ces convictions Accompagner les data scientists, data engineers et data ops des squads projet par la formation, le coaching et la mise en place des bonnes pratiques Dipl√¥m√©(e) en ing√©nierie informatique Plusieurs exp√©riences 100% Data √† minima pendant 3 ans. Dynamique et rigoureux (se), tu as un bon relationnel. Tu es √† la fois autonome et √† l‚Äô√©coute des autres. Tu es passionn√©(e) de technologie et curieux(se) au sujet de l‚Äô√©volution des pratiques d‚Äôing√©nierie logicielle (Continuous Delivery, DevOps, ‚Ä¶) Comp√©tences Expertise sur des technologies Cloud Data : GCP, AWS, Azure Expertise sur une solution de Data Warehousing : Teradata, BigQuery, Redshift, Synapse, Snowflake‚Ä¶. Expertise sur un outil d‚Äôorchestration de flux : Airflow, Prefect, Dragster‚Ä¶. Expertise de d√©veloppement sur un framework de traitement de donn√©es : Pandas, Spark (Python, Scala, Java), Apache Beam ou Dask Connaissances autour de technologies de ‚Äúevent/stream processing‚Äù : Kafka, Kinesis, Pub/sub,‚Ä¶ Connaissances li√©es √† l‚Äô√©cosyst√®me Hadoop serait un plus Connaissances en machine learning serait un plus Entretien t√©l√©phonique RH Test technique en ligne pour valider des pr√©-requis n√©cessaire pour nous rejoindre Un ‚Äúuse case‚Äù d‚Äô1h30 avec l‚Äô un de nos lead tech Une derni√®re √©tape avec un manager ou un associ√© pour parler de tes motivations / envies et de la compatibilit√© de tout cela avec la culture neoxienne et le parcours",,Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
464,57076,https://www.welcometothejungle.com/fr/companies/health-data-hub/jobs/referent-donnees-dataops-h-f_paris,R√©f√©rent donn√©es / data engineer,Health Data Hub,"{Jupyter,Microsoft,regard,Git,spark,GitLab,pandas,Gitlab,dask,GitHub,via,R,Spark,Azure,SQL,Python}",T√©l√©travail partiel possible,"9 Rue Georges Pitard, Paris, 75015","Intelligence artificielle / Machine Learning, Sant√©",CDI,2023-03-26,"Comment am√©liorer les d√©pistages et faire en sorte que les patients soient pris en charge le plus t√¥t possible ? Comment leur proposer les meilleurs traitements sur le long cours ? Comment appuyer les professionnels de sant√© dans un contexte clinique qui se complexifie ou en cas de crise sanitaire ? L‚ÄôIntelligence Artificielle et les donn√©es de sant√© font partie de la r√©ponse. Elles sont incontournables pour la recherche et l‚Äôinnovation en sant√©. Par exemple, pour pr√©venir des insuffisances cardiaques √† partir de donn√©es issues d‚Äôappareils connect√©s, ou pour acc√©l√©rer le d√©pistage du cancer du sein √† partir d‚Äôanalyses automatiques des examens de mammographies. Ou m√™me pour r√©unir assez d‚Äôinformations afin d‚Äôam√©liorer la prise en charge des maladies rares. Et pour √ßa, la France a la chance de disposer de bases de donn√©es extr√™mement riches ! Mais ces donn√©es sont souvent sous exploit√©es car dispers√©es. Gr√¢ce √† des solutions innovantes telles que l‚ÄôIA, l‚Äôobjectif du Health Data Hub est justement de permettre d‚Äôacc√©der de mani√®re facilit√©e; unifi√©e, transparente et s√©curis√©e √† un catalogue de bases de donn√©es de sant√© fran√ßaises. Comment ? Le Health Data Hub a mis en place une plateforme technologique qui met √† disposition des porteurs de projets d‚Äôint√©r√™t public, dans un environnement technologique s√©curis√© et √† l‚Äô√©tat de l‚Äôart, les donn√©es de sant√© pseudonymis√©es des fran√ßais. Ces porteurs de projets vont mobiliser des sources de donn√©es tr√®s volumineuses, les croiser entre elles, et utiliser une puissance de calcul pour faire tourner des algorithmes de recherche complexes. Il s‚Äôagit par exemple de projets de start-up pour am√©liorer des logiciels d‚Äôaide au professionnel de sant√©, de projets permettant d‚Äôam√©liorer la prise en charge des patients en comparant l‚Äôefficacit√© de prise en charge, de projets port√©s par les administrations pour √©clairer les politiques publiques. Notre offre technologique, en constante √©volution, peut √™tre consult√©e ici. Les d√©fis sont de taille pour traiter ces donn√©es de sant√© sensibles, volumineuses de natures et formats variables. La plateforme doit √™tre un levier d‚Äôinnovation dans l‚Äô√©cosyst√®me de la donn√©e de sant√© fran√ßais. En r√©sum√©, avec le Hub, nous accompagnons des porteurs de projets innovants qui contribuent √† trouver les solutions de demain pour am√©liorer la sant√© de tous les citoyens. Direction des donn√©es : Pour mener √† bien les missions qui lui ont √©t√© confi√©es, le Health Data Hub a form√© la direction des donn√©es dont les objectifs principaux sont de : D√©finir des strat√©gies novatrices sur la gestion, l‚Äôexploitation et le partage de donn√©es de sant√©, permettant de r√©aliser la vision du HDH ; Partager et mutualiser les outils et les connaissances n√©cessaires √† l‚Äôanalyse des donn√©es de sant√©, dans le cadre d‚Äôune d√©marche open source. G√©rer et mettre √† disposition les donn√©es qui lui sont confi√©es aux porteurs de projet au sein de la plateforme technologique du Health Data Hub ; Soutenir les projets d‚Äôint√©r√™t public que le HDH accompagne, aussi bien sur la compr√©hension des donn√©es de sant√© que sur leur exploitation via des experts des donn√©es de sant√©, des data scientists et des data engineers. P√¥le ‚ÄúGestion des donn√©es‚Äù : Pour r√©pondre √† la troisi√®me mission qui lui a √©t√© conf√©r√©e et d√©finir une approche claire pour l‚Äô√©cosyst√®me de la sant√©, la direction des donn√©es s‚Äôest dot√©e d‚Äôun p√¥le ‚ÄúGestion des donn√©es‚Äù. Ce p√¥le est responsable de l‚Äôint√©gralit√© du cycle de vie des donn√©es, et se structure autour des chantiers suivants : Traitement des donn√©es de sant√© massives et diverses transmises par les porteurs de projet √† la plateforme technologique du Health Data Hub ; Gestion et mise en qualit√© des donn√©es de sant√© stock√©es dans la plateforme technologique du Health Data Hub ; D√©veloppement de librairies en Python ou R pour faciliter, automatiser et syst√©matiser les traitements des donn√©es cit√©s pr√©c√©demment ; Analyses exploratoires de nouvelles fonctionnalit√©s et applications (e.g., cluster spark, lecteur d‚Äôimages sp√©cifiques au secteur de la sant√©) √† int√©grer √† la plateforme technologique du Health Data Hub. Ces missions sont essentielles pour garantir la fiabilit√© des recherches men√©es sur la plateforme technologique et pr√©sentent d‚Äôimportants d√©fis au regard du caract√®re h√©t√©rog√®ne des donn√©es manipul√©es (e.g., donn√©es m√©dico-administratives, imagerie m√©dicale, compte-rendus m√©dicaux) et des efforts n√©cessaires pour les rendre utilisables. Activit√©s du poste : En tant que data engineer ayant le r√¥le de ‚Äúr√©f√©rent des donn√©es‚Äù, au sein du p√¥le ‚ÄúGestion des donn√©es‚Äù, vous aurez pour missions de : r√©aliser les traitements n√©cessaires pour la bonne gestion du parcours des donn√©es pr√©sentes sur la plateforme technologique du Health Data Hub‚ÄØ: collaborer conjointement avec la Direction Projets et Services utilisateurs et prendre connaissance du protocole scientifique et des buts premiers de chacun des projets accompagner. Cette phase s‚Äôaccompagne d‚Äôune d√©couverte du ou des jeu(x) de donn√©es complet(s) tant au niveau fonctionnel qu‚Äôau niveau technique; documenter et d√©finir les conditions d‚Äôimport des donn√©es sur la plateforme, en relation avec des acteurs externes (producteurs de donn√©es, porteurs de projets de recherche) ; travailler dans la plateforme technologique du Health Data Hub ; utiliser les librairies existantes et les compl√©ter pour d√©velopper des scripts Python et PySpark permettant de manipuler des grande quantite de donn√©es (~To) sous diff√©rentes formats (e.g., tabulaires, texte libre, images, JSON) re√ßues sur la plateforme technologique. v√©rifier l‚Äôint√©grit√©, confidentialit√© et conformit√© √† certains crit√®res de qualit√© d√©finis en amont ainsi que de de les pr√©parer pour leur mise √† disposition (e.g., reformatage, jointure, transformation) ; contribuer √† la documentation de ces op√©rations. d√©velopper et g√©rer les outils logiciels internes √† la direction des donn√©es : d√©finir l‚Äôarchitecture des librairies logicielles servant √† automatiser les √©tapes de traitement des donn√©es ; d√©velopper, documenter, tester et maintenir ces librairies ; optimiser le traitement de jeux de donn√©es de grande taille (plusieurs t√©raoctets) pour minimiser les co√ªts et d√©lais de traitement ; adapter les librairies pour permettre de traitement de donn√©es diverses (comptes-rendus m√©dicaux, images d‚ÄôIRM, bases hospitali√®res, bases nationales) ; collaborer avec le reste du p√¥le en suivant la m√©thodologie Agile-scrum (gestion d‚Äôun backlog, rituels scrum, etc.) en s‚Äôappuyant sur des pratiques de d√©veloppement √† l‚Äô√©tat de l‚Äôart (notamment, int√©gration continue via GitLab). d√©velopper et g√©rer les outils √† destination des utilisateurs de la plateforme : accompagner l‚Äô√©quipe produit dans l‚Äôidentification ou l‚Äô√©tude de nouvelles fonctionnalit√©s √† int√©grer √† la plateforme technologique aupr√®s des utilisateurs (e.g., producteurs de donn√©es, porteurs de projets, √©quipe des r√©f√©rents des donn√©es) pour garantir un service adapt√©, et inscrire les demandes de nouveaux d√©veloppements ou rapports de bugs dans le backlog produit ; tester, via le d√©veloppement de prototypes, de nouvelles technologies √† int√©grer √† l‚Äôoffre technologique de la plateforme pour r√©pondre aux mieux aux besoins des utilisateurs, en collaboration avec les √©quipes Produit et Plateforme du Health Data Hub ; configurer, une fois le prototype valid√©, la technologie avant son int√©gration dans la plateforme technologique par la Direction technique du Health Data Hub. La tech stack (pile de technologies) utilis√©e pour ces missions sera principalement : Python comme langage de programmation g√©n√©raliste notebooks Jupyter pour acc√©der √† la plateforme et organiser la documentation d‚Äôutilisation (tutoriels) pandas pour l‚Äôanalyse des donn√©es CSV de petite taille et Spark / pyspark pour les donn√©es volumineuses pytest pour les tests de librairies Gitlab pour la gestion du d√©veloppement et l‚Äôint√©gration continue Microsoft Azure pour le stockage et le requ√™tage de donn√©es volumineuses Suite Google pour la bureautique (Google Docs, Google Sheets, etc.) Pour les besoins des utilisateurs externes, certaines librairies sont √©galement d√©velopp√©es et maintenues en R / sparklyR. Dans le cadre des projets d‚Äôaccompagnement du HDH aupr√®s de nos partenaires, vous pourrez √™tre amen√©(e) √† vous rendre disponible et vous mettre √† disposition selon les besoins aupr√®s d‚Äôinstitutions du domaine de la recherche m√©dicale en r√©gion parisienne. Comp√©tences indispensables Excellente ma√Ætrise du langage Python Bonne ma√Ætrise de SQL et de gestion de bases de donn√©es Bonne ma√Ætrise des librairies de traitement de donn√©es (e.g., pandas, dask, dplyr) Connaissance des diff√©rents paradigmes de d√©veloppement de librairies et applicatif (e.g., orient√© objet, fonctionnel) Connaissance des outils en ligne de travail collaboratif type Git (GitHub ou GitLab) Capacit√©s r√©dactionnelles Bon relationnel : capacit√© √† interagir avec les partenaires externes du HDH (startups, institutions publiques, etc.) Comp√©tences additionnelles recherch√©es Ma√Ætrise des frameworks de calcul distribu√© (Spark) Ma√Ætrise de R Ma√Ætrise d‚Äôenvironnements cloud (notamment Azure) Exp√©rience avec des formats de donn√©es complexes (par exemple : images DICOM, JSON complexes, CSV de tr√®s grande taille etc.) Connaissance des approches de d√©veloppement (notamment CI/CD et DevOps) Connaissance de la m√©thodologie Agile/scrum Une exp√©rience dans le domaine de la recherche m√©dicale est un plus. POURQUOI CHOISIR LE HEALTH DATA HUB ? Vous √™tes motiv√©(e) √† rejoindre une √©quipe impliqu√©e dans un projet ambitieux, qui a du sens et une finalit√© d‚Äôint√©r√™t public ? Rejoignez-nous ! Notre r√©cente structure a besoin de talents cr√©atifs, autonomes et proactifs pour continuer de grandir ! Ensemble, nous nous sommes engag√©s √† : Accompagner les porteurs de projet visant √† analyser les donn√©es de sant√© pour le bien commun. Construire et op√©rer une plateforme technologique pour leur offrir les meilleurs outils avec un tr√®s haut niveau de s√©curit√© √† respecter. R√©unir et mettre en forme les donn√©es au plus grand potentiel pour la recherche et l‚Äôinnovation. Promouvoir le partage des connaissances, des expertises et du savoir et diffuser une culture de la donn√©e de sant√© aupr√®s de tous. Bon √† savoir: üí™ Rejoindre le HDH c‚Äôest surtout participer √† un projet enrichissant humainement qui a du sens, avec un fort impact soci√©tal üèÜ Au HDH on favorise la prise d‚Äôinitiative, dans une ambiance de challenge perp√©tuel üòé Ici la bonne humeur et l‚Äôesprit d‚Äô√©quipe r√®gnent Apr√®s avoir postul√©, voil√† comment se d√©roulera le recrutement: Un premier entretien avec un membre de l‚Äô√©quipe Une mise en situation √† pr√©parer chez soi Un entretien technique, bas√© sur la mise en situation, avec un membre de l‚Äô√©quipe et le Directeur Data Un entretien avec la directrice du Health Data Hub Un entretien de formalit√© RH","The Health Data Hub is seeking a Data Engineer to work within the Data Management team to manage and manipulate large sets of health data. The role involves working with Python, notebooks Jupyter, Pandas, Spark, and SQL to develop and manage libraries and software tools to handle, process and store large amounts of data. The engineer will also work with stakeholders to communicate project requirements and ensure data quality. The ideal candidate will have experience in Agile and Scrum methodology, and experience with healthcare data formats, cloud environments, and dev-ops approaches would be helpful. The Health Data Hub is looking for a candidate who is proactive, autonomous, and driven to join a team working on an ambitious project with a strong social impact.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
212,65937,https://www.welcometothejungle.com/fr/companies/gleamer/jobs/data-engineer_paris,Medical Data Engineer,GLEAMER,"{Java,regard,Python}",T√©l√©travail ponctuel autoris√©,"117, Quai de Valmy, Paris, 75010","Logiciels, Intelligence artificielle / Machine Learning, Sant√©",CDI,2023-04-05,"GLEAMER met l‚Äôintelligence artificielle au service des m√©decins en d√©veloppant des solutions capables de s√©curiser leurs diagnostics et d‚Äôam√©liorer leur environnement de travail. Plus que des logiciels, ses produits sont de v√©ritables compagnons de travail pour les m√©decins utilisateurs. Ils agissent comme une seconde lecture automatis√©e et transparente. Actuellement en pleine croissance, GLEAMER a l‚Äôambition de r√©volutionner le monde de l‚Äôimagerie m√©dicale gr√¢ce √† une technologie de pointe. üöÄ Mission L‚Äôinterdisciplinarit√© est un des piliers de GLEAMER. Chaque Data Engineer collabore avec les membres de l‚Äô√©quipe Data, permettant le partage d‚Äôexp√©riences et de bonnes pratiques, mais est aussi associ√© √† une Squad, en charge du d√©veloppement et/ou de l‚Äôam√©lioration d‚Äôun produit et inclut des membres des √©quipes M√©dicale, Produit, IA, Data, Clinique et QARA. Responsable de la partie Data au sein de la Squad que tu int√©greras, tu auras un r√¥le d√©cisif dans la conception et l‚Äôam√©lioration de dispositifs m√©dicaux innovants et ambitieux. Ta mission principale sera de participer activement au d√©veloppement de nos produits futurs en imagerie 3D et √† l‚Äôam√©lioration continue de nos produits existants BoneView et ChestView √† travers les diff√©rentes t√¢ches qui te seront confi√©es. üíª Responsabilit√©s Participer √† la d√©finition de la strat√©gie d‚Äôannotation et des besoins en donn√©es en collaboration avec les membres de ta Squad et de l‚Äô√©quipe Data Assurer en bin√¥me avec le radiologue r√©f√©rent la qualit√© et le suivi des annotations Participer aux formations des annotateurs en collaboration avec l‚Äô√©quipe M√©dicale Participer √† la r√©flexion sur les outils utilis√©s, √† l‚Äôam√©lioration des outils internes, et notamment assurer l‚Äôenrichissement des m√©thodes de traitement du langage pour l‚Äôoptimisation de l‚Äôannotation Participer au processus d‚Äôimport de donn√©es en assurant le bon d√©roulement des exports en court, en aidant √† la mise en place de nouveaux exports et en prenant part au contr√¥le qualit√© des donn√©es r√©cup√©r√©es En tant que membre de l‚Äô√©quipe Data, tu pourras aussi √™tre amen√©(e) √† : Participer √† des t√¢ches en lien avec nos autres produits, existants ou √† venir Assurer l‚Äôint√©grit√© de la base de donn√©es ; Participer √† des t√¢ches en lien avec les √©tudes cliniques. üìå Hard skills Connaissances en Python et/ou Java Connaissances en base de donn√©es Bon niveau d‚ÄôAnglais üìå Soft skills Fort int√©r√™t pour le domaine m√©dical (des connaissances en imagerie m√©dicale/norme Dicom sont un plus) Rigueur scientifique et regard critique indispensables Bonnes capacit√©s de communication üéì Profil recherch√© Niveau d‚Äô√©tude Bac +5/Master, profils junior accept√©s üíµ Salaire 40 000‚Ç¨ - 50 000‚Ç¨ selon profil et exp√©rience","Data Engineer role at GLEAMER involves working with interdisciplinary teams to develop innovative medical imaging products that use artificial intelligence to enhance the medical diagnosis process. The main responsibility involves participating in the development of future 3D imaging products and enhancing existing products' BoneView and ChestView continuous improvement. The ideal candidate's hard skills include knowledge of Python, Java, and database with a good level of English. The candidate must also possess a strong interest in the medical field, scientific rigor, critical thinking, and excellent communication skills. Candidates with Bac+5/Master's degree and junior profiles are welcome to apply with a salary range of ‚Ç¨40k-‚Ç¨50k commensurate with experience.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,1,1,0.027697749441558416
201,57146,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_paris,Expert.e technique ETL Semarchy xDI / Stambia,CGI,{},T√©l√©travail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Semarchy xDI / Stambia ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Semarchy ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√©.e d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert.e technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a leader in digital consulting and services, is seeking a Data Integration Expert with experience in ETL Semarchy xDI/Stambia to work on national and international projects across various industries. Responsibilities include analysis, collaboration with engineers, developing technical documentation, and providing technical support to clients. The successful candidate must have at least three years of experience as a technical expert in data integration and be a team player with an ambitious and proactive mindset. Knowledge of data quality and governance is a plus. CGI is an inclusive employer committed to diversity, work-life balance, and career advancement for all employees.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
243,56562,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_85eO0j8,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",T√©l√©travail partiel possible,"Courbevoie, 92014",Energie,CDI,2023-03-26,"Enedis est une entreprise de service public, gestionnaire du r√©seau de distribution d'√©lectricit√©. Elle d√©veloppe, exploite, modernise le r√©seau √©lectrique et g√®re les donn√©es associ√©es. Elle facilite la transition √©nerg√©tique des territoires en les accompagnant dans le d√©veloppement et la planification de leur production d'√©lectricit√© d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le d√©pannage 24h/24, le relev√© des compteurs et toutes les interventions techniques. Ind√©pendante, Enedis d√©livre la m√™me qualit√© de service aux fournisseurs d'√©nergie. Comme le pr√©voit la loi, elle a √©tabli un code de bonne conduite auquel ses collaborateurs sont form√©s afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des m√©tiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilit√© du Syst√®me d'information dans un contexte de forte num√©risation des m√©tiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engag√©e notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Syst√®me d'Information √† la transformation num√©rique ou dans le positionnement d'Enedis comme op√©rateur de donn√©es, la DSI met en oeuvre de nombreux projets majeurs en lien avec les m√©tiers concern√©s. Chez Enedis comme chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez Enedis m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Le monde de l'IT et des nouvelles technologies vous int√©resse ? Contribuer √† la r√©ussite de la transformation digitale et num√©rique du Groupe EDF vous plairait ? Et travailler en mode collaboratif dans des espaces de travail innovants, inspirants et √©panouissants ? C'est ce que nous vous proposons en rejoignant une √©quipe dynamique, agile et passionn√©e ! Un des enjeux majeurs d'Enedis est de devenir un op√©rateur de confiance de Donn√©es √©nerg√©tiques. Afin de r√©pondre √† cet enjeu, Enedis a mis en place une plateforme de donn√©es pour l'entreprise. Cette plateforme est compos√©e d'une infrastructure de donn√©es centralis√©e construite sur Hadoop et d'outils √† destination des √©quipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'am√©liorer cette plateforme sur plusieurs axes : migration vers le cloud, √©volution de l'architecture avec en cible une plateforme modulaire composant des services manag√©s, automatisation et mont√©e en gamme de l'offre de services internes permettant aux √©quipes de gagner en autonomie dans la cr√©ation de v√©ritables produits de donn√©es. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des √©quipes du train SAFe DataServices4U - √©quipe SPHINX, en charge de l'infrastructure data des activit√©s exploratoires (big data, big mem, GPU) - d√©finira, d√©veloppera, mettra en place et maintiendra les outils et infrastructures ad√©quats aux op√©rations du reste du train (√©quipes data scientists et data engineers). - veillera √† garantir les op√©rations des solutions permettant le traitement de volumes importants de donn√©es tout en garantissant la s√©curit√© de celles-ci - d√©finira les enablers √† prendre en compte dans l'√©quipe - sera Tech. Lead d'une √©quipe d'une dizaine de personnes - testera les r√©alisations de l'√©quipe - contribuera aux d√©monstrations faites aux √©quipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous √™tes issu d'une formation de type Bac +5 dans le domaine de l'IT / syst√®me d'information / Num√©rique et DATA - Vous disposez d'une exp√©rience d'au moins 4 ans dans des activit√©s √©quivalentes, au cours desquelles vous avec avez d√©velopp√© de solides comp√©tences techniques - Vous avez un profil Ing√©nieur Big Data disposant de comp√©tences d'analyse, de synth√®se, de cr√©ativit√© et d'une app√©tence pour l'innovation. - Vous avez de bonnes connaissances de l'administration syst√®me UNIX : ma√Ætrise de Linux (Redhat), Bash - ainsi que composants s√©curit√© et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacit√©s de communication (orales et √©crites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacit√©s de coordination - Vous faites preuve de curiosit√©, d'esprit de synth√®se, de m√©thodologie et de rigueur dans un environnement complexe Le poste est situ√© √† Courbevoie, avec une possibilit√© de t√©l√©travail partiel. La r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","Enedis is seeking a System Team Engineer DataOps with a background in IT or data to become a technical leader of one of their teams to define, develop, implement, and maintain the tools and infrastructure needed to operate the big data, along with ensuring the safety of the data. The ideal candidate should have knowledge of UNIX system administration, Hadoop, Spark, Teradata, Kafka, and Python, along with excellent coordination and communication skills. The position offers competitive compensation and benefits and is located in Courbevoie, with the possibility of partial telecommuting.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
211,65931,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-f-h_toulouse_MERIT_Lgr6GVy,Data Engineer,Meritis,{Java},T√©l√©travail ponctuel autoris√©,"Place du Capitole, Toulouse, 31000","IT / Digital, Finance",CDI,2023-04-05,"Meritis est une soci√©t√© de conseil en transformation des Syst√®mes d‚ÄôInformation et Organisations. Notre mission : associer les meilleurs talents √† l‚Äô√©laboration de transformations cr√©atrices de valeur. Nous sommes une entreprise o√π il fait bon travailler ! R√©guli√®rement labellis√©e Great Place To Work ¬Æ : N¬∞3 GPTW en 2020, N¬∞1 GPTW en 2017, N¬∞7 GPTW en 2015, N¬∞5 GPTW en 2013. En 2021 Meritis est class√©e 11e du Palmar√®s Europ√©en des Best Work Places. üëâ GPTW Au sein du p√¥le Data IA, vous int√©grerez les √©quipes qui sont responsables de la collecte des donn√©es, vous serez en charge de : R√©cup√©rer, organiser et mettre en forme la donn√©e D√©velopper de nouvelles fonctionnalit√©s R√©aliser les tests techniques Faire √©voluer l'architecture Produire la documentation Encadrer une √©quipe de d√©veloppeur Pr√™t.e √† d√©marrer de nouveaux challenges dans une entreprise o√π il fait bon vivre ? Meritis offre √† ses collaborateurs : ‚Ä¢ Un accompagnement personnalis√© tout au long de leur carri√®re, ‚Ä¢ Des parcours professionnels sur mesure‚ÄØ: choix des projets, √©volution de carri√®re, formations adapt√©es et mentoring. Mais aussi de‚ÄØ: ‚Ä¢ B√©n√©ficier d‚Äôun r√©seau de clients riche et vari√©, ‚Ä¢ Travailler dans un environnement convivial avec de nombreux √©v√©nements festifs et techniques, ‚Ä¢ Envisager des mobilit√©s g√©ographiques internes gr√¢ce au maillage r√©gional du groupe. Nos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Vous avez un dipl√¥me d‚Äôing√©nieur (Bac+5), une sp√©cialisation dans l'ing√©nierie informatique est un plus Vous disposez de plus de 7 ans d'exp√©rience en d√©veloppement Java Vous √™tes autonome, rigoureux.se et organis√©.e Vous √™tes bilingue Anglais","Meritis, a consultancy firm in Information Systems and Organizational transformation, seeks a Java Developer with over 7 years of experience in Java development to join its Data IA team. The successful candidate will be responsible for collecting data, developing new features, testing technical aspects, evolving architecture, documentation, and leading a team of developers. Meritis encourages diversity and non-discrimination, and all their jobs are accessible to people with disabilities. The ideal candidate must have a master's in engineering, a specialization in IT engineering is desirable, be autonomous, organized, and bilingual in English. Meritis offers customized career paths, variety in clients, and internal geographical mobility.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,1,1,0.027697749441558416
248,56621,https://www.welcometothejungle.com/fr/companies/airbus-1/jobs/engineering-data-custodian-f-m_toulouse,Engineering Data Custodian (f/m),AIRBUS,"{via,GO}",T√©l√©travail ponctuel autoris√©,Toulouse,"Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-03-26,"Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world‚Äôs leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. About us Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world‚Äôs leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. Job description Airbus Commercial Aircraft is looking for an **Engineering Data Custodian (f/m) to join our Architecture and Integration department based in ** Toulouse, France. ** You will be part of a team developing processes and methodologies for the Systems engineering domain. As part of the Systems Engineering Office team, you will support the Systems Engineering process, culture, competency and discipline, on day-to-day business activities, enabled by adequate Methods & Tools (M&T) products and services. This support spans all aspects of the Systems life cycle. Your working environment: Global capital of aeronautics and European capital for space research, Toulouse is a dynamic city in the southwest of France served by an international airport. Ideally located between the Mediterranean sea and the Atlantic ocean and close to the Pyrenees mountains, it offers plenty of options for outdoor activities! How we care for you: **Financial rewards: **Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis. **Work / Life Balance: **Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services. **Wellbeing / Health: **Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application. Individual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking. Your challenges: Contribute to the engineering global picture in data/digital asset development and in the equipped framework blueprint. Under engineering common blueprint constraints, develop, execute, and supervise plans, policies, programs and practices that deliver, control, protect, and enhance the value of data and information assets throughout their life cycles. Improve existing, or implement new, processes/methodologies to support the business needs and the current challenges. Support team to help them adopt change. As part of the assessment board of the data/digital asset development quality package, provide the GO/NOGO of the data/digital asset deployment and commissioning based on Accountable for the well application and respect of data management frameworks used in data/digital asset development. Your boarding pass: Min 5 years of professional experience in an engineering business, ideally in aeronautics Strong process-minded approach. Prior experience in Functional Data of business processes and related processes. Good understanding of Data Architecture, Data Design and Modelling, Data Intelligence, Science and Analysis Ability to understand business needs and challenges in order to convey them via processes/methodologie. Leadership skills to carry change and to ensure adhesion or team members. Ideally a prior experience in change management. Comfortable working within an unclear/unidentified workframe Good communication skills, including strong competence in English language Many of our staff work flexibly in many different ways, including part-time. Please talk to us about the flexibility you need during the interview and we‚Äôll always do our best to accommodate your request. Salary range: Salary range based on the required profile: 55,000 to 65,000 ‚Ç¨/year (including a variable part based on your performance). Information provided as an indication. Not a 100% match? No worries! Airbus supports your personal growth with customized development solutions. Take your career to a new level and apply online now! #LI-AS1 This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company‚Äôs success, reputation and sustainable growth By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus. Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.","Airbus is seeking an Engineering Data Custodian to join their Architecture and Integration department in Toulouse, France. The role involves supporting the Systems Engineering process and improving processes and methodologies for the Systems engineering domain. The ideal candidate should have experience in engineering, strong process-minded approach, and leadership skills. Airbus offers financial rewards, work/life balance, wellbeing/health benefits, individual development opportunities, and flexible working arrangements. The salary range for the position is ‚Ç¨55,000 to ‚Ç¨65,000 per year. Airbus is committed to achieving workforce diversity and an inclusive working environment.",Bac +5 / Master,> 2000 salari√©s,> 4 ans,1,1,0.027697749441558416
434,49780,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",T√©l√©travail partiel possible,"Courbevoie, 92014",Energie,CDI,2023-02-07,"Enedis est une entreprise de service public, gestionnaire du r√©seau de distribution d'√©lectricit√©. Elle d√©veloppe, exploite, modernise le r√©seau √©lectrique et g√®re les donn√©es associ√©es. Elle facilite la transition √©nerg√©tique des territoires en les accompagnant dans le d√©veloppement et la planification de leur production d'√©lectricit√© d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le d√©pannage 24h/24, le relev√© des compteurs et toutes les interventions techniques. Ind√©pendante, Enedis d√©livre la m√™me qualit√© de service aux fournisseurs d'√©nergie. Comme le pr√©voit la loi, elle a √©tabli un code de bonne conduite auquel ses collaborateurs sont form√©s afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des m√©tiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilit√© du Syst√®me d'information dans un contexte de forte num√©risation des m√©tiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engag√©e notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Syst√®me d'Information √† la transformation num√©rique ou dans le positionnement d'Enedis comme op√©rateur de donn√©es, la DSI met en oeuvre de nombreux projets majeurs en lien avec les m√©tiers concern√©s. Chez Enedis comme chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez Enedis m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Un des enjeux majeurs d'Enedis est de devenir un op√©rateur de confiance de Donn√©es √©nerg√©tiques. Afin de r√©pondre √† cet enjeu, Enedis a mis en place une plateforme de donn√©es pour l'entreprise. Cette plateforme est compos√©e d'une infrastructure de donn√©es centralis√©e construite sur Hadoop et d'outils √† destination des √©quipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'am√©liorer cette plateforme sur plusieurs axes : migration vers le cloud, √©volution de l'architecture avec en cible une plateforme modulaire composant des services manag√©s, automatisation et mont√©e en gamme de l'offre de services internes permettant aux √©quipes de gagner en autonomie dans la cr√©ation de v√©ritables produits de donn√©es. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des √©quipes du train SAFe DataServices4U - √©quipe SPHINX, en charge de l'infrastructure data des activit√©s exploratoires (big data, big mem, GPU) - d√©finira, d√©veloppera, mettra en place et maintiendra les outils et infrastructures ad√©quats aux op√©rations du reste du train (√©quipes data scientists et data engineers). - veillera √† garantir les op√©rations des solutions permettant le traitement de volumes importants de donn√©es tout en garantissant la s√©curit√© de celles-ci - d√©finira les enablers √† prendre en compte dans l'√©quipe - sera Tech. Lead d'une √©quipe d'une dizaine de personnes - testera les r√©alisations de l'√©quipe - contribuera aux d√©monstrations faites aux √©quipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous √™tes issu d'une formation de type Bac +5 dans le domaine de l'IT / syst√®me d'information / Num√©rique et DATA - Vous disposez d'une exp√©rience d'au moins 4 ans dans des activit√©s √©quivalentes, au cours desquelles vous avec avez d√©velopp√© de solides comp√©tences techniques - Vous avez un profil Ing√©nieur Big Data disposant de comp√©tences d'analyse, de synth√®se, de cr√©ativit√© et d'une app√©tence pour l'innovation. - Vous avez de bonnes connaissances de l'administration syst√®me UNIX : ma√Ætrise de Linux (Redhat), Bash - ainsi que composants s√©curit√© et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacit√©s de communication (orales et √©crites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacit√©s de coordination - Vous faites preuve de curiosit√©, d'esprit de synth√®se, de m√©thodologie et de rigueur dans un environnement complexe Le poste est situ√© √† Courbevoie, avec une possibilit√© de t√©l√©travail partiel. La r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0","Enedis is seeking a System Team Engineer DataOps with a Bachelor's in IT, digital and data, and a minimum of four years related experience. The successful candidate will be responsible for the technical leadership of an Enedis team in charge of the infrastructure data of exploratory activities, developing and maintaining appropriate tools and infrastructures, ensuring data security, testing team achievements, and working with an agile team of over 10 other tech leaders. The position is based in Courbevoie and offers the possibility of partial remote work.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
245,56949,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-f-h_nanterre_AXA_V4Ra50p,Data Engineer,AXA,"{Microsoft,Databricks,Git,PowerBI,Spark,Azure,NoSQL,Python}",T√©l√©travail partiel possible,"313 Terrasses de l'Arche , Nanterre, 92727","Banque, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l‚Äôassurance et de la gestion d‚Äôactifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous prot√©ger en donnant √† chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! Le D√©veloppeur Big Data contribue directement aux projets des directions m√©tier d‚ÄôAXA France (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) & √† la construction du socle technique Big Data. Il a pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment : a. Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requetables dans le datalake (inf√©rer les sch√©mas de donn√©es, nettoyer et normaliser les donn√©es, publier les donn√©es)b. Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lakec. Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)d. De travailler √† la cr√©ation du socle technique Big Data (librairies de fonctions, features commun√©ment utilis√©es avec les data scientists‚Ä¶) et industrialiser le cycle de d√©veloppement de l'√©quipee. De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)f. D‚Äôaccompagner les d√©veloppeurs plus juniors de l‚Äô√©quipe (coaching, code review, pair programming‚Ä¶) De Formation scientifique (√©cole d‚Äôing√©nieur, √©cole d‚Äôinformatique), vous justifiez de: - Au moins 3 ans d‚Äôexp√©rience professionnelle tous langages confondus - Au moins 1 an d‚Äôexp√©rience professionnelle en d√©veloppement Big Data avec PySpark (Spark en Python) Dans l‚Äôid√©al vous avez eu une exp√©rience professionnelle sur le cloud Microsoft Azure avec des outils comme Azure Databricks Azure Data Lake Storage et Azure Data Factory. Vous avez l'habitude des cycles de d√©veloppements courts en mode Agile ainsi que des outils associ√©s: - Gestion de sources Git sur Azure DevOps - Int√©gration & d√©ploiement continue avec Azure Pipelines - Gestion des artefacts avec Azure Artifact Ces connaissances suppl√©mentaires seraient un plus : - Cloud Microsoft Azure - Traitements Big Data en mode Streaming - Bases de donn√©es relationnelles et NoSQL - Outils de BI (PowerBI, Spotfire) De nature pragmatique, vous √™tes capable de travailler en autonomie pour livrer du code de qualit√© satisfaisant des besoins m√©tiers. Vous avez de bonnes aptitudes relationnelles, et vous faites preuve d‚Äôune grande curiosit√© et de capacit√© d‚Äôinnovation et d'adaptation.","AXA is looking for a Big Data Developer to work on projects requested by AXA France business units and to contribute to the construction of their Big Data technical base. The developer will be responsible for developing Big Data projects, consolidating data, analyzing data, creating technical tools and functions, providing coaching and support to junior developers, and ensuring quality throughout the development cycle. The ideal candidate should have at least 3 years of professional experience, 1 year¬†of experience in Big Data development using PySpark, and knowledge of Azure cloud and associated tools, Git, Azure Pipelines, Azure Artifact, and BI tools. Good communication and innovation skills, pragmatic work style and¬†ability to work autonomously are essential.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
37,60592,https://www.welcometothejungle.com/fr/companies/extracadabra/jobs/data-engineer-f-h_paris_EXTRA_7lP8NMM,Data Engineer,Extracadabra,"{PowerBI,Redash,SQL,Zeppelin,Tableau}",T√©l√©travail partiel possible,"82, rue d'Hauteville, Paris, 75010 ","Application mobile, FoodTech",CDI,2023-03-28,"Extracadabra c‚Äôest une mission : simplifier l‚Äôemploi dans le domaine de l‚Äôh√¥tellerie-restauration, du retail et de la logistique. Cr√©√© en 2015 par Fr√©d√©ric Nardon et R√©mi Boisson Extracadabra est l‚Äôapp qui met en relation des candidats Extra ou CDI avec des √©tablissements gr√¢ce √† un syst√®me de matching hors du commun avec son √©quipe de maintenant 40 personnes. Elle a notamment √©t√© √©lue meilleure plateforme sp√©cialis√©e en h√¥tellerie-Restauration dans le palmar√®s 2021 des plateformes de travail r√©alis√©e par Mounir Mahjoubi, d√©put√© et ex-Secr√©taire d‚Äô√âtat au Num√©rique. Extracadabra a lev√© pr√®s de 3 Millions ‚Ç¨ aupr√®s de BPI Tourisme, Side Capital, Sowefund et des fondateurs de La Fourchette et Doctolib et compte bien consolider sa position de leader dans le secteur de l‚Äôh√¥tellerie-restauration. Bien plus qu‚Äôune application ou un site c‚Äôest une relation privil√©gi√©e avec 10 000 √©tablissements partenaires en France ( Big Mamma Group, Anne Sophie Pic, Le Perchoir, Potel & Chabot, Ducasse, Paris Society, Echo, Cali Sisters ‚Ä¶) et une communaut√© de 150 000 candidats. Depuis 2019, Extracadabra s‚Äô√©tend sur de nouvelles verticales (vente et logistique) avec des clients comme Bergamotte, Caba√Øa, Maison Landemaine, Selency, Pierre Herm√©, Moncler‚Ä¶ Nos Valeurs qui allient perfomance et valeurs humaines fortes dans un contexte o√π nous avons un impact fort sur la soci√©t√© sur un sujet central, l‚Äôemploi pour tous : CCLAP ! Confiance Cr√©ativit√© Lien Ambition Performance Au sein de l‚Äô√©quipe tech et produit, tu as un r√¥le cl√© dans la valorisation et le partage de la donn√©e business et produit en interne. En effet, Extracadabra cherche un profil confirm√© Data Engineer pour piloter l‚Äô√©vang√©lisation de la data. Tu devras consolider la data en faisant √©voluer le datawarehouse actuel, avant de construire des reports avec les outils de visualisation (PowerBI, Redash, Zeppelin). Tu encadreras 1 alternant et 1 stagiaire pour t‚Äôaccompagner dans la mise en place de solutions p√©rennes. Tes missions Participer √† la prise en compte des besoins internes en mati√®re de Data (√©quipes business et produit) Analyser l‚Äôarchitecture et les flux de data existants Participer au renforcement du datawarehouse existant pour le rendre plus scalable Construire des reports pour placer la data au c≈ìur de la strat√©gie des diff√©rentes √©quipes de l‚Äôentreprise Construire des pipelines de data pour notamment alimenter des outils business comme Salesforce Partager les pr√©requis data aux √©quipes de dev pour les features √† venir Ton profil Tu as une exp√©rience d‚Äôau moins 2 ans dans une entreprise o√π la data est cl√© dans sa strat√©gie et dans le quotidien des √©quipes. Tu poss√®des des connaissances techniques pour manipuler des donn√©es (ETL). Le langage SQL n‚Äôa pas de secret pour toi. Tu ma√Ætrises un outil de Data Visualisation (PowerBI, Tableau). Tu as une bonne capacit√© d‚Äôanalyse, de synth√®se et de priorisation. Tu es curieux(se) et force de proposition. Tu es d√©brouillard(e) et aime relever des d√©fis en dehors de ta zone de confort. Entretien avec la RH Entretien + Test technique (Echange avec un membre de l‚Äô√©quipe) Entretien co fondateur","Extracadabra is seeking an experienced Data Engineer to evangelize data within the company's tech and product team. The selected candidate will consolidate the data by evolving the existing data warehouse and creating reports using visualizing tools, manage data pipelines to feed business tools such as Salesforce, and share data requisites with dev teams for upcoming features. The ideal candidate should have a minimum of 2 years of experience, knowledge of technical data manipulation, SQL proficiency, proficiency in data visualization tools, good analytical and prioritization skills, and be curious and solution-oriented.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
429,44506,https://www.welcometothejungle.com/fr/companies/gorgias/jobs/data-analytics-engineer_paris,Data & Analytics Engineer,Gorgias,"{Datafold,go,python,Go,color,Airbyte,GitLab,DBT,GitHub,Fivetran,AWS,dbt,Hightouch,scale,Metaplane,BigQuery,GCP,SQL}",T√©l√©travail partiel possible,"Paris, 75001",SaaS / Cloud Services,CDI,2023-02-01,"Meet Gorgias, the customer service platform that‚Äôs designed for eCommerce merchants, and built to provide an amazing experience to shoppers. Our product empowers merchants to manage all their customer service in one place support over email, live chat, voice, Facebook, Instagram, Twitter, and SMS in one feed to help our merchants provide exceptional customer experiences at scale on Shopify, BigCommerce, and Magento. Everything we do is for our customers, and we‚Äôre currently serving over 10,000+ e-commerce merchants, including Steve Madden (linked case study), Timbuk2, Decathlon, and Sports Illustrated. They love us for our innovative product, our focus on their eCommerce needs, and, of course, our lightning-fast customer service response times. We raised a total of including x this year our $25 million Series B round in December 2020 and our $30 million Series C round this year. In between, share growth we more than doubled in size in every meaningful way: annual recurring revenue, the size of our customer base, and the size of our Gorgias team, for starters. We‚Äôre still growing fast and looking for new teammates who want to grow with us. Join our team for the opportunity to: üë©üèº‚ÄçüíªWork with smart, passionate people every day üí™ Get extreme ownership over your work and results üß† Be treated like the expert you are About the Growth Operations team Growth Ops is a cross-functional team that works hand-in-hand with all of the other Growth teams (Go-to-market Marketing, Sales, Success & Support, and Product) and also interacts with the dev teams. Our core role is to ensure that data flows accurately and efficiently across all of these teams and the tools they use to maintain and improve our data stack. In addition to this, we build complex data models and perform data analysis to provide insights. The Growth Ops team is also in charge of building data products that maximize each team‚Äôs efficiency: lead qualification models, optimizing deal routing, predicting churn, automated lead enrichment & prospecting, etc. The team itself is composed of three main squads: Business Intelligence , split into 2 squads, Go-to-market & Customer Operations, these teams help the rest of the company by providing insights on performance and by giving them the resources needed to achieve their goals. This includes things like providing or editing data marts, helping build dashboards, automating processes, researching new tools, and more. Core Ops is responsible for the management and maintenance of the Data Platform, including all data pipelines and assets. Their primary goal is to ensure that accurate and easily accessible data is provided at scale to end users. They also play a key role in advising and training Ops Analysts on analytics engineering best practices and maintaining up-to-date documentation and knowledge sharing. If you are naturally data curious, excited by data stack architecture, experienced in improving the availability and usability of datasets, and motivated by having an impact on the business where you work, we want to hear from you. What You‚Äôll Do We are looking for a Data & Analytics Engineer who is passionate about applying their analytical and engineering skills to democratize data, metrics, and insights to drive decision-making and analytics across Gorgias. You will join our Core Ops section and will be integral to building out our world-class data platform and enabling all teams across the company to move faster and smarter. You will work on the analytics infrastructure end-to-end - from data ingestion to reporting - ensuring high data quality, availability, and performance to support Data/Ops Analysts. Build and maintain efficient and scalable data pipelines, leveraging ETL tools and protocols. Full-stack analytics engineering development, designing, implementing, and documenting data models that deliver clean, well-structured data for visualization, exploration, and activation. Develop and maintain reliable cloud-based applications to automate processes for our teams and unlock their full potential. Help the team to maintain an overall position of strong data governance with great data observability (data monitoring & alerting, CI/CD pipelines). Develop and maintain documentation that increases the understanding and utilization of our data assets. Develop and communicate strong opinions about best practices in Analytics Engineering. As a member of the Core Ops team, you will also promote strong standards throughout the organization and help level-up team members through the adoption of software engineering best practices (testing, version control, documentation, etc). Who You Are You have 3+ years of hands-on experience as an analytics engineer, data engineer, or equivalent. 3+ years of experience in data modeling and data warehouse architecture, with solid SQL experience. You care about writing good and clean SQL, with an emphasis on readability and performance. 2+ years of experience with a general-purpose programming language (preferably python), including testing, deployment, and codebase refactoring. 2+ years of experience with the modern data stack (Segment / ETL / Warehouse / dbt / BI / Activation tool), creating data products within a data warehouse environment to meet business goals. You have experience working in a cloud-based environment (GCP or AWS), managing and monitoring resources. You have strong knowledge of software development best practices applied to data and analytics (DataOps), primarily related to version control, CI/CD, automation, and testing. You have a natural fit for both technical and business challenges. We are building technical solutions to solve business-oriented challenges, so strong business acumen is needed for the role. You are always learning and staying informed about new tools and practices. At the speed at which the ecosystem is evolving, it is essential to stay on top of things and always look for new ways to improve our work. You love working with a wide range of data sources and stakeholders from operational and product teams. You pay attention to detail, with strong organization and prioritization skills, comfortable switching gears and moving between projects seamlessly. Our current data analytics stack mainly includes: Data ingestion: Airbyte, Segment, Fivetran Storage: BigQuery Transformation: DBT BI tools: Periscope, push.ai Data Activation: Hightouch, Segment, Airplane Data Monitoring: Datafold, Metaplane GCP products (Compute Engine, Cloud Functions, Cloud Run, PubSub ‚Ä¶) CI/CD: GitHub Action & GitLab Project management: Linear, Notion Perks and Benefits üèñ 5 weeks of vacation üçºPaid parental leave üíªLatest MacBook Pro or equivalent üöä50% of public transportation reimbursed (V√©lib, Navigo, etc.) üçΩÔ∏è Personal credit card to buy lunches (we use Swile ) üè• We provide private health insurance (we use Alan ) üíÜüèª‚Äç‚ôÄÔ∏è Get up to $700 to set up your workstation at home (working from home should feel breezy) ü•∞ Every quarter, we organize an online company-wide summit to discuss where we‚Äôre going and strengthen social bonds. Once per year we organize offsite team retreats and company retreats! ( Here is the photo album from our last company retreat in Mexico in 2022, when we were a total of 200 people!) The position‚Äôs Interviewing Process Initial call with a recruiter that will present Gorgias, the team, and the position in more detail - ask all the questions you need Meet your manager, Elliot, Data Analytics Manager: get to know each other and set yourself up for success in this process Do a take-home case study where we don‚Äôt ask you to solve our problems, but we look for your creative insights. It‚Äôs the perfect time to show off what you know Case study review with Elliot, brainstorm and elaborate on key points Meet Axelle, Head of Growth at Gorgias. This is a good time to ask difficult questions and see if we are a good match for you! Why join us? üöÄ We‚Äôre among the fastest-growing startups in the eCommerce ecosystem ü¶Ñ We‚Äôve built an extremely efficient go-to-market engine ü•á Work with a talented team you‚Äôll learn a lot from üôè Join a company where automation and good & clean data are core beliefs shared by all üé• Here is an interview with one of our team member‚Äôs experiences from our most recent company retreat to Cancun! More cool things to know about Gorgias‚Ä¶ üòÅ Raised our Series C for $30M in 2022: TechCrunch Article ‚¨ÖÔ∏è We went from 0 to 10,000+ merchants using our platform since 2016 We have a 4.7 rating on Glassdoor & 4.7 Comparably culture score What our customers are saying: apps.shopify.com/helpdesk#reviews Other positions: gorgias.com/about-us/jobs Discover the Gorgias Platform‚Äù HERE Learn about our Compensation Policy: HERE Gorgias ensures equal employment opportunity without discrimination or harassment based on race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, veteran status, or any other characteristic protected by law.","Gorgias is seeking a Data and Analytics Engineer to join their Core Ops team. The successful candidate will have experience in data modeling, data warehouse architecture, general-purpose programming languages, and cloud-based environments. They will build and maintain data pipelines, design data models, and develop cloud-based applications. Additionally, they will maintain documentation and ensure data governance and strong data observability. The position offers benefits such as parental leave, private health insurance, and equipment reimbursement.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
428,44176,https://www.welcometothejungle.com/fr/companies/pretto/jobs/data-engineer_paris_PRETT_mg9OP0Y,Data Engineer,Pretto,"{python,Airflow,scale,via,R,BigQuery,SQL}",T√©l√©travail partiel possible,"42, Rue de Paradis, Paris, 75010","FinTech / InsurTech, Immobilier particulier",CDI,2023-02-01,"Qui sommes-nous chez Pretto ? L‚Äôachat immobilier est l‚Äôun des moments les plus importants d‚Äôune vie. Mais c‚Äôest aussi une √©tape stressante et complexe, surtout quand il s‚Äôagit de trouver le pr√™t immobilier qui valide son projet. Pretto, c‚Äôest la fintech qui rend simple, efficace et √©quitable la recherche de cr√©dit immobilier. Notre secret sauce ? Le meilleur simulateur du march√© qui permet de savoir en 3 min si on peut acheter, combien et √† quel taux, Un expert d√©di√© qui accompagne des premi√®res recherches de bien jusqu‚Äô√† la signature et n√©gocie pour ses clients aupr√®s des banques, Une UX aux petits oignons pour supprimer la paperasse et suivre son projet depuis son canap√©. Le r√©sultat : des acheteurs qui obtiennent facilement leur pr√™t et d√©couvrent la joie d‚Äô√™tre propri√©taire. Et √ßa, √ßa n‚Äôa pas de prix ! Depuis 2017, Pretto c‚Äôest 150 000 clients conseill√©s, 1 Milliard ‚Ç¨ de pr√™t financ√©s par an, une note de 4,8/5 sur Trustpilot, 220 collaborateurs entre Paris et Nantes, une r√©cente s√©rie B de 30 Millions d‚Äô‚Ç¨‚Ä¶ et ce n‚Äôest que le d√©but ! 3 raisons de nous rejoindre ? on a un vrai impact sur la vie de nos clients, c‚Äôest pourquoi on met toute notre √©nergie et notre exigence pour proposer la meilleure exp√©rience √† tous les niveaux nos √©quipes sont engag√©es et aux profils tr√®s vari√©s, on cultive la collaboration dans une atmosph√®re bienveillante et positive on aide chacun √† bien grandir avec des rituels de feedback ainsi qu‚Äôune formation continue via la Pretto Academy, notre super √©cole de vente. Pour aller plus loin, on vous pr√©sente sur notre site Inside Pretto tout ce qu‚Äôil faut savoir sur Pretto, ce qu‚Äôon y fait, pourquoi, comment on y travaille, grandit‚Ä¶ et s‚Äô√©panouit ! üéØ Nous rejoindre en tant que Data Engineer chez Pretto Chez Pretto, la data est au c≈ìur de notre strat√©gie. Nous sommes en train de changer le march√© de l'immobilier en apportant de la transparence et de la pr√©visibilit√© gr√¢ce aux donn√©es que nous collectons et analysons. Nous avons d√©cid√© tr√®s t√¥t d'investir sur la construction d'une stack data afin de centraliser dans une warehouse la source de v√©rit√© sur toutes nos m√©triques, et de construire les outils de pilotage et de mesure des diff√©rents p√¥les sur cette source de v√©rit√©. Cette data nous permet de suivre nos KPI business, d'am√©liorer en continu notre produit, mais √©galement de travailler sur des projets long terme, par exemple : - suivre et anticiper les √©volutions de taux - cat√©goriser nos utilisateurs pour nous adapter √† leurs besoins - scorer de mani√®re plus fine et efficace la finan√ßabilit√© de nos utilisateurs C'est dans ce cadre que nous cherchons un‚Ä¢e data engineer qui prendra la responsabilit√© de la partie infra de notre stack data. üåü Tes missions Ta mission est donc de scale up l'infrastructure data d'une plateforme amen√©e √† accompagner des centaines de milliers de projets immobiliers complexes et riches en donn√©es et √©v√®nements. Pour cela, tu devras : - Prendre le lead sur notre infrastructure de collecte de donn√©es. - Mettre en place et maintenir la collecte depuis tous nos sources : CRM / Bases de donn√©es / Tracking utilisateur / Outils tiers - Faire scaler notre infrastructure afin que les flux de donn√©es puissent y transiter en temps r√©el - En collaboration avec nos data scientists, mettre en place une infrastructure leur permettant de d√©ployer en production leur travail d'analyse de donn√©e - En collaboration avec nos ing√©nieurs R&D, augmenter notre flux de donn√©es brutes de signaux de scoring - Optimiser l'utilisation et la structuration de notre data warehouse BigQuery - En collaboration avec les directeurs des diff√©rents p√¥les de Pretto, mettre en place une infrastructure leur permettant d'acc√©der et d'utiliser au quotidien des datamarts m√©tier (dashboards, synchronisations avec outils d'analyse de donn√©e, alerting, ...) üë´ Ton profil - Dipl√¥m√©‚Ä¢e d'une √©cole d'ing√©nieur, avec au moins 3 ans d'exp√©rience de d√©veloppement, dont une sur des sujets de data engineering. - Connaissance solide des bases de donn√©es relationnelles, et ma√Ætrise du langage SQL. - Bonnes pratiques de d√©veloppement en √©quipe : versioning, code review, int√©gration continue, tests automatis√©s ... - Niveau solide en d√©veloppement python dans un contexte d'ETL - Bonus : exp√©rience avec Apache Airflow - Bonus : exp√©rience avec la stack Google Cloud üî• Rejoins la team Tech parce que : - On t‚Äôoffre un accompagnement en interne avec les meilleurs standards (formation coaching, culture de l‚Äôentraide et transmission de bonnes pratiques) - On te propose un plan de carri√®re qui te permettra de grandir chez nous - La culture du feedback : chez Pretto tout le monde a droit de donner son avis et proposer des solutions, c'est m√™me recommand√© ! üéÅ Les avantages √† travailler chez Pretto üí∞ Un package salarial avantageux : carte ticket restaurant Swile, mutuelle prise en charge √† 50% et remboursement de la moiti√© de ton abonnement de transport en commun üåü Des primes attractives : vacances, cooptation pouvant aller jusqu'√† 2000‚Ç¨, int√©ressement, naissance üè° Une charte de t√©l√©travail te permettant de t√©l√©travailler 3 jours par semaine, avec une indemnit√© de 2‚Ç¨ par jour üçª Des moments partag√©s entre coll√®gues : onboarding avec ta promo, rituels d‚Äô√©quipe, s√©ances de sport, tournois de Smash Bros, organisation de Happylunch, offsite üßë‚Äçü§ù‚Äçüßë Un parrain ou marraine r√©f√©rent(e) pour te permettre de t‚Äôint√©grer et de t‚Äô√©panouir chez Pretto","Pretto, a real estate fintech, is seeking a data engineer to lead the infrastructure of their data stack. The ideal candidate should have at least three years of experience in data engineering, strong knowledge of SQL and Python, and experience with Apache Airflow and the Google Cloud stack. The successful candidate will be responsible for managing data collection, maintaining data sources, optimizing data warehouses, and collaborating with data scientists and R&D engineers to develop data analysis tools. Pretto offers attractive compensation packages, career growth opportunities, and a telecommuting policy.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
209,56988,https://www.welcometothejungle.com/fr/companies/beamy/jobs/data-engineer_paris,Data Engineer,Beamy,"{airbyte,precisely,airflow,Airbyte,Airflow,Looker,grid,AWS,Snowflake,dbt,Airtable,scale,BigQuery,GCP,SQL,Python}",T√©l√©travail partiel possible,"6, Rue Auber, Paris, 75009","Intelligence artificielle / Machine Learning, SaaS / Cloud Services",CDI,2023-03-26,"SaaS apps are now everywhere to make our working life easier. Who hasn‚Äôt used Notion, Airtable, Atlassian, Adobe or Zoom at least once? Easily accessible, innovative and less expensive, this massive and widespread use is part of an underlying trend that is accelerating continuously. It offers employees new ways of working. This is what we call Business Led-IT. Beamy centralises SaaS knowledge on a single platform to master usage, optimise contracts and mitigate associated risks. Beamy helps to build an effective SaaS governance between all key stakeholders (Business Units, CIOs, CISOs, DPOs etc.) by using powerful automated workflows. In this way, Beamy re-establishes communication between the business teams (Marketing, HR, Finance, etc.) and the IT department. The entire company can then orchestrate their digitalisation through a single platform in a secured, compliant and transparent way. The successful use of Beamy by our customers is based on data. Without the Data Team, it would be impossible to fulfil Beamy's first promise : Shadow IT detection. For 2023 we have decided to reinforce this stream and grow our Data team. We are looking for Data Engineers. We need to build the best and most scalable infrastructure that will allow us to collect, store and transform our client's data. Your responsibilities : - Take part of the definition of the architecture and data flows between different data sources - Design, implement, test, deploy and maintain data pipelines - Be responsible for the monitoring and the data consistency throughout the data cycle - Create and maintain integrations with partner applications - Ensure that our data practices are always in line with the best trends of the industry - Actively share knowledge and document insights to support continuous team improvement and collaboration Stack : GCP, Airbyte, Airflow, ETL, BigQuery/Snowflake, Looker, PySpark‚Ä¶ What we offer: - 50K to 65K + stock options üí∞(Our salary grid focuses on two variables : your level of impact in the organisation and your job expertise observed during our interviews)(We frequently Benchmark with Radford ) - A strong transparency culture (salaries and financial situation of the company shared internally, transparent career tracks...) coupled to an excellent and healthy atmosphere (no micromanagement, strong autonomy...) - Office in the heart of Paris, at Opera, (9th district) - A key position in our organisation and the opportunity to be a fundamental player in Beamy's acceleration and international scale - The best health mutual and lunch vouchers available (Alan & Swile), 5 weeks of holidays + RTT About you: As we're growing fast, new challenges arise, requiring creativity and a willingness to take responsibility. - You have at least 3 years of experience as a Data Engineer - You have a strong knowledge of programming languages: Python and PySpark, SQL - You have a strong knowledge of cloud architecture: GCP or AWS - You have already managed a stack with modern data engineering tools (airbyte, airflow, dbt, BigQuery/Snowflake, Looker, ‚Ä¶) - You can communicate clearly in both written and oral form in English and French - You have interest in understanding and solving Business data challenges Application & Hiring process: We are looking for an overview of your background (either a resume or a Linkedin profile) and a short note to tell us why we're a great fit for each other and how you envision your future @Beamy We'll review your application and we'll get back to you within a week. Be sure you will hear from us üôÉ Our hiring process for this role: - A 30min Introduction call with Leslye - Senior Talent Acquisition Specialist to make sure our expectations are aligned. - A 30min video call with Tahir - CTO to deep dive into the role and to check that your skillset and mindset fit for the job. - A Case study - 1h of Who Interview with the HR team, to make sure we're a great fit in terms of culture - On-site session to get a feel of the work atmosphere during a lunch + reference check Research shows that while men apply to jobs where they meet an average of 60% of the criteria, women and other underrepresented groups tend to only apply when they meet 100% of the qualifications. At Beamy, we value respectful debate and people who aren't afraid to challenge assumptions, so we are looking for diverse perspectives as long as you meet our minimum criteria. You are encouraged to apply even if your experience doesn't precisely match the job description!","Beamy is seeking a Data Engineer to reinforce its data team in Paris. Candidates must have at least three years of experience in data engineering, strong knowledge of programming languages, cloud architecture, and modern data engineering tools. The role involves designing, implementing, testing, deploying, and maintaining data pipelines, among other responsibilities. Beamy offers a salary of ‚Ç¨50k-‚Ç¨65k, stock options, a healthy working environment, and an opportunity to be a fundamental player in the company's acceleration and international scale. Women and underrepresented groups are encouraged to apply.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
43,56861,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-cdi-f-h_grenoble,Data Engineer (Confirm√©) - CDI -,Atos,"{Cassandra,Hive,Docker,Azure,Microsoft,MongoDB,Beam,Logstash,Kafka,NoSQL,SnowFlake,ElasticSearch,Kubernetes,AWS,Teradata,Java,CouchBase,Hadoop,Redis,Redshift,Kibana,HDFS,Spark,BigQuery,Python}",T√©l√©travail partiel possible,"28 Rue Gustave Eiffel, Grenoble, 38000",IT / Digital,CDI,2023-03-26,"Bienvenue chez Atos, o√π nous imaginons le futur de la tech. Leader international du num√©rique s√©curis√© et d√©carbon√©, Atos contribue √† fa√ßonner les nouvelles technologies avec ses clients. Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carri√®re valorisants bas√©s sur des programmes de formation, de certification et de mobilit√©. C‚Äôest pourquoi chez Atos, la diversit√© des comp√©tences et des exp√©riences de nos √©quipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l‚Äôavenir de notre entreprise et de la soci√©t√©. LA MISSION QUE L‚ÄôON VOUS CONFIE : Au sein d'√©quipes dynamiques, vous aurez pour missions principales : Conseiller en architecture en gouvernance de la donn√©e. Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA. Mettre en place, int√©grer, d√©velopper et optimiser des solutions de pipeline sur des environnements Cloud pour les projets strat√©giques de nos clients. VOTRE PROFIL POUR REUSSIR : De formation sup√©rieure BAC +5 en Informatique d`une Ecole d‚ÄôIng√©nieur ou d‚Äôun Mast√®re universitaire dans le domaine des sciences informatiques que vous avez compl√©t√© par une exp√©rience significative en Data Science / Data Engineering. Votre stack technique : Requis : Connaissance des √©cosyst√®mes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS ‚Ä¶ ; Expertise en d√©veloppement Python ou Java Spring Boot ; Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam‚Ä¶ ; Connaissance des architectures conteneurs : Docker, Kubernetes. Appr√©ci√© : Connaissance d‚Äôun des services manag√©s BigData de Google Cloud Platform / AWS / Microsoft Azure ; Connaissance des approches Agile & DevOps. Soft skills : Passionn√©(e) d‚Äôinformatique en progressant et en vous tenant √† jour sur toutes les technologies et architectures, vous √™tes cr√©atif(ve), autonome, rigoureux(se), curieux(se), motiv√©(e) et avez le sens du travail en √©quipe et du relationnel alors rejoignez-nous ! Niveau de langue : Anglais : niveau interm√©diaire minimum recommand√© et Fran√ßais exig√©. Description du profil : POUR VOUS CONVAINCRE DE NOUS REJOINDRE : Travailler √† Grenoble dans une ambiance et cadre de travail agr√©able avec nos clients en direct . Un accompagnement personnalis√© avec mont√©e en comp√©tences, formation et √©volution sur des projets long terme. Un employeur attentif √† votre √©panouissement avec des possibilit√©s de t√©l√©travail pouvant aller jusqu‚Äô√† 50% du temps Un package d‚Äôavantages avec r√©gime de sant√© tr√®s favorable, RTT disponibles d√®s votre arriv√©e et un CE tr√®s dynamique, remboursement des d√©placements en transport en commun. NOTRE PROCESSUS DE RECRUTEMENT : Prise de contact avec un recruteur pour une pr√©qualification Evaluation technique en fonction du profil Entretien avec nos ing√©nieurs commerciaux / managers Vous voulez en d√©couvrir plus ? N‚Äôh√©sitez plus et postulez d√®s √† pr√©sent ! #TheFutureIsOurChoice","Atos is seeking a Data Engineer/Architect with experience in data governance, data ingestion, analytics, and data science/AI, and knowledge of various ecosystems and frameworks such as ELK, Spark, and Docker. The successful candidate should have a BAC+5 in Computer Science and significant experience in data engineering/science. They should be passionate, creative, curious, motivated, and a team player with good communication skills. The position offers personalized skills development, telecommuting up to 50% of the time, a comprehensive benefits package, and a dynamic work environment. Fluency in English (intermediate) and French (required) is necessary.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
53,73310,https://www.welcometothejungle.com/fr/companies/sicara/jobs/lead-data-software-engineer-cdi-paris_paris,Lead Data Software Engineer - CDI - Paris,Sicara,"{Hadoop,Spark,Python,Airflow}",T√©l√©travail ponctuel autoris√©,"48 Boulevard des Batignolles, Paris, 75017","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-04-22,"Sicara est une startup experte en data, bas√©e √† Paris : nous r√©volutionnons les projets data en combinant notre savoir-faire dans l‚Äôagilit√©, la data science et le data engineering afin d‚Äôacc√©l√©rer la transformation digitale de nos clients. Pourquoi on recrute un Lead Data Software Engineer ? Pour continuer √† renforcer les √©quipes Data Software Engineering de Sicara. En tant que Lead Data Engineer , et aupr√®s de tes clients, tu auras pour missions de : Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Leader une √©quipe de 2 √† 5 data software engineers dans le delivery de la solution √† impl√©menter au quotidien Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) D√©finir les m√©thodologies de d√©ploiement et plans de migration Construire et d√©ployer les pipelines de donn√©es (ETL et ELT) Assurer la migration des donn√©es vers les nouveaux environnements Choisir et mettre en oeuvre des outils de data analyse et/ou data visualisation Mettre en place des outils de contr√¥le de la qualit√© de la donn√©e Accompagner et former les √©quipes clients Au sein de Sicara, dans ton r√¥le interne tu pourras : Accompagner et former les √©quipes au data software engineering Assurer une veille technologique continue sur les solutions de l‚Äô√©tat de l‚Äôart Intervenir dans la r√©flexion sur la strat√©gie technique √† proposer en phases d‚Äôavant-vente de nos projets G√©n√©rer de la connaissance technique sur des sujets d‚Äôexpertises , pour les propager au sein de Sicara, et ce gr√¢ce √† l‚Äôencadrement de l‚Äô√©quipe dirigeante En fonction de tes envies et de tes comp√©tences, tu auras la possibilit√© de : Devenir un(e) expert(e) sur les sujets techniques qui te passionnent. Devenir un(e) leader gr√¢ce au d√©veloppement de comp√©tences transverses : coaching, recrutement, commercial, management, marketing, etc. Monter une tribe ou une guilde pour d√©velopper un nouvelle offre et am√©liorer nos pratiques. Tu as entre 2 et 4 ans d‚Äôexp√©rience sur des sujets de Data Software Engineering Tu es dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur en Bac+5 Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data ( Spark, Hadoop, Airflow, Terraform ) Tu souhaites participer √† la conception de produits √† fort impact business Tu recherches √† √™tre accompagn√©(e) par une √©quipe d‚Äôexperts pour exploiter √† fond ton potentiel et r√©aliser ton ambition sur des sujets data qui te passionnent ! 1 entretien RH + 1 test + 1 entretien technique + 2 entretiens dirigeants",,Bac +5 / Master,Entre 15 et 50 salari√©s,> 2 ans,1,1,0.027697749441558416
420,40487,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-banque-f-h_paris,Data Engineer - banque,CGI,"{Couchbase,NoSQL,MapR,Mongo,Nifi,HDFS,HBase,Kafka,Linux,Hive,Spark,Marklogic,YARN,Hadoop,Python,Cloudera}",T√©l√©travail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-01-29,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Principales missions: -Concevoir, d√©velopper et d√©ployer des pipelines de transformations de donn√©es en environnement Big Data -D√©finir des solutions globales permettant de r√©pondre aux besoins m√©tiers en prenant en compte les probl√©matiques de performances, d‚Äôindustrialisation, d‚Äôexploitation et de s√©curit√©. -Param√©trer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, ‚Ä¶) -Faire des prototypes sur des technologies et de la veille technologique sur le Big Data -Accompagner & supporter les √©quipes projet en coaching et expertise -Animer et faire progresser des juniors et stagiaires -Assurer le r√¥le de Lead Tech dans une √©quipe Vous disposez d‚Äôau moins 3 ans d‚Äôexp√©rience sur des fonctions IT de conception / d√©veloppement en environnement Big Data. Vous vous d√©finissez comme un ‚ÄòData Engineer‚Äô capable de faire du d√©veloppement tout en conservant une vue globale du besoin et des finalit√©s de clients. Vous avez acquis les comp√©tences suivantes au cours de votre exp√©rience: -Comp√©tences techniques autour des produits Data / Big Data: o Solution Hadoop (HDFS, YARN, Hive, Hue, Oozie‚Ä¶) et outillage associ√© o Spark, Python o Bases NoSQL (Mongo, HBase, Couchbase, Marklogic‚Ä¶) -Exp√©rience av√©r√©e de d√©veloppements Big Data dans des environnements complexes avec des contraintes techniques identifi√©s (s√©curit√©, performances, fonctionnel complexe‚Ä¶) -Connaissance de la stack standard Linux -Capacit√© √† travailler en √©quipe, et dans une organisation Agile type Srcum ou SAFE -Capacit√© √† coacher des juniors voire d‚Äôencadrer une √©quipe -Comp√©tences de tech lead appr√©ci√©es CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap.","CGI is seeking a Senior Big Data Engineer who will be responsible for designing and deploying data transformation pipelines, defining global solutions to meet business needs, configuring and maintaining Big Data clusters, coaching and supporting project teams, and leading a team. The ideal candidate should have at least 3 years of IT experience in Big Data environments, technical skills in Hadoop, Spark, Python and NoSQL databases, and the ability to work in a team and coach juniors. CGI is an inclusive employer and welcomes applications from candidates with disabilities.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
85,73539,https://www.welcometothejungle.com/fr/companies/airbus-1/jobs/engineering-data-custodian-f-m_toulouse_AIRBU_RzGrLNy,Engineering Data Custodian (f/m),AIRBUS,"{via,GO}",T√©l√©travail ponctuel autoris√©,"Toulouse, 31000","Cybers√©curit√©, A√©ronautique / Spatiale",CDI,2023-04-22,"Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world‚Äôs leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. About us Airbus pioneers sustainable aerospace for a safe and united world. The Company constantly innovates to provide efficient and technologically-advanced solutions in aerospace, defence, and connected services. In commercial aircraft, Airbus offers modern and fuel-efficient airliners and associated services. Airbus is also a European leader in defence and security and one of the world‚Äôs leading space businesses. In helicopters, Airbus provides the most efficient civil and military rotorcraft solutions and services worldwide. Job description Airbus Commercial Aircraft is looking for an **Engineering Data Custodian (f/m) to join our Architecture and Integration department based in ** Toulouse, France. ** You will be part of a team developing processes and methodologies for the Systems engineering domain. As part of the Systems Engineering Office team, you will support the Systems Engineering process, culture, competency and discipline, on day-to-day business activities, enabled by adequate Methods & Tools (M&T) products and services. This support spans all aspects of the Systems life cycle. Your working environment: Global capital of aeronautics and European capital for space research, Toulouse is a dynamic city in the southwest of France served by an international airport. Ideally located between the Mediterranean sea and the Atlantic ocean and close to the Pyrenees mountains, it offers plenty of options for outdoor activities! How we care for you: **Financial rewards: **Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis. **Work / Life Balance: **Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services. **Wellbeing / Health: **Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application. Individual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking. Your challenges: Contribute to the engineering global picture in data/digital asset development and in the equipped framework blueprint. Under engineering common blueprint constraints, develop, execute, and supervise plans, policies, programs and practices that deliver, control, protect, and enhance the value of data and information assets throughout their life cycles. Improve existing, or implement new, processes/methodologies to support the business needs and the current challenges. Support team to help them adopt change. As part of the assessment board of the data/digital asset development quality package, provide the GO/NOGO of the data/digital asset deployment and commissioning based on Accountable for the well application and respect of data management frameworks used in data/digital asset development. Your boarding pass: Min 5 years of professional experience in an engineering business, ideally in aeronautics Strong process-minded approach. Prior experience in Functional Data of business processes and related processes. Good understanding of Data Architecture, Data Design and Modelling, Data Intelligence, Science and Analysis Ability to understand business needs and challenges in order to convey them via processes/methodologie. Leadership skills to carry change and to ensure adhesion or team members. Ideally a prior experience in change management. Comfortable working within an unclear/unidentified workframe Good communication skills, including strong competence in English language Many of our staff work flexibly in many different ways, including part-time. Please talk to us about the flexibility you need during the interview and we‚Äôll always do our best to accommodate your request. Salary range: Salary range based on the required profile: 55,000 to 65,000 ‚Ç¨/year (including a variable part based on your performance). Information provided as an indication. Not a 100% match? No worries! Airbus supports your personal growth with customized development solutions. Take your career to a new level and apply online now! #LI-AS1 This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company‚Äôs success, reputation and sustainable growth By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus. Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief. At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.",,Bac +5 / Master,> 2000 salari√©s,> 5 ans,1,1,0.027697749441558416
442,53117,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_6Vowm79,System Team Engineer DataOps,Enedis,"{Jupyter,UNIX,Scala,Kafka,Linux,Teradata,Spark,MEM,Git,mem,Hadoop,Python,Bash}",T√©l√©travail partiel possible,"√† d√©finir, Courbevoie, 92026",Energie,CDI,2023-03-20,"Enedis est une entreprise de service public, gestionnaire du r√©seau de distribution d'√©lectricit√©. Elle d√©veloppe, exploite, modernise le r√©seau √©lectrique et g√®re les donn√©es associ√©es. Elle facilite la transition √©nerg√©tique des territoires en les accompagnant dans le d√©veloppement et la planification de leur production d'√©lectricit√© d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le d√©pannage 24h/24, le relev√© des compteurs et toutes les interventions techniques. Ind√©pendante, Enedis d√©livre la m√™me qualit√© de service aux fournisseurs d'√©nergie. Comme le pr√©voit la loi, elle a √©tabli un code de bonne conduite auquel ses collaborateurs sont form√©s afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des m√©tiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilit√© du Syst√®me d'information dans un contexte de forte num√©risation des m√©tiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engag√©e notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Syst√®me d'Information √† la transformation num√©rique ou dans le positionnement d'Enedis comme op√©rateur de donn√©es, la DSI met en oeuvre de nombreux projets majeurs en lien avec les m√©tiers concern√©s. Un des enjeux majeurs d'Enedis est de devenir un op√©rateur de confiance de Donn√©es √©nerg√©tiques. Afin de r√©pondre √† cet enjeu, Enedis a mis en place une plateforme de donn√©es pour l'entreprise. Cette plateforme est compos√©e d'une infrastructure de donn√©es centralis√©e construite sur Hadoop et d'outils √† destination des √©quipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'am√©liorer cette plateforme sur plusieurs axes : migration vers le cloud, √©volution de l'architecture avec en cible une plateforme modulaire composant des services manag√©s, automatisation et mont√©e en gamme de l'offre de services internes permettant aux √©quipes de gagner en autonomie dans la cr√©ation de v√©ritables produits de donn√©es. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des √©quipes du train SAFe DataServices4U - √©quipe SPHINX, en charge de l'infrastructure data des activit√©s exploratoires (big data, big mem, GPU) - d√©finira, d√©veloppera, mettra en place et maintiendra les outils et infrastructures ad√©quats aux op√©rations du reste du train (√©quipes data scientists et data engineers). - veillera √† garantir les op√©rations des solutions permettant le traitement de volumes importants de donn√©es tout en garantissant la s√©curit√© de celles-ci - d√©finira les enablers √† prendre en compte dans l'√©quipe - sera Tech. Lead d'une √©quipe d'une dizaine de personnes - testera les r√©alisations de l'√©quipe - contribuera aux d√©monstrations faites aux √©quipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous √™tes issu d'une formation de type Bac +5 dans le domaine de l'IT / syst√®me d'information / Num√©rique et DATA - Vous disposez d'une exp√©rience d'au moins 4 ans dans des activit√©s √©quivalentes, au cours desquelles vous avec avez d√©velopp√© de solides comp√©tences techniques - Vous avez un profil Ing√©nieur Big Data disposant de comp√©tences d'analyse, de synth√®se, de cr√©ativit√© et d'une app√©tence pour l'innovation. - Vous avez de bonnes connaissances de l'administration syst√®me UNIX : ma√Ætrise de Linux (Redhat), Bash - ainsi que composants s√©curit√© et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacit√©s de communication (orales et √©crites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacit√©s de coordination - Vous faites preuve de curiosit√©, d'esprit de synth√®se, de m√©thodologie et de rigueur dans un environnement complexe Le poste est situ√© √† Courbevoie, avec une possibilit√© de t√©l√©travail partiel. La r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Chez Enedis, accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous.","Enedis seeks a System Team Engineer DataOps with a background in IT/system information/Num√©rique and DATA, and at least four years of experience with a strong technical skill set. The engineer will lead a team and be responsible for defining, developing, implementing, and maintaining the appropriate tools and infrastructure for the operations of a platform of centralized data infrastructure based on Hadoop. Additionally, the engineer will test the team's achievements, contribute to demonstrations, and stay synchronized with other technical leaders and architecture.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
419,40397,https://www.welcometothejungle.com/fr/companies/edf/jobs/data-ingenieur-f-h_nanterre,Data Ing√©nieur,EDF,"{UNIX,PowerBI,Linux,Hadoop,SQL,Python}",T√©l√©travail partiel possible,"Avenue Pablo Picasso , Nanterre, 92200","Environnement / D√©veloppement durable, Energie",CDI,2023-01-29,"Le groupe EDF est l‚Äôun des premiers √©lectriciens mondiaux, √† la pointe de l‚Äôinnovation technologique. Le respect de la personne et celui de l‚Äôenvironnement, l‚Äôint√©grit√©, la solidarit√© sont au c≈ìur de nos actions. Face √† l‚Äôurgence climatique, notre r√¥le est d‚Äôinventer un mod√®le √©nerg√©tique qui respecte notre plan√®te. Nous voulons construire un monde o√π il sera possible de produire une √©lectricit√© neutre en CO2, gr√¢ce au nucl√©aire et aux √©nergies renouvelables, conciliant pr√©servation de la plan√®te, bien-√™tre et d√©veloppement, gr√¢ce √† l‚Äô√©lectricit√© et √† des solutions et services innovants. Notre ambition est de toujours innover, pour permettre √† notre soci√©t√© de continuer √† grandir. Depuis notre cr√©ation, c‚Äôest notre responsabilit√© de rendre l‚Äô√©nergie accessible √† tous, √† tout moment, en toutes circonstances, en proposant de nouvelles mani√®res de moins consommer, de mieux consommer. C‚Äôest √† nous, femmes et hommes d‚ÄôEDF, fiers de nos missions de service public, de transformer demain. Vous aussi vous souhaitez construire un avenir √©nerg√©tique neutre en CO2 ? En 2022, le groupe EDF recrutera plus de 15 000 nouveaux collaborateurs en CDI, alternance ou stage. Rejoignez-nous ! EDF, √©lectricien performant et responsable, champion de la croissance bas carbone recrute dans ses nombreux m√©tiers. Rejoignez nos √©quipes et relevez de nouveaux d√©fis au service de 38.5 millions de clients. Au sein d'EDF, la Direction Services Informatique et T√©l√©coms (DSIT) du groupe EDF propose aux m√©tiers du groupe des moyens d'exploitation des applications, infrastructures, et moyens collaboratifs communs. En tant que Data Ing√©nieur, vous int√©grez un collectif organis√© en Agile, et reposant sur 3 √©quipes Scrum pour un total de 20 personnes : 2 √©quipes de DataAnalysts 1 √©quipe de DataIng√©nieurs sur laquelle est publi√©e cette offre Les m√©thodologies Scrum et SAFe pour l'agilit√© √† l'√©chelle seront utilis√©es. Les services rendus par ce collectif sont de valoriser les donn√©es IT de toute l'entit√© et de tous nos coeurs d'activit√©s IT Des infrastructure (t√©l√©coms, syst√®me, IoT ‚Ä¶) A nos applicatifs (cloud priv√©, public ‚Ä¶) Afin de mieux piloter notre production et nos actifs. Vous aurez ainsi pour mission de fournir aux √©quipes de DataAnalyse une infrastructure de donn√©es fiable et performante, avec des donn√©es de qualit√©. Vos missions Au quotidien, les activit√©s du Data Ing√©nieur sont les suivantes : Infrastructures de donn√©es : Cartographie et documente les sources de donn√©es. Assure la maintenance des diff√©rentes applications donn√©es (Data) d√©ploy√©es en production et des infrastructures. Structure les bases de donn√©es (s√©mantique, format, etc.). Contribue √† la gestion des r√©f√©rentiels de donn√©es. Int√©gration des donn√©es : Capte et stocke, en toute s√©curit√©, les donn√©es (structur√©es ou non) produites dans les diff√©rentes applications ou venant de l'ext√©rieur de l'entreprise. Assure la supervision et l'int√©gration des donn√©es de diverses nature qui proviennent de sources multiples. V√©rifie la qualit√© des donn√©es qui entrent dans le Datawarehouse et s'assure de leur s√©curit√©. Nettoie la donn√©e (√©limination des doublons...) et la valide pour une utilisation aval. Maintien en condition op√©rationnelle S'assure de la maintenance de l'infrastructure de donn√©es. Maintien de la performance de l'infrastructure de donn√©es. Optimise l'infrastructure de donn√©es. Pour en savoir plus sur la culture num√©rique au sein d'EDF, cliquez ici. Vous souhaitez appliquer vos connaissances techniques autour des briques de stockage, traitement et restitution de la donn√©e . Vous avez une exp√©rience significative dans les domaines techniques de la Data en tant que Data Ing√©nieur, afin d'√™tre √† l'aise dans les environnements techniques suivants : Stockage des donn√©es : Bases SGBD traditionnelles :Administration et requ√™tage SQL Mod√©lisation de bases de donn√©es Traitement des donn√©esD√©veloppements Python Outils d'ETL Visualisation de donn√©es : Outils de Dataviz type PowerBI Connaissances syst√®me : Linux/UNIX Vous faites preuve d'autonomie, et √™tes force de proposition sur les choix techniques, de r√©activit√© dans la gestion des demandes et incidents, d''une capacit√© d'√©coute et de compr√©hension des besoins. Vous avez une culture sur les environnements et technologies du BigData (Hadoop, ELK ‚Ä¶). Vous √™tes √† l'aise dans une organisation Agile du travail. Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous.","EDF, a global electricity leader, is seeking a data engineer to provide reliable and high-performing data infrastructure to data analysis teams. The ideal candidate should have significant experience in data management and be familiar with SQL administration, database modeling, Python development, ETL tools, data visualization tools, and Unix/Linux systems. The position is part of an Agile team using Scrum and SAFe methodologies to support the IT activities of EDF. Applicants should be proactive, technically savvy, and comfortable working in an Agile environment. EDF welcomes candidates with disabilities and strives to offer equal opportunities to all.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
207,56583,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_toulouse,Expert technique ETL Semarchy xDI / Stambia,CGI,{},T√©l√©travail partiel possible,"Toulouse, 31000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Semarchy xDI / Stambia ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Semarchy ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√©.e d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert.e technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, seeks a candidate with at least three years of experience as an ETL Semarchy xDI/Stambia technical expert to join its Digital Innovation Center. The role involves improving the efficiency and effectiveness of implemented solutions, collaborating with engineers and other experts on data integration issues, developing technical standards, providing internal and external training, and providing daily technical support. The ideal candidate is ambitious, a team player, and has experience as a technical consultant in fixed-price projects. Knowledge of data quality and governance is a plus. CGI is a proponent of workplace diversity and welcomes applications from candidates with disabilities and members of the LGBT community.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
205,56584,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/concepteur-developpeur-talend-f-h_nantes,Consultant ETL Talend -,Micropole,"{Microsoft,durable,Talend,AWS,R,TALEND,GCP}",T√©l√©travail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. Comme nous, vous √™tes passionn√©(e) par la donn√©e etconvaincus que l‚Äôoptimisation du patrimoine data des entreprises est lacl√© de leur performance ? Vous voulez rendre les entreprises dataintelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sentleur futur ? Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitales , au sein d‚Äôuneagence √† taille humaine o√π r√®gnent entraide et convivialit√©, engag√©e en faveurd‚Äôun num√©rique plus responsable au service de clients principalement implant√©sr√©gionalement ? Si vous avez r√©pondu favorablement √†chacune de ces questions, qu'attendez-vous ? Rejoignez l'aventure Micropole ! EN TANT QUE CONSULTANT TALEND (F/H) : Micropole s‚Äôappuie sur l'expertise deses collaborateurs sp√©cialistes de la donn√©e pour accompagner les clients dansleurs projets de business intelligence, gouvernance de la donn√©e et pilotage de laperformance visant √† apporter de la valeur aux m√©tiers. L‚Äôun des Managers du P√¥le BI compos√©d'une trentaine de personnes sur l'Ouest recrute un Consultant ETL Talend (F/H) pour compl√©ter ses √©quipes sp√©cialistes de l‚Äôalimentation desyst√®mes d‚Äôinformations d√©cisionnels. Dans vos missions quotidiennes , vous serez amen√©(e) : - Comprendre le besoinexprim√© par les m√©tiers - Concevoir le mod√®le conceptuelde donn√©es et le mod√®le physique de donn√©es - R√©diger les sp√©cificationsd√©taill√©es - D√©velopper les jobs d‚ÄôalimentationTalend - Tester, d√©ployer, industrialiseret optimiser les performances des jobs - Documenter vos travaux Le mot du Manager: Fort de nos valeurs d‚Äôengagement et de collectif, nous accompagnons les transformations data et digitale vers un num√©rique plus responsable. Vos comp√©tences techniques : - Vousposs√©dez au moins 3 ans d‚Äôexp√©rience sur Talend - Vous√™tes id√©alement certifi√©(e) Talend Data Integration Vos atouts : - De formation en informatiqued√©cisionnelle ou √©quivalente, vous √™tes √† l‚Äôaise dans le traitement de la donn√©e, - Vous poss√©dez descapacit√©s relationnelles qui vous permettent de vous adapter et de communiqueravec l'ensemble des interlocuteurs d'un projet, - Votre rigueur etvos capacit√©s d'organisation sont souvent reconnues et particuli√®rementappr√©ci√©es, Devenir #INNOVATIVE PEOPLE C‚Äôest : - Int√©grer une communaut√© de1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg,la Suisse, l‚ÄôEspagne et la Chine. - Construire ensemble lessolutions strat√©giques et innovantes de demain pour accompagner nos clientsdans leur transformation data et digitale. - Participer au d√©veloppementde nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement autravers de formations et de certifications sur les plus grandes technologiesgr√¢ce √† Micropole Campus. - S‚Äôassurer d‚Äôune innovationcontinue gr√¢ce √† : o Notre √©cosyst√®me de partenaires technologiques o Notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR o Nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et deco-construction avec les clients o Notre management par les talents naturels Processus de recrutement : Chez Micropole, le processus de recrutement estr√©actif et transparent. - Etape 1 ‚Äì Si votre profil correspond √† nos attentes, vous √™tesrecontact√©(e)s dans les 72 heures qui suivent votre candidature par C√©line ouMika√´l nos Talent Specialist pour la r√©gion ouest pour un premier √©changet√©l√©phonique ; - Etape 2 ‚Äì Un premier entretien est programm√© avec l‚Äôun d‚Äôentre euxsur site ou √† distance - Etape 3 ‚Äì Vous rencontrez St√©phanie ou Camille les manager del‚Äô√©quipe Data de l‚ÄôOuest en second entretien En fonction du poste, vous pouvez passer des √©tapessuppl√©mentaires (entretien suppl√©mentaire ou test technique) LAVIE CHEZ MICROPOLE, C‚ÄôEST : - Une vie interne rythm√©epour se familiariser √† la culture d‚Äôentreprise et aux valeurs deMicropole ; - Des √©v√®nements internesr√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ; - Une politique de formationattractive et √©clectique (certifications prises en charge) ; - Un travail en √©quipevaloris√© pour une meilleure coh√©sion ; - La participation √† desprojets internes sur la base du volontariat. √Ä PROPOS DE MICROPOLE GRAND-OUEST Micropole GrandOuest regroupe les agences de Nantes, Niort, Rennes.Avec un d√©veloppement rapide sur le Data, leDigital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur duGroupe. Pr√©sent au pluspr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs dud√©veloppement √©conomique, nous accompagnons nos clients des secteurs del‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et dupublic dans leur transformation data et digitale, notamment au travers dem√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ. L‚Äôagence GrandOuest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit etmet en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôunnum√©rique responsable au sein des organisations. √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en avoir plus : https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Comp√©tences ETL‚ÄØTalend","Micropole is seeking a Talend ETL Consultant to support clients in their business intelligence, data governance and performance management projects. The successful candidate should possess at least 3 years of experience in Talend and be comfortable with data processing. They should also have strong communication and organizational skills. Micropole is a group of 1200 consultants in Europe and China, dedicated to helping clients transform their businesses through data.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
239,56900,https://www.welcometothejungle.com/fr/companies/visian/jobs/data-engineer-h-f_levallois-perret_VISIA_MP6apl8,DATA ENGINEER,Visian,"{NiFi,Tensorflow,Beam,MXNet,Kafka,Spark,Keras,NoSQL,Hadoop}",T√©l√©travail partiel possible,"22, Rue du Pr√©sident Wilson, Levallois-Perret, 92300","Intelligence artificielle / Machine Learning, IT / Digital, Strat√©gie",CDI,2023-03-26,"De la d√©finition d‚Äôune roadmap digitale au lancement de produits et services innovants, Visian concr√©tise les ambitions de ses clients en veillant √† int√©grer durabilit√© et sobri√©t√© num√©rique. Visian est sp√©cialis√© dans l‚Äôinnovation, le product design et la data. Ses consultants technophiles allient compr√©hension des enjeux digitaux et vision produit. Visian, cabinet de conseil sp√©cialis√© en Innovation, Design Produit, et Data, recherche pour son client, grand acteur du secteur de l‚Äô√©nergie, un Data Engineer pour rejoindre ses √©quipes sur un projet innovant. Contexte: La mission se d√©roule au sein de l‚Äôentit√© responsable du d√©veloppement de m√©thodologies et d‚Äôoutils d‚ÄôIA/d‚Äôapprentissage automatique pour des solutions intelligentes et bas√©es sur les donn√©es qui prennent en charge des mod√®les commerciaux nouveaux et innovants pour les cha√Ænes de valeur existantes et futures. L‚Äôing√©nieur sera responsable de l‚Äôexpansion et de l‚Äôoptimisation de l‚Äôarchitecture d‚ÄôIA, en mettant des mod√®les d‚Äôapprentissage automatique. Il agira en soutien des d√©veloppeurs de logiciels, architectes de bases de donn√©es, Data Analyst, et Data Scientist pour garantir l‚Äôarchitecture de prestation de services d‚ÄôIA optimale Missions : D√©velopper et maintenir un syst√®me de traitement de donn√©es √† grande √©chelle D√©ployer des mod√®les ML (fournis par des scientifiques des donn√©es) S‚Äôassurer que les pipelines ETL construites prendront en charge les flux de donn√©es √† volume √©lev√© D√©tecter les opportunit√©s d‚Äôacquisition, de stockage et d‚Äôinterrogation de donn√©es de mani√®re performante Utiliser une vari√©t√© de langages et d‚Äôoutils (sensibilisation aux donn√©es opensource apache/ML cadres connexes est une comp√©tence indispensable) Comprendre, personnaliser et maintenir des projets open source et contribuer au d√©veloppement de nouveaux cadres 3 √† 5 ans en tant que Data Engineer sur des sujets d‚ÄôIA Pratiques des Outils BIG DATA: Hadoop, Spark, Kafka, NoSQL, NiFi, Beam, Zookeeper,etc‚Ä¶ Savoir Construire des pipelines ETL de donn√©es √©volutifs et tol√©rants aux pannes bas√©es sur les technologies du Big Data Exp√©riences en impl√©mentation d‚Äôinf√©rences bas√©es sur des mod√®les d‚Äôapprentissage profond avec des frameworks comme Apache MXNet, Tensorflow, Keras etc Mise en production des mod√®les ML suite √† MLOps Exp√©riences avec les langages de programmation orient√©s objet Compr√©hension du web s√©mantique / des Donn√©es li√©es Approches agiles (SCRUM, SAFE) Exp√©riences de soutien et de travail avec des √©quipes interfonctionnelles dans un environnement dynamique Anglais courant","Visian, an Innovation, Product Design, and Data consultancy, is seeking a Data Engineer for its client in the energy sector. The engineer will be responsible for expanding and optimizing AI architecture, deploying ML models, and detecting opportunities for acquisition, storage, and effective data querying. The ideal candidate should have 3-5 years' experience in AI, familiarity with big data tools such as Hadoop, Spark, Kafka, among others, and proficiency in programming languages. The position requires excellent communication skills and the ability to collaboratively work in an agile environment.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
412,37324,https://www.welcometothejungle.com/fr/companies/gens-de-confiance/jobs/data-engineer-platform-f-m_nantes,"Data Engineer, Platform",Gens de Confiance,"{Amplitude,Ruby,Go,Metabase,JavaScript,Redshift,Glue,Lambda,AWS,scale,PHP,NoSQL,SQL,Python}",T√©l√©travail partiel possible,N,"Big Data, √âconomie collaborative, Immobilier particulier",CDI,2022-10-18,"Gens de Confiance est un service de petites annonces accessible sur recommandation pour les particuliers et les professionnels, qui permet √† ses 1.500.000 membres d‚Äôacheter, de vendre et de louer en ligne, en toute s√©curit√©. Les cat√©gories disponibles vont de l‚Äôimmobilier √† l‚Äô√©lectrom√©nager, en passant par le babysitting et l‚Äôautomobile. Vous √™tes aussi √† la recherche d‚Äôun artisan ou d‚Äôun professeur particulier ? La plateforme vous permet √©galement de trouver le professionnel de confiance ! Comment √ßa marche ? Tout le monde peut s‚Äôinscrire gratuitement sur Gens de Confiance, mais il faut √™tre membre pour r√©pondre aux annonces. Les inscrits qui souhaitent devenir membres doivent obtenir le parrainage de trois membres existants. Et le jeu en vaut la chandelle, car 70 % des annonces publi√©es sur Gens de Confiance sont introuvables ailleurs. Depuis 2014 nous avons compris qu‚Äôavec Gens de Confiance il est possible d‚Äôapporter un niveau de confiance radicalement sup√©rieur √† l‚Äôexistant ‚Äî et √† grande √©chelle ‚Äî en offrant un cadre simple, un service de qualit√© et un produit au meilleur niveau. Pour autant, nous n‚Äôen sommes qu‚Äôau d√©but de nos d√©couvertes et un boulevard s‚Äôoffre √† nous √† condition de savoir nous faire conna√Ætre au plus grand nombre ! Notre mission, est √† la fois simple et ambitieuse : remettre un peu plus de confiance dans notre soci√©t√© et contribuer au d√©veloppement de l‚Äô√©conomie circulaire. Et l‚Äôactualit√© nous confirme h√©las chaque semaine que ce n‚Äôest pas du luxe. Aujourd‚Äôhui, Gens de Confiance est disponible en fran√ßais et en anglais, sur le web comme sur mobile. L‚Äôentreprise compte 65 personnes, √† Nantes et en remote. Pour r√©v√©ler la confiance, l‚Äô√©quipe Tech / Produit adopte une culture qui repose sur l‚Äôintelligence collective, la soif d‚Äôapprendre, le partage de connaissances et un esprit ‚Äúdoer‚Äù. Et si le langage est un moyen, notre priorit√© reste le produit ! Le poste : Nous avons un r√©seau de pr√®s d‚Äô 1.400.000 membres et nos √©quipes r√©pondent √† de forts enjeux de scalabilit√©, de refonte d‚Äôarchitecture, et de recherche de performance accrue. Nous recherchons des personnes avec une r√©elle valeur-ajout√©e; l‚Äôexp√©rience nous prouve que la diversit√© et l‚Äôinclusion font la richesse de notre startup. Notre √©quipe Tech / Produit de plus de 30 personnes est notamment r√©partie au sein de diff√©rentes squads dont 3 feature teams autonomes et une team transverse: Team Classifieds Team Members Team Services & Pro Team Platform Chaque feature team est constitu√©e d‚Äôun Engineering Manager, d‚Äôun Product Manager, d‚Äôun Product Designer et de d√©veloppeurs back et front. Chaque team a ses objectifs (OKRs) et est autonome sur son mode de fonctionnement. La Team Platform compte 7 personnes. La data se trouve au c≈ìur de la strat√©gie de Gens de Confiance, afin d‚Äôam√©liorer l‚Äôexp√©rience utilisateur et pour proposer de nouveaux services et produits li√©s √† la confiance. Nous avons entam√© la mise en place d‚Äôune architecture de collecte, de traitement et d‚Äôanalyse des donn√©es. Notre √©quipe cherche des profils pour venir acc√©l√©rer le d√©ploiement de cette architecture, en d√©velopper les pans manquants (data warehouse, h√©bergement des mod√®les de machine learning, etc.) et cr√©er des fonctionnalit√©s produits exploitant nos donn√©es. Pourquoi ? Parce que la satisfaction de nos membres et de nos feature teams, coeur de notre m√©tier, passe par une architecture de donn√©es robuste et performante. Ton r√¥le : Fournir un acc√®s stable √† la donn√©e de GDC et enrichir l‚Äôexp√©rience utilisateur gr√¢ce √† des fonctionnalit√©s enrichie par la donn√©e. Pour ce faire tes principales missions seront de : D√©ployer et maintenir un pipeline de traitement capable de traiter un volume important de donn√©es tout en garantissant leur s√©curit√©. Monitorer et am√©liorer les m√©triques du data pipeline (disponibilit√©, taux d‚Äôerreur, latency, etc.) Rassembler et participer √† la priorisation des besoins data des √©quipes marketing, produit et des cofondateurs. Prendre en compte le contexte r√©glementaire quant √† la r√©colte et √† l‚Äôacc√®s aux donn√©es (RGPD) Faciliter l‚Äôint√©gration de nouvelles donn√©es par les √©quipes de d√©veloppement (back-end et front-end) Proposer et mettre en place des am√©liorations dans le processus de d√©veloppement (CI, tests, monitoring, d√©ploiement, etc.) D√©velopper des outils d‚Äôacc√®s et de visualisation de la donn√©es (Amplitude, Redshift, etc.) B√¢tir des nouveaux produits et fonctionnalit√©s bas√©es sur la donn√©e, par exemple dans la cr√©ation et la recherche d‚Äôannonce, l‚Äôinscription et la recommandation de parrainages, la d√©tection automatique d‚Äôanomalies et d‚Äôerreurs. Stack: Python AWS: Lambda Redshift Glue Neptune Terraform Serverless Metabase Avantages : Des horaires flexibles, une organisation agile et un environnement propice au t√©l√©travail Programme d‚Äô√©volution de carri√®re Accompagnement aux side projects et formations allou√©es (budgets et temps) Locaux agr√©ables, spacieux et id√©alement situ√©s dans le centre de Nantes Budget pour des abonnements de cours en ligne Compl√©mentaire sant√© familiale (mutuelle) prise en charge √† 85% par Gens de Confiance Cours d‚Äôanglais BSPCE Welcome Pack : budget d‚Äô√©quipement de l‚Äôentreprise de 4 k‚Ç¨ : √©cran panoramique incurv√© de 34‚Äù + fauteuil Herman Miller Aeron + ordinateur de ton choix) Qui es-tu ? Tu es de formation ing√©nieur ou √©quivalent. Tu disposes d‚Äôau moins 3 ans d‚Äôexp√©rience, id√©alement au sein d‚Äôune startup avec des contraintes de scale et product first Tu excelles dans au moins un langage de programmation (Python, JavaScript, PHP, Ruby, Go, Rust‚Ä¶). Tu ma√Ætrises le SQL, les concepts et le d√©ploiement des bases de donn√©es relationnelles et NoSQL. Tu es √† l‚Äôaise √† travailler dans un environnement de startup dynamique, avec de multiples priorit√©s √† g√©rer Bref, tu aimes la gestion de projet et l‚Äôam√©lioration continue. Seraient un plus : Tu as con√ßu, d√©ploy√© et maintenu une architecture complexe en production : sp√©cifications, conception, monitoring, alerting, gestion des incidents, recherche des root causes. Tu as de l‚Äôexp√©rience Cloud (de pr√©f√©rence AWS) Pourquoi devrais-tu postuler ? Tu crois comme nous que‚Ä¶ le succ√®s passe par le collectif pas d‚Äôimpact sans delivery faire preuve d‚Äôaudace et tenir ses engagements est primordial en donnant on re√ßoit beaucoup ! Les √©tapes cl√©s : Entretien avec notre √©quipe RH R√©alisation d‚Äôun test technique chez toi Entretiens avec tes futurs coll√®gues et un manager Entretien avec un co-fondateur","Gens de Confiance is a French online platform that allows its 1.5 million members to buy, sell and rent securely. They are looking for a Data Engineer to deploy and maintain a data pipeline that handles a large volume of data while ensuring its security, monitor and improve data pipeline metrics, prioritize the data needs of marketing and product teams, and propose improvements to the development process. The ideal candidate should have at least 3 years of experience in a startup environment and be comfortable working in a fast-paced, dynamic environment. AWS experience is preferred. The company offers flexible working hours, career development programs, and healthcare benefits.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
260,62900,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-f-h_toulouse,Data Engineer,Meritis,{Java},T√©l√©travail ponctuel autoris√©,"Place du Capitole, Toulouse, 31000","IT / Digital, Finance",CDI,2023-03-31,"Meritis est une soci√©t√© de conseil en transformation des Syst√®mes d‚ÄôInformation et Organisations. Notre mission : associer les meilleurs talents √† l‚Äô√©laboration de transformations cr√©atrices de valeur. Nous sommes une entreprise o√π il fait bon travailler ! R√©guli√®rement labellis√©e Great Place To Work ¬Æ : N¬∞3 GPTW en 2020, N¬∞1 GPTW en 2017, N¬∞7 GPTW en 2015, N¬∞5 GPTW en 2013. En 2021 Meritis est class√©e 11e du Palmar√®s Europ√©en des Best Work Places. üëâ GPTW Au sein du p√¥le Data IA, vous int√©grerez les √©quipes qui sont responsables de la collecte des donn√©es, vous serez en charge de : R√©cup√©rer, organiser et mettre en forme la donn√©e D√©velopper de nouvelles fonctionnalit√©s R√©aliser les tests techniques Faire √©voluer l'architecture Produire la documentation Encadrer une √©quipe de d√©veloppeur Pr√™t.e √† d√©marrer de nouveaux challenges dans une entreprise o√π il fait bon vivre ? Meritis offre √† ses collaborateurs : ‚Ä¢ Un accompagnement personnalis√© tout au long de leur carri√®re, ‚Ä¢ Des parcours professionnels sur mesure‚ÄØ: choix des projets, √©volution de carri√®re, formations adapt√©es et mentoring. Mais aussi de‚ÄØ: ‚Ä¢ B√©n√©ficier d‚Äôun r√©seau de clients riche et vari√©, ‚Ä¢ Travailler dans un environnement convivial avec de nombreux √©v√©nements festifs et techniques, ‚Ä¢ Envisager des mobilit√©s g√©ographiques internes gr√¢ce au maillage r√©gional du groupe. Nos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Vous avez un dipl√¥me d‚Äôing√©nieur (Bac+5), une sp√©cialisation dans l'ing√©nierie informatique est un plus Vous disposez de plus de 7 ans d'exp√©rience en d√©veloppement Java Vous √™tes autonome, rigoureux.se et organis√©.e Vous √™tes bilingue Anglais","Meritis, a consulting firm for information system and organizational transformation, is seeking a Java Developer with over 7 years of experience. The role involves data collection, organizing and formatting data, developing new functionalities, testing, and architecture evolution. The position also includes managing a team of developers. Meritis offers personalized career paths, diverse client network, friendly work environment, and regional mobility opportunities. They are committed to diversity and equal opportunity for people with disabilities. A degree in engineering is required, and proficiency in English is mandatory.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,1,1,0.027697749441558416
389,34697,https://www.welcometothejungle.com/fr/companies/apgar/jobs/data-engineer-confirme_neuilly-sur-seine,Data Engineer Confirm√©(e),Apgar Consulting,{portable},T√©l√©travail ponctuel autoris√©,Neuilly-Sur-Seine,"IT / Digital, SaaS / Cloud Services, Big Data",CDI,2022-08-08,"Apgar Consulting est un cabinet de Conseil sp√©cialiste de la Data. Apgar concilie son expertise ¬´ Data ¬ª avec une vision plus g√©n√©rale du fonctionnement de L‚ÄôEntreprise afin de concevoir des solutions organisationnelles et technologiques sur-mesure pour am√©liorer l‚Äôusage et le partage des informations capitales. L‚Äôexpertise d‚ÄôApgar s‚Äôarticule autour de 4 axes suivant : Le Meta Data Management : D√©crire et piloter les donn√©es de l‚Äôentreprise pour mieux les valoriser. Le Master Data Management : Maitriser la cr√©ation, l‚Äôusage, le partage et la qualit√© des donn√©es capitales au fonctionnement des processus de l‚Äôentreprise La Data Integration : Impl√©menter les solutions d‚Äô√©changes inter-applicatifs La Data Preparation : Appliquer la connaissance des donn√©es pour les nettoyer et les classer, avant de les entreposer et de les analyser. Pour chacune de ces offres, Apgar porte une attention particuli√®re √† l‚Äôexp√©rience utilisateur et √† la r√©ussite de son int√©gration dans le syst√®me d‚Äôinformation, en adoptant une m√©thodologie projet pragmatique, adapt√©e aux solutions impl√©ment√©es. En qualit√© de Data Engineer confirm√©(e), vous travaillez au sein d‚Äôune √©quipe intervenant directement sur un projet Client. Vous √™tes encadr√©(e) par un Data Engineer s√©nior ou un manager. Vous prenez la responsabilit√© d‚Äôun chantier qui vous aura √©t√© confi√© par votre chef de projet Vous √™tes impliqu√©(e) sur l‚Äôensemble du projet d√®s son d√©marrage et serez en interaction avec le client / m√©tier et les consultants techniques Vous participez √† toutes les phases de mise en ≈ìuvre de solutions de Data Management Vous participez √† l‚Äôanalyse des besoins, r√©digez les sp√©cifications fonctionnelles et assurez l‚Äôad√©quation de la solution avec le besoin du client Vous assurez un reporting fiable et pertinent de votre activit√© aupr√®s de votre responsable Vous animez les ateliers de conception fonctionnelles et r√©digez les comptes-rendus Vous accompagnez le client dans la recette et la mise en service de la solution Vous √™tes responsable de la qualit√© des livrables et des prestations fournis et contribuez √† la qualit√© globale des projets et missions auxquels vous participez De formation sup√©rieure BAC+4/5, vous disposez de minimum 3 ann√©es d‚Äôexp√©rience en cabinet de conseil ou ESN ¬∑ Vous avez des app√©tences relationnelles et avez des facilit√©s √† r√©diger et √† vous exprimer ¬∑ Vous avez la capacit√© de comprendre et de r√©diger des sp√©cifications fonctionnelles ¬∑ Vous souhaitez acqu√©rir des comp√©tences en gestion de projet et management d‚Äô√©quipe ¬∑ Une exp√©rience en lien avec l‚Äôune de nos offres (MDM, M√©ta data, Data Integration et Data Preparation) serait un r√©el plus Vos Avantages : Une r√©mun√©ration attrayante avec une part fixe et une part variable 75% de prise en charge du titre de transport (Navigo) Un t√©l√©phone portable et son forfait associ√© Des tickets restaurant avec participation de l‚Äôentreprise Des avantages sociaux et fiscaux (Mutuelle entreprise, PEE et PERCO) La possibilit√© de t√©l√©travailler 2 jours par semaine Alors si vous √™tes dynamique, enthousiaste et curieux n‚Äôh√©sitez pas √† postuler pour rejoindre un cadre de travail agr√©able, bienveillant et fraternel ‚Ä¶. Futur(e)s Apgariens, Apgariennes nous vous attendons !","Apgar Consulting, a data consulting firm, is seeking an experienced Data Engineer to work on client projects. The ideal candidate should have expertise in meta data management, master data management, data integration, and data preparation. The role involves working within a team, taking responsibility for a project, participating in all phases of data management solutions, and ensuring the quality of deliverables. The candidate should have strong communication skills and be able to write functional specifications. A minimum of three years of experience in consulting or ESN is required, with knowledge of one of Apgar's areas of expertise being a plus. The company offers attractive benefits, including a fixed and variable salary, transportation subsidies, and social and tax benefits.",N,N,N,1,1,0.027697749441558416
320,56424,https://www.welcometothejungle.com/fr/companies/chronotruck/jobs/data-engineer_puteaux,Data engineer,Chronotruck,"{Git,Metabase,PostgreSQL,Airflow,Docker,SQL,Python,MLFlow}",T√©l√©travail partiel possible,"Puteaux, 92800","Transports maritime et routier, Big Data",CDI,2023-03-26,"Chronotruck, c‚Äôest une boite tech‚Äô qui veut transformer le transport routier de marchandises √† coups d‚Äôalgorithmes et de Data ! En quelques mots : une plateforme web et mobile B2B de mise en relation d‚Äôexp√©diteurs et de transporteurs professionnels g√©olocalis√©s, qui facilite les transactions entre les deux parties. Pionnier dans son domaine (m√™me avant les US !), Chronotruck est un des leaders fran√ßais du fret routier 2.0. Rachet√© en 2019 par le g√©ant du transport GEFCO, lui-m√™me rachet√© en 2022 par CEVA Logistics, l‚Äôambition est de devenir le leader europ√©en du transport routier de marchandises digital. Chronotruck a √©t√© retenu dans les 20 entreprises mondiales qui vont r√©volutionner l‚Äôindustrie du fret routier par le cabinet Frost & Sullivan. C√¥t√© tech, l‚Äô√©quipe est compos√©e d‚Äôune dizaine de personnes qui travaillent ensemble pour proposer √† nos utilisateurs la meilleure exp√©rience possible. Nos valeurs : autonomie, implication, rigueur, d√©sir de progresser. Si tu veux en savoir plus on a un site d√©veloppeurs Au sein de l‚Äô√©quipe tech (10 personnes), tu viendras renforcer l‚Äô√©quipe data (3 personnes avec toi) sur les sujets de data engineering. Tu seras en charge de g√©rer les pipelines de donn√©es, l‚Äôint√©gration de donn√©es, la qualit√© des donn√©es et √©galement le bon fonctionnement de nos algos en prod. Tu reporteras au head of data. Tes missions Tu es LE (LA) responsable technique de la stack data. Aujourd‚Äôhui nous utilisons Python, Airflow comme ETL et pour faire tourner certains algos, fastAPI, MLFlow et Metabase pour la data analyse. Nos db sont en PostgreSQL et tout tourne sur Digital Ocean. Tu t‚Äôoccupes du d√©ploiement et de la maintenance des pipelines de prod, pour l‚Äôingestion de donn√©es et les algos. Tu participes au d√©veloppement des nouveaux algos en apportant notamment ton aisance technique. Tu fais grandir l‚Äô√©quipe sur les sujets de data engineering. Tu fais de la veille techno sur le data engineering. Id√©alement tu as d√©j√† de l‚Äôexp√©rience en tant que data engineer, √† d√©faut en tant que dev/devops/software engineer et int√©ress√© par les probl√©matiques data! Tu maitr√Æses Python, SQL, Docker et Git. Tu as d√©j√† mis en prod des algos de ML et des pipelines de donn√©es dans des contextes r√©els. Soft skills Tu es soucieux(se) de l‚Äôexp√©rience utilisateur, tu d√©testes voir un bug en prod. Tu es data-driven et orient√©(e) business. Tu as le souci du d√©tail, mais tu sais aussi √™tre pragmatique. Tu es pr√™t(e) √† t‚Äôint√©resser au secteur du transport de marchandises. Pourquoi nous rejoindre Tu feras partie d‚Äôune petite √©quipe data compos√©e aujourd‚Äôhui d‚Äôun head of data et d‚Äôun data scientist passionn√©s, dynamiques, talentueux et impliqu√©s. Tu b√©n√©ficieras d‚Äôune grande autonomie et tes prises d‚Äôinitiatives seront encourag√©es. Tu participeras aux d√©cisions techniques strat√©giques. Tu travailleras sur des donn√©es riches et sp√©cifiques au transport ainsi que sur des algorithmes originaux. Tu auras 3 jours de t√©l√©travail par semaine. Call de pr√©sentation. Test technique. Entretien physique ou visio.","Chronotruck is a technology company that uses algorithms and data to transform freight transport. They are searching for a data engineer to manage data pipelines, data integration, and data quality, as well as develop new algorithms and grow the data engineering team. The ideal candidate should have experience with Python, SQL, Docker, Git, and ML algorithms, and be data-driven, business-oriented, and detail-oriented. The company offers a small, dynamic, and talented data team, autonomy, and the opportunity to work on rich and specific transport data and original algorithms. Remote work is available three days a week.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
290,56994,https://www.welcometothejungle.com/fr/companies/fulll/jobs/data-scientist-ingenieur-h-f_aix-en-provence,Data Engineer,Fulll,"{React,python,AWS,tableau,SQL}",T√©l√©travail ponctuel autoris√©,"12, All√©e des Informaticiens, Aix-en-Provence, Aix-En-Provence, 13290",Logiciels,CDI,2023-03-26,"Parlons bien, parlons fulll ! L‚Äôhistoire commence en 2021, quand trois √©diteurs de logiciels historiques d√©cident d‚Äôunir leurs forces et donner naissance √† fulll. Aujourd‚Äôhui, fulll c‚Äôest la seule solution 100% web d√©di√©e √† la production comptable et sociale collaborative . Notre mission est d‚Äôaccompagner les experts-comptables dans le pilotage de leur activit√©, en mettant √† leur disposition des outils innovants, complets, agiles et √©volutifs pour simplifier la collaboration avec leurs clients (TPE/PME), les accompagner dans la mise en place de leur m√©thode de travail. C‚Äôest le sens de notre engagement quotidien : les aider √† relever leurs d√©fis de transformations, ils sont nombreux. Gestion documentaire, tableau de bord, agenda professionnel partag√©, collecte des variables de paie, analyse de la performance, suivi des d√©penses et des recettes,‚Ä¶ Nous proposons un panel de solutions performantes, et notre projet est d‚Äôen d√©velopper bien d‚Äôautres ! Notre ambition ? Devenir l‚Äôacteur incontournable du monde de l‚Äôexpertise comptable. En 2022, nous avons accompagn√© plus de 1000 cabinets et plus de 200 000 entreprises sont connect√©es √† notre portail. Pour ce qui est de l‚Äô√©quipe, nous sommes aujourd‚Äôhui 225 fulllers r√©partis sur 4 sites (Lyon, Aix-en-Provence, Rouen et Bordeaux), dont plus de 75% des m√©tiers sont des profils techniques (d√©veloppeurs, architectes, testeur QA, etc.). Esprit collectif, engagement personnel et d√©passement de soi, responsabilit√© soci√©tale, bienveillance sont autant de caract√©ristiques de nos collaboratrices et collaborateurs. Pour l‚Äôann√©e 2023, une cinquantaine de postes sont √† pourvoir. Et si c‚Äô√©tait toi, notre prochain fulller ? Qui cherchons-nous ? En tant que Data Engineer, vous avez la charge de la mise en place des pipelines d‚Äôint√©gration et de traitement de donn√©es pour pouvoir d√©velopper de nouveaux algorithmes de machine learning. Vous avez aussi la charge du maintien et de la mise √† jour de notre data lake et de nos nombreux ETL (Extract-Transform-Load). Vous travaillez main dans la main avec nos architectes et data scientists pour mettre en place la gestion des donn√©es pour nos futurs produits. Vous avez pour objectif de rendre nos outils proactifs, de guider le chef d‚Äôentreprise dans ses d√©cisions, gr√¢ce √† l‚Äôanalyse d‚Äôun ensemble de donn√©es (non) structur√©es et multisources. Vous pourrez voir l‚Äôimpact de votre travail sur des centaines de milliers de clients et contribuer de fa√ßon agile √† l‚Äôensemble de notre portfolio de services. Quel sera votre quotidien ? Concevoir et d√©velopper des preuves de concepts en r√©ponse √† des besoins clients Appuyer les √©quipes techniques dans l‚Äôimpl√©mentation de nouvelles fonctionnalit√©s Traduire des probl√®mes business en sch√©ma de donn√©es efficaces et scalables Mise en place de stack de transport et traitement de donn√©es comme source pour nos nouvelles applications Mise en production de ces pipelines et monitoring pour un impact direct sur des milliers de clients Explorer et donner du sens aux nombreuses sources de donn√©es que nous traitons sur les entreprises clientes de Fulll Participation au rayonnement technique de l‚Äô√©quipe Quels seront vos avantages ? Toutes les 5 semaines : des workshops Du bon caf√© gratuit pour bien travailler Des corbeilles de fruits pour faire le plein de vitamines Des participations aux conf√©rences qui comptent (React Europe, Devoxxx, ‚Ä¶) Des horaires am√©nag√©s et du remote (3 jours par semaine) Une carte Swile Quelles sont les qualit√©s requises ? En tant que Data Engineer, vous avez un minimum de deux ans d‚Äôexp√©rience de d√©veloppement data ops et Big Data, et de mise en production des pipelines. Vous avez de l‚Äôexp√©rience dans la cr√©ation d‚ÄôAPI et le datamining. Vous avez m√™me peut-√™tre contribu√© √† am√©liorer un ou plusieurs projets open source. Vous ma√Ætrisez SQL et python et vous avez de l‚Äôexp√©rience de la gestion de donn√©es non structur√©es comme structur√©es √† grande √©chelle. Vous prenez soin de cr√©er un code propre et performant, utilisant de fa√ßon efficace les concepts de data structure/pattern. Vous √™tes capable d‚Äôexpliquer avec des mots simples vos choix techniques. Vous ma√Ætrisez l‚Äôanglais et pouvez lire des articles scientifiques en anglais. Une exp√©rience avec les services AWS et infrastructures As code (Terraform) serait un atout. Bref, vous l‚Äôaurez s√ªrement compris, nous ne sommes pas des inconditionnels du CV et des process lourds, on pr√©f√®re avant tout les humains qui peuvent contribuer √† faire grandir notre √©quipe. Ainsi, le process se compose en 3 √©tapes : 1er entretien avec notre charg√©e de recrutement Tests techniques 2e entretien avec deux personnes de l‚Äô√©quipe Data","Fulll is seeking a Data Engineer to set up integration and data processing pipelines for creating new machine learning algorithms. The role involves maintaining and updating the data lake and ETL tools, building data management systems for future products, and collaborating with architects and data scientists. Candidates must have at least two years of experience in data ops, Big Data development, and pipeline production while having expertise in SQL, Python, and managing structured and unstructured data at scale. The position comes with a range of benefits like flexible hours and work from home, English fluency, and experience with AWS and infrastructure as code (Terraform).",Bac +3,Entre 50 et 250 salari√©s,> 2 ans,1,1,0.027697749441558416
107,72939,https://www.welcometothejungle.com/fr/companies/orange-1/jobs/cloud-data-engineer-confirme-f-h_lyon-6eme-arrondissement,Cloud Data Engineer - Confirm√©(e),Orange,"{Python,Scala,QlikView,Azure,durable,PowerBi,Tableau,JAVA,AWS,GCP}",T√©l√©travail ponctuel autoris√©,"Lyon - 6√®me Arrondissement, 69006","Objets connect√©s, Big Data, Electronique / T√©l√©communications",CDI,2023-04-22,"Nous sommes une entreprise de services digitaux n√©e du r√©seau, reconnue en France et √† l‚Äôinternational pour notre capacit√© √† transformer les infrastructures digitales de nos clients. En tant qu‚Äôentreprise de services num√©riques, les comp√©tences et l‚Äôexpertise de nos 29 000 collaborateurs sont au coeur de notre mod√®le √©conomique, √©thique, responsable et inclusif. Nous offrons des opportunit√©s passionnantes gr√¢ce √† des projets innovants et valorisants dans les domaines de l‚ÄôIoT, du cloud, du digital, du big data, de l‚Äôintelligence artificielle, de la cybers√©curit√© et du digital workspace. En travaillant ensemble dans une culture o√π chaque voix est entendue, nous aidons les individus √† cr√©er un impact positif et √† offrir une croissance durable √† nos clients. Au sein de Business & Decision, vous interviendrez sur diff√©rentes missions en tant que Consultant(e) : - L‚Äô√©tude, l‚Äôanalyse et le cadrage des besoins m√©tiers - Analyse des donn√©es sources afin d‚Äôidentifier les cas d‚Äôusages m√©tiers - Conception et mise en place de solutions r√©silientes et s√©curis√©es (Data Lake, pipeline, syst√®mes temps-r√©els, base de donn√©es‚Ä¶) - Migration fiable et maitris√©e des donn√©es vers les nouveaux environnements Cloud - Veille technologique pour √™tre √† la pointe sur les solutions cloud & Data Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieurs ou d‚Äôun Master 2 en Informatique ou √©quivalent, vous avez une exp√©rience significative sur des projets Data : architecture, mod√©lisation, traitement ou analyse de donn√©es, automatisation et outillage DevOps. Vous maitrisez au moins un des langages de programmation suivants : Python, JAVA, Scala. Vous √™tes passionn√©(e) par le Cloud. Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale. L‚Äôobtention de la certi_cation Data Engineer (Azure, AWS, GCP), est un vrai plus ! La connaissance d‚Äôau moins un outil de suivi et visualisation (PowerBi, Tableau, QlikView‚Ä¶) est √©galement un plus !",,Bac +5 / Master,> 2000 salari√©s,> 2 ans,1,1,0.027697749441558416
319,56371,https://www.welcometothejungle.com/fr/companies/gatewatcher/jobs/developpeur-data-engineer-h-f_puteaux,Data Engineer,Gatewatcher,"{Go,Kibana,Linux,SQL,Python}",T√©l√©travail ponctuel autoris√©,"5, Rue Bellini, Puteaux, 92800",Cybers√©curit√©,CDI,2023-03-26,"Leader technologique de la d√©tection d‚Äôintrusions et de menaces avanc√©es, Gatewatcher prot√®ge depuis 2015 les r√©seaux critiques des plus grandes entreprises comme des institutions publiques, en France et √† l‚Äôinternational. Fort d‚Äôun r√©seau de partenaires certifi√©s pour accompagner nos clients les plus exigeants, Gatewatcher se d√©ploie en Europe, mais aussi au Moyen Orient, en Asie et en Afrique Francophone. Notre vision est d‚Äôoffrir une approche flexible (cloud, sur site, hybride), innovante et ouverte √† l‚ÄôIA, sans perturber l‚Äôarchitecture en place pour permettre aux √©quipes cybers√©curit√© une meilleure efficacit√© dans la priorisation de leurs actions de rem√©diation. Nos solutions apportent une am√©lioration imm√©diate aux enjeux actuels et futurs de cybers√©curit√© par une r√©ponse adapt√©e aux nouveaux besoins de d√©tection des organisations. Elles combinent des algorithmes d‚Äôapprentissage automatique avec diff√©rentes m√©thodes d‚Äôanalyse du trafic r√©seau et sont con√ßues pour √™tre √©volutives et imm√©diatement op√©rationnelles pour une int√©gration facilit√©e dans les SOC (Security Operations Center). Chez Gatewatcher, nous vous proposons d‚Äô√©voluer dans un environnement stimulant au sein d‚Äôune √©quipe pluridisciplinaire de haut niveau d‚Äôexperts en s√©curit√©, syst√®me, r√©seau, chiffrement et machine learning. Nos collaborateurs sont des passionn√©s et aiment partager leurs connaissances au quotidien. Nos bureaux sont situ√©s au Campus Cyber au c≈ìur du quartier de la D√©fense, soit l‚Äôendroit id√©al pour s‚Äô√©panouir et prendre part √† un √©cosyst√®me dynamique autour de la cybers√©curit√©. Nous recherchons actuellement Data Engineer en CDI , pour accompagner l‚Äôhyper-croissance de nos produits en France et √† l‚Äôinternational. Vos missions : Am√©lioration des pipelines de donn√©es et optimisation des BDD Mise en place d‚Äôoutils de benchmark Dashboarding Kibana Environnement technique : Linux Python 3 SQL Go Dipl√¥m√©(e) d‚Äôun Master en informatique Exp√©rience de 2 ans minimum en tant que Ing√©nieur Data Comp√©tent sur un environnement Linux Ma√Ætrise de SQL, Python 3, ELK ou une techno similaire Ma√Ætrise de Go appr√©ci√© Passionn√©(e), force de proposition et autonome Pourquoi nous rejoindre ? Soci√©t√© en hyper-croissance D√©couvrir ou peaufiner ses comp√©tences en cybers√©curit√© au contact d‚Äôune expertise pluridisciplinaire reconnue Afterwork, team building et baby-foot avec des √©quipes de passionn√©s Flexibilit√© sur le sujet du t√©l√©travail Entretien RH en visio (test) Entretien Technique en visio Entretien avec la Direction dans nos locaux","Gatewatcher, a technology leader in intrusion detection and advanced threat protection, is seeking a Data Engineer with minimum of 2 years experience working with Linux, Python 3, SQL and ELK or similar technologies. They are looking for someone who is passionate, independent, and a proposal force to join their highly skilled security experts team. With an emphasis on flexible, innovative, AI-driven approaches maintaining pre-existing architecture, the company works to provide immediate and lasting solutions for cyber-security challenges ranging from database optimization to bench-marking, all in the context of a highly collaborative work environment.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 2 ans,1,1,0.027697749441558416
165,63013,https://www.welcometothejungle.com/fr/companies/le-pont/jobs/data-engineer-poei_levallois-perret,Data Engineer - POEI,Le Pont,"{Java,Scala,Python,SPARK}",T√©l√©travail ponctuel autoris√©,Levallois-Perret,N,CDI,2023-03-31,"Acteur multi-sp√©cialiste en transformation digitale avec 960 collaborateurs, conseil m√©tier et conseil en technologies, Audensiel accompagne ses clients de tout secteur d‚Äôactivit√© en France et √† l‚Äôinternational dans les domaines suivants : Digital : projets de transformation digitale, de la direction de projets en m√©thode Agile en passant par l‚ÄôAMOA et le d√©veloppement d‚Äôapplications jusqu‚Äô√† la recette/test. Conseil : conseil IT au sein des DSI et conseil m√©tier au sein des directions fonctionnelles sp√©cifiquement pour la Banque, l‚ÄôAssurance et l‚ÄôIndustrie pharmaceutique dans leurs probl√©matiques de gouvernance, de conformit√© r√©glementaire, de gestion des risques et de transformation des directions financi√®res. Data/IA : Architecture et d√©veloppement de solutions Big Data avec des consultants Data Engineer et Data Scientists. D√©veloppement projets innovants d‚Äôintelligence artificielle de nos clients sous forme de POC. IoT : Exploitation des donn√©es des objets connect√©s et leurs traitements au sein de syst√®mes complexes interconnect√©s. Conception de l‚Äôensemble de la cha√Æne de valeur qui permet d‚Äôoffrir la meilleure exp√©rience utilisateur pour ces nouveaux services et d‚Äôoptimiser les gains de productivit√©. Cybers√©curit√© : Accompagnement sur la gouvernance des probl√©matiques de cybers√©curit√© de nos clients. Audit et gestion de projets pour la d√©fense et la s√©curit√© de donn√©es. - Cloud/DevOps : Accompagnement √† diff√©rents niveaux de votre projet, strat√©gie et gouvernance, architecture, d√©veloppement ou encore DevOps. Rejoignez AUDENSIEL en int√©grant la formation POEI ‚ÄúData Engineer‚Äù avec l‚Äôorganisme LePont 100% financ√©e par P√¥le Emploi afin d‚Äôacqu√©rir les comp√©tences cl√©s qui vous permettront d‚Äôaccompagner nos clients dans leur projet de transformation digitale et booster votre carri√®re en tant que Data Engineer. En tant que Data Engineer, vous intervenez sur diff√©rentes missions transverses : Proposer des architectures et orienter le choix des technologies adapt√©es aux besoins de diff√©rents projets Data Concevoir et mettre en ≈ìuvre les traitements d‚Äôalimentation du DataLake et de transformation des donn√©es Cr√©ation de pipelines de donn√©es, traitement et transformation de la donn√©e. Garantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats Identifier, collecter, explorer, comprendre et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnelles Assurer le suivi de la production 15 POSTES OUVERTS en CDI Villes : Lille, Evreux, Paris, Strasbourg, Rennes, Nantes, Tours, Niort, Bordeaux, Biarritz, Toulouse, Lyon, Aix en Provence, Sophia Antipolis **Vous √™tes inscrit(e) √† P√¥le Emploi. ** Issu(e) d‚Äôune fili√®re scientifique ou informatique vous disposez d‚Äôun Bac+4/5 ou dipl√¥me d‚Äôing√©nieur, vous disposez d‚Äôune exp√©rience significative en d√©veloppement informatique minimum. Hard Skills : Vous maitrisez un langage objet :Java/Python Notions compl√©mentaire en SPARK et ou Scala seraient un + Niveau d‚Äôanglais requis Soft Skills : Des qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√© L‚Äôesprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collective Vous passez un premier entretien avec LePont Vous passez un second entretien avec l‚Äôentreprise partenaire Votre dossier passe en commission d‚Äôadmission Si vous √™tes valid√©s par l‚Äôentreprise, vous d√©butez votre formation avec LePont Une fois la formation valid√©e, vous d√©butez votre CDI chez l‚Äôentreprise partenaire. Pour postuler : https://www.lepont-learning.com/fr/contact/inscription-poei/","Audensiel, a digital transformation company with 960 employees, is looking for Data Engineers to support diverse projects such as Digital, Consultancy, Data/IA, IoT, Cybersecurity, and Cloud/DevOps. The ideal candidate must have experience in Java/Python, and the knowledge of languages such as Spark and Scala is a plus. Candidates will need to attend an interview with LePont and the second interview with the hiring company before starting the training with LePont. Once the training is completed, candidates are eligible for a full-time position at the partnering company.",Bac +4,Entre 50 et 250 salari√©s,> 2 ans,1,1,0.027697749441558416
162,57091,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/engineer-analytics-h-f-poei_puteaux,Analytics Engineer  | POEI,Datascientest,"{UNIX,Python,LINUX}",T√©l√©travail ponctuel autoris√©,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"Vous cherchez la bonne opportunit√© pour booster votre carri√®re ? Cette offre d‚Äôemploi vous permet de d√©marrer votre carri√®re en tant que Analytique ing√©nieur, un m√©tier en tension et en plein essor. Une fois s√©lectionn√©(e), vous b√©n√©ficierez d‚Äôune formation 100% financ√©e par P√¥le Emploi d‚Äôune dur√©e de 3 mois afin de d√©velopper les comp√©tences d‚Äôun v√©ritable expert. Cette formation sera certifi√©e par l‚ÄôUniversit√© Paris 1 Panth√©on-Sorbonne. En tant que Analytics Engineer vous serez responsable des missions suivantes : D√©finir, mettre en place et ex√©cuter l‚Äôensemble des techniques en vue de la r√©alisation exp√©rimentale des projets. Traiter, analyser, interpr√©ter les donn√©es et valider les r√©sultats. R√©diger ou v√©rifier les protocoles et rapports en lien avec l‚Äôactivit√© D√©veloppement analytique. Communiquer avec le client sur les r√©sultats obtenues et les avanc√©s D√©velopper, optimiser et valider les m√©thodes d‚Äôanalyse des produits R√©diger ou v√©rifier les protocoles et rapports en lien avec l‚Äôactivit√© analytique Mener et/ou participer √† la r√©solution des probl√®mes afin d‚Äôy parvenir. Participer √† la veille technologique Dynamique, autonome et rigoureux(se), vous avez le sens du serviceclient ? Issue d‚Äôun Bac +3/5 en syst√®mes et r√©seaux ou Bac + 3/5 en Informatique Connaissance des syst√®mes d‚Äôexploitation Windows et/ou UNIX/LINUX Vous avez un bon niveau d‚Äôanglais Un plus : Vous avez des notions en Python. Vous √™tes inscrit(e) √† P√¥le Emploi. N‚Äôh√©sitez pas √† postuler ! Step 1 : Premier √©change avec DataScientest Step 2 : Entretien d‚Äôembauche avec notre entreprise partenaire, sp√©cialis√©e dans le conseil Step 3 : Si step 2 valid√© : Formation de 3 mois chez DataScientest Step 4 : D√©but des missions en CDI","This job offers a training opportunity to become an Analytics Engineer with skills in experimental project execution, data analysis, and communication with clients. Applicants should have a degree in systems and networks or computer science, knowledge of Windows and/or UNIX/LINUX, and a good level of English. Python skills are a plus. The position is open to candidates registered with P√¥le Emploi. The hiring process involves three steps: an initial conversation with DataScientest, an interview with the company's partner, a consulting firm, and a three-month training program at DataScientest before starting full-time employment.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,1,1,0.027697749441558416
352,56586,https://www.welcometothejungle.com/fr/companies/cenisis/jobs/data-engineer_lille,Data Engineer,CENISIS - Data Agency,"{NoSql,R,Cassandra,SQL,Python}",T√©l√©travail partiel possible,"149, Avenue de Bretagne, Lille, 59000","IT / Digital, Transformation",CDI,2023-03-26,"CENISIS, expert fran√ßais en Data Management, aide les entreprises √† tirer profit de leur Data, patrimoine pr√©cieux et √† en exploiter toute la richesse. Gr√¢ce √† ses collaborateur.rice.s, Cenisis a pour but d‚Äôinspirer l‚Äôinnovation de la Data. Rejoindre Cenisis, c‚Äôest rejoindre une entreprise qui place l‚Äôambition et le d√©veloppement national au c≈ìur de ses objectifs dans un environnement riche et stimulant. Nos √©quipes nous poussent √† l‚Äôexigence pour progresser dans la bienveillance ! L‚Äôentreprise incarne les valeurs port√©es par ses collaborateur.rice.s : üëâ L‚Äôaudace : Oser des choix inspirants et singuliers. Savoir prendre des risques et des initiatives au quotidien. üëâ L‚Äôauthenticit√© : Rester coh√©rent avec nos engagements. Favoriser la transparence et l‚Äôhonn√™tet√©. üëâ La coh√©sion : Partager nos richesses individuelles et collectives. Cr√©er une unicit√©. üëâ La responsabilit√© : Porter et assumer des ambitions durables. üéì Cenisis Academy, √©cole du Data Management en France, propose des formations adapt√©es √† la fois en interne et en externe √† tous les publics de l‚Äôentreprise. Tu souhaites rejoindre une communaut√© Data Addict √† taille humaine‚ÄØ? Nous recherchons un Data Engineer F/H qui aura un r√¥le √† part enti√®re dans la communaut√© CENISIS. Nous t‚Äôapportons l‚Äôopportunit√© d‚Äôintervenir sur un large choix de projets mais √©galement de faire partie de la CENISIS Academy. Tes missions‚ÄØ? G√©rer et mettre en place les structures n√©cessaires ainsi que les donn√©es de type big data pour permettre l‚Äôexploitabilit√© par les data scientists Permettre la collecte, le stockage et l‚Äôexploitabilit√© fluide des donn√©es Constuire les outils de collecte et d‚Äôanalyse de donn√©es (structur√©es et non structur√©es) Choisir la ou les m√©thode(s)/technologie(s) les plus adapt√©e Rejoindre CENISIS, c‚Äôest rejoindre une entreprise qui‚ÄØ: ‚ôüPositionne ses consultants au c≈ìur de la strat√©gie de transformation digitale üöÄ ‚ö°Ô∏èPermet √† ses collaborateurs d‚Äôavoir un r√©el impact, d‚Äôinnover, tester et construire notre avenir üí• üåèChoisit de porter des valeurs fortes et d‚Äô√™tre avanc√© au niveau social et environnemental avec une forte politique de diversit√© et d‚Äôinclusion #TeamRSE üçÉ üèü Anime des formations en interne et en externe #CENISISAcademy üìö Ce qui nous anime‚ÄØ? Nos valeurs bas√©es sur l‚Äôaudace, la coh√©sion, l‚Äôauthenticit√© et la responsabilit√© nous poussent √† l‚Äôinnovation et √† la croissance. Pour cela, en 2020, CENISIS a int√©gr√© l‚Äôacc√©l√©rateur BPI d√©di√© aux entreprises ambitieuses pour ainsi, devenir une Data Agency. En tant qu‚Äôentreprise engag√©e dans une d√©marche responsable, nous accordons une grande importance √† l‚Äôimpact du bien-√™tre personnel et collectif et √† l‚Äôengagement envers la diversit√©, l‚Äô√©quit√© et l‚Äôinclusion. Ton profil‚ÄØ? Tu es issu(e) d‚Äôune formation sup√©rieure Bac+3/5 de type licence ou master dans le domaine de l‚Äôing√©nierie avec une orientation Data. Id√©alement tu poss√®des une exp√©rience significative de 3 ans dans la Data. Ton savoir-√™tre‚ÄØ: Ta capacit√© √† f√©d√©rer une √©quipe et √† contribuer √† la r√©ussite de celle-ci dans ses diff√©rents projets Ta curiosit√©, ton envie de toujours innover, et ton autonomie Tu es force de proposition et tu aimes le challenge et challenger les autres Ta diff√©rence, ce qui fait ta force et ta richesse pour l‚Äôentreprise Ton savoir-faire‚ÄØ: Ton expertise √©lev√©e dans les technologies de manipulation des donn√©es Ta ma√Ætrise des technologies de base de donn√©es (NoSql, SQL, ‚Ä¶), Ta ma√Ætrise des technologies type Cassandra, Python, R, ‚Ä¶ Ta compr√©hension des probl√©matiques des datascientists Ta capacit√© √† mettre en musique des solutions dans une d√©marche DataOps Alors tu es partant(e) pour relever le d√©fi‚ÄØ? N‚Äôh√©site pas √† postuler, ce serait le d√©but d‚Äôune superbe aventure ensemble‚ÄØ! A comp√©tences √©gales, tous nos postes sont ouverts aux personnes en situation de handicap. Le processus de recrutement ? Premi√®re rencontre avec Marine, Human Resource Manager. Deuxi√®me √©change avec ton futur Manager, Laurence et/ou Laurent, Responsable Fondations Data ou J√©r√¥me, Responsable du P√¥le Data Insight. Troisi√®me √©change avec Gilles, Directeur Offres et Innovation et/ou C√©dric, Dirigeant.","CENISIS, a French Data Management company, is seeking a Data Engineer who will play a significant role in their community. The ideal candidate should have a Bachelor's or Master's degree in engineering with a data focus, at least three years of experience in the field, and strong expertise in data manipulation technologies. The Data Engineer will be responsible for managing and establishing the necessary structures and big data types for data scientists to exploit, collecting, storing and utilizing data, constructing data collection and analytics tools, choosing suitable methodologies/technologies, and contributing to team success. CENISIS is committed to being socially and environmentally responsible, and the recruitment process includes several meetings with key team members.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
113,34757,https://www.welcometothejungle.com/fr/companies/aphp/jobs/ingenieur-donnees-imagerie-medicale-projet-operandi_paris,Ing√©nieur Donn√©es - Imagerie M√©dicale (projet OPERANDI),Assistance Publique - H√¥pitaux de Paris - DSI,"{NVIDIA,Oracle,UNIX,bash,Hive,Nvidia,Docker,Postgresql,MySQL,gitlab,Kafka,Linux,Jenkins,Kubernetes,HBase,Hadoop,Jupyter,R,Spark,sql,Python}",T√©l√©travail ponctuel autoris√©,Paris,"Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDD / Temporaire,2022-08-08,"L‚Äô Assistance Publique - H√¥pitaux de Paris (AP - HP) est un √©tablissement public de sant√© et le centre hospitalier universitaire - CHU - de la r√©gion Ile-de-France, reconnu mondialement pour sa recherche. Le d√©partement Web Innovation Donn√©es (WIND) s‚Äôinscrit au sein de sa Direction des Syst√®mes d‚ÄôInformation. Sa mission ? üéØR√©aliser les projets num√©riques innovants au contact du monde hospitalier. Ses projets phares ? üöÄ Construire le plus large entrep√¥t public de donn√©es de sant√© en Europe ! Le projet vise √† valoriser les donn√©es produites √† l‚ÄôAP-HP pour la recherche, l‚Äôinnovation et le pilotage des soins, tout en prot√©geant les donn√©es patient. L‚ÄôEntrep√¥t de Donn√©es de Sant√©, c‚Äôest d√©j√† +8 millions de patients dont les donn√©es sont structur√©es et r√©f√©renc√©es sur une plateforme Big Data d√©di√©e. üôã‚Äç‚ôÄÔ∏èüôã‚Äç‚ôÇFaciliter le quotidien des patients! Le domaine g√®re notamment toutes les applications mobiles et tous les t√©l√©services de l‚ÄôAP-HP. üî¨Monter une plateforme Bio-Informatique centrale pour assister les p√¥les de biologie de l‚Äô AP-HP dans leurs besoins informatiques (gestion du s√©quen√ßage, d√©ploiement de ressources de calcul). üåºD√©velopper et d√©ployer au niveau national les outils de collecte et d‚Äôanalyse √©pid√©miologique des donn√©es relatives aux maladies rares. La mission de votre √©quipe Afin de permettre le d√©veloppement de projets de recherche innovants, en particulier dans le domaine de l‚Äôintelligence artificielle, l‚ÄôAP‚ÄìHP a mis en place une plateforme Big Data, infrastructure informatique propre, int√©grant des capacit√©s de stockage et de calcul pour l‚Äôexploitation s√©curis√©e et performante des donn√©es de sant√© dont elle est d√©positaire. Cette plateforme h√©berge notamment l‚Äôentrep√¥t de donn√©es de sant√© (EDS) de l‚ÄôAP-HP. ‚Äã L‚ÄôEntrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP int√®gre des donn√©es administratives et m√©dicales de plus de 8 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (20 millions de dossiers m√©dicaux, plus de 10 millions de diagnostics, 181 millions de r√©sultats de laboratoires‚Ä¶). Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision. ‚Äã La Plateforme Big Data de l‚ÄôAP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d‚Äôespace disque), de machines GPU (24 Nvidia P40, 12 NVIDIA V100), de 10 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es, et de nombreuses autres machines applicatives. ‚Äã Votre √©quipe, le domaine ¬´ Plateforme Big Data ¬ª, a pour mission l‚Äôint√©gration des donn√©es de sant√© massives et complexes (donn√©es structur√©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation √† grande √©chelle, de mani√®re performante, ergonomique et s√©curis√©e dans le respect des principes et r√®gles de gouvernance des donn√©es d√©finis par l‚ÄôAP-HP. Dans le domaine de l‚Äôimagerie m√©dicale, les images sont majoritairement produites dans les plus de 20 services de radiologie de l‚ÄôAPHP et stock√©s dans un PACS Centrale APHP, g√©r√© par le p√¥le imagerie de la DSI. Vos missions Au sein de l‚Äô√©quipe en charge de la Plateforme m√©gadonn√©es de l‚ÄôAPHP, vous serez recrut√© dans le cadre du projet OPERANDI. Le projet OPERANDI, Optimisation et am√©lioration de l‚Äôefficacit√© des th√©rapies cibl√©es par radionucl√©ides dans les cancers digestifs par imagomics, coordonn√© par le Pr Val√©rie Vilgrain, est laur√©at de l‚Äôappel √† projet Recherche Hospitalo-Universitaire en sant√© (RHU) ‚Äì Appel √† projets ‚Äì vague 5 ‚Äì 2021. Le projet OPERANDI vise √† l‚Äô√©laboration d‚Äôalgorithmes d‚Äôintelligence artificielle bas√©s sur l‚Äôimagerie multi-√©chelle pr√©dictive et pronostique, au d√©veloppement d‚Äôune approche holistique de la th√©rapie guid√©e simultan√©ment par TEP-IRM, au d√©codage des ph√©nom√®nes de radio-r√©sistance et de r√©ponse tumorale aux traitements et √† l‚Äô√©valuation de nouvelles combinaisons de m√©dicaments et radiopharmaceutiques, ceci dans le but d‚Äôam√©liorer la s√©lection, le traitement et le suivi des patients. Vous serez directement int√©gr√© dans l‚Äô√©quipe Imagerie de la plateforme m√©gadonn√©es. Tout en b√©n√©ficiant de l‚Äôensemble des expertises et comp√©tences de la plateforme m√©gadonn√©es, vous devez compl√©ter et mettre en ≈ìuvre l‚Äôensemble des composants n√©cessaire √† la collecte et l‚Äôexploitation des donn√©es d‚Äôimageries pr√©vues dans le projet RHU OPERANDI. Cela sera r√©alis√© au travers de d√©veloppements sp√©cifiques, d‚Äôint√©gration d‚Äôoutils pr√©-existants et libres ainsi que d‚Äôoutils et logiciels mis √† disposition par les partenaires acad√©miques ou industriels du projet. Afin d‚Äôaccompagner au mieux la r√©alisation du projet, vous serez en charge de mettre en ≈ìuvre le suivi et le cadrage du projet technique en interagissant avec les m√©decins, chercheurs, industriels, ing√©nieurs, data-scientist du projet. Vous intervenez dans le cadre de groupes de travail pluridisciplinaires visant la d√©finition de nouvelles fonctionnalit√©s et vous r√©aliserez le test et la validation des nouvelles fonctionnalit√©s impl√©ment√©es avant leur mise en production. Par ailleurs, vous participez √† l‚Äôassistance √† la mise en ≈ìuvre et √† la maintenance en condition op√©rationnelle des outils d√©velopp√©s. En tant que data engineer sp√©cialis√© en imagerie m√©dicale, vous : R√©diger des cahiers des charges, sp√©cifications fonctionnelles et techniques ainsi que des dossiers d‚Äôarchitecture technique ; Concevoir et d√©velopper des outils (s√©lection de cohortes de patients, mod√©lisation, algorithmes d‚Äôanalyse, m√©thodes statistiques, visualisation, etc.) adapt√©s au contexte du cluster big data ; Contribuer √† la mise en place de pipelines de traitement et d‚Äôanalyse de donn√©es d‚Äôimagerie m√©dicales radiologiques (DICOM) et anatomocytopathologies (Lame virtuelle); Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark) ; R√©diger la documentation technique ainsi que la documentation utilisateur ; Dans le cadre des d√©veloppements r√©alis√©s en Open Source, participer √† l‚Äôanimation de la communaut√© autour des projets cr√©√©s par la r√©solution de bugs, la gestion des suggestions de modification du code (Pull/Request) ou encore la gestion des propositions d‚Äôam√©liorations ; Intervenir sur la conception d‚Äôoutils pour l‚Äôannotation de donn√©es m√©dicales d‚Äôimagerie, textuelles, physiologiques et autres, et ce, afin de permettre aux chercheurs d‚Äôentra√Æner des mod√®les de Machine Learning/Deep Learning en lien avec l‚Äô√©mergence de l‚ÄôIntelligence Artificielle √† l‚ÄôAP-HP ; Assurer la s√©curisation des applications ou outils d√©velopp√©s ; R√©aliser une veille technique dans son domaine d‚Äôactivit√© et un transfert de comp√©tence au sein de l‚Äô√©quipe. Vous avez un savoir faire dans un de ces domaines : Expertise en Programmation Informatique (Windows & UNIX) Bonne ma√Ætrise des langages Python/R et de bash Ma√Ætrise des architectures et de l‚Äô√©cosyst√®me Big Data (Hadoop, Hive, HBase, Spark, Kafka, ‚Ä¶) Bonnes connaissances des bases de donn√©es Oracle, Postgresql ou MySQL et langages associ√©s (sql) Bonne ma√Ætrise des donn√©es d‚Äôimagerie m√©dicales radiologiques (DICOM, NIFTI ‚Ä¶) Bonne ma√Ætrise des donn√©es d‚Äôimagerie m√©dicales anatomocytopathologiques (SVS, NDPI, MRXS, ‚Ä¶) Connaissance approfondie en m√©thodes de d√©veloppement logiciel (m√©thodes agile), m√©thodes d‚Äôanalyse et de mod√©lisation (Kanban, UML ‚Ä¶) Connaissance des m√©thodologies devops et des outils associ√©s (Docker, Kubernetes, Jenkins‚Ä¶) Connaissance des outils de versionning (gitlab Connaissance des outils d‚Äôint√©gration & de d√©ploiement continue (CI/CD) Connaissances en m√©thode de conduite de projet (planification, reporting, analyse de risques, ‚Ä¶) Id√©alement, vous avez des connaisances ‚Ä¶ du mod√®le de donn√©e OMOP et du standard d‚Äôinterop√©rabilit√© HL7-FHIR en administration d‚Äôenvironnements Linux des probl√©matiques fonctionnelles hospitali√®res (structures, processus) et des m√©tiers de la sant√© en droit des donn√©es informatiques des bonnes pratiques de s√©curit√© informatique ; de la r√©glementation informatique et libert√©s ; Et une exp√©rience concernant le travail en √©quipe, Concevoir et √©valuer un projet / un processus relevant de son domaine de comp√©tence ; Identifier, analyser, prioriser et synth√©tiser les informations relevant de son domaine d‚Äôactivit√© ; Animer / communiquer / motiver au sein d‚Äôune √©quipe projet ; Capacit√© √† animer des r√©unions courtes, en imposant une pr√©paration et un compte rendu ; R√©diger et mettre en forme des notes, documents et /ou rapports, relatifs √† son domaine de comp√©tence ; Concevoir et r√©diger une documentation sp√©cifique √† son domaine de comp√©tence ; S‚Äôexprimer en public ; Au travers de 2 √† 3 entretiens vous √©changerez avec diff√©rents chefs de projets et le directeur de la plateforme","L'AP-HP, un centre hospitalier universitaire de renomm√©e mondiale, cherche un data engineer sp√©cialis√© en imagerie m√©dicale pour rejoindre leur √©quipe Plateforme Big Data. Le candidat sera charg√© de concevoir et d√©velopper des outils pour la collecte et l'analyse de donn√©es d'imageries pr√©vues dans le projet RHU OPERANDI. La personne id√©ale doit avoir des connaissances en programmation informatique, en √©cosyst√®me Big Data, en donn√©es d'imagerie m√©dicale, en m√©thodes de d√©veloppement logiciel et de conduite de projet, ainsi que des connaissances en s√©curit√© informatique et en r√©glementation informatique.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,1,1,0.027697749441558416
324,56541,https://www.welcometothejungle.com/fr/companies/fabernovel/jobs/data-engineer-marketing_paris_FABER_zxr4wmK,Data Engineer (Marketing),FABERNOVEL,"{Scala,SQL,Python,noSQL}",T√©l√©travail ponctuel autoris√©,"46 rue Saint Lazare, Paris, 75009","IT / Digital, Strat√©gie, Transformation, Formation",CDI,2023-03-26,"Cr√©√© en 2003 au c≈ìur de l‚Äô√©cosyst√®me num√©rique fran√ßais, Fabernovel na√Æt d‚Äôune conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure. Aujourd‚Äôhui, ce sont 350 talents, sur 4 continents, experts du conseil en transformation num√©rique et de la cr√©ation de produits et de services num√©riques. Nous ma√Ætrisons les expertises li√©es au design, aux technologies, au marketing et aux cultures nouvelles dans l‚Äôentreprise et accompagnons de grandes entreprises de tous secteurs d‚Äôactivit√© dans leur projet de transformation digitale et culturelle. Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Analysts, Product Managers, Media Specialists, Finance Managers, DevOps, Communication Managers, Business Developers‚Ä¶ qui font na√Ætre l‚Äôinnovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de m√©thodologies √† la pointe, avec toujours l‚Äôobjectif de les rendre le plus autonome possible. Rattach√©(e) au p√¥le Marketing de l‚Äôagence et √† l‚Äô√©quipe Tech, vous √™tes garant du d√©veloppement d'architectures et flux Data, de la collecte multi-sources de donn√©es, du pilotage et de la pertinence de ces donn√©es. Vos missions : Analyser les besoins d‚Äôinfrastructure des donn√©es du client pour proposer la solution la plus pertinente : Data Warehouse, Database etc. Concevoir, construire et mettre en production des solutions d‚Äôextraction, de transformation et de chargement des donn√©es (ETL) Cr√©er, automatiser, g√©rer et maintenir des flux de donn√©es Assurer la qualit√© et l‚Äôaccessibilit√© de la donn√©e pour qu‚Äôelle soit facilement exploitable par les experts Fabernovel et les clients. Trouver et mettre en place la meilleure solution d‚Äôarchitecture bas√©e sur le besoin, la nature / volum√©trie de la donn√©e et l‚Äôenvironnement du SI du client. Assurer la maintenance de projets internes et des missions clients. Assister les experts Fabernovel et nos clients dans la mise en place d‚Äôun socle data robuste et fiable (outils de webanalyse, dashboarding, ETL), √† travers l‚Äôaudit des dispositifs de mesure, la proposition de solutions techniques adapt√©es et l'exploration de techniques d‚Äôautomatisation / de nettoyage de la donn√©e (redressement, enrichissement‚Ä¶) Faire de la veille active (tendances march√©s, solutions innovantes) pour mieux conseiller nos clients ou participer √† la r√©daction d‚Äô√©tudes de cas / livres blancs en support des √©quipes communication et commerciales de l‚Äôagence. Assurer la transmission et le partage de connaissance √† ses pairs. Profil recherch√© Dipl√¥m√© d‚Äôune √©cole d‚Äôing√©nieur, d‚Äôun Master en ing√©nierie informatique ou √©quivalent. A au moins 1 an d'exp√©rience en data engineering A d√©j√† √©volu√© sur un environnement Cloud PaaS, IaaS (Google, Amazon...) Ma√Ætrise la programmation en Python et / ou Scala A une bonne connaissance du Web en g√©n√©ral, et des probl√©matiques data engineering en particulier Est √† l'aise avec le Data processing Dispose de bonnes connaissances en SQL, noSQL & est familier avec au moins un ETL ou √©quivalent A une connaissance des outils de data management (webanalyse, data viz, DMP,...) Est rigoureux, organis√©, pragmatique et curieux Ma√Ætrise l‚ÄôAnglais technique Fait preuve d‚Äôaisance r√©dactionnelle et relationnelle Une certification Google Cloud Platform est un plus Ce que nous offrons √† tous nos talents Des projets riches et impactants, chez Fabernovel nous transformons les environnements, les situations, avec nos propres m√©thodes et secrets de fabrication. Une soci√©t√© apprenante ou nous avons con√ßu notre propre Learning development factory pour un partage de connaissance et un apprentissage continue. Un management fond√© sur la bienveillance, il n‚Äôy a pas d‚Äô√©chec, seulement des it√©rations et des occasions d‚Äôapprendre. De la libert√© dans ses choix : Flex office, horaires am√©nageables, possibilit√© de remote, culture de l‚Äôintrapreunariat. Des avantages toujours sympa, avec des locaux au coeur de Paris, des paniers fruits, du caf√©/th√©, des salles de jeux techs et low techs, ainsi que des salles de siestes. Mais aussi‚Ä¶ Une Carte Swile prise en charge √† 60% par Fabernovel Acc√®s √† des offres privil√®ges Classpass Remboursement de 50% des transports RTT PC ou MacBook √Ä propos de nous : Cr√©√© en 2003 au c≈ìur de l‚Äô√©cosyst√®me num√©rique fran√ßais, Fabernovel na√Æt d‚Äôune conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure. Aujourd‚Äôhui, ce sont 350 talents, sur 3 continents, experts du conseil en transformation num√©rique et de la cr√©ation de produits et de services num√©riques. Nous ma√Ætrisons les expertises li√©es au design, aux technologies, au marketing et aux cultures nouvelles dans l‚Äôentreprise et accompagnons de grandes entreprises de tous secteurs d‚Äôactivit√© dans leur projet de transformation digitale et culturelle. Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Analysts, Product Managers, Media Specialists, Finance Managers, Communication Managers, Business Developers‚Ä¶qui font na√Ætre l‚Äôinnovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de m√©thodologies √† la pointe, avec toujours l‚Äôobjectif de les rendre le plus autonome possible. Fabernovel s‚Äôengage √† accorder la m√™me consid√©ration √† toutes les candidatures, sans distinction discriminatoire. L‚Äôinclusivit√© fait partie de nos valeurs et nous souhaitons faire vivre la m√™me exp√©rience √† tou.te.s","Fabernovel, a digital transformation company with 350 employees across four continents, is seeking a data engineer with experience in cloud environments such as Google Cloud Platform or Amazon Web Services. The successful candidate will have knowledge of data management tools, programming in Python and/or Scala, and data processing. Other requirements include a master's degree in computer engineering, a good level of English, and the ability to work well in a team. Fabernovel offers a positive, learning-based workplace culture, flexible hours, and remote working options, as well as other perks.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 1 an,1,1,0.027697749441558416
141,56521,https://www.welcometothejungle.com/fr/companies/datapy/jobs/data-engineer-spark-scala_paris,Data Engineer  SPARK et python ou SCALA,Datapy,"{GCP,python,Jenkins,Scala,GitLab,Kubernetes,AWS,Docker,via,Spark,Azure,Hadoop}",T√©l√©travail partiel possible,"94, Rue Saint-Lazare, Paris, 75009",IT / Digital,CDI,2023-03-26,"La donn√©e et la technologie sont des leviers majeurs pour rendre le monde meilleur. Les donn√©es sont devenues une ressource centrale des entreprises. DataPy industrialise leur traitement et le d√©veloppement des applications qui les utilisent. DataPy accompagne ses consultants et ses clients avec des valeurs socialement et √©cologiquement responsables. La mission consiste en la construction de bout en bout d applications permettant d‚Äôexploiter des donn√©es: Cadrage de la question, des besoins et de la probl√©matique Ingestion des donn√©es depuis les syst√®mes existants Mod√©lisation et transformation de donn√©es via Spark D√©veloppement, d√©ploiement et optimisation de jobs Spark Cr√©ation des tables, analyse et recherche d informations dans les bases de donn√©es D√©veloppement des reportings et outils d analyse et visualisation des donn√©es Utilisation de technologies et m√©thodes de DevOps pour industrialiser les projets Stack technique: Spark Langage: Scala, python Infrastructure selon le contexte du client : Hadoop, Azure, AWS ou GCP, avec souvent des projets de migrationCI/CD et Devops: Terraform, Ansible, Jenkins, Azure Devops, GitLab, JUnit, Sonarqube, Kubernetes, Docker Dans le cadre de cette mission, vous serez amen√© √† d√©velopper vos comp√©tences sur les technologies de CI/CD et de devops. Data Engineer, avec a moins minimum 3 ans d‚Äôexp√©rience confirm√©e sur Spark et Scala . Les qualit√©s humaines requises: Force de proposition, Rigueur, R√©activit√©, Esprit analytique et de synth√®se, Esprit d √©quipe, Excellent relationnel, Sens de l organisation, Sens de la qualit√© Le processus de s√©lection comprend un entretien avec un responsable Datapy, un entretien avec notre client permettant de pr√©ciser finement la mission, et √©ventuellement un test technique auquel vous pourrez vous pr√©parer.","DataPy is seeking a Data Engineer with at least 3 years of confirmed experience in Spark and Scala to develop end-to-end applications for exploiting data in socially and environmentally responsible ways. The role involves framing questions and requirements, ingesting data, modeling and transforming data using Spark, developing Spark jobs, creating tables and analyzing databases, and developing reporting and analysis tools. The job requires proficiency with DevOps and CI/CD technologies such as Terraform, Ansible, Jenkins, Azure Devops, GitLab, JUnit, Sonarqube, Kubernetes, and Docker. The ideal candidate should possess qualities such as proposal strength, rigor, agility, analytical and synthetic thinking, teamwork, excellent relationship skills, organizational skills, and quality awareness.",Bac +5 / Master,N,> 3 ans,2,0,0.027697749441558416
301,56980,https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer-confirme-h-f_neuilly-sur-seine,Data Engineer Confirm√©.e,LittleBigCode,"{GCP,Scala,AWS,via,R,Azure,SQL,Python}",T√©l√©travail partiel possible,"7 Rue de Chartres, Neuilly-Sur-Seine, 92200","Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"LittleBigCode est un laboratoire de conseil digital sp√©cialis√© dans la conception d‚Äôapplications d‚ÄôIntelligence Artificielle et de plateformes Big Data. Leur mission est de contribuer √† d√©mocratiser l‚Äôusage de ces technologies en construisant avec leurs clients des solutions utiles et profitables pour la soci√©t√© de demain. Dans les faits, ils permettent √† leurs clients (soci√©t√©s du CAC40, ETI, PME et startup) de valoriser leurs donn√©es en la rendant exploitable sur le Cloud. Puis, ils la rendent intelligible via l‚Äôindustrialisation de mod√®les d‚ÄôIntelligence Artificielle orient√©s ¬´ Aide √† la d√©cision ¬ª ou ¬´ Automatisation ¬ª. Pour cela, ils d√©livrent des applications cl√©s en main et d√©veloppent √©galement leurs propres solutions tout en intervenant sur des missions de conseil. Nous cherchons √† renforcer notre √©quipe technique gr√¢ce √† un profil Data Engineer ! Concr√®tement au quotidien, tu travailleras en mode agile et en √©quipe (compos√©e de Data Scientist, d‚Äôarchitectes, de coach Devops ‚Ä¶). Quel sera ton r√¥le chez nous ? Tu interviendras sur les activit√©s et probl√©matiques suivantes : Conseil et expertise aupr√®s de nos clients sur leurs projets strat√©giques : Mod√©lisation, Conception & Delivery Formation, accompagnement & animation : Formation et accompagnement des √©quipes dans leur mont√©e en comp√©tences Organisation & Animation des communaut√©s et des Tech-Events (Workshops, Challenge interne, Hackaton ‚Ä¶) R√©daction des articles R&D et Solutions : Participation au d√©veloppement de solutions internes Proposition et cr√©ation de solutions innovantes Avant-vente : Participation aux appels d‚Äôoffres R√©alisation de POC Tu es dipl√¥m√©.e d‚Äôune grande √©cole d‚Äôing√©nieur en math√©matique, statistique ou informatique et tu as au moins 3 ans d‚Äôexp√©rience ! N‚Äôoublie pas que nous recherchons un profil confirm√© pour ce poste ce qui signifie que tu dois maitriser ton environnement technique ! Tu es solide sur les concepts de mod√©lisation et structuration de donn√©es. Tu ma√Ætrises l‚Äôindustrialisation de pipelines d‚Äôingestion et la mise en production de mod√®les Data Sciences. Tu ma√Ætrises parfaitement les langages : Python, SQL (si possible Scala) et tu sais d√©livrer un code propre facilement maintenable et industrialisable. Tu sais parfaitement utiliser l‚Äôune des plateformes suivantes : Azure, GCP, AWS et connais √©galement bien les diff√©rentes typologies de Base de donn√©es. Tu es robuste sur la mise en place et l‚Äôutilisation d‚ÄôETL. Si en plus tu as une exp√©rience les environnements de donn√©es √† haut volume ‚Ä¶ ‚Ä¶ Alors n‚Äôattends plus et viens rencontrer notre LittleBigTeam !","LittleBigCode is seeking a Data Engineer to join their team of Agile developers. The ideal candidate would have at least three years of experience working in a mathematical, statistical, or IT field, as well as solid knowledge of data structuring and modeling concepts, pipeline data ingestion, and data science model production. Additionally, the candidate should be proficient in Python, SQL, and one of the following platforms: Azure, GCP, or AWS.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
294,56885,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-semarchy-xdi-stambia-h-f_tours,Expert.e technique ETL Semarchy xDI / Stambia,CGI,{},T√©l√©travail partiel possible,"Tours, 37000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Semarchy xDI / Stambia. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Semarchy xDI / Stambia ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Semarchy ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√©.e d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert.e technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global leader in digital consulting and services, seeks an experienced technical expert in data integration and ETL using Semarchy xDI/Stambia. The role involves improving the efficiency and effectiveness of solutions, collaborating with engineers to find technical solutions, contributing to technical documentation, providing training, and participating in pre-sale and recruitment activities. The successful candidate will have at least three years of experience in digital services or consulting, a passion for teamwork and learning, and an audacious and ambitious spirit. Knowledge of data quality and governance is desirable, and CGI is an inclusive employer that promotes career development and well-being for all employees.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
326,52913,https://www.welcometothejungle.com/fr/companies/helloasso/jobs/database-administrator_begles,Data Engineer,HelloAsso,"{Python,nosql,Snowflake,Synapse,Kafka,sql,SQL,SISense,Tableau}",T√©l√©travail partiel possible,"2, Rue Marc Sangnier, B√®gles, 33130","FinTech / InsurTech, √âconomie collaborative",CDI,2023-03-20,"Notre mission est d‚Äôapporter la meilleure innovation technologique aux acteurs de l‚Äôinnovation sociale üöÄ üèÜHelloAsso est la solution de paiement leader du secteur associatif. Depuis 2009, nous avons accompagn√© +215 000 organismes √† collecter 850 millions d‚Äôeuros gr√¢ce √† nos services. Nous faisons partie de ces pionniers qui se sont appuy√©s sur la tech pour jouer un r√¥le positif sur la soci√©t√© ‚ö°Ô∏è Et pour concr√©tiser cette vision nous nous appuyons sur un mod√®le vertueux unique en France : HelloAsso est 100% gratuit pour les associations et financ√© librement par les internautes qui souhaitent donner de l‚Äôampleur √† notre impact üîÅüå± Quels que soient nos m√©tiers, notre √©quipe de +100 personnes partage le go√ªt de l‚Äôaudace, de l‚Äôengagement et de l‚Äôinnovation qui fait bouger les lignes. ü´µüèº Votre futur r√¥le chez HelloAsso Au sein de l‚Äô√©quipe DevOps vous garantissez la coh√©rence, la qualit√©, la s√©curit√© et l‚Äôaccessibilit√© permanente des informations . Votre r√¥le est de concevoir, g√©rer et maintenir les syst√®mes de collecte, de stockage, de traitement et de diffusion de donn√©es pour r√©pondre aux besoins op√©rationnels et analytiques de HelloAsso. üöÄ Vos futures missions üõ¢Ô∏è Conception et d√©veloppement de syst√®mes de stockage de donn√©es robuste et fiables Vous √©valuez les besoins en mati√®re de donn√©es de l‚Äôentreprise. Vous s√©lectionnez et mettez en place les technologies de stockage de donn√©es appropri√©es aux besoins √©valu√©s Vous concevez et mettez en oeuvre des syst√®mes de stockage de donn√©es maintenables et scalables Vous mettez en place un processus de surveillance pour garantir la fiabilit√© et la disponibilit√© des syst√®mes ‚úèÔ∏è Collecte, pr√©paration et traitement de donn√©es Vous √©laborez des strat√©gies pour collecter et acqu√©rir des donn√©es de diverses sources. Vous √™tes en charge du nettoyage, de la validation et de la transformation des donn√©es pour les rendre utilisables pour les analyses et les applications. Vous mettez en place des processus pour garantir la qualit√©, la s√©curit√© et l‚Äôint√©grit√© des donn√©es. Vous concevez et mettez en oeuvre des syst√®mes pour traiter des grandes quantit√©s de donn√©es. Vous g√©rez le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD ‚òéÔ∏è Support technique et assistance Vous collaborez avec les √©quipes de donn√©es et d‚Äôanalyse pour d√©terminer les besoins en mati√®re de donn√©es et les aider √† les r√©soudre. Vous mettez en place et veillez au maintien du catalogue de donn√©es Les √©quipes techniques grandissent √† vos c√¥t√©s gr√¢ce √† vos formations et partages de bonnes pratiques Vous ma√Ætrisez les technologies de stockage de donn√©es, en particulier Event streaming (Kafka,‚Ä¶), CDP (Segment), Data Cloud (Synapse Analytics, Snowflake), Data discovery/reporting/BI (Tableau, SISense, QlikSense,‚Ä¶) Vous avez des comp√©tences en programmation, notamment en Python (pySpark) et SQL, Vous avez une connaissance approfondie de l‚Äôing√©nierie des donn√©es, y compris les techniques de collecte, de nettoyage, de validation et de transformation de donn√©es, en particuler de mod√©lisation de la donn√©e (sql et nosql) Vous avez une exp√©rience en mise en ≈ìuvre de pipelines de donn√©es et en automatisation des processus de gestion de donn√©es. Vous √™tes p√©dagogue Pers√©v√©rant.e et curieux.se sont des adjectifs qui vous d√©finissent Phase 1 : un entretien avec RH + Manager Phase 2 : un test technique","HelloAsso, the leading payment solution for the nonprofit sector, is looking for a DevOps engineer to design, manage, and maintain data collection, storage, processing, and dissemination systems for operational and analytical needs. Responsibilities include developing robust and reliable data storage systems, collecting and preparing data from diverse sources, supporting technical teams, and providing training and best practices. Required skills include expertise in data storage technologies, programming (Python, SQL), data engineering (collection, cleaning, validation, transformation, data modeling), and data pipeline implementation and automation. The hiring process involves an interview with HR and a manager, followed by a technical test.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
132,73630,https://www.welcometothejungle.com/fr/companies/atos/jobs/data-engineer-confirme-cdi-f-h_grenoble_ATOS_4ZmzXkl,Data Engineer (Confirm√©) - CDI -,Atos,"{SnowFlake,Microsoft,Kafka,Hive,Redshift,Kibana,CouchBase,HDFS,Beam,AWS,BigQuery,Azure,Spark,Redis,Logstash,ElasticSearch,Java,MongoDB,Python,Cassandra,Teradata,Hadoop,Docker,Kubernetes,NoSQL}",T√©l√©travail partiel possible,"28 Rue Gustave Eiffel, Grenoble, 38000",IT / Digital,CDI,2023-04-22,"Bienvenue chez Atos, o√π nous imaginons le futur de la tech. Leader international du num√©rique s√©curis√© et d√©carbon√©, Atos contribue √† fa√ßonner les nouvelles technologies avec ses clients. Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carri√®re valorisants bas√©s sur des programmes de formation, de certification et de mobilit√©. C‚Äôest pourquoi chez Atos, la diversit√© des comp√©tences et des exp√©riences de nos √©quipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l‚Äôavenir de notre entreprise et de la soci√©t√©. LA MISSION QUE L‚ÄôON VOUS CONFIE : Au sein d'√©quipes dynamiques, vous aurez pour missions principales : Conseiller en architecture en gouvernance de la donn√©e. Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA. Mettre en place, int√©grer, d√©velopper et optimiser des solutions de pipeline sur des environnements Cloud pour les projets strat√©giques de nos clients. VOTRE PROFIL POUR REUSSIR : De formation sup√©rieure BAC +5 en Informatique d`une Ecole d‚ÄôIng√©nieur ou d‚Äôun Mast√®re universitaire dans le domaine des sciences informatiques que vous avez compl√©t√© par une exp√©rience significative en Data Science / Data Engineering. Votre stack technique : Requis : Connaissance des √©cosyst√®mes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS ‚Ä¶ ; Expertise en d√©veloppement Python ou Java Spring Boot ; Expertise sur un des framework suivants : Spark, Kafka Connect & Streams, Apache Beam‚Ä¶ ; Connaissance des architectures conteneurs : Docker, Kubernetes. Appr√©ci√© : Connaissance d‚Äôun des services manag√©s BigData de Google Cloud Platform / AWS / Microsoft Azure ; Connaissance des approches Agile & DevOps. Soft skills : Passionn√©(e) d‚Äôinformatique en progressant et en vous tenant √† jour sur toutes les technologies et architectures, vous √™tes cr√©atif(ve), autonome, rigoureux(se), curieux(se), motiv√©(e) et avez le sens du travail en √©quipe et du relationnel alors rejoignez-nous ! Niveau de langue : Anglais : niveau interm√©diaire minimum recommand√© et Fran√ßais exig√©. Description du profil : POUR VOUS CONVAINCRE DE NOUS REJOINDRE : Travailler √† Grenoble dans une ambiance et cadre de travail agr√©able avec nos clients en direct . Un accompagnement personnalis√© avec mont√©e en comp√©tences, formation et √©volution sur des projets long terme. Un employeur attentif √† votre √©panouissement avec des possibilit√©s de t√©l√©travail pouvant aller jusqu‚Äô√† 50% du temps Un package d‚Äôavantages avec r√©gime de sant√© tr√®s favorable, RTT disponibles d√®s votre arriv√©e et un CE tr√®s dynamique, remboursement des d√©placements en transport en commun. NOTRE PROCESSUS DE RECRUTEMENT : Prise de contact avec un recruteur pour une pr√©qualification Evaluation technique en fonction du profil Entretien avec nos ing√©nieurs commerciaux / managers Vous voulez en d√©couvrir plus ? N‚Äôh√©sitez plus et postulez d√®s √† pr√©sent ! #TheFutureIsOurChoice",,Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
339,37436,https://www.welcometothejungle.com/fr/companies/consortia/jobs/consultant-data-engineer_paris,Consultant(e) Data engineer (Paris),Consortia,"{Azure,NoSQL,Scala,AWS,Spark,GCP,SQL,Hadoop,Python}",T√©l√©travail partiel possible,"58 Boulevard Gouvion-Saint-Cyr, Paris, 75017",Bureau d'√©tudes et d'ing√©nierie,CDI,2022-10-18,"Acteur majeur de la Data intelligence, le Groupe Estia rassemble une centaine d‚Äôexperts de la donn√©e, mettant √† profit leurs comp√©tences autour d‚Äôun projet commun : le management et la valorisation de l‚Äôinformation au service des directions IT. Vous √™tes Informatics lover et le monde de la Data vous passionne ? Rejoignez Consortia en qualit√© de consultant(e) Data engineer. ‚Ä¢ Votre mission principale consiste √† intervenir en client√®le sur des demandes d‚Äôexpertise solution/m√©thodologie ‚Ä¢ Gr√¢ce √† votre expertise en Big Data, vous concevez des plateformes permettant de traiter des volumes importants de donn√©es et mettez en place des bases de donn√©es ‚Ä¢ Vous veillez √† ce que les pipelines de donn√©es d√©ploy√©s soient s√©curis√©s et clairs pour analyser et exploiter la donn√©e Dipl√¥m√©(e) d‚Äôun Bac +5 en Ecole d‚Äôing√©nieurs ou Master 2 en statistiques et/ou data, vous avez un int√©r√™t prononc√© pour les nouvelles approches et outils de la Data Ing√©nierie. Fort d‚Äôune solide exp√©rience en Data Ing√©nierie (3 ans minimum) acquise en cabinet de conseil ou en entreprise, vous avez d√©velopp√© une expertise sur des outils comme Python, Spark, Scala et en Big Data, ainsi que sur des environnements Hadoop et/ou Cloud (GCP, AWS ou Azure). Vous √™tes √† l‚Äôaise sur des environnements SQL et NoSQL. Vous avez une bonne connaissance de l‚Äôanglais et avez id√©alement une sensibilit√© aux m√©thodes agiles. Vous faites preuve de dynamisme, √™tes un(e) adepte du travail en √©quipe et accordez une grande importance √† la qualit√© & la fiabilit√© de vos livrables. En outre, vous avez un sens du service client d√©velopp√© et une capacit√© √† communiquer, vulgariser et pr√©senter votre travail. ‚Ä¢ 1er entretien : RH ‚Ä¢ 2√®me entretien : Op√©rationnel (manager ou superviseur) ‚Ä¢ 3√®me entretien : Direction en bin√¥me avec un ing√©nieur d‚Äôaffaires lors du 1er ou 2√®me entretien","The Estia Group is seeking a Data Engineer consultant to design platforms for managing and processing large data volumes, secure data pipelines, and implement databases. Applicants should have a master's degree in statistics or data science, solid experience in data engineering, and expertise in Python, Spark, Scala, and Big Data tools. Strong English language skills and a sensitivity to agile methodologies are preferred, as well as the ability to work well in teams and prioritize quality and reliability. The hiring process involves three interviews with HR, operational management, and a director, possibly alongside a business engineer.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
332,57068,https://www.welcometothejungle.com/fr/companies/illuin-tech/jobs/data-engineer-kafka-cassandra_neuilly-sur-seine,Data Engineer Kafka / Cassandra,ILLUIN Technology,"{React,Python,UNIX,Kubernetes,AWS,Docker,Kafka,R,Cassandra,Elasticsearch,Git,Java,SQL,Lucene,Bash,Postgresql}",T√©l√©travail partiel possible,"183, Avenue Charles de Gaulle, Neuilly-sur-Seine, Neuilly-Sur-Seine, 92200","Logiciels, Intelligence artificielle / Machine Learning, Big Data",CDI,2023-03-26,"ILLUIN Technology, c‚Äôest LA r√©f√©rence pour le d√©veloppement de solutions technologiques de pointe en France. En √† peine 6 ans, ILLUIN Technology est pass√©e de 11 √† 80+ Illuiners et a atteint un chiffre d‚Äôaffaires de 7,2 M‚Ç¨ en 2022 en r√©alisant des projets sur mesure aussi diversifi√©s - IA, web, mobile, AR/VR, IoT, etc. - que bluffants sur le plan technique et UX. Le secret ? Leurs quelques 50+ clients grands comptes, startups, asso, etc. vous le disent : ‚ÄúILLUIN, ce sont des personnes agr√©ables, dot√©es d‚Äôun tr√®s haut niveau technique, polyvalentes et toujours engag√©es.‚Äù Et ce n‚Äôest pas tout ! Depuis 2 ans, la soci√©t√© propulse aussi ses propres produits utilisant l‚Äô√©tat de l‚Äôart du NLU dans le domaine de l‚ÄôIA conversationnelle et du traitement intelligent de document (parsing, search‚Ä¶). Pourquoi nous rejoindre ? üèÖ Nous sommes certifi√©s HappyAtWork 2022 et avec le 2√®me meilleur score des startups fran√ßaises üåç Nous donnons 1500‚Ç¨ √† une association pour chaque cooptation et autant au cooptant üöÄ Nous avons un framework d‚Äô√©volution clair et transparent qui permet de se projeter üí∏ Nous proposons un package de r√©mun√©ration des plus attractifs du march√© et une √©volution rapide üåø Nous donnons du sens au travail : coaching d‚Äô√©tudiants, Tech4Good, unit√© Data x Sant√©, startup studio‚Ä¶ üòç Nous valorisons plus que tout la bienveillance, la stimulation intellectuelle et l‚Äô√©quilibre pro-perso üíª Nous travaillons sur du mat√©riel haut de gamme (Macbook Pro / DELL XPS, √©cran QHD) ‚Üí Votre mission En tant que Data Engineer Kafka / Cassandra, votre r√¥le sera d‚Äôindustrialiser des solution d‚ÄôIA scalable √† grande √©chelle dans un cluster Apache Kafka, de d√©velopper des pipelines de transformation de donn√©es √† gros volume ainsi que de mettre en place des solutions de persistance de donn√©es dans des bases de donn√©es Cassandra / Postgresql / Elasticsearch. Ces solutions s‚Äôinscrivent dans le cadre de projets sur-mesure pour nos clients ou pour r√©pondre aux besoins en data engineering de nos produits ILLUIN Technology. ‚Üí Vos responsabilit√©s Participer √† la conception et l‚Äôoptimisation de solutions technologiques traitant un gros volume de donn√©es √† grande √©chelle et r√©pondant aux besoins des utilisateurs/clients R√©aliser des projets en √©quipe, encadr√©.e par des profils exp√©riment√©s qui vous feront monter en comp√©tences Perfectionner ses comp√©tences et chercher constamment √† am√©liorer les outils et les m√©thodes employ√©es (veille technologique, R&D, √©changes de bonnes pratiques, hackathons) Participer √† des code reviews avec les membres de votre √©quipe, challenger les impl√©mentations, partager votre expertise et faire grandir les illuiners juniors autour de vous Prendre part aux c√©r√©monies et sprint reviews en lien direct avec le client / nos √©quipes produits Participer au d√©veloppement de projets internes transverses : recherche, OPS, s√©curit√©, formations, ‚Ä¶ Participer √† l‚Äô√©volution de notre offre de Data Engineering en √©paulant ponctuellement l‚Äô√©quipe commerciale gr√¢ce √† votre expertise technique Nous cherchons le match parfait üíì ‚Ä¶mais nous croyons √† la richesse des rencontres ! Alors si vous n‚Äô√™tes pas certain.e de matcher notre recherche nous vous encourageons √† nous contacter quand m√™me ‚úâÔ∏è ‚úÖ Must have Exp√©rience avec le langage de programmation Java Bonne compr√©hension des bases de donn√©es SQL Bonne compr√©hension du fonctionnement d‚ÄôApache Kafka Compr√©hension de base du fonctionnement d‚ÄôApache Cassandra Exp√©rience avec Git et des outils d‚Äôint√©gration continue Exp√©rience avec Docker üåà Nice to have Exp√©rience avec le framework backend Spring / Spring Boot Bonne compr√©hension du fonctionnement du Web Tests unitaires et d‚Äôint√©gration Exp√©rience en OPS (Kubernetes, Terraform, Ansible, ‚Ä¶) Exp√©rience avec de l‚Äôindexation Lucene Exp√©rience avec Elasticsearch / stack ELK Exp√©rience avec le langage de programmation Python Connaissances de base UNIX & Bash Exp√©rience sur des outils cloud (Google Cloud, AWS, OpenStack, ‚Ä¶) Usage d‚Äôun framework front-end (React, Angular, Vue, ‚Ä¶) Connaissances en IA / data science (machine learning, deep learning, NLP) ü§© Les gens disent de vous que‚Ä¶ Vous √™tes engag√©.e et pr√™t.e √† donner le meilleur de vous-m√™mes Vous √™tes curieux.se, flexible, empathique, autonome Vous avez le sens du partage et le sens du travail en √©quipe Vous partagez nos valeurs : confiance, empowerment, excellence, innovation Apr√®s un 1er contact par t√©l√©phone, voici le processus : Test technique √† distance (1h) Entretien Tech Live Entretien Human Fit Entretien Head of Software Engineering Entretien CEO La plupart des entretiens se font en pr√©sentiel mais l‚Äôoption visio est √©galement possible. Dans l‚Äôensemble, entre le premier contact et la remise de proposition, il s‚Äô√©coule rarement plus de 2 semaines !","ILLUIN Technology is seeking a Data Engineer with expertise in Kafka and Cassandra to work on custom projects for clients and ILLUIN Technology's own products. The role involves developing data transformation pipelines at scale, implementing data persistence solutions in Cassandra, and participating in the development of transversal internal projects. The ideal candidate has experience with Java, SQL databases, and Apache Kafka, as well as version control and continuous integration tools. Nice-to-have skills include experience with Spring, ELK stack, and cloud tools such as AWS or Google Cloud. The company values teamwork, innovation, and excellence and offers attractive compensation and career growth opportunities.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 3 ans,2,0,0.027697749441558416
106,72901,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_nantes_ASI_4ogDM0K,Data Engineer,ASI,"{Microsoft,Azure,NIFI,Matillion,Kafka,Spark,NoSQL,SQL,Airflow,Glue,S3,Talend,Java}",T√©l√©travail partiel possible,Nantes,"IT / Digital, Transformation, Big Data",CDI,2023-04-22,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Avec Simon GRIFFON, responsable de l‚Äô√©quipe Data Nantaise, nous recherchons un Data Engineer pour mettre en place, int√©grer, d√©velopper et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une √©quipe d√©di√©e, principalement en contexte agile, voici les missions qui pourront vous √™tre confi√©es : Participer √† la r√©daction de sp√©cifications techniques et fonctionnelles Ma√Ætriser les formats de donn√©es structur√©s et non structur√©s et savoir les manipuler Connecter une solution ETL / ELT √† une source de donn√©es Concevoir et r√©aliser un pipeline de transformation et de valorisation des donn√©es et ordonnancer son fonctionnement Prendre en charge les d√©veloppements de m√©diations Veiller √† la s√©curisation des pipelines de donn√©es Concevoir et r√©aliser des API utilisant les donn√©es valoris√©es Concevoir et impl√©menter des solutions BI Participer √† la r√©daction des sp√©cifications fonctionnelles et techniques des flux D√©finir des plans de tests et d‚Äôint√©gration Prendre en charge la maintenance √©volutive et corrective Traiter les probl√©matiques de qualit√© de donn√©es En fonction de vos comp√©tences et app√©tences, vous intervenez sur l‚Äôune ou plusieurs des technologies suivantes : L‚Äô√©cosyst√®me data notamment Microsoft Azure Les langages : SQL , Java Les bases de donn√©es SQL et NoSQL Stockage cloud: S3, Azure Blob Storage‚Ä¶ Les ETL/ESB et autres outils : Talend , Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue... Nos engagements : Avec Simon, votre manager de proximit√© , vous co-construisez votre trajectoire professionnelle Vous b√©n√©ficiez d'une offre de formation riche en ad√©quation avec vos attentes gr√¢ce √† la ""ASI Academy"" Vous int√©grez les diff√©rentes communaut√©s techniques d'ASI, pour partager des bonnes pratiques et participer aux actions d'am√©lioration continue Vous pouvez participer (ou animer si le c≈ìur vous en dit) √† des √©v√®nements internes de type dej‚Äôtech et midi geek, mais aussi √† des √©v√®nements externes : Camping des Speakers, DevFest, Salon de la Data ‚Ä¶ Vous √©voluez dans une entreprise porteuse d‚Äôune d√©marche RSE VRAIMENT active . Issu d‚Äôune formation sup√©rieure en informatique, math√©matiques ou sp√©cialis√© en Big Data, vous avez une exp√©rience minimale de 3 ans en ing√©nierie des donn√©es et d'une exp√©rience op√©rationnelle r√©ussie dans la construction de pipelines de donn√©es structur√©es et non structur√©es. Le salaire propos√© pour ce poste est compris entre 36 000 et 40 000 ‚Ç¨, selon l'exp√©rience et les comp√©tences, tout en respectant l'√©quit√© salariale au sein de l'√©quipe. Attach√© √† la qualit√© de ce que vous r√©alisez, vous faites preuve de rigueur et d' organisation dans la r√©alisation de vos activit√©s. Dot√© d'une bonne culture technologique , vous faites r√©guli√®rement de la veille pour actualiser vos connaissances. Un bon niveau d‚Äôanglais, tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral est recommand√©. Vous souhaitez (comme nous) agir pour un num√©rique plus responsable au service de ses utilisateurs. Vous savez travailler en √©quipe et vous accordez de l'importance au partage et √† l' entraide . Enfin, vous adh√©rez √† nos valeurs de respect , de bienveillance et d' engagement professionnel et soci√©tal . √Ä comp√©tences √©gales ce poste est ouvert aux personnes en situation de handicap",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
334,56611,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/ingenieur-data-h-f-poei_puteaux,Ing√©nieur Data  | POEI,Datascientest,"{Java,Python}",T√©l√©travail ponctuel autoris√©,"1, Terrasse Bellini, Puteaux, 92800","SaaS / Cloud Services, EdTech, Formation",CDI,2023-03-26,"DATASCIENTEST ? LA REFERENCE EN DATASCIENCE Cr√©√©e en 2017, DataScientest r√©volutionne la formation en Data Science et devient leader en France ! Notre √©cole compte plus de 6 000 apprenants √† son actif, et a s√©duit 50 entreprises dont une trentaine du CAC40 et des leaders internationaux (BCG, Allianz, Christian Dior, Axa‚Ä¶), Nous formons aussi les demandeurs d‚Äôemploi en leur offrant un CDI au sein de nos entreprises partenaires Pr√©sents en Espagne et en Allemagne, notre p√©dagogie repose sur une structure hybride : Qui allie l‚Äôadaptabilit√© du distanciel avec une plateforme enti√®rement con√ßue par nous-m√™me et La motivation du pr√©sentiel avec des s√©ances de coaching anim√©es par nos enseignants data scientists ! En tant qu‚ÄôIng√©nieur Data, vous serez charg√©(e) de proposer les meilleures solutions √† l‚Äôentreprise en leur permettant d‚Äôoptimiser leur activit√©, √† travers quelques missions principales : D√©velopper des solutions pour traiter des volumes importants de donn√©es, Concevoir, collecter et fabriquer des donn√©es brutes, Cr√©er des outils et algorithmes pour le traitement des donn√©es, Pr√©parer des donn√©es pour le Data Analyst, S√©curiser des Pipelines donn√©es pour les Data Analysts et Data Scientists, Organiser l‚Äôarchitecture du cloud, Contribuer √† l‚Äôeffort d‚Äôanimation technique, de veille technologique et d‚Äôinnovation Et si nous parlions de vous ? Issu(e) d‚Äôune fili√®re scientifique bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieur, Vous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la Data, Vous ma√Ætrisez un langage objet type Java, Python, C++, etc. Vous √™tes demandeur d‚Äôemploi N‚Äôattendez plus, envoyez nous votre CV, nos √©quipes se feront un plaisir de vous contacter et de vous accompagner pour pr√©parer vos entretiens avec notre entreprise partenaire.","DataScientest seeks an experienced Data Engineer to develop solutions to help companies optimize their activities. The role involves designing, collecting, processing, and preparing data for analysis by Data Analysts and Data Scientists. The ideal candidate should have a scientific background, a degree in engineering, and significant experience in development, network architecture, or Data. Proficiency in Java, Python, C++, or a similar object-oriented language is crucial. DataScientest provides an innovative hybrid teaching method combining virtual and in-person mentoring, with partnerships with major companies like Allianz, Christian Dior, and Axa. DataScientest also offers job opportunities to job seekers, including a CDI with partner organizations.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,1,1,0.027697749441558416
374,57066,https://www.welcometothejungle.com/fr/companies/societe-generale-assurances/jobs/dataops-engineer_la-defense,Dataops Engineer,Soci√©t√© G√©n√©rale Assurances,"{Jenkins,Trino,LakeFS,Gitlab,Kubernetes,Cloudera,HDFS,Kedro,MLflow,Hive,Spark,Superset,Python,linux}",T√©l√©travail partiel possible,La D√©fense,Assurance,CDI,2023-03-26,"Pr√©sente en France avec Sog√©cap, Antarius, Sogessur et Orad√©a Vie, et dans 9 pays √† l'international, Soci√©t√© G√©n√©rale Assurances propose une gamme compl√®te de produits et de services r√©pondant aux besoins de la client√®le de particuliers, de professionnels et d'entreprises, en mati√®re d'assurance-vie √©pargne, d'√©pargne retraite et de protection des personnes et des biens. Votre r√¥le La direction du DataLab effectue des travaux transverses visant √† valoriser au mieux les donn√©es disponibles en interne. Le DataLab cherche √† renforcer les moyens techniques lui permettant de d√©mocratiser l'acc√®s et l'usage des donn√©es ainsi qu'acc√©l√©rer et faciliter la mise en production des applications Data et IA. En tant que DataOps Engineer, vous intervenez sur l'√©volution et le maintien de la plateforme de d√©veloppement data interne. Vous travaillerez notamment sur les sujets suivants : Release management des applications Data et IA Evolution des solutions de Data orchestration Impl√©mentation d'une solution de Data quality Entra√Ænement et √©valuation continue des mod√®les ML Maintenance et √©volution du Framework de d√©veloppement data science Dipl√¥m√© d'une formation orient√©e informatique, vous justifiez d'une exp√©rience significative en data et platform engineering (4 ans et +). Vous avez une connaissance approfondie sur les pratiques du software engineering et sur les diff√©rentes approches de mod√©lisation, stockage et requ√™tage des donn√©es. Vous ma√Ætrisez linux et au moins un syst√®me distribu√© orient√© Data. L'√©cosyst√®me Python vous est familier. Des connaissances en Machine Learning sont un plus. Environnement technique : Vous travaillerez sur une ou plusieurs de ces Plateformes : Plateforme Data Science : Jupyterhub, VScode (code-server), MLflow, Apache Superset, Trino, LakeFS, Kedro Plateforme DevOps: Gitlab, Nexus, MLflow, Jenkins, Kubernetes, Vault, Gatling Plateforme Big Data: Cloudera Data Platform (HDFS, Hive, Spark,..) Informations g√©n√©rales Poste √† pourvoir en CDI √† partir de mars 2023 bas√© √† Paris La D√©fense (92).","Soci√©t√© G√©n√©rale Assurances is seeking a DataOps Engineer to strengthen its internal data development platform. The role involves release management of data and AI applications, data orchestration, data quality implementation, ML model training and evaluation, and maintenance and evolution of the data science development framework. The ideal candidate should have a degree in computer science, a significant experience in data and platform engineering, knowledge of software engineering practices, and familiarity with Python and Linux. Knowledge in Machine Learning is a plus.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
152,56459,https://www.welcometothejungle.com/fr/companies/polyconseil/jobs/data-engineer-h-f-cdi_paris_POLYC_WA1Dg7r,Data Engineer -  - CDI,Polyconseil,"{DBT,PostgreSQL,Snowflake,Azure,Docker,MongoDB,Databricks,Luigi,Kafka,Git,NoSQL,ElasticSearch,Kubernetes,AWS,SQL,Airflow,via,Spark,GCP,Python}",T√©l√©travail ponctuel autoris√©,"14, Boulevard Poissonni√®re, Paris, 75009","Logiciels, IT / Digital",CDI,2023-03-26,"Expert de la transformation num√©rique depuis 1989, Polyconseil poss√®de un positionnement atypique, alliant expertise en conseil et r√©alisation de produits digitaux. Nos √©quipes s‚Äôint√®grent sur toute de la cha√Æne de valeur, afin d‚Äôavoir une vue d‚Äôensemble d‚Äôun projet et d‚Äôen ma√Ætriser chaque √©tape : cadrage des besoins, pr√©conisations, conception, d√©veloppement et d√©ploiement de solutions innovantes et complexes. Nous accompagnons aussi bien des grands comptes, que des institutions publiques ou des start-ups, dans des secteurs vari√©s tels que : M√©dias, Assurance, Mobilit√©, A√©rospatial, √âcologie, etc. Nous intervenons sur des projets √† forte valeur ajout√©e et apportons un accompagnement sur-mesure √† nos clients, en constituant des √©quipes multidisciplinaires de D√©veloppeur(se)s, Product Managers, Digital Consultant(e)s, UI / UX Designers, Data Scientists et InfraOps. Polyconseil est fond√© sur des valeurs d‚Äôexcellence, de bienveillance et d‚Äôentraide favorisant la responsabilisation et la mont√©e en comp√©tence graduelle de tous nos collaborateurs. Pourquoi rejoindre Polyconseil ? Vous intervenez sur des missions √† impact et voyez le r√©sultat de vos actions Vous √™tes responsabilis√©(e) et √©voluez dans un environnement propice √† l‚Äô apprentissage et √† la progression , au contact de talents qui se tirent vers le haut. Vous travaillez dans une ambiance √† la fois d√©tendue et stimulante , pr√¥nant esprit d‚Äô√©quipe et prises d‚Äôinitiative Vous profitez d‚Äôune vie interne riche en √©v√©nements (sportifs, culturels, culinaires‚Ä¶) Votre √©quilibre vie pro / vie perso est respect√© et vous b√©n√©ficiez d‚Äôune politique de t√©l√©travail flexible Vous rejoignez nos locaux r√©cents en plein Paris (Paris 9, m√©tro Grands Boulevards, lignes 8-9) Vous avez acc√®s √† la participation, plan √©pargne entreprise avec abondement, tickets restaurant‚Ä¶ Int√©gr√©(e) au sein de l‚Äô√©quipe Data, vous intervenez notamment sur : Le d√©veloppement, d√©ploiement et maintenance de pipelines d‚ÄôETL/ELT La mise en place d‚ÄôAPIs et de backends applicatifs La d√©finition et mise en place de mod√®les de donn√©es, administration de base de donn√©es L‚Äôutilisation de plateformes et outils Cloud La compr√©hension et application de principes d‚Äôarchitecture La supervision et monitoring d‚Äôapplications Entour√©(e) de nos experts, vous montez rapidement en comp√©tence sur les technologies suivantes : Python, Apache Spark, MongoDB, ElasticSearch, Airflow, et participez au d√©veloppement de nouveaux produits innovants dans le cadre de notre Datalab. En fonction de vos app√©tences, vous aurez √©galement la possibilit√© de vous impliquer sur des sujets transversaux pour accompagner notre croissance : recrutement, r√©ponses aux AOs, organisation d‚Äô√©v√©nements, chantiers internes (RSE‚Ä¶) etc. Principales technologies √† utiliser ou √† d√©couvrir Langages : Python, SQL, DBT, Spark Bases de donn√©es : PostgreSQL, base de donn√©es NoSQL (MongoDB, ELK‚Ä¶) Orchestration : Airflow, Luigi DevOps : Git, CI/CD, Docker, Kubernetes/Nomad, Ansible‚Ä¶ Outils Cloud : AWS, GCP, Azure, Snowflake, Databricks‚Ä¶ Autres : Kafka Quelques exemples de missions : D√©veloppement et commercialisation en SaaS d‚Äôun syst√®me de gestion intelligente de la politique de stationnement pour une centaine de villes en France Solution d‚Äôoptimisation du pricing des produits vendus via une plateforme de ventes aux ench√®res en ligne D√©veloppement d‚Äôune plateforme de suivi et de pr√©diction des incidents sur un parc IT D√©veloppement from scratch d‚Äôun feature store √† destination des data scientists d‚Äôun acteur de la r√©assurance Algorithmes de d√©tection de fraude aupr√®s d‚Äôassureurs Conception d‚Äôune plateforme data temps r√©√©l sur AWS Vos moyens pour r√©ussir Formation : d√®s votre arriv√©e, vous avez acc√®s √† un large panel de formations et ressources documentaires pour approfondir vos connaissances sur vos sujets de pr√©dilection ou bien d√©couvrir des sujets nouveaux par simple curiosit√©. Nous finan√ßons √©galement des formations AWS Management op√©rationnel : vous √™tes accompagn√©(e) par un manager de mission et un Talent Manager tout au long de votre parcours chez nous Contact constant avec d‚Äôautres m√©tiers / √©quipes au sein de nos locaux Issu(e) d‚Äôune √©cole d‚Äôing√©nieurs ou d‚Äôune √©cole sp√©cialis√©e en d√©veloppement informatique, vous poss√©dez minimum 2 ann√©es d‚Äôexp√©rience en Data Engineering et ma√Ætrisez Python et SQL. Une exp√©rience ou une formation sp√©cifique (ex : Udemy) avec le calcul distribu√©, le traitement des donn√©es temps r√©el ou les bases de donn√©es NoSQL est un plus. Avoir d√©j√† travaill√© avec un ou plusieurs fournisseurs de cloud (AWS, GCP, Azure notamment) est √©galement appr√©ci√©. Nous recherchons avant tout un fit humain, et de futur(e)s coll√®gues avec qui nous prendrons plaisir √† travailler chaque jour. Alors, si comme nous vous poss√©dez : Une curiosit√© naturelle pour le monde du num√©rique Un go√ªt pour le challenge Une envie de progresser et d‚Äôapprendre Un esprit d‚Äô√©quipe √† toute √©preuve Une r√©elle volont√© de transmettre vos connaissances et d‚Äôaider les autres Une tr√®s bonne ma√Ætrise de la langue fran√ßaise ‚Ä¶n‚Äôh√©sitez pas √† nous envoyer votre candidature !","Polyconseil, a digital transformation expert, is seeking a Data Engineer with at least two years of experience in data engineering, Python, SQL, and cloud providers. The successful candidate will work on a range of tasks, including administering databases, developing ETL/ELT pipelines, and employing API and application backend solutions. The company offers comprehensive training and resources to help employees develop professionally, a balanced work-life policy, and a generous employee benefits package.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 2 ans,1,1,0.027697749441558416
377,56682,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-bi-f-h_nantes,Data Engineer / BI Developer,Micropole,"{Microsoft,durable,Talend,SAP,Informatica,AWS,R,GCP,SQL,Qlik,Tableau}",T√©l√©travail partiel possible,"25 Rue Paul Bellamy, Nantes, 44000",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√©‚ÄØ: Data Engineer F/H Localit√© : Nantes Type de contrat : CDI Niveau d‚Äôexp√©rience‚ÄØminimum : 2 ans Vous souhaitez rejoindre une entreprise pionni√®re des grandes innovations data et digitales, au sein d‚Äôune agence √† taille humaine o√π r√®gnent entraide et convivialit√©, engag√©e en faveur d‚Äôun num√©rique plus responsable au service de clients principalement implant√©s r√©gionalement ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur gr√¢ce √† la puissance du Cloud ? Rejoignez Micropole ! Dans vos missions quotidiennes , vous serez amen√©(e) √† : Participer aux recueil du besoin aupr√®s des Directions M√©tiers ; R√©diger les dossiers de conception technique ; Intervenir sur toute la cha√Æne de valeur de la donn√©e : extraction √† l'aide d'un ETL, mod√©lisation & dataviz ; Pr√©parer et d√©rouler les tests ; Accompagner la ma√Ætrise d‚Äôouvrage dans la validation de livrables, l‚Äôassistance √† la recette et la conduite du changement sur le projet ; Capitaliser et partager les bonnes pratiques, connaissances et retours d‚Äôexp√©rience au sein de nos communaut√©s. Vos comp√©tences techniques : Vous ma√Ætrisez parfaitement au moins un ETL du march√© (Informatica, Talend, Big Query, Data Factory, etc) et la cr√©ation de tableaux de bord (Power BI, Tableau, Qlik, Spotfire, SAP BI...) id√©alement dans un environnement Cloud ; SQL n‚Äôa plus de secrets pour vous. Vos atouts : Vous √™tes dipl√¥m√©(e) d‚Äôune formation sup√©rieure en Informatique d√©cisionnelle ; Vous poss√©dez une exp√©rience d'au moins 3 ans dans la fonction ; Votre esprit d‚Äôanalyse, de synth√®se, votre organisation et vos capacit√©s r√©dactionnelles sont souvent reconnus ; Vous appr√©ciez travailler en √©quipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C‚ÄôEST‚ÄØ: - Int√©grer une communaut√© de 1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. - Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud‚ÄØ: AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. - S‚Äôassurer d‚Äôune innovation continue gr√¢ce √†‚ÄØ: Notre √©cosyst√®me de partenaires technologiques Notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR Nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C‚ÄôEST‚ÄØ: Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole‚ÄØ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles‚ÄØ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion‚ÄØ; La participation √† nos communaut√©s sur la base du volontariat. PROCESSUS DE RECRUTEMENT‚ÄØ: Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì Si votre profil correspond √† nos attentes, vous √™tes recontact√©(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist pour la r√©gion ouest pour un premier √©change t√©l√©phonique‚ÄØ; Etape 2 ‚Äì Un premier entretien est programm√© avec l‚Äôun d‚Äôentre eux sur site ou √† distance Etape 3 ‚Äì Vous rencontrez St√©phanie ou Camille les manager de l‚Äô√©quipe Data de l‚ÄôOuest pour un second entretien En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un d√©veloppement rapide sur le Data, le Digital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur du Groupe. Pr√©sent au plus pr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs du d√©veloppement √©conomique, nous accompagnons nos clients des secteurs de l‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et du public dans leur transformation data et digitale, notamment au travers de m√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ. L‚Äôagence Grand Ouest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit et met en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôun num√©rique responsable au sein des organisations √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en savoir plus‚ÄØ: https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Comp√©tences Mod√©lisation informatique decisionnelle","Micropole is seeking a Data Engineer to work on their projects ranging from requirement gathering to technical design, data extraction, and model building. The ideal candidate should have at least 2 years of experience in data-driven decision-making and strong knowledge of ETL tools, data visualization software, and Cloud environments. They should also have excellent analytical, communication and team collaboration skills. Micropole is a leading European data transformation and consulting firm with over 1200 experts and several innovation ecosystems, and promotes a sustainable and responsible form of digital transformation.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
310,58095,https://www.welcometothejungle.com/fr/companies/sancare/jobs/data-engineer_paris_SANCA_ed4r6Dy,Data Engineer,Sancare,"{GitHub,Docker,Linux,Git,RabbitMq,SQL,Python}",T√©l√©travail partiel possible,"5, Rue Saint-Germain-l'Auxerrois, Paris, 75001","Intelligence artificielle / Machine Learning, Big Data, Sant√©",CDI,2023-03-26,"Sancare propose des outils pr√©dictifs utilisant les derni√®res avanc√©es en intelligence artificielle pour mettre ces donn√©es au service des m√©tiers de la sant√©. L‚Äô√©quipe de Sancare est compos√©e d‚Äôune trentaine de personnes sp√©cialis√©es dans le d√©veloppement informatique, le machine learning et la sant√©. Nous avons de plus la chance d‚Äô√™tre accompagn√©s par des chercheurs reconnus dans le domaine du machine learning, ainsi que par des m√©decins et experts du monde de la sant√©. √ätre chez Sancare, c‚Äôest avant tout √™tre une √©quipe bienveillante, qui s‚Äôentraide et cherche constamment √† progresser. Nous sommes une √©quipe soud√©e, avec des valeurs fortes‚ÄØet partag√©es : Pers√©v√©rer en s‚Äôentraidant Rester proche du besoin client Allier rigueur et pragmatisme Grandir et faire grandir les autres Collaborer avec transparence et respect. Nous recherchons une Data Engineer avec de solides comp√©tences op√©rationnelles et souhaitant rejoindre une √©quipe dynamique, exp√©riment√©e et motiv√©e, afin d‚Äôacc√©l√©rer l‚Äôarriv√©e de nos solutions en rupture dans le monde de la sant√©. La gestion et le traitement de la donn√©e sont au coeur des probl√©matiques de Sancare. Comme chaque h√¥pital dispose de son propre syst√®me d‚Äôinformation, des connecteurs doivent √™tre impl√©ment√©s pour chacun, afin de nourrir les algorithmes de machine learning. Les moyens d‚Äôacc√®s et le format des donn√©es contenues dans les dossiers patients sont tr√®s vari√©s et diff√®rent d‚Äôun √©tablissement √† un autre. De plus, de nombreuses mesures sont √† respecter afin de garantir la s√©curit√© et la confidentialit√© des donn√©es. Missions : D√©veloppement de connecteurs permettant la transmission des donn√©es hospitali√®res entre les SI hospitaliers et les logiciels de Sancare D√©veloppement d‚Äôoutils de standardisation et de traitement des donn√©es hospitali√®res en vue de leur utilisation par les algorithmes de machine learning Am√©lioration et maintenance des fonctionnalit√©s existantes de traitement de donn√©es Gestion op√©rationnelle des diff√©rents services de traitement de donn√©es. Les avantages Sancare : Des superbes locaux en plein centre de Paris (Ch√¢telet) Une organisation du travail flexible (109 jours de t√©l√©travail par ann√©e civile pour les salari√©s en forfait jour: soit deux jours de t√©l√©travail possibles par semaine et ce forfait pourra √™tre port√© √† 131 jours de t√©l√©travail si les salari√©s au forfait jour justifient d‚Äôun temps de d√©placement domicile-bureau sup√©rieur √† 3h par jour: soit trois jours de t√©l√©travail possibles par semaines pour les personnes √† plus d‚Äô1h30 du bureau) Tickets restaurant √âligibilit√© BSPCE Mutuelle Alan Hello CSE Chez Sancare on n‚Äôest jamais √† l‚Äôabri d‚Äôun ap√©ro ou d‚Äôun cours de street-art ! Des retours d‚Äôexp√©rience r√©guliers dans des formats vari√©s (afterworks, s√©minaires, ‚Ä¶) pour valoriser le partage d‚Äôid√©es et la connaissance commune. Exp√©rience significative dans le d√©veloppement en Python orient√© objet (3ans √† 5ans) Exp√©rience de d√©veloppement sous Linux Exp√©rience dans la manipulation de donn√©es avec le langage SQL Pratique avanc√©e des outils d‚Äôint√©gration continue avec Git et tests unitaires Des qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√© L‚Äôesprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collective Un int√©r√™t pour le monde de la sant√© Sont un plus : Familiarit√© avec Docker et RabbitMq Exp√©rience avec les donn√©es de sant√© dans le secteur hospitalier N‚Äôh√©sitez pas √† partager vos projets personnels de d√©veloppement (sur GitHub ou ailleurs). Entretien Visio avec Thomas notre Head Of Recruitment Test Technique puis entretien de pair programing avec l‚Äô√©quipe Entretien avec notre fondateur","Sancare, a health-tech company specialized in predictive tools, is looking for a Data Engineer with 3-5 years of experience in Python, Linux, SQL, and CI tools to develop connectors between hospital information systems and Sancare's software. The ideal candidate should demonstrate autonomy, flexibility, and a collaborative mindset. Knowledge of Docker, RabbitMq, and healthcare data is a plus. Working at Sancare offers benefits such as flexible work arrangements, regular after-work events, and a dynamic and supportive team.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 3 ans,2,0,0.027697749441558416
179,56697,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-powercenter-informatica-h-f_tours,Expert technique ETL Powercenter Informatica,CGI,{Informatica},T√©l√©travail partiel possible,"Tours, 37000","IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√© par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Powercenter Informatica. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Powercenter Informatica ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Powercenter ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√© d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√© d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es ou dans le MDM ou sur Informatica Cloud sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI, a global consulting and digital services leader, is seeking a Data Integration Expert with a solid experience in ETL Powercenter Informatica. The ideal candidate is passionate about data and decision-making, enjoys learning and sharing knowledge, and has at least three years of experience in data integration within digital services or consulting firms. The role includes analyzing and improving solutions, collaborating with engineers and other experts, participating in technical documentation, providing technical support, and participating in technical recruitment. CGI offers diverse career paths, including technical management, integration consulting, or BI project management. The company is an inclusive employer, committed to the career development of all candidates and employees, regardless of gender or ability.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
365,56322,https://www.welcometothejungle.com/fr/companies/ornikar/jobs/bi-engineer_paris,Analytics Engineer,Ornikar,"{Metabase,matillion,Snowflake,Dataiku,Looker,PowerBI,moderne,Mixpanel,Qlik,Airbyte,scale,SQL,Airflow,Redshift,dbt,via,BigQuery,GCP,Tableau}",T√©l√©travail partiel possible,"France, Paris, 23230","Mobilit√©, FinTech / InsurTech, EdTech",CDI,2023-03-26,"Ornikar √©toffe son offre historique d‚Äôauto-√©cole et devient une plateforme d‚Äôacc√®s √† la mobilit√© pour les jeunes ! Leur volont√© : r√©inventer l‚Äôexp√©rience des jeunes g√©n√©rations autour de l‚Äôapprentissage de la conduite, et les accompagner gr√¢ce √† un √©cosyst√®me de services tels que l‚Äôassurance automobile. Fond√©e en 2013 et leader sur la modernisation du permis de conduire, l‚Äô√©quipe Ornikar continue d‚Äô√©voluer et de militer pour l‚Äô√©mancipation des jeunes et la transition vers leur ind√©pendance ! Aujourd‚Äôhui constitu√©e de 260 collaborateurs, leur √©quipe conna√Æt une croissance continue construite sur de solides fondations : leur produit permis de conduire (plateforme d‚Äôe-learning et marketplace de mise en relation avec nos enseignants de la conduite) d‚Äôune part, mais √©galement leur connaissance utilisateur approfondie qui leur permet d‚Äôoffrir une assurance auto plus proche des besoins des jeunes assur√©s : modulable, simplifi√©e, adapt√©e √† tous avec un prix et des options personnalis√©es. √Ä propos de la Team Data üìä La data est une direction √† part chez Ornikar compos√©e d‚Äôune vingtaine de personnes, et s‚Äôorganise autour de plusieurs m√©tiers compl√©mentaires (Data Analysts, Analytics Engineers, Data Engineers, Machine Learning Engineers) dont certains en contact permanent avec des √©quipes m√©tiers (produit, marketing, op√©rations). Nous avons principalement 3 missions : L‚Äôaide √† la d√©cision : on accompagne les √©quipes √† tous les niveaux de management, que ce soit pour des objectifs strat√©giques, de d√©veloppement produit, de m√©tier‚Ä¶ Nous menons des analyses complexes pour permettre aux √©quipes de prendre les d√©cisions bas√©es sur des chiffres qui nous permettront d‚Äôatteindre nos objectifs ou d‚Äôidentifier de nouveaux leviers de croissance. L‚Äôefficacit√© op√©rationnelle : Les √©quipes chez Ornikar sont tr√®s sensibles aux enjeux data, ce qui nous a permis de mettre en place d‚Äôune part le self-service BI pour leur permettre d‚Äôeffectuer leurs recherches quantitatives en parfaite autonomie, et d‚Äôautre part nous r√©pondons √† des probl√©matiques d‚Äôautomatisation de flux de donn√©es pour enrichir leurs outils et acc√©l√©rer leur quotidien. Des features data et algorithmes que nous d√©veloppons pour apporter encore plus de valeur diff√©rentiante √† nos produits, et faire de la data un √©l√©ment fort de notre proposition de valeur. Pour soutenir ces missions, toute l‚Äô√©quipe participe √† la construction d‚Äôune stack Data de pointe r√©pondant aux enjeux d‚Äôune √©quipe Data moderne. Nous recherchons un¬∑e Analytics Engineer üåã Le d√©veloppement de l‚Äôactivit√© d‚Äôassurance d‚ÄôOrnikar s‚Äôaccompagne d‚Äôun grand nombre d‚Äôengagements contractuels et l√©gaux quant √† la mise √† disposition de donn√©es aupr√®s d‚Äôacteurs tiers, partenaires ou r√©gulateurs. Des sinistres aux indicateurs de production, en passant par les m√©triques financi√®res ou op√©rationnelles, toutes les activit√©s de l‚Äôentreprise sont concern√©es. Plus g√©n√©ralement, Ornikar a √† coeur d'√©tablir ses prises de d√©cision sur une offre de donn√©e partag√©e, comprise et ma√Ætris√©e par toutes les √©quipes, ind√©pendamment de leur app√©tence technique. Notre objectif est de centraliser la production de rapports d‚Äôint√©gration, comptables et r√©glementaires, en termes de cr√©ation, maintenance et r√©vision, et de renforcer nos bonnes pratiques en la mati√®re en s‚Äôinspirant des standards du d√©veloppement moderne : optimisation et r√©silience du code, peer review, gestion des versions et des environnements, alertes et observabilit√©, tests et qualit√©, documentation et indempotence. Le ou La Analytics Engineer aura √©galement la responsabilit√© de transposer ces standards aux rapports internes orient√©s m√©tier. Les missions du poste : G√©rer la relation avec les demandeurs finaux (r√©gulateurs, partenaires), et les √©quipes internes associ√©es √† la bonne r√©alisation des rapports (Data Engineers, Data Analysts, √©quipes plateforme) R√©colter, documenter et cadrer les expressions de besoins en mati√®re de rapports, structurer une feuille de route et prioriser les sujets en fonction des enjeux l√©gaux, op√©rationnels et m√©tiers D√©velopper, d√©ployer, maintenir et am√©liorer les m√©triques et rapports r√©glementaires, comptables et d‚Äôint√©gration, ainsi que la mod√©lisation de donn√©e sous-jacente. Int√©grer des standards de s√©curit√©, de confidentialit√© et de protection des donn√©es personnelles En garantir la fiabilit√© et la ponctualit√© par tous les moyens n√©cessaires (optimisation du code ou de la stack, rajout de tests et d‚Äôalertes, r√©conciliations et validation de donn√©es, mise en place de bonnes pratiques DevOps) Former les interlocuteurs m√©tiers et les membres de l'√©quipe au bon usage des rapports et des tableaux de bord Etre l‚Äôinterlocuteur privil√©gi√© en cas d‚Äôaudit, et les anticiper (pistes d‚Äôaudit, ajouts de logs, conservation des m√©tadonn√©es, indempotence, conservation des rapports partag√©s, documentation, lineage, versions) Notre stack en quelques mots : Mixpanel, Appsflyer, Airflow/Airbyte, GCP dont BigQuery, dbt, Metabase, Dataiku Aussi, l‚Äô√©quipe √©tant encore en d√©veloppement, on reste tr√®s ouverts aux initiatives (technos / outils / etc.) ! Nous rejoindre, c‚Äôest la garantie de travailler dans un environnement stimulant, d‚Äôavoir de l‚Äôimpact dans la structuration de l‚Äô√©quipe et de ses process et de participer √† la croissance d‚Äôun super projet. Vous √™tes notre candidat¬∑e id√©al.e si ü§© Vous avez une exp√©rience au pr√©alable en SQL, en bases de donn√©es relationnelles, en environnement Big Data et en Data warehouse Cloud (Snowflake, Redshift, etc.) Vous avez d√©j√† occup√© un poste en mod√©lisation de donn√©es, conception de DWH et pipelines de donn√©es (orchestration, transformation, ETL ou ELT) Vous connaissez un outil de transformation comme dbt, SSIS, matillion ou Data Form (chez nous, nous utilisons dbt !) Cerise sur le g√¢teau si... üç∞ Vous poss√©dez une exp√©rience pr√©alable avec un ou plusieurs outils de visualisation de donn√©es (Looker, Tableau, Spotfire, PowerBI, Metabase, Qlik Vous avez la connaissance de BigQuery et de l‚Äôenvironnement GCP Nous sommes votre entreprise id√©ale si vous recherchez‚Ä¶ Une start-up fran√ßaise devenue scale-up qui se structure, d√©veloppe de nouveaux produits et s‚Äôexporte √† l‚Äôinternational üåé Une vision nouvelle et innovante qui d√©poussi√®re le secteur de l'assurance Un leadership inspirant et expert du secteur L'agilit√© d'une structure √† taille humaine, et la place pour des initiatives innovantes et cr√©atives Un environnement de travail respectueux de tous et toutes. En tant que membre fondateur du pacte IDEA , nous nous engageons pour la diversit√©, l'√©quit√© & l‚Äôinclusion Ce qu‚ÄôOrnikar a √† vous offrir‚Ä¶ üéÅ Une r√©mun√©ration fixe entre 47k‚Ç¨ et 55k‚Ç¨, en fonction de votre niveau d‚Äôimpact et d‚Äôexpertise observ√© pendant nos entretiens. Parmi nos avantages 1 jour de RTT par mois en plus des 25 jours de cong√©s l√©gaux Notre charte de t√©l√©travail hybride (3 jours par semaine en pr√©sentiel dans nos locaux WeWork pour les franciliens, 2 jours par mois si vous b√©n√©ficiez d‚Äôun contrat full-remote hors √éle-de-France) Une carte Swile qui vous permettra √† la fois de b√©n√©ficier de 11‚Ç¨/jour de tickets restaurant pris en charge √† 50% par Ornikar, et de 42‚Ç¨/mois de remboursement transport pris en charge √† 100% par Ornikar Un abonnement sport et bien-√™tre Gymlib Une assurance sant√© compl√©mentaire avec Alan Les frais de gestion pour votre √©pargne salariale avec Epsor La possibilit√© de passer votre permis gratuitement Des centaines de r√©ductions et avantages via Leeto , partenaire de notre Comit√© Social √âconomique L'acc√®s √† notre plateforme associative Vendredi pour vous engager en parall√®le de votre activit√© chez nous Notre process de recrutement üî• Un premier entretien avec Romane, notre Talent Acquisition Specialist ou directement avec votre futur manager Thibault. Un entretien d‚Äôune heure avec Thibault notre Head of Data Ops Assurance üî≠ Un test technique √† r√©aliser chez vous ‚öôÔ∏è La restitution du test avec l‚Äôun de nos Data Analysts/Analytics Engineer et un membre de l'√©quipe Tech üìä Une rencontre avec Aur√©lien Rayer notre Chief Data Officer et un membre d‚Äôune √©quipe m√©tier","Ornikar is looking for an Analytics Engineer to manage the relationship with external regulatory partners while taking the lead on the development, deployment, maintenance, and improvement of regulatory, accounting, and integration metrics and reports. Candidates should have experience in SQL, data modeling, cloud data warehousing, and transformation tools along with prior experience working with data visualization tools. Ornikar offers a hybrid telework policy, flexible working hours, and numerous employee benefits.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
280,56925,https://www.welcometothejungle.com/fr/companies/descartesunderwriting/jobs/data-engineer-scientific-engine-airflow-dvc_paris,"Data Engineer - Scientific Engine (Airflow, DVC) (Starting 2024)",Descartes Underwriting,"{python,Git,LAMP,spark,azure,Gitlab,Kubernetes,Airflow,GitHub,DVC,AWS,Docker,via,Linux,GCP,Python}",T√©l√©travail ponctuel autoris√©,"148 Rue de Courcelles, Paris, 75017","Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‚Äòfull stack‚Äô insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (250+ and counting) - our diverse team is headquartered in Paris and operates out of our 12 global offices in North America, Europe, Australia, Singapore, and Hong Kong. ABOUT DESCARTES UNDERWRITING Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‚Äòfull stack‚Äô insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (250+ and counting) - our diverse team is headquartered in Paris and operates out of our 12 global offices in North America, Europe, Australia, Singapore, and Hong Kong. ABOUT YOUR ROLE Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects. You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events. üîî KEY MISSIONS üîî Setup, automate, maintain and update: Connections to external and internal APIs Data preparation process Model training and inference process Data storage process Associated CI/CD pipelines Associated package versioning and releasing pipeline Modularization of code base Notification tools to inform the team of the status of the operations Setup data storage, data processing and data visualizing tools, by : Assessing the pains and needs of the teams Benchmarking the open source and private solutions Assessing the security, price and reliability of data architecture Following the development the evolution of technologies on the topic Forecasting the usage of the tools Tracking the cost of the tools Participate in: Tech stack selection Discussions with tech partners Training of software and underwriting teams Support and debug of internal users TECH STACK üñ• Ô∏è Cloud provider: GCP Code versioning tool: Git + Gitlab OS: Linux Container: Docker Container orchestrator: Kubernetes Website architecture: LAMP Code base: Python Notification tool: Slack DATA STACK üóÑ Ô∏è Types: images, timeseries, Storage: GCP bucket Version: DVC (roll out in progress) Pipeline: Airflow (PoC stage) Data base: to be setup depending on the use cases In our project, data is collected by sensors (satellite, weather station, IoT). We don‚Äôt work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation ‚Ä¶). EQUIPMENT üñ± Ô∏è Laptop: Dell Latitude 7530 OS: you decide ABOUT YOU EXPERIENCE & QUALIFICATIONS üë© ‚Äç üíªüë® ‚Äç üíª [Hard skills] Knowledge of the tech stack or equivalent tools Experience converting python code to efficient data engineering tools (eg: spark) Experience with Docker Experience with a cloud provider (GCP, AWS or azure) Experience automating a CI/CD pipeline Good knowledge in English and fluency in French [Soft skills] Desire to train junior developers and explain CI/CD and cloud tools Desire to suggest improvements to the architecture [Nice-to-have] Experience working data science project or scientific code Experience with Kubernetes Experience in HPC Contribution to an open source project MINDSET üí• Strong interest with climate issue (it‚Äôs not a hoax, many people suffer from it) Being comfortable to work alongside corporate insurers (some still wear suits üëî) You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline) Strong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed) Rigorous, creative and meticulous mind (we handle large insurance, we take our time) Strong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools) Eagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è) WHY JOIN DESCARTES UNDERWRITING? Join a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks Commitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.); Work in a collaborative & professional environment; Be part of an international team that values diversity; Benefit from a nice referral scheme for successfully referring peers; You can benefit from a hybrid work mode thanks to our telecommuting agreement. OUR COMMUNITY At Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences. With equal skills, all our positions are open to people with disabilities. HOW TO APPLY If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application! https://www.descartesunderwriting.com/careers/ If you don‚Äôt check all the requirements in the description, don‚Äôt worry. We can try to make some room for you within the company if you‚Äôre motivated to work on climate risk. RECRUITMENT PROCESS Step 1: Call and HR Interview with our Talent Recruiter Step 2: Technical project submitted via GitHub Step 3: Technical interview Step 4: Manager interview Step 5: Final round interview with the team (Candidates can opt to have the manager interview before the technical project and interview)","Descartes Underwriting is seeking a data engineer to help build and maintain data pipelines for its scientific engine modeling climate phenomena. The ideal candidate should have experience with Python, Docker, cloud providers, automating CI/CD pipelines, and Kubernetes. Additionally, the candidate should have a strong interest in climate issues and a desire to work in a collaborative environment with diverse teams from around the world. Descartes Underwriting is committed to fostering an inclusive work environment that respects all differences.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,1,1,0.027697749441558416
284,56781,https://www.welcometothejungle.com/fr/companies/the-information-lab/jobs/consultant-data-engineer-experimente_paris_TIL_dM95MA9,Consultant.e data engineer exp√©riment√©.e,The Information Lab,"{Snowflake,Alteryx,Tableau}",T√©l√©travail ponctuel autoris√©,"6, Rue Auber, Paris, 75009","Logiciels, IT / Digital, Big Data",CDI,2023-03-26,"The Information Lab a √©t√© fond√©e en 2010 par des passionn√©s de data autour des solutions Tableau, Alteryx et Snowflake. Ils sont convaincus que ce sont les meilleures technologies pour accompagner la transformation digitale de leurs clients. Cette sp√©cialisation leur permet d‚Äô√™tre les premiers partenaires de ces √©diteurs et d‚Äô√™tre des experts reconnus de ces solutions en France et en Europe. The Information Lab a pos√© ses valises en France en 2015. Ils ont aujourd‚Äôhui plus de 250 clients sur tous les secteurs d‚Äôactivit√© : banque, assurance, logistique, ONG, retail, etc. L‚Äô√©quipe est r√©partie dans toute la France, la majorit√© se trouvant √† Paris. Rattach√©(e) au p√¥le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous m√©tiers. Vos missions ont pour objet le traitement, l‚Äôanalyse, l‚Äôenrichissement des donn√©es de nos clients et l‚Äôadoption par nos clients des technologies que nous proposons. Au sein d‚Äôune √©quipe de 5 √† 8 personnes, vous r√©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre ‚Äúpod leader‚Äù (chef d‚Äô√©quipe). Votre r√¥le consiste √† : Intervenir en avant-vente et cadrer vos missions Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours √† quelques mois Mener des projets de bout en bout, en m√©thode classique ou agile, en coordination avec les √©quipes de nos clients, nos √©quipes internes et les √©diteurs partenaires Pr√©senter les livrables de vos missions et mettre en avant leur ROI Former nos clients √† nos technologies Mettre vos comp√©tences au service de vos coll√®gues au-del√† des missions dont vous avez la charge et participer au d√©veloppement des comp√©tences en partageant vos retours d‚Äôexp√©rience Participer aux activit√©s d‚Äô√©vang√©lisation, par exemple : r√©daction de posts de blogs, participation aux communaut√©s des √©diteurs, interventions lors d‚Äô√©v√©nements (salons, conf√©rences, webinaires) Participer aux projets internes (BI interne, m√©thodes & qualit√©s) Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires. Vos principales qualit√©s : Excellentes facult√©s d‚Äô√©coute et de communication, orale et √©crite Aptitude √† travailler sur plusieurs sujets en parall√®le, √† prioriser Humilit√© et capacit√© √† apprendre ainsi qu‚Äô√† transmettre ses connaissances Sens du service, un bon relationnel avec les clients et la rigueur n√©cessaire au succ√®s de leurs projets Team player Comp√©tences m√©thodologiques : Analyse du besoin et cadrage de mission Construction d‚Äôindicateurs m√©tiers √† partir de donn√©es brutes Id√©alement connaissance d‚Äôun ou plusieurs m√©tiers et de leurs indicateurs cl√©s Pr√©paration de donn√©es complexes √† des fins d‚Äôanalyse M√©thodes de gestion de projet (classique et agile) Capacit√© prouv√©e √† r√©aliser des d√©monstrations d‚Äôoutils Comp√©tences techniques : Connaissance d‚Äôau moins Alteryx Designer ou Tableau Prep (id√©alement vous avez d√©j√† une exp√©rience solide sur ces outils) Ma√Ætrise d‚Äôautres outils d‚Äôanalyse de donn√©es Connaissance de la mod√©lisation de donn√©es √† des fins d‚Äôanalyse Exp√©rience professionnelle : vous b√©n√©ficiez d‚Äôau moins 5 ans d‚Äôexp√©rience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis d‚Äôutiliser les technologies similaires aux n√¥tres. Id√©alement, vous avez d√©j√† une exp√©rience dans un cabinet de conseil ou une ESN. Langues : Fran√ßais, Anglais professionnel Situation g√©ographique : Ile-de-France. D√©placements en France √† pr√©voir. R√©mun√©ration : 50 √† 65 k‚Ç¨, selon exp√©rience. Ecrivez-nous √† jobs@theinformationlab.fr avec votre CV, et dites-nous pourquoi vous souhaitez nous rejoindre. Nos entretiens sont r√©alis√©s par vos futurs homologues, vous permettant de leur poser toutes vos questions sur leur m√©tier de consultant et la vie @ TIL !","The Information Lab is looking for a consultant with excellent communication skills, the ability to work on multiple projects simultaneously, and a desire to learn and share knowledge. The consultant should be able to analyze client needs, advise on solutions, and deliver complex data projects using Alteryx, Tableau, and similar technologies. The position requires at least five years of experience and fluency in French and English. The consultant will work with clients of all sizes and sectors and will travel within France. The salary ranges from ‚Ç¨50,000 to ‚Ç¨65,000 per year.",Bac +5 / Master,N,> 5 ans,1,1,0.027697749441558416
371,39670,https://www.welcometothejungle.com/fr/companies/ba-sh-1/jobs/data-engineer-f-h_paris,data engineer f/h,ba&sh,"{Snowflake,durable,SQL,Talend}",T√©l√©travail partiel possible,"67 Av. Raymond Poincar√©, Paris, 75116",Mode,CDI,2022-11-29,"En 2003, Barbara Boccara & Sharon Krief, entrepreneuses et cr√©atives, se lancent pour cr√©er ba&sh et son vestiaire id√©al o√π toutes les femmes pourraient s‚Äôexprimer, avec modernit√©, simplicit√© et chic. Elles offrent la possibilit√© d‚Äô√™tre libres, belles et bien. Puis, en 2015, L Catterton, le fonds d‚Äôinvestissement de LVMH, accompagne ba&sh dans son expansion internationale et son d√©veloppement en hyper-croissance, dans un environnement transform√© par la r√©volution digitale. ba&sh est une maison innovante, dynamique et tourn√©e vers les probl√©matiques de demain. Elle lance officiellement en 2021, son programme de d√©veloppement durable BLOSSOM et √©tablit un plan d‚Äôaction concret tourn√© vers une profonde transformation ambitieuse. Bien plus qu‚Äôune marque, ba&sh souhaite couvrir les th√©matiques sociales, environnementales et soci√©tales par le choix de mati√®res √©co responsables, transparence & tra√ßabilit√© dans la chaine de valeur, accompagnement des fournisseurs, suivi et r√©duction des √©missions de gaz √† effet de serre, √©conomie circulaire et innovations durables. Au sein de l‚Äô√©quipe de la direction des syst√®mes d‚Äôinformation, vous rapportez directement au Responsable de projets informatiques. A ce titre, vos missions sont les suivantes : Suivi de l‚Äôex√©cution de la roadmap technique D√©veloppement de flux Responsable de la gouvernance et le management des donn√©es Evolution de l‚Äôarchitecture du Hub √ätre force de propositions Pr√©paration des projets et des kick-offs Participer √†/organiser l‚Äô√©tablissement des sprints Garantir la bonne ex√©cution des sprints R√©daction et maintien de la documentation technique Cette liste n‚Äôest pas exhaustive et sera susceptible d‚Äô√©voluer avec le d√©veloppement de ba&sh. Vous vous reconnaissez dans ce parcours : Formation sup√©rieure Bac +4/+5 type √©cole d‚Äôing√©nieur ou formation sp√©cialis√©e en informatique App√©tence/int√©r√™t prononc√© pour le domaine du retail Au moins 3 ann√©es d‚Äôexp√©rience sur un poste similaire en tant que data engineer Vous vous d√©marquez pour votre : Structuration, rigueur et sens du d√©tail Esprit transverse et votre relationnel Curiosit√©, proactivit√©, rigueur et organisation App√©tence pour faire de la veille technique et suivre les sujets li√©s √† la data. Vous maitrisez : Parfaitement Talend, le PL/SQL, la mod√©lisation de donn√©e et les r√®gles de gouvernance associ√©es. La connaissance de la Cloud Data Platform Snowflake serait un plus. ba&sh n‚Äôattend plus que vous ! Chez ba&sh, nous croyons que la diversit√© est une force, et nous nous engageons √† la cultiver. La diversit√© sous toutes ses formes (genre, √¢ge, nationalit√©, culture, croyances religieuses, orientation sexuelle, ‚Ä¶) enrichit les √©changes et le cadre de travail, favorisant ainsi le d√©veloppement de l‚Äôentreprise & de chacun des individus qui la composent. En tant qu‚Äôemployeur qui positionne l‚Äô√©galit√© des chances au c≈ìur de son syst√®me de valeurs, nous accueillons et consid√©rons les candidatures de l‚Äôensemble des candidats qualifi√©s et comp√©tents. Nous nous engageons √† continuer √† avancer vers un ba&sh toujours plus inclusif, o√π chaque employ√© d√©veloppe un fort sentiment d‚Äôappartenance. Si vous souhaitez rejoindre une marque en pleine expansion avec une vraie philosophie, faites-nous parvenir votre candidature.","ba&sh, a French clothing brand focused on sustainability, is seeking a data engineer to join its information systems team. The ideal candidate will have at least three years of experience in a similar role, a background in computer science or a related field, and strong knowledge of Talend, PL/SQL, data modeling, and data governance. The data engineer will manage data flows, improve data architecture, propose innovative solutions and contribute to the development of sustainable practices within the company. Diversity is at the heart of ba&sh's values, and the company encourages all qualified candidates to apply.",Bac +4,Entre 250 et 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
94,73664,https://www.welcometothejungle.com/fr/companies/enedis/jobs/system-team-engineer-dataops-f-h_courbevoie_ENEDI_kRNw38z,System Team Engineer DataOps,Enedis,"{Python,Scala,Teradata,Linux,MEM,Jupyter,Kafka,Hadoop,Bash,Spark,UNIX,mem,Git}",T√©l√©travail partiel possible,"11 place des Vosges, Courbevoie, 92400",Energie,CDI,2023-04-22,"Enedis est une entreprise de service public, gestionnaire du r√©seau de distribution d'√©lectricit√©. Elle d√©veloppe, exploite, modernise le r√©seau √©lectrique et g√®re les donn√©es associ√©es. Elle facilite la transition √©nerg√©tique des territoires en les accompagnant dans le d√©veloppement et la planification de leur production d'√©lectricit√© d'origine renouvelable. Ses 39 000 collaborateurs assurent chaque jour les raccordements des clients, le d√©pannage 24h/24, le relev√© des compteurs et toutes les interventions techniques. Ind√©pendante, Enedis d√©livre la m√™me qualit√© de service aux fournisseurs d'√©nergie. Comme le pr√©voit la loi, elle a √©tabli un code de bonne conduite auquel ses collaborateurs sont form√©s afin d'en respecter les principes et engagements au quotidien. La DSI d'Enedis se positionne comme partenaire des m√©tiers et cultive sa dimension entrepreneuriale et d'anticipation au service d'Enedis, de ses clients et des territoires. Elle propose une offre de services industrielle, performante et innovante, garantissant l'agilit√© du Syst√®me d'information dans un contexte de forte num√©risation des m√©tiers. Avec un effectif d'environ 600 collaborateurs, la DSI est au coeur des transformations d'Enedis. Engag√©e notamment dans l'essor des solutions SmartGrids, dans l'adaptation du Syst√®me d'Information √† la transformation num√©rique ou dans le positionnement d'Enedis comme op√©rateur de donn√©es, la DSI met en oeuvre de nombreux projets majeurs en lien avec les m√©tiers concern√©s. Chez Enedis comme chez EDF, ce sont au total 230 m√©tiers qui composent notre activit√© et permettent chaque jour de travailler √† cr√©er un monde neutre en CO2. Oublions les id√©es re√ßues, oui vous pouvez travailler chez Enedis m√™me si vous n'√™tes pas √©lectricienne ou √©lectricien. Pour accompagner ses clients tout en r√©pondant aux d√©fis de la transition √©nerg√©tique et num√©rique, le Groupe mobilise toutes les comp√©tences, en France et √† l'international. Envie d'en savoir plus ? Consultez notre site internet https://www.edf.fr/edf-recrute/pourquoi-choisir-edf/lesraisons-de-rejoindre-edf Le monde de l'IT et des nouvelles technologies vous int√©resse ? Contribuer √† la r√©ussite de la transformation digitale et num√©rique du Groupe EDF vous plairait ? Et travailler en mode collaboratif dans des espaces de travail innovants, inspirants et √©panouissants ? C'est ce que nous vous proposons en rejoignant une √©quipe dynamique, agile et passionn√©e ! Un des enjeux majeurs d'Enedis est de devenir un op√©rateur de confiance de Donn√©es √©nerg√©tiques. Afin de r√©pondre √† cet enjeu, Enedis a mis en place une plateforme de donn√©es pour l'entreprise. Cette plateforme est compos√©e d'une infrastructure de donn√©es centralis√©e construite sur Hadoop et d'outils √† destination des √©quipes produit ou des DataScientists utilisent la plateforme Big Data. Nos ambitions sont de transformer et d'am√©liorer cette plateforme sur plusieurs axes : migration vers le cloud, √©volution de l'architecture avec en cible une plateforme modulaire composant des services manag√©s, automatisation et mont√©e en gamme de l'offre de services internes permettant aux √©quipes de gagner en autonomie dans la cr√©ation de v√©ritables produits de donn√©es. Dans le cadre de ses missions, le/la System Team Engineer DataOps : - sera technical leader d'une des √©quipes du train SAFe DataServices4U - √©quipe SPHINX, en charge de l'infrastructure data des activit√©s exploratoires (big data, big mem, GPU) - d√©finira, d√©veloppera, mettra en place et maintiendra les outils et infrastructures ad√©quats aux op√©rations du reste du train (√©quipes data scientists et data engineers). - veillera √† garantir les op√©rations des solutions permettant le traitement de volumes importants de donn√©es tout en garantissant la s√©curit√© de celles-ci - d√©finira les enablers √† prendre en compte dans l'√©quipe - sera Tech. Lead d'une √©quipe d'une dizaine de personnes - testera les r√©alisations de l'√©quipe - contribuera aux d√©monstrations faites aux √©quipes produits utilisatrices de la plateforme B4ALL - se synchronisera avec les autres technical leader et avec l'architecture train du train SAFe B4ALL Votre Profil ? - Vous √™tes issu d'une formation de type Bac +5 dans le domaine de l'IT / syst√®me d'information / Num√©rique et DATA - Vous disposez d'une exp√©rience d'au moins 4 ans dans des activit√©s √©quivalentes, au cours desquelles vous avec avez d√©velopp√© de solides comp√©tences techniques - Vous avez un profil Ing√©nieur Big Data disposant de comp√©tences d'analyse, de synth√®se, de cr√©ativit√© et d'une app√©tence pour l'innovation. - Vous avez de bonnes connaissances de l'administration syst√®me UNIX : ma√Ætrise de Linux (Redhat), Bash - ainsi que composants s√©curit√© et CI (Git, Kerberos..) - Vous maitrisez Hadoop, Spark, Teradata, Kafka - Vous avez de bonnes connaissances en technologies DataScience (Python, noeuds Big MEM et GPU, Scala, Jupyter, etc.) - Vous avez d'excellentes capacit√©s de communication (orales et √©crites) permettant de travailler avec un grand nombre d'acteurs, ainsi que des capacit√©s de coordination - Vous faites preuve de curiosit√©, d'esprit de synth√®se, de m√©thodologie et de rigueur dans un environnement complexe Le poste est situ√© √† Courbevoie, avec une possibilit√© de t√©l√©travail partiel. La r√©mun√©ration sera propos√©e selon vos comp√©tences, vos exp√©riences acquises et vos dipl√¥mes. L'√©tude de r√©mun√©ration sera effectu√©e en ad√©quation avec le march√© de l'emploi actuel. Par ailleurs, des primes variables sur les r√©sultats, int√©ressement, √©pargne salariale sont mises en place. Cette mission est un moyen id√©al d'accro√Ætre votre valeur professionnelle, vos comp√©tences et de progresser vers d'autres directions du Groupe. Alors n'h√©sitez pas, rejoignez-nous, ce poste est fait pour vous ! Dans le groupe EDF accueillir des personnes en situation de handicap fait partie de notre ADN. Notre objectif est d'ouvrir nos portes √† toutes les comp√©tences, toutes les √©nergies et toutes les personnalit√©s sans exclusion. Le poste propos√© est donc ouvert √† toutes et √† tous. Venez d√©couvrir nos diff√©rents r√©seaux qui oeuvrent √† favoriser la mixit√© dans le groupe : https://www.edf.fr/edfrecrute/pourquoi-choisir-edf/un-employeur-responsable/egalite-professionnelle-0",,Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
368,56685,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-f-h_suresnes_AXA_wgNQjro,Data Engineer,AXA,"{Databricks,Git,Scala,Kubernetes,Docker,Spark,Azure,NoSQL,SQL,Python}",T√©l√©travail partiel possible,Suresnes,"Banque, Assurance, FinTech / InsurTech",CDI,2023-03-26,"Avec 6 000 recrutements par an en France rejoignez AXA, un leader mondial de l‚Äôassurance et de la gestion d‚Äôactifs. Ils accompagnent plus de 105 millions de clients qui leurs font confiance pour leurs biens, leur famille, leurs collaborateurs, leur patrimoine ou les actifs de leur entreprise. Chaque jour, ils agissent ensemble pour vous prot√©ger en donnant √† chacun les moyens de vivre une vie meilleure. Un challenge qui donne le sourire ! L‚Äô√©quipe ¬´ Big Data ¬ª de Direct Assurance a pour mission principale de contribuer √† la dynamique continue d‚Äôinnovation et de perfectionnement de l‚Äôentreprise en r√©solvant des probl√©matiques business concr√®tes par la mise en place d‚Äôune plateforme Data dans le Cloud, ainsi que la conception et la r√©alisation de solutions techniques de data science en s‚Äôappuyant sur des sources de donn√©es vari√©es tant en interne qu‚Äôen externe. Vos missions seront les suivantes : Proposer des architectures et orienter le choix des technologies adapt√©es aux besoins de diff√©rents projets Data Concevoir et mettre en ≈ìuvre les traitements d‚Äôalimentation du DataLake et de transformation des donn√©es Garantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats Identifier, collecter, explorer, comprendre et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnelles Assurer le suivi de la production Participer, avec l‚Äô√©quipe, au d√©veloppement de la plateforme sur Azure et √† la d√©finition des bonnes pratiques de d√©veloppement Accompagner les √©quipes m√©tier dans la prise en main de la plateforme Azure et les aider √† monter en comp√©tences en programmation en s‚Äôassurant du respect des standards internes Environnement technique : Spark, Scala, Python, Cloud Azure, OpenShift, SQL De formation Bac+5 (ou plus) en d√©veloppement informatique / data engineering, vous justifiez d'une premi√®re exp√©rience en stage ou alternance au cours desquels vous avez pu d√©velopper les comp√©tences techniques suivantes : Spark Scala + Python Cloud Azure (DataFactory, ADLS, Databricks) Bonnes connaissances sur les architectures de donn√©es et le cloud Solides connaissances des processus collaboratifs et outils de d√©veloppement (DevOps, Git, CI/CD‚Ä¶) SQL Les qualit√©s suivantes sont n√©cessaires : Bonne facult√© pour appr√©hender les couches technologiques et les outils Capacit√© √† travailler de mani√®re collaborative au sein d‚Äô√©quipes pluridisciplinaires Autonomie, grande rigueur, pragmatisme et r√©elle capacit√© √† d√©livrer Bon niveau d‚Äôanglais, parl√© et √©crit Les connaissances suivantes seraient un plus : OpenShift, Docker, Kubernetes Framework de stream processing Data visualisation Bases NoSQL Le poste est bas√© √† Suresnes (92) √† proximit√© de la D√©fense.","AXA is hiring a Big Data Engineer for its Direct Assurance team to work on data science solutions for both internal and external data sources. The successful candidate should have experience with Spark, Scala, Python, Cloud Azure, OpenShift, and SQL as well as solid knowledge of collaborative processes and development tools. The role requires an ability to work collaboratively in a multidisciplinary team and good English language skills. The position is located in Suresnes, France.",Bac +5 / Master,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
151,56417,https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-e-technique-etl-powercenter-informatica-h-f_paris,Expert.e technique ETL Powercenter Informatica,CGI,{Informatica},T√©l√©travail partiel possible,Paris,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"Leader mondial du conseil et des services num√©riques, CGI est convaincue que l‚Äôinnovation technologique permet aussi bien d‚Äôacc√©l√©rer la transformation de la soci√©t√© et de son √©conomie, que le d√©veloppement de ses collaborateurs. Sa mission, accompagner au quotidien les entreprises et les administrations dans leur transformation pour les rendre plus performantes. 30 agences r√©parties partout en France Des synergies en Europe de l‚Äôouest et du sud (Belgique, Luxembourg, Espagne, Portugal, Maroc, Roumanie) Tous les secteurs d‚Äôactivit√©s repr√©sent√©s (Banques, assurances et services financiers, CPG, retail et luxe, √ânergie & Utilities, Industrie, Secteur public, Transport) 4 m√©tiers : business consulting, int√©gration de syst√®mes, business solutions, managed IT services D√©veloppement, cybers√©curit√©, big data, intelligence artificielle‚Ä¶ Autant d‚Äôenjeux qui rythmeront votre quotidien. Vous √™tes passionn√©.e par le D√©cisionnel et la Data et avez d√©j√† une tr√®s solide exp√©rience sur l‚Äôoutil ETL Powercenter Informatica. Vous souhaitez diversifier vos comp√©tences pour √™tre toujours √† la pointe des nouvelles technologies et souhaitez rejoindre une entit√© sp√©cialis√©e dans la data et l‚Äôinnovation (> 250 consultants Data). Vous √©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements m√©tiers vari√©s avec un niveau de responsabilit√© √©lev√©. Vous aurez √©galement la possibilit√© de monter en comp√©tences sur d‚Äôautres outils Data que ceux de votre domaine de comp√©tences initial. Votre r√¥le au sein du Centre d‚ÄôInnovation Digitale aura de tr√®s nombreuses facettes, toutes orient√©es vers un seul et m√™me objectif : Contribuer √† la transformation digitale et au succ√®s de nos clients. Vos missions sont : ‚Ä¢ Analyser, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place ‚Ä¢ Travailler en collaboration avec les ing√©nieurs et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques autour de l‚Äôint√©gration de donn√©es ‚Ä¢ Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre des projets ‚Ä¢ Animer des formations internes et externes. Accompagner la mont√©e en comp√©tences des √©quipes ‚Ä¢ Assurer un support technique aux √©quipes et aux clients au quotidien ‚Ä¢ Participer aux avants ventes en tant qu‚Äôexpert.e ETL Powercenter Informatica ‚Ä¢ Participer aux √©changes avec l‚Äô√©diteur Powercenter ‚Ä¢ Participer √† la qualification technique de candidats en recrutement Fort d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique, dans le consulting autour de l‚Äôint√©gration de donn√©es, ou dans une fonction de Chef.fe de Projet BI. - Passionn√©.e d‚Äôinformatique d√©cisionnelle, vous aimez le travail en √©quipe, apprendre, partager. - Vous √™tes √©galement dot√©.e d'un esprit audacieux et ambitieux. - Vous faites preuve d‚Äôinitiative et travaillez sur le long terme. - Vous justifiez d‚Äôau moins 3 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil en tant qu‚Äôexpert.e technique dans le domaine de l‚Äôint√©gration de donn√©es. - Vous justifiez √©galement et si possible d‚Äôune pratique en tant que consultant.e technique dans des projets en mode forfait. Des connaissances dans les domaines de la qualit√© de donn√©es, de la gouvernance des donn√©es ou dans le MDM ou sur Informatica Cloud sont un plus. CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.","CGI is a global leader in digital consulting and services, helping companies and administrations transform to become more innovative and efficient. They are seeking a technical expert in data integration with at least 3 years of experience, particularly with ETL Powercenter Informatica. The role involves analyzing solutions to improve efficiency, collaborating with engineers to find technical solutions, leading internal and external training, and providing technical support to teams. The successful candidate will have opportunities for growth into technical leadership, data integration consulting, or BI project management. Knowledge of data quality, governance, MDM, or Informatica Cloud is a plus. CGI is an inclusive employer dedicated to the career development and well-being of all employees.",Non sp√©cifi√©,> 2000 salari√©s,> 3 ans,2,0,0.027697749441558416
445,56425,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-engineer_utrecht,Data Engineer,Artefact,{},NaN,"Utrecht, 3511","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that‚Äôs why we identify as ‚Äúmarketing engineers‚Äù. In order to improve the performance and impact of brands, and consumers‚Äô experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). Who we are Artefact is a new generation of a data service provider, specializing in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organizations. We are proud to say we‚Äôre enjoying skyrocketing growth. We have 1100+ employees across 16 offices who are focused on accelerating digital transformation and marketing excellence with our 1000+ clients. Thanks to a unique mix of company assets: State of the art data technologies, agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client. What you will be doing: Key responsibilities As a Data Engineer, your role will encompass: Conducting ambitious projects in the transformation of clients through data Collaborating with the other Divisions (Activation, Creativity, and Strategy) to provide comprehensive services to your clients Developing privileged relationships with our clients, using your technical abilities to assist in the transformation of their marketing department You‚Äôll also participate in international projects. Among your responsibilities as a Data Engineer, you will be responsible for: Performing data projects Securing delivery on your projects Communicating your work and achievements among the team Working closely with your Consulting counterpart to build and maintain strong relationships with your clients and best understand their needs Ensuring that your solutions are bringing value to the client Being a good team player, knowing your role and responsibility in the global ambition Being a great tech person Demonstrating the skill and credibility required to ensure the success of our clients‚Äô initiatives Researching and developing new technical approaches to address problems efficiently Sharing best practices and contributing to Artefact‚Äôs institutional knowledge Embodying Artefact‚Äôs values and inspiring others to do the same Qualifications: Education & experience required A Master‚Äôs degree in computer science, machine learning, mathematics, or related fields Hands-on experience developing and applying data-driven solutions in a corporate or consulting setting, preferably in a consumer marketing context (experience in the web industry is a plus) Strong knowledge of computer science, data processing, algorithms, and data architecture Intellectual curiosity and excellent problem-solving skills, including the ability to structure and prioritise an approach for maximum impact What we are looking for A Doer : you get things done and inspire your teams to do the same An Analyst : you LOVE data and think every company should take their decisions with facts A Pragmatist : you have a hacker mindset and always find the quick wins A Mentor : your clients and teams naturally seek for advice An Adventurer : you‚Äôre an entrepreneur constantly looking for problems to solve We welcome people from all nationalities, and background, but are focusing on people who already reside in The Netherlands. Why you should join us Artefact is the place to be: come and build the future of marketing Progress: every day offers new challenges and new opportunities to learn Culture: join the best team you could ever imagine Entrepreneurship: you will be joining a team of driven entrepreneurs. We won‚Äôt give up until we make a huge dent in this industry! Come join us!","Artefact, a consulting firm specializing in AI and data, is seeking a data engineer to help transform clients through data by collaborating with other divisions, developing relationships with clients, and performing data projects. The ideal candidate should have a master's degree in computer science or a related field, hands-on experience with data-driven solutions, and excellent problem-solving skills. Additionally, they should be a doer, analyst, pragmatist, mentor, and adventurer. Artefact offers a challenging and entrepreneurial environment for career growth.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
143,50432,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-preparation-london-or-remote-uk_london,Software Engineer Data Preparation - London or Remote UK,Dataiku,"{Jupyter,go,Dataiku,Javascript,regard,Kubernetes,Redshift,dataiku,Snowflake,Synapse,dataset,Spark,K8s,BigQuery,Azure,Java,SQL,Python}",NaN,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. As enterprises worldwide become more and more invested in the cloud, Dataiku looks to expand its services and offerings to adapt to rapidly shifting customer needs. Dataiku brings together Big Data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with user-friendly visual interfaces or code. To help us fulfill this mission, we are looking for a talented full-stack software engineer to work on the Data preparation part of Dataiku and other core features of the platform. Our current technical stack is based on a mix of Java, Javascript and Python. The mission of the Designer & OPALS teams is to maintain and improve the core features of Dataiku that are dedicated to Business Analysts & Developers, such as: Data preparation & integration: this includes reading from and writing to Snowflake, BigQuery, Redshift, Azure Synapse, and processing data using the latest processing engines: Spark on K8s, SQL with UDFs SQL workbench & Jupyter notebooks Integration with IDEs Help and onboarding experience - Plugins infrastructure Automation & public REST APIs What you will be doing: Support new databases capabilities to read/write or process data faster Optimize our layout engine to be able to render flows of 1000 datasets faster Improve our help system to make it smarter Bring spatial joins and isochrone computing to the platform Improve dataset upload experience using A/B testing Add support for graphically explain plans in our SQL workbench You are the ideal recruit if: You have experience in software development and are interested in data processing. You are ""customer-oriented"" you want to understand how the product is used and solve actual customer problems You know, Data science is 80% preparing data and 20% complaining about preparing data. You are curious about working '≈ìunder the hood' and want to learn how things are built. You have firsthand experience (either professional or personal) in building a real product. You are humble and kind. You don't hesitate to ask questions when you don't know, and treat your colleagues with respect, kindness, and honesty. Dataiku's culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits. You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines. You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more. You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week . You care about giving back - it's what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing . If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a full-stack software engineer to work on the Data preparation part of their platform, as well as other core features. The ideal candidate should have experience in software development and an interest in data processing, be customer-oriented, and have firsthand experience in building a real product. They should also be humble, kind, and curious about working ""under the hood."" Dataiku offers a flexible work-life balance, autonomy, and opportunities for learning and giving back. They are an equal opportunity employer committed to treating all employees with dignity, decency, and fairness.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
214,65905,https://www.welcometothejungle.com/fr/companies/longevity-partners/jobs/database-engineer_austin,Database Engineer,Longevity Partners,"{MySQL,Azure,MongoDB,shell,DuckDB,PostgreSQL,AWS,Cassandra,Linux,R,SQL,NoSQL,MariaDB,Python}",NaN,"Austin, 78701","Environnement / D√©veloppement durable, Energie, Immobilier commercial",CDI,2023-04-05,"Founded in 2015, Longevity Partners assists and advises real assets businesses at every stage of their ESG approach, to turn environmental and social issues into levers for value creation throughout their activities. With offices in ten cities around the world, Longevity Partners has established itself as a reference in the field of independent ESG consulting. This presence has been growing steadily over the years, to the point of being recognised by the Financial Times as the fastest growing ESG consultancy in Europe in 2022. Longevity Partners assists companies in the transition to a low-carbon economy, particularly in the following areas: Analysis of the challenges; definition of ESG strategies; facilitation of the deployment and development of programs related to social responsibility Implementation of operational solutions for environmental and social efficiency Support for the validation of asset performance Sustainable design, asset repositioning, Net-Zero Carbon, identification, and management of climate risks Company Overview Longevity Partners is a multi-disciplinary energy and sustainability consultancy and investment business. It was established in 2015 to support the transition to a low carbon economy in the UK, USA, Europe and worldwide. Position Overview: The company is recruiting a Database Engineer who can provide vision & creativity to new data environments that can transform the way Longevity Partners delivers value to its clients. This critical role is an exciting opportunity that will involve building and maintaining the development of a new database ecosystem that can enable information to move seamlessly throughout our company. An ideal candidate will use their extensive knowledge of back-end infrastructure to enable meaningful, human-oriented data products that can power critical decision-making both within Longevity and on behalf our clients. The team is currently managing a wide variety of internal and client-side projects, even though this position will not be responsible for interfacing directly with clients. This position reports to the Associate Director of Data Science + Analytics and is based principally in our offices in Austin, TX, with minimal expectations for travel. Essential Functions Build and maintain database ecosystems that are high-quality and reliable Design + build both NoSQL + SQL database warehouses Orchestrate data backups + recovery processes Analyze database performance, pain points, and implement improvements to speed + efficiency Ensure data security and protection across both storage and transfers Help develop ETL and data pipeline maps Provide thoughtful + responsive management support for database ecosystems Define, enforce and document database policies, protocols and best-practices. Design + perform tests and evaluations processes to ensure data security, performance, and integrity Assist with monitoring databases, implementing required upgrades and resolving critical issues. Requirements 5+ years of experience as a Database Administrator or Architect Extensive experience with database standards and developing end-user applications Exceptional problem solving skills. Excellent understanding of conventional SQL, query optimization and NoSQL databases (MongoDB, MariaDB, Cassandra, PostgreSQL, MySQL) as well as emerging tools like Apache Arrow, Arrow Flight, + DuckDB Experience with cloud database management systems like Azure and AWS Experience with time series databases preferred Excellent knowledge of data backup, recovery, security, integrity Experience with database design, documentation and optimization Prior experience using DBA case tools (frontend/backend) and third-party tools Knowledge and experience with Linux, shell, networking tools, and version control Experience working and developing with APIs ETL experience programming in R or Python (Preferred) Experience designing and maintaining APIs or API wrappers (Preferred) BS or graduate degree in a computer-related discipline or relevant certification (Preferred) Experience or familiarity with Shiny, RStudio Connect, and Quarto ‚Äã Benefits Employee Health and Dental Benefits that are 100% Paid For by LP Guaranteed 401k Retirement Contributions by Employer Generous PTO Offerings Fun and Relaxed Office Environment Ability to work in a hybrid working environment","Longevity Partners, an ESG consultancy firm, is seeking a Database Engineer to develop and maintain a high-quality and reliable database ecosystem. The ideal candidate should have at least five years of experience as a Database Administrator or Architect, with exceptional problem-solving skills and extensive knowledge of SQL, NoSQL databases, and emerging tools like Apache Arrow and DuckDB. The position comes with health and dental benefits and a 401k retirement plan, among other benefits.",Bac +3,Entre 50 et 250 salari√©s,> 5 ans,0,1,0.013848874720779208
228,60138,https://www.welcometothejungle.com/fr/companies/thales/jobs/alternance-data-engineering-supply-chain-f-h_bordeaux,Alternance ‚Äì Data engineering supply-chain,Thales,"{durable,POWERBI}",NaN,Bordeaux,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",Autres,2023-03-28,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? L‚Äôactivit√© Syst√®mes de missions de d√©fense fournit des √©quipements, des solutions et des services li√©s aux syst√®mes de combat √©lectroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Sur le Campus Thales Bordeaux, nous concevons, d√©veloppons et livrons des syst√®mes, des √©quipements et des services pour assurer la r√©ussite des missions a√©roport√©es de nos clients, dans les domaines du transport, de la surveillance et du combat. La Direction Industrielle recherche un alternant en tant que Data engineering supply-chain (F/H), au sein du Campus Thales Bordeaux. QUI ETES-VOUS ? Issu d‚Äôune formation de niveau BAC+3 √† dominante informatique, vous recherchez une alternance d‚Äôune dur√©e de 1 √† 2 an(s) ? Vous avez des connaissances g√©n√©rales en Supply chain ? Vous avez des comp√©tences significatives en d√©veloppement logiciel VBA, POWERBI ? Id√©alement, vous ma√Ætrisez le traitement de donn√©es et vous avez un fort int√©r√™t pour les syst√®mes d‚Äôinformations de production ? Vous savez faire preuve de rigueur, d‚Äôune bonne capacit√© d‚Äô√©coute, d‚Äôanalyse et de synth√®se ? Vous √™tes force de proposition, dot√© d‚Äôun bon relationnel ? Vous appr√©ciez collaborer et travailler en √©quipe ? Votre niveau d‚Äôanglais vous permet de lire, √©crire et parler avec des termes techniques ? Vous vous reconnaissez ? Alors vous avez de bonnes chances de vous √©panouir dans nos √©quipes ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE : Au sein du Centre de Comp√©tence Industrie de Thales Defence Mission Sytems, vous int√©grerez le D√©partement Supply-chain. Dans le cadre de vos missions, en support aux activit√©s du service data management, vous serez en charge de d√©velopper des tableaux de bord de pilotage supply-chain. Vous serez int√©gr√© √† une √©quipe de 10 personnes sur le campus Thales Bordeaux En nous rejoignant, vos principales missions seront les suivantes : ‚Ä¢ Prendre en charge de la mise √† jour des indicateurs de pilotage de la supply-chain industrielle et du reporting associ√© aux supply-chain managers et responsables de ligne de production. ‚Ä¢ D√©velopper des outils d‚Äôaide √† la d√©cision √† partir d‚Äôextraction des donn√©es de l‚ÄôERP en s‚Äôappuyant sur les rapports BI existants et en les personnalisant par des macro excel et des traitements POWERBI ‚Ä¢ Maquetter des reports pour r√©pondre aux besoins op√©rationnels des lignes de production Au fil du d√©veloppement de vos comp√©tences, vous serez amen√© √† prendre en charge la sp√©cification aux √©quipes de d√©veloppement BI des besoins des utilisateurs et √† en assurer le suivi jusqu‚Äô√† la mise en place (d√©veloppement, test, mode op√©ratoire, support). Le rythme de l'alternance doit permettre, dans la mesure du possible, d'assurer une continuit√© dans les missions. Cette alternance sera l‚Äôopportunit√© pour vous de travailler en √©quipe au sein d‚Äôune entreprise innovante, de valoriser les acquis acad√©miques en environnement industriel et d√©velopper de nouvelles comp√©tences. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales is looking for an alternate Data Engineering Supply-Chain, with knowledge in supply chain and software development. The candidate should be interested in information systems and have significant competence in VBA Development and Power BI. They should be able to work in a team, have a good sense of analysis and proposal, and have proficiency in reading, writing, and speaking with technical terms in English. The main duties include developing and updating dashboards for industrial supply-chain management using ERP data and existing BI reports, developing decision-making tools for different production lines, and personalizing reports according to production line requirements. The candidate will also need to provide user requirements to the BI development team, aid the development of BI tools, and deliver support.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
244,4069,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/saas-full-stack-developer_paris,Software Engineer Dataiku Online - Paris,Dataiku,"{React,go,Dataiku,python,regard,Kubernetes,Docker,Python}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Dataiku is looking for an experienced developer with an interest in SaaS platforms to join the team in charge of developing the Dataiku Online Launchpad. This role is an opportunity to be an early member of a team who launched an exciting new project, with a strong and direct impact on the final outcome. What we do: The mission of the Dataiku online‚Äôs team is to offer the best Dataiku DSS experience for small data teams growing their AI maturity. The Dataiku online platform consists of a cloud infrastructure and a launchpad, the component where Dataiku Online users can manage their DSS instance(s), invite users to contribute, set up some data sources and manage the Dataiku souscription. What you will be doing: The role consists in actively participating in the design and implementation of a SaaS portal associated with the managed service offering. Here are some examples of what you might do: Develop new features to provide the smoothest experience for users so that they can benefit the power of DSS in a few clicks on the online environment. Ease installation and lifecycle management of the DSS instances running on our infrastructure. Improve the quality of the code to ensure high availability and low latency for the platform. Work with other Dataiku services to provide a more customized experience for online users. Our current technical stack is python (Flask) for the backend of the launchpad and VueJS for the frontend. The position is either at the company HQ in Paris (Gare de Lyon) or remote. You are the ideal recruit if: You have experience working on a full stack application and know that backend and frontend code are two sides of the same coin and you are eager to use both. You have a first experience (either professional or personal) building a real SaaS portal. You are customer-oriented ‚Äî you want to understand how the product is used and solve actual customer problems. You are humble and kind. Bonus points for any of these: - Hands-on expertise working with Docker and Kubernetes - Experience on an high availability SaaS - Knowledge in DataScience, AI and Machine Learning - Advanced knowledge in Python (Flask) and Vue.JS (Or React/ Angular) Dataiku‚Äôs culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking an experienced developer with expertise in full-stack development and an interest in SaaS platforms. The role involves actively contributing to the design and implementation of a SaaS portal associated with the managed service offering. The ideal candidate has experience building a real SaaS portal, is customer-oriented, and has working knowledge of Python (Flask) and Vue.JS. Bonus points for expertise in Docker and Kubernetes, experience on a high availability SaaS platform, and knowledge in data science, AI, and machine learning. The position can be either at the company headquarters in Paris or remote.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
439,50212,https://www.welcometothejungle.com/fr/companies/mantu/jobs/data-engineering-manager_madrid,Data Engineering Manager,Mantu,"{Microsoft,Azure,Synapse,GIT}",NaN,"Madrid, 28014","Logiciels, IT / Digital, Organisation / Management",CDI,2023-02-07,"Mantu is an independent and international consulting player, founded in 2007. Mantu stands out for the breadth of its intervention spectrum, which responds to all the challenges of business transformation. Its activities are divided into 4 practices: Leadership & Advocacy, Technology, Digital Marketing & Experience, Total Talent Management. A wide range of skills, all serving a single mission: connecting and powering companies with leading team and technology, to succeed faster and sustainably. From its headquarters in Geneva, Switzerland, Mantu relies on a community of 10,000 talented people in more than 60 countries on 5 continents and a turnover of 810 million euros. Mantu is strongly committed to the development of its talented people and their skills. Its community of over 110 nationalities guarantees a multicultural experience. An experience characterized by the group‚Äôs strong confidence in its teams: whether in young people, by offering them rapid career development, or in the autonomy and level of responsibility entrusted to them. Whatever their specialty or activity¬¥s sector, all Mantu brands address environmental and social issues with the same determination to align the pioneering spirit dear to its DNA with our collective responsibility. Your role: As a data engineering manager, you will primarily manage, coach, and develop a data engineering team. Coordinate with analyst and report maker on needs, fulfil and organize backlog. Deliver, with your teammates, new features, data flows and datasets efficiently with Microsoft Azure Data services (Data Factory, Synapse, Database, Datalake, Logic Apps) and Power BI. Dispatch development across your team members, organize plannings and deliveries. Review team code, ensure quality, manage source control (GIT) and CI/CD (Azure Dev Ops) operations. Analyze data engineering issues and requests to provide strong support to users‚Äô communities. Works to set the data vision and roadmap with head of department, IT, and governances. Profile description : ‚Ä¢ You are Data enthusiast and have strong technical experience specifically in the development of datawarehouse or something equivalent‚Ä¢ You already have project management habits.‚Ä¢ You like to drive and follow multiple tasks & projects at the same time. You are able to prioritize and estimate technical tasks within the team.‚Ä¢ You are solution oriented and find technical ways to answer needs. You plan sustainable solutions.‚Ä¢ You are graduated from Engineering School or hold an IT Master Degree‚Ä¢ You have between 4 and 10 years of experience minimum working in Microsoft Data and Azure topics. DevOps experience is a plus.‚Ä¢ You are a proactive person who like to learn new things. You are curious, you like to understand the global picture and work in international teams","Mantu, an international consulting firm, is seeking a data engineering manager to lead and develop a team, coordinate with analysts and report makers, deliver new features and datasets using Microsoft Azure Data services and Power BI, manage source control and CI/CD operations, analyze issues and requests, and set the data vision and roadmap. The ideal candidate should have strong technical experience in data warehouse development, project management skills, ability to prioritize and estimate technical tasks, and hold an Engineering School degree or IT Master Degree with at least 4-10 years of experience in Microsoft Data and Azure topics. DevOps experience is a plus, and the candidate should also be a proactive learner who enjoys working in international teams.",Bac +5 / Master,> 2000 salari√©s,> 10 ans,0,1,0.013848874720779208
130,37283,https://www.welcometothejungle.com/fr/companies/dhl-information-services/jobs/senior-dwh-bi-data-engineer_praha,DWH/BI Data Engineer,DHL Information Services,"{PowerBI,Teradata,tabular,Azure,SQL,DAX,Tableau}",NaN,N,"Application mobile, Logiciels, Intelligence artificielle / Machine Learning, Robotique",CDI,2022-10-18,"Deutsche Post DHL, the world‚Äôs leading logistics company with the distinctive yellow-red logo needs no introduction. Even though DHL IT Services are a part of it, you will not find any packages here. In DHL IT Services, they provide IT services to all Deutsche Post DHL divisions: DHL Express, DHL Supply Chain, DHL Global Forwarding & Freight, Post & Parcel and e-Commerce. They are a global IT organization with two key data centers ‚Äì one in Kuala Lumpur/Cyberjaya (Malaysia) and one here in Prague. Do you enjoy crunching data? Do you feel at home when writing T-SQL statements, making the code as lean as possible and optimising query performance? Do you have experience with database backups and restores and other database and server administration? Or you like to get your hands dirty with data on Azure? Are you eager to learn Teradata SQL? Does it bring you joy to turn raw data into valuable information and insights to help your business colleagues to make better business decisions? If your answer is yes, then we must definitely talk! You will be: ‚Ä¢ Involved in development of strategic DWH/BI solutions using SQL Server, Teradata, Analysis Services, Azure Data Service and Power BI ‚Ä¢ Participating in requirement analysis and solution design ‚Ä¢ Cooperating with other developers, eventually technical leading of the product team ‚Ä¢ Providing ad-hoc analyses of data by SQL querying and possibly using presentation layer of choice (Tableau, PowerBI, Excel..) ‚Ä¢ Improving performance of current long-running queries ‚Ä¢ Connecting new data sources ‚Ä¢ Performing unit testing of your code and peer review of the pull requests from your team colleagues using Azure DevOps ‚Ä¢ Working In DevOps oriented culture with high trust, high spirit and great colleagues that make you smile every day You should have: ‚Ä¢ Passion about data ‚Ä¢ Experience with database and dimensional modelling for DWH/BI solutions ‚Ä¢ Ability to write advanced T-SQL queries ‚Ä¢ Advanced knowledge of SSAS ‚Äì tabular model ‚Ä¢ Experience in Database and Windows Server Administration ‚Ä¢ Experience with database and dimensional modelling for DWH/BI solutions‚Ä¶ ‚Ä¢ Knowledge of DAX and PowerBI ‚Äì knowledge of Tableau would be a bonus ‚Ä¢ Azure skills are very welcome ‚Ä¢ Ability to manage your time efficiently to avoid over-commitments ‚Ä¢ Ready to learn extremely fast in a very agile, high pace environment. ‚Ä¢ Pro-active and critical thinking ‚Ä¢ Continuous improvement mindset You will get from us: ‚Ä¢ Great team of professionals and possibility of development ‚Ä¢ Modern offices in Chodov next to metro station ‚Ä¢ Home office possibilities ‚Ä¢ Permanent contract ‚Ä¢ CAFETERIA employee benefit program with wide selection of benefits from Edenred ‚Ä¢ Extra week of holiday (25 days/year) ‚Ä¢ 6 Self-sickness days/year ‚Ä¢ Full salary compensation for up to 10 days absence due to illness per calendar year ‚Ä¢ Lunch vouchers fully covered by company ‚Ä¢ Multisport card ‚Ä¢ Mobile and laptop ‚Ä¢ Fruit days, sport clubs for employees ‚Ä¢ Referral program In DHL ITS Prague, you will have the opportunity to be part of over 1650 highly skilled IT professionals of 67 nationalities. Would you like to develop your career in DHL ITS Prague ‚Äì the largest data center operation in the Czech Republic? Start your application now!","DHL IT Services is seeking a Data Warehouse Developer to develop strategic DWH/BI using SQL Server, Teradata, Analysis Services, Azure Data Service and Power BI. The ideal candidate should have a passion for data, experience with database and dimensional modelling for DWH/BI solutions, advanced T-SQL query writing ability, and know-how of SSAS Tabular Model. The role involves working in a DevOps culture and providing ad-hoc analyses of data, improving query performance, and connecting new data sources. The benefits include a modern office, home office possibilities, employee benefit programs, extra week of holiday, and more.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
300,63012,https://www.welcometothejungle.com/fr/companies/sifflet/jobs/data-engineer_paris,Data Engineer,Sifflet,"{Azure,Scala,AWS,scale,Sifflet,GCP,Java,SQL,Python}",T√©l√©travail ponctuel autoris√©,"5, Rue des Italiens, Paris, 75009","Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data",CDI,2023-03-31,"Created in 2021, Sifflet is an early-stage start-up backed by Tier 1 investors. We are building the world‚Äôs best observability platform to enable companies to trust their data and excel at data-driven decision-making. It‚Äôs normal if you‚Äôve never heard of data observability because we‚Äôre building this category! We are based in Paris but serve organizations from all over the world, from scale-ups to large enterprises. Young, ambitious, and extremely passionate about data. We are looking for an experienced Data Engineer to join our ML engineers Marie and Gwenna√´lle. In this role, you will, Design, build, and maintain the infrastructure required for data processing and analysis (we‚Äôre still at the beginning, there‚Äôs a lot to build) Work closely with all the teams to ensure that the data infrastructure supports the needs of the organization and enables data-driven decision-making. Collaborate with the engineering team to solve technically complex challenges, hiring, and shaping the culture. This is a key moment to join Sifflet, as we‚Äôre still a small team with a lot of room to grow: you‚Äôll have a major impact on the development of our data-driven initiatives. You have a BS/MS/PhD in a scientific field or equivalent experience. You have at least 3 years of experience in data engineering , ideally in a start-up. Strong technical skills in areas such as data modeling, database design, ETL processes, data warehousing, and programming languages such as SQL, Python, Java, and Scala. Strong knowledge of a major cloud environment (AWS, GCP, or Azure) You have excellent communication skills and the ability to adapt messaging to technical and non-technical audiences. You are autonomous, organised, self-motivated and able to drive ambitious projects to success from conception through coding to deployment. You value ownership of your projects from design to production .","Sifflet, a data observability startup, is seeking an experienced Data Engineer to design, build, and maintain the company's infrastructure required for data processing and analysis. The ideal candidate should have at least 3 years of experience in data engineering, strong technical skills in data modeling, database design, ETL processes, data warehousing, as well as programming languages such as SQL, Python, Java, and Scala. Additionally, the candidate should have strong knowledge of a major cloud environment (AWS, GCP, or Azure), excellent communication skills, and the ability to adapt messaging to technical and non-technical audiences.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,> 3 ans,1,0,0.013848874720779208
136,48256,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/bi-engineer-finance-tableau-dataviz-bi-factory-f-m-d_croix,DataViz Engineer - Financial Solutions,Decathlon Technology,"{AWS,dataset,GCP,SQL,Github,Tableau}",NaN,"4 Rue du Professeur Langevin, Croix, 59170","Grande distribution, Sport, E-commerce",CDI,2023-02-05,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOIGNEZ LES EQUIPES DATA DE LA BI FACTORY DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Pour r√©pondre au mieux √† son ambition de pilotage par la data, Decathlon a organis√© une DATA UNIT √† laquelle la BI Factory est rattach√©e. L‚Äô√©quipe BI Finance est une composante de la BI Factory et r√©pond aux besoins des process m√©tiers suivants: Stock & marge Comptabilit√© Omnicommerce Encaissement Production Tr√©sorie Achats Syst√®mes financiers TA RESPONSABILITE : Au sein de l'√©quipe BI Finance, ta mission principale consiste √† : R√©pondre √† des demandes d‚Äôanalyses r√©currentes de KPIs en mettant √† disposition des m√©tiers, de mani√®re automatique et r√©guli√®re, des outils de data visualisation performants. Intervenir d√®s la finalisation du cadrage projet par le Project Manager jusqu‚Äô√† la livraison en production et assurer le run de la solution ; Interagir avec le collectif Data : les autres Dataviz Engineers, les m√©tiers, les experts des data domains, les scrum masters et le BI Manager. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e Dataviz Engineer, bas√©-e dans la r√©gion Lilloise. Le p√©rim√®tre technique : Ma√Ætrise de Tableau Software (QlikSense un plus) Ma√Ætrise du SQL Ma√Ætrise d'un ETL/ELT un plus R√©daction de documentation dans Github M√©thodologie Agile (SAFE) CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience d‚Äôau moins 3 ans en d√©veloppement de data visualisation et parle un Anglais courant (relation avec des √©quipes √† l'international). Tu as d√©j√† produit de la data visualisation performant avec Tableau Software Pour r√©ussir, tu dois savoir: Comprendre le besoin m√©tier / interagir avec les interlocuteurs fonctionnels Comprendre un mod√®le de donn√©es et t'en servir. Mod√©liser un dataset afin de d√©velopper des visualisations en assurant les performances techniques D√©velopper le flux d‚Äôextraction des data n√©cessaires au produit final Apporter une expertise sur la visualisation des KPIs et faire des propositions correspondant aux usages m√©tiers exprim√©s lors du cadrage Ma√Ætriser les technologies utilis√©es et les bonnes pratiques de d√©veloppement Partager ton avancement et les difficult√©s rencontr√©es lors des instances AGILE d√©di√©es. R√©diger la documentation technique permettant d‚Äôassurer un run efficace Tu es particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle t'a permise d‚Äôacqu√©rir dans ton style de leadership et la vie en √©quipe ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes, Lyon, Londres, Madrid et Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a Data Visualization Engineer in the Lille region to support its mission of making sports accessible to everyone through innovative digital products and sustainable practices. The successful candidate will have at least three years of experience in developing data visualizations using tools such as Tableau and a strong understanding of SQL and ETL/ELT processes. The engineer will work with the BI Finance team to develop and deliver automated and high-quality data visualization solutions to meet the needs of various business processes. The ideal candidate must be comfortable interacting with different stakeholders, understanding business requirements, and complying with agile methodologies. Decathlon offers flexibility, growth opportunities, certification programs, employee shareholding, and a diverse and inclusive work environment.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
23,67013,https://www.welcometothejungle.com/fr/companies/salsify/jobs/data-systems-integration-engineer_lisbon,Data & Systems Integration Engineer,Salsify,"{go,Athena,color,Boomi,Workato,Looker,Alteryx,SQL,Domo,Python,Tableau}",NaN,"Lisbon, 1050-115","SaaS / Cloud Services, Big Data",CDI,2023-04-07,"Salsify was created to empower brands and retailers to win on the digital shelf. Salsify solutions offer unique functions to help drive results. For Manufacturers Empowering brand manufacturers to manage, syndicate, and optimize product content for winning shopping experiences. For Retailers Empowering retailers to create engaging, high-quality shopping experiences for the digital shelf. For Distributors Empowering retail distributors to manage unique ecommerce product data management needs. Come join a company who is a key leader in the industry scaling the next core commerce infrastructure and on the path from $100M to $500M! Founded in 2012, Salsify helps brand manufacturers, distributors, and retailers in over 80 countries collaborate to win on the digital shelf. As the market leader globally, our products are shopper-centric, frictionless, and create memorable commerce experiences. Our products provide a competitive edge through experiences that improve brand trust, amplify product differentiation and assortments, increase conversion rate, improve profit margins, and speed time to market. Learn how the world‚Äôs largest brands, including Mars, L'Oreal, Coca-Cola, Bosch, and GSK, as well as retailers and distributors such as E.Leclerc, Carrefour, Metro, and Intermarch√© use Salsify everyday to stand out on the digital shelf. At Salsify, we strive to embody an equitable, diverse, and inclusive company culture. We are united across countries, levels, tenures, and a host of other dimensions of diversity. We understand that while work is just one aspect of who we are, a truly inclusive culture accounts for the full authenticity of every single human being that works here. About the Opportunity Are you a data and / or a systems integration junkie? Do you like to work with new technology to solve complex technical issues related to moving data (ELT/ETL), building data models, or providing systems integration / automation solutions? The role of the Data & Systems Integration Engineer is a new role at Salsify on our Business Technology team, and it‚Äôs a role that is expected to have a high impact on our Data & Automation strategy across the business. In this individual contributor role, you will have the opportunity to work on solutions like Domo, Workato, Boomi, Alteryx, and Amazon Athena. You also may have the opportunity to use your Python skills as we evaluate different solutions and identify how existing systems can integrate with other systems or pull / push data to our data warehouse and business intelligence platforms. We are looking for someone who has an appetite for a big challenge and is ready to demonstrate their technical skills. A majority of your role will be focused on using out-of-the box solutions, but we also welcome creativity, innovation, and ideas on how to solve problems most effectively. While the majority of your work will be focused on technical tasks such as building ETL jobs, data models, or systems integration solutions, there is a customer service component that is important to the job too. Being customer friendly, collaborative, and authentic are important traits to the role as well. How You'll Make an Impact: Become the subject matter expert for how to build and manage our data warehouse Become the go-to person for all things related to data and systems integration Become well versed in capabilities of the technologies that we support internally for data and systems integration Create a governance model that allows data stewards and analysts to self-serve their data needs Develop relationships, build trust, have a high quality mindset, and collaborate effectively with others Don‚Äôt let your ego get in the way of success You'll Enjoy This Role If You Have: Must have prior experience working in a data engineer or systems integration role SQL, Python, and other data modeling / querying languages are required Must be able to understand and articulate the pros and cons of various data warehouse, ETL/ELT, data modeling, and business intelligence solutions Experience with BI tools such as Domo, Looker, or Tableau is preferred Experience working with systems integration tools like Boomi or Workato is preferred Experience working on teams that support internal business operations (e.g. IT, Business Systems) is preferred What We Have for You: Competitive Salary Equity Unlimited Vacation Medical, Dental and Vision Insurance (Multicare) Life Plan Meal Allowance Referral Bonuses #LI-KT1 #LI-Remote Salsify loves a good success story and it would be our privilege to help write yours! We recognize that talent and potential come in all forms and that years of experience does not guarantee on the job effectiveness or leadership potential. Our hiring process involves recognizing a person‚Äôs achievements, subject matter expertise, and passion, not just check marks next to a job description. If you have an interest in our roles please do not hesitate to apply - we would be happy to speak with you! A member of Talent ' talent@salsify.com ' will be reaching out about next steps if we would like to move forward. Salsify‚Äôs mission is to empower brand manufacturers to win on the digital shelf. Helping brand manufacturers to win online is what we do. Our culture is who we are. We are empowered. We are positive thinkers. We take action. We care deeply. These values have driven Salsify‚Äôs growth and earned the company numerous top workplace awards. We are headquartered in Boston, Massachusetts and have hubs in Lisbon (Portugal), Paris (France), and Sydney (Australia). If you are excited to work in a fast-paced environment with a team that values agility, curiosity and passion, we want to hear from you! Please see our Candidate Privacy Statement for information on the personal data we process in connection with your application. An Inclusive Place To Work Salsify does not discriminate based on race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. Studies have found that people of color and women do not apply to jobs if they do not meet all the requirements. At Salsify we are committed to empowering a diverse workforce. We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Accommodations Salsify is committed to an inclusive hiring process, and we aim to provide accommodations for persons with disabilities. If you need any accommodations for the application or throughout the interview process please contact cx@salsify.com .",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
448,56560,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_brest_ASI_KV32Rpz,Data Ing√©nieur - Manipulation et valorisation des big-datas,ASI,"{MySQL,Oracle,ElasticSearch,Scala,Kafka,Cassandra,PostGreSQL,Spark,SQL,Java,NoSQL,Hadoop,Python,Cloudera}",NaN,Brest,"IT / Digital, Transformation, Big Data",CDI,2023-03-26,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Vous aurez pour mission de : Concevoir et r√©aliser un sourcing de donn√©es Big Data Temps r√©els ou non Ma√Ætriser les formats de donn√©es non structur√©s et savoir les manipuler Concevoir et r√©aliser une cha√Æne de traitement dans un environnement Big Data Concevoir et r√©aliser des applications et API utilisant les donn√©es valoris√©es G√©rer et administrer les bases de donn√©es filesystem et NoSQL Ecosyst√®me en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, Big Query Langages de d√©veloppement‚ÄØ: Python, Java, Scala. Id√©alement titulaire d‚Äôun Bac+4/5 (Ecole d‚ÄôIng√©nieur ou Universitaire), vous maitrisez : Hadoop (Cloudera)et/ou une solution de base de donn√©es NoSQL Le requ√™tage SQL, HiveQL Le d√©veloppement Spark avec SQL, Python et/ou Scala Le d√©veloppement Java (API en particulier) Les bases de donn√©es relationnelles (PostGreSQL, Oracle, SQLServer, MySQL‚Ä¶)","ASI, a digital expertise firm committed to responsible and positive impacts through digital transformation, seeks a Big Data Consultant to design and implement data processing and API applications in Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, and BigQuery using Python, Java and Scala. The ideal candidate holds a bachelor's or master's degree in engineering or computer science and has experience in Hadoop, NoSQL databases, SQL querying, Spark, Java and SQL databases.",Bac +4,Entre 250 et 2000 salari√©s,> 5 ans,0,1,0.013848874720779208
3,72829,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/an-apprentice-12-24-months-data-engineering-m-f_paris,An apprentice 12/24 months ‚Äì Data Engineering,Sanofi,"{Python,Scala,JavaScript,NoSQL,SQL}",NaN,"54 Rue la Bo√©tie, Paris, 75008",Pharmaceutique / Biotechnologique,CDI,2023-04-22,"At Sanofi, we pursue the miracles of science to improve people‚Äôs lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi‚Äôs roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Sanofi is dedicated to supporting people through their health challenges. We are a global biopharmaceutical company focused on human health. We prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. We stand by the few who suffer from rare diseases and the millions with long-term chronic conditions. With more than 100,000 people in 100 countries, Sanofi is transforming scientific innovation into healthcare solutions around the globe. Sanofi, Empowering Life In this context, Sanofi is looking for: AN APPRENTICE ‚Äì DATA ENGINEERING (M/F) Location: Paris (XVIIe) Assignment : Within the Digital Health Department and in connection with your tutor, you will participate in an international project on a high-impact drug. In this context, your missions will consist in: Support connected ecosystem solutions such as patients‚Äô glycemic control and full disease management, leveraging connected pens, Help building symptom checking apps able to understand diseases and track symptoms, Participate in creating remote treatment solutions to provide individual recommendations, accessible by anyone, anytime, anywhere, Support personalized care models, informed by Artificial Intelligence, to identify symptoms‚Äô early signals and recommend corrective actions to the patient and the care giver. Required profile : You are looking for an apprenticeship contract of 12/24 months , starting between September and October 2023 as part of a training of level BAC +4/+5 or equivalent in Computer Science, Engineering with math background. For this position, you justify a first experience or knowledge of programing languages such as Python, Scala and different database systems such as SQL, NoSQL. Knowledge in JavaScript is a plus. Self-starting and self-motivating team player, your rigor and your analytical mind allow you to carry out your missions. Open-minded, you enjoy working in a team and interacting on transversal topics. If you are interested in our mission, send us a CV and cover letter. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.",,Bac +4,N,Non sp√©cifi√©,0,1,0.013848874720779208
236,11359,https://www.welcometothejungle.com/fr/companies/smart/jobs/data-engineering-manager_paris_SA_DJe9ND0,Data Engineering Manager,Smart AdServer,"{Insider,color,Scala,Kafka,scale,R,Spark,blend,Dataflow,GCP,Java,Hadoop}",NaN,Paris,AdTech / MarTech,CDI,2022-01-25,"Smart est une AdTech fran√ßaise proposant une plateforme de mon√©tisation publicitaire √† destination des plus importants sites web dans le monde. Leur objectif‚ÄØ? Disrupter l‚Äôindustrie de la publicit√© digitale avec des solutions performantes, des formats innovants et toujours plus de qualit√©. Bas√©e en plein c≈ìur de Paris (IX·µâ), la soci√©t√© poursuit son d√©veloppement international avec d√©sormais 12 bureaux dans le monde (ouverture du bureau de Singapour en 2019) et rejoint les classements ‚ÄúChampions de la Croissance‚Äù par Les Echos et ‚ÄúFast 500 EMEA‚Äù par Deloitte. Leur fiert√© ? Une team de plus de 420 Smarties qui s‚Äô√©panouissent √† travers une culture d‚Äôentreprise pr√¥nant l‚Äôownership et qui vit √† travers 4 valeurs essentielles : Care, Innovation, Transparency et Excellence. üë´ About the team At Smart, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic. Our innovation team based in Paris, Krakow and Nantes is composed of 90 straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges. ü§ùYour mission At Smart, Data is core. We ingest tens of billions of events daily. This data is then transformed and crunched to be used by our customers and everybody throughout the company (BI analytics, data science ML algorithms, customer reporting, invoicing and more) Our Data Engineering Team is responsible for building a scalable and robust platform that handles log ingestion, data storage and optimization, aggregation and external access through dedicated APIs. You report directly to our CTO and you are responsible for our data stack, as well as designing its future evolutions to make it more reliable, more powerful, more flexible. ‚úèÔ∏è What you'll do Manage the Data Engineering team and hire new talents Promote a strong engineering culture and passion for quality and things well done Drive and design a highly performing and robust data pipeline Define platform KPIs (latency, accuracy, response time, ‚Ä¶) and associate them to ambitious objectives Identify data needs and design systems to guarantee the success of new projects Interact with other managers and team leads to guarantee a smooth delivery of our R&D wide projects üëáAbout you 2+ years successfully managing and leading an engineering team Passion for large scale data ecosystems (several PBs of stored data, billions of events per day) Experience with big data technologies in production (Hadoop, Spark, Kafka, Java, Scala, ‚Ä¶) Experience with the GCP stack (Dataflow, Big Query, pub/sub, ...) Enthusiasm to discover and push new technical environments Fluent in English and French Master Degree in a technical field (Engineering, Computer Science, Applied Math) üëã About us Headquartered in France, Smart employs over 420 employees in 12 countries in Europe, America, and Asia. The company is backed by private equity, led by Capital Croissance through a management buyout operation in 2019. With the recent acquisitions of LiquidM (2019) and DynAdmic (2021), Smart accelerates its growth in three key areas - CTV&OTT, US expansion & Marketer Services. The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies. Smart has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment. Smart works directly with hundreds of buyers and more than 1,000 publishers worldwide including Meredith, Insider, The Guardian, Cafe Media, Groupe Marie Claire, Le Figaro, Altice, and PlutoTV to deliver display, video, native, and rich-media ads to over 50,000 sites and apps. Thanks to its holistic ad monetization platform (Adserver/SSP/Buyer Tools/DSP) , brands can achieve greater efficiency through their advertising spend and publishers can act with certainty and have the control they need to provide the right blend of transaction models, channels, format (Display, Audio, Video, CTV, Mobile) and audience data to deliver true value path optimization to brands. Come and lead the charge with us in building a transparent ecosystem based on quality . ---------------------- Smart AdServer is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@smartadserver.com This content is blocked Youtube cookies are required to show you this content Accept cookies","Smart is an AdTech company based in Paris, with a team of over 420 employees in 12 countries. They are looking for a Data Engineering Manager to lead their data engineering team and manage the development of a scalable and robust data platform. The ideal candidate should have experience managing engineering teams, a passion for large-scale data ecosystems, experience with big data technologies, and be fluent in English and French.",N,N,N,0,1,0.013848874720779208
15,4806,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/analytics-engineer_paris,Analytics Engineer,Dataiku,"{UNIX,Dataiku,regard,PostgreSQL,S3,Snowflake,R,SQL,Python}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2022-01-01,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Dataiku is looking for an Analytics Engineer to join our fast-growing Product team, who will work on the collection and processing of our product usage data. Your role will be key in supporting the development of our product. Your missions will be run in tight partnership with several Dataiku‚Äôs key teams: R&D, Marketing, Operations and Customer... In this role, you will: Define, lead, maintain our data pipeline collecting usage data of our product ( available both as a SaaS and on-premise). Contribute to and leverage our analytics stack (Dataiku Platform, Amazon S3, PostgreSQL, Snowflake, etc...) and build automations for your team. Build a framework and provide recommendations (including for efficiency and performance of the SQL queries) to data analysts from other teams so that they can leverage product usage data. Support the Product team and provide insights or reports around specific product usage questions. Work with Product and Engineering teams to build, maintain, and refine high-level dashboards for specific features or user types. You might be a good fit if you have: Master‚Äôs degree or equivalent: engineering school, business school, etc‚Ä¶ 2-4 years of experience working with large data sets for analytics Strong knowledge of SQL and relational databases Ability to code in Python Knowledge of basic terminal UNIX commands Ability to synthesise data into a suitable format to drive actionable insights for Product and Customers teams Great attention to details and ability to work independently Enjoy sharing & learning from others About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking an analytics engineer to work on the collection and processing of product usage data, with the aim of supporting the development of the firm's AI platform. The successful candidate will help to define, lead and maintain the data pipeline for both on-premise and SaaS deployments. The role requires experience working with large data sets for analytics, with working knowledge of SQL and relational databases, and coding skills in Python, and shell scripting. Dataiku promotes a culture of diversity, dignity, and fairness as an equal opportunity employer.",Bac +5 / Master,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
14,72983,https://www.welcometothejungle.com/fr/companies/groupe-seloger/jobs/data-engineering-geo-engineering-team_paris,Data Engineering - Geo Engineering Team,Groupe SeLoger,"{PostgresQL,Github,Python,Jenkins,Datadog,Grafana,Docker,R,Kubernetes,Airflow,AWS,SQL,ElasticSearch,GCP}",NaN,"7 Boulevard Haussmann, Paris, 75009","Application mobile, IT / Digital, M√©dia",CDI,2023-04-22,"Le Groupe SeLoger est LA marketplace des portails immobiliers en France qui accompagne et aide les Fran√ßais dans la r√©alisation de tous leurs projets immobiliers depuis 30 ans . Notre mission est d‚Äôoffrir √† chacun de nos utilisateurs, une exp√©rience immobili√®re simple et efficace afin qu‚Äôils concr√©tisent leurs projets d‚Äôachat, de vente ou de location en toute s√©r√©nit√©. Nous mettons √† disposition des Fran√ßais le plus large choix d‚Äôannonces afin de leur faciliter la recherche d‚Äôun bien selon leurs crit√®res propres, et r√©pondre √† toutes les questions soulev√©es par la r√©alisation d‚Äôun projet immobilier. Avec 52 millions de visites par mois , Le Groupe SeLoger est la marque pr√©f√©r√©e des Fran√ßais pour se rep√©rer et se lancer dans leur projet immobilier. Le poste Nous recherchons un Data Engineer GEO pour rejoindre l‚Äô√©quipe charg√©e des relations entre vendeur et agent au sein de l‚Äôentit√© Marketplace du groupe. L'√©quipe Data Science est charg√©e de produire et d'exposer les insights les plus pertinents sur le march√© du logement (cartes de prix, outils d'estimation, ...) et les analyses data-driven √† un large public : particuliers, agents immobiliers, institutions priv√©es et publiques. Au sein de ce p√¥le, notre √©quipe Geo Engineering est compos√©e de plusieurs profils ayant une forte expertise en g√©ographie informatique (sources de donn√©es g√©ographiques, mod√©lisation vectorielle, g√©ocodage, application web de cartographie‚Ä¶) et des comp√©tences en extraction et traitement de l'information, gestion de bases de donn√©es, architecture syst√®me et logicielle ‚Ä¶ Nous travaillons en √©troite collaboration avec des doctorants, docteurs en math√©matiques, √©conomie, finance et statistique, Machine Learning et Data Engineers. Vos responsabilit√©s Int√©grer et consolider les meilleures sources de donn√©es g√©ographiques dans des mod√®les de donn√©es sp√©cialis√©s pour faciliter le d√©veloppement de nos projets de R&D Exposer des APIs et UIs g√©ographiques (querying, geocoding, mapping, routing, ‚Ä¶) √† haute disponibilit√© et forte volum√©trie pour assurer le d√©veloppement de nos plateformes immobili√®res Renforcer l'√©quipe Data Science en leur fournissant un environnement de R&D stable Garantir le bon fonctionnement (production, exposition, surveillance) et √©volution de nos plateformes immobili√®res Comp√©tences recherch√©es A une forte exp√©rience en Python et SQL * Incarne les valeurs d'entraide, bienveillance et qu√™te de l'excellence Est rigoureux, curieux, autonome et constructif A une forte app√©tence pour et/ou une premi√®re exp√©rience en syst√®mes d'information g√©ographique Outils GCP, AWS Python, Docker, Airflow, PostgresQL, ElasticSearch, Kubernetes Github, Jenkins, ArgoCD, Terraform, Grafana, Datadog Postgis, GDAL, QGIS",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,0,1,0.013848874720779208
321,56492,https://www.welcometothejungle.com/fr/companies/bpi-france-digital/jobs/data-engineer-core-banking-system-f-h_toute-la-france,Data Engineer Core Banking System  ‚Äì France enti√®re (Hybride),Bpifrance.io,"{durable,Python,Jenkins,Gitlab,Kubernetes,attentive,AWS,Kafka,Spark,Docker,Datadog,Mongodb,Aws,Postgresql}",NaN,Toute La France,FinTech / InsurTech,CDI,2023-03-26,"Bpifrance, une banque pas comme les autres Bpifrance, Banque publique d'investissement est une banque citoyenne qui accompagne les entreprises, de l'amor√ßage jusqu'√† la cotation en bourse, du cr√©dit aux fonds propres. Si nous sommes une structure historique, organis√©e et reconnue, nous avons l‚Äôesprit agile et rapide et les moyens de notre transformation. Nous sommes LA banque partenaire des entrepreneurs, pr√©sente √† leurs c√¥t√©s au c≈ìur de nos 50 implantations. Pr√©sents √† chaque √©tape de leur vie ; nous rejoindre c‚Äôest ≈ìuvrer pour leur comp√©titivit√© et une mission d‚Äôint√©r√™t g√©n√©rale. Notre ambition ? Devenir une Fintech . Et nous avons besoin des meilleurs ! Nous souhaitons transmuter pour devenir une FINTECH et offrir les meilleurs services digitaux √† l‚Äôensemble de nos clients, gr√¢ce √† des plateformes digitales : plateformes d‚Äôoctroi de pr√™t en ligne et la Banque en Ligne Bpifrance (BEL). Le go√ªt du challenge Notre challenge: d√©ployer toutes les solutions Tech d'aujourd'hui, de demain, et ainsi offrir √† nos clients des outils adapt√©s et novateurs, tout en ayant une conscience Green IT afin de servir l'avenir de fa√ßon durable. Vos missions au service de l‚Äô√©conomie fran√ßaise Nous recherchons un data engineer ¬´ pas comme les autres ¬ª !‚Äã ‚Äã Rejoignez l‚Äô√©quipe Core Banking System du train Data & IA et contribuez √† la transformation Data Centric de BPIFRANCE. Au sein de la plateforme Cloud AWS, vous contribuerez √† la construction d‚Äôune architecture Data compos√©e de comptoir de donn√©es, c≈ìur du SI, et de Micro-Services acc√©l√©rant la valorisation de la donn√©e pour nos clients. ‚Äã ‚Äã En plus de cela, vous serez impliqu√©.e sur :‚Äã ‚Äã Concevoir et d√©velopper des pipelines de donn√©es des comptoirs de donn√©es‚Äã Mettre en place des tests unitaires et d‚Äôint√©gration‚Äã R√©aliser des d√©ploiements des flux‚Äã Documenter les flux de donn√©es produits‚Äã Assurer le RUN des comptoirs‚Äã Participer √† la conception, au refactoring et aux choix techniques en collaboration avec le Techlead‚Äã Participer aux d√©veloppement des bonnes pratiques DevSecOps pour am√©liorer la fiabilit√© et la fr√©quence des d√©ploiements‚Äã Participer √† toutes les c√©r√©monies de l‚Äôagilit√© √† l‚Äô√©chelle de l‚Äôentreprise (SAFe)‚Äã ‚Äã Vous serez en interaction avec les architectes, Tech Leads et Data Designer du train. Votre environnement technique sera le suivant : Data : Postgresql, Atlas Mongodb‚Äã Cloud : stack Aws ‚Äã Langages / Frameworks : Python, Spark, openApi, API Gateway‚Äã Architecture : Microservices, API (REST), √âv√®nementiel (Kafka, Kstream)‚Äã DevSecOps : Gitlab, Gitlab CI, Docker, Kubernetes, Jenkins, Maven, Tanzu, Ansible, Terraform, Shifleft‚Äã Testing : Cucumber, Postman, Gherkin, Selenium‚Äã Observability : Datadog, ELK ‚Äã ‚Äã Pr√™ts √† rejoindre notre √©quipe ? Vous avez un background de data engineer talentueux et passionn√©, dot√© d‚Äôun dipl√¥me sup√©rieur en informatique. Vous avez une exp√©rience professionnelle dans des environnement bancaires √† forts enjeux sur des projets ambitieux. Vos comp√©tences en d√©veloppement ajout√© √† votre app√©tence pour les environnements DATA, font de vous un profil avec un fort potentiel.‚Äã ‚Äã Vous avez d√©j√† travaill√© dans des environnements AGILE et en Feature team d√©montrant votre capacit√© √† travailler dans des contextes challengeant.‚Äã ‚Äã Vous souhaitez continuer de d√©velopper et d‚Äôam√©liorer sans cesse les services et pratiques pour am√©liorer la qualit√© et acc√©l√©rer le delivery.‚Äã Les + du poste : Des challenges tech √† relever et des √©v√©nements tech futuristes auxquels vous serez acteur.trice et convi√©.e Vivre au rythme d‚Äôune culture Tech affirm√©e au c≈ìur d‚Äôune √©quipe soud√©e Vibrer au son d‚Äôun podcast hebdo Assister √† des Town Hall (√©v√©nements virtuels & soir√©es) trimestriels Poste ouvert sur toute la France, √† la condition d‚Äô√™tre situ√© √† moins de 3h de TGV de Paris (exemple : Nantes, Lyon, Lille, Montpellier..) Les bonnes raisons de rejoindre l‚Äôaventure Bpifrance ! Un travail avec du sens : Vous contribuerez √† une mission unique d‚Äôutilit√© publique au service de l‚Äô√©conomie fran√ßaise et au sein d‚Äôune banque engag√©e sur des sujets de soci√©t√© (climat, jeunesse, √©galit√© des chances‚Ä¶). Un environnement dans lequel il fait bon vivre : Vous int√©grerez des √©quipes dynamiques et bienveillantes, au sein d‚Äôune entreprise attentive √† la Qualit√© de Vie au Travail de ses collaborateurs. Nos certifications Happy Trainees et Meilleurs Employeurs France par Glassdoor en t√©moignent ! Des conditions avantageuses : Vous b√©n√©ficierez des nombreux avantages qu‚Äôoffre le groupe pour ses collaborateurs : t√©l√©travail, cong√©s pay√©s sup√©rieurs au minimum l√©gal, √©pargne salariale attractive, CSE, dispositifs de Qualit√© de Vie au Travail‚Ä¶ Un tremplin pour votre carri√®re : Vous profiterez des meilleures conditions mises en place chez Bpifrance pour d√©velopper vos comp√©tences et construire votre parcours de carri√®re, gr√¢ce √† un accompagnement sur-mesure et des parcours de formation complets et personnalis√©s. Travailler chez Bpifrance, c‚Äôest int√©grer une banque pas comme les autres, un projet d‚Äôentreprise ambitieux et tourn√© vers l‚Äôavenir. C‚Äôest plus qu‚Äôun m√©tier : c‚Äôest une mission, une √©quipe, un r√©seau et un √©cosyst√®me. Pour d√©couvrir nos autres opportunit√©s et tout savoir de la vie au sein du groupe, rendez-vous sur notre site carri√®re ! Bpifrance est une banque citoyenne dot√©e d‚Äôun code de d√©ontologie et d‚Äôune politique anti-corruption. Avant de postuler, nous vous invitons √† consulter notre politique relative √† la gestion des donn√©es √† caract√®re personnel disponible sur notre site.","Bpifrance, a public investment bank, is seeking a talented and passionate data engineer to contribute to its data-centric transformation. The ideal candidate should have experience working with Python, Spark, Postgresql, and MongoDB, as well as proficiency in DevSecOps tools like Docker, Jenkins, and GitLab CI. The successful candidate will work on developing robust data pipelines, implementing testing and integration protocols, deploying data flows, documenting the data produced, and improving the reliability and frequency of deployments. The role is open to candidates across France.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 5 ans,0,1,0.013848874720779208
161,49889,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-reunion-island-or-remote-europe_paris,Software Engineer Data Visualization - Reunion Island or Remote Europe,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",NaN,Reunion Island,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend).- Prototype and create new ways to import and request data at large scale.- Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions.- Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best.- Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a software engineer with experience in software development and an interest in data visualization tools. The ideal candidate should have experience building a real product, be comfortable with both front-end and back-end development, and have an eye for design. The role involves building components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way, prototyping and creating new ways to import and request data at large scale, and brainstorming new features with product managers and UX designers. Dataiku is committed to providing a rewarding, enjoyable, and diverse work experience for all employees.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
158,56968,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/data-flow-engineering-manager-f-m-d_croix,Data Flow Engineering Manager,Decathlon Digital,"{durable,Kafka,IBM,SAP}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES DATA EXCHANGE DE DECATHLON Les √©quipes Data Exchange de Decathlon ont pour mission d'√™tre garante de la cr√©ation et du bon fonctionnement des √©changes de donn√©es sur l'int√©gralit√© du SI Monde (e-commerce, retail, logistique, supply., finance, RH..) au travers des technologies Webmethods, SAP PO, MQ et Kafka. REJOINS L'√âQUIPE DATA IN MOTION L'√©quipe Data In Motion est responsable des technologies de messaging (Webmethods, SAP PO, IBM MQ) et accompagne la transformation digitale en permettant au SI de communiquer environ 84 millions de flux qui circulent par mois, gr√¢ce au travail de l‚Äô√©quipe. Dans le cadre de la croissance de l'√©quipe, celle ci cr√©√© deux postes de Team Leaders qui se r√©partirons le p√©rim√®tre technologique suivant : 1. Webmethods et SAP PO : 8 collaborateurs internes Webmethods : 552 Flows (178 critiques)24 M de messages par mois250 partenaires B2B SAP PO : 116 Flows (10 Critiques)30 M de messages par mois 2. IBM MQ, IBM ITX, AS400 : 5 collaborateurs internes 277 Flows (36 critiques)30 M de messages par mois Les deux postes en CDI de Data Flow Engineering Managers (un remplacement suite √† une mobilit√© interne, et une cr√©ation de poste) sont bas√©-e √† Lille. TES RESPONSABILITES Ton challenge consiste a assurer la responsabilit√© du pilotage de la fin de la technologie IBM MQ au profit de nouvelles technologies Co-√©crire un projet ambitieux, coh√©rent et align√© avec le domaine ainsi qu'avec la strat√©gie Groupe ; Leader une culture d'ing√©nierie saine et collaborative conforme aux valeurs de l'entreprise ; Developper les comp√©tences des co√©quipiers de ton √©quipe, les inspirer et d√©velopper leur talent ; Assurer l'animation r√©guli√®re de proximit√© du collectif dans le r√©alisation de leur mission et du projet ; D√©velopper l'efficience de tes √©quipes et mettre en place les bonnes pratiques ; Animer l‚Äô√©quipe en s‚Äôadaptant √† la diversit√© des probl√©matiques rencontr√©es et en s‚Äôengageant sur les r√©sultats ; Assurer la performance durable de ton activit√© et le respect de tes engagements. CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as une exp√©rience d'au moins 2 ans en management directe d'une √©quipe technique (forte autonomie de l'√©quipe) ; Ton style manag√©rial est particuli√®rement orient√© sur la collaboration et l'empowerment de l'√©quipe ; Tu as une bonne culture technique et une app√©tence pour la data - sans √™tre un expert de telle ou telle technologie - tu recherches l‚Äôimpact sur une strat√©gie technique et porter une vision et partager tes points de vue avec tes co√©quipier-e-s (co-construction) ; Tu as une exp√©rience dans la gestion, l‚Äôencadrement et le mentorat en vue de fournir avec eux des solutions de haute qualit√© Tu as envie de rejoindre une entreprise √† impact positif Le plus de ta candidature : ton parcours t'a permis d'avoir une exp√©rience dans les √©changes de donn√©es chez un retailer, un √©quipementier ou une ESN (projet forfait exclusivement). CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination, et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien","Decathlon is seeking two Data Flow Engineering Managers to lead and develop their Data in Motion team responsible for ensuring the successful operation of Webmethods, SAP PO, IBM MQ and other technologies which help to process up to 84 million flows, as part of the Decathlon worldwide SI. Responsibilities include: overseeing IBM MQ technology‚Äôs termination, collaborating on ambitious projects, leading with a healthy engineering culture, developing team members' skills and making sure their collective efforts align with project completion goals. Candidates should have at least 2 years of direct technical team management experience, an interest in data and technical expertise. Decathlon offers a diverse work culture, two days of telecommuting per week, and the opportunity to work with an impact-driven company in a collaborative and empowering work environment.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,0,1,0.013848874720779208
145,2272,https://www.welcometothejungle.com/fr/companies/softbank-robotics-europe/jobs/ingenieur-data-f-h_paris,Ing√©nieur data,SoftBank Robotics Europe,"{GIT,Mapreduce,Python,Jenkins,EMR,Scala,Shell,Redshift,Glue,AWS,Hadoop,Linux,Spark,Java,SQL,Jupyter,EC2,Tableau}",NaN,Paris,"Objets connect√©s, Robotique",CDI,2021-12-27,"SoftBank Robotics Europe (SBRE) con√ßoit des robots interactifs et bienveillants. Filiale du groupe mondial SoftBank et leader en robotique humano√Øde, SoftBank Robotics Europe est bas√©e √† Paris et emploie 350 personnes. Cr√©atrice des robots NAO & Pepper, aujourd‚Äôhui utilis√©s dans plus de 70 pays, dans des domaines aussi divers que la recherche, l‚Äô√©ducation, la distribution, la banque, le tourisme, la sant√© ou le divertissement, SoftBank Robotics Europe a pour objectif de rendre leurs robots accessibles √† tous pour qu‚Äôils deviennent des compagnons du quotidien. NAO est le premier robot de l‚Äôaventure, un vrai pr√©curseur qui a conquis le monde acad√©mique. Pepper, quant √† lui, est d√©j√† le nouveau compagnon des familles japonaises et un nouvel outil pour aider √† accueillir et informer les visiteurs dans de nombreuses entreprises. En tant qu'Ing√©nieur Data au service Cloud OSS, vos t√¢ches principales seront les suivantes : - Conna√Ætre les besoins en termes d'outils √† d√©velopper - Concevoir la m√©thode optimale pour d√©velopper les outils - Agr√©ger et stocker de grandes quantit√©s de donn√©es dans des bases de donn√©es - D√©velopper des outils de visualisation de donn√©es et analyser les KPI - Conna√Ætre les besoins en termes d'analyses pr√©dictives - Concevoir la m√©thode optimale pour faire les analyses - D√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins - Conna√Ætre les besoins en termes d'int√©gration des syst√®mes d'information - D√©velopper des outils qui unifient les diff√©rentes sources de syst√®mes d'information Requirements Comp√©tences techniques demand√©es : - Ma√Ætrise de la manipulation de grandes bases de donn√©es IOT (Internet Of Things) pour la flotte mondiale des robots et de diverses sources de donn√©es (Spark, Hadoop, No SQL, Streaming, Mapreduce) - Ma√Ætrise d'outils d'analyse de donn√©es : Jupyter, Jupyter Hub - Ma√Ætrise des frameworks des machines learning / deep learning : Tensor flow, Scikit-learn - Bonnes connaissances du d√©veloppement Cloud (AWS, EMR, EC2, Glue, Redshift, RDS‚Ä¶) - Exp√©rience du syst√®me GIT, Jenkins, Terraform, Ansible - Ma√Ætrise des langages : Python, Linux, SQL, Shell scripting ; en plus : Scala, Java - Un plus : connaissance des outils de visualisation (Tableau, AWS Quicksight) Comp√©tences relationnelles : - Savoir communiquer et se faire entendre Autres comp√©tences requises : - Ma√Ætrise de l'anglais ou du japonais professionnel ; Ma√Ætrise du chinois appr√©ci√©e - Sens des priorit√©s, rigueur Ce contenu est bloqu√© Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","SoftBank Robotics Europe is seeking an Engineer with expertise in data manipulation, analysis, and cloud development to develop tools for its fleet of robots. The ideal candidate should have experience in managing large datasets and knowledge of IoT technology, tools for data analysis, machine learning frameworks, and cloud development. Strong communication skills and proficiency in Python, Linux, SQL, and Shell scripting are needed, along with fluency in English or Japanese.",N,N,N,0,1,0.013848874720779208
9,2299,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-london_london,Software engineer Data Presentation - London,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",NaN,London,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku‚Äôs culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku is seeking a talented software engineer with experience in software development and an interest in data visualization tools to create usable, intuitive, and beautiful interfaces and scalable engines for Dataiku DSS. The candidate must be customer-oriented, proficient in both frontend and backend development, and have firsthand experience building a real product. They will work closely with product managers and UX designers to brainstorm new features and iteratively refine solutions. Dataiku offers a flexible work-life balance, trusting its people to do their best and stay away from artificial deadlines. The company is committed to ensuring that each employee has the most rewarding, enjoyable, and memorable work experience.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
382,34233,https://www.welcometothejungle.com/fr/companies/deliveroo/jobs/analytics-engineer-data-engineer_paris,"Analytics Engineer, Data Engineer",Deliveroo,"{parquet,ElasticSearch,Ruby,Go,Scala,Looker,Kubernetes,AWS,Snowflake,Lambda,Kafka,via,Spark,instrumental,Docker,Python,EC2}",NaN,Hyderabad,"Application mobile, E-commerce, FoodTech",CDI,2022-08-08,"Lorsque Will Shu, le CEO et fondateur de Deliveroo, a d√©m√©nag√© √† Londres en 2013, il a d√©couvert une ville foisonnant de tr√®s bons restaurants. Mais √† sa grande surprise, peu d‚Äôentre eux proposaient de livrer leurs plats. D√®s lors, il s‚Äôest donn√© pour mission de faire venir la cuisine des meilleures p√©pites de quartier directement chez les gens. En offrant aux restaurateurs un canal de vente suppl√©mentaire, et l‚Äôopportunit√© de faire progresser leur chiffre d‚Äôaffaires, Deliveroo joue un r√¥le √©conomique majeur au sein de l‚Äô√©cosyst√®me de la restauration en France. Aujourd‚Äôhui, Deliveroo collabore avec 160 000 restaurants et 180 000 livreurs sur 11 march√©s g√©ographiques, afin de proposer la meilleure exp√©rience de livraison de repas et de courses d‚Äô√©picerie au monde. Deliveroo est pr√©sent sur 11 march√©s : Australie, Belgique, Emirats arabes unis, Espagne, France, Hong Kong, Irlande, Italie, Kowe√Øt, Pays-Bas, Royaume-Uni, Singapour. Pr√©sent en France, son deuxi√®me march√© mondial, depuis 2015, Deliveroo travaille aujourd‚Äôhui avec plus de 26 000 restaurants et commerces partenaires, et offre une opportunit√© d‚Äôactivit√© flexible et bien r√©mun√©r√©e √† 22 000 livreurs partenaires qui nous font confiance. Deliveroo continue depuis ses d√©buts de grandir g√©ographiquement et d‚Äôinnover : d√©veloppement d‚Äôune offre d‚Äô√©picerie, cr√©ations de sites Editions d√©di√©s √† la livraison de plats par de grandes marques exclusives, services technologiques innovants pour les restaurateurs, etc The Analytics & Data Engineering team enables Deliveroo to be data driven in how we build products and make decisions. We are responsible for ensuring the completeness, accuracy, and timeliness of key data sets across all three sides of our marketplace: riders, restaurants, and consumers. We help ensure that the right data is generated at source as we innovate in our products. Our team builds (and maintains) tools and develops solutions to ingest, transform and surface data for teams across the company and other disciplines in Tech to consume, including partnering closely with data science and machine learning engineering. We both own pipelines and processes where the use-case is primarily of an analytical nature (i.e. human decisions) and producing data sets that power algorithms like dispatching orders to riders. We set the strategy for providing reliable, timely robust business-critical data to these teams via our Kafka message bus, Snowflake data warehouse, and our BI tool Looker. We utilise a variety of data-focused products to build scalable solutions. You could be a good fit for our team if you are comfortable working with unfamiliar codebases, internal, open source or third party. If you have a desire to deeply understand how how a business works and to play an instrumental role in positively affecting the company trajectory, Deliveroo may be the right place for you. Our skills We need skilled software engineers who enjoy solving infrastructure and data problems with code. We don't expect you to meet all of the below but would love you to have experience in some of these areas. Pride in readable, well-designed, well-tested software 5+ years of experience with various data technologies, in particular analytics, aggregation, search and streaming technologies such as Spark, ElasticSearch and MPP data warehouses. Experience with operating systems, configuration management and ""Infrastructure as Code"". (We use AMIs, Docker Images, Terraform and Kubernetes). Experience with data lake design, and working with different file formats found within lakes (parquet, csv, json etc.) Most of our coding currently happens in Python, but we have some applications also written in Scala. Experience in data engineering type roles that involve partnering with others in the product/application space to ensure that data is treated like a 1st class citizen from the outset of product development. Professional experience writing infrastructure services and applications in any language, and a willingness to quickly get up to speed on the wider Deliveroo engineering stack (Ruby/Rails, Go and, Python). Experience with VMs, containers and serverless compute platforms. (We use AWS for compute, e.g. EC2, ECS and Lambda). Life at Deliveroo We are a growing team, with very large impact, seeking to answer some of the most interesting questions out there. We move fast, we‚Äôre always looking for new ideas and we‚Äôre very transparent about the decisions we make and why we make them. There are so many questions we need to answer and plenty more we haven‚Äôt even encountered. How do data and technology help restaurants to grow as consumer habits change? How can we predict what someone wants to order for dinner long before the idea has even crossed their mind? At Deliveroo these are just some of the tough problems we are solving - and there is no challenge that cannot be yours. No solution is owned by a particular team, which means the scope for growth and personal impact is enormous.","Deliveroo is seeking skilled software engineers with experience in data technologies, infrastructure, and strong coding abilities to join its Analytics & Data Engineering team. The team is responsible for ensuring data completeness, accuracy, and timeliness across all three sides of the marketplace and builds tools and solutions to ingest, transform, and surface data for teams across the company. Deliveroo is a fast-moving company seeking to solve tough problems in the food delivery industry, and engineers in this role will have a significant impact on the company's trajectory.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 5 ans,0,1,0.013848874720779208
427,49577,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_kglgqWo,Data Engineer,FACILECOMM (SHIPPINGBO),"{Redis,MongoDB,Pandas,PostgreSQL,Redshift,Airflow,AWS,R,SQL}",NaN,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-02-07,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait men√©(e) jusqu‚Äô√† cette annonce ! Peut-√™tre est-ce toi, le/la futur(e) Data Engineer que nous attendons‚Ä¶ En tout cas, nous l‚Äôesp√©rons. Dans un premier temps, permets nous de nous pr√©senter. Qui est Shippingbo ? La premi√®re chose que tu dois te demander c‚Äôest ‚Äúqui est Shippingbo‚Äù et c‚Äôest une tr√®s bonne question ! Shippingbo est une technologie logistique e-commerce fond√©e en 2016, par la soci√©t√© facilecomm. Nous mettons √† disposition des vendeurs en ligne une technologie qui leur permet d‚Äôoptimiser toute leur cha√Æne logistique : depuis la r√©cup√©ration des commandes, jusqu‚Äô√† leur exp√©dition, en passant par la pr√©paration. Pour la faire tr√®s simple, on est la technologie de l‚Äôombre qui permet √† ton site favori de te livrer dans les meilleurs d√©lais, tout en te notifiant de l‚Äôavanc√©e de ta commande. Pas mal, non ? Notre ambition : permettre √† nos clients de proposer aux consommateurs un parcours d‚Äôachat au top, digne des g√©ants du e-commerce ! Aujourd‚Äôhui, nous comptons pas moins de 1000 clients aux activit√©s e-commerce assez vari√©es : e-commer√ßants, retailers, fournisseurs, grossistes‚Ä¶. mais dont le point commun reste la vente en ligne ! Avec pr√®s de 72% de croissance en 2021 et plus d‚Äô1 milliard d‚Äôeuros de GMV, nous sommes bien d√©cid√©s √† poursuivre sur cette lanc√©e pour relever notre challenge ambitieux : nous imposer comme une technologie logistique SaaS leader dans le paysage europ√©en d‚Äôici 3 ans ! Shippingbo cherche aujourd‚Äôhui √† d√©velopper les outils d‚Äôanalyse qu‚Äôelle met √† disposition de ses clients ainsi qu‚Äô√† d√©velopper de nouvelles fonctionnalit√©s se fondant sur l‚Äôanalyse des donn√©es. En tant que data engineer, votre r√¥le sera de construire et maintenir les entrep√¥ts et pipelines de donn√©es. Vos missions principales consisteront √† : Participer √† la d√©finition des sch√©mas de donn√©es et aux choix d‚Äôarchitecture ; D√©finir et optimiser les requ√™tes fa√Ætes par l‚ÄôAPI et celles au c≈ìur des pipelines ; Pr√©parer des datasets exploitables √† des fins d‚Äôanalyse ; Identifier de facon plus g√©n√©rale les moyens optimaux de r√©pondre √† l‚Äôensemble des requ√™tes de donn√©es ; Optimiser √©galement le fonctionnement des pipelines et maintenir les syst√®mes surveillant leur bon fonctionnement et la qualit√© des donn√©es ; Participer √† l‚Äôadministration, la configuration et le param√©trage des bases de donn√©es. - Vous avez au moins 2 ans d‚Äôexp√©rience comme data engineer (ou des r√¥les similaires) et dans la construction et la maintenance de pipelines de donn√©es ; - Vous avez une connaissance approfondie de SQL , de l‚Äôoptimisation de requ√™tes et des entrep√¥ts de donn√©es ; - Vous avez une exp√©rience avec au moins une base de donn√©e orient√©e colonnes ; - Id√©alement vous avez √©galement une exp√©rience avec une base de donn√©e orient√©e documents et une base de donn√©e cl√©-valeur. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en m√©tro, arr√™t Ramonville) Rattach√© au d√©partement R&D de l'entreprise Mise √† disposition d‚Äôoutils informatiques Tickets restaurant >>> Venez d√©couvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversit√© occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'√©galit√© professionnelle et l'emploi des travailleurs en situation de handicap. A comp√©tences √©quivalentes, ce poste est ouvert √† tous.","Shippingbo is looking for a Data Engineer to develop and maintain data warehouses and pipelines, support the definition of data schemas and architecture, optimize queries, prepare datasets, and administer and configure databases. The ideal candidate should have at least 2 years of experience in data engineering, a deep understanding of SQL and data warehousing, and experience with column-oriented, document-oriented, and key-value databases. Shippingbo offers a permanent contract, based in Toulouse, and a range of benefits including IT tools and restaurant tickets.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
126,57142,https://www.welcometothejungle.com/fr/companies/aldebaran/jobs/data-engineer-f-h_paris,Data engineer,Aldebaran - a part of United Robotics Group,"{Kinesis,Glue,AWS,lambda,S3,R,Python}",NaN,"43 rue du Colonel Pierre Avia , Paris, 75015","Objets connect√©s, Robotique",Autres,2023-03-26,"Aldebaran, anciennement connu sous le nom de SoftBank Robotics Europe, est le leader de la robotique humano√Øde, fabricant des robots embl√©matiques NAO et Pepper. Depuis sa cr√©ation en 2005, nous sommes devenus le leader du march√© des robots humano√Ødes. Plus de 40 000 robots sociaux et d‚Äôinteraction - NAO et Pepper - sont utilis√©s dans plus de 70 pays, dans divers secteurs, allant du commerce de d√©tail au tourisme, en passant par la sant√© et l‚Äô√©ducation. Apr√®s avoir d√©velopp√© et commercialis√© les robots humano√Ødes NAO et Pepper, Aldebaran d√©veloppe d√©sormais une nouvelle g√©n√©ration de robots de services. Ces d√©veloppements mobilisent de nombreux m√©tiers (√©lectronique, m√©canique, logiciel) au sein de la R&D. En 2022, Aldebaran a uni ses forces √† celles du groupe allemand United Robotics. Aldebaran emploie actuellement plus de 180 personnes dans ses bureaux de Paris, son si√®ge social, et de Suzhou. Aldebaran, anciennement connu sous le nom de SoftBank Robotics Europe, est le leader de la robotique humano√Øde, fabricant des robots embl√©matiques NAO et Pepper. Depuis sa cr√©ation en 2005, nous sommes devenus le leader du march√© des robots humano√Ødes. Plus de 40 000 robots sociaux et d'interaction - NAO et Pepper - sont utilis√©s dans plus de 70 pays, dans divers secteurs, allant du commerce de d√©tail au tourisme, en passant par la sant√© et l'√©ducation. Apr√®s avoir d√©velopp√© et commercialis√© les robots humano√Ødes NAO et Pepper, Aldebaran d√©veloppe d√©sormais une nouvelle g√©n√©ration de robots de services. Ces d√©veloppements mobilisent de nombreux m√©tiers (√©lectronique, m√©canique, logiciel) au sein de la R&D. En 2022, Aldebaran a uni ses forces √† celles du groupe allemand United Robotics. Aldebaran emploie actuellement pr√®s de 180 personnes dans ses bureaux de Paris, son si√®ge social, et de Suzhou. Au sein de l‚Äô√©quipe Cloud, le data engineer int√©grera une √©quipe DATA responsable du d√©veloppement des produits destin√© au collecte, process et exploitation des donn√©es robot. L‚Äôobjet de ce r√¥le consiste √† d√©finir et √† impl√©menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g√®rent les robots du groupe. Le data engineer aura pour r√¥le de: ‚óè √©valuer les choix d‚Äôarchitectures et de solution technique lors de mise en place de PoC ‚óè concevoir et d√©velopper des services Data en respectant la sp√©cification fonctionnelle et la m√©thodologie agile ‚óè agr√©ger et stocker de grandes quantit√©s de donn√©es, Mise en place de solutions pour le data processing ‚óè int√©grer/D√©velopper des outils de visualisation de donn√©es et analyser les KPI ‚óè d√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins ‚óè r√©aliser des analyses de donn√©es ‚óè la mise en place de tests de charge et fonctionnelles pour les solutions Data ‚óè investiguer et corriger les bugs remont√©s par les utilisateurs ‚óè contribuer √† la mise en place de l‚Äôinfrastructure et outil de d√©ploiement (CI/CD) Requirements Pour la bonne ex√©cution de ces fonctions, au moins 6 ans en tant que d√©veloppeur sur des projets data en Cloud en Python et avec comme Cloud provider AWS. Les comp√©tences technique suivantes seront requises: ‚óè Une bonne compr√©hension des technologies d‚Äôinfrastructure et de d√©ploiement. Une certification AWS sera appr√©ci√©e. ‚óè Comp√©tence technique sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS ‚óè Une bonne compr√©hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels. ‚óè Une bonne connaissance et une exp√©rience pratique de Scrum\Scrumban et des m√©thodes agiles est n√©cessaire. ‚óè Une bonne ma√Ætrise du fran√ßais et de l‚Äôanglais (lu, √©crit, parl√©) est indispensable. ‚óè Des exp√©riences dans des environnements fortement internationaux sont un plus. Benefits Nos principaux avantages : Une culture du bien-√™tre en entreprise qui a fait ses preuves (happy events, budget c√©l√©bration et convivialit√© par √©quipes et directions, s√©minaires d'entreprise, restauration collective de qualit√©, environnement de travail agr√©able...) Un engagement fort en mati√®re de responsabilit√© sociale (promotion de l'√©galit√© professionnelle, cr√©ation d'ERG, performance de notre plan diversit√© et inclusion, r√©f√©rent handicap) Une forte culture du t√©l√©travail encadr√©e de mani√®re appropri√©e ! Tous nos postes sont ouverts aux personnes en situation de handicap.","Aldebaran, a leading humanoid robotics manufacturer, is seeking a data engineer with at least 6 years of experience in Python and AWS. The role involves designing and developing data services, aggregating and storing large amounts of data, and analyzing KPIs. A good understanding of infrastructure and deployment technologies, AWS services, and Scrum/Scrumban methodologies is required. The company offers a strong corporate culture of well-being, social responsibility, and telecommuting. The position is open to people with disabilities.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
262,56730,https://www.welcometothejungle.com/fr/companies/enea-consulting/jobs/data-science-and-software-engineer-manager,Data Science and Software Engineer Manager,Blunomy (formerly Enea Consulting),"{GCP,Azure,go,Dask,AWS,R,Spark,Git,Python}",NaN,Melbourne,"Environnement / D√©veloppement durable, Strat√©gie, Energie",CDI,2023-03-26,"Let‚Äôs get right to the point: we believe the best is yet to come, if we put everything we have into inventing new rules for a new economy. We want to play a role in creating these innovative rules and tools, beginning with new ways to define what success is. So, who are we? We‚Äôre the Blunomists: a unique breed of highly experienced business explorers and experts who provide the multidisciplinary skills that are so often fragmented today. We believe breaking silos is the only way to move towards a regenerative society that‚Äôs decarbonized, circular and inclusive. üåé We are action-oriented and offer more than a consulting-only business model: we don‚Äôt shy away from complexity, we work hand-in-hand with our clients and partners in the long term and we share the risks when it comes to success. From strategic advice to industrial partnerships and innovative data solutions, we strive to provide end-to-end transformations. We‚Äôre never happier than when we‚Äôre pushing boundaries: ‚Ä¢ Accelerating the go-to-market rate for promising and innovative technologies ‚Ä¢ Transforming existing infrastructure into low-carbon and resilient infrastructure ‚Ä¢ Switching from linear and global supply chains to multiple, circular, local, ethical and largely bio- sourced supply chains, while ensuring social cohesion ‚Ä¢ Optimizing land use to respond to growing needs for food and housing, recreate biodiversity, produce bioenergy and capture carbon ‚Ä¢ Ensuring that this period of increased attention on the environment creates a reduction in inequalities, with a particular focus on the development of essential infrastructure around the world These are the transition bottlenecks that get us up in the morning. üåÖ Although we‚Äôve already got plenty of incredible projects to work on, we‚Äôre a growing organization. So, stay tuned in the coming months to find out more about us, and until then, feel free to send us your application! Blunomy is the result of a perfect match between Isabelle Kocher de Leyritz, former CEO of ENGIE and internationally renowned business leader, and Enea Consulting, a pioneering strategy consulting firm specializing in the energy transition. Sharing a common goal of bringing about a positive economy, they decided to join forces to contribute to make change happen. Blunomy was founded by Isabelle Kocher de Leyritz in 2022. ENEA Consulting brought 100% of its shares in the adventure, to build a common future in a truly unique company. Blunomy is fully owned by Blunomy Manco, a company composed of Blunomy‚Äôs managers. Blunomy is an international strategy consulting firm, dedicated to accelerating the move towards a regenerative society that is decarbonised, circular and inclusive. We do this by partnering with those in the energy supply chain, as well as financial institutions, business and entrepreneurs to ensure the transition of their resources from brown to green. We have been operating since 2007, previously trading as Enea Consulting, and continue to expand our international team of Blunomists. Our high performing, multidisciplinary team are based across 6 offices: Melbourne, Sydney, Paris, Singapore, Hong Kong and London. We come from a wide variety of backgrounds and experiences, are open minded and focused on the future, united by shared values and are passionate about sustainable development and energy access. We are looking for a passionate, engaging and ambitious Data Science and Software Engineering Manager to join our team in either Melbourne or Sydney. We invite all of those who want to break the mould to join us to get change done! About the role: Data analytics in the energy and climate space is growing at an incredible rate. Blunomy provides data-based solutions to support the energy industry, financial institutions and supply chains through their digitisation, decentralisation and decarbonisation transitions. Our tools support improved energy market operability, automation and planning. We are also developing digital solutions that better measure impact and transition speed, to help decarbonise financial resources. We are looking for someone who is passionate about energy, climate change and data analytics to do-well-and-do-good by delivering data science products to crack transition challenges. As a Manager , you will be responsible for: managing the end-to-end delivery of the project engaging and communicating with the client anticipating and managing project risks, timelines, and budget code quality (PR review) managing and leading analysts and senior analysts In this setting, you will be exposed to the diversity of current energy challenges, leveraging your data and analytical skills to address them. We are always growing the products we deliver but over the last 12 months we have delivered: Load forecasting: model and predict the evolution of the load on the electrical network. Use machine learning, data analytics and a fair amount of software development to forecast long-term energy consumption, daily energy profiles and Distributed Energy Resources (Electric Vehicles, Battery, Solar PV). PV connections approval tool: dynamically model the energy network bringing together power flow modelling and machine learning to determine the PV hosting capacity of the local area. Used in production to approve hundreds of PV connection requests a day. Vegetation management using LiDAR: collect three dimensional images of the local network gathered by drone or helicopter. Use machine learning and geometric models to detect and manage vegetation near powerlines. Bushfire risk modelling: model and compute the network‚Äërelated bushfire risk based on fault ignition likelihood. Calculate the consequences of bushfires such as property damage or agricultural loss. Low-Voltage network mapping: identify errors within the current mapping of the low-voltage network, especially targeting customers whom connection to the network has not been properly recorded. This was performed using outlier detection with out-of-bag predictors. Depending on the objectives, projects will entail tasks of varying nature. Your first focus will be on projects requiring data analytics capabilities. We are looking for a motivated, experienced and passionate person to join our growing team. The right person will have some of the following, and a willingness and ability to learn the rest. An undergraduate degree or a postgraduate in a relevant discipline such Computing Science, Statistics, Mathematics or Engineering. 5+ years‚Äô experience on data science projects and at least 2 years‚Äô experience in managing projects and staff. A background in data science or software development. Some experience or a passion for energy, environment and/or sustainable development. Knowledge of statistical and machine learning concepts and algorithms. Experience with the data science tool kit: Python or R Source control (such as Git) software engineering and app development skills Knowledge of cloud computing (such as Azure, GCP, AWS) Parallel computing (such as Spark or Dask) is a plus. Consultant tool kit: Good oral and written communication Client engagement skills An ability to work to project timelines. Fluent in English To be eligible to apply for this position, candidates must be either an Australian citizen or have full working rights in Australia. Location: Melbourne or Sydney CBD Salary: Depending on experience Work type: Full Time, starting ASAP","Blunomy, an international strategy consulting firm dedicated to accelerating the transition towards a regenerative society, is looking for a Data Science and Software Engineering Manager for their Melbourne or Sydney office. The role involves managing end-to-end delivery of projects, engaging with clients, and leading a team of analysts and senior analysts. The ideal candidate should have 5+ years of experience in data science projects, at least 2 years of experience in managing projects and staff, background in data science or software development, and a passion for energy, environment, and/or sustainable development. Fluency in English and working rights in Australia are necessary for eligibility.",Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
409,36973,https://www.welcometothejungle.com/fr/companies/kiwi/jobs/analytics-engineer_bratislava_KIWIC_9KkWRA8,Analytics Engineer,Kiwi.com,"{Microsoft,regard,Airflow,Looker,Fivetran,Keboola,Snowflake,scale,Stitch,BigQuery,Azure,SQL,Python,Tableau}",NaN,N,"Logiciels, Tourisme",CDI,2022-10-12,"Kiwi.com is an online travel agency that developed its own algorithm for finding flight tickets. Their mission is to move people from any A to any B anywhere in the world, affordably and conveniently. They are achieving this by creating virtual interlining, by combining flights, trains and buses, in their search. Kiwi.com was founded in 2012 in Brno, the Czech Republic and today they‚Äôre called a young scale-up. They even got awarded by Forbes that they are the most successful Czech startup! Today, Kiwi.com is counting more than a thousand employees in their core offices and they have offices in Brno and Prague (the Czech Republic), Bratislava (Slovakia), London (UK) and Barcelona (Spain). As an Analytics Engineer, you will define, prepare, maintain, and document data sets (mainly in form of data models) so that users are able to get actionable insights from the data in a self-service way. You will work with Data Platforms, Business Analysts, and Data Intelligence teams to implement data modeling solutions and help to streamline company information management. Job responsibilities: Elicit business data requirements, identify data sources and required data elements, perform data validation and integration activities. Translate business data needs to specific technical requirements and tasks. Take responsibility for the whole ETL/ELT solution and design new sustainable solutions from the ground up. Oversee the data warehouse, source system tables, and transformations necessary for intelligent reporting, thus ensuring that business users have access to reliable data which are essential to make informed decisions. Work in conjunction with Data Engineering to build scalable and manageable data intelligence solutions. Diagnose data quality issues using formal problem-solving techniques and probe underlying issues to generate potential solutions. Make recommendations and guide corrective and/or preventive actions. Write and document the results of your work to make them easily understandable to other colleagues. We would love to see you apply, if You: Have at least 2 years of relevant experience in the area of business intelligence, data analytics, or data engineering. Have a solid understanding of data integration tools, ETL/ELT processes, data modeling concepts, and data warehouse architecture. Are familiar with data pipeline orchestration tools such as Airflow, Fivetran, Keboola, or Stitch. Have experience with DWH platforms like BigQuery, Snowflake, Azure Data Warehouse, or MS SQL Server. Have a good knowledge of database principles, strong proficiency in SQL and programming languages (like Python) used for data manipulation and data analysis. Have an inquisitive, analytical problem-solving mindset. Have experience with BI tools like Looker, Tableau, or similar is welcomed. Are Fluent English (C1 level). We offer you We give our employees a freedom to choose between the environment of work from home and our modern office located in Zuckermandel where you can enjoy sleeping spots, chillout zones, free refreshments, parking for car/bicycle/motorbike. We also enjoy benefits, such as meal vouchers, 25 days vacation, sick days, Multisport card, Employee Assistance Program. Flight vouchers to celebrate your kiwi anniversaries. Hardware from Apple or Microsoft based on your preferences. Relocation package (including visa transfer support). We offer unlimited contracts within a forward-thinking and ambitious company. Dogs, kids, and parties are welcome in our offices. The salary is starting at 2200 Euro (depending on seniority). Interested? Join us and hack the traditional ways of travel! Kiwi.com is proud to be an equal opportunity workplace and employer. We review applications for employment without regard to their race, colour, religion, sex, sexual orientation, gender identity, national origin, ancestry, citizenship, age, uniformed services, genetic information, physical or mental disability, medical condition, marital status, or any other basis prohibited by law. Throughout the recruitment process and for some time after it‚Äôs finished, we‚Äôre going to process your Personal Data. You can find all the necessary information in our Privacy Policy available at: https://jobs.kiwi.com/recruitment-privacy-policy/ .#LI-BS1","Kiwi.com is seeking an Analytics Engineer to prepare, maintain, and document data sets for users to access actionable insights in a self-service way. The successful candidate should have at least two years of relevant experience in business intelligence or data engineering, a solid understanding of data integration tools and warehouse architecture, proficiency in SQL and programming languages, and knowledge of database principles. Kiwi.com offers a flexible working environment, benefits, and a competitive salary starting at ‚Ç¨2200, depending on seniority.",N,N,N,0,1,0.013848874720779208
54,62974,https://www.welcometothejungle.com/fr/companies/ibanfirst/jobs/data-engineer_dijon_IBANF_ORRXLKb,Data Engineer,iBanFirst,"{MySQL,GIT,Talend,Metabase,DBT,Airflow,Snowflake,R,Java,SQL,Python,Tableau}",NaN,"2b Avenue de Marbotte, Dijon, 21000","FinTech / InsurTech, Finance",CDI,2023-03-31,"iBanFirst is a global financial services provider delivering solutions across banking borders. As an alternative to the traditional bank offer, iBanFirst helps international SMEs to thrive while simplifying their daily operations. To do so, iBanFirst has developed a cutting-edge core banking platform enabling fast, secure and cost-effective multicurrency transactions. Thanks to iBanFirst, financial teams can make and receive payments in over 30 currencies and hedge foreign exchange risks. Founded in Paris in 2013, iBanFirst is a French company headquartered in Belgium. It is regulated as a payment institution, passported throughout the European Union, and serves thousands of customers all over Europe. Member of the SWIFT network and SEPA certified, iBanFirst holds AISP and PISP accreditations under PSD2. The company has raised ‚Ç¨46m from Xavier Niel and leading European venture capital funds, such as Elaia and Bpifrance Large Venture, among others. In May 2021, iBanFirst completed a growth equity funding round with Los Angeles-based private equity firm Marlin Equity Partners. Job description The R&D team at iBanFirst provides key features to disrupt the B2B payments and FX solutions market. Our web platform combines a full range of financial products and services with a robust core banking infrastructure. We are looking for a Data Engineer for our Data Engineering team who can help us develop, maintain and push our product to the next level. You will be part of a team with strong collaboration, curiosity is in you DNA and you are ready to proactively share your ideas with us to unlock the potential of a borderless world. This is a hybrid role with at least 50% of time being spent in either our Paris or Dijon offices. What you will do Complete our Data engineer team by bringing rigor and enthusiasm Help maintain and develop our data acquisition and transformation chain enrich our possibility of sharing the resulting indicators understand the needs of the business and the data analyst team and propose robust and innovative solutions to meet them What do you bring? Master SQL language and GIT versioning Have a minimum of 2 years of experience in the use of the Python language and mastery of the associated good practices Be comfortable with APIs to collect and disseminate Be a force of proposal and exchange within the team of data engineers on the maintenance and the evolution of the eco system in place Plus points Have used DBT / Airflow / Snowflake / Terraform before Be comfortable with Java Have Cloud or real-time relative skills Be familiar with the world of Finance Tech stack Python, Talend, DBT for data acquisition and transformation Snowflake, MySQL for data storage Airflow for job scheduling Terraform for configuration management Tableau, Metabase for dataviz What do we offer? Various missions and projects in an innovative and rising start-up in a thriving industry (fintech) A key role and a unique opportunity to shape the future of iBanFirst A professional and international team with a flat hierarchy A nice work environment Who are we? iBanFirst is an international financial services provider offering alternative payment solutions to traditional banking. iBanFirst is a fintech that developed a banking platform to enable international SMEs to carry out fast, secure and fairly priced multi-currency transactions. Thanks to iBanFirst, finance teams can send and receive payments in more than 30 currencies and benefit from personalized support to cover their foreign exchange exposure. Since 2016, iBanFirst has raised 46 million euros and in May 2021, the Californian fund Marlin Equity Partners invested ‚Ç¨200M to further accelerate the growth and development of iBanFirst. Joining iBanFirst is a unique opportunity to develop your skills and evolve quickly in an international company that is at the cutting edge of innovation. #LI-CM1 #-LI-Hybrid","iBanFirst seeks a data engineer to join their team in Paris or Dijon to develop, maintain and enhance their data acquisition and transformation processes to enable fast and secure multicurrency transactions with a wide range of financial products and services. Candidates should have a minimum of 2 years of experience in using Python language and API collection, be proficient in SQL and GIT versioning, and have excellent collaboration skills. Knowledge of DBT, Airflow, Snowflake, Terraform, Java, and finance tech is a plus. The company offers a challenging work environment, an innovative fintech field, and a professional international team with a flat hierarchy.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
257,56716,https://www.welcometothejungle.com/fr/companies/thales/jobs/alternance-data-engineer-f-h_paris,Alternance - Data Engineer,Thales,"{Kubeflow,durable,Scala,DVC,Hive,Spark,Git,Hadoop,Python,AirFlow,MLFlow}",NaN,Paris,"Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale",Autres,2023-03-26,"Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L‚Äôintelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Chez Thales, tout commence par l‚ÄôIntelligence Humaine. C‚Äôest pourquoi notre ambition est de vous offrir la meilleure ¬´ exp√©rience ¬ª possible. Nous nous effor√ßons de mettre en place les conditions de votre d√©veloppement, de faciliter votre quotidien, votre √©quilibre vie personnelle - vie professionnelle, et d‚Äô√©tendre vos perspectives. Un savoir-faire technologique au service de la soci√©t√©. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d‚Äôune centaine de disciplines, de l‚Äôoptique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l‚Äôintelligence artificielle. Rejoindre Thales, c‚Äôest repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C‚Äôest donc √™tre au c≈ìur d‚Äôune formidable aventure technique. Une attention port√©e √† l‚Äô√©quilibre des collaborateurs au service de leur r√©ussite. C‚Äôest pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d‚Äôaccorder la flexibilit√© n√©cessaire √† l‚Äô√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C‚Äôest aussi la possibilit√© d‚Äô√©voluer, de changer de fonction ou d‚Äôactivit√©, voire de pays. QUI SOMMES-NOUS ? Thales Digital Factory s‚Äôinscrit dans le programme de transformation de Thales qui a pour ambition de devenir un acteur incontournable et exemplaire du digital, et ce dans l‚Äôensemble de ses march√©s. Notre mission consiste √† acc√©l√©rer la transition num√©rique du Groupe Thales en s'aventurant dans de nouveaux modes de travail et de d√©cision. Notre strat√©gie s‚Äôarticule autour de 6 valeurs : Responsabilisation, Orient√©e sur la donn√©e, Centr√©e sur l‚Äôutilisateur, Collaboration, Am√©lioration continue et Culture de l‚Äô√©chec. Nos bureaux se r√©partissent de Paris √† Singapour en passant par Montr√©al au c≈ìur d'√©cosyst√®mes innovants. Thales Digital Factory se distingue √©galement gr√¢ce √† son incubateur qui accompagne des start-ups internes et externes, ses plateformes digitales, son centre d‚Äôexcellence Cloud et le d√©veloppement de MVP, porteurs d‚Äôinnovation pour l‚Äôoffre digitale du Groupe et de nos clients. QUI ETES-VOUS ? Vous √™tes √©tudiant en √©cole d‚Äôing√©nieur et vous suiviez une sp√©cialisation en Data ? Vous √™tes √† la recherche d'une alternance pour l'ann√©e 2023-2024? Vous avez √† minima un BAC+3 ? Vous √™tes apte √† communiquer et √©crire ais√©ment en anglais ? Vous disposez d‚Äôune base de connaissances m√©tier sur les √©l√©ments suivants : -Les enjeux du m√©tier de la donn√©e -Le cycle de vie de la donn√©e (extraction, transformation, traitement) dans un contexte d‚Äôexploitation par de la data science. Vous disposez d‚Äôune base de connaissances sur les langages et outils suivants : - Python - Scala - Hive -Hadoop -Git ‚Äã Vous disposez √©galement d‚Äôun panel de comp√©tences sur : - Les principes MLOps - Spark - Kubeflow -AirFlow -MLFlow -DVC Vous √™tes de nature curieuse ? Vous √™tes reconnu pour votre autonomie ? Vous souhaitez apprendre ? Vous vous reconnaissez ? Parlons missions ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE Vous occupez un r√¥le de Data Engineer au sein du Data Studio. L‚Äôenvironnement dans lequel vous allez √©voluer : Le Data Studio, embarqu√© dans la Thales Digital Factory, a pour mission de d√©velopper des solutions d‚ÄôIntelligence Artificielle/de Data Science innovantes pour les march√©s de Thales. Cette √©quipe de deux personnes g√®re des projets innovants relatifs au traitement d‚Äôimage, √† l‚Äôanalyse de log, au traitement de textes ou s√©ries temporelles. Le Data Studio est associ√© √† la discipline Data & Algorithme r√©unissant des experts du m√©tier Data (Data Engineer, Data Architect, Data Scientist, Algoritmicien). Cette communaut√© se r√©unit de mani√®re hebdomadaire pour partager des savoirs et pratiques relatifs au m√©tiers de la data et permet de maintenir un niveau permanent sur ce domaine en constante √©volution. Les enjeux : Le groupe Thales a mis en place une strat√©gie de transformation, par le biais de l‚Äôexploitation de la donn√©e. Le Data Studio a pour objectif de concr√©tiser cette transformation, en accompagnant les diff√©rents d√©partements du groupe Thales dans la mise en place et l‚Äôindustralisation de solutions √† base d‚ÄôIA. Vos missions couvriront : Le support √† l‚Äô√©quipe de Data Scientist pour les aspects de Data Engineering - depuis le collecte des donn√©es jusqu‚Äô√† la mise en place de solution industrialis√©e, mise entre les mains d‚Äôutilisateurs. L‚Äôindustrialisation d‚Äôune solution de traitement de donn√©es texte (NLP) ‚Äì √† l‚Äô√©tat de prototype, cette solution a besoin d‚Äô√™tre d√©velopp√©e de mani√®re it√©rative, en fonction des nouveaux cas d‚Äôusage qu‚Äôelle pourra servir. Cette mission s‚Äôeffectue dans des environnements technologiques divers, cloud ou on-premise, streaming ou batch et la vari√©t√© des cas d‚Äôusage √† traiter garantissent une mont√©e en comp√©tence pratique pendant les temps en entreprise. L‚Äôaide √† qualification technique des opportunit√©s de l‚Äô√©quipe Data Studio ‚Äì pour chaque mission potentielle, il s‚Äôagira de comprendre les contraintes techniques li√©es √† la demande et valider la faisabilit√© technique et la valeur associ√©e. Nous sommes toujours en phase ? N'attendez plus, rejoignez-nous! Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.","Thales Digital Factory is seeking a Data Engineer student for an internship for the 2023-2024 academic year. The Data Engineer will work on data engineering aspects from data collection to the industrialization of a text data processing solution. Skills required include a knowledge of data challenges and the data lifecycle, as well as proficiency in Python, Scala, Hive, Hadoop, and Git, and a curiosity to learn and work autonomously.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
171,56897,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/dataops-engineer-data-solutions-factory-f-m-d_croix,DataOps Engineer - Data Solutions Factory,Decathlon Digital,"{DynamoDB,PostgreSQL,Hive,Elasticsearch,Datastudio,Kinesis,Talend,Hbase,Kafka,GCS,Linux,Dataflow,NoSQL,BigQuery,Jenkins,Kubernetes,AWS,YARN,Github,Hadoop,Jupyter,Prisma,Sagemaker,EMR,Airflow,Redshift,S3,Druid,Spark,Superset,GCP,Tableau}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. REJOINS L'EQUIPE DATAOPS DE LA DATA SOLUTIONS FACTORY DE DECATHLON L‚Äôentit√© Data de Decathlon coordonne l‚Äôensemble des activit√©s visant √† l‚Äôacc√©l√©ration et la g√©n√©ralisation de l‚Äôusage et la valorisation des donn√©es. Au sein de la BU Data, l ‚Äô√©quipe DataOPS innove tous les jours pour r√©pondre au mieux aux besoins de notre data platform . Nos enjeux sont : Une plateforme data enti√®rement multi-cloud (AWS & GCP) De la haute disponibilit√©, avec une plateforme r√©siliente et des technologies innovantes La s√©curit√© au coeur de nos projets Les besoins de nos data scientist, data engineers data analystes, et d√©veloppeurs traduits en solutions techniques Compos√©e d‚Äôune 15aine d‚Äôexperts, l‚Äô√©quipe DataOPS t‚Äôattends pour apporter ta contribution √† ce grand enjeu qu‚Äôest la Data. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e DataOPS Engineer, bas√©-e, au choix √† Lille ou Paris (si tu es localis√©.e hors de la r√©gion lilloise, pr√©voir une d√©placement sur Lille √† un rythme d'1 journ√©e / par semaine ou 2 jours tous les 15 jours). TES RESPONSABILITES Expert.e dans ton domaine, tu con√ßois, d√©ploies et maintiens les offres techniques pour l‚Äôensemble des infrastructures de la BU Data, tout en suivant les strat√©gies techniques de l‚Äôentreprise (excellence op√©rationnelle, full cloud, full automatisation, s√©curit√©). Tu participes et contribues aux strat√©gies techniques de l‚Äôentreprise au sein de la communaut√© OPS . En tant que r√©f√©rent.e sur les technologies que tu g√®res, tu partages et fais grandir tes coll√®gues Tu participes au processus de support, en prenant en charge avec l‚Äô√©quipe les demandes, incidents et probl√®mes en escalade sur ton p√©rim√®tre d‚Äôexpertise Tu contribues √† la transformation du SI Tu accompagnes les changements strat√©giques li√©s √† l‚Äôinfrastructure Tu aides au recrutement de profils OPS externes, tu les formes et les animes. Le p√©rim√®tre technique : Un environnement full cloud (AWS-GCP) compl√®tement infra-as-code (Terraform, Ansible) ; Une plateforme Kubernetes, avec full CI/CD (Flux, Jenkins, Github Action‚Ä¶), haute disponibilit√©, haute s√©curit√© (Prisma,...) ; Une infrastructure d'√©change de donn√©es, en pleine √©volution pour √™tre 100% industrialisable, avec de multiples technologies : Kafka, Talend, Airflow, Kinesis, Dataflow... Une infrastructure DataViz : QlikSense, Superset, Quicksight, Datastudio, Tableau ; De multiples technologies de stockage : S3, Redshift, PostgreSQL, GCS, BigQuery ; Une plateforme Hadoop : EMR, Hive, Spark, YARN, Ranger, Atlas ; Des bases de donn√©es NoSQL : Elasticsearch, Druid, DynamoDB, Hbase ; De multiples environnements de d√©veloppements Data : Github, Jupyter, RStudio, Sagemaker ; Une grande communaut√© OPS tr√®s soud√©e, qui partage les bonnes pratiques, construit des process communs, etc. CE DONT TU AURAS BESOIN POUR R√âUSSIR Tu as au moins 2 ans en tant qu'OPS sur Linux, conteneurisation, monitoring, CI/CD, automatisation & industrialisation ET en environnement Cloud (AWS fortement appr√©ci√©) Tu as une app√©tence pour la data (Spark, Airflow, Sagemaker, BigQuery), et la gestion de bases de donn√©es relationnelles et NoSQL ; Tu aimes √©voluer en contexte Agile et tu as envie de travailler dans un environnement international (anglais technique ma√Ætris√©). Tu es f orce de propositions, et aimes le challenge ! Passionn√©¬∑e de technique et de s√©curit√©, la veille technologique sera une part importante de ton activit√© ; Rejoindre une entreprise qui rend accessible au plus grand nombre le plaisir et les bienfaits du sport fait sens pour toi et tu as envie de partager tes passions en √©quipe ! Tu as envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Possibilit√© de travailler au choix dans l‚Äôun des bureaux de Decathlon Technology √† Lille, Paris, Nantes ou Lyon (pr√©voir un d√©placement r√©gulier sur Lille, √† un rythme de 2 ou 3 jours tous les 15 jours ) Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes et Lyon, Londres, Madrid, Berlin. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon is seeking a DataOPS Engineer to join their Data Solutions Factory team in Lille or Paris. The successful candidate will be responsible for designing, deploying, and maintaining technical offerings for data infrastructure, contributing to technical strategy, and providing support while participating in infrastructure changes. The ideal candidate will have at least two years of experience in Linux OPS, containerization, monitoring, CI/CD, automation, and industrialization in a cloud environment (AWS preferred) and possess an interest in Spark, Airflow, Sagemaker, and BigQuery.",Non sp√©cifi√©,> 2000 salari√©s,> 2 ans,0,1,0.013848874720779208
61,73359,https://www.welcometothejungle.com/fr/companies/make-1/jobs/summer-internship-data-engineer_prague,Summer Internship - Data Engineer,Make,"{Celonis,Python,BigQuery,scale,color,regard,SQL,Snowflake,Java}",NaN,"Menclova, Prague, 180 00","Logiciels, SaaS / Cloud Services",Autres,2023-04-22,"Make is the leading visual platform for anyone to design, build, and automate anything - from tasks and workflows to apps and systems - without coding. Make enables individuals, teams, and enterprises across all verticals to create powerful custom solutions that scale their businesses faster than ever. Make powers over 500,000+ organizations around the globe. Make has been a part of Celonis, a German software company focused on process mining, currently one of the most valuable start-ups in Germany and NYC, since 2020. Make currently operates as an independent business unit under the Celonis umbrella. Join us for the ride! Make is the leading visual platform for anyone to design, build, and automate anything‚Äîfrom tasks and workflows to apps and systems‚Äîwithout the need for coding skills. We are headquartered in the flourishing tech hub of Prague, Czech Republic, and our teams are spread across the USA, UK, Germany, France, Canada, India and Chile, among other locations. Join us on a 3-month internship ( July-September) for University students who want to gain real-life work experience in a fast-growing SaaS company. As a Summer Intern, you will be part of real projects and take more responsibility as you grow. We are looking for an enthusiastic and motivated student to join as a Data Engineer. Data engineering is the intersection of data management, orchestration, DataOps, data architecture, security and software engineering. Data engineers handle management of the data lifecycle - beginning with getting data from source systems and ending with serving data for various use cases such as analysis and machine learning. Responsibilities You will get familiar, adopt and participate on our system and concepts of working with data throughout the whole lifecycle such as: Communication with producers of data - product developers. Work closely with our Analytics and Data Science teams Development, tests and integration of ingestion jobs. Data modeling to reflect the goals and business logic of the company. Serving data in appropriate shape and form based on the business needs to facilitate data driven decision making. Orchestrate the whole flow. Contribute to the data architecture and gain knowledge about the data warehousing, design patterns and data tools. Work on data governance and data quality. Assist in adopting and spread of software engineering best practices. Requirements Pursuing a degree in Computer Science, Data Analytics, or a related field. Work on school projects implemented in Python/Java/C++. Big plus is work related to data oriented applications. Work on a school project focused on development of databases and information systems. Basic understanding of data modeling techniques and normalization. Hands-on experience writing SQL queries. Strong problem solving, conceptualization, and communication skills. Exposure to CI/CD. Knowledge of building ETL/ELT data pipelines is a plus. Knowledge of cloud data warehouses such as Snowflake or BigQuery is a plus. Strong written and verbal fluency in English What we offer: üåé Multinational team with 42 nationalities creating the future of automation üçé Notebook/Macbook and 34‚Äô‚Äô curved monitor üçç Snack bar, coffee, tea, fruit and vegetable, and sweets all day - every day - available for everyone ü•ó Monday breakfast, Wednesday lunch, and Friday break, with company-provided food and drinks, with music and lively discussion ‚è∞ Flexible working hours üêï‚Äçü¶∫ Company therapy pets (dog-friendly office) üñ®Ô∏è Company 3D printer ü•≥ Parties, and company events If you see a match, let us know and apply now! #careeratmake Make is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment and equal opportunity in all aspects of employment. We will not tolerate any unlawful discrimination or harassment of any kind. We make all employment decisions without regard to race/ethnicity, color, sex, pregnancy, age, sexual orientation, gender identity or expression, transgender status, national origin, citizenship status, religion, physical or mental disability, veteran status, or any other factor protected by applicable anti-discrimination laws. As a US federal contractor, we are committed to the principles of affirmative action in accordance with applicable laws and regulations. Different makes us better. Accessibility and Candidate Notices",,Non sp√©cifi√©,Entre 50 et 250 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
261,56966,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/ia-project-engineer-data-value-lab-f-m-d_croix,IA Project Engineer - Data Value Lab,Decathlon Digital,"{GCP,SQL,Python,AWS}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. LES EQUIPES DU DATA VALUE LAB DE l'IA FACTORY DE DECATHLON Le Data Value Lab , au sein de l'unit√© Decathlon AI factory, est l'√©quipe charg√©e de d√©couvrir & d√©finir les cas d'utilisation d'IA qui apportent le plus de valeur ajout√©e. Mais aussi d'assurer l'exp√©rimentation de ces cas d'usages. Le terme X4, qui signifie eXplore, eXamine, eXperiment et eXtend, r√©sume parfaitement le modus operandi de l'√©quipe. Au sein du Data Value Lab, nous utilisons une approche agile ""test & learn"" pour analyser le potentiel de valeur, la faisabilit√© d'un cas d'usage et mesurer la performance de la solution avant d'en √©tendre les succ√®s (industrialisation). Nous sommes √©troitement li√©s aux parties prenantes m√©tiers de l'entreprise et aux √©quipes d'IA (personnalisation, tarification, pr√©vision, optimisation des offres) charg√©es de d√©ployer √† grande √©chelle les r√©sultats de nos exp√©rimentations . L'√©quipe joue un r√¥le central dans l'√©tablissement de nouvelles orientations en mati√®re d'IA au sein de Decathlon, en exp√©rimentant les derni√®res technologies d'apprentissage automatique pour r√©soudre des probl√®mes commerciaux √† fort impact et en diffusant la culture de l'IA dans toute l'organisation.Vous serez en charge de projets qui ont le potentiel de d√©finir l'avenir du sport. Rejoindre nos √©quipes c'est vraiment une chance de fa√ßonner l'industrie du sport gr√¢ce aux donn√©es et √† l'IA Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons en CDI un-e Data Value Engineer, bas√©-e √† Paris (pr√©voir des d√©placements r√©guliers de 2 jours tous les 15 jours sur Lille). VOS RESPONSABILITES En tant que Senior Data Value Engineer au sein du Data Value Lab, vous devrez: √ätre d√©di√© √† 100% aux projets digitaux strat√©giques li√©s √† la transformation de l'entreprise par l'IA, sur des sujets transverses (Sports & Process, Supply Chain, Marketing, Offre, Pricing, Sustainability principalement) Vous identifierez, cadrerez, prioriserez et construirez des solutions d'IA pour les m√©tiers : r√©alisation d'un business case, traduction d'un probl√®me m√©tier en solution d'IA, estimation du potentiel de valeur, exploration des donn√©es pour d√©terminer un niveau de faisabilit√© et enfin pilotage du build avec les √©quipes de Data Science. Vous remettrez en question les probl√®mes m√©tiers, la valeur potentielle et la faisabilit√© technique des besoins remont√©s . Vous serez amen√© √† projeter des cas d'usages pragmatiques √† partir de nos trajectoires digitales prioris√©es. Vous utiliserez vos connaissances des applications business de l'IA, ainsi que votre maitrise du cycle de vie d'un projet de Data Science , pour d√©finir les cas d'usages d'IA √† fort impact et garantir leurs mise en oeuvre. Vous serez en charge de l'organisation, de la pr√©paration et de l'ex√©cution des workshops m√©tiers lors de la phase de Design, avec des parties prenantes √† 360¬∞ afin d'identifier des besoins ou alors les cadrer. Vous appliquerez la m√©thodologie agile pour mener √† bien votre feuille de route et animer votre roadmap. V ous serez en charge du pilotage du projet lors des phases de Define et de Build , en collaborant avec des parties prenantes techniques et m√©tiers. Vous identifierez les donn√©es critiques (√† valeur) √† collecter et √† int√©grer dans le domaine des donn√©es d'entreprise, en partie gr√¢ce √† vos cadrages. Vous communiquerez efficacement l'analyse et les r√©sultats des exp√©rimentations, en passant par une mesure concr√®te de la valeur cr√©√©e. Et ce par le biais de visualisations, de documents et de pr√©sentations √† toutes les parties prenantes. CE DONT VOUS AUREZ BESOIN POUR R√âUSSIR Vous avez au moins 3 ans d'exp√©rience en tant que Consultant-e Data, Business Translator, PM Data ou Data Scientist; qui vous as permis-e d'√™tre un-e solide g√©n√©raliste Data sur l'ensemble du cycle de vie de la donn√©e. Hards Skills : Vous avez acquis une expertise des applications IA pour les business, de la traduction d'un probl√®me m√©tier en solution d'IA ; Vous comprenez et vous avez une connaissance compl√®te du cycle de vie d'un projet de Data Science, ainsi que des besoins et exigences en mati√®re de donn√©es; Vous avez acquis une exp√©rience en Business Analyse; Vous avez de solides comp√©tences de restitution d'analyses, pitch/argumentation ; Vous avez acquis une exp√©rience en management de projet Data, pilotant des √©quipes transverses √† la fois techniques et m√©tiers; Vous avez des comp√©tences en analyse des donn√©es : analyse et visualisation exploratoires des donn√©es; Vous avez un niveau de base en SQL et/ou en Python ; Vous √™tes exp√©riment√© en techniques de Design Thinking et leurs applications aux produits Data; Soft Skills : Vous avez d' excellentes comp√©tences interpersonnelles, analytiques, de communication et de pr√©sentation - capacit√© √† communiquer des r√©sultats complexes de mani√®re simple ; Vous avez des comp√©tences solides en mati√®re de r√©solution de probl√®mes, l'accent √©tant mis sur le d√©veloppement de produits ; Vous aimez d√©couvrir et r√©soudre des probl√®mes ; chercher de mani√®re proactive √† clarifier les exigences et les orientations ; vous √™tes une personne autonome qui prenez des responsabilit√©s lorsque cela est n√©cessaire ; Vous √™tes capable d'explorer diff√©rentes directions √† partir de donn√©es et √™tes capable de changer rapidement de direction en fonction de l'analyse ; Vous √™tes passionn√©.e par le sport et la mobilit√© Vous avez envie de rejoindre une entreprise √† impact positif (#Tech4Good) CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine (jours libres) ; Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Possibilit√© de se certifier d√®s la premi√®re ann√©e (AWS, GCP, etc..) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, notamment implant√©es √† Paris, Lille, Nantes, Lyon et Amsterdam. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si vous souhaitez en savoir plus sur nos engagements, vous pouvez consulter ce lien .","Decathlon is seeking a Senior Data Value Engineer for its Data Value Lab team in Paris to work on strategic digital projects related to the company's AI transformation. The role involves identifying, prioritizing, and building AI solutions for various business areas, challenging business problems, and value potential. The ideal candidate should have at least three years of experience as a data consultant, business translator, PM data, or data scientist, with expertise in AI applications for business, data science project lifecycle, and data analysis. They should also have excellent interpersonal, communication, problem-solving, and presentation skills and be passionate about sports and mobility. Decathlon offers a positive impact work environment, telecommuting, competitive compensation, stock options, mentoring, and training opportunities, among other benefits.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
362,50175,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-visualization-london-or-remote-uk_london,Software Engineer Data Visualization - London or Remote UK,Dataiku,"{go,Dataiku,Javascript,regard,Typescript,grid,dataiku,Node,scale,Java}",NaN,London,"Logiciels, Intelligence artificielle / Machine Learning, Big Data",Autres,2023-02-07,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1000 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,000+ employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku. Our solutions bring together big data and AI technologies into a unique and easy-to-use platform. It allows citizen data scientists to process and analyze data with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful data apps with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript/Typescript, ReactJS, Echarts on the frontend (we only support the latest versions of Chrome and Firefox!). Our backend is mostly based on Node.js microservices as well as some Java processes. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku users to create and display charts, dashboards, and ad-hoc data applications in a scalable way (both frontend and backend).- Prototype and create new ways to import and request data at large scale.- Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions.- Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best.- Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel!You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Dataiku‚Äôs culture is right for you if: You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com","Dataiku is seeking a talented software engineer to create intuitive, beautiful interfaces and scalable engines for its platform, which empowers non-technical users to process and analyze data with either user-friendly interfaces or code. The ideal candidate has experience in software development and data visualization tools, is customer-oriented, and comfortable with both frontend and backend development. Dataiku values diversity and is an equal opportunity employer.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
337,34803,https://www.welcometothejungle.com/fr/companies/inetum/jobs/data-engineer-azure-h-f_orleans_INETU_qD4d0wr,Data Engineer Azure,Inetum,"{Microsoft,Azure,Databricks,GitHub,AZURE}",NaN,Orl√©ans,IT / Digital,CDI,2022-08-08,"Inetum est une ESN agile, une soci√©t√© de services et de solutions digitales, et un groupe international qui aide les entreprises et institutions √† tirer le meilleur du digital flow. Dans un contexte de mouvement permanent, o√π les besoins et les usages se r√©inventent sans cesse, le groupe Inetum s'engage aupr√®s de tous les acteurs pour innover, s'adapter continuellement et garder une longueur d'avance. Avec son profil de multi-sp√©cialiste, Inetum met au service de ses clients une combinaison unique de proximit√©, d'organisation sectorielle et de solutions de qualit√© industrielle. Pr√©sent dans plus de 26 pays, le Groupe compte pr√®s de 27 000 collaborateurs et a r√©alis√© en 2020 un chiffre d'affaires de 1,966 milliard d'euros. Tous nos postes sont ouverts aux personnes en situation de handicap. Inetum r√©gion Centre, recherche un profil AZURE Data Engineer. Vos principales missions consistent √† : Concevoir et mettre en oeuvre des solutions sur la plateforme Microsoft Azure pour la persistance, l'enrichissement et l'analyse de donn√©es Conseiller sur diff√©rents types d'architecture Data lake et Data warehouse pour r√©pondre au mieux aux besoins des clients dans le respect des politiques s√©curit√©s Mettre en place les tests pour assurer la qualit√© des livrables et l'int√©grit√© des donn√©es produites Vous engager dans des projets clients, allant de la conception √† la mise en oeuvre de projets cloud (configuration, d√©veloppements, documentations...) Assurer le R√¥le de conseil pour la mise en oeuvre des bonnes pratiques La mise en oeuvre des strat√©gies de contr√¥le des co√ªts et recherche d'optimisations financi√®res des services La r√©daction de dossier d'architecture technique et de dossier de sp√©cifications techniques Ce que nous allons vous apporter : La consolidation de vos connaissances par la formation et des certifications. De formation sup√©rieure en informatique, avec plusieurs ann√©es d'exp√©riences. Vous avez une bonne connaissance des technologies Azure et une exp√©rience significative sur le Cloud Azure IAAS, PAAS Vous d√©montrez d'excellentes comp√©tences dans le relationnel avec les clients et en interne. Vous √™tes autonome et savez travailler en √©quipe. Comp√©tences techniques : Exp√©rience de d√©veloppement Big Data, Mod√©lisation d√©cisionnelle, en √©toile (Datawarehouse, Datamart), en offrant des niveaux √©lev√©s de performance, de s√©curit√©, d'√©volutivit√©, de maintenabilit√© et de fiabilit√© de la solution Microsoft AZURE Exp√©rience sur l'int√©gration de donn√©es D√©finition des indicateurs Azure Data Factory, GitHub, Azure DevOps minimum 3 ans Facultatif : Databricks","Inetum is seeking an Azure Data Engineer to design and implement solutions on Microsoft Azure for data persistence, enrichment, and analysis, advise on different types of Data lake and Data warehouse architecture, implement testing for quality and data integrity, and engage in client projects from design to implementation. The ideal candidate should have a good understanding of Azure technologies and experience on Azure Cloud IAAS and PAAS, in addition to excellent communication skills and the ability to work independently and in a team. Technical skills required include experience with Big Data development, decision modeling, and integration, as well as knowledge of Azure Data Factory, GitHub, and Azure DevOps. Optional skills include experience with Databricks.",N,N,N,0,1,0.013848874720779208
99,73676,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/data-solutions-engineer_paris,Data Solutions Engineer,Numberly,"{python,javascript,Python,SQL}",NaN,"28 rue de Ch√¢teaudun, Paris, 75009","Logiciels, Digital Marketing / Data Marketing, Big Data",CDI,2023-04-22,"Depuis sa cr√©ation en 2000, Numberly, Marketing Technologist, aide ses clients √† se diff√©rencier par la qualit√© de leur relation avec leurs propres clients. Son approche people-based permet aux annonceurs d‚Äôidentifier et de comprendre les besoins de leurs cibles pour dialoguer avec eux de mani√®re plus efficace et pertinente. Trois p√¥les compl√©mentaires permettent de r√©pondre aux enjeux des annonceurs, de l‚Äôacquisition √† la r√©tention : des experts en orchestration omnicanale mettent en place des programmes CRM intelligents et le trading programmatique en optimise l‚Äôimpact. Pour amorcer ou fortifier la relation entre la marque et sa cible, des plateformes conversationnelles sont mises en place pour cr√©er des exp√©riences personnalis√©es. Avec des √©quipes √† Paris, Londres, Duba√Ø, Montr√©al et New York, Numberly op√®re dans plus de 50 pays : le groupe, r√©solument international, poursuit son expansion. Plus de 500 collaborateurs contribuent tous les jours √† la qualit√© d‚Äôex√©cution et la satisfaction client, en restant curieux, agile et innovants, un √©tat d‚Äôesprit qui anime Numberly depuis plus de 20 ans ! Numberly offers one of the most advanced independent Customer Data Platform in France. For more than 10 years, Numberly has been improving its in-house solution, enabling data integration and usage in real-time. We combine our own tech infrastructure, our machine learning algorithms, and deep API integrations with the ecosystem to help brands build their data assets and optimize their marketing investments. What You Will Do: As a Solutions Engineer, you will join the Data team to work on our Customer Data Platform. Your role will be to make sure Numberly's solution is properly set up and ready to deliver the best performances for our clients. You will be working closely with people across Data Engineers, Software Engineers, Product and Marketing teams. Responsibilities will include: Create the technical specifications to implement Numberly‚Äôs solution on the client‚Äôs side Be the Tech Expert for clients' advanced discussions Ensure that everything is well set from a technical point of view Challenge our way of working and define new processes to maximize our internal efficiency Act as a Technical Project Manager to fix, develop or improve client-specific projects (from writing technical specifications to the delivery) Be able to work closely with both Tech (Data Scientists, Software Engineers, Data Engineers, Data Analysts) and Business teams (Media Traders, Marketing, Legal) to ensure we deliver the best possible solution to our client. At Numberly, we share a passion for passing on information to both our teams and clients: weekly internal talks, meetings with professionals who are experts in their field, and ongoing learning. Our onboarding is fast and powerful, thanks to the ""Jedi Masters"" assigned to each newcomer; the ""Vis ma vie"" (‚ÄúLive my life‚Äù in different teams); and the ""Happy Meetings"" (monthly internal get-togethers with all of our teams around the world to share the group's latest news). We cultivate freedom of speech, which allows everyone to participate in the group's on-going development. We positively impact our ecosystem through 1000mercis actions and activities that create value in the Open Internet; we contribute to the enrichment of the Open Source. Numberly is a diversity player and Gender Equal by design (WeConnect International certification and a gender equity score of 97/100). Numberly offers an international environment, hosting over 30 nationalities worldwide. Other perks: offices that reflect each team, a generous library, a large fully equipped music studio, two cats, waste separation and worm composting, the ability to bring your pet, and room for bikes! In each kitchen: coffee, tea, infusions at will and also mystery lunches, yoga classes, sports classes and parties (often disguised). Possibility to be remote up to 50% of your time (to be organized as you wish) and to work up to 60 consecutive days (working days) in remote locations in Europe Swile card (meal vouchers). Mobility is possible within our various international offices. Numberly welcomes people with disabilities. Who You Are: Minimum qualifications: Engineering master degree or business master degree with strong technical dimension You are curious about how things work and do not hesitate to be hands-on You have a problem-solving mindset with a strong tech curiosity You are a team-player and you enjoy working in a highly collaborative‚ÄØenvironment Fluent in English Preferred qualifications: Skilled in any data crunching language (SQL, Python...) At ease with understanding javascript or python scripts You already worked with a data visualization tool",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
279,56706,https://www.welcometothejungle.com/fr/companies/realadvisor/jobs/data-acquisition-engineer_geneva,Data Acquisition Engineer,RealAdvisor,"{React,MongoDB,NodeJS,Kubernetes,GitHub,PostgreSQL,Docker,github,TypeScript,GCP,GraphQL,Clickhouse}",NaN,"Geneva, 1201","Intelligence artificielle / Machine Learning, Immobilier commercial, Immobilier particulier",Freelance,2023-03-26,"RealAdvisor is a European PropTech startup based in Geneva. We use the power of cutting-edge web, data mining and machine learning technologies to make real estate transactions more transparent, fair and efficient. We help over 250k monthly users in their real estate projects whether they are: Searching for a place to buy or rent on our listings aggregator Estimating the value of their home online using our algorithms or browsing market data Our team has over 10 nationalities and is spread across Europe working remotely or based in our offices in Geneva & Z√ºrich. We are looking for a talented Data Acquisition Engineer to make new scrapers and maintain current stack of scrapers. You will work with a rockstar team of developers and data scientists (incl. Kaggle Masters) with over 10k github stars with over 10 nationalities and is spread across Europe working remotely. Our data acquisition stack is composed of NodeJS, Playwright, TypeScript, Temporal.io, MongoDB, Kubernetes, Helm, Terraform and GitHub Actions. Our application stack is composed of NextJS, React, Svelte, GraphQL, NodeJS, PostgreSQL & Clickhouse, GCP, Google AI Platform, Terraform, Nomad. Here are a couple of things you will be doing: Develop new scrapers and parsers for new countries & portals Migrate existing scrapers and parsers from our old stack Maintain and improve existing scrapers and parsers You‚Äôre the perfect candidate if you: Have extensive experience with NodeJS and TypeScript Are experienced in Docker, MongoDB, Relational Databases Are comfortable communicating in English Have a keen eye for checking every small detail Have passion for Data Acquisition Problem Solving Have shipped projects to production Have experience with large data sets and cloud computing Considered a plus: You have an interest in real estate / economics Enjoy writing extensive documentation Please send your proposal with details of your experience level, plus links to your previous works (if applicable). Important note: your proposal should start with ‚Äúrealadvisor-120485‚Äù as first line, this way we can see you have actually read our job posting and not applying automatically. We will send you a test challenge consisting of writing a simple scraper with NodeJS + TypeScript + ESM","RealAdvisor, a European PropTech startup based in Geneva, is seeking a talented Data Acquisition Engineer to develop new scrapers and maintain the current stack of scrapers. The ideal candidate should have extensive experience with NodeJS and TypeScript, be experienced in Docker, MongoDB, and Relational Databases, have a keen eye for details, and a passion for data acquisition problem-solving. Knowledge of real estate and economics is considered a plus. Fluency in English is a must.",Non sp√©cifi√©,Entre 15 et 50 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
177,2540,https://www.welcometothejungle.com/fr/companies/blade-shadow/jobs/data-software-engineer-h-f_paris_SHADO_ZmwMl8y,Data Software Engineer,Shadow,"{Go,via,Docker,SQL,Python,Bash}",NaN,Paris,SaaS / Cloud Services,CDI,2021-12-27,"Fond√©e en 2015 , Shadow est une entreprise fran√ßaise dont l‚Äôobjectif est de rendre l'informatique haut de gamme accessible √† tous.te.s ! Chez Shadow, nous r√©volutionnons la fa√ßon dont les utilisateurs du monde entier utilisent les ordinateurs pour travailler et jouer. La promesse ? Acc√©dez √† un PC puissant depuis le cloud qui peut faire tourner n'importe quelle application et jeu sur tous les √©crans gr√¢ce √† une configuration jamais obsol√®te ! Aujourd'hui, Shadow compte plus de 100 000 client.e.s r√©parti.e.s en Europe et aux √âtats-Unis. Notre √©quipe comprend d√©sormais pr√®s de 140 collaborateurs et collaboratrices, bas√©.e.s √† Paris et la Silicon Valley, qui ont pour mission commune de r√©volutionner le monde informatique. Shadow est une entreprise fondamentalement humaine, se nourrissant de l'√©nergie issue de la rencontre de profils tr√®s divers, avec le grain de folie de ceux qui peuvent rendre l'impossible possible. ‚Äúlls ne savaient pas que c‚Äô√©tait impossible, alors ils l‚Äôont fait‚Äù Si tu es d√©sireu.x.se de d√©buter une nouvelle aventure au sein d‚Äôune √©quipe qui pense ‚Äúoutside the box‚Äù, qui te fera grandir √† la fois professionnellement et personnellement, alors Shadow est fait pour toi ! Soyez libre d‚Äôesprit en cr√©ant, travaillant et jouant avec Shadow ! Depuis 2015, Shadow propose le meilleur de l‚Äôinformatique , utilisable n‚Äôimporte o√π et n‚Äôimporte quand gr√¢ce au cloud computing . Nous sommes convaincus que cr√©er de nouveaux outils puissants et accessibles √† tous.tes, permettra √† chacun.e.s de r√©aliser des choses extraordinaires. Aujourd‚Äôhui Shadow c‚Äôest une communaut√© comptant plusieurs dizaines de milliers d‚Äôutilisateur.trice.s en Europe et aux Etats-Unis , qui nous challenge au quotidien √† devenir une meilleure version de nous-m√™me. Mais Shadow c‚Äôest avant tout une √©quipe en constante croissance qui compte 130 collaborateur.rice.s bas√©s entre Paris & la Silicon Valley . Une entreprise fondamentalement humaine qui se nourrit de l'√©nergie issue de l‚Äô√©change entre des profils tr√®s divers , avec le grain de folie de ceux qui peuvent rendre l'impossible possible . Si tu es d√©sireu.x.se de commencer une aventure au sein d‚Äôune √©quipe aux id√©es infinies, qui te fera grandir √† la fois professionnellement et personnellement, alors rejoins Shadow ! Nous recherchons activement un.e Data Software Engineer pour rejoindre notre √©quipe Engineering ! Tes missions: -Concevoir et cr√©er une toute nouvelle architecture data √©volutive afin de r√©pondre √† l'ambition de scaling-up de l'entreprise; -Definir les technologies les plus adapt√©es pour le stockage et le traitement de donn√©es. Cela comprend l'√©tude, la mise en ≈ìuvre et le d√©ploiement; -D√©velopper des m√©thodes de mesure et de monitoring de la pr√©cision des metrics surveiller la pr√©cision des mesures, puis les analyser pour les optimiser; -Collaborer avec notre Machine Learning Enginer sur le d√©ploiement des mod√®les de machine learning (MLOps); -Rendre les datas facilement utilisables par tous dans l'entreprise; -Mettre en place et maintenir des outils √† disposition des collaborateurs Shadow. Ton profil: Tu ne te reconnais pas √† 100% dans les crit√®res ci-dessous ? Aucun probl√®me, envoie quand m√™me ton CV! Ces derniers ne sont pas tous √©liminatoires: Ta passion, ta curiosit√© et ta motivation nous aideront √† te faire grandir ;) -Tu poss√®des au moins 3 ans d‚Äôexp√©rience dans un poste similaire; -Tu sais cr√©er et maintenir des pipelines; -Tu as cr√©√© from scratch et scal√© un Data Warehouse; -Tu as une solide expertise en programmation (Python, Go et Bash); -Tu ma√Ætrises SQL, Docker et les tests unitaires; -Tu es √† l‚Äôaise avec les frameworks de traitement de donn√©es en temps r√©el; -Tu poss√®des une bonne exp√©rience en analyse data; -Tu as de bonnes connaissances en machine learning; -Tu fais preuve d‚Äôautonomie et tu restes proactif.ve dans tes missions; -Tu es un vrai team player, tu travailleras √©troitement avec plusieurs √©quipes pour atteindre un succ√®s commun; -Tu ma√Ætrises l‚Äôanglais (√©crit ; oral). Nos petits plus: -Une tr√®s bonne ambiance au sein d‚Äôune √©quipe passionn√©e ! -Ta machine virtuelle dispo de suite; -Des bureaux en plein c≈ìur de Paris (2eme), parfait pour les afterworks ! -Un CSE au top qui t‚Äôaccompagne dans toutes les situations et qui te trouve des super plans (via notre plateforme Leeto); -Les meilleurs outils pour faciliter ton exp√©rience chez Shadow (Payfit, Alan, Swile‚Ä¶); -T√©l√©travail sur ce poste possible. Tu peux aussi venir tous les jours si tu le souhaites ! ; -Le go√ªter √† volont√© (manger/bouger); -Tout pour apprendre √† conna√Ætre tes coll√®gues ‚Äúen off‚Äù: Borne d‚Äôarcade, jeu de fl√©chettes, game night... -Petit-d√©jeuner du lundi au mercredi pour bien commencer la semaine; -Le reste est √† d√©couvrir ;) Et bien s√ªr: -Tickets restaurant (via Swile); -Remboursement √† 50% du pass navigo; -Cotisation √† 50% de la mutuelle (ALAN). Ton process de recrutement: Nous te proposerons un appel de 30 minutes, avec une personne de l‚Äô√©quipe de recrutement pour faire connaissance et te pr√©senter le poste. S‚Äôil nous semble pertinent (√† toi et √† nous) d‚Äôavancer, tu rencontreras: 1)Edouard, notre Chief information Officer 2)Martin, notre Business Intelligence Director et Baptiste, notre Data Engineer 3)Octave, notre CTO N‚Äôattends plus, rejoins-nous ! Shadow valorise la diversit√© des personnes qu‚Äôelle embauche et accompagne. La diversit√©, pour Shadow, c‚Äôest favoriser un milieu de travail o√π les diff√©rences individuelles sont reconnues, appr√©ci√©es et respect√©es de fa√ßon √† d√©velopper le plein potentiel et les forces de chacun.e. Restez vous-m√™me, vous √™tes le.a bienvenu.e ;) Ce contenu est bloqu√© Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","Shadow is seeking a Data Software Engineer with at least 3 years of experience in a similar role to join their Engineering team. The engineer will be responsible for designing and creating a new scalable data architecture, defining the most appropriate technologies for data storage and processing, developing methods for measuring and monitoring metric accuracy, and collaborating with the Machine Learning Engineer on machine learning model deployment. The ideal candidate must have experience in programming, SQL, Docker, and unit testing, as well as real-time data processing frameworks and data analysis. A team player with autonomy, proactiveness, and English fluency is preferred. Shadow is committed to diversity and welcomes candidates of different backgrounds.",N,N,N,0,1,0.013848874720779208
195,56522,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_strasbourg,DATA ENGINEER,ACTINVISION,"{Microsoft,MySQL,GCP,Talend,Matillion,AWS,Snowflake,Alteryx,Azure,Java,SQL,Python,Tableau}",NaN,"5, Quai de Paris, Strasbourg, 67000","Intelligence artificielle / Machine Learning, Transformation, Big Data",CDI,2023-03-26,"Fond√©e en 2014, Actinvision est un regroupement de Data Heroes accompagnant diff√©rents acteurs dans leur transformation vers une culture data. Cr√©ant un lien de confiance avec ses clients, elle donne √† ces derniers les moyens d‚Äôanalyser leurs innombrables donn√©es. M√™lant expertise technique de haut niveau et cr√©ativit√© sans limites, elle d√©veloppe des approches personnalis√©es destin√©es √† valoriser les donn√©es de l‚Äôorganisation. Actinvision, c‚Äôest aujourd‚Äôhui plus de 300 clients en France et √† l‚Äôinternational dans divers secteurs, allant de l‚Äôindustrie √† la grande distribution en passant par le secteur financier. Son fief se trouve dans la r√©gion Grand Est et plus pr√©cis√©ment en Alsace, √† Strasbourg. C‚Äôest de l√† qu‚Äôest dirig√© l‚Äôensemble des op√©rations, notamment men√© √† travers un second bureau, positionn√© √† Paris. Actinvision est, en interne, une communaut√© multiculturelle ‚Äúfun‚Äù orient√©e autour de la data et, en externe, un partenaire reconnu et privil√©gi√© par de nombreuses entreprises leaders du march√© : Tableau, Alteryx, Snowflake, Microsoft, Talend, etc. Entreprise accr√©dit√©e ‚ÄúHappy at Work‚Äù par ChooseMyCompany Vous serez amen√©(e) √† travailler sur diff√©rents projets innovants , pour des clients de toute taille , dans des secteurs divers et vari√©s tels que l‚Äôagroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l‚Äô√©nergie, l‚Äôindustrie, la pharma/chimie ou encore la sant√©. En tant que Data Engineer passionn√©(e), vous aiderez nos clients √† relever les challenges d‚Äôaujourd‚Äôhui et de demain en int√©grant leurs donn√©es au sein d‚Äôinfrastructures, On-Premise et Cloud. A la suite d‚Äôune p√©riode d‚Äôint√©gration destin√©e √† vous familiariser avec la m√©thodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l‚Äôanalyse du besoin client √† la livraison de la solution technique en passant par le chiffrage et les d√©veloppements. Vous √©voluerez en √©quipe mais √©galement de mani√®re autonome dans un environnement technique porteur d‚Äôinnovations incluant par exemple la mod√©lisation et la construction d‚Äôentrep√¥ts de donn√©es (Data Warehouses), le design de flux d‚Äôint√©gration au moyen d‚Äôoutils (e.g. Talend ou ADF, Matillion etc. ) permettant l‚Äôalimentation de ces derniers, ou encore la mise en place et l‚Äôoptimisation dans le respect des bonnes pratiques d‚Äôarchitectures Data, notamment Cloud (e.g. Snowflake ou Azure). Le d√©veloppement des comp√©tences est un aspect primordial. Ce d√©veloppement continu est appuy√© par les ressources officielles mises √† disposition par l‚Äôensemble des √©diteurs partenaire d‚ÄôActinvision et compl√©t√© par des ressources internes. Les comp√©tences acquises pourront √™tre valoris√©es aux travers de certifications √©diteurs hautement qualifiantes. MISSIONS PRINCIPALES : ‚Ä¢ Participer en √©quipe ou de fa√ßon autonome √† la mise en ≈ìuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie int√©gration et stockage de la donn√©e ‚Ä¢ Recueil du besoin client technico-fonctionnel permettant la mise en place d‚Äô architectures pour la collecte et l‚Äôextraction de donn√©es depuis diverses sources (bases de donn√©es Cloud, applications m√©tier, API, etc.), la manipulation et la transformation de ces donn√©es, puis le chargement de ses derni√®res au sein de base de donn√©es de type Data Warehouses (DWH) ‚Ä¢ Design des infrastructures/architectures Data et mod√©lisation des DWH cibles, lesquels seront principalement utilis√©s dans le cadre d‚Äôop√©rations de Reporting et/ou de Data Visualisation ‚Ä¢ R√©alisation de flux d‚Äôint√©gration et transformation de donn√©e De formation Bac+5 en informatique, vous disposez de minimum 1 an d‚Äôexp√©rience sur un poste similaire. Savoir-faire, comp√©tences techniques requises : ‚Ä¢ Langage SQL et mod√©lisation DWH ‚Ä¢ Pratique d‚Äôun outil d‚Äôint√©gration ETL / ELT ‚Ä¢ Connaissances en bases de donn√©es relationnelles (e.g. SQL Server ou MySQL) ‚Ä¢ Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP) ‚Ä¢ Connaissances de la cha√Æne de valeur de la Data, et particuli√®rement de la BI Savoir-faire, comp√©tences techniques appr√©ci√©es : ‚Ä¢ Connaissances en architectures Cloud (s√©curit√©, performances, ma√Ætrise des co√ªts, etc.) ‚Ä¢ Programmation proc√©durale, e.g. T-SQL ou PL/SQL ‚Ä¢ Un langage de programmation orient√© objet, e.g. Java ou Python ‚Ä¢ A l‚Äôaise avec l‚Äôutilisation d‚ÄôAPI / de Web Services ‚Ä¢ Notions sur l‚ÄôESB Savoir-√™tre, comp√©tences fonctionnelles : ‚Ä¢ Passion pour la Data ‚Ä¢ Autonomie / Travail et esprit d‚Äô√©quipe (incluant le partage des connaissances) ‚Ä¢ Force de proposition / Capacit√© √† rechercher et trouver des solutions ‚Ä¢ Cr√©ativit√© et curiosit√© ‚Ä¢ Dynamisme et r√©activit√© ‚Ä¢ Sens du service ‚Ä¢ Capacit√© √† participer √† l‚Äôanimation de la communaut√© (interne et externe) ‚Ä¢ Anglais technique ‚Ä¢ Pour un poste confirm√© : Exp√©rience probante dans les domaines du DWH et de l‚Äôint√©gration de donn√©es (cloud et/ou on-prem) Moyenne de temps du process de recrutement chez Actinvision : 15 jours Pr√© qualification t√©l√©phonique : 15 √† 20 minutes Entretien technique : 1h00 Entretien RH : 1h00","Actinvision is a data consulting firm seeking a passionate Data Engineer with knowledge in ETL tools, SQL, and data warehousing. The Data Engineer will participate in all project phases from client analysis to solution delivery, and work with various sectors, including finance, retail, agriculture, and energy. Actinvision encourages team collaboration, innovation, and professional development opportunities with official resources from their technology partners. The ideal candidate is a creative problem solver, team player, and fluent in English with at least one year of experience.",Bac +5 / Master,Entre 50 et 250 salari√©s,> 1 an,0,1,0.013848874720779208
268,62111,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-ingenieur-manipulation-et-valorisation-des-big-datas-f-h_brest_ASI_4oZeyg8,Data Ing√©nieur - Manipulation et valorisation des big-datas,ASI,"{MySQL,Oracle,ElasticSearch,Scala,Kafka,Cassandra,PostGreSQL,Spark,SQL,Java,NoSQL,Hadoop,Python,Cloudera}",NaN,Brest,"IT / Digital, Transformation, Big Data",CDI,2023-03-30,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Vous aurez pour mission de : Concevoir et r√©aliser un sourcing de donn√©es Big Data Temps r√©els ou non Ma√Ætriser les formats de donn√©es non structur√©s et savoir les manipuler Concevoir et r√©aliser une cha√Æne de traitement dans un environnement Big Data Concevoir et r√©aliser des applications et API utilisant les donn√©es valoris√©es G√©rer et administrer les bases de donn√©es filesystem et NoSQL Ecosyst√®me en place : Hadoop, Spark, Kafka, ElasticSearch, MangoDB, Cassandra, Big Query Langages de d√©veloppement‚ÄØ: Python, Java, Scala. Id√©alement titulaire d‚Äôun Bac+4/5 (Ecole d‚ÄôIng√©nieur ou Universitaire), vous maitrisez : Hadoop (Cloudera)et/ou une solution de base de donn√©es NoSQL Le requ√™tage SQL, HiveQL Le d√©veloppement Spark avec SQL, Python et/ou Scala Le d√©veloppement Java (API en particulier) Les bases de donn√©es relationnelles (PostGreSQL, Oracle, SQLServer, MySQL‚Ä¶)","ASI is a digital expertise company that develops digital services for public and private organizations to support them in their digital transformation. They are looking for a Big Data Developer who can design and execute real-time and non-real-time data sourcing, manipulate unstructured data formats, develop an end-to-end processing chain in a Big Data environment, and create applications and APIs using the data. The ideal candidate should have a degree in Engineering or a related field and experience with Hadoop, NoSQL databases, SQL and HiveQL querying, Spark development, and Java.",Bac +4,Entre 250 et 2000 salari√©s,> 5 ans,0,1,0.013848874720779208
387,34756,https://www.welcometothejungle.com/fr/companies/axians/jobs/consultant-data-engineer-f-h_la-defense,Consultant Data Engineer,Axians France,"{durable,GIT,regard,HADOOP,Hive,Spark,SQL,JAVA}",NaN,La D√©fense,"Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Cybers√©curit√©",CDI,2022-08-08,"Rejoindre Axians, c'est rejoindre un r√©seau d'entreprises agiles pr√©sentes dans 26 pays et compos√© de 12 000 collaborateurs r√©alisant un CA de 2,6 Milliards d'euros. Axians est la marque de VINCI Energies d√©di√©e aux solutions ICT, c'est-√†-dire la maitrise de l'ensemble des technologies de l'information et de la communication : R√©seaux d'entreprises, digital Workspace & Collaboration, Cloud priv√© et hybride, Cybers√©curit√© sur projets ou en Services Manag√©s. Nous accompagnons nos clients entreprises priv√©es, secteur public, op√©rateurs et fournisseurs de services - dans la transformation de leurs solutions digitales. Fortement impliqu√©e sur nos territoires respectifs, Axians a une forte politique de d√©veloppement durable en s'engageant sur une r√©duction de 40% de ses √©missions de CO2 √† l'horizon 2030 mais √©galement d'actions solidaires touchant √† l'insertion, √† l'√©ducation au travers de la Fondation VINCI et de nombreux partenariats √©coles.Connexion, performance, efficience √©nerg√©tique, datas : dans un monde en √©volution permanente, VINCI Energies acc√©l√®re le d√©ploiement des nouvelles technologies pour concr√©tiser deux mutations majeures : la transformation digitale et la transition √©nerg√©tique. Ancr√©es dans les territoires et organis√©es en mode agile, les entreprises de VINCI Energies rendent les infrastructures d'√©nergie, de transport et de communication, les usines ainsi que les b√¢timents chaque jour plus fiables, plus s√ªrs, plus efficients. 2021 : 15,1 milliards d'euros (chiffre d'affaires) // 85 700 collaborateurs // 1800 entreprises // 55 pays www.vinci-energies.com Dans le cadre du d√©veloppement de notre activit√©, nous recherchons un consultants Data Engineer (F/H) pour intervenir chez l'un de nos clients √† Paris La D√©fense. Votre mission portera sur des t√¢ches parmi les suivantes : - Participer aux c√©r√©monies (daily, affinage, sprint planning) - Assurer les d√©veloppements sp√©cifiques - R√©aliser des tests unitaires et d'int√©gration - Garantir la maintenabilit√© et les performances des programmes d√©velopp√©s - Maintenir √† jour la documentation - Apporter un regard critique sur les fonctionnalit√©s d√©j√† d√©velopp√©es ou √† d√©velopper. Vous poss√©dez un dipl√¥me d'ing√©nieur ou Master en informatique (sp√©cialit√© statistique ou informatique d√©cisionnelle) et vous b√©n√©ficiez d'un exp√©rience minimum de 2 ans sur des projets utilisant les √©co-syst√®me Big Data. Comp√©tences techniques : - Langage SQL - Technologie HADOOP : Spark, Hive - D√©veloppement JAVA - GIT - Connaissance en mod√©lisation de la donn√©e Comp√©tences relationnelles et fonctionnelles : - Esprit d'√©quipe et connaissance des m√©thodes agiles - Pro-activit√© et regard critique sur la conception de traitement techniques - Connaissance du domaine de l'assurance","Axians, part of VINCI Energies, is looking for a Data Engineer Consultant to join their team in Paris La Defense. The role involves participating in daily planning, developing specific programs, conducting unit and integration testing, ensuring program maintainability and performance, updating documentation, and providing critical insight on developed and to-be-developed functionalities. The ideal candidate should possess a degree in computer science, statistics, or decision-making, have a minimum of 2 years' experience working with Big Data ecosystems, and have experience with SQL, HADOOP technology like Spark and Hive, Java development, and data modeling. The role also requires teamwork, knowledge of agile methodology, and a proactive approach to technical processing design.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 1 an,0,1,0.013848874720779208
410,37143,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_niort_ASI_0rWWPNz,Data Engineer,ASI,"{DynamoDB,Matillion,Glue,Cassandra,Hive,Neo4J,Azure,Cloudera,MongoDB,Talend,Kafka,NoSQL,CouchDB,HBase,Java,Hadoop,Redis,EMR,Scala,Airflow,HDFS,S3,Spark,Python}",NaN,N,"IT / Digital, Transformation, Big Data",CDI,2022-10-18,"ASI est un cabinet d‚Äôexpertises num√©riques qui accompagne les organisations publiques et priv√©es dans leur transformation digitale en d√©veloppant des services num√©riques destin√©s √† leurs collaborateurs, partenaires et clients. Nous sommes pr√©sents dans 7 villes en France : Nantes (notre si√®ge), Rennes, Brest, Niort, Paris, Lyon & Bordeaux. Soucieux de favoriser un num√©rique aux impacts positifs (social, environnemental, soci√©tal‚Ä¶), notre raison d‚Äô√™tre inscrite dans nos statuts traduit nos engagements : agir pour un monde num√©rique responsable au service de l‚Äôhumain. üå≥ Consultant Digital, Product Owner, Consultant Marketing, Lead Dev, D√©veloppeur, Data Analyst, Agiliste, Chef de projet, UX / UI Designer, Product Manager, Scrum Master, Directeur de projet, Architecte‚Ä¶ Nous sommes une belle et grande communaut√© de 500 collaborateurs aux comp√©tences compl√©mentaires qui partagent les m√™mes valeurs : confiance, √©coute, engagement et plaisir de travailler dans le bonne humeur ! üòÄ Dans un souci d‚Äôaccessibilit√© et de clart√©, les termes employ√©s au masculin se r√©f√®rent aussi bien au genre f√©minin que masculin. Dans le cadre du d√©veloppement de nos expertises Data et pour r√©pondre aux enjeux de nos clients, nous recherchons un Data Engineer pour int√©grer notre √©quipe Niortaise Au quotidien : Vous concevez et r√©alisez un sourcing de donn√©es Big Data, temps r√©el ou non Vous ma√Ætrisez les formats de donn√©es non structur√©s et savez les manipuler Vous mod√©lisez un sch√©ma de base de donn√©es relationnelle ou non-relationnelle Vous connectez une solution ETL / ELT √† une source de donn√©es (fichiers, API, base de donn√©es, flux temps r√©el) Vous concevez et r√©alisez un pipeline de transformation et de valorisation des donn√©es et ordonnancez son fonctionnement Vous veillez √† la s√©curisation des pipelines de donn√©es Vous concevez et r√©alisez des API utilisant les donn√©es valoris√©es Vous r√©alisez une veille technologique constante. Parlons de vous : Issu d‚Äôune formation sup√©rieure en informatique, math√©matiques ou sp√©cialis√© en Big Data. Vous poss√©dez une exp√©rience minimum de 2-3 ans en ing√©nierie des donn√©es et d'une exp√©rience op√©rationnelle r√©ussie dans la construction de pipelines de donn√©es structur√©es et non structur√©es. Vous avez une exp√©rience pratique dans l‚Äôun ou plusieurs des environnements technologiques suivants : L‚Äô√©cosyst√®me Data : Spark, Hive, HDFS, Kafka, HBase et id√©alement une distribution Hadoop (Cloudera, EMR, HDInsight) Les langages : Scala, Java, Python Les bases de donn√©es NoSQL : MongoDB, Cassandra, DynamoDB, CosmosDB, CouchDB, Redis, Neo4J Stockage cloud: S3, Azure Blob Storage‚Ä¶ Les ETL/Outils d'orchestration du march√© : Matillion, Airflow, Datafactory, Glue, Talend,... Le respect et l‚Äôengagement font partie int√©grante de vos valeurs. Vous avez l‚Äôesprit d‚Äô√©quipe et vos qualit√©s relationnelles vous permettent de vous int√©grer facilement au sein de l‚Äô√©quipe. √Ä comp√©tences √©gales ce poste est ouvert aux personnes en situation de handicap .","ASI is seeking a Data Engineer to join their team in Niort to support the development of their Data expertise and meet client needs. The ideal candidate should have a minimum of 2-3 years of experience in data engineering and should possess practical experience in one or more of the following technological environments: Data Ecosystem, Languages, NoSQL Databases, Cloud Storage, and ETL/Orchestration Tools. The candidate should also have excellent teamwork skills and a commitment to respect and engagement. The position is open to all, including people with disabilities.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,0,1,0.013848874720779208
289,56734,https://www.welcometothejungle.com/fr/companies/artefact/jobs/data-software-engineer-m-f-d_utrecht,Data & Software Engineer,Artefact,{},NaN,"Utrecht, 3511","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing",CDI,2023-03-26,"Artefact is a consulting firm specialized in AI and Data. We are convinced that marketing cannot be optimized without engineering and technology, that‚Äôs why we identify as ‚Äúmarketing engineers‚Äù. In order to improve the performance and impact of brands, and consumers‚Äô experience, we assemble lots of different talents: data application engineers, data scientists, creatives and designers, advertising strategists and consultants. In only four years, Artefact has become one of the international references for Data and IA expertise. The society counts today more than 1000 collaborators worldwide, in 17 countries and gathers 3 complementary offers: Data Consulting, Digital Marketing expertise and the Deployment of Technologies (Big Data and Artificial Intelligence). tl;dr From design to deployment , you manage your solution end-to-end, while also optimising the performance, security and scalability. Salary range : from 42K-80k euro per year in France, or equivalent in other countries. Our working language is in English and preferably the local language of the office. The team The most tech people of our Data & Consulting division, the title of ""Data engineer"" or ""Software engineer"" does not describe everything our amazing women and men can do: data engineering, operation management, security, cloud architecture, MLOps, and more. Presenting in each and every office of Artefact, working seamlessly with our consultants and data experts, our Data & Software engineers are the ones who make our data projects come true. Mission You will work with the team to identify your clients' needs and define innovative solutions of which you will be ownership from start to end. You manage both its conception and implementation, while also optimising the performance and scalability. You will also coach others, keep abreast of industry news/updates and get stuck into training sessions with our business partners and suppliers, such as Google & Amazon. You share your knowledge, learnings and success, with the capability of presenting and communicating. Desirable skills You are the master of several, or all the value chain's activities of the projects: cloud infrastructure, data pipeline implementations, data warehouse and data lake management, machine learning engineering, APIs, software testing, continuous integration and deployment; You have no problem popularizing technical terms or solutions to more business-oriented profiles, you can work in a team with very diversified profiles. You know how to prioritize your tasks, respect deadlines, and anticipate projects' risks. ... or soon you will be, contact us! Why should you join us Artefact is the place to be: come and build the future of data and marketing Innovation: We have a passion for creating impacting projects, and believe innovation can come from anyone. Action: We make things rather than telling people how to make them. Collaboration: We believe in bringing talented people together, in winning together, and in learning from each other. Come join us!","Artefact is a consulting firm specializing in AI and data, seeking a data or software engineer to work with clients to identify their needs and develop end-to-end solutions. The ideal candidate will have proficiency in various aspects of the project value chain, including cloud infrastructure and machine learning engineering, and will have the ability to communicate technical solutions to business-oriented profiles. With a passion for innovation and collaboration, Artefact offers an exciting opportunity to build the future of data and marketing. Salary ranges from 42K-80k euro per year.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
414,39629,https://www.welcometothejungle.com/fr/companies/contentsquare/jobs/data-engineer-barcelona_barcelona,Data Engineer,Contentsquare,"{go,regard,ContentSquare,Go,color,Scala,Akka,AWS,Contentsquare,scale,Kafka,Elasticsearch,Spark,ClickHouse,Java}",NaN,"Barcelona, 08007","SaaS / Cloud Services, E-commerce",CDI,2022-11-29,"Contentsquare is a digital experience analytics company dedicated to making the digital world more human through online experiences built on trust, privacy, and accessibility. Since their founding in France in 2012, they have grown to be a truly global team, representing more than 70 nationalities in offices across the world, including New York, London, Paris, Munich, San Francisco, Barcelona, Amsterdam, Tel Aviv, Tokyo, Singapore, and more. As they‚Äôve grown and evolved, their customers, investors, and the media have taken notice. They have been recognized by Frost & Sullivan as a Global Company of the Year, and by Wired Magazine as one of Europe‚Äôs hottest startups. In July of 2022, they raised $600M in Series F funding, doubling their valuation to $5.6B. Contentsquare is a global digital analytics company empowering the brands you interact with every day to build better online experiences for all. Since our founding in France in 2012, we have grown to be a truly global and distributed team ‚Äì known as the CSquad ‚Äì representing more than 70 nationalities across the world. In 2022, we raised $600M in Series F funding, doubling our valuation to $ 5.6B and were recognised as a certified Great Place to Work in France, Germany, Israel, US and UK. As a Data Engineer, you will join a team of passionate and talented developers, designing and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to work at ContentSquare ! We collect several billions events per day, and query hundreds of terabytes in real time. Your daily work will consist of: ‚Ä¢Designing efficient architectures to store and analyze petabytes of data ‚Ä¢Leading large scale projects and mentoring other developers ‚Ä¢Implementing complex acquisition workflows ‚Ä¢Thinking of smart data formats to serve the functionalities of the product, while minimizing the cost ‚Ä¢Developing tools to help data-scientists ....by using some open source technologies such as Scala, Go, Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc. With a minimum 2-3 years of experience, you are proficient in either Scala, Java or Go, and ideally several other backend languages. You practice or have an interest in functional programming and seek to develop your skills in Data engineer programming languages. Kafka, Akka, Spark, AWS‚Ä¶ You have had the chance to discover or work with these big data technologies. Ideally, you have some experience on a wide range of databases and you are interested in streaming. You would like to challenge yourself developing distributed infrastructure with a real time and data-intensive environment. You would like to share your skills and take part in technical choices. Why join ContentSquare‚Äôs Data Engineering team? ‚Ä¢You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data ‚Ä¢You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences ‚Ä¢You are looking for an environment where you‚Äôll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategical corporate axes. If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross team innovation days, we are committed to innovate towards tomorrow‚Äôs user experience. You‚Äôll also have: flexible working hours, remote ; yoga, and many other activities; after work beers provided every Friday, monthly parties‚Ä¶and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge! Why you should join Contentsquare: ‚ñ™Ô∏è We‚Äôre humans first. We hire dedicated people and provide them with the trust, resources and flexibility to get the job done. ‚ñ™Ô∏è We invest in our people through career development, mentorship, social events, philanthropic activities, and competitive benefits. ‚ñ™Ô∏è We are a fast growing company with a track record of success over the past 10 years, yet we operate with the agility of a startup. That means a huge chance to create an immediate and lasting impact. ‚ñ™Ô∏è Our clients, partners and investors love our industry-leading product. To keep our employees happy and engaged, we are always assessing the benefits/perks we offer to ensure we are competitive. Here are a few we want to highlight: ‚ñ™Ô∏è Virtual onboarding, Hackathon, and various opportunities to interact with your team and global colleagues both on and offsite each year. ‚ñ™Ô∏è Work flexibility: hybrid and remote work policies. ‚ñ™Ô∏è Generous paid time-off policy (every location is different). ‚ñ™Ô∏è Immediate eligibility for birthing and non-birthing parental leave. ‚ñ™Ô∏è Wellbeing allowance. ‚ñ™Ô∏è Home Office Allowance. ‚ñ™Ô∏è A Culture Crew in every country to coordinate regular outings such as game nights, movie nights, and happy hours. ‚ñ™Ô∏è Every full-time employee receives stock options, allowing them to share in the company‚Äôs success. ‚ñ™Ô∏è We offer many benefits in various countries -- ask your recruiter for more information. Uniqueness is embedded in our DNA as one of our core values. Even if you don‚Äôt meet all of the requirements above, we encourage you to apply. Contentsquare is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. Your personal data is used by Contentsquare for recruitment purposes only. Read our Job Candidate Privacy Notice to find out more about data protection at Contentsquare and your rights.","Contentsquare is seeking a data engineer to design and develop a new data architecture, including designing efficient architectures to analyze petabytes of data, leading large-scale projects, implementing complex acquisition workflows, and developing tools to help data scientists. The ideal candidate has 2-3 years of experience and is proficient in backend languages such as Scala, Java, or Go, as well as big data technologies such as Kafka, Akka, and Spark. The company offers a variety of cool projects, flexible work hours and remote working, career development opportunities, competitive benefits, and a friendly team.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 2 ans,0,1,0.013848874720779208
295,56767,https://www.welcometothejungle.com/fr/companies/decilia/jobs/azure-data-engineer-h-f_boulogne-billancourt,Azure Data Engineer,Decilia,"{Microsoft,Databricks,Scala,Synapse,Spark,Azure,SQL,Python}",T√©l√©travail ponctuel autoris√©,"39, Rue de la Saussi√®re, Boulogne-Billancourt, 92100",IT / Digital,CDI,2023-03-26,"D√©cilia est une ESN Gold Partner Microsoft. Sp√©cialiste de la data depuis 14 ans, elle accompagne ses clients dans la r√©alisation de projets complexes et innovants. Poste : Azure Data Engineer (H/F) Type de contrat : CDI √† plein temps Lieu : Normandie ou Ile de France Niveau d‚Äôexp√©rience : confirm√© Salaire : selon profil D√©cilia est une ESN Gold Partner Microsoft. Sp√©cialiste de la data depuis 14 ans, nous accompagnons nos clients dans la r√©alisation de projets complexes et innovants. Dans le cadre de la croissance de nos activit√©s, nous recrutons un(e) Azure Data Engineer. En tant que Azure Data Engineer , vous serez amen√©(e) pour le compte de nos clients √† : D√©velopper et optimiser des pipelines de donn√©es (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions, Assurer le recueil du besoin client Participer √† la conception de Datalake, Travailler en √©troite collaboration avec l‚Äô√©quipe architectes, Industrialiser des mod√®les de Machine Learning issus de notre entit√© D√©cilia Science Utiliser au quotidien la m√©thodologie SCRUM et DEVOPS Pourquoi nous rejoindre ? D√©cilia favorise la consolidation des connaissances de ses consultants par la formation et la multiplication des certifications ; Devenez r√©f√©rent d‚Äôune brique technologique, et √† terme, animez une de nos squads ! Vous serez accompagn√© personnellement par un coach et boosterez vos comp√©tences relationnelles ; Un grand nombre de vos missions seront en t√©l√©travail ; B√©n√©ficiez d‚Äôun cadre de travail stimulant et bienveillant : 2 agences id√©alement situ√©es √† Boulogne-Billancourt (Les Passages) et √† Rouen Centre (Palais de Justice) Plusieurs √©v√©nements internes organis√©s : s√©minaires, tech lunch, afterworks, team building,‚Ä¶ Et int√©grez une entreprise certifi√©e ¬´ Happy at Work ¬ª depuis 3 ans ! Environnement technique : Cloud‚ÄØ: Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning) Langages: Python, Scala, SQL, C# Big Data‚ÄØ: Spark, Databricks Niveau d‚Äôexp√©rience : confirm√© Et pour plus d‚Äôinformations sur l‚Äôentreprise et son processus de recrutement n‚Äôh√©sitez pas √† consulter notre site internet : Decilia.fr Si vous aimez les challenges, l‚Äôesprit d‚Äô√©quipe, la bonne humeur, rejoignez une soci√©t√© √† taille humaine en postulant d√®s maintenant !!","D√©cilia, a Microsoft Gold Partner, is seeking an Azure Data Engineer with experience in developing and optimizing data pipelines and conducting elicitation of client needs. The candidate should have expertise in working with Microsoft Azure, Python, Scala, Spark, and Databricks. The company offers a stimulating work atmosphere, training, and certification opportunities, as well as a chance to become a technology reference and eventually lead a squad.",Bac +5 / Master,Entre 15 et 50 salari√©s,> 3 ans,1,0,0.013848874720779208
338,56797,https://www.welcometothejungle.com/fr/companies/decathlon-technology/jobs/support-engineer-data-exchange-f-m-d_croix_DT_VdMRw52,"Support Engineer, Data Exchange",Decathlon Digital,"{Solarwinds,splunk,SAP,Kafka,IBM}",NaN,Croix,"Grande distribution, Sport, E-commerce",CDI,2023-03-26,"Depuis plus de 40 ans, gr√¢ce √† ses produits innovants et fort de sa culture reposant sur l‚Äôaccessibilit√©, Decathlon ne cesse de r√©inventer le march√© du sport. Notre mission : rendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre. Aujourd‚Äôhui, nous tirons parti de cette culture de l‚Äôinnovation et de notre expertise digitale pour qu‚Äôun public plus large puisse b√©n√©ficier des plaisirs du sport et ce, √† l‚Äôaide de la technologie. Nous cr√©ons de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d‚Äôoccasion, mais aussi services de location d‚Äôune large gamme de produits Decathlon et de partenaires. Notre objectif: cr√©er un √©cosyst√®me digital de produits et services. Nos √©quipes tech fran√ßaises implant√©es √† Paris (Global Business Hub), Lille (HQ), Nantes et Lyon rassemblent plus de 2500 software engineers, product manager et expert¬∑e¬∑s de la data, uni¬∑e¬∑s pour construire et faire √©voluer nos produits dont le but unique est de r√©pondre aux besoins de nos 500 millions d‚Äôutilisateurs. La BU Data Exchange La BU Data Exchange regroupe des √©quipes d'√©changes de donn√©es sur nos technologies Webmethods, SAP PO, IBM MQ et Kafka. Notre mission : √™tre garant du bon fonctionnement et de la cr√©ation des √©changes de donn√©es de l‚Äôint√©gralit√© du groupe au sein de notre syst√®me d'information et avec nos partenaires. REJOINS L'√âQUIPE Data in Motion L'√©quipe Data In Motion est responsable des technologies de messaging : Webmethods, SAP PO et IBM MQ. Nous accompagnons la transformation digitale et permettons au SI de communiquer sur les domaines Logistique, Ecommerce, Retail, Supply, Finance, RH. Ce sont environ 200 millions de flux qui circulent par mois, gr√¢ce au travail de l‚Äô√©quipe. Dans le cadre de l‚Äôouverture d‚Äôun poste en interne, nous recrutons un-e Ing√©nieur-e support, bas√©-e √† Lille. TES RESPONSABILIT√âS Prendre en compte les demandes des utilisateurs (incidents et tickets), support niveau 2 & 3 Anticiper les incidents (monitoring, proactivit√©) Diagnostiquer et qualifier les probl√®mes D√©clencher les actions correctives, √† son niveau directement, ou en alertant d‚Äôautres √©quipes, tout en priorisant les cas les plus critiques V√©rifier le bon fonctionnement des d√©veloppements envoy√©s en production Le p√©rim√®tre technique : Nos Enterprise Service Bus (ESB) : SAP PI/PO, Webmethods, IBM MQ √âchanges de donn√©es : (Rest, Idoc, API, FTP, SOAP, JMS, Proxy...) Monitoring : Solarwinds, splunk IT System Management JIRA Qui es-tu : Que tu sois ing√©nieur exp√©riment√©.e ou d√©butant.e, nous saurons te former et t'accompagner dans ta progression Tu es orient√©.e ‚ÄúClient‚Äù : anim√©.e par les besoins m√©tiers et la satisfaction utilisateur Tu communiques avec aisance au sein de ton √©quipe, mais aussi aupr√®s d‚Äô√©quipes tiers et tu sais d‚Äôadapter aux situations critiques / crises. Tu as une forte curiosit√© technique et envie d‚Äôapprendre pour travailler sur des sujets vari√©s et analyser les probl√®mes afin de proposer des solutions √† tes utilisateurs CE QUE NOUS OFFRONS 2 jours de t√©l√©travail par semaine Libert√© de choix de l'outil de travail (Mac, Windows, Chromebooks) √âquipe projet en local et partage avec le r√©seau mondial (parcours international) Mont√©e en comp√©tences et mentorat (diversit√© de projets, langages et technologies, certification, events) Formations internes et externes Actionnariat salari√© Primes mensuelles et trimestrielles LE CONTEXTE DECATHLON Et si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon. ‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde. Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires. Decathlon Technology, c‚Äôest aujourd‚Äôhui plus de 2500 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille et Londres. Decathlon est engag√© dans l'inclusion et la non-discrimination , et agit ainsi quotidiennement en faveur du handicap, des s√©niors, de la mixit√© sociale, de l'√©galit√© entre les femmes et les hommes. Nous recrutons avant tout des personnalit√©s et la diversit√© au sein de nos √©quipes est un enjeu majeur car elle est source d‚Äôinnovation et de performance. Si tu souhaites en savoir plus sur nos engagements, tu peux consulter ce lien .","Decathlon seeks an experienced or beginner Engineer Support to join the Data In Motion team responsible for messaging technology. The candidate will offer support, diagnose, and qualify problems, while being proactive in anticipating and addressing incidents. The engineer will also ensure the correct functioning of developments, including monitoring the performance of the system. The position is based in Lille, with the perk of working two days a week from home. Decathlon is an equal opportunity employer committed to diversity and inclusion.",Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
431,49637,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-dataops-h-f-innovative-tech_niort_DIT_xoPAMLM,Data Engineer - DataOps  - Innovative Tech,Devoteam Innovative Tech,"{scala,java,python,Databricks,k8s,Cloudera,linux,Docker,via,Kafka,Neo4J,Spark,Cassandra,Azure,Hadoop,Elastic}",NaN,"493 Avenue de Paris, Niort, 79000","IT / Digital, Strat√©gie, SaaS / Cloud Services",CDI,2023-02-07,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs strat√©gies de modernisation de plateformes. Face √† l‚Äôav√®nement du Cloud et des nouvelles m√©thodes de travail qui en d√©coulent, les DSI doivent aujourd‚Äôhui r√©pondre √† plusieurs enjeux majeurs pour √™tre agiles, porteuses d‚Äôinnovation, per√ßues comme un v√©ritable ‚Äúbusiness partner‚Äù tout en ayant une gestion responsable de la consommation √©nerg√©tique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant √† adopter une posture cr√©ative et apprenante. Franck et ses √©quipes niortaises n'attendent que vous pour relever de nouveaux d√©fis. Ensemble vous accompagnerez nos clients dans la transformation de leur projet vers la mise en ≈ìuvre et le d√©ploiement de solutions data. Ce qu'on attend de vous ? Vous disposez d'au moins trois ann√©es d'exp√©rience sur des sujets similaire en d√©veloppement Hadoop/Spark et Ansible. Vous aimez travailler en mode Agile Vous avez cette double comp√©tence Dev & Infra Vous exposez la donn√©e via des API, vous automatisez le provisionning/monitoring des environnements Data Ce qu'on vous apportera ? Un manager √† vos c√¥t√©s en toute circonstance Une communaut√© Data France o√π vous trouverez votre place : Ideation Lab, Hackathon, Meetup ... Un parcours de formation et de certification via ‚ÄúmyDevoteam Academy‚Äù sur les technologies du moment et √† venir : Azure Data, Databricks, Spark, Elastic.io, Neo4J, Kafka, Cloudera, Cassandra, Ansible, Docker, k8s ‚Ä¶ La possibilit√© de vous i nvestir personnellement : √™tre formateur interne, leader de communaut√©, participer aux entretiens candidats, aider √† d√©velopper nos offres et pourquoi pas manager ta propre √©quipe ... Expert dans le domaine de la Data : 3 √† 5 ans d‚Äôexp√©rience post dipl√¥me Ecole d‚Äôing√©nieurs ou Master 2 en informatique Des certifications seront un plus sp√©cialement sur Spark, Azure, Databricks Une double comp√©tence d√©v (java, scala, python) infra (linux, ansible, k8s) Une bonne connaissance des API Rest et microservices Un excellent relationnel, vous aimez travailler en √©quipe and you are fluent in english , indeed ! Alors n'h√©sitez pas √† r√©pondre √† l'annonce de @Margaux et rejoignez la communaut√© Devoteam ! Le saviez-vous? Le Groupe Devoteam ≈ìuvre pour l'√©galit√© des chances, pour la promotion au m√©rite de ses collaboratrices et de ses collaborateurs et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.","Devoteam Innovative Tech is seeking an experienced Data Expert with a strong background in Hadoop/Spark development, Ansible, DevOps, and API exposure for a transformational role in Niort. The ideal candidate must have experience working in Agile environments, a double skillset in both development and infrastructure, a good understanding of REST APIs and microservices, and excellent communication skills. This role offers opportunities to work with cutting-edge technology, continuous learning through training and certification, personal development, and be part of Devoteam‚Äôs growing data community. The company also promotes equal opportunity, inclusivity, and diversity in the workplace, and all positions are open to people with disabilities.",N,N,N,0,1,0.013848874720779208
430,48019,https://www.welcometothejungle.com/fr/companies/devoteam-innovative-tech/jobs/data-engineer-h-f-innovative-tech_lille_DIT_Aw2zX8D,Data Engineer  - Innovative Tech,Devoteam Innovative Tech,"{DataStudio,Looker,Keras,TensorFlow,AWS,QlikView,GCP,Tableau}",NaN,"8 Rue Anatole France, Lille, 59800","IT / Digital, Strat√©gie, SaaS / Cloud Services",CDI,2023-02-05,"Hyper technologique et multidisciplinaire, Devoteam Innovative Tech accompagne les DSI dans leurs strat√©gies de modernisation de plateformes. Face √† l‚Äôav√®nement du Cloud et des nouvelles m√©thodes de travail qui en d√©coulent, les DSI doivent aujourd‚Äôhui r√©pondre √† plusieurs enjeux majeurs pour √™tre agiles, porteuses d‚Äôinnovation, per√ßues comme un v√©ritable ‚Äúbusiness partner‚Äù tout en ayant une gestion responsable de la consommation √©nerg√©tique de leurs nouveaux services. Devoteam Innovative Tech assure la transformation des savoir-faire technologiques de ses clients en les aidant √† adopter une posture cr√©ative et apprenante. L'√©quipe lilloise n‚Äôattendent que toi pour relever de nouveaux d√©fis. Ensemble nous accompagnerons nos clients dans la transformation de leur projet. Tes missions si tu l‚Äôacceptes : Accompagner les grands comptes dans leur projet de mise en place de projets Data avec GCP, AWS ou tout autre syst√®me Big data. Analyser les besoins clients : Animer des ateliers Pr√©coniser des architectures cibles R√©diger des dossiers d'architecture et sp√©cifications techniques D√©finir les m√©thodologies de d√©ploiement et plans de migration Construire les architectures de donn√©es : Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s Construire et d√©ployer les pipelines de donn√©es (ETL) Assurer la migration des donn√©es vers les nouveaux environnements Analyser les donn√©es : Analyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio‚Ä¶) S√©lectionner, entra√Æner, √©valuer et d√©ployer des mod√®les pr√©dictifs en s‚Äôappuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn) Accompagner et former Assurer une veille technologique continue sur les solutions cloud Accompagner et former les √©quipes clients aux m√©thodes et concepts du cloud Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieurs ou d‚Äôun Master 2 en informatique , tu souhaites t'investir dans une √©quipe dynamique, passionn√©e et aux valeurs humaines. And You are fluent in english ! Tu es d√©sireux (se) de t'investir dans des projets challengeants et gagner rapidement en responsabilit√©s. Rejoigne la tribu ! Tu veux en savoir plus? Viens √©changer directement avec nos ambassadeurs . Le Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme dediscrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation.","Devoteam Innovative Tech seeks a data architect to work with big data systems such as GCP and AWS while accompanying clients in their data-related transformations. The ideal candidate has experience in data analysis and integration, building secure data pipelines, providing methodologies for deployment, and is familiar with BI and visualization applications. The candidate must also be fluent in English, hold a Master's degree in computer science or engineering, and have a passion for working in a dynamic and innovative team. The company is committed to equality and fighting against discrimination.",N,N,N,0,1,0.013848874720779208
125,73151,https://www.welcometothejungle.com/fr/companies/armee-de-l-air-et-de-l-espace/jobs/responsable-data-engineer_bordeaux_ADLEDL_kAXRjpz,Responsable Data engineer,arm√©e de l'Air et de l'Espace,{},NaN,"Bordeaux, 33000, Gironde, Nouvelle-Aquitaine, France",Administration publique,CDD / Temporaire,2023-04-22,"Cr√©√©e en 1934, l‚ÄôArm√©e de l‚ÄôAir est devenue l‚Äôarm√©e de l‚ÄôAir et de l‚ÄôEspace üõ©üõ∞ le 11 septembre 2020. üßë‚Äç‚úàÔ∏è 365 jours par an, 7 jours/7, 24 heures/24, les femmes et les hommes de l‚Äôarm√©e la plus f√©minis√©e (24%) assurent avec d√©termination la protection des fran√ßais. ‚û° Pilotes, m√©caniciens, contr√¥leurs a√©riens, fusiliers commandos, pompiers, sp√©cialistes de l‚Äôinfrastructure, informaticiens, sauveteurs: ils participent tous au succ√®s des op√©rations a√©riennes. Vous √™tes charg√©(e) : - De piloter et r√©aliser des extractions de donn√©es issues des Syst√®mes d‚ÄôInformation (SI) du MCO-A De piloter et superviser les activit√©s de Reprise de Donn√©es (RdD) produites par l‚Äô√©quipe Datafactory De piloter l‚Äôanalyse et la mise en coh√©rence des donn√©es De travailler en partenariat avec les √©quipes ‚Äúcatalogue‚Äù et ‚Äúqualit√© des donn√©es‚Äù De s‚Äôassurer, en relation avec les industriels, de l‚Äôad√©quation de la fourniture des donn√©es Donn√©es non contractuelles. ¬∑ P√©riode de formation initiale ~ 1.328 ‚Ç¨ net ¬∑ Aspirant ~ 1.408 ‚Ç¨ net (√† l‚Äôissue de la formation militaire initiale) ¬∑ Sous-lieutenant ~ 1.810 ‚Ç¨ net (√† partir de 6 mois d‚Äôaspirant) ¬∑ Lieutenant ~ 1.958 ‚Ç¨ net (apr√®s 1 an de sous-lieutenant) \ √Ä titre indicatif, hors primes et indemnit√©s ; solde pour un c√©libataire sans enfant log√© sur base.* L‚Äôacc√®s √† chaque grade est soumis √† la parution d‚Äôun d√©cret de nomination. Vous justifiez d‚Äôun bac** +3 ou √©quivalent dans le domaine Data** Vous avez la nationalit√© fran√ßaise Vous avez moins de 30 ans √† la date de signature du contrat",,Bac +3,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
40,73087,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/an-apprentice-12-24-months-data-engineering-m-f_paris_SANOF_GRXgZ3X,An apprentice - 12/24 months ‚Äì Data Engineering,Sanofi,"{Python,Scala,JavaScript,NoSQL,SQL}",NaN,"54 Rue la Bo√©tie, Paris, 75008",Pharmaceutique / Biotechnologique,CDI,2023-04-22,"At Sanofi, we pursue the miracles of science to improve people‚Äôs lives. In France, more than 20,000 passionate men and women tirelessly push their limits to transform the practice of medicine and improve patient health with drugs and vaccines. The desire to advance science is our strength . We want to improve the health of populations and find new solutions for patients by combining scientific progress and advanced technologies. In France, we provide more than 400 drugs, vaccines and health products, including 18 vaccines and more than 200 drugs of major therapeutic interest. Sanofi‚Äôs roots are anchored in France where most of the Research and Development is located. In the French medical research landscape, we hold a central role and actively participate in the construction of a dynamic health sector. To contribute to the world of tomorrow, three commitments guide our actions: access to care for the most vulnerable, inclusion of all through work and preservation of the planet. Nothing would be possible without the remarkable mobilization of our employees and partners. Sanofi is dedicated to supporting people through their health challenges. We are a global biopharmaceutical company focused on human health. We prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. We stand by the few who suffer from rare diseases and the millions with long-term chronic conditions. With more than 100,000 people in 100 countries, Sanofi is transforming scientific innovation into healthcare solutions around the globe. Sanofi, Empowering Life In this context, Sanofi is looking for: AN APPRENTICE ‚Äì DATA ENGINEERING (M/F) Location: Paris (XVIIe) Assignment : Within the Digital Health Department and in connection with your tutor, you will participate in an international project on a high-impact drug. In this context, your missions will consist in: Support connected ecosystem solutions such as patients‚Äô glycemic control and full disease management, leveraging connected pens, Help building symptom checking apps able to understand diseases and track symptoms, Participate in creating remote treatment solutions to provide individual recommendations, accessible by anyone, anytime, anywhere, Support personalized care models, informed by Artificial Intelligence, to identify symptoms‚Äô early signals and recommend corrective actions to the patient and the care giver. Required profile : You are looking for an apprenticeship contract of 12/24 months , starting between September and October 2023 as part of a training of level BAC +4/+5 or equivalent in Computer Science, Engineering with math background. For this position, you justify a first experience or knowledge of programing languages such as Python, Scala and different database systems such as SQL, NoSQL. Knowledge in JavaScript is a plus. Self-starting and self-motivating team player, your rigor and your analytical mind allow you to carry out your missions. Open-minded, you enjoy working in a team and interacting on transversal topics. If you are interested in our mission, send us a CV and cover letter. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all. As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.",,Bac +4,N,Non sp√©cifi√©,0,1,0.013848874720779208
251,2447,https://www.welcometothejungle.com/fr/companies/dataiku/jobs/software-engineer-data-presentation-paris_paris,Software engineer Data Presentation - Paris,Dataiku,"{go,Dataiku,Javascript,Java,regard,Kubernetes,grid,PowerBI,Spark,D3,SQL,Python,Tableau}",NaN,Paris,"Artificial Intelligence / Machine Learning, Big Data, Software",CDI,2021-12-27,"Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 800 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and Serena, we‚Äôve set out to build the future of AI. Let‚Äôs do it together! Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 900 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI. Data visualization is often the most striking (and for some, the most accessible) part of the data-to-insights process. Let‚Äôs face it ‚Äî there‚Äôs nothing more exciting than a beautiful fit-for-purpose data viz. We are looking for a talented software engineer to create usable, intuitive, beautiful interfaces and their scalable engines for Dataiku DSS. Dataiku DSS brings together big data and AI technologies into a unique and easy-to-use platform. It allows data scientists to process data with SQL databases, Spark, and Kubernetes with either user-friendly interfaces or code. The same platform also allows business analysts to create powerful machine or deep learning models with just a few clicks. What we do We design and code experiences that resonate with our growing customer base. We empower non-technical users with user-friendly and well-thought tools to let them quickly and efficiently visualize, analyze, or process their data. Our current technical stack is based on Javascript, AngularJS, Angular, and D3.js on the frontend (we only support the latest versions of Chrome and Firefox!). We develop using Java, Spring, and Python on the backend. What you will do With your top-tier teammates from the engineering team and the help of the UX team, you will: - Build the components that allow Dataiku DSS users to create and display charts, dashboards, and ad- hoc web applications in a scalable way (both frontend and backend). - Prototype and create new ways to interact with data or integrations with other products such as Tableau, PowerBI, Salesforce, Slack, etc. - Work closely with product managers and UX designers to brainstorm on new features and iteratively refine solutions. - Shape a safe place to work where all ideas and suggestions are welcome and taken into account, and where we all know everyone does their best. - Write high-quality code, as your teammates do! You are the ideal recruit if: You have experience in software development and you are interested in data visualization tools. You are customer-oriented ‚Äî you want to understand customer needs and how the product is used. You are at ease with both frontend and backend development, or you‚Äôve mastered frontend development but are not afraid to dive into backend code to better understand how it works. You know that a chart is worth a thousand grid cells. You have firsthand experience (either professional or personal) building a real product. You blink each time you see a misaligned pixel! You are humble and kind. You don't hesitate to ask questions when you don't know, and you treat your colleagues with respect, kindness, and honesty. Hiring process: Initial call with the talent acquisition manager On-site meeting (or video call) with a software developer or a team lead Home test to show your skills Final interviews with an engineering manager and a VP of engineering An informal interview with a Dataiker to understand our culture Dataiku‚Äôs culture is right for you if You want to be able to define your own version of work-life balance - flexible is our go-to word, it applies equally to remote work, vacations and parental benefits You need autonomy to thrive - we trust our people, give them space to do their best and stay away from artificial deadlines You enjoy spending time with your colleagues and learning from your peers - meet for Friday universities, annual offsites, virtual trivia nights and more You like feeling cared about - watch out for the magical Christmas box delivered at home and an unforgettable onboarding week You care about giving back - it‚Äôs what our Ikig.AI program is all about: Dataikers are encouraged to work pro bono for one or several nonprofits of their choosing If you want to learn more about our hiring process, you can read this article about our engineering hiring philosophy . About Dataiku: Dataiku is the platform for Everyday AI, systemizing the use of data for exceptional business results. By making the use of data and AI an everyday behavior, Dataiku unlocks the creativity within individual employees to power collective success at companies of all sizes and across all industries. Don‚Äôt get us wrong: we are a tech company building software. Our culture is even pretty geeky! But our driving force is and will always remain people, starting with ours. We consider our employees to be our most precious asset, and we are committed to ensuring that each of them gets the most rewarding, enjoyable, and memorable work experience with us. Fly over to Instagram to learn more about our #dataikulife. Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. This content is blocked Youtube cookies are required to show you this content Accept cookies","Dataiku, a platform for Everyday AI, is seeking a talented software engineer to create usable, intuitive and visually appealing user interfaces and their scalable engines for Dataiku DSS. The ideal candidate should be comfortable with both front-end and back-end development, understand customer needs and have experience building a real product. Dataiku's platform combines big data and AI technologies to empower data scientists and business analysts, and the company has more than 900 employees across the globe, with offices and remote workers.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
44,61889,https://www.welcometothejungle.com/fr/companies/betclic/jobs/data-engineering-manager-h-f_bordeaux,Data Engineering Manager,Betclic Group,"{durable,TABLEAU,Talend,SNOWFLAKE,DBT,Uber,Snowflake,Azure,AtScale,SQL,Tableau}",NaN,"117 Quai de Bacalan, Bordeaux, 33300",Application mobile,Autres,2023-03-30,"Entreprise fran√ßaise leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c‚Äôest : üßë‚Äçü§ù‚Äçüßë 11 millions de joueurs vibrants au rythme des comp√©titions sportives ‚≠êÔ∏è Une offre tr√®s large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne ‚öΩÔ∏è Plus de 50 sports ouverts aux paris üìÖ 300 000 √©v√®nements sportifs disponibles aux paris chaque ann√©e üñ• 60 000 √©v√®nements sportifs diffus√©s en live chaque mois üé∞ Plus de 3 000 jeux de casino √† exp√©rimenter üÉè Plus de 2 millions de parties de poker jou√©es chaque mois üöÄ De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l‚ÄôUBB, les Boxers de Bordeaux‚Ä¶ Depuis sa cr√©ation en 2005, Betclic est une soci√©t√© de technologie ‚Äúmobile-only‚Äù, anim√©e par une passion in√©branlable pour le sport. Guid√© par l‚Äô√©motion et le plaisir du jeu, Betclic d√©veloppe des applications de divertissement mobile et place ses clients au c≈ìur d‚Äôune exp√©rience de jeu unique en innovant avec agilit√© et rapidit√© pour offrir toujours plus de jeux et plus de fun √† ses joueurs. Notre ambition ? Proposer √† nos clients l‚Äôexp√©rience de jeu la plus divertissante gr√¢ce √† des applications simples, immersives et innovantes. Betclic, dont le si√®ge est √† Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalit√©s parmi ses 800 collaborateurs r√©partis dans 5 pays d‚ÄôEurope : France, Italie, Malte, Pologne, et Portugal. WE ARE BETCLIC Entreprise fran√ßaise leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c'est :‚Ä¢ ‚Äç‚Äç 11 millions de joueurs vibrants au rythme des comp√©titions sportives ‚Ä¢ ‚≠ê Une offre tr√®s large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne‚Ä¢ ‚öΩ Plus de 50 sports ouverts aux paris ‚Ä¢ 300 000 √©v√®nements sportifs disponibles aux paris chaque ann√©e ‚Ä¢ 60 000 √©v√®nements sportifs diffus√©s en live chaque mois ‚Ä¢ Plus de 3 000 jeux de casino √† exp√©rimenter‚Ä¢ Plus de 2 millions de parties de poker jou√©es chaque mois‚Ä¢ De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l'UBB, les Boxers de Bordeaux‚Ä¶Depuis sa cr√©ation en 2005, Betclic est une soci√©t√© de technologie ""mobile-only"", anim√©e par une passion in√©branlable pour le sport. Guid√© par l'√©motion et le plaisir du jeu, Betclic d√©veloppe des applications de divertissement mobile et place ses clients au c≈ìur d'une exp√©rience de jeu unique en innovant avec agilit√© et rapidit√© pour offrir toujours plus de jeux et plus de fun √† ses joueurs. Notre ambition ? Proposer √† nos clients l'exp√©rience de jeu la plus divertissante gr√¢ce √† des applications simples, immersives et innovantes.Betclic, dont le si√®ge est √† Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalit√©s parmi ses 800 collaborateurs r√©partis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal. Les profils recherch√©s sont ceux qui ont l'ambition de construire en √©quipe, qui sont pr√™ts √† relever des challenges tous plus passionnants les uns que les autres, et qui ont cette volont√© de cr√©er des solutions offrant une exp√©rience client in√©dite. L'univers du sport et du jeu vous fait vibrer ? Vous aimez les d√©fis et participer √† l'effort collectif ? Betclic vous propose de rejoindre l'aventure !#JoinBetclic #WeAreBetclic Chez Betclic, la transformation DATA est toujours en marche et s'acc√©l√®re. Nos Apps sont √† la pointe de ce qui se fait dans notre industrie digitale et √©voluent sans cesse. La bonne gestion de la DATA devient un des principaux leviers d'acc√©l√©ration de nos activit√©s. Au sein de l'√©quipe DATA FABRIC vous serez au c≈ìur de l'activit√© : offre, jeux, protection du joueur, s√©curit√©, performance des plateformes, r√©gulation, marketing, analytics, excellence op√©rationnelle, etc‚Ä¶ Avec la DATA, Betclic casse les codes. Fini le monolithe traditionnel. Place aux DATA PRODUCTS, √† la donn√©e et √† une organisation distribu√©es au plus pr√®s des √©quipes Produit et des √©quipes M√©tier. ENTER THE GAME Envie de participer √† la transformation DATA de Betclic ? Envie de concevoir des outils de pilotage pour aider les √©quipes Business √† devenir DATA-DRIVEN ? En tant qu'expert en Data (Engineering et Business Intelligence), vous aimez partager votre savoir, votre exp√©rience et votre vision. Vous souhaitez d√©velopper votre leadership, dans ce contexte nous recherchons notre futur Data Engineering Manager, qui prendra en charge une √©quipe de 3-4 Data/BI Engineers. Grace √† votre expertise vous pourrez continuer √† contribuer au design et au delivery et ainsi d√©velopper vos comp√©tences TECH. Votre √©quipe est int√©gr√©e dans une organisation en Data Squad (Data Mesh) au service d'un domaine M√©tier. Ces Data Squads regroupent, en plus de l'expertise en ing√©nierie dont vous aurez la responsabilit√©, des analystes, des scientistes, des MLOps. Les √©quipes Tech Betclic sont organis√©es autour des principes de d√©veloppement agiles et s'organisent en squad et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique. Gr√¢ce √† cette organisation chaque Squad a la responsabilit√© de A √† Z de ses projets : d√©veloppement, livraison, suivi de production. You build it, you run it, you own it ! Votre quotidien sera de travailler avec un large √©ventail de technologies innovantes telles que Snowflake, Stacks Amazon et Azure, Tableau, Talend, DBT Cloud, AtScale, en particulier. Et par cons√©quent d'assurer le maintien des comp√©tences de votre √©quipe. Vous participerez au d√©veloppement de l'√©cosyst√®me DATA de Betclic permettant √† la compagnie d'avoir toujours une meilleure vision de son activit√© et un r√©el avantage concurrentiel. Vous contribuerez au virage pris par Betclic qui vise √† d√©cupler la cr√©ation de DATA PRODUCTS √† forte valeur ajout√©e et ainsi accompagner le d√©veloppement de l'offre et du produit Betclic. YOUR ROLE WITHIN BETCLIC Dans ce contexte; vos missions sont les suivantes: Manager une √©quipe de 3-4 Ing√©nieurs BI/Data Collaborer avec l'√©quipe d'ing√©nieurs BI/Data pour aider √† la conception, au delivery (mod√©lisation, flux DATA. processus d'automatisation, ‚Ä¶) Concevoir, impl√©menter et g√©rer les nombreux KPI de l'entreprise Offrir des conseils strat√©giques aux diff√©rentes √©quipes de Betclic sur l'optimisation des r√©sultats et de leur donn√©es Superviser les processus de Version Control et de QA pour garantir l'exactitude et la qualit√© des donn√©es du delivery de votre √©quipe Garantir un haut niveau de qualit√© de service (QOS/SLA) des DATA PRODUCTS dont votre √©quipe a la charge Concevoir et mettre en ≈ìuvre de nouveaux tableaux de bord intuitifs et innovants (sur desktop et mobile) Surveiller et r√©soudre les probl√®mes op√©rationnels ou de donn√©es (Incident Management, Problem Management) Garantir la disponibilit√© et la fiabilit√© des donn√©es dans les d√©lais pr√©vus Participer aux astreintes li√©es √† nos activit√©s/livrables strat√©giques WHO WE ARE LOOKING FOR? Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, un amour pour la technique, un peu de z√®le et une r√©elle passion pour leur m√©tier ! Ce job est fait pour vous si: Vous avez une exp√©rience r√©ussie de 4 ans minimum en tant qu'ing√©nieur BI/Data Votre leadership vous a d√©j√† permis de vous exprimer, de vous positionner comme un manager, un d√©cideur. Vous aimez √©changer, n√©gocier, convaincre autour de vous. Vous avez un sens de l'√©coute exacerb√©. Vous aimez rendre service et relever les challenges. Vous pouvez justifier d'un grande aisance et autonomie dans la conduite des sujets que vous prenez en charge. Vous avez un gout prononc√© pour les √©changes et la collaboration intra/inter-√©quipes. Vous savez communiquer en Anglais Vous maitrisez l'utilisation de plusieurs bases de donn√©es (en particulier SNOWFLAKE) et de technologie d'int√©gration de donn√©es (ELT/ETL) Vous maitrisez SQL et √™tes exp√©riment√© dans l'utilisation de bases de donn√©es relationnelles, dans la cr√©ation de requ√™tes optimis√©es Vous avez l'habitude d'utiliser des outils de Dataviz tel que TABLEAU Vous vous int√©ressez aux architectures et univers cloud Une affinit√© avec l'univers du pari sportif et du sport en g√©n√©ral est un plus WHAT CAN YOU EXPECT? Un package de r√©mun√©ration attractif25 jours de cong√©s pay√©s et 10 jours de repos compensateursUne carte Ticket Restaurant¬Æ financ√©e √† hauteur de 50% (10‚Ç¨/ jour)Une mutuelle d'entreprise prise en charge √† 100% pour vous et vos enfants Un abonnement de transport pris en charge √† hauteur de 50% ou une prime annuelle de mobilit√© durable (200‚Ç¨ pour les trajets domicile ‚Äì travail en transport durable)Un pack mobilit√© (aide au d√©m√©nagement) Une flexibilit√© de travail encadr√©e par un accord sur le t√©l√©travailUn souci constant de d√©veloppement des comp√©tences avec un programme de formation annuel personnalis√©Des √©volutions de carri√®re dans un environnement internationalDes locaux hors du commun avec un rooftop am√©nag√© pour profiter d'animations r√©guli√®res, de pauses et de d√©jeuners au soleil face √† la Cit√© du VinDes cours de sports 2 fois par semaineEt l'opportunit√© de travailler dans une atmosph√®re conviviale, jeune et fun !Poste en CDI √† pourvoir d√®s que possible √† BordeauxBetclic Group - 117 quai de Bacalan 33300 BORDEAUX Tous nos postes sont ouverts aux personnes en situation de handicap.","Betclic, a French leader in sports betting and online gaming, is seeking a Data Engineering Manager to join their Data Fabric team. The ideal candidate will have at least 4 years of experience as a BI/data engineer and possess strong leadership skills. Responsibilities include managing a team of 3-4 BI/data engineers, collaborating with teams to design and deliver KPIs, offering strategic advice, and ensuring data quality and availability. Betclic offers a competitive compensation package, flexible work arrangements, and a fun, international work environment.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
344,56529,https://www.welcometothejungle.com/fr/companies/aircall/jobs/senior-data-analytics-engineer_madrid,Data Visualization Engineer,Aircall,"{Kinesis,Flink,GitLab,Redshift,Airflow,Looker,Lambda,AWS,Spark,SQL}",NaN,"Madrid, 28014","SaaS / Cloud Services, Electronique / T√©l√©communications",CDI,2023-03-26,"Aircall is on a mission to revolutionize the business phone industry! We exist to empower every professional to have richer conversations. We provide an entirely cloud-based voice solution, which seamlessly integrates with popular productivity and helpdesk tools. We have raised more than $220 million since 2015, and our base of 8000+ customers (and growing) is at our forefront. Behind our product are the amazing teams driving it, split between Paris, New York, Sydney, Madrid, London, Berlin and remote locations. Despite our distance, we all work together to drive our product! Aircall is a place where voices are valued. Backed by over $220 million of investment since 2015, we create technology that fuels accessible, transparent and collaborative communication to empower our base of 14,000+ customers (and growing) to make authentic, human connections. Conversation is a cornerstone of our culture. Wherever our people find themselves in the Aircall world ‚Äì Paris, New York, Sydney, Madrid, London, Berlin, Tel Aviv, or at home ‚Äì everyone has a voice that is valued. Whatever your background, wherever you‚Äôre from ‚Äì we want you to join the conversation. Let‚Äôs talk. We are looking for an engaged and passionate Data & Analytics Senior Engineer to join our growing Engineering Team. **This position can be fully remote within Europe** Your role at Aircall: - Design & build great analytics solutions for our 10000+ customers across the world - Design & maintain easy to use data models, ensuring their quality - Design & develop reliable data pipelines and be accountable for them - Maintain data model documentations & definitions available to all in our Data Catalog, allowing easy understanding of our data warehouse - Influence product and cross-functional teams to identify data opportunities to drive impact. - Mentor team members through giving and receiving actionable feedback. Our stack: - AWS (Lambda, SQS, Kinesis, Redshift), Airflow, Flink, Spark, Looker, - A continuous deployment process based on GitLab A little more about you: - A Bachelor's degree in a technical field (eg. computer science or mathematics). - 3+ years experience in the data warehouse space, ETL design, implementation and maintenance - Proven experience with schema design and dimensional data modeling - Proficient in SQL and working with Looker/LookML (or equivalent technologies) - Shipping and maintaining code in production. - You like sharing your ideas, and you're open-minded. We love to take care of our people and offer the following benefits: üíª Full remote üè• Medical insurance for you and your family üçî 9‚Ç¨/day meal allowance üí™ 45‚Ç¨/month for Gym expenses üèñÔ∏è 25 days off üë∂ 150‚Ç¨/month allowance per child < 10 years of age üìà Stock options to be part of Aircall's success. Aircall is constantly moving forward. We‚Äôre building new roads to complete our journey, and we‚Äôre taking people with us who have the same builder mentality. Let‚Äôs grow together: Aircall is a place for those who dare to be bold and seek responsibility, excellence, and the opportunity to push themselves to new heights. We‚Äôre creating a place where great people trust one another and thrive together. People flourish at Aircall and now is the time to be part of the team and the journey we‚Äôre on. Why join us? üöÄ Key moment to join Aircall in terms of growth and opportunities üíÜ‚Äç‚ôÄÔ∏è Our people matter, work-life balance is important at Aircall üìö Fast-learning environment, entrepreneurial and strong team spirit üåç 45+ Nationalities: cosmopolite & multi-cultural mindset üí∂ Competitive salary package & benefits DE&I Statement: At Aircall, we believe diversity, equity and inclusion ‚Äì irrespective of origins, identity, background and orientations ‚Äì are core to our journey. We pride ourselves on promoting active inclusion within our business to foster a strong sense of belonging for all. We‚Äôre working to create a place filled with diverse people who can enrich and learn from one another. We‚Äôre committed to ensuring that everyone not only has a seat at the table but is valued and respected at it by providing equal opportunities to develop and thrive. We will constantly challenge ourselves to make sure that we live up to our ambitions around diversity, equity and inclusion, and keep this conversation open. Above all else, we understand and acknowledge that we have work to do and much to learn. Want to know more about candidate privacy? Find our Candidate Privacy Notice here.","Aircall is seeking a Data & Analytics Senior Engineer to design, build and develop analytics solutions for the company's growing customer base, providing data expertise and insight to drive impactful decision making. The successful candidate should have experience in data warehousing, ETL design, and a strong proficiency in SQL and Looker/LookML, as well as a technical Bachelor's degree. Aircall offers full remote working and competitive benefits, including medical insurance, a 25-day annual leave allowance, and gym and meal allowances. The company is committed to promoting diversity, equity, and inclusion in its workforce, creating a strong sense of belonging for all.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
117,73309,https://www.welcometothejungle.com/fr/companies/back-market/jobs/data-engineering-manager-customer-squad-copy_berlin,Data Engineering Manager - Customer squad,Back Market,"{Python,Scala,Datadog,Lambda,via,Spark,color,AWS,dynamodb,GCP}",NaN,"Berlin, 10117","Environnement / D√©veloppement durable, √âconomie collaborative, E-commerce",CDI,2023-04-22,"BackMarket is the number one European (and soon global) marketplace specializing in the sale of fully refurbished tech devices. Back Market is the world‚Äôs leading refurbished electronics marketplace with a team of 700 people, powering operations in 17 countries (and counting!). Named one of the World's Most Innovative Companies by Fast Company in 2019 and again in 2021, our mission is simple: empowering people to consume tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact . We have indeed contributed to avoid the production of more than 1,000,000‚ÄØtons of CO2e worldwide since our launch in 2014. Be part of an exciting and growing international adventure that will change the way the world consumes tech. Are you a data-driven leader who is passionate about building reliable, high-performing, and secure data infrastructures and tools? Do you want to have a meaningful impact on a fast-growing company like Back Market? Here is an exciting opportunity for you! As the Engineering Manager of the Customer data team , you will have the unique opportunity to shape and develop the end-to-end scope of the team, which is composed among others of: - all data linked to the marketing . - all the data engineering needs for the top management (COMEX) all the data needs coming from the tribe in charge of customers in the Bureau of Technology - You will manage a well-balanced team of five data and analytics engineers, who are distributed across different offices and remote locations. What you'll be doing : Managers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. You are responsible of having a tech vision for your team, aligned with the objectives of the company, and execute it You build and execute a growth plan, via hiring but more importantly by ensuring the development of people and teams through open communication, feedback, and continuous coaching Ensure the team keeps a frugal and sustainable mindset (people, infra, solution, resources...). spending is fine, wasting is not. You work in an agile ""build it and run it"" environment where engineering teams build, launch, monitor and support the sections they own, incrementaly. You identify and make improvements in our processes, practices, and product You are in the right place if : You are people-first oriented and know how to build and run a high-performing team You embrace the servant leadership principles as much as you value empathy and cordial debates over a ""top-down"" management posture ; Production health is a priority for you ; You work well with non-tech partners, explain tech constraints and yet try to solve their problems, even by getting your hands dirty from time to time ; You are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. You have great communication skills in English Recruitment process : - Call with Yann, Tech recruiter - Management principles interview with your future manager - Data Engineering interview with your future peers - Stakeholders interview with your future colleagues - Back Market value interview WHY SHOULD YOU JOIN US ? - A meaningful job: you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! - A meaningful company : we became a mission-driven company in January 2022. - Be part of a worldwide growing company based in Europe, the USA and Asia to face great challenges : you will have the freedom to innovate and adopt new ideas! - Work alongside passionate experts: who will share their knowledge and help you develop and grow in your career. - Grow your career : with a flexible career path and a dedicated Learning & Development team. Back Market will help you evolve with personalized internal trainings and external handpicked providers from day 1! - Leadership Academy by Back Market: ‚Äúbe a coach not a dictator‚Äù is at the core of this program ! We train and enable all our leaders to support their team towards achieving goals. Be a manager at Back Market is an unique experience we take by heart. - An attractive salary, equity and a host of benefits including : Lunch voucher, health insurance, relocation package, paid time off for activism in your community, parental benefits, flexible hours, etc‚Ä¶ - One Loving Tribe: you will have the opportunity to work in a fast-paced, open-minded and friendly environment. - Be part of one of our Employee Resource Groups createdaround shared identities, common backgrounds and/or special interests crafted to be a safe space and an expressive outlet. - Several internal events: The Monday Brief (weekly)/ The Somehands (monthly)/ The All Hands (annual). - We‚Äôre here to SABOTAGE: It‚Äôs our mantra. It keeps us focused on what we aspire to be: a little bit sneaky, always smart, kinda frugal and constantly conspiring to create maximum impact. Back Market is an Equal Opportunity Employer which means we pledge to not discriminate against employees based on race, color, religion, sex, national origin, age, disability or genetic information.. If reasonable accommodations are needed for the interview process, please do not hesitate to discuss this with the Talent Acquisition Team. Back Market is helping to address one of the biggest challenges of our time: climate change. We take this so seriously that we were awarded status as a ‚ÄúSoci√©t√© √† Mission‚Äù, or company with a social mission, by the French government. We know we can‚Äôt tackle a global problem without a globally representative team so we are committed to embedding diversity, equity and inclusion principles in every aspect of our organization. But more importantly, being One Loving & Free Spirited Tribe is in our DNA as it is one of the five foundational values of our company since we got started way back in 2014. We are committed to hiring and supporting diverse teams of people from all backgrounds, experiences, and perspectives. We know our lofty goals cannot be reached unless everyone has a seat at the table along with the resources and opportunity to grow.",,Non sp√©cifi√©,Entre 250 et 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
349,11205,https://www.welcometothejungle.com/fr/companies/d2si/jobs/data-engineer_paris,Data Engineer,Devoteam Revolve,"{NoSQL,Jenkins,Scala,AWS,Docker,via,Spark,GCP,Java,SQL,Hadoop,Python}",NaN,Paris,"IT / Digital, SaaS / Cloud Services",CDI,2022-01-25,"Les √©quipes de Devoteam Revolve travaillent en partenariat avec les DSI, les entit√©s digitales et les m√©tiers pour les accompagner dans leur transformation num√©rique . Sp√©cialistes du Cloud et du DevOps , nos consultantes et consultants travaillent en co-cr√©ation avec nos client¬∑es, le Cloud √©tant le terrain de jeu propice √† cette transformation. Les collaborateurs et collaboratrices de Devoteam Revolve posent ainsi les bases de nouvelles m√©thodes de travail et de collaboration au travers notamment du mentoring et de l‚Äôapprentissage entre pairs. Passionn√©.e par le Big Data, vous √™tes convaincu.e que le cloud est l‚Äôenvironnement naturel des syst√®mes Big Data ? √áa tombe bien, nous aussi. Rejoignez la #teamD2SI ! Au sein de D2SI, nous √©voluons dans un contexte pur cloud, qui vous permettra de travailler sur des sujets de data engineering sur des plateformes cloud AWS ou/et GCP . Vous travaillerez sur des probl√©matiques m√©tiers de big data en collaboration avec les data scientists, les data analysts, les √©quipes BI et √©quipes infra‚Ä¶. En tant que Data Engineer vous devrez d√©velopper, construire et maintenir des pipelines de data. Votre r√¥le sera en quelques sortes de cr√©er un outillage sur mesure qui permettra d‚Äôextraire, transformer et injecter toutes sortes de donn√©es dans l‚Äôentreprise via un Datalake ou des BDD ! Pour mener √† bien votre mission, la ma√Ætrise de Python est un pr√©requis, celles de Spark, Scala ou Java sont fortement recommand√©es ainsi que les bonnes pratiques de d√©veloppement. Vous aimez √©galement √©voluer dans un √©cosyst√®me Hadoop et vous avez une connaissance g√©n√©rale des BDD SQL et NoSQL pour extraire la donn√©e. Enfin des connaissances d‚Äôoutils DevOps sont appr√©ci√©s tel que Docker, outils de CI/CD tel que Jenkins‚Ä¶ 1 - Entretien RH - parce que travailler ensemble veut dire se conna√Ætre, se comprendre, et s‚Äôaccorder 2 - Entretien Tech - parce que le meilleur moyen de se challenger, c‚Äôest de se rencontrer 3 - Entretien Final - parce que l‚Äôon-boarding de nos nouvelles recrues doit se faire de mani√®re qualitative Ce contenu est bloqu√© Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","Data Engineer with expertise in Python, Spark, Scala or Java, and strong knowledge of Big Data ecosystems like Hadoop and SQL and NoSQL databases, is required to join Devoteam Revolve's Cloud and DevOps specialized team, working on big data projects in collaboration with data scientists, data analysts, BI teams, and infrastructure teams. Candidates should also have knowledge of DevOps tools like Docker and CI/CD tools like Jenkins.",N,N,N,0,1,0.013848874720779208
47,67465,https://www.welcometothejungle.com/fr/companies/mars-france/jobs/site-ie-data-engineer-f-m-x_cambrai,Site IE Data Engineer X),MARS,"{color,via,regard}",NaN,"Cambrai, 59400","Grande distribution, Agroalimentaire / Nutrition animale, Distribution s√©lective, Grande consommation",CDI,2023-04-07,"M&M‚ÄôS¬Æ, Twix¬Æ, Royal Canin¬Æ, Ben‚Äôs Original¬Æ, Pedigree¬Æ Skittles¬Æ, Whiskas¬Æ - Mars abrite certaines des marques les plus connues au monde. Chaque jour, les 130 000 associ√©s de Mars dans le monde ont l‚Äôoccasion de travailler dans les secteurs de la confiserie, des repas familiaux, des produits pour animaux de compagnie, des services v√©t√©rinaires et bien plus encore. Mais ce qui distingue MARS, c‚Äôest son objectif. Mars est une entreprise familiale, et fi√®re de l‚Äô√™tre, depuis plus de 100 ans. C‚Äôest gr√¢ce √† cette ind√©pendance que MARS peut penser en termes de g√©n√©rations, et non de trimestres, afin d‚Äôinvestir dans l‚Äôavenir √† long terme de l‚Äôentreprise, de ses collaborateurs et de notre plan√®te tout en restant fid√®les aux m√™mes principes √©prouv√©s. Chez Mars, nous pensons en termes de g√©n√©rations, mais nous traitons chaque jour comme une opportunit√© d‚Äô≈ìuvrer pour le monde que nous voulons. Unis par notre ambition de faire la diff√©rence, nous travaillons avec d√©termination, int√©grit√© et vision - en combinant nos diverses comp√©tences pour fa√ßonner l‚Äôavenir de certaines des marques les plus appr√©ci√©es au monde. Alors, pr√©parez-vous √† saisir toutes les opportunit√©s, √† prendre des responsabilit√©s et √† avoir un r√©el impact. Job Description: Site IE Data Engineer (F/M/X) Royal Canin Location : Cambrai (1 hour from Lille) Contract : Permanent The Site IE data engineer will partner with the site teams; Production Manager, Technical Manager ‚Ä¶ to develop and execute the overall site F I activities through Mars Supply Excellence and supporting all pillar s in the day-to-day activities to improve site performance by improving data management. He/she will be responsible for all data reporting and 1st level analysis related to site performance KPI reporting and benchmarks and will be the 1 st contact for all data reporting system for improvement and new tool s implementation . The role is responsible for data integrity and adherence to the established ways of calculation , management (through tools ‚Ä¶ ) and reporting. What are we looking for? Process Management experience with analytic and priority setting capabilities Ability to solve problems and influence with a strong customer focus 3 to 5 years experience in Supply (Manufacturing) with a collaborative approach Experience in Lean and TPM with strong communication skills Fluent in French & English University degree in Ind. Engineering, Engineering or equivalent qualification What would be your key responsibilities? Proactive for associate Safety , QFS and SIG roadmap Daily, weekly, periodically and annual data reporting for line performance such as TRS/OEE by line and equipment including the different element that builds the TRS/OEE reports. As well as for lines speeds, flowrates, NQC elements such as (run setup, re-use, destruction). This will also applied to data required such as MTBF, MTBR, MTBS‚Ä¶ for selected lines within the site MSE deployment plan Responsible to prepare the data in such a way that could provide ability to drill down and identify root causes for downtimes working closely with the site teams Maintains and ensures the accuracy of the data within the designated tools/systems while supporting new tool implementation, setting up recommendation to improve. Support testing and implementation of new systems and enhancements such as automating KPI calculations and performance reporting and display Deliver tangible savings from continuous improvement projects / FI activities identified by the operation team and other supporting functions . independently elaborate and implement improvement proposals and where necessary, with various departments such as HSE, RI, Q&FS, PPTS, US team (DD team and TLs) all this in collaboration with the operators Active member of local & regional IE/MSE team, give functional support to the team when it ‚Äòs needed. What can you expect from Mars? At Mars, we believe in a relationship of mutual trust, dignity and respect between our company and Associates that is more meaningful than the standard employer/employee relationship. As Associates, we can expect to be respected, supported and valued as individuals, to be treated fairly and equitably. ‚Äã Royal Canin's CSR commitments, to build a better world for tomorrow: Since 2015, no waste to landfill is made by the 16 Royal Canin factories in the world ‚Äã All Royal Canin products manufactured in Europe are ISO 14001 certified from design to factory gate Since 2017, Royal Canin has supported the K-DOG program of the Curie Institute, which trains dogs to detect breast cancer via olfaction. #LI-NM1 #LI-Onsite Mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. The company is pleased to provide such assistance, and no applicant will be penalized as a result of such a request.",,Non sp√©cifi√©,> 2000 salari√©s,Non sp√©cifi√©,0,1,0.013848874720779208
235,11382,https://www.welcometothejungle.com/fr/companies/april-technologies/jobs/data-analyst-f-h-paris-5746_paris,DATA Engineer  - PARIS,APRIL,"{Oracle,SAS,Qlik,Talend,via,R,Java,NoSQL,SQL,Python,Tableau}",NaN,Paris,"Assurance, Big Data, Logiciels",CDI,2022-01-25,"April est num√©ro 1 du courtage d‚Äôassurance en France, anim√© par un esprit d‚Äôinnovation et de ‚Äúpionnier‚Äô depuis sa cr√©ation. Nous accompagnons plus de 14,000 interm√©diaires d‚Äôassurance. APRIL con√ßoit, distribue et g√®re des solutions sp√©cialis√©es d‚Äôassurance ainsi que des prestations d‚Äôassistance pour ses partenaires et clients particuliers, professionnels et entreprises. Notre mission est de rendre la souscription d‚Äôassurance des particuliers et professionnels la plus simple et rapide possible, pour les courtiers comme pour les assur√©s. Pour atteindre cet objectif nous construisons une plateforme digitale multicanale innovante et proposant une exp√©rience utilisateur de haut niveau, quel que soit le produit souscrit. L‚Äô√©quipe en charge du d√©veloppement business et technologique de cette plateforme et son expansion est en pleine croissance. Tr√®s orient√©e tech, digital et UX, nous sommes anim√©s par la volont√© de faire de notre infrastructure Front une r√©f√©rence afin de rendre la plus scalable et performante possible. Notre challenge actuel ? R√©pondre aux attentes d‚Äôinnovation de notre base d‚Äôutilisateurs (la plus grande de France) tout en maintenant un haut niveau de qualit√© technique et d‚Äôexp√©rience. Pour atteindre cette ambition, nous souhaitons nous appuyer sur une plateforme tech de haut niveau. Pourquoi travailler avec nous ? Vous b√©n√©ficierez des moyens et r√©seaux d‚Äôun groupe d‚Äôenvergure tout en √©voluant dans un environnement hyper dynamique. Tr√®s responsabilis√©, vous pourrez √™tre impliqu√© dans la conception technique de la plateforme et aurez la possibilit√© de faire monter en comp√©tence votre √©quipe. Vous d√©velopperez une expertise tr√®s rapidement et la mettrez en ≈ìuvre dans une √©quipe multidisciplinaire. Venez travailler et exploiter les diff√©rentes sources de donn√©es afin de r√©aliser, pr√©senter et communiquer des analyses m√©tiers avanc√©es. Votre objectif : √©clairer et objectiver les prises de d√©cisions des diff√©rentes parties prenantes de l'entreprise. Et si √™tre ¬´ DATA Analyst ¬ª chez APRIL vous permettait ‚Ä¶ de choisir un m√©tier dont vous pourrez √™tre fier : ¬´accompagner et prot√©ger √† chaque moment qui compte, simplement¬ª telle est la mission et la raison d‚Äô√™tre partag√©e par l‚Äôensemble de nos collaborateurs, de d√©velopper votre expertise dans un environnement en pleine transformation, au carrefour de l‚Äôinnovation et de l‚Äôexp√©rience client : notre ambition √† horizon 2023, √™tre un acteur digital, omnicanal et agile, champion de l'exp√©rience client, de vous engager au sein d'une entreprise engag√©e : nous rejoindre, c‚Äôest faire partie d‚Äôun Groupe responsable qui agit en entreprise citoyenne en √©tant mobilis√© autour de 4 axes (sant√©, aidants, √©ducation et environnement) avec un impact soci√©tal positif et r√©el. Nous nous engageons √† promouvoir des emplois respectant la diversit√© et la diff√©rence, ouverts √† chacun. Vos futures missions : 1. Gestion des donn√©es et support √† la d√©cision contribuer √† la mise en ≈ìuvre d‚Äôune plateforme Data fiable, agile et s√©curis√©e permettant d‚Äôorchestrer des donn√©es issues du Back Office, participer aux ateliers d'expression des besoins internes m√©tiers comprendre leurs probl√©matiques et les traduire de mani√®re analytique, extraire les donn√©es n√©cessaires √† l'analyse, analyser les donn√©es (mod√®les et tests statistiques) restituer les r√©sultats des analyses sous forme de tableaux de bord ou au travers d'outils de data vision, √©changer sur les r√©sultats et les solutions avec les √©quipes m√©tiers, participer au contr√¥le de la qualit√© des donn√©es tout au long de leurs traitements, Participer aux audits assureurs, Maintenance et √©volution des outils existants (Extractions via Talend/ SQL/ PLSQL/ Reporting Tableau & Power BI) Participer √† la cl√¥ture comptable : Lancement des outils comptable, analyser les r√©sultats dans leurs grandes masses pour v√©rifier l‚Äôint√©grit√© des donn√©es. 2. Veille et d√©veloppement de l'activit√© contribuer √† la promotion de la culture DATA au sein de l'entreprise, assurer une veille technologique sur les outils d'analyse de la donn√©e et proposer des am√©liorations sur les process existants. Cette opportunit√© est √† pourvoir dans le cadre d‚Äôun remplacement . Directement rattach√©.e √† Omar , Responsable de d√©veloppement informatique , vous rejoindrez notre √©quipe Parisienne compos√©e de 4 collaborateurs. D√®s votre arriv√©e, vous b√©n√©ficierez d'un parcours d'int√©gration pour favoriser votre prise de poste. Une fois autonome dans vos missions, vous pourrez b√©n√©ficier de notre accord t√©l√©travail. Vous disposez au minimum d'un Bac +5 en informatique, vous poss√©dez une exp√©rience professionnelle de 3 ans concluante en tant que Data Analyst, id√©alement dans le secteur de l'assurance ou de la banque. Vous pourrez √©galement mettre √† profit : vos comp√©tences techniques : techniques statistiques, gestion de bases de donn√©es, outils de bases de donn√©es (Ex : SQL/ NoSQL/PLSQL), SGBD relationnels (Oracle, SQL Server), ETL (Talend), langages de programmation (Ex : Java, SQL, Python, R, SAS etc.), Excel VBA, outils de visualisation (Qlik, Tableau, Power BI), connaissance du RGPD, connaissance des principes de cybers√©curit√©. La connaissance du mod√®le de donn√©es du progiciel Cleva et Salesforce, vos comp√©tences transverses : capacit√© d'analyse et de synth√®se, rigueur, orientation client, adaptabilit√©, capacit√© d'organisation et de planification, travail en √©quipe et en transverse, communication √©crite, communication orale, la pratique de l‚Äôanglais professionnel sera un plus. Cette opportunit√© est faite pour vous ? N'attendez plus pour postuler en nous adressant votre CV accompagn√© de quelques lignes sur votre projet professionnel et ce qui pourrait vous √©panouir aujourd'hui. Ce sera la premi√®re √©tape de notre processus de recrutement. Si vous n‚Äô√™tes pas s√ªr(e) que cette offre soit LA bonne, d‚Äôautres postes sont √† pourvoir , alors n‚Äôh√©sitez pas √† consulter notre site carri√®re et/ou notre page Linkedin ! Ce contenu est bloqu√© Le cookie Youtube est obligatoire pour voir ce contenu Accepter le cookie","APRIL, the #1 insurance brokerage in France, is seeking a Data Analyst with technical skills in statistics, database management, data visualization tools (Qlik, Tableau, Power BI), and programming languages (Java, SQL, Python, R, SAS). The successful candidate will extract, analyze, and communicate data insights to support decision-making for the company's digital and UX platform. The role requires an understanding of the insurance or banking industry and a minimum of three years of professional experience. The company offers a dynamic and agile work environment and opportunities for personal and professional development.",N,N,N,0,1,0.013848874720779208
170,56869,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-business-intelligence-f-h_niort,Data Engineer,Micropole,"{Microsoft,durable,Qlikview,Talend,SAP,Informatica,AWS,TALEND,via,R,PowerBI,BigQuery,GCP,SQL,Python,Tableau}",NaN,"4 Rue du 14 Juillet, Niort, 79000",IT / Digital,CDI,2023-03-26,"Micropole est acc√©l√©rateur de la transformation des entreprises par la Data. Du conseil √† la mise en ≈ìuvre op√©rationnelle, Micropole accompagne les entreprises dans leur strat√©gie data, et les transformations organisationnelles, humaines et technologiques associ√©es. Sa mission : aider ses clients √† garder un temps d‚Äôavance en exploitant tout le potentiel de la data pour avoir un impact business positif, gr√¢ce √† l‚Äôinnovation, qu‚Äôelle soit technologique, de process ou de m√©thode. Ses 1200 experts consultants, en Europe et en Chine, accompagnent leurs clients dans la compr√©hension des enjeux de transformation de leurs m√©tiers et/ou secteurs d‚Äôactivit√©, par la data. Ils con√ßoivent, construisent, s√©curisent et d√©ploient, √† l‚Äô√©chelle, des mod√®les op√©rationnels et performants, pour permettre une croissance durable et responsable. En r√©sum√©‚ÄØ: Poste : Data Engineer (F/H) Localit√© : Niort Type de contrat : CDI Niveau d‚Äôexp√©rience‚ÄØ: Au moins 3 ans Comme nous, vous √™tes passionn√©(e) par la donn√©e et convaincu(e) que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales , au sein d‚Äôune agence √† taille humaine o√π r√®gnent entraide et convivialit√© et engag√©e en faveur d‚Äôun num√©rique plus responsable au service de clients principalement implant√©s r√©gionalement ? Rejoignez l'aventure Micropole √† Niort ! En int√©grant l‚ÄôAgence Niortaise vous viendrez renforcer une √©quipe soud√©e qui porte l‚Äôesprit d‚Äô√©quipe, ayant √† c≈ìur de faire de votre int√©gration un succ√®s et de vous accompagner dans votre mont√©e en comp√©tences. Id√©alement situ√©e dansl‚Äôhypercentrede Niort, l‚Äôagence Micropole se trouve √† proximit√© des transportsen commun et des axes routiers. Vous aurez l'opportunit√© d'intervenir sur des projets data innovants, riches et vari√©s et participerez activement au rayonnement de l'agence sur le bassin niortais. Dans vos missions quotidiennes , vous serez amen√©(e) √†: Participer au recueil des besoins des m√©tiers ; R√©diger les dossiers de conception technique ; Mod√©lisez les entrep√¥ts de donn√©es ; D√©velopper des flux de donn√©es via des ETL, Concevoir des tableaux de bord via des outils de reporting et datavisualisation ; Vousaccompagnez la ma√Ætrise d‚Äôouvrage dans la validation de livrables, ls tests, l‚Äôassistance√† la recette et la conduite du changement sur le projet, Vos comp√©tences techniques : Vous ma√Ætrisez la manipulation des donn√©es (pr√©paration, mod√©lisation, restitution), Vous ma√Ætrisez parfaitement au moins un ETL du march√© (Informatica, Talend, BigQuery, Datafactory,...) et la cr√©ation de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, Cognos...), Python ou SQL n‚Äôont plus de secrets pour vous, Vos atouts : Dipl√¥m√©(e)d‚Äôune formation sup√©rieure en Informatique parcours BI, Data, Aide √† la D√©cision, Vousposs√©dez une exp√©rience d'au moins 3 ans dans la fonction, Votreesprit d‚Äôanalyse, de synth√®se, votre organisation et vos capacit√©sr√©dactionnelles sont souvent reconnus, Vousappr√©ciez travailler en √©quipe, dans un contexte multi-projets. DEVENIR #INNOVATIVE PEOPLE C‚ÄôEST‚ÄØ: - Int√©grer une communaut√© de 1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine. - Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale. - Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud‚ÄØ: AWS, Microsoft, Salesforce, GCP. - Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus. - S‚Äôassurer d‚Äôune innovation continue gr√¢ce √†‚ÄØ: Notre √©cosyst√®me de partenaires technologiques Notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR Nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients Notre management par les talents naturels LA VIE CHEZ MICROPOLE, C‚ÄôEST‚ÄØ: Une vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole‚ÄØ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles‚ÄØ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion‚ÄØ; La participation √† des projets internes sur la base du volontariat. PROCESSUS DE RECRUTEMENT‚ÄØ: Chez Micropole, le processus de recrutement est r√©actif et transparent. Etape 1 ‚Äì Si votre profil correspond √† nos attentes, vous √™tes recontact√©(e)s dans les 72 heures qui suivent votre candidature par C√©line ou Mika√´l nos Talent Specialist pour la r√©gion ouest pour un premier √©change t√©l√©phonique‚ÄØ; Etape 2 ‚Äì Un premier entretien est programm√© avec l‚Äôun d‚Äôentre eux sur site ou √† distance Etape 3 ‚Äì Vous rencontrez St√©phanie ou Camille les manager de l‚Äô√©quipe Data de l‚ÄôOuest pour un second entretien En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique) MICROPOLE GRAND-OUEST Micropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un d√©veloppement rapide sur le Data, le Digital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur du Groupe. Pr√©sent au plus pr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs du d√©veloppement √©conomique, nous accompagnons nos clients des secteurs de l‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et du public dans leur transformation data et digitale, notamment au travers de m√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ. L‚Äôagence Grand Ouest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit et met en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôun num√©rique responsable au sein des organisations. √Ä PROPOS DU GROUPE MICROPOLE Groupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement. MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy. Pour en savoir plus‚ÄØ: https://www.linkedin.com/company/micropole/mycompany/ #LI-CB1 Comp√©tences ETL Informatica TALEND PowerBI Qlikview SAPBO","Micropole is seeking a Data Engineer to join their team in Niort, France. The ideal candidate should have at least three years of experience in data manipulation, ETL development, and data visualizations. They will be responsible for collecting business requirements, developing technical design documents, modeling data warehouses, and developing data flows. They should also have expertise in at least one ETL tool (Informatica, Talend, BigQuery, Datafactory) and one data visualization tool (Power BI, Tableau, QlikSense, SAP BO, Cognos). Micropole is an international consulting and technology firm specializing in Data & Digital.",Bac +5 / Master,Entre 250 et 2000 salari√©s,> 3 ans,0,0,0.0
296,56877,https://www.welcometothejungle.com/fr/companies/scalapay/jobs/data-engineer_milan,Data Engineer,Scalapay,"{Athena,Kubernetes,Glue,AWS,magic,S3,scale,Linux,Git,SQL,Python}",NaN,"Milan, 20121","FinTech / InsurTech, Mode, Art de vivre",CDI,2023-03-26,"Scalapay transforme la fa√ßon dont les consommateurs r√©alisent leurs achats online et en magasin, en permettant aux commer√ßants d‚Äôoffrir √† leurs clients des exp√©riences magiques. Avec plus de 4 000 d√©taillants dans les secteurs de la mode, de la beaut√©, de la maison et du voyage qui nous font confiance (Moschino, Calzedonia, G√©rard Darel, Nike, Shein, pour n‚Äôen citer que quelques-uns), nous avons plus d‚Äôun million de clients qui utilisent Scalapay aujourd‚Äôhui en Europe. Apr√®s une s√©rie B de 497M$ en f√©vrier 2022 men√©e par Tencent et Willoughby Capital, nous avons obtenu le statut de licorne ! Gr√¢ce √† cela, nos √©quipes grandissent rapidement et nous recherchons des talents extraordinaires pour venir rejoindre l‚Äôaventure et nous aider √† fa√ßonner l‚Äôavenir du paiement et des produits checkout dans l‚Äô√©cosyst√®me eCommerce. Travailler avec nous signifie un quotidien o√π tout va tr√®s vite, o√π chacun a l‚Äôopportunit√© de mener des projets passionnants et stimulants, et de faire partie d‚Äôune √©quipe anim√©e par 4 valeurs tr√®s fortes : #createmagic #staycurious #beimpactful #playasateam. Nous sommes fiers d‚Äô√™tre l‚Äôune des 10 meilleures startups pour lesquelles travailler selon LinkedIn, et la startup de l‚Äôann√©e 2021 en Italie. This is where your magic happens. If you love it, Scalapay it üñ§ Thanks to our innovative BuyNow PayLater payment solution, Scalapay is transforming the way more than 2 million customers buy online and in-store, empowering 5,000+ merchants to give their customers magical shopping experiences. Being only 3 years old didn‚Äôt stop us from becoming a unicorn ü¶Ñ We have raised over $700mln and we did this thanks to a team built around our 4 core values: #createmagic #staycurious #beimpactful #playasateam . This is where your magic happens. If you love it, Scalapay it ‚ô• THE MISSION Data-driven decisions are the centre of our efforts to automate processes and support decisions across the business. As Data Engineer , your role will focus on developing distributed software for large-scale heterogeneous data processing, the development of ETL and reverse ETL pipeline. You will be responsible for: - Data modelling - Data lineage - Data quality / Data observability - SLA, performance and scalability You‚Äôll be required to discuss requirements for data access and integrations with colleagues across the business, design solutions to the company‚Äôs problems and implement these using modern software processes in the cloud. The role gives a large amount of autonomy and the chance to work with a top-notch team of experienced data experts. Who we are looking for: - Strong Python and SQL experience - Experience building and deploying ETL pipelines - Experience with API integration - Ability to scope projects and decompose work into tasks - Familiarity with Linux-like development stacks, including Git, Kubernetes, etc - Familiarity with AWS infrastructure (such as S3, Athena, Glue, etc) - Knowledge of Data Modeling / Data Observability is a plus - Ability to engage with colleagues on business processes - A Bachelor's degree in computer science or a related field Why you should join Scalapay: - Attractive packages based on skills and experience - International environment with significant challenges to be met every day - Lots of opportunities to work with a team of industry tech leaders who are focused on delivering products that offer exceptional user experiences - Personalised support to accelerate your professional growth and take ownership of the products you deliver: we want to help you grow! - Latest technologies and being encouraged to bring your flair to the role Recruitment Process: 1) A quick chat with one of our Talent Acquisition team members 2) The first interview with the Hiring Manager to deep dive into your experiences and better understand your motivation 3) A case study to test your hard skills 4) A Meet The Team session where you‚Äôll get to meet different people at Scalapay and see if you‚Äôll fit into our culture _________________________________________________________________________ Want to learn more? Don't hesitate to explore our Careers website and Careers website, and our LinkedIn, WTTJ, Meritocracy and Glassdoor pages. Pro tip: send your CV in English üòâ Super Pro tip: we know that application processes can be scary and frustrating but‚Ä¶ we look for talent, not people that tick all our boxes. We believe in the power of diversity: Scalapay is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation.","Scalapay is seeking a Data Engineer with strong Python and SQL skills to develop distributed software for large-scale heterogeneous data processing, ETL and reverse ETL pipelines. The role involves scoping projects, designing solutions, and implementing them using modern software processes in the cloud. Candidates should be familiar with AWS infrastructure, Linux-like development stacks, Git, and Kubernetes, and have experience with API integration, data modelling, and data observability. Scalapay offers an international environment, attractive packages based on skills and experience, and opportunities to work with a team of industry tech leaders dedicated to delivering products with exceptional user experiences.",Bac +3,Entre 50 et 250 salari√©s,> 3 ans,0,0,0.0
188,37270,https://www.welcometothejungle.com/fr/companies/nnit/jobs/python-developer-digital-biomarkers-data-engineering_prague,Python Developer (Digital Biomarkers Data Engineering),NNIT Czech Republic,"{SciPy,MySQL,go,UNIX,MongoDB,Microsoft,Mapreduce,Pandas,Luigi,Hadoop,Kafka,Spark,Azure,NoSQL,SQL,Python,NumPy}",NaN,N,"IT / Digital, SaaS / Cloud Services, Cybers√©curit√©",CDI,2022-10-18,"NNIT is a leading provider of IT transformation services and solutions to international life sciences companies and for the Danish private and public sector. Working in NNIT means being part of an international team with talented colleagues who all work the NNIT way. Each and every day, more than 3,000 NNIT colleagues go to work globally towards a common goal to make a mark on business and society, by bringing digital transformation to life. At NNIT, IT is not just IT. For those at NNIT, working with IT, is to ensure that vital parts of our society are functional and developing in vital areas such as pharma production, banking, transportation and food supplies. In short, they handle critical infrastructure across sectors and across countries. That is why making a mark means everything to NNIT. Their values are not just phrases that were written down and hung up on a poster. They are alive in the offices around the world and embodied when meeting their customers and other stakeholders. NNIT are open and honest, value adding and conscience driven in every aspect. At NNIT, independent thinking and individual responsibility is encouraged, allowing you to pave the way and make your mark in and with NNIT. There are very few boring days with NNIT. There are fun days, busy days, inspiring days, suprising days and so forth. They are all part of everyday life at NNIT. Our Life Science unit is looking for a Python developer to further develop the Remote Monitoring Patient Platform collecting sensor data from digital devices handed out in clinical studies. You will be dedicated to one of our big pharma client and work closely with the whole team of great IT professionals. The successful candidate will establish processes and implementations to enable and facilitate the mining of digital biomarkers out of the mentioned data. In addition, the candidate will help the staff to setup and maintain new digital biomarker studies. You need to expect to be working closely with the client, sometimes from their offices. Responsibilities: ‚óè Develop the computational back-end of applications used to discover Digital Biomarkers ‚óè Help to automate the creation of reports and dashboards supporting the analytics driven decision taken from the sensor data collected ‚óè Participate in technical decision regarding the implementation of new algorithm to mine sensor data ‚óè Enhance the existing infrastructure that handles the data collected from sensors used in clinical trials ‚óè Proactively collaborate with a team comprising data scientists, software engineers and life science experts. Your experience: ‚óè Bachelor with emphasis on coursework of a quantitative nature (e.g. Computer Science, Engineering, Mathematics, Data Sciences) ‚óè 3 years of software development experience ‚óè Experience in or eagerness to write and maintain ETLs (extract, transform, load) pipelines which operate on a variety of structured and unstructured sources ‚óè Experience with SQL and NoSQL data stores ‚óè Deep knowledge of Python and frameworks around it. ‚óè Previous working experience with the common Python data analysis (e.g. NumPy/SciPy, Pandas, Scikit-learn, SQLAlchemy, etc.) and, ideally, data pipelining (e.g. Luigi) libraries ‚óè Knowledge of UNIX internals and workload management systems (SLURM, SGE /UGE) ‚óè Ability to write standards-compliant database related code for MongoDB and MySQL ‚óè Strong working knowledge of best coding practices (versioning, TDD, debugging) ‚óè Strong analytical skills combined with conceptual thinking and structured working style; ability to work in a multicultural team ‚óè Fluent in English. It‚Äôs good if you also have: ‚óè Previous experience in designing, creating, and implementing methods, algorithms and pipelines of digital signal processing ‚óè Experience with the Microsoft Azure environment ‚óè Experience with big-data systems (in particular Hadoop, Apache Spark, Apache Kafka and Mapreduce) with respective ecosystems ‚óè Previous working experience within an AGILE environment (ideally SCRUM) ‚óè Project-based work experience in the pharmaceutical industry/consulting preferred. Please submit your application in English.","NNIT is seeking a Python developer with experience in back-end development, ETL pipelines, SQL, NoSQL data stores, data analysis libraries, Unix internals, and workload management systems. The successful candidate will work within the Life Science unit and collaborate with data scientists, software engineers, and life science experts to implement algorithmic solutions for biomarker data analysis collected from clinical studies. Knowledge of digital signal processing, Microsoft Azure, big data systems, and agile development is a plus. The candidate should have a bachelor's degree in a quantitative field, three years of software development experience, and strong communication skills in English.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,0,0,0.0
131,37284,https://www.welcometothejungle.com/fr/companies/lemonade/jobs/data-engineer_tel-aviv_LEMON_Ll5Vj2G,Data Engineer,Lemonade,"{Airflow,Adept,AWS,Kafka,Lemonade,Spark,NoSQL,SQL,Python}",NaN,N,"Assurance, FinTech / InsurTech",CDI,2022-10-18,"Our mission is simple: Create the world‚Äôs most loved insurance through technology and social impact. As a certified Public Benefit Corporation and B Corp, Lemonade is constantly challenging how the insurance industry does business. We‚Äôre creating an experience that is fast, affordable, and hassle-free across renters, homeowners, pet, life and car insurance. And through our annual Giveback program, in which leftover premiums are donated to charities our customers choose, we‚Äôve donated over $6 million to a variety of organizations in need. Lemonade is currently available in the United States and in Europe (France, Germany, the Netherlands, and the UK) and continues to expand globally. We‚Äôre looking for a Data engineer to join our Data Platform team in TLV. As part of the Data infrastructure group, you‚Äôll be responsible for building scalable and accessible data solutions that help data consumers from around the organization produce crucial business insights. In this role you‚Äôll Build a scalable platform that draws data from multiple sources and formats, and allows for all users to easily consume it Develop and manage orchestration tools, governance tools, data discovery tools, and more Ensure our scalable data systems and pipelines run smoothly so that analysts, data scientists, machine learning engineers, and other stakeholders can access them effectively and efficiently Help expand and optimize our data pipelines architecture Take part in designing and architecting data solutions for all application requirements in a distributed microservices environment What you‚Äôll need 3+ years knowledge in data engineering or database development (background in the big data domain is an advantage). SQL expertise, working with various databases (relational and NoSQL), data warehouses, and third-party data sources and AWS cloud services Proficient with Python Adept at building, designing, and optimizing data pipelines, architecture, and data sets Familiarity with the data engineering tech stack: ETL and ELT tools, Airflow, Spark, Kafka Experience working in an agile development environment is an advantage. Ability to work in an office environment","Lemonade, a certified Public Benefit Corporation and B Corp in the insurance industry, is seeking a Data Engineer for their Data Platform team in TLV. The candidate will be responsible for building scalable and accessible data solutions, developing and managing orchestration tools, ensuring smooth data systems and pipelines, optimizing data pipelines architecture, and designing data solutions for all application requirements in a distributed microservices environment. The ideal candidate should have 3+ years of experience in data engineering, SQL expertise, proficiency in Python, familiarity with the data engineering tech stack, and experience working in an agile development environment.",Non sp√©cifi√©,Entre 250 et 2000 salari√©s,> 3 ans,0,0,0.0
