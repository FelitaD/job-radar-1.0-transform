,id,url,title,company,stack,remote,location,industry,type,created_at,text,summary,education,size,experience,remote_num,exp_num,rank
0,73785,https://www.welcometothejungle.com/fr/companies/lisi/jobs/ingenieur-traitement-donnees-data-engineer-h-f_paris,Ingénieur Traitement Données  - Data Engineer,LISI,"{KNIME,R,AWS,via,SQL,Python}",Télétravail partiel possible,"Paris, 75000","Pharmaceutique / Biotechnologique, Aéronautique / Spatiale, Automobile",CDI,2023-05-03,"""Shape & Share Sustainable Links"" LISI est un Groupe industriel mondial. Il est spécialisé dans la fabrication de solutions d’assemblage et de composants à forte valeur ajoutée pour les secteurs de l’aéronautique, de l’automobile et du médical. LISI est partenaire des plus grands acteurs mondiaux et est porté par ses valeurs familiales de long terme. Le Groupe innove et investit dans la recherche et le développement des produits de demain pour répondre aux besoins de ses clients, notamment en matière de qualité, de sécurité et de performance. Comment LISI se différencie ? En s’appuyant sur deux axes stratégiques : l’innovation et l’excellence opérationnelle, tout en intégrant une forte culture RSE. Sa filiale, Lisi Aerospace, équipementier aéronautique de premier rang spécialisé dans la fabrication de pièces de fixation et de composants de structure recherche un Ingénieur Traitement Données - Data Engineer (H/F) basé à Paris 12ème en CDI. Au sein d’une équipe de 3 personnes sous la responsabilité du Responsable Performance, l’Ingénieur(e) Traitement Données supporte les 8 usines de la BU Composants de Structure dans l’amélioration de leur maîtrise process. Pour ce faire, il ou elle propose, conseille ou implémente les moyens le plus adaptés pour collecter, transformer, stocker et analyser les données utiles au processus de production. Sa mission principale consiste à réaliser tout ou une partie des étapes suivantes en laissant à chaque usine la plus grande autonomie possible : - Recueillir les besoins fonctionnels des différentes usines de la BU Composants de Structure concernant la collecte, la transformation et le stockage des données. - Définir, en partenariat avec les métiers concernées et l’IT, l’architecture de données la plus adaptée pour y répondre - Développer les flux de données prototypes, mettre en place les bases de données associées - Déployer les solutions sur le terrain, accompagner les utilisateurs - Industrialiser et assurer la MCO des solutions mises en place Il / Elle aura également en charge les missions suivantes : Définir les standards de collecte de données process pour la BU, dès les phases d’industrialisation Faire le lien avec la maintenance et les automaticiens pour la mise en place de collecte de données process Participer à la résolution de problèmes liés aux données, y compris en développant des algorithmes permettant l’optimisation des process de fabrication au sein de la BU Participer et co-animer la communauté Data Etablir le lien entre les métiers et analyser les données pour une maitrise optimale du process Assurer un rôle de référent métier pour le DataLake Soutenir la démarche d’excellence opérationnelle en apportant son expertise sur le traitement de la donnéeLe poste implique des déplacements réguliers en France et à l'étranger (10% à 30%) Ce poste est pour vous si : Vous avez, de préférence, des compétences en mécanique avec un goût avéré pour l'informatique Vous maîtrisez des méthodes et outils de collecte, transformation et stockage de données, via l’utilisation par exemple d’un ou plusieurs outils/langages usuels : SQL, Power Query, KNIME, Python, R… La connaissance des outils Analytics d’AWS est un plus La connaissances de certains procédés métallurgiques (forge, usinage, contrôles 3D…) est un plus Vous avez un niveau d'anglais opérationnel oral et écrit Vous êtes-vous déjà demandé de quoi est fait un avion ? Prenez part à notre ambition : accompagner les acteurs du changement pour rendre les avions plus rapides à assembler, plus sûrs et plus économes. Notre Raison d’Etre ? Créer et Partager des liens durables ! Nos valeurs ? https://careers.lisi-group.com/fr/decouvrir-lisi/nos-valeurs/ POURQUOI NOUS REJOINDRE : Cadre de travail agréable et équipe conviviale dans une entreprise familiale Télétravail 2 jours par semaine après 6 mois de présence Prime d'objectifs de 10% du salaire fixe annuel Prime de participation et Intéressement sur l'ensemble de la rémunération (fixe + variable)",,Bac +4,> 2000 salariés,< 6 mois,2,3,0.3100868364730212
15,73705,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_fontenay-sous-bois_SG_QX9ryP,Data engineer,Société Générale,"{Scala,Spark,Nifi,Kafka,Hadoop,Python}",Télétravail partiel possible,"Fontenay-Sous-Bois, 92060","Banque, FinTech / InsurTech, Finance",Alternance,2023-05-03,"Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer ! Détection de fraude en temps réel, anonymisation de données ou encore amélioration de moteurs de recommandation, vous créez des architectures qui répondent aux problématiques de masse de données, de rapidité et de volume. Bref, Vous êtes un(e) vrai(e) maestro de la data ? Rejoignez-nous ! Concrètement, vous serez amené(e) à: Concevoir des solutions pour collecter, nettoyer, organiser et synthétiser de gros volumes de données (pour alimenter bases de données, datalakes et projets Big Data) Travailler en étroite collaboration avec les Data Architectes et Data Scientists pour industrialiser le procédé et produire des analyses opérationnelles Participer à l'analyse complexe de données provenant de différentes sources Assurer une veille technologique permettant de tester de nouvelles fonctionnalités et nouveaux outils Vous préparez un Bac+5 en école de Commerce, d'Ingénieur ou Université avec une spécialisation en i nformatique. Vous avez des compétences dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc. Vous êtes Passionné(e) de data, vous participerez aux développement de projets innovants et partagez avec votre équipe Vous êtes curieux(se), avec un bon esprit d'analyse et de synthèse Vous aimez développer en Python, Spark et Scala You're fluent in English! Vous êtes notre candidat(e) idéal(e) ! Pensez à accompagner votre CV de votre planning de formation.",,Bac +5 / Master,> 2000 salariés,< 6 mois,2,3,0.3100868364730212
13,73928,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_fontenay-sous-bois_SG_M2VbYO8,Data Engineer,Société Générale,"{Scala,Spark,Nifi,Kafka,Hadoop,Python}",Télétravail partiel possible,"6 Allée des Sablons, Fontenay-Sous-Bois, 94120 ","Banque, FinTech / InsurTech, Finance",Stage,2023-05-03,"Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer ! Détection de fraude en temps réel, anonymisation de données ou encore amélioration de moteurs de recommandation, vous créez des architectures qui répondent aux problématiques de masse de données, de rapidité et de volume. Bref, un(e) vrai(e) maestro de la data ! Concrêtement, vous serez amené(e) à: * Concevoir des solutions pour collecter, nettoyer, organiser et synthétiser de gros volumes de données (pour alimenter bases de données, datalakes et projets Big Data) * Travailler en étroite collaboration avec les Data Architectes et Data Scientists pour industrialiser le procédé et produire des analyses opérationnelles * Participer à l'analyse complexe de données provenant de différentes sources * Assurer une veille technologique permettant de tester de nouvelles fonctionnalités et nouveaux outils * De formation Bac +4/5 en école d'ingénieur, ou en informatique et avez des compétences dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc. * Passionné(e) de data, vous participerez aux développement de projets innovants et partagez avec votre équipe * Vous êtes curieux(se), avec un bon esprit d'analyse et de synthèse * Vous aimez développer en Python, Spark et Scala * You're fluent in English!",,Bac +4,> 2000 salariés,< 6 mois,2,3,0.3100868364730212
11,73915,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_fontenay-sous-bois_SG_kykrQYW,Data Engineer,Société Générale,"{Python,SQL,Java}",Télétravail partiel possible,"FONTENAY-SOUS-BOIS, Fontenay-Sous-Bois, 93200","Banque, FinTech / InsurTech, Finance",Alternance,2023-05-03,"Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer ! Vous savez « faire parler » les données pour créer de la valeur ? Vous souhaitez travailler en mode agile ? Rejoignez les Infrastructures Informatiques d'un Groupe en pleine transition numérique ! Vous intégrerez les équipes de transformation de la chaine Solvabilité et participerez notamment à la mise en place d'une chaine applicative sous le Cloud. Concrètement, et sous la supervision de votre tuteur(rice) et/ou manager, vous serez amené(e) à : Participer à la création des User Stories de la Feature Team concernée Développer, tester et livrer des nouveaux composants associés Créer de tests unitaires, contribution aux travaux d'intégration, automatiser des tests et construire de TDD et BDD Analyser, paramétrer et coder des composants logiciels ainsi que l'optimisation du code et diffusion de bonnes pratiques Réaliser le reporting , participer au suivi de la production et support Gérer la qualité des développements : temps de traitement, optimisation et contrôle des données Vous allez préparer un Bac+4/Bac+5 en école d'Ingénieur ou Université avec une spécialisation en Informatique Vous êtes curieux(se), autonome et avide de nouvelles technologies. Vous avez de bonnes capacités de rédaction, d'analyse et de conception et vous faites preuve d'écoute et de prise d'initiative Vous souhaitez évoluer dans un environnement dynamique et faites preuve d'une excellente communication Vous avez des notions de SQL et de développement en Python/Java. You're fluent in english ! Vous êtes notre candidat(e) idéal(e) ! Pensez à accompagner votre Cv de votre planning de formation !",,Bac +4,> 2000 salariés,< 6 mois,2,3,0.3100868364730212
10,73806,https://www.welcometothejungle.com/fr/companies/shine/jobs/analytics-engineer_paris,Analytics Engineer,Shine,"{Ruby,BigQuery,Shell,Looker,Tableau,Metabase,SQL,Mixpanel,scale,Python}",Télétravail total possible,"Paris, 75001","Application mobile, FinTech / InsurTech",CDI,2023-05-03,"Shine simplifie le quotidien des indépendant·es et petites entreprises pour leur permettre de se concentrer sur ce qui compte vraiment : leur réussite. ✨ C’est un compte pro responsable , qui propose des services en ligne et un véritable copilote administratif . Shine simplifie l’expérience bancaire et administrative des indépendant·es, grâce à un équilibre entre service en ligne et accompagnement humain. Les entrepreneur·es peuvent se reposer sur une équipe d’expert·es disponibles sept jours sur sept pour répondre à toutes leurs interrogations administratives et sur une application et des fonctionnalités innovantes: un compte pro 100% en ligne, avec une application simple et intuitive, pour gérer leur activité un copilote administratif, pour les accompagner de la création de leur entreprise à la gestion quotidienne des assurances inédites, pour protéger l’activité des indépendant·es Au delà de cette mission, Shine en tant qu’entreprise aspire à avoir un impact social et écologique positif . La startup a à cœur de favoriser la diversité et l’inclusion au sein de ses équipes et de sa communauté. Elle est également labellisée B Corp. Enfin, Shine fait partie du mouvement 1% pour la planète et reverse 1% de son chiffre d’affaires annuel à des associations environnementales. Lancé en 2018, Shine a levé 10,8 millions d’euros auprès de Daphni, Kima Ventures, XAnge et plusieurs business angels. La startup a rejoint en 2020 la Société Générale et accélère son développement tout en restant une structure indépendante. Rejoindre Shine aujourd’hui, c’est faire partie d’une équipe internationale de 130 personnes passionnées qui travaillent en remote ou dans leurs bureaux dans le centre de Paris. C’est aussi aider 100 000 entrepreneur·es et prendre part à leur croissance pour impacter des millions de personnes ! Shine’s Data team We build the most reliable data architecture to insure the best collect, analysis and data visualisation possible - it goes without saying that the data team plays an essential role for Shine ! ✨ Our squad is made of 4 Data Engineers, 1 scientist, 3 Data Analysts, 1 Lead Data Analyst and a head of data to insure top synchronisation with our product and or business. You will report directly to Saghar , our Lead Data Analyst and will create and maintain the company's analytics infrastructure (data pipelines, data warehousing, and data visualisation tools) to support our needs. You will also evangelize best practices and be responsible for ensuring the reliability and integrity of the collected and analyzed data. Regarding our stack, we are mainly using : BigQuery for our data warehouse Segment for events tracking, documentation and enrichment Mode, Metabase, Looker Studio and Mixpanel for visualization Google Analytics et Matomo for web data Joining us as an Analytics Engineer 👋 Proactively designing a product friendly data model by creating and updating data tables on different layers Collaborating with data analysts to create analytics tables that are ready for analysis Working as pair with Data Engineers to make sure the Analytics platform is logically integrating as part of the Data Platform Contributing to the development of the data team to ensure the adoption of best practices in terms of analysis, data visualisation Collaborating with Tech and Business teams who produce part of the data to give them feedback and improve how the data is produced Enriching our data documentation glossary which involves adding data and business definitions Working on the migration of all the dashboards from Mode Analytics to Data Studio It's a match if 🤝 You have 3+ years of experience in a Analytics Engineer or equivalent position (Data Analyst, BI, Data Engineer…) You're proficient with SQL in the context of complex data transformations You’re comfortable with a visualisation tool (ex: Data Studio, Looker, Tableau, Mode, Metabase) You have experience with data modelling, ETL processes and data warehousing You’re autonomous to script actions and tasks in your favorite language (Python, JS, Ruby, Shell…) You demonstrate the ability to communicate complex business activities, technical requirements, and recommendations in a clear and concise manner. You have a good product sense : ability to empathize with customers, understand business and product problems Your role is at the crossroads of different disciplines and you'll interact with a lot of different people - you enjoy working as a team-player and learning from others You stick to Shine’s values and are interested by our product 💛 You can understand this job description and work in English (our data team is international!) Life at Shine ✨ Working at Shine is joining a fast paced scale-up, a useful and UX driven product but not only… Before anything else, it’s being a part of a great human experience in a company driven by amazing values toward people and ecological matters We do believe that caring is not only about giving autonomy, responsibility and encouraging proactivity. That’s why we offer: 💰 A fair and transparent salary ( More informations ) 🏠 A flexible and remote-friendly environnement. From France and Europe! 🏢 A brand new and stunning office in Paris - Also a nice corner in Station F 🖥️ Everything you need to work in perfect conditions (Co-working space, furniture, monitors, mouse, etc.) But also... 👩‍💻 1 freelancing day / month. The perfect occasion to put yourself in a Shine’s user’s shoes (Shine premium is offered) 👪 A second parent leave extended to 8 weeks + 3 days of parental leave for sick child 💚 Healthcare program 100% covered by Shine for you and your family 🎶 Culture budget : 275€/ year to buy books or listen to music (Spotify, Deezer …) 🤸 Sport pack: 300€ per year to subscribe to gym, participate in sport competitions … Take care of yourself! 🚴‍♂️ Bike + transport : Refund of your fees, on jump seats like on bike paths! ☀️ 35 days of holidays for everyone! 🏝 1% salary bonus in June to enjoy your Holiday You wonder about our hiring process ? 1️⃣ A 45’ first call with Annaïg, our data talent acquisition specialist, to get to know each other and tell you more about Shine. 2️⃣ A 60’ technical Interview with Saghar , your future manager about your data experiences. 3️⃣ A 45’ Interview with Nicolas , our Head of Data + a 45’ cultural interview to give you more context about Shine’s values. 4️⃣ A half-day immersion for you to understand Shine’s culture, meet the team and get an introduction to our data analysis environment with a case study.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,3,1,0.24806946917841696
12,73890,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-banque-bordeaux_bordeaux_SS_wy9yV7R,Data Engineer - Big Data - Banque - Bordeaux,Sopra Steria,"{Scala,Shell,Hdfs,hive,GitLab,Jenkins,spark}",Télétravail total possible,"Avenue Pythagore, Bordeaux, 33700","IT / Digital, Organisation / Management",CDI,2023-05-03,"Sopra Steria, l'un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. Fort de 50 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d'affaires de 5,1milliards d'euros en 2022. The world is how we shape it Sopra Steria (SOP) est coté sur Euronext Paris (Compartiment A) - Code ISIN : FR0000050809 Pour plus d'informations, retrouvez-nous sur www.soprasteria.com/fr La division « Banque » s'est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement. Votre futur environnement de travail : Intégré(e) au sein d'une équipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participez à un projet Big Data, en mode Agile, et intervenez en tant que référent(e) technique au sein de votre équipe. Votre rôle et vos missions : A cette occasion vous êtes amené(e) à : - Apporter votre expertise et votre expérience à vos collègues lors des phases de conception et développement - Accompagner vos collègues dans leur montée en compétence technique au sein du projet - Définir et implémenter des solutions au sein d'un périmètre applicatif existant - Proposer des idées d'amélioration continue à votre client et à votre équipe (revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie) - Concevoir et développer des sujets complexes. Environnement du projet : - Méthodologie projet : Mode Agile (Scrum). Environnement technique : - Hdfs, hive, spark, oozie - Scala, HQL, Shell - GitLab, Nexus, Maven, Jenkins, Sonar Environnement fonctionnel : - Alimentation d'un DataLake jusqu'au build d'un moteur de calcul ; - Intervention sur la mise en place de règle relatives aux normes Bâloise. Ce que nous vous proposons : - Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. - Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation. - Un accompagnement individualisé avec un mentor que vous choisissez. - Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy. - La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…). Votre profil : De formation Bac+5, vous avez au moins 5 ans d'expérience dans la data dont 3 ans en Big Data, notamment sur les technologies mentionnées ci-dessus. Vous aimez travailler en équipe, relever les défis techniques, conseiller et apporter votre valeur ajoutée à une équipe. Vous savez être challengeant et leader envers le client et l'équipe de Dev en ce qui concerne l'amélioration continue (process de livraison, automatisation du testing/validation, maintenance des bonnes pratiques et performance des runs). Vous aimez vous tenir informé(e) des nouveautés technologiques et êtes à la recherche d'évolution de carrière réelle basées sur l'expérience projet et l'acquisition de nouvelles compétences. Employeur inclusif et engagé, Sopra Steria œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils",,Bac +5 / Master,> 2000 salariés,> 5 ans,3,1,0.24806946917841696
16,73758,https://www.welcometothejungle.com/fr/companies/veolia/jobs/digital-factory-data-engineer-m-f_saint-maurice,Digital Factory - Data Engineer,Veolia,"{Athena,Lambda,observable,Python,Spark,AWS,Git,GitLab,NoSQL,Kinesis,R,Glue}",Télétravail total possible,"Saint-Maurice, 94410","Environnement / Développement durable, Bâtiment / Travaux publics, Energie",CDI,2023-05-03,"Would you like to give meaning to your professional activity? Do you feel the need to be useful? Would you like to help the planet and work towards a better and more sustainable future? Do you have a “Resourcer” spirit? …. At Veolia, 84% of employees and 92% of managers feel invested in their job*. Teams find meaning and purpose in their work in the water, energy or waste management. At Veolia, we recruit several hundred young graduates every year, from engineering or business schools and universities. They join us for either an internship, a work-study contract or their first job. We also offer them V.I.E. contracts (international voluntary programs in companies) through our dedicated Pangeo program. Through our Campus network, we also take on trainees, supporting them from CAP-level (certificate of professional aptitude) to a master’s degree. At Veolia, our 178,894 employees share a mission: resourcing the world. This is why we call them “Resourcers”. We all work together towards Veolia’s ambition: to be the benchmark company for ecological transformation. Operating in 51 countries on five continents, with more than 178,894 employees , Veolia designs and implements solutions that contribute to sustainable development in cities and industries, in the fields of water, waste and energy management. Specialized in environmental services, Veolia is committed every day, on every continent, to improving access to resources , while preserving and replenish them. The Group ensures that international laws and treaties guaranteeing the human and social rights of all people are strictly observed, both within the company and by its stakeholders. These values and rules of conduct take the cultural diversity of the Group into account. In 2020, Veolia supplied 95 million people with drinking water and 62 million people with wastewater services, produced almost 43 million megawatt hours of energy and recovered 47 million metric tons of waste. We are looking for an experienced data engineer to join our team on this fantastic journey, working together to ensure that our customers get the best experience possible. We have a huge potential for analytics and machine learning, based on our IoT and enterprise data, which require solid data engineering. Your work will have very concrete outcomes and observable value. You will be fully integrated into the development team, which is organised in an Agile Scrum fashion, and with an excellent team spirit. You will: Design, develop, and test data pipeline infrastructures and database systems Collaborate with data analysts and data scientists to build and improve data models, algorithms and predictive models according to the busines’s requirements Ensure that all current data infrastructures and processes meet industry standards Utilise cutting edge data engineering technologies and software Search for elements of the data collection and processing that need improvement, and improve them Implement systems to monitor data quality for optimised accuracy and clarity Design and implement scalable and high-performing solutions Collaborate with several other teams: Product and Business Development teams for HUBGRADE, Corporate IS&T teams (Data Lake, Cybersecurity, ERP, Networking, FinOps, …), external Digital Partners. Continuously transfer knowledge to the Run&Support team Take part in L3 support Identify synergies between software components and improve efficiency of development and code maintenance Keep the product vision in mind while working on details Help to build flexible, future-proof solutions Continuously improve our agile development process, architecture, and engineering practices Mentor and coach less experienced engineers on the team The platform being very rich and diverse, you will have the opportunity to work on different areas and projects. Additional Information As an inclusive company, Veolia is committed to diversity and gives equal consideration to all applications, without discrimination. Education & Experience Bachelor's degree in Computer Science 5+ years of experience in software development or data-related fields (DWH, …), with at least 2 years in pure data engineering / big data, using modern programming languages, frameworks, and technologies Experience working in an agile cross-functional team Technical skills Skilled with Git, Python or R, Big Data frameworks (especially Spark) Skilled with relational and NoSQL databases Skilled with data modelling and popular data viz tools Fully operational on public Cloud technologies, especially AWS and its managed services (Glue, Kinesis, Athena, Lambda, IoT Core, EventBridge, …) Fully operational on Agile practice Familiar with event-driven architectures Familiar with automation and IaC tools (CI/CD, Terraform, AWS SAM) Familiar with enterprise tools, such as ServiceNow and GitLab Good understanding of IoT, Web development, Data Lake, and Machine Learning domains Soft skills Fluent in English and French Good communication skills Able to work in a multicultural environment Technology minded Able to quickly skill up on any technology or business topic Passion for quality Innovative state of mind",,Non spécifié,> 2000 salariés,Non spécifié,3,1,0.24806946917841696
2,73820,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/developpeur-data-engineer-teletravail_MD_8DG8qmx,Développeur / Data Engineer - Télétravail,MP DATA,"{Azure,Postgres,Airflow,GCP,MongoDB,Spark,AWS,Snowflake,Git,Java,SQL,Kafka,S3,Django,Hadoop,Python,GCS}",Télétravail total possible,Boulogne-Billancourt,"Intelligence artificielle / Machine Learning, IT / Digital, Big Data",CDI,2023-05-03,"Bonjour ! MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance, l’exploitation de leur données et leur décarbonation. Les collaborateurs, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français. MP DATA accompagne ses clients sur toute la chaine de la donnée au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science. Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences. Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort, et des possibilités d’évolution intéressantes. MP DATA, recrute un développeur , avec des affinités pour le métier de Data Engineer (ou un Data Engineer) afin de travailler pour un client, acteur majeur du secteur transport, le tout en télétravail. Accompagné par un Lead Data Engineer, vous monterez en compétences sur l’utilisation de nombreuses technologies notamment AWS , Python , Snowflake , Spark , Airflow, Ansible. Vos missions seront les suivantes : Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données Création de pipelines de données, traitement et transformation de la donnée. Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles Assurer le suivi de la production De formation Bac+5 (ou plus) en développement informatique / data engineering, vous justifiez d’une première expérience professionnelle au cours de laquelle vous avez pu développer les compétences techniques suivantes : Python Spark, Kafka, Hadoop Cloud : AWS (S3, Lambdas,…) / GCP / Azure Technologies de stockage : Snowflake / GCS / Azure Blob SQL : Postgres / MongoDB Django / Flask CI/CD : Ansible / Git Terraform C/C++ / Java / Rust Alors venez grandir avec nous ! 1 entretien RH -> 1 entretien technique -> 1 entretien dans les locaux",,Bac +5 / Master,Entre 15 et 50 salariés,> 1 an,3,1,0.24806946917841696
7,73885,https://www.welcometothejungle.com/fr/companies/shippingbo/jobs/data-engineer-h-f_toulouse_FS_m93gNd1,Data Engineer,FACILECOMM (SHIPPINGBO),"{Airflow,PostgreSQL,Pandas,MongoDB,AWS,SQL,Redshift,R,Redis}",Télétravail partiel possible,"3 Av. de l'Europe, Toulouse, 31400","Logiciels, SaaS / Cloud Services",CDI,2023-05-03,"Cher(e) candidat(e), Nous sommes ravis que le vent t'ait mené(e) jusqu’à cette annonce ! Peut-être est-ce toi, le/la futur(e) Data Engineer que nous attendons… En tout cas, nous l’espérons. Dans un premier temps, permets nous de nous présenter. Qui est Shippingbo ? La première chose que tu dois te demander c’est “qui est Shippingbo” et c’est une très bonne question ! Shippingbo est une technologie logistique e-commerce, créée en 2016, qui permet aux vendeurs en ligne d'optimiser leur chaîne logistique. Notre ambition est de devenir une technologie logistique SaaS leader en Europe d'ici 3 ans. En 2022, nous avons expédié plus de 10 millions de colis et 2 milliards d'euros de marchandises avec plus de 2000 entrepôts connectés. Notre équipe de plus de 100 collaborateurs est en pleine croissance et nous cherchons de nouveaux talents pour nous aider à atteindre ces objectifs ! Shippingbo cherche aujourd’hui à développer les outils d’analyse qu’elle met à disposition de ses clients ainsi qu’à développer de nouvelles fonctionnalités se fondant sur l’analyse des données. Nous recherchons un(e) Ingénieur Data (H/F) avec une expérience solide en data engineering pour renforcer notre équipe data et contribuer à la maintenance et au développement de notre infrastructure de données. Aujourd'hui, notre équipe data est composée d'une seule personne et nous souhaitons l'agrandir pour répondre aux besoins croissants. Nous recherchons spécifiquement un profil axé sur l’ingénierie des données et non sur la data science ou le machine learning. Vos missions principales consisteront à : Construire et maintenir les entrepôts et pipelines de données ; Optimiser les requêtes SQL et la performance des pipelines ; Participer à l'administration, la configuration et le paramétrage des bases de données. Vous avez au moins une expérience significative en tant qu'ingénieur data, avec une expertise en maintenance de pipelines de données ; Vous avez une connaissance approfondie de SQL , de l’optimisation de requêtes et des entrepôts de données ; Vous avez une expérience avec au moins une base de donnée orientée colonnes ; Idéalement vous avez également une expérience avec une base de donnée orientée documents et une base de donnée clé-valeur. Compétences et qualités personnelles pour ce poste : Facilité à travailler en équipe et aptitude à entretenir de bonnes relations de travail ; Capacité d'adaptation aux nouvelles technologies et méthodes de travail ; Force de proposition et esprit d'initiative pour améliorer les processus et les outils en place ; Capacité à communiquer de manière directe, honnête et bienveillante. Stack technique : PostgreSQL AWS Redshift MongoDB Redis Airflow Pandas Et vous, que pouvez-vous attendre de nous ? Intégrer une équipe dynamique, en pleine croissance et avoir un impact significatif sur la réussite de notre entreprise ; Participer à un projet ambitieux et contribuer au succès de notre entreprise en Europe ; Une formation continue pour te permettre d’approfondir tes compétences ; Une équipe jeune, dynamique et soudée ; Une bonne ambiance et un cadre de travail sympa ; Des afterworks ; De la bonne humeur ! Autres Informations : Type de contrat : CDI Lieu : 31400 Toulouse (Parking et accessible en métro, arrêt Ramonville) Rattaché au département R&D de l'entreprise Mise à disposition d’outils informatiques Tickets restaurant >>> Venez découvrir Shippingbo et les applications client : https://www.youtube.com/watch?v=MPSikIskB1Y La diversité occupe une place importante dans notre groupement, nous nous engageons, notamment en favorisant l'égalité professionnelle et l'emploi des travailleurs en situation de handicap. A compétences équivalentes, ce poste est ouvert à tous.",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.18605210188381271
1,73803,https://www.welcometothejungle.com/fr/companies/visian/jobs/data-engineer_levallois-perret,Data Engineer,Visian,"{Beam,Keras,NiFi,Tensorflow,Spark,Kafka,NoSQL,Hadoop,MXNet}",Télétravail partiel possible,"22, Rue du Président Wilson, Levallois-Perret, 92300","Intelligence artificielle / Machine Learning, IT / Digital, Stratégie",CDI,2023-05-03,"De la définition d’une roadmap digitale au lancement de produits et services innovants, Visian concrétise les ambitions de ses clients en veillant à intégrer durabilité et sobriété numérique. Visian est spécialisé dans l’innovation, le product design et la data. Ses consultants technophiles allient compréhension des enjeux digitaux et vision produit. Visian, cabinet de conseil spécialisé en Innovation, Design Produit, et Data, recherche pour son client, grand acteur du secteur de l’énergie, un Data Engineer pour rejoindre ses équipes sur un projet innovant. Contexte: La mission se déroule au sein de l’entité responsable du développement de méthodologies et d’outils d’IA/d’apprentissage automatique pour des solutions intelligentes et basées sur les données qui prennent en charge des modèles commerciaux nouveaux et innovants pour les chaînes de valeur existantes et futures. L’ingénieur sera responsable de l’expansion et de l’optimisation de l’architecture d’IA, en mettant des modèles d’apprentissage automatique. Il agira en soutien des développeurs de logiciels, architectes de bases de données, Data Analyst, et Data Scientist pour garantir l’architecture de prestation de services d’IA optimale Missions : Développer et maintenir un système de traitement de données à grande échelle Déployer des modèles ML (fournis par des scientifiques des données) S’assurer que les pipelines ETL construites prendront en charge les flux de données à volume élevé Détecter les opportunités d’acquisition, de stockage et d’interrogation de données de manière performante Utiliser une variété de langages et d’outils (sensibilisation aux données opensource apache/ML cadres connexes est une compétence indispensable) Comprendre, personnaliser et maintenir des projets open source et contribuer au développement de nouveaux cadres Toute séniorité en tant que Data Engineer sur des sujets d’IA Pratiques des Outils BIG DATA: Hadoop, Spark, Kafka, NoSQL, NiFi, Beam, Zookeeper,etc… Savoir Construire des pipelines ETL de données évolutifs et tolérants aux pannes basées sur les technologies du Big Data Expériences en implémentation d’inférences basées sur des modèles d’apprentissage profond avec des frameworks comme Apache MXNet, Tensorflow, Keras etc Mise en production des modèles ML suite à MLOps Expériences avec les langages de programmation orientés objet Compréhension du web sémantique / des Données liées Approches agiles (SCRUM, SAFE) Expériences de soutien et de travail avec des équipes interfonctionnelles dans un environnement dynamique Anglais courant 1 échange téléphonique (30min) 1 test technique (40min) 1 échange avec notre directeur commercial Yohan (30min) 1 échange dans nos bureaux avec la direction et un consultant tech sénior (30min)",,Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.18605210188381271
9,73934,https://www.welcometothejungle.com/fr/companies/the-product-crew/jobs/data-engineer_paris_TPC_KbxzMk8,Data Engineer,The Product Crew,{scale},Télétravail partiel possible,"11 Rue Greneta, Paris, 75003",Recrutement,CDI,2023-05-03,"Chez The Product Crew, ils cherchent à inventer le Futur du recrutement. Ils animent pour cela une communauté de membres sélectionnés pour leur talent en Product, Design, Data et Tech, avec pour vocation de leur apporter du soutien tout au long de leur vie professionnelle. Leur mission est d’aider les membres de cette communauté à libérer leur potentiel. Mais également de permettre aux entreprises de construire et commercialiser les plus meilleurs produits technologiques. Pour cela, ils organisent du partage de connaissance (webinars, ateliers, meetups, masterclass, contenus exclusifs…) et des sessions intensives de recrutement en ligne. Fort d’une communauté de plus de 7500 talents et de plus de 400 entreprises technologiques partenaires; The Product Crew s’adresse spécifiquement aux métiers du Product, du Design, de la Data et de la Tech. Nous travaillons avec +400 startups et scale ups de la scène tech française et européenne, à la recherche de Data Engineers expérimentés de Confirmés à C-Level : Heetch, Scaleway, Skello, Blablacar, Sendinblue, Mirakl, Partoo, Frichti, Swan, Jellysmack, MangoPay, Coinhouse … mais aussi les startups d’eFounders comme Collective Work, Numeral, ou Folk… et bien d’autres. Nous développons une communauté de hauts talents avec pour vocation d’apporter du soutien à leur carrière tout au long de leur vie professionnelle. Événements, ressources, sessions de recrutement… 🤜 Décroche ton prochain rôle de Data Engineers avec l’aide de la communauté The Product Crew 🤛 Comme chaque 1er du mois, nous lançons une nouvelle session de recrutement. Les inscriptions sont ouvertes pour quelques jours seulement : Tu as la possibilité de rendre ton profil visible auprès de nos startups partenaires, Celles qui sont intéressées rentrent directement en contact avec toi, Nous t’accompagnons tout au long du process. On sera ravis de t’accompagner ton prochain objectif 🚀 L’inscription prend 5min. Pas besoin de CV, et c’est 100% gratuit 😊 Voici le lien pour t’inscrire 👉 https://bit.ly/jobs-wttj En t’inscrivant 1 seule fois, tu pourras décrocher : 💎 Des mises en relations directes avec les équipes de ces startups 💎 Jusqu’à 10 opportunités concrètes en quelques jours 💎 Que des équipes qui ont flashé sur ton profil ⚡️ Tu peux postuler pour devenir membre de The Product Crew et participer à cette session de recrutement (ou à une prochaine). L’inscription prend 5min. Pas besoin de CV 😊 En prenant ton café ☕️ Inscription ici 👉 https://bit.ly/jobs-wttj",,Non spécifié,< 15 salariés,Non spécifié,2,1,0.18605210188381271
6,73826,https://www.welcometothejungle.com/fr/companies/iceberg/jobs/data-scientist-data-engineer_paris,Data Scientist/Data Engineer,Iceberg Data Lab,"{Ruby,Celery,ElasticSearch,Langchain,Pandas,Spark,Git,SQL,Streamlit,Iceberg,Python,Docker}",Télétravail partiel possible,"48, Boulevard des Batignolles, Paris, 75017",FinTech / InsurTech,Alternance,2023-05-03,"Get your resume ready, because you can help an innovative start-up accelerating the transition to a more Sustainable world ! Iceberg Data Lab is a Fintech developing data solutions to help financial institutions assessing their environmental impact with a strong focus on biodiversity, climate, and pollution prevention and control. Faced with growing demand from regulators and stakeholders and mounting environmental risks, Financial institutions need reliable data solutions. We help them (1) measuring their environmental impact and (2) aligning it to their ESG goals. To have the most relevant environmental scores, we need a rich database, relying of multiple sources (relying on a single source is risky), a efficient impact computation (mostly the 2° aligment and the biodiversity impact) and frequent deep analyses on the quality of our scoring. Among the ~30 companies employees, the data science team (4 people) is part of the IT team (10 people) and is looking for an apprentice to: Improve our data pipelines (we fetch financial and ecological data from different sources). The cleanest the data we fetch, the better is our final coverage of companies worldwide. Search and collect new data sources (GHG emissions from companies, assets, tons of products produced, consumed, companies facilities, etc. Leverage on Large Language Models (ChatGPT like) API and Langchain framework to improve our semi-structured data parser (like ESG reports) Automatically detect discrepancies between the default model and all refinements brought by our analysts. Benchmark our scores against academic environmental papers and competitors Minimum: Data Science, data analysis, data engineering, Python, Pandas, SQL, Git, interest in environmental issues. Optional: Machine Learning, Docker, Langchain, FastAPI, ElasticSearch, Streamlit, Spark, Kubertnetes, Celery, , Ruby, Financial or ecological knowledge. 20 min call, then 1H30 technical interview.",,Bac +4,< 15 salariés,Non spécifié,2,1,0.18605210188381271
4,73833,https://www.welcometothejungle.com/fr/companies/woop/jobs/data-modeler,Data Engineer,Woop,"{Bigquery,BigQuery,Mage,couchbase,postgreSQL,GCP,PostgreSQL,Python,Java,MongoDB,Couchbase,SQL,dbt,NoSQL,DBT}",Télétravail partiel possible,Lille,"Grande distribution, Logistique, SaaS / Cloud Services",CDI,2023-05-03,"✨ Il était une fois Woop… Créée en 2018, Woop est une startup qui met le Commerce en mouvement ! Notre plateforme SaaS connecte les marques omnicanales aux meilleurs transporteurs pour offrir une expérience de livraison exceptionnelle et responsable à leurs clients. 🌱Mapotempo, éditeur de solutions complètes de gestion de tournées, rejoint en 2022 l’équipe Woop afin de créer ensemble un Delivery Management System unifié. Woop, c’est aussi et surtout : 🫶Une équipe de plus 120 Moopistes enthousiastes et engagés, répartis sur 3 sites à Lille, Bordeaux et Pau. 📦Une start-up en pleine croissance qui intervient sur le sujet de la livraison du dernier kilomètre, au cœur des sujets de la ville de demain. 💛 Pourquoi coder chez Woop ..? Un projet au coeur de la ville de demain, à fort impact environnemental & sociétal La confiance et les responsabilités au sein d’une start-up adossée à un grand groupe Variété des produits, technos à la pointe et des experts Devops aux petits soins ! 👥 Ton équipe Aujourd’hui l’équipe technique WOOP est composée de : 1 CTO 1 Lead Engineer 1 Architecte Urbaniste 2 Release Manager 2 Lead & 11 Back-end Developer 3 Front-end Developer 1 Lead & 3 Mobile Developers 1 Lead QA et 3 QA Ton manager sera Haithem Souala . Il a pu démarrer sa carrière en tant que développeur Java, avant de passer ingénieur devops puis head of data. Il a récemment rédigé cet article sur Medium, expliquant comment on a intégré Mage.AI pour la réplication de nos data couchbase vers BigQuery. Tu auras l’occasion de travailler également avec Antoine, notre expert BI, qui a surtout travaillé sur des problématiques de geomarketing avant de rejoindre Woop. 💼 Tes missions L’équipe data s’agrandit et recherche un data modeler qui participera à la conception et au développement de nos modèles de données, pour représenter les informations de manière structurée et hiérarchisée, en tenant compte des besoins des utilisateurs finaux. Le but est de pouvoir offrir à nos clients des outils d’analytics et des dashboards pour qu’il puissent avoir une visibilité sur des données comme les ordres de transport, les paiements, ou le suivi des émissions de CO2. Au niveau de la roadmap, on en est au début du projet. L’objectif pour les 6 prochains mois sera de modéliser la data, pour transformer notre data brute en un data warehouse clair avec des patterns identifiés. Par la suite, les missions évolueront vers plus de BI (notamment pour les dashboards), et à long terme, de machine learning. Plus de précisions sur le poste : Exploration de données : Examiner les données pour en comprendre les tendances, les modèles et les relations entre les variables. Analyse des données : Utiliser des techniques statistiques et des algorithmes d’apprentissage automatique pour analyser les données et en extraire des informations significatives. Communication des résultats : Présenter les résultats de l’analyse aux parties prenantes et expliquer les implications pour les décisions métier. Collaboration avec les équipes interfonctionnelles : Travailler en étroite collaboration avec les équipes métier, IT et autres pour assurer la compréhension et l’utilisation des informations. Optimisation des performances : Améliorer la performance des modèles de données et des analyses en ajustant les paramètres et en mettant en œuvre de nouvelles techniques. Veille technologique : Se tenir informé des dernières tendances et technologies dans le domaine de la modélisation et de l’analyse des données, afin de continuellement améliorer les méthodes et les outils utilisés. Documentation : Rédiger et maintenir la documentation relative aux modèles de données, aux processus d’analyse et aux résultats obtenus. Formation des utilisateurs : Former les utilisateurs finaux et les parties prenantes sur la manière d’utiliser et d’interpréter les résultats des analyses de données. Pour ce qui est de notre stack, on utilise postgreSQL pour nos bases de données SQL. Concernant nos bases de données NoSQL, on est sur MongoDB et Couchbase. Aussi, pour la récupération de données d’applications tierces, on ira les chercher aussi bien sur Jira ou Hubspot. Enfin, côté cloud, on utilise la suite GCP et notamment son Data Warehouse Bigquery. Surtout, sur la phase de modélisation, on est amené à travailler avec dbt pour modéliser la donnée brute. Si jamais tu ne te sens pas à l’aise avec l’outil, on peut prendre le temps de te former dessus durant quelques semaines (surtout si tu as bonnes bases sur les bases de données SQL)! Tu l’as compris, nous faisons face à de multiples projets build stratégiques. Pour réussir à nos côtés dans cette mission, il te faudra connaître: La modélisation des données avec DBT: Tu as des connaissances des concepts et techniques de modélisation de données, comme les modèles relationnels, les modèles en étoile et OBT Les bases de données : Tu as des connaissance approfondies des systèmes de gestion de bases de données: BigQuery, PostgreSQL, MongoDB Les langages de programmation : Tu as des connaissances de langages de programmation comme Python Pour ce qui est de l’expérience, nous sommes ouverts aux personnes ayant eu un premier rôle similaire. Plus que le nombre d’années sur le rôle, ce qui importe ici, est surtout le fait de comprendre les problématiques liées à la modélisation de données, et de faire une veille constante sur le sujet. Aussi, pour réussir sur ce poste, il sera important de faire preuve d’autonomie, de force de proposition et d’audace. ⭐️ Let’s’ Woopit ! Poste en CDI Rémunération à définir selon expérience 3 bureaux en France pour rencontrer tes collègues : Lille, Pau et Bordeaux 11 RTT/an Flex office avec 3 jours en remote par semaine Assurance santé prise en charge à 60 % Formations Soft & Hard Skills Hackathons & petits déjeuners tech hebdomadaires Team buildings réguliers Un rôle clé dans une start-up en pleine croissance ! Pré-qualification (visio de 30 mns) avec Boubou, notre Talent Acquisition Specialist, pour se présenter Entretien technique avec Haithem, notre Head of Data Entretien avec François, notre CTO Dernier échange avec Perrine ou Boubou, membres de l’équipe Talent Acquisition pour parler de Woop, notre vision et nos valeurs Nous sommes engagés en faveur de l’intégration des femmes dans la tech Dans le livre The Confidence Code* , les autrices ont démontré que les femmes ne postulent à un emploi que si elles correspondent à 100 % aux exigences de l’offre. Les hommes, quant à eux, envoient leur candidature s’ils remplissent 60 % des critères. Saches qu’ici, il n’est pas forcément nécessaire de maîtriser à 100% les missions mentionnées sur l’offre. On met aussi l’accent sur la montée en compétences, et si ce poste t’intéresse, n’hésites pas à postuler! *The Confidence Code, Claire Schipman & Katty Kay, 2014",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.18605210188381271
14,73729,https://www.welcometothejungle.com/fr/companies/descartes-mauss/jobs/data-engineer_paris,Data engineer,Descartes & Mauss,"{GCP,scale,SQL,Spark}",Télétravail partiel possible,"Paris, 75001","Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Stratégie",CDI,2023-05-03,"Want to help predict the future? Our platform uses leading edge A.I. to help some of the world’s biggest brands identify the future trends that will shape their industry five years from now. By combining advanced data modelling, machine learning, and generative AI with intuitive user centric design, our products help organizations develop better, more resilient long term strategies with the detail needed to make them happen. We are looking for an experienced, highly motivated, entrepreneurial and dedicated data engineer, who ensures technical excellence and quality assurance is embedded into everything they do Responsibilities: Design, implement and maintain scalable data pipelines, databases and Lakehouses Work with cross-functional teams to optimize data flow and collection Develop and maintain database systems Ensure data quality and accuracy Troubleshoot and debug data pipeline, database and Lakehouse issues Manage data security Stay up to date with new technologies and suggest improvements to existing systems Bachelor’s or Master’s degree in Computer Science, Data Science, or a related field 3+ years of experience in data engineering Proficient in SQL and experience with database development and management Experience with large-scale data processing tools such as Apache Spark Experience with cloud computing services such as GCP Strong problem-solving and troubleshooting skills Excellent communication and collaboration skills Ability to work independently and in a team environment What we offer: Flexible working arrangements: A flexible hybrid approach to work. Work from home (or wherever you do your best work) up to 3 days per week. 2 days per week in the office with colleagues (depending on your location). Access to WeWork offices worldwide. An international, diverse, and inclusive work environment: join a team that already boasts 12 nationalities and counting. Regular team building activities Company-wide events locally and abroad (our last was in Copenhagen). Continuous learning and development: A culture that supports career growth and well-being, guided by mentors, managers, and peers. Access to annual training and development resources. Collaborate with world-renowned AI experts from institutions like Carnegie Mellon, MIT, and France’s École Polytechnique, who serve as advisors for the product you’ll be working on and are at the forefront of shaping AI’s future.",,Non spécifié,Entre 15 et 50 salariés,Non spécifié,2,1,0.18605210188381271
8,73870,https://www.welcometothejungle.com/fr/companies/groupe-ingena/jobs/data-engineer-h-f_paris,Data Engineer,Groupe Ingena,"{Scala,HDFS,HBase,Azure,MapR,Hive,GCP,Java,AWS,Git,durable,Jenkins,Kubernetes,NoSQL,Hadoop,Python,SPARK,Docker}",Télétravail partiel possible,"140 bis Rue de Rennes, Paris, 75006",IT / Digital,CDI,2023-05-03,"Le groupe INGENA promeut la transition numérique en étant acteur d’un monde souhaitable. Le Groupe INGENA est spécialisé en Conseil Métier et en Intégration pour les marchés de l’Assurance, de la Banque et de la Finance. Il intervient notamment sur les projets associés à la Data, aux Risques et à la Distribution. DRiMS est son entité spécialisée en Finance de Marché. INGENA Assurance adresse les métiers de l’Assurance et de la Prévoyance. Son effort constant d’innovation et de veille métier, et son réseau de partenaires éditeurs, lui permettent d’accompagner proactivement les besoins de ses clients. Le groupe INGENA revendique une conception humaniste de la relation. L’Homme, ses valeurs fondamentales, ses savoir-faire et son savoir-être sont les vecteurs fondamentaux de la relation. Les processus, les outils et la technologie sont au service de cette relation. Les valeurs humaines qui fondent leur entreprise, ENGAGEMENT, INTEGRITE, BIENVEILLANCE les inscrivent durablement sur un temps long. La mise en pratique du monde souhaitable au sein du groupe INGENA, c’est une entreprise éco-responsable, éthique, inclusive, sociale, soucieuse du bien-être, de l’évolution et de l’épanouissement de ses équipes. Ce sont aussi des offres pour un monde durable comme la maîtrise des risques ou l’ESG. Dans un esprit convivial et engagé, les dirigeants d’INGENA font en sorte que chacun puisse être acteur de l’INGENA souhaitable. Votre mission : · Concevoir, développer et tester des algorithmes de collecte et de traitement de gros volumes de données sous Scala, Python ou Java · Automatiser et optimiser les flux de données et leurs visualisations en dashboards · Industrialiser les traitements, la qualité et l’intégrité des données · Participer à la Modélisation et à la Gouvernance des données (process, normalisation, référentiel,…) · Contribuer à la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme · Analyser les données pour répondre aux questions métiers et participer à l’évolution de l’architecture Big Data · Concevoir, Développer et Industrialiser des modèles de Machine Learning, Deep Learning, en collaboration avec les Data Scientists · Appliquer une démarche CI/CD (Git, Jira, Jenkins) · Expérience de 5 ans minimum en développements Scala, Python ou Java · Expérience de 2 ans minimum sur SPARK et sur le traitement des flux en streaming · Expertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou Hortonworks · Expérience souhaitée sur ELK, Terraform, NoSQL,… · Fort background en Modélisation de données ou ETL · Maîtrise des briques analytiques des clouds AWS, GCP ou Azure · Sensibilisation à la démarche CI/CD tools (Git, Jenkins) · La connaissance de Docker, Kubernetes et Ansible est un plus · Mise en œuvre des méthodes Agile (Scrum, Kanban,…) · Anglais souhaité",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,2,1,0.18605210188381271
3,73783,https://www.welcometothejungle.com/fr/companies/pix/jobs/data-engineer-data-analyst-h-f_paris-19,Data Engineer/Data Analyst (h/f),Pix,"{Scala,Tableau,Pandas,Unix,Metabase,Spark,Git,via,SQL,Linux,NoSQL,QlikView,Python,docker}",Télétravail ponctuel autorisé,"Paris 19, 75019","IT / Digital, Formation",CDI,2023-05-03,"Chez Pix, nous travaillons pour permettre à chaque citoyen de mesurer, d’améliorer et de valoriser tout au long de sa vie son niveau de maîtrise des usages numériques. Comment ? En développant une plateforme en ligne gratuite adaptée à tous les niveaux pour s’auto-évaluer et progresser dans 5 grands domaines du numérique, En proposant une expérience ludique via des questions-défis apprenants et des activités interactives axées sur la pratique, En valorisant les acquis via le passage de la Certification Pix, reconnue par l’Etat et le monde professionnel, En outillant les acteurs de l’enseignement, de la formation professionnelle, de l’insertion et de la médiation numérique, en France et à l’international. Aujourd’hui, Pix c’est : 💻 Près de 75 000 usagers chaque jour 🤝 6 millions d’utilisateurs par an 🏆 2.7 millions de Certification Pix passées 🌍 Utilisé dans 18 pays Avec plus de 240 millions de réponses apportées par 3,5 millions d’utilisateurs, Pix accueille et traite de grandes quantités de données. Leur analyse est au cœur de notre activité et apporte des informations précieuses, que ce soit pour identifier le niveau de maîtrise des utilisateurs, leur suggérer des actions de formation pertinentes, piloter le déploiement des usages, améliorer la qualité des services, ou encore contribuer à la production de statistiques publiques. Vous savez manipuler de grandes quantités de données et mettre en place les architectures pour le faire facilement ? Vous connaissez les différents types de SGBD, que ce soit SQL, NoSQL ou clé/valeur ? Vous aimez travailler en lien avec des partenaires variés, en interne comme en externe ? Alors Pix vous ouvre grand ses portes ! Le ou la Data Engineer sera rattaché(e) au pôle développement de Pix, en collaboration étroite avec le pôle Produit. Les missions : 1. Concevoir et mettre en place des architecture et des plateformes permettant l’étude et la valorisation de nos données Pour traiter les volumes importants de données au sein de Pix, nous avons besoin de maintenir mais aussi de mettre en place nos architectures de données et des plateformes pour les utiliser. Vous serez notamment en charge de : Définir, avec le métier ou l’équipe de développement, les besoins en termes de data Proposer et valider des choix architecturaux Mettre en place les architectures choisies Développer des pipelines pour une bonne circulation des données et pour assurer leur fiabilité 2. Maintenir les architectures et bases de données mises en places Garantir le bon fonctionnement, la disponibilité et la performance des différentes bases de données et outils utilisés pour l’analyse de données Proposer et valider des choix architecturaux Mettre en place les architectures 3. Travailler avec l’équipe data mais aussi avec l’équipe de développement pour améliorer globalement les pratiques Vous serez amené à travailler avec l’équipe de développement produit, et dans ce cadre à : Aider dans les choix data de l’équipe de développement produit Contribuer à optimiser notre architecture et nos bases de données Participer aux ateliers de partage et de réflexion sur des problématiques techniques de la plateforme Data Contribuer à la mise en place d’algorithmes de machine learning Avantages Télétravail partiel possible 2 à 3 jours par semaine en fonction du rythme de l’équipe 20 RTT par an titres restaurant prime de fin d’année, prime télétravail, prime d’équipement. Conditions Type d’emploi : CDI ou mise à disposition pour les agents de la fonction publique Chez Pix, nous veillons à l’équilibre de l’équipe et le bien-être des personnes qui la composent. Cette conviction nous pousse à chercher un profil avec les qualités humaines et opérationnelles suivantes : Diplôme et expérience Vous êtes diplômé(e) au minimum d'un Bac + 5 et vous avez minimum 3 années d’expérience sur un poste similaire. Vous avez une expérience dans la conception, l'implémentation et l'automatisation de pipelines de données Savoir-faire et savoir-être - Curiosité, dynamisme, force de proposition - Autonomie et grande rigueur - Capacités d’écoute, bon relationnel (savoir s’adapter à son interlocuteur) et qualités de communication - Capacités à travailler en équipe et à mener des activités de façon collaborative - Envie de partager les connaissances Connaissances et compétences - La maîtrise d’un framework: Spark, Pandas ... - La maîtrise du SQL - Une bonne connaissance de Git et des outils d’intégration et de déploiement continue : création de CI/CD, docker, etc.. - Maîtrise des langages de programmations : Scala, Python. Le JS serait un plus- Connaissances des systèmes d’exploitation : Unix, Linux - Connaissances des bases de données PGSQL, etc ... - Savoir consolider les données, produire des KPI et avoir des notions de conception de tableaux de bord à l’aide d’outils de data visualisation tels que Metabase, Excel Power BI, Tableau Software, ou encore QlikView- Avoir des connaissances basiques sur le Machine Learning, et la Data science afin de pouvoir travailler en collaboration avec l’équipe Data et l’équipe de développeurs. Candidater chez Pix, c’est vouloir intégrer une structure innovante, comportant une diversité de profils issus des domaines de la tech, du secteur public et privé. C’est aussi vouloir évoluer auprès de collègues engagés, qui souhaitent avoir un impact sur la société en mettant leurs compétences au service d’un projet d’utilité sociale d’envergure nationale et internationale. Si un bon CV est toujours agréable à lire, nous pensons qu’une bonne histoire bien racontée (avec son lot de projets et d’expériences, réussites ou échecs) est encore plus intéressante à découvrir. Pour rejoindre un service public en pleine expansion, envoyez-nous votre candidature !",,Non spécifié,Entre 50 et 250 salariés,Non spécifié,1,1,0.12403473458920848
5,73765,https://www.welcometothejungle.com/fr/companies/amazon-web-services/jobs/data-center-project-engineer-mechanical_courbevoie,Data Center Project Engineer - Mechanical,Amazon Web Services,"{regard,AWS}",NaN,"31, Place des Corolles, Courbevoie, 92400",SaaS / Cloud Services,CDI,2023-05-03,"Amazon Web Services (AWS) est la plateforme cloud la plus complète et la plus largement adoptée au monde. Elle propose plus de 200 services complets issus de centres de données du monde entier. Des millions de clients (dont certaines des startups les plus dynamiques au monde, de très grandes entreprises et des agences fédérales de premier plan) utilisent AWS pour réduire leurs coûts, gagner en agilité et innover plus rapidement. The Global Expansion Engineering team is looking for a results-oriented, inventive data center engineer to drive development, implementation and delivery of enterprise data centers through the use of colocation facilities, which meet strict quality and performance levels across the globe. What we offer: Amazon offers a fast paced, fun, and exciting work environment. We continue to grow at exponential rates and are looking for individuals that can support our speed to market, enjoy a challenge, and have a desire for professional growth and continuous learning experiences. Amazon’s work environment is unique in every aspect and offers an exceptional opportunity for the right candidate. Our Global Expansion Engineers (Data Center Project Engineer): assist in site planning, development and delivery of data center environments globally, which maintain the highest performance standards and utilize innovation to reduce budgets and increase efficiency. design review site selection technical negotiation single point of failure remediation infrastructure upgrade site acceptance of mission-critical facilities and associated MEP components. You may also be required to respond to off hour calls in regard to emergent events and contribute to the resolution of various data center performance impacting infrastructure issues. Our Engineers are strong leaders who can prioritize well, communicate clearly, and have a consistent track record of delivery. Master’s degree in Mechanical/ Electrical Engineering or relevant discipline. 3-5 years experience directly related to Data Center Infrastructure Professional Engineering license. Certified Data Center Design Professional (CDCDP). Understanding of international code requirements. Fundamental knowledge of network design and layout. Possess excellent communication skills, attention to detail, and maintain high quality standards. Possess leadership and problem solving skills. Be a motivated, highly dependable individual. Amazon est un employeur engagé pour l'égalité des chances. Nous sommes convaincus qu'une main d'oeuvre diversifée est essentielle à notre réussite. Nous prenons nos décisions de recrutement en fonction de votre expérience et de vos compétences. Nous apprécions votre envie de découvrir, d'inventer, de simplifier et de construire. La protection de votre vie privée et la sécurité de vos données constituent depuis longtemps une priorité absolue pour Amazon. Veuillez consulter notre Politique de Confidentialité pour en savoir plus sur la façon dont nous collectons, utilisons et traitons les données personnelles de nos candidats.",,Bac +3,N,> 5 ans,0,1,0.06201736729460424
