import pytest
import pandas as pd
import numpy as np


@pytest.fixture(scope="session")
def sample_raw_jobs():
    normal = pd.DataFrame({
        'id': 56886,
        'url': 'https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/data-engineer',
        'title': 'Data Engineer',
        'company': '52 Entertainment',
        'location': "Villeneuve-D'ascq",
        'type': 'CDI',
        'industry': 'Jeux vid√©o',
        'remote': 'T√©l√©travail total possible',
        'created_at': np.datetime64('2023-03-26T01:00:00.000000'),
        'text': " 52 Entertainment is a leading e-gaming company, worldwide leader on the Online Bridge with recognized brands like  Bridge Base Online ,  Funbridge ,  Exoty ,  Casualino  and on the e-sailing thanks to its well known  Virtual Regatta . One of the worldwide leader on a lot of e-mind and strategy games like Tarot, Canasta or Belote to name a few. At the crossroads of gaming, entertainment and e-sport 52 entertainment provides unique experiences to truthful communities. Based in France (Lille) with offices and people all around the globe 52 entertainment invents the tomorrow‚Äôs company based on  People ,  Innovation  and  Mindset . Job description We are looking for a  Data Engineer  to join our Data Team. You will be responsible for  developing, implementing, and monitoring the Data Pipelines of several games of the group . You will work inside the Data Team (1 Data Engineer, 2 Analytics Engineers, 4 Data Analysts, 1 Data scientist) and you will report to the Head of Growth and Data. We use a  modern data stack  that is primarily composed of  Google BigQuery, dbt, Airbyte, Prefect, Deepnote  and  Looker . The Data Engineering activities focus on GCP, Airbyte, Prefect but also includes Prometheus, Thanos, Graphana tools and Kubernetes nodes management.  Team description The Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia).  The Data team is fully remote  (but all the team is currently based in Europe). We are using top notch communication & project management tools (Slack/Jira/Confluence) and a fantastic stack of technical tools (Airbyte, Prefect, Google Big Query, dbt, Looker, ‚Ä¶) . We talk to each other on a daily basis and organize frequent virtual coffees ‚òïÔ∏è.  Some are geeks, some are not, apply as you are,  we‚Äôre a diversity-friendly team  üßï üëßüèΩ  ü•∑ üë®üèø üë© ü¶æ. Stack Data: Airbyte, Prefect, Google BigQuery, dbt, Github, VSCode, Deepnote & Looker Project Management: Slack, Google Drive, Confluence, Jira Missions Create, monitor, and optimize Data Pipelines for existing Games and third-party sources.   Manage relations with B.U. Developers and be proactive to prevent pipeline deprecation because of products evolution.  Ingest third-party data and setup data consumption endpoints.  Ensuring best practices for data integrity and performances. Investigate new initiatives like Data Cataloging, Data Discovery, ML Ops Provide our Data Scientists with Big Data tools that will allow them to process our data more easily (prediction, machine learning, ‚Ä¶). We‚Äôre excited about you because‚Ä¶ You‚Äôve been hesitating between Dev Ops and Data Engineering for a while, but realized that the later was much more fun+   While you already have some experience in this role, you are passionate to learn even more and want to grow as an expert in a friendly team, while being coached by a senior Data Engineer. +You can easily discuss technical concepts with other Dev Ops to help other teams create systems you will need to connect your pipelines to. +You like to learn new concepts and tools and are not afraid of getting your hands dirty.                                                                                                                                                                                     +Benefits Work in a start-up with exceptional growth +Highly interesting work environment with flat hierarchies, fast pace and fun                                                                                                                                                         +You‚Äôll have a real impact on people‚Äôs lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development.                                                                                                                +Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best.                                                                                                                                                                                       + Extreme autonomy. No micro-managing here. After onboarding, you‚Äôll be given high-level direction and then left to solve it the way you feel is best.                                                                                                                                                                                                            +Amazingly friendly Data team.                                                               +‚ÄÉ Your Profile Minimum 1.5 year of experience either in Data Engineering, Big Data or DevOps                                                                                                                                                                                                          +Familiar with modern data stacks and principles (cloud-based platforms/data-lakes and managed services)                                             +Skilled in SQL and Python                                             +Experienced in working in interdisciplinary teams and in multi-cultural team environments                                                                                                                                                                                             +Strong communication skills and facilitation abilities                                                                                        +Priorities management & time management skills                                                                                                                    +Highly open minded                                                                                                      +Diplomacy, pedagogy and humility                                                                                                                       +Fluent English.                                                                                               +Collecting applications until April 7th 2023  First interviews from March 27th 2023 onward. Our hiring process is sequential : we know job seeking is a stressful time of life, and we‚Äôll make sure things are transparent from our side. If you don‚Äôt pass step 2, we won‚Äôt waste your time on step3.  Interview steps Step 1 Visio-call - Preliminary interview where the scope of mission, our company, your aspirations, and salary compensation are discussed to see if we agree on the important things on both sides (30 min)                                                                                                                                                                      +Step 2 Written case-study - Few questions to check that written communication is clear                                                                                                          +Step 3 Technical case-study - Skills check (take home assignment) on some data problems (no more than 2 hours of involvement)                                                                                                                                                                                                   +Step 3 Visio-call - Debrief from assignment + Experience and background discussion to get to know you and your experience in Data. Interview questions will be sent ahead of time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          +"
    }, index=[0])
    missing_value = pd.DataFrame({
        'id': 1,
        'url': 'https://www.welcometothejungle.com/fr/missing-value',
        'title': 'Data Engineer',
        'company': 'Missing Data',
        'location': "China",
        'type': 'CDD',
        'industry': 'Surveillance',
        'remote': 'N',
        'created_at': np.datetime64('2023-03-26T01:00:00.000000'),
        'text': "Lorem ipsum"
    }, index=[0])
    return pd.concat([normal, missing_value], ignore_index=True)


# Output of preprocess()
normal = pd.DataFrame({
    'id': 56886,
    'url': 'https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/data-engineer',
    'title': 'Data Engineer',
    'company': '52 Entertainment',
    'location': "Villeneuve-D'ascq",
    'type': 'CDI',
    'industry': 'Jeux vid√©o',
    'remote': 'T√©l√©travail total possible',
    'created_at': np.datetime64('2023-03-26T01:00:00.000000'),
    'text': "52 Entertainment is a leading e-gaming company, worldwide leader on the Online Bridge with recognized brands like  Bridge Base Online ,  Funbridge ,  Exoty ,  Casualino  and on the e-sailing thanks to its well known  Virtual Regatta . One of the worldwide leader on a lot of e-mind and strategy games like Tarot, Canasta or Belote to name a few. At the crossroads of gaming, entertainment and e-sport 52 entertainment provides unique experiences to truthful communities. Based in France (Lille) with offices and people all around the globe 52 entertainment invents the tomorrow‚Äôs company based on  People ,  Innovation  and  Mindset . Job description We are looking for a  Data Engineer  to join our Data Team. You will be responsible for  developing, implementing, and monitoring the Data Pipelines of several games of the group . You will work inside the Data Team (1 Data Engineer, 2 Analytics Engineers, 4 Data Analysts, 1 Data scientist) and you will report to the Head of Growth and Data. We use a  modern data stack  that is primarily composed of  Google BigQuery, dbt, Airbyte, Prefect, Deepnote  and  Looker . The Data Engineering activities focus on GCP, Airbyte, Prefect but also includes Prometheus, Thanos, Graphana tools and Kubernetes nodes management.  Team description The Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia).  The Data team is fully remote  (but all the team is currently based in Europe). We are using top notch communication & project management tools (Slack/Jira/Confluence) and a fantastic stack of technical tools (Airbyte, Prefect, Google Big Query, dbt, Looker, ‚Ä¶) . We talk to each other on a daily basis and organize frequent virtual coffees ‚òïÔ∏è.  Some are geeks, some are not, apply as you are,  we‚Äôre a diversity-friendly team  üßï üëßüèΩ  ü•∑ üë®üèø üë© ü¶æ. Stack Data: Airbyte, Prefect, Google BigQuery, dbt, Github, VSCode, Deepnote & Looker Project Management: Slack, Google Drive, Confluence, Jira Missions Create, monitor, and optimize Data Pipelines for existing Games and third-party sources. Manage relations with B.U. Developers and be proactive to prevent pipeline deprecation because of products evolution.  Ingest third-party data and setup data consumption endpoints.  Ensuring best practices for data integrity and performances. Investigate new initiatives like Data Cataloging, Data Discovery, ML Ops Provide our Data Scientists with Big Data tools that will allow them to process our data more easily (prediction, machine learning, ‚Ä¶). We‚Äôre excited about you because‚Ä¶ You‚Äôve been hesitating between Dev Ops and Data Engineering for a while, but realized that the later was much more fun+ While you already have some experience in this role, you are passionate to learn even more and want to grow as an expert in a friendly team, while being coached by a senior Data Engineer. +You can easily discuss technical concepts with other Dev Ops to help other teams create systems you will need to connect your pipelines to. +You like to learn new concepts and tools and are not afraid of getting your hands dirty. +Benefits Work in a start-up with exceptional growth +Highly interesting work environment with flat hierarchies, fast pace and fun +You‚Äôll have a real impact on people‚Äôs lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development. +Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best. + Extreme autonomy. No micro-managing here. After onboarding, you‚Äôll be given high-level direction and then left to solve it the way you feel is best. +Amazingly friendly Data team. +‚ÄÉ Your Profile Minimum 1.5 year of experience either in Data Engineering, Big Data or DevOps +Familiar with modern data stacks and principles (cloud-based platforms/data-lakes and managed services) +Skilled in SQL and Python +Experienced in working in interdisciplinary teams and in multi-cultural team environments +Strong communication skills and facilitation abilities +Priorities management & time management skills +Highly open minded +Diplomacy, pedagogy and humility +Fluent English. +Collecting applications until April 7th 2023  First interviews from March 27th 2023 onward. Our hiring process is sequential : we know job seeking is a stressful time of life, and we‚Äôll make sure things are transparent from our side. If you don‚Äôt pass step 2, we won‚Äôt waste your time on step3.  Interview steps Step 1 Visio-call - Preliminary interview where the scope of mission, our company, your aspirations, and salary compensation are discussed to see if we agree on the important things on both sides (30 min) +Step 2 Written case-study - Few questions to check that written communication is clear +Step 3 Technical case-study - Skills check (take home assignment) on some data problems (no more than 2 hours of involvement) +Step 3 Visio-call - Debrief from assignment + Experience and background discussion to get to know you and your experience in Data. Interview questions will be sent ahead of time. +"
}, index=[0])
missing_value = pd.DataFrame({
    'id': 1,
    'url': 'https://www.welcometothejungle.com/fr/missing-value',
    'title': 'Data Engineer',
    'company': 'Missing Data',
    'location': "China",
    'type': 'CDD',
    'industry': 'Surveillance',
    'remote': np.nan,
    'created_at': np.datetime64('2023-03-26T01:00:00.000000'),
    'text': "Lorem ipsum"
}, index=[1])
preprocessed_jobs = pd.concat([normal, missing_value], ignore_index=True)


@pytest.fixture(scope="session")
def sample_preprocessed_jobs():
    return preprocessed_jobs


# Output of process_technos()
stacked = preprocessed_jobs.copy()
stacked['stack'] = ''
stacked['stack'] = stacked['stack'].apply(
    lambda x: ['Looker', 'Prefect', 'Airbyte', 'Prometheus', 'SQL', 'BigQuery',
               'Deepnote', 'GCP', 'Kubernetes', 'Python', 'Github', 'dbt'])
stacked.loc[1, 'stack'] = ''
df_technos = pd.DataFrame({0: ['Looker', None],
                           1: ['Prefect', None],
                           2: ['Airbyte', None],
                           3: ['Prometheus', None],
                           4: ['SQL', None],
                           5: ['BigQuery', None],
                           6: ['Deepnote', None],
                           7: ['GCP', None],
                           8: ['Kubernetes', None],
                           9: ['Python', None],
                           10: ['Github', None],
                           11: ['dbt', None]})
processed_jobs = pd.merge(stacked, df_technos, left_index=True, right_index=True)


@pytest.fixture(scope="session")
def sample_processed_jobs():
    return processed_jobs

@pytest.fixture(scope="session")
def text_input_gpt():
    text = 'Sicara est une startup experte en data, bas√©e √† Paris : nous r√©volutionnons les projets data en combinant notre m√©thodologie agile de delivery de projet et notre savoir-faire en data science et data engineering afin d‚Äôaider nos clients √† capitaliser sur le potentiel de la donn√©e. Filiale du groupe Theodo, un √©cosyst√®me de 9 filiales et +400 personnes situ√©es √† Paris, Londres, New York et Casablanca, cr√©√©e en novembre 2016 , Sicara est pass√©e de 2 √† 35 personnes en quatre ans. Pour soutenir notre croissance de 50%, nous cherchons √† faire grandir notre portefeuille client. R√©guli√®rement en contact avec les √©quipes techniques et les consultants Sicara seniors, nos AI Project Managers utilisent leurs comp√©tences pour d√©ployer la m√©thodologie projet de d√©veloppement de solution en data science. Sur nos projets, tu seras amen√©(e) √† : Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tier+\
  Travailler en √©quipe de 2 √† 4 data engineers √©paul√©s par un coach agile et un coach technique                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +\
  Mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) sur le cloud                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             +\
  D√©ployer les pipelines de donn√©es (ETL et ELT)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             +\
  Assurer la migration des donn√©es vers les nouveaux environnements                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          +\
  Mettre en place des outils de contr√¥le de la qualit√© de la donn√©e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          +\
  Accompagner et former les √©quipes clients                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  +\
  Au sein de Sicara, tu seras amen√©¬∑e √† : Contribuer √† notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               +\
  Contribuer √† am√©liorer nos savoir-faire en exp√©rimentant continuellement de nouvelles m√©thodes et de nouveaux outils afin d‚Äôam√©liorer l‚Äôefficacit√© des √©quipes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            +\
  Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         +\
  Tu as une forte app√©tence pour le secteur de la data et tu as id√©alement une premi√®re exp√©rience dans le conseil ou dans la tech                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           +\
  Tu as une exp√©rience pass√©e en tant que Data Engineer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      +\
  Tu as envie de progresser et d‚Äô√©voluer dans un environnement challengeant et bienveillant au quotidien                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     +\
  Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data (Spark, Scala, Hadoop)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +\
  Tu connais ou as envie d‚Äôapprendre √† utiliser l‚Äôun des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       +\
  1 entretien RH + 2 entretiens techniques + 2 entretiens dirigeants'
    return text